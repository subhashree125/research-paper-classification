{
  "The University of Hong Kong Shenzhen Key Laboratory of Safety and Security for Next Generationof Industrial Internet, Southern University of Science and Technology University of Reading": "AbstractIntrusion Detection Systems (IDS) are crucial forsafeguarding digital infrastructure. In dynamic network environ-ments, both threat landscapes and normal operational behaviorsare constantly changing, resulting in concept drift. While con-tinuous learning mitigates the adverse effects of concept drift,insufficient attention to drift patterns and excessive preservationof outdated knowledge can still hinder the IDSs adaptability. Inthis paper, we propose SSF (Strategic Selection and Forgetting),a novel continual learning method for IDS, providing continuousmodel updates with a constantly refreshed memory buffer. Ourapproach features a strategic sample selection algorithm to selectrepresentative new samples and a strategic forgetting mechanismto drop outdated samples. The proposed strategic sample selec-tion algorithm prioritizes new samples that cause the driftedpattern, enabling the model to better understand the evolvinglandscape. Additionally, we introduce strategic forgetting upondetecting significant drift by discarding outdated samples tofree up memory, allowing the incorporation of more recentdata. SSF captures evolving patterns effectively and ensures themodel is aligned with the change of data patterns, significantlyenhancing the IDSs adaptability to concept drift. The state-of-the-art performance of SSF on NSL-KDD and UNSW-NB15datasets demonstrates its superior adaptability to concept driftfor network intrusion detection.Index Termscontinual learning, concept drift, network intru-sion detection",
  "I. INTRODUCTION": "Intrusion Detection Systems (IDSs) serve as the primarydefenders of digital infrastructures and interconnected systems,such as the Internet of Things, playing a critical role in moni-toring network traffic to identify and alert on unauthorized ormalicious activities . They act as early warning systems,providing vital defense against the constant threat of cyber-attacks and ensuring system integrity .In dynamic network environments, both the threat land-scapes and normal operational behaviors are constantly chang-ing . Attackers always look for new vulnerabilities, leadingto new attack types. Additionally, user behaviors may shift,resulting in changing normal operation patterns. These ele-ments drive concept drift , a phenomenon characterizedby changing statistical distribution in data over time .The effectiveness of IDSs depends on their ability to detect,anticipate, and adapt to the above changes. This adaptability",
  "Co-corresponding authors: Edith C.H. Ngai (Email: ),Shuang-Hua Yang (Email: )": "is crucial for maintaining their resilience against the persistentevolution of both cyber attacks and normal patterns.However, traditional learning-based IDSs typi-cally function with static models that, once trained, remainunchanged regardless of subsequent shifts in the environment,like system behaviors or attack strategies. This static naturereveals that most existing learning-based IDSs cannot copewith the inherent variability of dynamic environments, as theylack mechanisms to adapt to concept drift.By incorporating continual learning, IDSs can adapt to con-cept drift with the capability for continuous updates and evolu-tion , . To keep pace with concept drifts, it is essentialto select new samples that accurately reflect these evolvingpatterns. However, existing continual learning strategies typ-ically employ random sampling , or rely on criteriasuch as the importance of a sample in the learning processor its representativeness of the overall distribution . Thesecriteria often fail to provide adequate attention to the driftedpattern, the most challenging aspect. Simply treating the driftas part of the overall distribution overlooks its critical role incausing concept drift. In addition, the most common solutionin current continual learning methods is to preserveas much old knowledge as possible to prevent catastrophicforgetting , where a model forgets previously learnedinformation upon learning new data. However, they ignore thepotential concern that past knowledge becomes out-of-date orrequires correction when drifting occurs. Maintaining outdatedor incorrect knowledge can hinder, rather than facilitate, themodels adaptation to new drifts .In this work, we present SSF (Strategic Selection andForgetting), a novel continual learning method that providesdynamic model updates to the IDS, facilitated by a refreshedmemory buffer to strategically address concept drifts byincluding the most representative new data while retaininguseful historical data. More specifically, we propose a novelsample selection strategy that identifies the most representativenew samples for the drifted pattern. By accurately capturingthese drifts, our algorithm significantly enhances the modelsadaptability to concept drift and provides valuable insightsinto the evolving landscape. For the unchanged pattern, weutilize already labeled old samples to save labeling effort.This combination of labeled old samples for the unchangedpattern and unlabeled new samples for the drifted pattern",
  ": Illustration of concept drift": "offers a comprehensive and resource-efficient foundation forupdating the model. Moreover, upon detecting significant drift,we employ strategic forgetting, which discards old samplesthat no longer represent the new pattern. This timely removalof outdated or potentially incorrect knowledge ensures themodel adapts effectively to new patterns and frees upspace of the limited memory buffer for incorporating morerecent data. During concept drift, retaining new samples thatnaturally represent the new pattern can be more beneficial foradaptation than keeping old samples.Our contributions are summarized as follows: We present SSF, a novel continual learning method forIDSs, featuring a strategic sample selection algorithm anda strategic forgetting mechanism. Our method facilitateseffective and accurate adaptation of IDSs in dynamic en-vironments with concept drift due to constantly changingsystem behaviors and evolving attack strategies. We design a strategic sample selection algorithm thatidentifies the most representative new samples for thedrifted pattern. Our approach excels in capturing evolv-ing trends by prioritizing the underlying causes of conceptdrift, ensuring the models high adaptability. We introduce strategic forgetting to actively discard out-dated or potentially incorrect knowledge that no longerrepresents current behaviors, especially when significantconcept drift occurs. This facilitates effective adaptationto new patterns by keeping the memory buffer up-to-date. We validate the superior performance and adaptability ofour method on network traffic datasets, NSL-KDD andUNSW-NB15. Comparative experiments show that ourmethod consistently outperforms baselines under varyinglabeling resources. The ablation study highlights theindividual contributions of each component.",
  "II. PRELIMINARIES FOR CONCEPT DRIFT": "Learning-based applications often perform well under in-dependently and identically distributed (i.i.d.) assumption.However, in open-world scenarios, this assumption may failas test distributions can diverge , causing concept drift. Definition 1 (Concept Drift). Concept drift refers to thephenomenon where the statistical properties of the joint prob-ability distribution P(X,Y) of the input feature space X andthe label space Y change over time. Formally:",
  "where P(X,Y,t) represents the joint probability distribution attime t, and t = t0 indicates t and t0 are different time points": "Considering that the joint probability distribution P(X,Y) =P(X)P(Y|X), concept drift can be attributed to three sources: (1) change of the data distribution P(X), known asvirtual shift, shown in a; (2) change of the conditionalprobability of the label space P(Y|X), know as actual shift,shown in b; (3) a mixture of the above two changes,shown in c.Since virtual shift does not affect model performance, wefocus on actual shift. Direct observation of the actual shift inP(Y|X) is impractical, so we use the models learned distribu-tion P( f(X) | X) as an approximation. Therefore, addressingconcept drift translates to addressing the drift in the learnedprobabilistic distribution P( f(X) | X).In intrusion detection, x X represents a network trafficsample and y Y represents the label, where y = {0,1} denotesnormal (0) or abnormal (1) traffic. f(x) = P(y = 0 | x) denotesthe probability that x is classified as normal by the model.",
  "In the following sections, the term distribution refers tothis discrete learned probabilistic distribution": "III. METHODOLOGYThis section details the framework of SSF, which follows thecommon logic of memory-based continual learning methods, : training the model on a fixed memory buffer,periodically updating the memory buffer/dataset, and fine-tuning the model based on the updated dataset.As shown in , the workflow of SSF comprises fourmain steps: drift detection, sample selection, memory bufferupdate, and model fine-tuning, which are executed periodi-cally. The drift detection step identifies significant changesin the distribution. The sample selection step aims to findthe most valuable samples for update training/fine-tuningwith minimal labeling resources. The memory buffer updatestep takes different actions based on drift detection results,employing strategic forgetting when drift is detected to helpthe model adapt quickly to significant changes. Finally, themodel fine-tuning step adjusts the model based on the updatedmemory buffer, ensuring continuous adaptation to new data.",
  "A. Drift Detection": "Considering a scenario where the memory buffer Mt ={(xi,yi) | i {1,2,...,N}} with size N is updated periodicallyby new samples/dataset Dt = {(xi, /0) | i {1,2,...,N}}, withsize N. For the new dataset Dt, all new samples are initiallyunlabeled. When updating the memory buffer, we can label asubset of new samples under labeling resource constraints.We initiate the continual learning process with a criticalpreliminary step: examining whether the new distributionPn = { f(xi) | xi Dt} of new dataset Dt, has drifted fromold distribution Po = { f(xi) | xi Mt} of the existing memorybuffer Mt. The superscript o denotes variables related to oldsamples, while the superscript n for new samples. Detectingany such drift is essential, as it sets the stage for subsequentactions based on the drift status.To detect distributional shifts, we employ the Kolmogorov-Smirnov (K-S) test , which determines if two discrete sam-ples originate from the same continuous distribution, therebyidentifying any significant changes in the distribution. In thiscontext, samples are subsets of data extracted from a largerpopulation. The K-S test is a nonparametric statistical method,which allows for the detection of distribution drifts withoutspecific assumptions about the underlying distribution. Thiskind of method provides greater flexibility and robustness,particularly useful in scenarios where the exact distributionis unknown. Specifically, the K-S test measures the maximumdistance between the empirical cumulative distribution func-tions of two samples. A large distance suggests the samplesmay come from different distributions, indicating potentialdrift between the memory buffer Mt and the new dataset Dt.The K-S test produces a p-value, which measures thelikelihood that the observed difference between samples couldoccur if they were from the same distribution. The driftdetection result is determined by comparing the p-value witha predefined significance level, typically set at . We define adecision function h() for drift detection as follows:",
  "B. Strategic Sample Selection": "Before updating the memory buffer by incorporating newsamples and discarding old samples, it is essential to identifythe most representative samples. Selecting the right samplesis critical for effective training, especially when labelingresources and memory resources are limited, as it ensures thatthe memory buffer contains the most relevant information forthe model to learn from with minimal labeling resource cost.This step has two phases: (i) common distribution rep-resentation selects old samples to represent the commondistribution between the old and new data. Both old samplesand new samples can represent the common distribution, butchoosing already labeled old samples helps conserve labelingresources; and (ii) distribution drift representation selectsnew samples to represent the distribution drift between the oldand new data. This ensures that the most representative andmeaningful new samples are included, maximizing the valueof each labeled sample.For common distribution representation, both new and oldsamples can contribute to the construction of the commondistribution between the old and new distributions. However,the distribution drift can only be represented by new samples.Therefore, using old samples to reconstruct the new distribu-tion essentially means selecting old samples that represent thecommon distribution between the old and new distributions.To achieve this, we introduce a mask vector mo ={mo1,mo2,...,moi ,...} for the old samples within the memorybuffer Mt. Each entry moi in the mask vector represents theselection decision for the corresponding old sample xoi . Themask values, ranging between 0 and 1, indicate selecting asample for representing the common distribution when thevalue is 0.5 or higher, and not selecting it otherwise. Weformulate the problem of reconstructing the new distributionwith selected old samples xo as:",
  "Lnew = DKL (H (Pn)H ((mo Po)(mn Pn))).(5)": "Here, (mo Po) is the distribution constructed by selectedold samples, and (mn Pn) is the distribution constructed byselected new samples. The symbol denotes the combinationof these two distributions, representing the aggregation ofsamples from both selected old and new distributions into asingle new distribution.It is important to note that in the process of identifyingnew samples representing distribution drift, we do not directlyuse new samples to represent the drifted part in the newdistribution. This is because the memory buffer and the newlyacquired dataset typically differ in size, and simply addingthese two distributions of different sizes might not yield thedesired overall distribution. Instead, we combine both newand old samples to form the new distribution with fixed oldsamples to address the issue of differing data volumes betweenthe new and old distributions. Since old samples adequatelyrepresent the common distribution in the first step of sampleselection, the new samples naturally need to represent thedrift part to minimize Lnew during the second step. illustrates the difference between our sample selectionmethod and previous methods. Traditional approaches typi-cally select samples based on the representativeness of theoverall distribution. In these methods, both new and old sam-ples from the common region of the old and new distributions",
  "Mt = (Mt1 \\Mdropt1 )Dselectt;": "are selected simultaneously. Using a new sample that requireslabeling to represent a region that can be covered by an oldsample (which does not require labeling) is a waste of valuablelabeling resources. Furthermore, the drifted part in the overalldistribution may be a small but critical region. If samples areselected solely based on the representativeness of the overalldistribution, the common distribution with no drift, whichoccupies the majority of the distribution, is likely to dominatethe selection process, leading to insufficient attention on thedrifted part crucial for addressing concept drift. Our methodoptimizes labeling resources by having old samples representthe common region and using new samples to represent onlythe drifted part to capture the drift more effectively.We employ a gradient descent method to address the aboveoptimization problems. For the initialization, since old samplesare already labeled while new samples are not, we aim toretain as many old samples as possible and include as fewnew samples as necessary to optimize labeling resources.Therefore, we randomly initialize mo in the range [0.5, 1]and mn in the range [0, 0.5].",
  "C. Memory Buffer Update with Strategic Forgetting": "The memory buffer update process is essential for maintain-ing the relevance and effectiveness of the model in the faceof changing distributions. The update strategy depends on theoutcome of the drift detection h(p). The detailed process isoutlined in Algorithm 1, and the specific functions used in thisprocess are described in Algorithm 2.According to the result of the sample selection, new samplescan be classified into two types: representative (mn 0.5) ornon-representative (mn < 0.5) for distribution drift. Similarly,",
  "end": "old samples can be classified as representative (mo 0.5) ornon-representative (mo < 0.5) for the common distribution.For non-representative samples, their representative score (mnior moi ) is not important and all non-representative samplesare treated equally. This means that selection among non-representative samples is done randomly.When no drift is detected, i.e., h(p) = 0, the memory bufferis updated based on the labeling resource k, which refers tothe number of new samples that can get ground truth labeledin each update round, for example, through manual labeling.Essentially, this step involves incorporating k labeled newsamples into the memory buffer and discarding k old samples,given the fixed memory size.To ensure that these labeling resources are used effectively,the process first targets new samples that are representative ofthe distribution drift, i.e., those with mn 0.5. Among theserepresentative samples, the top k samples with the highestscores mni are selected. If the number of these representativenew samples is less than k, all such samples are labeled, andadditional samples are randomly selected from the remaining non-representative new samples to fully utilize the labelingresource k (Algorithm 1, line 2).To incorporate these selected new samples with groundtruth labels into the memory buffer (Algorithm 1, line 3), anequivalent number of k old samples need to be dropped. Oldsamples that are not representative of the common distribution,identified by mo < 0.5, are prioritized for removal. If thenumber of such non-representative old samples exceeds k, werandomly select k samples for removal. If the number is lessthan k, we drop all non-representative samples and then selectadditional old samples with the lowest moi scores to make roomfor new samples, ensuring that exactly k samples are removed(Algorithm 1, line 4).When drift is detected, i.e. h(p) = 1, the strategy involves amore significant update to the memory buffer through strategicforgetting. In the face of significant drift, retaining outdatedknowledge is not advisable as it may hinder the modelseffective adaptation. Therefore, all old samples that are notrepresentative of the common distribution, i.e., those withmo < 0.5, are discarded (Algorithm 1, lines 7-8). The numberof new samples added to the buffer is equal to the number ofold samples dropped. These new samples are selected usingthe same method as in the no drift scenario (Algorithm 1, line9). If the number of non-representative old samples is lessthan or equal to k, all selected new samples can obtain theirground truth labels, similar to the no drift scenario (Algorithm1, line 11). If the number of old samples dropped exceeds k,after selecting and labeling k new samples (Algorithm 2, lines22-23), the remaining new samples, up to the number of oldsamples dropped, are labeled using pseudo-labels generated bythe detection model f() (Algorithm 2, lines 25-25) to facilitatethe continual learning process (Algorithm 1, line 14). Strategicforgetting, in this context, is advantageous because it allowsfor the inclusion of a greater number of new samples thatnaturally represent the updated distribution, which is essentialfor maintaining the models accuracy and relevance over time.This approach ensures that the buffer is refreshed with themost relevant and representative new samples that accuratelyreflect the current distribution while discarding outdated non-representative old samples, allowing the model to adapt swiftlyto concept drift in a continual learning scenario.",
  "D. Model Fine-Tuning": "This step involves updating/fine-tuning the model using theupdated memory buffer/dataset, with a strategy of assigninggreater weights to new samples for better adaptation to conceptdrift. Based on the drift detection results h(p), differentstrategies are employed for each scenario.For intrusion detection using deep learning-based methods,model training typically involves a task-specific loss Ltask.This loss can take various forms, such as cross-entropy loss forclassification-based approaches or contrastive loss, for similarity-based approaches, depending on thespecific method used to tackle the problem.The task-specific loss Ltask is generally computed as thesum of individual losses for each sample. In a static environ- ment, treating each sample equally is justified since there isno major difference between them. However, in our dynamicscenario where concept drift occurs, it becomes essential topay more attention to new samples, as the drift is likely drivenby changes in these new samples. Although these new samplesmay be few, they indeed convey more meaningful informationfor the model to learn from than the old samples.In our approach, the memory buffer/dataset after update Mtconsists of both old and new samples, i.e., Mt = {Do,Dn} ={{xoi ,yoi },{xni ,yni }}. We handle the losses of new and oldsamples differently by assigning a weight to the losses of newsamples while keeping the weight for old samples as 1. Thiscan be formulated as:",
  "Ltask =(xoi ,yoi )Do(xoi ,yoi )+(xnj,ynj)Dn(xnj,ynj),": "where (xk,yk) represents the loss for each sample, and is ahyperparameter for the weight of the loss for new samples.This weighting strategy allows us to control the influence ofnew samples during model training. By increasing (i.e., set-ting > 1), the model places more emphasis on incorporatingthese new data points. This is particularly beneficial when newsamples are a minority in the memory buffer, ensuring theyare given adequate importance despite their smaller number.This promotes a stronger learning process that adapts to thechanging data landscape.When no drift is detected, i.e. h(p) = 0, focusing onpreventing catastrophic forgetting is beneficial for maintainingthe models performance. To achieve this, we leverage existingregularization-based continual learning methods , whichintroduce constraints on weight updates during fine-tuning toconsolidate existing knowledge and mitigate forgetting. Theoverall training loss function, which incorporates both the task-specific and regularization components, is given by:",
  "Lno drift = Ltask + Lreg,": "where Lreg is the regularization loss that helps preserveimportant weights, and is a hyperparameter that balancesthe contributions of the task-specific loss and the regularizationterm. This approach ensures that while the model learns newtasks, it does not forget how to perform previously learnedtasks, thereby maintaining its overall effectiveness when thereis no significant drift.When drift is detected, i.e. h(p) = 1, the model mustprioritize rapid adaptation to the new distribution over theconsolidation of previous knowledge. By excluding the reg-ularization term, the model can fully focus on learning thenew distribution, which is crucial for adapting quickly to thedetected drift. The loss function, in this case, simplifies to:",
  "IV. EXPERIMENTS": "This section presents the experimental setup and results. Wedetail the datasets, experiment settings, and baseline methodsin subsection IV-A. The superior performance of AOC-IDSover the baseline methods in the online setting is demonstratedin subsection IV-B. Additionally, ablation experiments areconducted to illustrate the contribution of sub-componentsin AOC-IDS in subsection IV-C. The experimental resultsreveal that our method outperforms the state-of-the-art (SOTA)techniques and underscores the significant contributions ofeach component in our system to its capacity and adaptability.",
  "A. Dataset Preparation and Experiment Settings": "1) Datasets: We conduct experiments on two datasets thatare widely used in network intrusion detection , , ,i.e., NSL-KDD and UNSW-NB15.The NSL-KDD dataset comprises 125,973 training samplesand 22,544 test samples of network traffic. The UNSW-NB15dataset is divided into a training set with 175,341 samples anda test set with 82,332 samples.2) Baselines: We compare our proposed method with fivewell-established continual learning methods within the samecontinual learning setting. The continual learning baselinesinclude AOC-IDS , which is specifically designed for theintrusion detection domain, as well as other notable continuallearning approaches including Experience Replay (ER) ,, Averaged Gradient Episodic Memory (AGEM) ,Learning without Forgetting (LwF) , and Elastic WeightConsolidation (EWC) .",
  "LwF penalizes the model for deviating from the outputsit produced on earlier tasks by knowledge distillation": "EWC estimates the importance of each parameter usingthe Fisher Information Matrix and constrains the updateof important parameters from previous tasks.We also include a static model without continual learningfor reference to quantify the improvements in model perfor-mance due to continual learning in the context of concept drift.3) Experiment Settings: In a continual learning scenario,the IDS starts with a limited number of labeled datasets. Therest of the samples are incrementally fed into the systemwithout ground truth labels in a streamlined manner. Followingthe widely used setting, we select 20% of the data from theoriginal training dataset as the initial labeled dataset, whichamounts to 25,194 samples for NSL-KDD and 38,068 samplesfor UNSW-NB15, for initial training and memory buffer",
  "Acc.Pre.Rec.F1Acc.Pre.Rec.F1": "SSF (Ours)90.5089.2294.7991.9090.2789.0693.8991.40w/o sample selection87.8391.3386.9288.9986.5782.2996.3988.77w/o strategic forgetting89.0990.5090.3490.3889.3286.5795.5190.79w/o regularization90.2089.0494.4391.6490.0088.0494.7991.21 incorrect knowledge, ensuring the model adapts effectivelyto new patterns and frees up space in the limited memorybuffer for incorporating more recent data. During conceptdrift, retaining new samples that naturally represent the newpattern can be more beneficial for adaptation than keeping oldsamples, thereby facilitating adaptation.3) Regularization: We compare adopting LwF when nodrift is detected, with no adoption of such regularization-basedcontinual learning method, described as w/o regularization.TABLE II demonstrates that the adoption of LwF enhancesperformance, but the improvement is minimal. Therefore, thisproves that LwF is not the primary reason for the improvedperformance. Instead, it is the strategic sample selection andstrategic forgetting that predominantly account for the signif-icant improvements observed in our systems performance.",
  "B. Comparitive Experiments": "We compare SSF against five well-established continuallearning methods, as well as a static model for reference.All methods are evaluated under the same continual learningsetting, where we can only obtain 1% ground truth labels ofnew unlabeled samples. Moreover, we highlight the excep-tional capacity of SSF in scenarios with extremely limited la-beling resources by analyzing its performance across differentlabeling conditions. Additionally, we provide a visualizationexample to illustrate how SSF enhances the models ability.1) Overall Performance: As displayed in TABLE I, SSFsurpasses other methods in both accuracy and F1 scoreon the NSL-KDD and UNSW-NB15 datasets. Specifically,our method achieves high detection accuracies of 90.50%and 90.27% on the NSL-KDD and UNSW-NB15 datasets,respectively, demonstrating improvements of approximately4.0% and 3.7%. Notably, our method is the only one toperform uniformly well on both datasets, while other comparedmethods either exhibit generally poor performance across bothdatasets or excel only on one dataset. AOC-IDS is designed under the assumption of infinitememory capacity, allowing it to retain all past samples whileincorporating new ones. This overlooks the inherent con-straints of physical storage, which have finite capacities andcannot store unlimited amounts of data. In a realistic continuallearning scenario with finite memory constraints, AOC-IDSloses its effectiveness, indicating that AOC-IDS relies heavilyon having access to the entire historical dataset. It lacks theability to select representative samples and learn rich, conceptdrift-adaptive information from a limited set of samples.Both ER and AGEM are memory-based continual learningmethods that store and replay a subset of past information fromprevious tasks in a fixed-size memory buffer, similar to our ap-proach. The performance of ER shows improvement comparedto the static, non-updated scenario, successfully achievinglearning new knowledge without catastrophically forgettingold knowledge. However, this conservative and simple randomselection approach is highly likely to miss the most represen-tative samples and fail to capture the most critical samplesfor adapting to concept drift, preventing it from achievingexceptional performance. Similarly, the moderate performanceof AGEM demonstrates that AGEMs approach of preservingpast knowledge by gradient projection is far less effective thanour methods approach of selecting the most representativesamples for drift adaptation. Our method prioritizes learningnew, useful knowledge over merely preserving old knowledge,which proves to be more beneficial.LwF and EWC, which are regularization-based methods,perform relatively well on the UNSW-NB15 dataset but poorlyon the NSL-KDD dataset. These methods do not requireretaining past data; instead, they use constraints to mitigatecatastrophic forgetting. However, they face significant limi-tations when the absolute number of new samples availableis very small. To be specific, in the NSL-KDD dataset, themodel is updated every 5000 samples, providing only 50 newsamples (1%) per update. In contrast, the UNSW-NB15 datasetallows for model updates every 20,000 samples, providing 200new samples (1%) per update. The poor performance of thesemethods on NSL-KDD can be attributed to their inability toeffectively learn from such a small number of new samples,which hampers their ability to update knowledge withoutdisrupting existing information. In contrast, by focusing onidentifying and utilizing the most representative samples, wemaximize the value of labeled resources. With the help ofold samples representing the common distribution for newpatterns, our method proves to be particularly advantageousin scenarios with very limited labeling resources.2) Accuracy under Different Label Conditions: We analyzethe accuracy of our method in comparison to other baselinemethods under varying label resource conditions, as illustratedin . It is evident that continual learning is most effectivewhen only a small portion of new samples are labeled. Ifthe majority of new samples are manually labeled, the IDSessentially loses its purpose as an automated detection method.The continual learning method that can operate effectivelywith fewer labeled resources is superior and more practical.",
  ": t-SNE visualization of decoder feature extraction onNSL-KDD dataset": "Consequently, primarily focuses on scenarios with lessthan 1% labeled resources. Higher labeling percentages, up to50%, are also provided for reference.For the NSL-KDD dataset, our method performs exception-ally well across all labeling resource conditions, achievingnearly 90% accuracy even with just 0.1% labeled data. Weconsistently outperform other baselines when labeling re-sources are under 2%. Beyond this level of labeling resources,other memory-based methods like ER and AGEM achievecomparable performance. However, in terms of the labelingresources needed to achieve the same performance level, ourmethod reaches the performance level that others achieve with5% labeling resources, using only 0.1% of the resources. Thisunderscores a nearly 50-fold reduction in labeling resourcerequirements of our approach. For the UNSW-NB15 dataset,our method consistently outperforms other baselines acrossall labeling percentages. Our method reaches the performancelevel that others achieve with 20% labeling resources, usingonly 1% of the resources. This demonstrates a nearly 20-foldreduction in labeling resource requirements.Overall, our method demonstrates superior performanceacross both datasets and labeling resource conditions. It high-lights the effectiveness of our techniques to optimize the use ofthe memory buffer and maximize the value of limited labelingresources by distinguishing and storing the most representativesamples to improve the models adaptability.3) Visualization: shows the t-SNE visualization ofthe features extracted by the decoder on the NSL-KDD dataset.The visualization illustrates the distribution and clusteringof the features after dimensionality reduction. For IDS, the goal is to clearly distinguish between normal samples andabnormal samples. Therefore, an optimal model will showclear boundaries and minimal overlap between the clusters ofnormal and abnormal samples. In a, the visualization forAOC-IDS shows significant overlap between normal (green)and abnormal (red) samples. The normal regions are largelycovered by abnormal data, reflecting its struggle to maintaindetection ability under its own continual learning updateframework. In contrast, b illustrates that our methodachieves a more distinct separation between the clusters ofnormal and abnormal samples. The clear separation of theclusters suggests that the model has learned more usefulfeatures for distinguishing between the two classes. C. Ablation ExperimentsIn this section, we perform ablation experiments to evaluatethe effectiveness of key techniques of SSF, including strategicsample selection and strategic forgetting. Additionally, weconduct an ablation study with and without (w/o) usingthe existing regularization-based continual learning method,specifically LwF, to illustrate that LwF is not the primaryreason for the improved performance of our method.1) Strategic Sample Selection: We compare our strategicsample selection algorithm with simple random sampling,denoted by w/o sample selection. As shown in TABLE II,the results demonstrate that our strategic sample selectionalgorithm significantly outperforms random sampling. Thisindicates that merely selecting samples randomly is likely tomiss crucial information, especially when the proportion ofnew samples available for labeling is very low. Randomlyselected samples may not adequately represent the new dis-tribution. In contrast, by using our strategic sample selectionalgorithm, even with a limited number of new samples, themost representative samples can still effectively represent thenew distribution, particularly the drifted part. By maximizingthe value of labeled resources, our approach leads to notableperformance enhancements compared to random sampling.2) Strategic Forgetting: We compare adopting strategicforgetting, which discards all non-representative old sampleswhen drift is detected, with dropping the same number ofsamples as labeling resources the whole time, described asw/o strategic forgetting. TABLE II suggests that the adoptionof strategic forgetting enhances performance. This improve-ment is due to the timely removal of outdated or potentially",
  "A. Continual Learning": "Continual learning strategies are generally categorized intomemory-based , regularization-based , and expansion-based approaches . We focus on the first two categoriessince expansion-based methods, which involve expanding themodel architecture, do not align with our scenario with afixed model structure. Therefore, we focus on comparingour method with memory-based and regularization-based ap-proaches to ensure a fair evaluation.1) Memory-based Methods: Memory-based methods ad-dress concept drift and mitigate catastrophic forgetting by stor-ing and replaying a subset of past information from previoustasks, including but not limited to data, such as ER , and gradients, such as GEM (Gradient Episodic Memory) and A-GEM , an improved version of GEM that simplifiesthe computation by using average gradients. However, existingmethods overlook the critical drift aspect of concept drift andfail to recognize the value of strategic forgetting the potentialbenefits of strategic forgetting, missing the potential for it tofacilitate rapid adaptation in dynamic environments.2) Regularization-basedMethods:Regularization-basedmethods , preserve knowledge from prior tasks whilelearning new tasks by applying constraints to the learningprocess. These methods typically incorporate a regularizationterm into the objective function, penalizing updates that wouldchange or overwrite weights crucial for past tasks. Althoughthese methods do not require storing previous data, they oftenstruggle when labeling resources are very limited due to",
  "insufficient learning from available new data samples and anover-reliance on the initial training": "B. Continual Learning for Intrusion DetectionWhile continual learning mechanisms have been adoptedinto IDSs to accommodate dynamic environments, signifi-cant issues remain unaddressed. For example, AOC-IDS periodically updates the IDS to address concept drift butretains all encountered data, neglecting practical memorybuffer limitations. Similarly, the approach in necessitateslabor-intensive labeling for continuous training, overlookingthe constraints on labeling resources. Han et al. proposeda continual learning mechanism that targets labeling for themost influential samples, thereby reducing the labeling burdenwith a fixed memory buffer size. However, this method istailored for zero-positive learning, focusing solely on trainingwith normal data, which leads to a waste of valuable abnormaldata and labeling resources since new abnormal samples arediscarded after manual labeling.In this study, we introduce a novel memory-based continuallearning approach that optimally leverages both normal andanomalous samples within realistic constraints such as fixedmemory size and limited labeling resources, thereby address-ing the aforementioned challenges. VI. CONCLUSIONIn this paper, we introduced a novel continual learningmethod for IDSs, comprising four steps: drift detection, sampleselection, memory buffer update, and model fine-tuning. Thedrift detection step lays the foundation for the followingsteps, which handle drift and no-drift scenarios differently.The sample selection step identifies the most representativenew samples while achieving minimal labeling cost. Strategicforgetting, used in the memory buffer update step, ensures themodel aligns with the current data. By assigning weights tolosses of new samples during fine-tuning, we balance learningfrom new tasks and consolidating previous knowledge. Thesefour steps ensure that IDSs can swiftly and accurately adapt toconcept drifts with minimal cost. Experimental results on theNSL-KDD and UNSW-NB15 datasets demonstrate the supe-rior performance and adaptability of our method, surpassingstate-of-the-art solutions. The optimal labeling efficiency ofour approach is further highlighted under extremely limitedlabeling resource conditions. Furthermore, our ablation studyconfirms the contributions of our proposed techniques. Overall,our proposed method makes IDSs more robust and responsivein dynamic network environments, balancing efficient labelingwith rapid adaptation to concept drifts. ACKNOWLEDGMENTThis research is supported in part by the National Nat-ural Science Foundation of China (Grant No. 92067109,61873119, 62211530106), in part by the Shenzhen Science andTechnology Program (Grant No. ZDSYS20210623092007023,GJHZ20210705141808024), and in part by the UGC GeneralResearch Fund (Grant No. 17203320, 17209822) from HongKong.",
  "P.Garca-Teodoro,J.Daz-Verdejo,G.Macia-Fernandez,andE. Vazquez, Anomaly-based network intrusion detection: Techniques,systems and challenges, Computers & Security, vol. 28, no. 1, pp.1828, 2009": "M. A. Ferrag, L. Maglaras, S. Moschoyiannis, and H. Janicke, Deeplearning for cyber security intrusion detection: Approaches, datasets, andcomparative study, Journal of Information Security and Applications,vol. 50, p. 102419, 2020. X. Zhang, Z. Jiang, Y. Ding, E. C. Ngai, and S.-H. Yang, Anomalydetection using isomorphic analysis for false data injection attacks inindustrial control systems, Journal of the Franklin Institute, vol. 361,no. 13, p. 107000, 2024. A. Khraisat and A. Alazab, A critical review of intrusion detectionsystems in the internet of things: techniques, deployment strategy, vali-dation strategy, attacks, public datasets and challenges, Cybersecurity,vol. 4, pp. 127, 2021.",
  "J. Gama, I. Zliobaite, A. Bifet, M. Pechenizkiy, and A. Bouchachia, Asurvey on concept drift adaptation, ACM computing surveys (CSUR),vol. 46, no. 4, pp. 137, 2014": "D. Han, Z. Wang, W. Chen, K. Wang, R. Yu, S. Wang, H. Zhang,Z. Wang, M. Jin, J. Yang et al., Anomaly detection in the open world:Normality shift detection, explanation, and adaptation, in 30th AnnualNetwork and Distributed System Security Symposium (NDSS), 2023. N. Wang, Y. Chen, Y. Hu, W. Lou, and Y. T. Hou, Feco: Boostingintrusion detection capability in iot networks via contrastive learning,in IEEE INFOCOM 2022 - IEEE Conference on Computer Communi-cations, 2022, pp. 14091418.",
  "Y. Yue, X. Chen, Z. Han, X. Zeng, and Y. Zhu, Contrastive learningenhanced intrusion detection, IEEE Transactions on Network andService Management, vol. 19, no. 4, pp. 42324247, 2022": "W. Wang, C. Liang, Q. Chen, L. Tang, H. Yanikomeroglu, and T. Liu,Distributed online anomaly detection for virtualized network slicingenvironment, IEEE Transactions on Vehicular Technology, vol. 71,no. 11, pp. 12 23512 249, 2022. F. Pendlebury, F. Pierazzi, R. Jordaney, J. Kinder, L. Cavallaro et al.,Tesseract: Eliminating experimental bias in malware classificationacross space and time, in Proceedings of the 28th USENIX SecuritySymposium.USENIX Association, 2019, pp. 729746. S. T. Jan, Q. Hao, T. Hu, J. Pu, S. Oswal, G. Wang, and B. Viswanath,Throwing darts in the dark? detecting bots with limited data usingneural data augmentation, in 2020 IEEE symposium on security andprivacy (SP).IEEE, 2020, pp. 11901206.",
  "V. W. Berger and Y. Zhou, Kolmogorovsmirnov test: Overview, Wileystatsref: Statistics reference online, 2014": "Y. N. Kunang, S. Nurmaini, D. Stiawan, A. Zarkasi et al., Automaticfeatures extraction using autoencoder in intrusion detection system, in2018 International Conference on Electrical Engineering and ComputerScience (ICECOS).IEEE, 2018, pp. 219224. J. Zhao, S. Li, R. Wu, Y. Zhang, B. Zhang, and L. Han, Tri-trainingalgorithm based on cross entropy and k-nearest neighbors for networkintrusion detection. KSII Transactions on Internet & Information Sys-tems, vol. 16, no. 12, 2022."
}