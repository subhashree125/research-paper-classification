{
  "ABSTRACT": "In this paper, we explore a new way for user targeting, wherenon-expert marketers could select their target users solely givendemands in natural language form. The key to this issue is howto transform natural languages into practical structured logicallanguages, i.e., the structured understanding of marketer demands.In practical scenarios, the demands of non-expert marketers areoften abstract and diverse. Considering the impressive natural lan-guage processing ability of large language models (LLMs), we tryto leverage LLMs to solve this issue. To stimulate the LLMs rea-soning ability, the chain-of-thought (CoT) prompting method iswidely used, but existing methods still have some limitations inour scenario: (1) Previous methods either use simple Lets thinkstep by step spells or provide fixed examples in demonstrationswithout considering compatibility between prompts and concretequestions, making LLMs ineffective when the marketers demandsare abstract and diverse. (2) Previous methods are often imple-mented in closed-source models or excessively large models, whichis not suitable in industrial practical scenarios. Based on these, wepropose ARALLM (i.e., Analogical Reasoning Augmented LargeLanguage Models) consisting of two modules: Analogical Reason-ing based Prompting and Reasoning-Augmented Multi-Task ModelDistillation. To be specific, we first construct a reasoning libraryconsisting of several high-quality and topic-rich reasoning exam-ples. Then, we adopt a retrieval-based method to conduct analogicalreasoning with the help of the reasoning library. The experimen-tal results show that this prompting strategy achieves better per-formance than the ordinary prompting method. Beyond that, wedistill knowledge from super LLMs (GPT-3.5) to fine-tune smaller",
  "Equal contributionsCorresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08...$15.00",
  "User Targeting, Large Language Models, Analogical Reasoning,Knowledge Distillation, Chain of Thought": "ACM Reference Format:Junjie Wang, Dan Yang, Binbin Hu, Yue Shen, Wen Zhang, and Jinjie Gu.2024. Know Your Needs Better: Towards Structured Understanding of Mar-keter Demands with Analogical Reasoning Augmented LLMs. In Proceedingsof the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Min-ing (KDD 24), August 2529, 2024, Barcelona, Spain. ACM, New York, NY,USA, 12 pages.",
  "INTRODUCTION": "Recently, the practice of user targeting has gained significant at-tention in real-world applications (e.g., Alipay and WeChat), ashighlighted by a variety of studies . This ap-proach has the excellent potential to attract high-quality users forspecific campaigns, aligning with the goals of marketers to enhanceconversions and minimize operational expenses. Roughly speaking,current methods devoted to user targeting mainly fall into two lines:model-based methods ( (a)) that perform expansion of seedusers/entities with well-designed neural networks andrule-based methods ( (b)) that manually group users withdifferent tags based on domain knowledge .Unfortunately, both of the above prior studies have primarilyemphasized the intricate architectures for effectively and efficientlygathering targeted users, while commonly ignoring the naturaland significant gap between marketers demand and the capabilityof current models. In particular, current user targeting pipelinesmainly force the marketers to decompose their demands into mul-tiple tags/entities, e.g., Preference, Resident City and User AgeGroup which are characterized in . The process incursseveral weaknesses: i) unfriendly to marketers; ii) time-consuming",
  ": The comparison of user targeting approach": "for manual deconstruction of demands; and iii) unpromising per-formance due to partial tags/entities.Therefore, in this paper, we take the initial stride towards enhanc-ing current user targeting systems by probing into the structuredunderstanding of marketers demands in an automatic way, en-abling the system to know your needs better solely based on naturallanguage inputs. As shown in (c), the marketers only needto input their native demands like Young people in City A whoenjoy milk tea or white-collar workers in first-tier cities who en-joy listening to audiobooks and our new approach can instantlyconduct structured decomposition of marketers demands and thusprovide the user targeting cards. After verifying the cards, theycan export the target users with just one click and the system willautomatically run the existing targeted user aggregation modules.The core of this new approach lies in how to transformnatural languages into structured forms, or so-called structuredunderstanding of marketer demands. To address this issue, we firstdraw upon existing logical and programming languages to designa logical expression that offers both readability and practical appli-cability for the structured representation of marketers demands.We name it as SELL, i.e., Structured and Editable Logical Language,which mainly consists of Keys (e.g., Resident City), Values (e.g., CityA), Operators (e.g., Belongs To) and Intersection/Union symbols(i.e., AND, OR). It forms the basis of the user targeting cards shownin (c). The main concern of our work is transforming theNatural Language into SELL (NL2SELL). For example, the naturallanguage Young people in City A who enjoy milk tea or white-collar workers in first-tier cities who enjoy listening to audiobook can be translated into SELL as ((Resident City#Belongs To# CityA) AND (User Age Group#Between#18,35) AND (Preference#BelongsTo#Milk Tea)) OR ((City Level#Belongs To#First-tier) AND (Daysof listening to audiobooks#Greater Than#3) AND (Career#BelongsTo#White-collar)).Previous research has highlighted the remarkableabilities of Large Language Models (LLMs) in language transla-tion tasks. LLMs are renowned for their robust natural languageprocessing and zero-shot capabilities, which render them possiblyeffective in NL2SELL. Consequently, we opt to employ LLMs totackle this task. However, there are still some challenges in usingLLMs in our scenario: (1) The challenge of reasoning accuracy.In practical user targeting scenarios, understanding of marketersdemands could be very challenging. For example, a marketer mightwant to market products related to education, targeting parentsof middle school students who are focused on education. There-fore, the demand she inputs into the system is a simple sentenceParents of middle school students, and we need to use existingtags to convert this demand into a structured expression, such as(Marital Status#Belongs#True) AND (User Child Age#Between#12,15)AND (Preference#Belongs To#Education). However, the key MaritalStatus, User Child Age, and Preferences do not directly appear inthe marketers demand, which requires the LLMs to possess a highlevel of language comprehension and reasoning abilities. Recently,it has been pointed out that prompting LLMs with chain-of-thought (CoT) could enhance the reasoning ability of LLMs. Thesemethods either provide fixed reasoning examples as demonstra-tions through few-shot learning or tell the model Lets think step",
  "Know Your Needs Better: Towards Structured Understanding ofMarketer Demands with Analogical Reasoning Augmented LLMsKDD 24, August 2529, 2024, Barcelona, Spain": "NL2SQL is an important and challenging task in helping non-expert users to better manipulate databases. Graph neural networks(GNNs) are popular in NL2SQL research , which focus onmodeling the relationship between the question and the schemain database system. Recently, large pre-trained language models(PLMs), such as T5 and GPT-3 , have shown strong trans-lating ability in NL2SQL tasks. Due to the extensive knowledgeinjection during the pretrain phase, PLM-based methods achievebetter results compared to GNN-based methods by fine-tuningthem with a small amount of data. Some works also explore solvingNL2SQL tasks with in-context learning , it has been pointedout that LLMs show strong few-shot or zero-shot abilities evenwithout any training data, which start a new direction for futureresearch on NL2SQL field. The LLM-based methods in NL2SQLbring inspiration to our works.",
  "In this work, we focus on how to convert a sentence of mar-keters demand into a standard structured expression SELL,": "while how to parse and execute the SELL and return the targetusers from the database will be handled by the internal system,which does not constitute the core of this article. Inspired by theanalogical reasoning in the classic artificial intelligencefield and CoT prompting methods in LLMs, we first propose anovel prompting method enhanced by analogical reasoning andthen adopt a reasoning-augmented multi-task training strategy tofine-tune smaller LLMs.",
  "Design of SELL": "We first explain the design of SELL to help readers understand ourtask better. The SELL is mainly composed of four elements: Keys,Values, Operators, and Intersection and Union symbols:(1) Keys are a series of tags that describe the features of the user,such as Gender, Monthly Income, Pet Owning, and so on.(2) Values are the fillings of the corresponding keys. They canbe generally divided into three types: numerical type, string type,and boolean type.(3) Operators represent the relationship between keys and val-ues. For numerical values, seven types of operators can be used toconnect them with corresponding keys: Equal To, Greater Than, LessThan, Not Equal To, Not Greater Than, Not Less Than, and Between.For values of string type and boolean type, there are two types ofoperators: Belongs To and Not Belongs To. Keys, operators, and val-ues can form a basic conditional expression in SELL, formatted as(key#operator#value), such as (User Marital Status#Belongs#True).A conditional expression represents a cluster of target users.(4) Intersection and Union symbols are used to take the in-tersection or union of multiple conditional expressions (targetedusers). We use the symbols AND and OR to denote the intersectionand union operations, respectively.Compared to the popular database languages SQL and logiclanguage FOL, the advantages of SELL are: (1) SELL is simpler inexpression and has much fewer syntax symbols, making it easierfor non-programming experts to understand. (2) Since SELL canbe transformed into a clear tree structure, marketers can easilymodify them even if the generated results have flaws. Due to spacelimitations, we recommend readers to read more details about SELLin the supplementary materials.",
  "Prompting With Analogical Reasoning": "The core idea of analogical reasoning in the NL2SELL task is that iftwo demands are similar, they may share similar reasoning steps,as well as similar logical structures. Thus, we construct a small buthigh-quality reasoning library to provide references for numerousdemands with unknown reasoning steps, minimizing the cost ofmanually writing reasoning steps for each of them. 2.2.1Construction of Reasoning Library. To construct a reasoninglibrary, we first randomly collect N marketer demands fromreal-world scenarios and write their corresponding answers basedon our expert knowledge to form Q&A pairs R = {(,)}N=1 ,where is the demand, is the corresponding SELL expressions.The collected marketers demands encompass services that arepopular on Alipay, including education, technology, reading, travel,financial management, insurance, government affairs, and publicwelfare, thus ensuring that the reasoning library constructed based",
  "I want to sell tickets. Please help me select the Young people interested in the Asian Games tickets": "Demand: Students in City A who enjoy football matches.Tag list:[Resident City, Age, Career, Preference, ]Reasoning steps:1. Extract keywords: Students, City A, football matches2. Select tags: Location, Career, Preference3. Form conditional expressions: (Location#Belong to#CityA), (Career#Belong To#Students), (Preference#BelongsTo#Football Matches)4. Combine: (Resident City #Belongs to#City A) AND (Career#Belongs To#Students) AND (Preference#BelongsTo#Football Matches)Answer:(Resident City#Belongs To#City A) AND (Career#BelongsTo#Students) AND (Preference#Belongs To#Football Matches)",
  ": Overview of analogical reasoning based prompting methods": "on this can cover as many demand topics as possible. Then we usea small amount of manual effort to write corresponding reasoningdetails for 10% random selected Q&A pairs R to construct theseed examples in the format (,,), where represent thereasoning details. We generally summarize the procedure of solvingthe NL2SELL problem as four steps:",
  "(4) Combine: Combine conditional expressions using intersec-tion or union symbols": "What we need to do is to fill in the details of these four steps.For the remaining data in R, we utilize the OpenAI gpt-3.5-turbo-1106 (GPT-3.5) API to help us fill the corresponding reasoning steps,and our seed examples serve as demonstrations in the prompt. Sincewe have standardized the overall framework of reasoning, it is notdifficult for GPT-3.5 to complete this part of the reasoning steps,cases are shown in supplemental materials. After being verifiedby experts. we harvest a batch of solid reasoning details to form areasoning library R = {(,,)}N=1 . 2.2.2Retrieval-Based Analogical Prompt Construction. After theconstruction of the reasoning library, we can provide referencesfor unknown demands through analogical reasoning. As shownin , given a marketer demand that needs to predict thecorresponding SELL expression, we first retrieve similar demands in R based on their text embedding similarity:",
  "(,) = (E(), E()), R(1)": "where E is the embedding model in which we use BGE-large-zh off the shelf as it is well-performed in the Chinese textretrieval field. The top demands in R that get the highest similarityscore when compared with will be fetched as analogical examplesin this stage, along with their corresponding and . In addition, to help the LLMs better organize answers, we shouldalso inform the LLMs of the tags in the marketing database asexplicit knowledge. To address the issue of an excessive number oftags, we still use BGE as a retriever to retrieve the most relevant ntags of every demand from the marketing database to construct apart of the prompt. The top n tags that get the highest similarityscores when compared with demand will form a small-scale tag list = { }=1 to provide a reference for selecting keys in SELL.Therefore, the basic organizational form of the final prompt for predicting is :",
  "= (I, {(,,,)}=1, (,))(2)": "where I is the instruction which simply describes the task, k isthe number of analogical examples, and are the most relevanttag lists of the and respectively.Compared to the ordinary CoT method, our approach exhibitsseveral main differences: (1) The NL2SELL task is more challenging.Unlike solving mathematical problems or common sense reasoningtasks, the training data for LLMs dont inherently include the syntaxof SELL. This highlights the importance of appropriate reasoningsteps. (2) We place a greater emphasis on the compatibility betweenprompts and questions. We believe that using an analogical reason-ing based prompting method can make LLMs more adaptable tospecific problems, rather than relying on fixed few-shot examples,which could potentially limit the models performance.",
  "Reasoning-Augmented Multi-Task ModelDistillation": "To train a private small model for deployment, we first distill knowl-edge from teacher LLM (GPT-3.5) to construct an NL2SELL datasetwith over 10,000 pieces of training samples and then propose amulti-task training method with reasoning augmentation. 2.3.1Knowledge Distillation. We collect nearly 10,000 demandsfrom our daily marketing environment. Following the analogicalreasoning method mentioned above, we construct input promptsfor each demand in the form of Equation (2), where analogical",
  "((,),) 3.5 (3)": "where is the synthesized SELL answers. The language fluencyand logical rationality of the generated demand will be checked.We denote this part of data distilled through the answer to de-mand pipeline. We obtain 1,200 pieces of data in this way and com-bine them with data coming from the demand to answer pipeline toform the final training data D = {(,)}=1 for small model,where N is the number of training data.",
  "EXPERIMENTS3.1Experimental Settings": "3.1.1Benchmarks. We manually construct an NL2SELL testingbenchmark for predicting, which contains 170 pieces of data basedon expert knowledge in the format D = {(,)}170=1. The de-mands in D do not exist in the training set D or reasoninglibrary R, eliminating the issue of label leakage. shows thestatistics of these 3 parts of data1. It should be noted that all train-ing data generated by GPT-3.5 are strictly verified by well-trainedvolunteers, and we provide some examples in the supplementarymaterials. We will open source all these datasets on request. 3.1.2Baseline. We first use GPT-3.5 to test the effectiveness of theanalogical reasoning based prompting method. For comparison, wepropose four additional variants of prompts as baselines: Zero-shot: Only given the instruction I, tag list and a testdemand . Fixed few-shot: Given the instruction I, k fixed examples{(,)}=1 R for all D, tag list and a . Fixed few-shot + RS (Reasoning Steps): Given the instructionI, k fixed examples {(,,)}=1 R for all D, tag list and a . Random few-shot + RS: Given the instruction I, k randomlysampled examples {(,,)}=1 R for every D ,tag 1The dataset does not contain any Personal Identifiable Information (PII). The datasetis desensitized and encrypted. Adequate data protection was carried out during theexperiment to prevent the risk of data copy leakage.",
  "KDD 24, August 2529, 2024, Barcelona, SpainWang, Yang and Hu, et al": "Yuan Yang, Siheng Xiong, Ali Payani, Ehsan Shareghi, and Faramarz Fekri. 2023.Harnessing the Power of Large Language Models for Natural Language to First-Order Logic Translation. arXiv:2305.15541 [cs.CL] Zhen Yao, Wen Zhang, Mingyang Chen, Yufeng Huang, Yi Yang, and HuajunChen. 2023. Analogical inference enhanced knowledge graph embedding. InProceedings of the AAAI Conference on Artificial Intelligence, Vol. 37. 48014808.",
  ": The impact of the size of parameter settings": "methods in various evaluation metrics, especially in terms of struc-tural accuracy which improves by over 7%, proving that analogicalexamples provide a good logical structure for reasoning. (2) Evenrandomly selected few-shot reasoning examples are better thanfixed ones. This indicates that fixed reasoning examples for allinputs are often suboptimal, demonstrating the necessity of estab-lishing a reasoning library to provide diverse reasoning samples.(3) Reasoning steps are essential in prompting. When comparingresults between Fixed few-shot and Fixed few-shot + RS, wefound that reasoning steps have a significant active impact on rea-soning accuracy, which is similar to the trend in other previousresearch works .Further, we explore the impact of parameter settings, such asthe size of reasoning library N and the number of analogicalexamples . As shown in (a), as the size of the reasoninglibrary increases, the overall accuracy gradually increases, but therate slows down, indicating that when the inference library reachesa certain scale, it can already provide references for most marketersdemands. In (b), it can be observed that the overall accuracyfirst increases and then decreases when the number of examplesin prompts increases. This reflects that when engaging in context-based learning, providing more examples to LLMs is not alwaysbetter. When an excessive number of examples are input, irrelevantexamples may introduce noise, and an overly lengthy context canalso impose a greater burden on the models understanding. 3.2.2Case Study. is a case we obtained from GPT-3.5 withdifferent versions of prompts. Although we provide the same taglist for a specific demand across different prompt versions, there aresignificant variations in the selection of key-value pairs. For the firstdemand Company white-collar workers who enjoy drinking Star-bucks, all baseline versions ignore the tag of Career, indicatingthat the model cannot smoothly map the description white-collarworkers to Career, although this is common sense. Meanwhile,in both fixed few-shot versions, the model treats company white-collar workers as the value of the Resident City, which is dueto the answers of fixed examples in prompts containing similarexpressions such as (Resident city#Belongs To#Hangzhou), resultingin the model being inappropriately imitated. While in ARAP, weretrieve similar demands like Young people who enjoy swimmingor female white-collar workers who enjoy reading in Shanghaiand its reasoning steps from the reasoning library, thus helpingthe LLM analogically transform the white-collar workers intoconditional expression (Career#Belongs To#White-collar) as theyshare the similar description white-collar workers.",
  "Knowledge distillation results on smallerLLMs": "3.3.1Main Results. shows the testing results on fine-tunedLLMs with the knowledge distilled from GPT-3.5, where ARAFTrepresents fine-tuning (FT) in the reasoning-augmented multi-taskparadigm mentioned in section 2.3.2. All testing prompts are thesame as ARAP prompts in GPT-3.5. As is shown: (1) Both two mod-els show comparable capability to GPT-3.5, especially on Baichuan2-13B-Chat, where the score of S-BLEU is improved by over 5% com-pared to GPT-3.5 after fine-tuning. This demonstrates the superi-ority of our distillation and training methods. (2) Compared withthe results of the single-task training strategy (-MT), the multi-tasktraining strategy brings improvement to the reasoning performanceof the LLMs. Although during testing, we limit the model to onlyoutput the final answers without reasoning steps, adding trainingtasks that predict reasoning steps can enhance the models reason-ing abilities and robustness. (3) Compared with the results withoutreasoning steps in the input corpus (-RS), we can conclude thatproviding explicit reasoning steps in training input is beneficial. Ifthere are no reasoning steps in the input corpus but a multi-tasktraining strategy is used, it will increase the difficulty of the trainingtask and lead to poor performance, which is particularly evidentin Baichuan2-13B-Chat. (4) The result of fine-tuning using onlythe normal demand and answer pairs is not satisfactory, whichindicates that it is challenging for LLMs to learn the data patternssolely based on the Q&A pairs in situations where tasks are difficult.Therefore, it is necessary to design appropriate demonstrations andtraining tasks to fine-tune the LLMs. 3.3.2Ablation Study. As mentioned in section 2.3.1, there are twosources of distilled knowledge we use when fine-tuning, i.e., knowl-edge distilled from demand to answer and answer to demand ap-proach. The knowledge distilled from demand to answer is the mostcommonly used knowledge distillation approach, and what wemainly want to explore is the effectiveness of the knowledge dis-tilled from answer to demand. To verify this, we conduct ablationexperiments on the best-performing models Baichuan2-13B-Chatwith two training settings (i.e., ARAFT and ARAFT - RS). shows the effect of the knowledge distilled from answer to demand(a2d), it can be found that when removing this part of data duringthe fine-tuning, the performance on both ARAFT and ARAFT - RSsignificantly decreases, although this part of data only accountsfor about one-tenth of the training data. This indicates that addingsamples with a more uniform distribution of logic and tags to thetraining corpus can improve the robustness of the LLMs, and ourdistillation method from answers to demand achieves this.",
  "APPLICATION": "Model Deployment. The LLM tuned in section 3.3 has been de-ployed online for application using an A10 with a memory ca-pacity of 24G. To achieve optimal online inference performance,the deployment involves a total of 8 cards, including both the pre-production and online environments. Meanwhile, the retriever ser-vice based on BGE has also been deployed on an A10 GPU.Application Case. shows an application case of AR-ALLM in online user targeting. A marketer wants to do marketingfor a stage drama performance, so he can input a raw demand andclick the Search button. Our system will invoke the retriever ser-vice to retrieve similar top-k demonstrations and top-n tags fromthe reasoning library embeddings (RL Embs) and tag embeddings(Tag Embs), respectively. After filling the prompt based on retrieveddemonstrations and tags, our system requests the deployed ARAFTmodel to generate the answer expressed in SELL. The SELL expres-sion will be parsed by our parser and results will be visualized tothe marketers on the panel as shown in . The marketers canverify and edit the card on the panel after clicking the edit button.Finally, they can click the Export button to get the target users.Practical Effects. Our system has been already running formonths. We have set two metrics to evaluate the new approach on-line, including operation time, and number of likes from marketers.By collecting the operation log, the entire system takes no morethan 10 seconds to complete a request and the average marketersoperation time of the new system is about 3 minutes, which is",
  "Digital car+55.21%+0.33%Housing provident fund+30.56%-0.21%Ophthalmic health+69.17%+0.01%Traditional Chinese Medicine+112.7%+0.67%Recharge+73.89%+0.20%": "4-10 times shorter than the former on average. Beyond that, we re-ceive likes 1.3 times larger than the former, revealing the operationfriendliness of this new way of user targeting.Online A/B testing results. We conduct online A/B exper-iments to compare our methods with the traditional rule-basedmethods and use the direct metrics CTR (Click-Through-Rate) andExposure (the number of users who have been exposed by the cam-paign) to evaluate them. Results are shown in . From anend-to-end perspective, our solution has achieved better marketingresults than rule-based methods in multiple marketing campaigns.",
  "RELATED WORK5.1User targeting": "Methods of user targeting mainly can be categorized into twolines: rule-based and model-based methods. The rule-based meth-ods match potential users with specific demographic tags(age, gender, geography) or interests that are targeted by marketerswhich need marketers to do user profile association or mining.The model-based methods expand a given seed set by calculatingthe similarity of all pairs between seed users and candidate users or training customized prediction models for each service or",
  "CONCLUSION AND FUTURE WORK": "In this paper, we provide a novel user targeting approach by lever-aging LLMs to gain a structured understanding of marketers de-mands. We first define a new language SELL to express the needsof marketers more clearly. Subsequently, we propose an analogi-cal reasoning augmented framework, ARALLM, which consists ofanalogical reasoning based prompting and reasoning-augmentedmulti-task model distillation. The experimental results on GPT-3.5show that our analogical reasoning based prompting significantlyoutperforms other baseline prompting methods in the NL2SELLtask. In addition, we distill a large-scale dataset using GPT-3.5 andtrain the student LLMs using a multi-task training approach, whichis successfully used for online deployment.Since we primarily focus on the NL2SELL task in practical appli-cation scenarios, we have not yet applied the ARALLM frameworkto other reasoning tasks, such as coding or other structured lan-guage translation(e.g., HTML, JSON), which will be explored asfuture work. At the same time, there are still labor costs in the con-struction of reasoning libraries and SELL datasets, we will exploremore automated construction methods in the future. This work is funded by NSFC62306276, NSFCU23B2055 and NS-FCU19B2027. This work is supported by the Fundamental ResearchFunds for the Central Universities (226-2023-00138). This work wassupported by Ant Group.",
  "Paul E Black. 2004. Ratcliff/Obershelp pattern recognition. Dictionary of algo-rithms and data structures 17 (2004)": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shot learners. Advances in neuralinformation processing systems 33 (2020), 18771901. Ruisheng Cao, Lu Chen, Zhi Chen, Yanbin Zhao, Su Zhu, and Kai Yu. 2021.LGESQL: Line Graph Enhanced Text-to-SQL Model with Mixed Local and Non-Local Relations. In Proceedings of the 59th Annual Meeting of the Association forComputational Linguistics and the 11th International Joint Conference on NaturalLanguage Processing (Volume 1: Long Papers).",
  "Dedre Gentner. 1983. Structure-mapping: A theoretical framework for analogy.Cognitive science 7, 2 (1983), 155170": "Zihui Gu, Ju Fan, Nan Tang, Lei Cao, Bowen Jia, Sam Madden, and Xiaoyong Du.2023. Few-shot Text-to-SQL Translation using Structure and Content PromptLearning. Proceedings of the ACM on Management of Data 1, 2 (2023), 128. hiyouga. 2023. LLaMA Factory. Cheng-Yu Hsieh, Chun-Liang Li, Chih-Kuan Yeh, Hootan Nakhost, YasuhisaFujii, Alexander Ratner, Ranjay Krishna, Chen-Yu Lee, and Tomas Pfister. 2023.Distilling step-by-step! outperforming larger language models with less trainingdata and smaller model sizes. arXiv preprint arXiv:2305.02301 (2023). Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, SheanWang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of largelanguage models. arXiv preprint arXiv:2106.09685 (2021). Binyuan Hui, Ruiying Geng, Qiyu Ren, Binhua Li, Yongbin Li, Jian Sun, FeiHuang, Luo Si, Pengfei Zhu, and Xiaodan Zhu. 2021. Dynamic Hybrid RelationExploration Network for Cross-Domain Context-Dependent Semantic Parsing.Proceedings of the ... AAAI Conference on Artificial Intelligence,Proceedings of the... AAAI Conference on Artificial Intelligence (May 2021). Seungone Kim, Se June Joo, Doyoung Kim, Joel Jang, Seonghyeon Ye, Jamin Shin,and Minjoon Seo. 2023. The CoT Collection: Improving Zero-shot and Few-shotLearning of Language Models via Chain-of-Thought Fine-Tuning. arXiv preprintarXiv:2305.14045 (2023). Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and YusukeIwasawa. 2022. Large language models are zero-shot reasoners. Advances inneural information processing systems 35 (2022), 2219922213.",
  "Aiwei Liu, Xuming Hu, Lijie Wen, and PhilipS. Yu. 2023. A comprehensiveevaluation of ChatGPTs zero-shot Text-to-SQL capability. (Mar 2023)": "Haishan Liu, David Pardoe, Kun Liu, Manoj Thakur, Frank Cao, and Chongzhe Li.2016. Audience expansion for online social network advertising. In Proceedingsof the 22nd ACM SIGKDD International Conference on Knowledge Discovery andData Mining. 165174. Xuantao Lu, Jingping Liu, Zhouhong Gu, Hanwen Tong, Chenhao Xie, JunyangHuang, Yanghua Xiao, and Wenguang Wang. 2022. Parsing Natural Languageinto Propositional and First-Order Logic with Dual Reinforcement Learning. InProceedings of the 29th International Conference on Computational Linguistics.International Committee on Computational Linguistics, Gyeongju, Republic ofKorea, 54195431.",
  "Qiang Ma, Eeshan Wagh, Jiayi Wen, Zhen Xia, Robert Ormandi, and DatongChen. 2016. Score look-alike audiences. In 2016 IEEE 16th International Conferenceon Data Mining Workshops (ICDMW). IEEE, 647654": "Ashish Mangalampalli, Adwait Ratnaparkhi, Andrew O Hatch, Abraham Bagher-jeiran, Rajesh Parekh, and Vikram Pudi. 2011. A feature-pair-based associativeclassification approach to look-alike modeling for conversion-oriented user-targeting in tail campaigns. In Proceedings of the 20th international conferencecompanion on World wide web. 8586. Matt Post. 2018. A Call for Clarity in Reporting BLEU Scores. In Proceedings ofthe Third Conference on Machine Translation: Research Papers. Association forComputational Linguistics, Belgium, Brussels, 186191. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,Michael Matena, Yanqi Zhou, Wei Li, and PeterJ. Liu. 2019. Exploring the Limits ofTransfer Learning with a Unified Text-to-Text Transformer. arXiv: Learning,arXiv:Learning (Oct 2019).",
  "Peter D Turney. 2008. The latent relation mapping engine: Algorithm and exper-iments. Journal of Artificial Intelligence Research 33 (2008), 615655": "Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, and MatthewRichardson. 2020. RAT-SQL: Relation-Aware Schema Encoding and Linking forText-to-SQL Parsers. In Proceedings of the 58th Annual Meeting of the Associationfor Computational Linguistics. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoningin large language models. Advances in Neural Information Processing Systems 35(2022), 2482424837.",
  "Peitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou, and Jian-Yun Nie. 2023.Retrieve Anything To Augment Large Language Models. arXiv:2310.07554 [cs.IR]": "Yongchun Zhu, Yudan Liu, Ruobing Xie, Fuzhen Zhuang, Xiaobo Hao, Kaikai Ge,Xu Zhang, Leyu Lin, and Juan Cao. 2021. Learning to Expand Audience via MetaHybrid Experts and Critics for Recommendation and Advertising. In Proceedingsof the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining.40054013. Chenyi Zhuang, Ziqi Liu, Zhiqiang Zhang, Yize Tan, Zhengwei Wu, ZhiningLiu, Jianping Wei, Jinjie Gu, Guannan Zhang, Jun Zhou, et al. 2020. Hubble: Anindustrial system for audience expansion in mobile marketing. In Proceedings ofthe 26th ACM SIGKDD International Conference on Knowledge Discovery & DataMining. 24552463.",
  "ADESIGN OF SELL": "We provide a detailed explanation of the design and the usage ofthe SELL. The SELL is mainly composed of four elements:Keys are a series of tags that describe the features of the user,such as Gender, Marital Status, Resident City, and so on. In practicalmarketing scenarios, the database contains tens of thousands oftags that describe user profiles. Selecting the appropriate keys fromthis vast array of tags is a challenging task.Values are the fillings of the corresponding keys. They can begenerally divided into three types: numerical type, string type, andboolean type. For instance, the value corresponding to the keyMonthly Income is of numerical type, because they are continuousand non-enumerable. The value of Gender is of string type, withlimited options: Male or Female. Boolean type values have only twostates, i.e., True or False, such as Marital Status.Operators represent the relationship between keys and values.For numerical values, seven types of operators can be used to con-nect them with corresponding keys: Equal To, Greater Than, LessThan, Not Equal To, Not Greater Than, Not Less Than, and Between.For values of string type and boolean type, there are two types ofoperators: Belongs To and Not Belongs To. Keys, operators, and val-ues can form a basic conditional expression in SELL, formatted as(key#operator#value), such as (Marital Status#Belongs To#True).A conditional expression represents a cluster of target users, forexample, in the above example, the target users are married.Intersection and Union symbols are used to take the inter-section or union of multiple conditional expressions. In practicalmarketing scenarios, the features of the target users are often com-plex and difficult to describe using a single conditional expression.Therefore, it is necessary to combine the target users through in-tersection or union operations. In SELL, we use the symbols ANDand OR to denote the intersection and union operations, respec-tively. For example, ((Resident City#Belongs To#City A) OR (ResidentCity#Belongs To#City B)) AND (Pet Owning#Belongs To#True) de-scribes the pet owners who live in City A or City B.Some demands and their corresponding SELL expressions areshown in . More data can be found at",
  "As mentioned in the main paper, we write reasoning steps for 10%of data in the reasoning library. shows an example": "You are a robot skilled in reasoning. Please learn the followingexamples and complete the final reasoning steps:###Demand: Mothers who pay attention to baby educationTag list: [User Has Child/Days of Listening to Audiobooks/Homepage Visits/Red Packet Cover Collection/Current Insured Products/Balance of Points/Alipay User in Gourmet Scene/User Age Group/Number of Days Since User's First Account Opening/User Child Age/User Gender/User Marital Status/Preferences/]Answer: (Preference#Belongs To# Baby Education) AND (User Gender#Belongs To# Female) AND ((User Has Child#BelongsTo#True) OR (User Child Age#Between#0,4))Reasoning:(1)Extract keywords: Mothers, baby education(2) Select tags: User Has Child, User Child Age, User Gender, User Marital Status, Preferences(3) Form conditional expressions:(User Has Child#Belongs To#True) (User Gender#Belongs To#Female)(User Child Age#Between#0,4)(Preference#Belongs To#Baby Education)(4) Combine:(Preference# Belongs To# Baby Education) AND (User Gender#Belongs To#Female) AND ((User Has Child#BelongsTo#True) OR (User Child Age#Between#0,4))###......###Demand:{Input Demand}Tag list: {Input Tag list}Answer: {Input Answer}Reasoning:",
  ": Reasoning steps generation prompt": "You are a robot skilled in reasoning and story writing, giving you alogical expression that describes a certain group of people, and yourtask is to transform them into smooth natural language for expression.Whengeneratingnaturallanguage,pleasedonotcopythe expressions in logical expressions, but rather convert them into somesynonymous expressions. The following are some examples. Pleaseunderstand and complete the conversion of the final logicalexpression.###Answer: (Reference#Belongs To#Game) AND (User Age Group#Between#15,25) AND ((Career#Equals To#Student) OR (Is College student#Belongs to#True))Demand: A group of students aged 15-25 who love games.###......###Answer: {Input Answer}Demand:",
  "Answers(Preference#Belongs To#Baby Education) AND (User Gender#Belongs to#Female) AND ((User Has Child#Belongs To#True) OR (UserChild Age#Between#0,4))": "You are a professional grading expert. Given a predicted logicexpression and a ground truth logical expression, your task is toassess the accuracy of the predicted logic expression compared to thestandard logical expression. Score the accuracy of the predicted logicexpression between 0 and 10. 10 if the predicted answer and theground truth answer are identical, and 0 if they are entirely different.If only part of them is identical, please rate it between 0 and 10 basedon your judgment. The closer the score is to 10, the predicted answeris more accurate. Here are some examples:###Predicted answer: (Game#Belongs To#Genshin Impact) AND (Age#Greater Than#High) AND (Enthusiast#Equal To#Game) AND (Gender#Equal To#Male)Ground Truth Answer: (Preference#Belongs To#Genshin Impact) AND (User Age Group#Between# 18,35) AND (Gender#BelongsTo#Male)Accuracy: 3###Predicted answer: (User Age Group#Between#16,45) AND (Gender#Belongs To#Female) AND (Pet Owning#Belongs To#True)Ground Truth answer: (User Age Group #Between#16,45) AND (Gender#Belongs To#Female) AND (Pet Owning#Belongs To#HavePets)Accuracy: 8......Now given a predicted answer and a ground truth answer, please think carefully and output the accuracy score (don't output other contents):Predicted answer: {Input Predicted answer}Ground truth answer:{Input Ground truth answer}Accuracy:",
  ": GPT4 Evaluation prompt": "You are a robot skilled in reasoning. Please learn the followingexamples and complete the final reasoning steps:###Demand: Mothers who pay attention to baby educationTag list: [User Has Child/Days of Listening to Audiobooks/Homepage Visits/Red Packet Cover Collection/Current Insured Products/Balance of Points/Alipay User in Gourmet Scene/User Age Group/Number of Days Since User's First Account Opening/User Child Age/User Gender/User Marital Status/Preferences/]Answer: (Preference#Belongs To# Baby Education) AND (User Gender#Belongs To# Female) AND ((User Has Child#BelongsTo#True) OR (User Child Age#Between#0,4))Reasoning:(1)Extract keywords: Mothers, baby education(2) Select tags: User Has Child, User Child Age, User Gender, User Marital Status, Preferences(3) Form conditional expressions:(User Has Child#Belongs To#True) (User Gender#Belongs To#Female)(User Child Age#Between#0,4)(Preference#Belongs To#Baby Education)(4) Combine:(Preference# Belongs To# Baby Education) AND (User Gender#Belongs To#Female) AND ((User Has Child#BelongsTo#True) OR (User Child Age#Between#0,4))###......###Demand:{Input Demand}Tag list: {Input Tag list}Answer: {Input Answer}Reasoning:",
  "c OR c OR c OR c(c AND c) OR c(c OR c) AND c": "(c AND c) OR (c AND c)(c OR c) AND (c OR c)c AND (c OR c OR c)c OR (c AND c AND c)(c AND c) OR (c OR c)(c AND c) AND (c OR c)c AND ((c AND c) OR c)c AND ((c OR c) AND c)c OR ((c OR c) AND c)c OR ((c AND c) OR c)"
}