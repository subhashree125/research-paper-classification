{
  "ABSTRACT": "Trajectory prediction of moving traffic agents is crucial for thesafety of autonomous vehicles, whereas previous approaches usu-ally rely on sufficiently long-observed trajectory (e.g., 2 seconds)to predict the future trajectory of the agents. However, in manyreal-world scenarios, it is not realistic to collect adequate observedlocations for moving agents, leading to the collapse of most predic-tion models. For instance, when a moving car suddenly appears andis very close to an autonomous vehicle because of the obstruction,it is quite necessary for the autonomous vehicle to quickly andaccurately predict the future trajectories of the car with limitedobserved trajectory locations. In light of this, we focus on inves-tigating the task of instantaneous trajectory prediction, i.e., twoobserved locations are available during inference. To this end, weput forward a general and plug-and-play instantaneous trajectoryprediction approach, called ITPNet. Specifically, we propose a back-ward forecasting mechanism to reversely predict the latent featurerepresentations of unobserved historical trajectories of the agentbased on its two observed locations and then leverage them ascomplementary information for future trajectory prediction. Mean-while, due to the inevitable existence of noise and redundancy inthe predicted latent feature representations, we further devise aNoise Redundancy Reduction Former (NRRFormer) module, whichaims to filter out noise and redundancy from unobserved trajecto-ries and integrate the filtered features and observed features into acompact query representation for future trajectory predictions. In",
  "Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08...$15.00 essence, ITPNet can be naturally compatible with existing trajec-tory prediction models, enabling them to gracefully handle the caseof instantaneous trajectory prediction. Extensive experiments onthe Argoverse and nuScenes datasets demonstrate ITPNet outper-forms the baselines by a large margin and shows its efficacy withdifferent trajectory prediction models.",
  "Instantaneous Trajectory Prediction;Backward Forecasting;Noiseand Redundancy Reduction": "ACM Reference Format:Rongqing Li, Changsheng Li, Yuhang Li, Hanjie Li, Yi Chen, Ye Yuan,and Guoren Wang. 2024. ITPNet: Towards Instantaneous Trajectory Pre-diction for Autonomous Driving. In Proceedings of the 30th ACM SIGKDDConference on Knowledge Discovery and Data Mining (KDD 24), August2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages.",
  "INTRODUCTION": "Predicting the future trajectories of dynamic traffic agents is acritical task for autonomous driving, which can be beneficial to thedownstream planning module of autonomous vehicles. In recentyears, many trajectory prediction methods have been proposed incomputer vision and machine learning communities . Among these methods, they usually need to collectsufficiently long observed trajectories (typically, 2 to 3 seconds)of an agent, in order to accurately predict its future trajectories.Recent advances have shown promising performance in trajectoryprediction by learning from these adequate observations.However,in real-world self-driving scenarios, it is often difficultto accurately predict trajectories due to the limited availability ofobserved locations. For instance, due to the obstruction, a moving",
  "(b)": ": (a) Results of HiVT in terms of minADE@6 and minFDE@6 on the validation set of Argoverse with differentobserved locations as inputs during training and testing. The value in the horizontal axis denotes the number of observedlocations. (b) Future predictions (shown in green) when utilizing different lengths of predicted unobserved trajectory locations.The observed trajectories are shown in orange, the predicted unobserved trajectories are shown in brown, the ground-truthunobserved trajectories are shown in blue, and the ground-truth future trajectories are shown in red. car might suddenly appear and be very close to the autonomousvehicle. At this moment, the autonomous vehicle does not haveenough time to collect adequate observed locations of the car toaccurately predict the vehicles future trajectories. Such a case willcause the collapse of the aforementioned prediction models due tothe lack of information. To verify this point, we perform a typicaltrajectory prediction method, HiVT , with different settingson the Argoverse dataset . As shown in the left part of (a), if we use 20 observed locations as the inputs of the predictionmodel during both training and test phases as in , the predictionresults are 0.698 and 1.053 in terms of minADE@6 and minFDE@6,respectively. However, if we set only 2 observed locations as theinputs of the model during testing, the model will degrade sharply,no matter if the number of observed locations is 2 or 20 during thetraining phase. Thus, it is essential to study the trajectory predictiontask, when observed locations are very limited.In light of this, we focus on studying the task of instantaneouslypredicting future trajectories of moving agents, under the assump-tion of only 2 trajectory locations available. Recently, The work in proposes a trajectory prediction method based on momentaryobservations. However, this method mainly focuses on the trajec-tory prediction of pedestrians, which has not been explored forother moving agents. In addition, the input of their model is theRGB image which usually contains abundant context and seman-tic information. Thus, it is much easier for the model to predictfuture trajectories using RGB images, compared to only severaldiscrete trajectory locations. Moreover, design a knowledgedistillation mechanism based on limited observed locations andachieves promising results. Since the method needs to pre-traina teacher model, and learns a student model distilling knowledgefrom the teacher model, which largely increases the computationalcomplexities.To this end, we propose a general and principled approach, calledITPNet, for instantaneous trajectory prediction by only two ob-served trajectory locations. Specifically, ITPNet aims to train apredictor to backwardly predict the latent feature representationsof unobserved historical trajectory locations of the agent based on its two observed trajectory locations. The additional informationcontained in the predicted unobserved trajectory features assistsobserved trajectory features in better predicting future trajectories.Nevertheless, we find that as we increase the number of backwardlypredicted unobserved trajectory locations, the models performanceinitially improves but subsequently deteriorates (This is verifiedin of Experiment section). We analyze two primary factorsthat impede the utilization of more unobserved trajectory features:One is the noise brought by inaccurate prediction of the unobservedtrajectory features. The other is a negative impact on the trajectoryprediction due to the intrinsic redundant information. Lets con-sider a scenario where a vehicle travels straightly for a while andthen suddenly executes a turn. In such a case, a longer historicaltrajectory may erroneously boost the models confidence in thevehicle continuing straight in the future, as depicted in the upperportion of (b). Conversely, a shorter unobserved histori-cal trajectory with less redundancy tends to yield more accuratepredictions because it maintains lower confidence in the vehiclespersistence in a straight trajectory and, instead, maintains higherconfidence in the vehicles persistence in a turning trajectory, asshown in the lower portion of (b). Thus, how to removenoisy and redundant information from the predicted features ofthe unobserved trajectories becomes the key to success in instanta-neous trajectory prediction.In view of this, we devise a Noise Redundancy Reduction For-mer (NRRFormer) module and integrate it into our framework.NRRFormer can filter out noise and redundancy from a sequenceof predicted unobserved latent features, and effectively fuse thefiltered unobserved latent features with the observed features by acompact query embedding to acquire the most useful informationfor future trajectory prediction. It is worth noting that our ITPNetis actually plug-and-play, and is compatible with existing trajectoryprediction models, making them the kinds that can gracefully dealwith the instantaneous trajectory prediction problem.Our main contributions are summarized as: 1) We design a back-ward forecasting mechanism to reconstruct unobserved historical",
  "ITPNet: Towards Instantaneous Trajectory Prediction for Autonomous DrivingKDD 24, August 2529, 2024, Barcelona, Spain": "HiVT. If a car has a driving speed of 70km/s, our method can savearound 30 meters to observe the agent for trajectory prediction.Qualitative Results. We perform a visualization of the predictedmulti-modal trajectories generated by MOE, Distill, HiVT, and ourproposed method ITPNet+HiVT respectively on Argoverse datasetwith only 2 observed locations. The results are shown in .We observe that our method exhibits diversity and more accuratetrajectory prediction than other baselines in the scenario of turn-ing and going straight. This suggests that our method can handledifferent driving scenarios and can achieve improved predictionswith only 2 observed locations.",
  "RELATED WORKS2.1Trajectory Prediction with SufficientObservation": "In recent years, many trajectory prediction approaches have beenproposed . In the early stage of tra-jectory prediction, studies such as usually rely solely onobservation points and adopt simple social pooling methods to cap-ture interactions between agents. To capture the map information,including occupancy or semantic information, proposeto use Convolutional Neural Networks (CNN) to encode map im-ages. In addition, incorporate the information of lanes andtraffic lights on the map in the form of vectors. Recently, numer-ous methods have been proposed to fully exploit the interactioninformation between nearby agents, including implicit modelingby graph neural networks and attention mechanisms, and explicit modeling . To handle the uncer-tainty of road agents, researchers propose to generate multi-modaltrajectories using various approaches, including GAN-based meth-ods , VAE-based methods , flow-based methods, and diffusion models . Among them, one typi-cal approach is to establish a mapping between future trajectoriesand latent variables, producing multiple plausible trajectories bysampling the latent variable. In addition, goal-based methods havebecome popular recently , which first gener-ates multi-modal goals by sampling or learning , and thenpredict future trajectories conditioned on the goals.Although these methods have shown promising performance intrajectory prediction, they usually learn depending on sufficientlylong-observed locations. As aforementioned, these methods de-grade severely or even collapse when the number of observed loca-tions is limited. Different from these works, we attempt to addressthe task of instantaneously predicting the future trajectories of mov-ing agents, under the condition that only two trajectory locationsare observable.",
  "Trajectory Prediction with InstantaneousObservation": "Predicting the future trajectories of a moving agent by its limitedobserved locations remains a challenging problem. Recently, proposes an approach to integrate the velocity of agents, social andscene contexts information, and designs a momentary observationfeature Extractor (MOE) for pedestrian trajectory prediction. Theinput of MOE contains image frames from videos which usuallycontain abundant semantic information. Thus, it is much easierto predict future trajectories using image frames than that using several discrete trajectory points. Moreover, since this method ismainly designed for predicting trajectories for pedestrians, whatis the performance on other moving agents, e.g., cars, is worthto be further verified. proposes a knowledge distillation ap-proach using few observations as input, with the goal of loweringthe influence of noise introduced by the machine perception side(i.e., incorrect detection and tracking). As we know, knowledgedistillation-based approaches generally need to pre-train a teachermodel, and then distill knowledge from the teacher model to helpthe student model learn, which makes this kind of method compu-tationally expensive. designed a unified framework for tacklingmultiple tasks including instantaneous pedestrian trajectory predic-tion, where they constructed a universal singular space to share theinformation between long and short trajectory points. Differently,our focus lies on the task of instantaneous trajectory prediction,achieved by predicting unobserved historical trajectories, withoutusing any information of long trajectory points.",
  "PROPOSED METHOD3.1Problem Definition": "We denote a sequence of observed trajectory locations for a tar-get vehicle as X = {1,2, ..., }, where R2 is the -thlocation of the agent, and represents the number of observedhistorical locations. We set = 2 for the most extreme case, align-ing with the setting of MOE , which is the first work of in-stantaneous trajectory prediction. Moreover, we also denote thesequence of previous unobserved trajectory locations of the agentas X ={+1,+2, ,0}, where is the total numberof unobserved trajectory locations. The ground-truth future trajec-tories are denoted as X ={3,4, ...,2+}, where is the lengthof ground-truth future trajectory. Our goal is to predict plausi-ble trajectories {X} = {( 3, 4, ..., 2+)}, asin multi-model trajectory prediction methods . In con-trast to previous methods utilizing sufficient observed trajectorylocations (typically, 20 observed trajecotory locations on the Argo-verse dataset ), we attempt to leverage merely = 2 observedlocations X for instantaneous trajectory prediction. It is notewor-thy that, in principle, our proposed method is capable of acceptingobserved trajectory locations of arbitrary length as input.",
  "Overall Framework of ITPNet": "illustrates an overview of our proposed framework. Wefirst feed the instantaneous observed trajectory locations X intoa backbone (e.g., HiVT ) to obtain the latent feature representa-tions V = {1, 2}. Based on this representation V, we thenattempt to backwardly predict the latent feature representationsV = { +1, +2, ..., 0} of unobserved historical trajec-tories X. Considering that the predicted unobserved featurerepresentations V inevitably contain redundant and noisy in-formation as mentioned above, we design a Noise RedundancyReduction Former (NRRFormer) module to filter out this informa-tion from a predicted feature sequence. Subsequently, the filteredfeatures are combined with the observed features to generate acompact query embedding Q. The query embedding Q is then sentto the decoder for future trajectory predictions. Since the backbone",
  "BackwardForecast": ": Overview of our ITPNet framework. ITPNet mainly consists of two modules: 1) We propose a backward forecastingmechanism that attempts to reconstruct the latent feature representations V of previous unobserved trajectory locationsX by the two observed trajectories locations X. 2) We devise a Noise Redundancy Reduction Former to filter outnoise and redundancy in the predicted latent feature representations V, and both the resulting filtered features and theobservation features V are integrated into a compact query embedding Q. Finally, the query embedding is sent to the decoderto instantaneously predict future trajectories { X}. in our framework is arbitrary, our method is plug-and-play, andis compatible with existing trajectory prediction models, enablingthem to gracefully adapt to the scenario of instantaneous trajectoryprediction. In the following section, we will delve into a detailedintroduction of backward forecasting and the NRRFormer.",
  "Backward Forecasting": "When given only 2 observed locations X, one major issue weface is the lack of information, making existing trajectory predic-tion approaches degraded sharply. To alleviate this problem, wepropose to backwardly predict the latent feature representations ofprevious unobserved trajectory locations, and then leverage themas additional information for future trajectory prediction.First, we can obtain the latent feature representations V ofthe observed locations X via the backbone :",
  "V = {1, 2} = (X;),(1)": "where R is the latent feature representation of the -th lo-cation of the agent, and is the dimension of the feature. Thebackbone is parameterized by , and can be an arbitrary trajec-tory prediction model, e.g., HiVT and LaneGCN used inthis paper.After that, we attempt to backwardly predict the latent featurerepresentations V on the basis of V, addressing the issueof the lack of information. To this end, we introduce two self-supervised tasks: the first one is the reconstruction of the latentfeature representations, and the loss function is designed as:",
  "max(0,()()+),": "(7)where is a margin. It is worth noting that the first loss L in(5) targets at reconstructing the latent feature representation asaccurately as possible, while the second loss L in (7) aims to min-imize the discrepancy between the predicted unobserved featurerepresentations and the corresponding ground-truth feature repre-sentations at each timestep, while it enlarges a margin betweenthe predicted unobserved and non-corresponding ground-truth fea-ture representations. This can further assist in better reconstructingunobserved trajectory locations.",
  "Noise Redundancy Reduction Former": "Our Noise Redundancy Reduction Former (NRRFormer) modulethat is parameterized by contains Noise Redundancy ReductionBlocks (NRRBlocks). Each NRRBlock attempts to filter out noiseand redundancy in the predicted latent feature representationsV, and integrate the resulting filtered feature representations and observed feature representations V into a query embeddingQ+1, = 0, 1, , 1.As shown in the , The layer of NRRBlock takes asinput the query embedding Q and the unobserved feature repre-sentations Vthrough a self-attention mechanism:",
  "Q, V+1= SelfAtt(Q || V;,1),(8)": "where || denotes the concatenation operation, the self-attentionmodule is parameterized by ,1. Q0 is a random initialized tensor,V0= V, and the Qrepresents the output queryembedding. It is worth noting that the length of the query, denotedas , is smaller than the length of V, denoted as , so thatinformation in Vis forced to condense and collate into the",
  "Q,, V = SelfAtt(Q||V;,2),(9)": "where the self-attention module is parameterized by,2, Q,represents the query embedding after integrating both the filteredunobserved trajectory features and the observed trajectory features.Through this self-attention operation, the information of canbe effectively distilled into Q, while enabling it to fuse with ,thereby facilitating the exchange of complementary informationbetween them. Note that we assume the observed trajectory featuresV do not contain noise or redundancy, because the featuresare obtained by encoding X. Therefore, the Equation (9) onlyintegrates the information of V into the query Q through self-attention, but not input the V into the next NRRBlock. At theend of the NRRBlock, we employ a feed forward layer to producethe query representation for the next layer,",
  "Optimization and Inference": "We adopt the commonly used winner-takes-all strategy onthe obtained multi-modal trajectories {X}, which re-gresses the trajectory closest to the ground truth, denoted as L.In order to help the downstream planner make better decisions, aclassification loss L is also adopted to score each trajectory. Here,we adopt the same L and L as those in the correspondingbackbones (see Appendix A.5 for details of L and L). Finally,the total loss function can be expressed as:",
  "L = L + L + L + L,(12)": "where and are three trade-off hyper-parameters. We providethe pseudo-code of our training procedure in the Algorithm 1.For inference, when only 2 observed trajectory locations of atarget vehicle are collected, we first extract the latent feature repre-sentations based on the backbone , and then apply our backwardforecasting mechanism to predict the latent feature representationsof previous unobserved locations of the target agent by the net-works . After that, the NRRFormer = {,1,,2,,3}=1 filtersout the noise and redundancy in the unobserved latent feature rep-resentations and integrates the filtered features and observed latentfeature representations into query embedding. Finally, the queryembedding are fed into the decoder network for instantaneoustrajectory prediction.",
  "Output: Network parameters: , , {,1,,2,,3}=1, and.Initialize: Randomly initialize , , {,1,,2,,3}=1, ,and Q.while not converges do": "Compute latent feature representationsV = (X;) and V = (X;);Backward forecast V by V = (V;);Compute L, L by Eq. (5) and (7), respectively;Employ NRRFormer to filter out redundancy and noisein predicted unobserved latent feature representationsand integrate the resulting filtered featurerepresentations and observed feature representationsinto , byV0= V;for = 0... 1 do",
  "EXPERIMENTS4.1Datasets": "We evaluate our method for the instantaneous trajectory predictiontasks on two widely used benchmark datasets, Argoverse andNuScene .Argoverse Datasets: This dataset contains a total of 324,557 scenes,which are split into 205,492 training scenes, 39,472 validation scenes,and 78,143 testing scenes. The observation duration for both thetraining and validation sets is 5 seconds with a sampling frequencyof 10Hz. In contrast to previous approaches taking the first 2 seconds(i.e., 20 locations) as the observed trajectory locations and the last 3seconds as the future ground-truth trajectory, we only utilize = 2observed trajectory locations, and predict the future trajectory ofthe last 3 seconds in our experiments.NuScene Datasets The dataset consists of 32,186 training, 8,560validation, and 9,041 test samples. Each sample is a sequence of x-ycoordinates with a duration of 8 seconds and a sample frequencyof 2Hz. Previous approaches usually take the first 2 seconds (i.e., 5locations) as the observed trajectory locations and the last 6 secondsas the future ground-truth trajectory. However, we leverage only",
  "Implementation Details": "We perform the experiments using two different backbone models,HiVT and LaneGCN . Specifically, we utilize the temporalencoder in HiVT and the ActorNet in LaneGCN to extract the latentfeature representations, respectively. We set the feature dimensions to 64 and 128 when using HiVT and LaneGCN as the backbone,respectively. The hidden size of the LSTM for predicting unob-served latent feature representations is set to . The NRRFormerconsists of three NRRBlocks. In our experiments, the predicted un-observed length is set to 10 for the Argoverse dataset and 4 forthe nuScenes dataset. We set the query embedding length to = 4for the Argoverse dataset and = 2 for the nuScenes dataset. Inaddition, we set the trade-off hyper-parameters and to 0.1 and0.1.",
  "Baselines and Evaluation Metrics": "We first compare with two most related works: MOE and Distill. Since we use HiVT and LaneGCN as our backbone,respectively, we also compare our method with them. When usingHiVT as the backbone, we denote our method as ITPNet+HiVT.When using LaneGCN as the backbone, we denote our method asITPNet+LaneGCN.To evaluate these methods, we employ three popular evaluationmetrics , minADE@, minFDE@, and minMR@,where represents the number of the generated trajectories. weset to 1 and 6 in our experiments.",
  "Results and Analysis": "Performance on Instantaneous Trajectory Prediction. To demon-strate the effectiveness of our method for instantaneous trajectoryprediction, we compare our method with the state-of-the-art base-lines. The results listed in , shows that ITPNet+LaneGCNand ITPNet+HiVT significantly outperforms LaneGCN and HiVT,respectively. This illustrates that current state-of-the-art trajectoryprediction approaches struggle to effectively handle cases involvinginstantaneous observed trajectory inputs. However, when pluggingour framework into these two backbone models, respectively, theperformance is significantly improved. This shows our method iseffective for instantaneous trajectory prediction, and is compatiblewith different trajectory prediction models. Moreover, our methodsachieve better performance than MOE and Distill, which indicatesthe effectiveness of our methods once more.Ablation Study. We conduct ablation studies on the Argoversedataset, and we employ HiVT as the backbone. showsthe results. When the L is applied to the loss function, ourmethod significantly improves the performance. This indicates theeffectiveness of our proposed backward forecast mechanism for pre-dicting the latent feature representations of previous unobservedtrajectory locations. The loss L further boosts the performanceof the model, demonstrating the self-supervised task is meaning-ful. Moreover, our method can further improve the performancewhen integrating our NRRFormer, underscoring the effectiveness",
  "minADEminFDEminMRminADEminFDEminMR": "01.0681.6780.241----10.9691.4940.1930.9641.4980.19420.8721.3290.1600.8681.3230.15830.8321.2620.1490.8281.2540.14740.8451.2910.1540.8241.2400.14650.8591.3120.1560.8221.2320.14560.8671.3020.1610.8231.2310.14570.8811.3750.1730.8201.2220.14380.9031.4100.1810.8211.2220.14290.9331.4530.1870.8191.2200.142100.9671.5220.1960.8191.2180.141 of our NRRFormer in filtering out noise and redundancy from thepredicted unobserved latent features.Analysis of Different Lengths of Unobserved Trajectories.We investigate the influence of different lengths of unobservedtrajectory locations on instantaneous trajectory prediction. We useHiVT as the backbone on the Argoverse dataset. The results arelisted in . Note that when NRRFormer is not used, we di-rectly concatenate the predicted unobserved features with observed features for future trajectory prediction. As increases, the per-formance of the model is gradually improved. This reveals thatpredicting more latent feature representations can introduce moreuseful information, and thus be beneficial to trajectory prediction.However, when exceeds a certain value ( > 3), the perfor-mance deteriorates. This is attributed to the introduction of noiseand redundancy when predicting a longer feature sequence. When",
  "(d) ITPNet+HiVT": ": Qualitative results of a) HiVT, b) MOE+HiVT, c) Distill+HiVT, d) ITPNet+HiVT on Argoverse. The observed historicaltrajectories are shown in red, the ground-truth future trajectories are shown in black, and the predicted multi-modal futuretrajectories are shown in green. NRRFormer is enabled, the performance of our method is consis-tently improved as increases. This illustrates our NRRFormermodule can indeed filter out redundant and noisy information,demonstrating its effectiveness.Results of Varied Lengths of Observed Trajectories. To fur-ther demonstrate the effectiveness of our method, we utilize HiVTas the backbone and conduct experiments with varied lengths of observed trajectories on Argoverse dataset. As depicted in ,our approach consistently exhibits superior performance across arange of when compared to the baseline methods. One interestingpoint is that our ITPNet+HiVT with = 2 achieves comparableperformance to HiVT with = 5. This means that our method canaveragely save 1.5 seconds for trajectory prediction, compared to",
  "CONCLUSION": "In this paper, we investigated a challenging problem of instanta-neous trajectory prediction with very few observed locations. Weproposed a plug-and-play approach that backwardly predicted thelatent feature representations of unobserved locations, to mitigatethe issue of the lack of information. Considering the noise andredundancy in unobserved feature representations, we designedthe NRRFormer to remove them and integrate the resulting filteredfeatures and observed trajectory features into a compact queryembedding for future trajectory prediction. Extensive experimentalresults demonstrated that the proposed method can be effective forinstantaneous trajectory prediction, and can be compatible withdifferent trajectory prediction models.",
  "Inhwan Bae and Hae-Gon Jeon. 2023. A Set of Control Points ConditionedPedestrian Trajectory Prediction. Proceedings of the AAAI Conference on ArtificialIntelligence (2023)": "Inhwan Bae, Jean Oh, and Hae-Gon Jeon. 2023. EigenTrajectory: Low-RankDescriptors for Multi-Modal Trajectory Forecasting. Proceedings of the IEEE/CVFInternational Conference on Computer Vision (2023). Inhwan Bae, Young-Jae Park, and Hae-Gon Jeon. 2024. SingularTrajectory: Uni-versal Trajectory Predictor Using Diffusion Model. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition. 1789017901.",
  "Mayank Bansal, Alex Krizhevsky, and Abhijit Ogale. 2018. Chauffeurnet: Learn-ing to drive by imitating the best and synthesizing the worst. arXiv preprintarXiv:1812.03079 (2018)": "Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong,Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. 2020.nuscenes: A multimodal dataset for autonomous driving. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 1162111631. Sergio Casas, Cole Gulino, Renjie Liao, and Raquel Urtasun. 2020. Spagnn:Spatially-aware graph neural networks for relational behavior forecasting fromsensor data. In 2020 IEEE International Conference on Robotics and Automation(ICRA). IEEE, 94919497. Sergio Casas, Cole Gulino, Simon Suo, Katie Luo, Renjie Liao, and Raquel Urtasun.2020. Implicit latent variable model for scene-consistent motion forecasting. InComputer VisionECCV 2020: 16th European Conference, Glasgow, UK, August2328, 2020, Proceedings, Part XXIII 16. Springer, 624641. Ming-Fang Chang, John Lambert, Patsorn Sangkloy, Jagjeet Singh, SlawomirBak, Andrew Hartnett, De Wang, Peter Carr, Simon Lucey, Deva Ramanan, andJames Hays. 2019. Argoverse: 3D Tracking and Forecasting with Rich Maps. arXiv:1911.02620 [cs]. Guangyi Chen, Junlong Li, Jiwen Lu, and Jie Zhou. 2021. Human trajectoryprediction via counterfactual analysis. In Proceedings of the IEEE/CVF InternationalConference on Computer Vision (CVPR). 98249833. Jie Cheng, Xiaodong Mei, and Ming Liu. 2023. Forecast-MAE: Self-supervisedPre-training for Motion Forecasting with Masked Autoencoders. Proceedings ofthe IEEE/CVF International Conference on Computer Vision (2023). Sehwan Choi, Jungho Kim, Junyong Yun, and Jun Won Choi. 2023. R-Pred: Two-Stage Motion Prediction Via Tube-Query Attention-Based Trajectory Refinement.Proceedings of the IEEE/CVF International Conference on Computer Vision (2023). Jiyang Gao, Chen Sun, Hang Zhao, Yi Shen, Dragomir Anguelov, Congcong Li,and Cordelia Schmid. 2020. Vectornet: Encoding hd maps and agent dynamicsfrom vectorized representation. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR). 1152511533. Thomas Gilles, Stefano Sabatini, Dzmitry Tsishkou, Bogdan Stanciulescu, andFabien Moutarde. 2022. THOMAS: Trajectory Heatmap Output with learnedMulti-Agent Sampling. In International Conference on Learning Representations. Roger Girgis, Florian Golemo, Felipe Codevilla, Martin Weiss, Jim Aldon DSouza,Samira Ebrahimi Kahou, Felix Heide, and Christopher Pal. 2021. Latent Vari-able Sequential Set Transformers for Joint Multi-Agent Motion Prediction. InInternational Conference on Learning Representations.",
  "Junru Gu, Chen Sun, and Hang Zhao. 2021. Densetnt: End-to-end trajectoryprediction from dense goal sets. In Proceedings of the IEEE/CVF InternationalConference on Computer Vision (CVPR). 1530315312": "Tianpei Gu, Guangyi Chen, Junlong Li, Chunze Lin, Yongming Rao, Jie Zhou,and Jiwen Lu. 2022. Stochastic trajectory prediction via motion indeterminacydiffusion. In Proceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition (CVPR). 1711317122. Agrim Gupta, Justin Johnson, Li Fei-Fei, Silvio Savarese, and Alexandre Alahi.2018. Social gan: Socially acceptable trajectories with generative adversarialnetworks. In Proceedings of the IEEE Conference on Computer Vision and PatternRecognition (CVPR). 22552264.",
  "Sepp Hochreiter and Jrgen Schmidhuber. 1997. Long short-term memory. Neuralcomputation 9, 8 (1997), 17351780": "Chiyu Jiang, Andre Cornman, Cheolho Park, Benjamin Sapp, Yin Zhou, DragomirAnguelov, et al. 2023. MotionDiffuser: Controllable Multi-Agent Motion Pre-diction using Diffusion. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition. 96449653. Vineet Kosaraju, Amir Sadeghian, Roberto Martn-Martn, Ian Reid, HamidRezatofighi, and Silvio Savarese. 2019. Social-bigat: Multimodal trajectory fore-casting using bicycle-gan and graph attention networks. Advances in NeuralInformation Processing Systems 32 (2019). Mihee Lee, Samuel S Sohn, Seonghyeon Moon, Sejong Yoon, Mubbasir Kapadia,and Vladimir Pavlovic. 2022. Muse-VAE: multi-scale VAE for environment-awarelong term trajectory prediction. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR). 22212230. Namhoon Lee, Wongun Choi, Paul Vernaza, Christopher B Choy, Philip HS Torr,and Manmohan Chandraker. 2017. Desire: Distant future prediction in dynamicscenes with interacting agents. In Proceedings of the IEEE Conference on ComputerVision and Pattern Recognition (CVPR). 336345. Lingyun Luke Li, Bin Yang, Ming Liang, Wenyuan Zeng, Mengye Ren, Sean Segal,and Raquel Urtasun. 2020. End-to-end contextual perception and prediction withinteraction transformer. In 2020 IEEE/RSJ International Conference on IntelligentRobots and Systems (IROS). IEEE, 57845791.",
  "Rongqin Liang, Yuanman Li, Jiantao Zhou, and Xia Li. 2022. STGlow: A Flow-based Generative Framework with Dual Graphormer for Pedestrian TrajectoryPrediction. arXiv preprint arXiv:2211.11220 (2022)": "Yicheng Liu, Jinghuai Zhang, Liangji Fang, Qinhong Jiang, and Bolei Zhou. 2021.Multimodal motion prediction with stacked transformers. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). 75777586. Osama Makansi, Julius Von Kgelgen, Francesco Locatello, Peter Vincent Gehler,Dominik Janzing, Thomas Brox, and Bernhard Schlkopf. 2021. You Mostly WalkAlone: Analyzing Feature Attribution in Trajectory Prediction. In InternationalConference on Learning Representations. Karttikeya Mangalam, Yang An, Harshayu Girase, and Jitendra Malik. 2021. FromGoals, Waypoints & Paths To Long Term Human Trajectory Forecasting. In 2021IEEE/CVF International Conference on Computer Vision (ICCV). IEEE, Montreal,QC, Canada, 1521315222.",
  "Mancheng Meng, Ziyan Wu, Terrence Chen, Xiran Cai, Xiang Sean Zhou, FanYang, and Dinggang Shen. 2022. Forecasting Human Trajectory from SceneHistory. arXiv preprint arXiv:2210.08732 (2022)": "Abduallah Mohamed, Kun Qian, Mohamed Elhoseiny, and Christian Claudel.2020. Social-stgcnn: A social spatio-temporal graph convolutional neural networkfor human trajectory prediction. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR). 1442414432. Alessio Monti, Angelo Porrello, Simone Calderara, Pasquale Coscia, LambertoBallan, and Rita Cucchiara. 2022. How many observations are enough? knowledgedistillation for trajectory forecasting. In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition (CVPR). 65536562. Nigamaa Nayakanti, Rami Al-Rfou, Aurick Zhou, Kratarth Goel, Khaled S Refaat,and Benjamin Sapp. 2022. Wayformer: Motion forecasting via simple & efficientattention networks. arXiv preprint arXiv:2207.05844 (2022). Jiquan Ngiam, Vijay Vasudevan, Benjamin Caine, Zhengdong Zhang, Hao-Tien Lewis Chiang, Jeffrey Ling, Rebecca Roelofs, Alex Bewley, Chenxi Liu,Ashish Venugopal, et al. 2022. Scene transformer: A unified architecture forpredicting future trajectories of multiple agents. In International Conference onLearning Representations.",
  "Daehee Park, Hobin Ryu, Yunseo Yang, Jegyeong Cho, Jiwon Kim, and Kuk-JinYoon. 2023. Leveraging Future Relationship Reasoning for Vehicle TrajectoryPrediction. arXiv preprint arXiv:2305.14715 (2023)": "Tung Phan-Minh, Elena Corina Grigore, Freddy A. Boulton, Oscar Beijbom, andEric M. Wolff. 2020. CoverNet: Multimodal Behavior Prediction Using TrajectorySets. In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR). Amir Sadeghian, Vineet Kosaraju, Ali Sadeghian, Noriaki Hirose, HamidRezatofighi, and Silvio Savarese. 2019. Sophie: An attentive gan for predictingpaths compliant to social and physical constraints. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition (CVPR). 13491358. Tim Salzmann, Boris Ivanovic, Punarjay Chakravarty, and Marco Pavone. 2020.Trajectron++: Dynamically-feasible trajectory forecasting with heterogeneousdata. In Computer VisionECCV 2020: 16th European Conference, Glasgow, UK,August 2328, 2020, Proceedings, Part XVIII 16. Springer, 683700. Jianhua Sun, Yuxuan Li, Liang Chai, Hao-Shu Fang, Yong-Lu Li, and Cewu Lu.2022. Human trajectory prediction with momentary observation. In Proceedingsof the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).",
  "Zikang Zhou, Jianping Wang, Yung-Hui Li, and Yu-Kai Huang. 2023. Query-Centric Trajectory Prediction. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition. 1786317873": "Zikang Zhou, Luyao Ye, Jianping Wang, Kui Wu, and Kejie Lu. 2022. Hivt:Hierarchical vector transformer for multi-agent motion prediction. In Proceedingsof the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR).88238833. Dekai Zhu, Guangyao Zhai, Yan Di, Fabian Manhardt, Hendrik Berkemeyer,Tuan Tran, Nassir Navab, Federico Tombari, and Benjamin Busam. 2023. IPCC-TP: Utilizing Incremental Pearson Correlation Coefficient for Joint Multi-AgentTrajectory Prediction. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition. 55075516.",
  "A.2Failure cases of ITPNet": "We provide failure cases of ITPNet+HiVT on Argoverse dataset, asshown in . The model fails (1) when the future intentionof the agents suddenly changes (a, d); (2) the future behavior iscomplex and hard to perceive from observed trajectories, such asovertaking; (3) the agent does not follow the traffic rules, such asturning left from the lane for right turns (c).",
  "A.4Convergence Analysis": "We study the convergence of our method on Argoverse and nuScenes.The curves of the total loss of our method are shown in .we can see the loss decreases as the training steps, and it finallylevels off. 020k40k60k80k100kSteps 0.8 1.0 1.2 1.4 Final loss 05k10k 15k 20k 25k 30k 35kSteps 1.0 1.5 2.0 2.5 3.0 3.5 Final loss"
}