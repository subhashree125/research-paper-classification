{
  "Abstract": "In the e-commerce domain, the accurate extraction of attribute-value pairs (e.g., Brand: Apple) from product titles and user searchqueries is crucial for enhancing search and recommendation sys-tems. A major challenge with neural models for this task is the lackof high-quality training data, as the annotations for attribute-valuepairs in the available datasets are often incomplete. To address this,we introduce GenToC, a model designed for training directly withpartially-labeled data, eliminating the necessity for a fully annotateddataset. GenToC employs a marker-augmented generative modelto identify potential attributes, followed by a token classificationmodel that determines the associated values for each attribute. Gen-ToC outperforms existing state-of-the-art models, exhibiting upto56.3% increase in the number of accurate extractions. Furthermore,we utilize GenToC to regenerate the training dataset to expandattribute-value annotations. This bootstrapping substantially im-proves the data quality for training other standard NER models,which are typically faster but less capable in handling partially-labeled data, enabling them to achieve comparable performance toGenToC. Our results demonstrate GenToCs unique ability to learnfrom a limited set of partially-labeled data and improve the trainingof more efficient models, advancing the automated extraction ofattribute-value pairs. Finally, our model has been successfully inte-grated into IndiaMART, Indias largest B2B e-commerce platform,achieving a significant increase of 20.2% in the number of correctlyidentified attribute-value pairs over the existing deployed systemwhile achieving a high precision of 89.5%.",
  "Introduction": "The rapid expansion of e-commerce has led to a significant in-crease in the variety and complexity of products available online.Each product typically includes a set of attributes such as Brand,Model Name, Color, with distinct values like Boat, Rockerz 255Pro, Raging Red (as demonstrated in ). These attributes andvalues help consumers locate and select their desired products. Au-tomatic attribute-value identification is a well-studied problem inthe e-commerce literature . It has beeninvestigated in various contexts that involve additional metadata,such as product descriptions , knowledge graphs or",
  "Both authors contributed equally to this research": "images . In this study, we focus on automated extractionusing only textual information , such as product titles anduser search queries.To illustrate the practical utility of attribute-value extractionsystems, we examine their usage in IndiaMART1, Indias largestB2B e-commerce platform, where our system is currently deployed.In this platform, our attribute-value extraction system serves a dualpurpose, enhancing both product listings and user searches. Theattribute-value pairs provided in product listings by sellers are oftenincomplete and can be enhanced using extractions from the producttitle. In addition, the system is used to extract attribute-value pairsfrom user search queries, and these extracted pairs are matchedwith attribute-value pairs from the retrieved product listings tohighlight the matching ones. This dynamic feature highlighting ofproduct attribute-value pairs based on the search query enablesusers to easily find the products that meet their requirements.The predominant approach for acquiring training datasets forattribute-value extraction tasks typically relies on leveraging prod-uct listings and associated attribute-value pairs as furnished byvendors on e-commerce platforms. This method is directly depen-dent on the comprehensiveness and accuracy of the data that ven-dors provide. However, it is common practice for vendors to listthese details in an incomplete or inconsistent manner. Such gapsand irregularities in the data present a substantial obstacle, as thedevelopment of effective deep learning models for attribute-value : Complete collection of attribute-value pairs cover-ing all words in the specified product title, with only theattributes Brand, Model Name and Color (marked with *)are included in the training data and the remaining attributesare extracted by our GenToC model.",
  "D. Subhalingam, Keshav Kolluru, Mausam, and Saurabh Singal": ": Model architectures. (a) Seq2Seq-AVE outputs a string that concatenates all attribute-value pairs for a given inputquery. (b) NER-AVE classifies each word in the query, tagging it with the relevant attribute. (c) GenToC employs Gen-AE toyield a concatenated list of attributes and ToC-VE to annotate the values linked to every recognized attribute. The Gen-AEmodel incorporates markers (M) during the training process for the words which are covered. During inference, these markersare applied to all the words in the query.",
  "Related Work": "Attribute-value extraction has been asignificant topic of study in the realm of e-commerce, with a wealthof research targeting the extraction of product details from variousmodalities, including purely text-based methods as wellas those that incorporate images . A common limitationof these methods is their assumption of high-quality training data,which fails in many real-world scenarios where the training data iscreated using distant supervision and hence potentially incomplete. Some publicly available datasets like MAVE offer high-quality data (achieving over 98% F1-score), but our work specificallyaddresses the more challenging case of partially-labeled settings,where existing models struggle.Few works, such as Zhang et al. , Zheng et al. focus onimproving the training data quality in attribute-value extractiontasks but are severely limited to operating on a small number ofattributes only. For instance, Zhang et al. rely on a subset ofstrongly-labeled data to train a teacher network which in turn cre-ates training data for a student network. The requirement of havinga strongly-labeled subset limits them to operate on 13 attributes.Zheng et al. also relies on a small set of labeled instances tobe used in an active learning setting to collect good examples formanual annotation. They apply the technique to only one attributeper dataset. In contrast, GenToC introduces a fundamentally newmodel design that can handle incomplete training data withoutrequiring any completely labeled subsets. This allows the model toscale to tens of thousands of attributes.In terms of modelling, some of the earliest works on attribute-value extraction primarily employed rule-based extraction methods.They utilized a specialized seed dictionary or vocabulary to identifykey phrases and attributes . Moving beyond rule-basedsystems, several neural models have also been proposed for thistask in the recent past . Neural architectures for this task can bebroadly divided into two categories token classification or generative models. Token classification models utilizeNER models to identify the spans in the input text correspond-ing to an attribute. On the other hand, generative models utilizeSeq2Seq models to produce relevant attribute-value pairs from aspecified input. Our GenToC model makes clever use of both typesof architectures, using a generative model for attribute extractionand a token-classification model for value extraction. We compareextensively with both types of architectures and show significantgains achieved by GenToC.Token classification systems that rely on NER use atomic em-beddings for encoding attributes, which makes it challenging tohandle long-tail and complex attributes with less training data.Other token-classification systems utilize a BERT+LSTM model toembed each attribute separately . The embedded representationattends over the input query and identifies the corresponding value.However, this approach encounters scalability issues as the modelmust check for values using every possible attribute. Some genera-tive models are limited in their operation to a relatively small setof attributes (in their case, 38). This is because they use a Seq2Seqmodel pass for every attribute to identify the relevant values. Othergenerative models are applicable to larger attribute sets as theygenerate the attribute name as well. Similarly, GenToC can handle",
  "NERfastSeq2SeqslowGenToCslow": "large attribute sets due to a dedicated module that generates all therelevant attributes. Like other generative models, GenToC employscompositional encoding for attributes, which allows it to capturethe semantic meaning of attribute names by considering the wordsthey contain. So it is better at handling long-tail and complex at-tributes compared to NER models. But the generative nature ofthe model comes with a higher response time. We summarize thecharacteristics of the different models in .",
  "Problem Statement": "Given a query with words, where = 12 . . ., and a setof all potential attributes A, the objective of attribute-value ex-traction is to identify all possible attribute-value pairs, denoted as{(1, 1), (2, 2), . . . , (, )}, where A and is a subset ofwords in . In our setup, the input may be a product title or usersearch query, with each word in linked to at most one attribute.",
  "NER-AVE": "Following NER models used for the task , NER-AVE is anencoder-only model that operates by classifying tokens in the inputquery, where each token in the query is assigned a label corre-sponding to the relevant attribute. For example, boat is assignedthe attribute Brand, each of three words rockerz, 255 and pro areassigned the attribute Model Name, and so on. In case no attributeexists for a particular word, a special label, NoAttribute is usedto indicate the same. As an NER model, it treats every attribute as aunique label and assigns an atomic embedding. However, its majorstrength lies in its speed due to the simple encoder-only architec-ture. Although it is not capable of effectively learning from partiallylabeled data, we find that training it with better quality data gen-erated by GenToC, results in a fast and powerful attribute-valueextraction system.",
  "Seq2Seq-AVE": "The Seq2Seq-AVE model is based on the model developed in Shin-zato et al. , which employs a Seq2Seq model that yields a con-catenated string, incorporating the respective attribute-value pairs,for a given input query. For instance, the encoder takes an input ,and the decoder generates the output string 1:1, 2:2, . . . , :.For example, the decoder produces the generation Brand: boat,Model Name: rockerz 255 pro ..., one token at a time. The attribute",
  "Methods": "In this section, we describe the two-stage GenToC model and themarker-based training that enables it to learn from partially-labeleddata. We show the working of GenToC in (c). The initialstep employs a Generative Attribute Extraction (Gen-AE) model,which takes the product title or user search query as input andsubsequently generates a concatenated list of predicted attributes.The model is trained to generate attributes in the order their valuesoccur in the input. Given the models generative ability, it mightgenerate attributes outside the training set. However, these arevery infrequent (occur less than 0.1% of the times), so we forgoconstrained generation , avoiding any restrictions that wouldforce the attributes to belong solely to the original set of attributes. Markers: To deal with partially-labeled training data, we initiallyidentify the words within the input query that correspond to valuesof any attribute. We refer to these identified words as marked words.For the example, Boat Rockerz 255 Pro Raging Red Bluetooth Neck-band, in , [boat, rockerz, 255, pro, raging, red] are treatedas marked words during training, as they have been labeled withsome attribute. A special learnable embedding, termed as markerembedding, is added to the encoders final hidden states of everytoken of the marked words before being passed to the decoder. Thesame learnable embedding is shared across all marked tokens ev-erywhere. The model is then able to learn that the output attributes,as observed in the training data, are a result of considering only thelimited set of words in the input that have been marked. In other words, the marker embeddings act as signals that instruct the modelto focus on and incorporate the information from these markedwords into its attribute generation process, while preserving thebroader context of the input query.At inference time, the marker embedding is applied to all wordswithin the input query, nudging the model to generalize and out-put attributes that are relevant to any word present in the query.This enhances the models capability to recognize and associate at-tributes with words like bluetooth and neckband, which did not havevalid attribute-value pairs annotated and hence were not markedat training time.In the next stage, a Token Classification Value Extraction (ToC-VE) model takes each of the attribute names from the first stagealong with the original query, separated by a special delimiter,<sep>. It then labels each token with a binary value, for yes or no,to denote whether it corresponds to a value or not for the chosenattribute. This model is trained independently of the first-stagemodel. Since attribute names are used in the training process, itallows the model to learn from closely related attributes whichshare similarities in their names. This becomes particularly crucialwhen dealing with a noisy attribute name ontology, which mayinclude different attribute names conveying the same property, suchas Model Number and Model No. Value Pruning: When training the ToC-VE model with a set ofattribute-value pairs, it always contains a value for every attribute.However, during the inference phase, the attributes may be erro-neously generated by the Gen-AE model. As a consequence, ToC-VEmodel would tend to assign some value to even the incorrect at-tributes. To counteract this, we supplement the ToC-VE trainingwith additional data to identify instances where no correct value",
  ": Distribution of product categories within trainingdataset. Specific percentage values are omitted to preservedata confidentiality": "is present for a given attribute. We accomplish this by taking anexisting attribute-value pair and deleting the value from the orig-inal query. Consequently, we ensure that the chosen attribute nolonger appears in the query, training the model to label all tokens asNO values for the attribute. For example, if we remove the token,boat, the example, brand <sep> rockerz 255 pro raging red bluetoothneckband, will have no value for the attribute brand. We term thegeneration of this kind of synthetic training data as Value Pruning.For the final set of attribute-value pairs yielded by the model, weexclude those attributes that do not have any associated values.Therefore, the architecture of GenToC ensures effective attribute-value pair extraction, preventing error build-up in the pipeline,even in the face of partially labeled data and vast attribute setsthat contain redundancies. The complete algorithm for trainingand inference are described in Algorithm 1 and Algorithm 2 (inAppendix), respectively.",
  "Experimental Setup6.1Dataset and Metrics": "To curate data for the attribute-value extraction task, we make useof the product specifications that are provided by the sellers forproduct listings on IndiaMART. IndiaMART has 194M buyers, 7.9Msellers, and features over 108M different products and services. Forthe experiments in this paper, we limit our input exclusively toproduct titles and use a set of 2M examples for training models.It comprises 715K unique attribute-value pairs covering 24.7K at-tributes. The category-wise distribution of products is presented in. lists the top-five attributes and provides a set ofexample values for each. Despite the large scale of attributes, only40.7% of the words of a product title are tagged on average with anattribute. This motivates us to build models designed for partiallylabeled data, where the present attribute-value pairs are reliable andof high quality but might lack the complete set of attribute-values.We evaluate the systems on 39,671 samples (39K) based on theground truth values available. We compute the precision, recall and",
  "AttributeValues": "Brandhp, samsung, dell, siemens, boschMaterialstainless steel, plastic, brass, wooden, cottonColorblack, white, blue, red, brownModel name/numbern95, classic, 12a, kn95, ecoUsageindustrial, office, kitchen, packaging, home F1-score by comparing the set of attribute-value pairs generatedfor each input with the ground truth set of attribute-value pairs.We then report their averages taken across all examples. However,we find that automatic evaluation is challenging and often unreli-able due to the lack of normalization in the attribute names, as theground truth set can use different attributes to express the samecharacteristic. So, we randomly sample 2,000 examples (2K) andget every output checked using 3 data annotators (DAs). Theseannotators are skilled professionals who perform various annota-tion tasks within our organization. We consider the majority classassigned by the DAs to determine if a given attribute-value pairis correct/incorrect. We find that the inter-annotator agreement,computed using Fleiss kappa , is = 0.73, indicating substantialagreement among the annotators . The response time is mea-sured by calculating the average time taken for queries from the 2Ktest set (with a batch size of one) using an NVIDIA GeForce RTX3090 GPU.",
  "Implementation and Systems Compared": "To compare GenToC with the two classes of state-of-art models, weuse NER-AVE as a representative of the available NER-style models and Seq2Seq-AVE as a representative of the publishedgenerative models . We use our own implementations dueto the lack of availability of standard open-source implementationsfor the above works. For a fair comparison, we use the DeBERTa-V3-Small2 for all the classification tasks and BART-Base3 for all generation tasks. Both architectures consist of 6 encoderlayers, and BART has 6 additional decoder layers. Due to the needfor industry-scale systems to be used by millions of users, we dontexperiment with LLMs, which are highly resource intensive.",
  "Comparison with Other Models": "In , we present a comparison of three systems NER-AVE,Seq2Seq-AVE and GenToC. GenToC model outperforms its coun-terparts in recall, achieving 71.8% in automatic and 80.1% in manualevaluations, which are the highest among the three models. Thesescores are notably higher (by 11.7% and 27.3% in automatic andmanual evaluations) than those of the next best-performing model,NER-AVE. Such a significant gap in recall demonstrates that Gen-ToC effectively leverages the partially labeled nature of the trainingdata, resulting in more extractions. Indeed, the total number ofcorrect attribute-value extractions rose from 2,636 to 4,121 (a 56.3%increase) on the 2K test set. This increase in recall is mainly due toMarkers, which is elaborated upon in .2. In terms of preci-sion, both the NER-AVE and Seq2Seq-AVE models exhibit higherprecision than the GenToC model in both automatic and manualevaluations, with approximately 9-10% and 4-5% higher precision,respectively. Overall, GenToC maintains its superiority in F1-score,recording the highest at 71.3% in automatic evaluations and 83.0% inmanual evaluations, indicating a more balanced and consistent per-formance. However, a drawback of GenToC is its slower responsetime compared to the NER-AVE model. We address a potentialsolution to this performance-speed trade-off in .3.In , we present example cases showcasing GenToCs supe-rior performance in comparison to both NER-AVE and Seq2Seq-AVEmodels, in terms of the number of attribute-value pairs extracted.NER-AVE and Seq2Seq-AVE models are unable to leverage thepartially-labeled nature of the training data, as indicated previouslyin , despite possibly encountering the remaining unlabeledattribute-value pairs in other examples. In particular, each trainingexample is tagged with only 1.53 attribute-value pairs on average,so its not unexpected that these models maintain a similar taggingfrequency during inference. GenToC addresses this challenge byincorporating Markers, which allow for the identification of morenumber of attribute names than what is typically found in thetraining data.For instance, in the product title Casual Juliet Sleeve Solid WomenMaroon Top from the first example in , the GenToC modelsurpasses the other models by identifying four additional attributes Occasion, Sleeves Type, Pattern and Gender.",
  "Ablation Study": "Our initial hypothesis posited that incorporating Markers wouldenhance recall by identifying more attributes (critical in dealingwith partially-labeled data), while Value Pruning (VP) would boostprecision by eliminating inaccurately generated attributes. To vali-date this, we evaluated variations of the GenToC model, specificallyconfigurations excluding either Markers, VP, or both. The outcomes,as presented in , align with our expectations. Notably, in the2K test set, the absence of Markers in the GenToC model resulted ina 29.1% decrease in recall, while omitting VP led to a 7.2% reductionin precision. This pattern was also evident in the larger 39K test set.The findings clearly demonstrate the critical roles of both Markersand VP in balancing recall and precision. The GenToC model, whendevoid of either component, shows a diminished F1-score comparedto its complete configuration. These results substantiate our choice to incorporate both these strategies in the final formulation of theGenToC model, for its superior overall performance.We also experiment with adding Markers to NER-AVE and Seq2Seq-AVE. During training, we incorporate marker embeddings to thosewords which have been covered by the available attributes, andat inference, we incorporate the marker embeddings to all words.Consistent with earlier practices, these embeddings are added intothe final hidden states of the encoder. In the 2K test set, this modifi-cation results in considerable reductions in precision scores, plum-meting to 66.5% from 90.8% in NER-AVE and to 65.2% from 89.6%in Seq2Seq-AVE. A similar pattern can be observed in case of the39K test set as well. This outcome underscores the importance oftwo-stage model for using markers effectively. The bifurcated struc-ture of the two-stage model ensures that markers are exclusivelyutilized in the first stage. This design circumvents the problem insingle-stage models, where markers can force the assignment ofattributes to every word, often resulting in suboptimal performance.This also significantly increases the response time for the Seq2Seq-AVE model (see ), as it has to generate a longer output dueto more extractions. On the other hand, Value Pruning is usefulwhen there is an candidate set of attribute names that might includesome incorrect ones, such as those generated by the first stage ofthe GenToC model. It aims to reduce irrelevant attribute names inthe final result by predicting empty values for them. Conversely,Seq2Seq-AVE and NER-AVE produce both attribute-value pairs in aunified step, making Value Pruning inapplicable for them.",
  "Bootstrapping Training Data": "From , we find that NER-AVE has the fastest response time.Seq2Seq-AVE is the slowest, as it has to generate a long stringcontaining all attributes and values. The high performance of Gen-ToC comes at the cost of speed, as its response time is 10x greaterthan NER-AVEs. With the motivation to build a deployable systemthat can handle real-world traffic, we experiment with cleaningthe training data by regenerating it using the trained GenToCmodel. It increases the average number of words tagged in anyattribute-value pair from 0.41 to 0.65 while increasing the totalnumber of attribute-value pairs from 3M to 4.7M on the full train-ing data. In , we find that the NER-AVE model trained withthis GenToC-bootstrapped training data significantly improvesthe performance over the NER-AVE model trained with originalpartially-labeled data. In fact, its performance when trained withGenToC-bootstrapped data is comparable to the GenToC model inboth automatic and manual evaluations. This makes it a strong alter-native to the GenToC model for production environments, whererapid response times are crucial. Additionally, we experiment withregenerating the training data using the originally trained NER-AVE,the second-best model in terms of F1-score. However, we find thattraining with this data results in marginally decreased performance,proving less effective than training with GenToC-bootstrappeddata. This is because, unlike GenToC, the NER-AVE model is notequipped to learn from incomplete data. Consequently, it does nothelp in reducing the partially labeled nature of the training dataupon regeneration, rendering the bootstrapping unproductive. Fur-thermore, in Appendices B and C, we also assess the performance ofthese models on long product titles and long-tail attributes. We find",
  "Precision-Recall Trade-off": "To understand the trade-off between precision and recall acrossdifferent systems, we evaluate the systems using a precision-recallcurve. We employ a common re-scoring model to compute the con-fidence level for all system extractions in this process. The modelused for re-scoring is an independent Seq2Seq model, trained byusing the product title as the input and the attribute: value stringas the output, utilizing the same training data. The model com-putes the confidence level associated with any given attribute-valuepair by accumulating the log probabilities for every token presentwithin the output string. We found that the model provides us withbetter-calibrated scores for an attribute-value pair generated byany of the systems. Using the results from the manually evaluated(2K) set, we applied uniformly spaced thresholds between 0 and1 for the confidence values to create the Precision-Recall curveshown in . Upon inspection, it was clear that GenToCsperformance significantly eclipsed that of baselines. Across mostof the curve, GenToC achieves a higher precision for a given recall,demonstrating its power. Further, the AUC in case of NER-AVE andSeq2Seq-AVE are 0.51 and 0.48 respectively, while that of GenToCis 0.76. This substantiates the superior quality and efficacy of theGenToC system.Additionally, the curve for NER-AVE trained with GenToC boot-strapped data closely mirrors that of GenToC, with an AUC of 0.77.This further demonstrates the effectiveness of training with databootstrapping from GenToC.",
  "Deployment Status and Impact": "Our system has been deployed on Indias largest B2B e-commerceplatform, IndiaMART, with 194M buyers and 7.9M sellers. It hasbeen successfully integrated into the core product search function-ality and has already served over 200Mrequests since deployment.Specifically, it extracts attribute-value pairs from product titles inlistings, and enables dynamic feature highlighting of product fea-tures according to user search queries. As an illustration of dynamicfeature highlighting, when a user searches for 10 tier shoe rack,the system detects the attribute-value pair Number of shelves:10. This information is then used to highlight the correspondingfeature Available number of shelves: 10 available for a listingwith the product title Steel Shoe Rack, in the search results. Thisleads to enriched user search experience.For the deployment version, we train GenToC using a datasetthat is 3x larger, with a similar partially-labeled nature. Further, weregenerate the training dataset using the trained GenToC model andsubsequently train a faster NER-AVE model with this bootstrappeddata, as detailed in .3. We use this GenToC-bootstrappedNER-AVE model for deployment.We find significant improvements over the prior deployed system(which is based on rule-based non-neural system) for this task. Rule-based systems that use regular-expression based techniques havetheir own limitations, such as struggling with negations (e.g., non-stretchable jeans), handling common spelling variations (litre, liter, l,or ltr), making broad generalizations (both red and raging red referto colors), and properly tagging attributes contextually (Galaxycould refer to either a chocolate brand or a Samsung mobile model).In an offline evaluation, based on a manual audit of searchqueries, we observe the results tabulated in . It can be ob-served that the previously deployed rule-based system falls short ofour proposed approach by more than 20% in terms of recall, whilebeing only marginally better by less than 2.5% in precision. Thisresults in an overall difference of approximately 10% in the F1-scorebetween the two methods. In online evaluation, we find that oursystem leads to a 9% increase in queries with identified attributesthat lead to dynamic feature highlighting.",
  "Conclusion and Future Work": "In this work, we introduce a new framework designed to effectivelyutilize incomplete training data, which is common in attribute-valueextraction tasks, and provide a solution suitable for real-time de-ployment. We achieve this by employing the novel GenToC modelfor attribute-value extraction, incorporating Markers to learn frompartially labeled data and Value Pruning to avoid erroneous attributetagging. Moreover, by utilizing GenToCs ability to enhance train-ing data through bootstrapping, we can train faster NER modelsthat are not designed to learn from partially labeled data, thereby",
  "A Framework for Leveraging Partially-Labeled Data for Product Attribute-Value Identification": "bridging the gap between research and practical application. Oursystem has been deployed on Indias largest B2B e-commerce plat-form, IndiaMART, into the core product search functionality. Futurework could explore performing multiple stages of bootstrapping,handling near-redundancy in attributes, and uncovering novel at-tributes. We would like to thank IndiaMART for providing us with the datafor our research and helping us integrate with their current sys-tems. We would like to thank KnowDis Data Annotator team fortheir timely help with the annotations required for this project andKnowDis Data Science members for giving valuable suggestions.",
  "David Nadeau and Satoshi Sekine. 2007. A survey of named entity recognitionand classification. Lingvisticae Investigationes 30 (2007), 326": "Katharina Probst, Rayid Ghani, Marko Krema, Andrew E Fano, and Yan Liu. 2007.Semi-supervised learning of attribute-value pairs from product descriptions. InProceedings of the 20th International Joint Conference on Artificial Intelligence.Morgan Kaufmann Publishers Inc., 28382843. Duangmanee Putthividhya and Junling Hu. 2011. Bootstrapped named entityrecognition for product attribute extraction. In Proceedings of the 2011 Con-ference on Empirical Methods in Natural Language Processing. Association forComputational Linguistics, 15571567. Martn Rezk, Laura Alonso Alemany, Lasguido Nio, and Ted Zhang. 2019. Ac-curate Product Attribute Extraction on the Field. 2019 IEEE 35th InternationalConference on Data Engineering (ICDE) (2019), 18621873. Thomas Ricatte and Donato Crisostomi. 2023. AVEN-GR: Attribute Value Ex-traction and Normalization using product GRaphs. In Proceedings of the 61stAnnual Meeting of the Association for Computational Linguistics (Volume 5: Indus-try Track), Sunayana Sitaram, Beata Beigman Klebanov, and Jason D Williams(Eds.). Association for Computational Linguistics, Toronto, Canada.",
  "K. Wang, Jianzhi Shao, T. Zhang, Qijin Chen, and Chengfu Huo. 2023. MPKGAC:Multimodal Product Attribute Completion in E-commerce. Companion Proceed-ings of the ACM Web Conference 2023 (2023)": "Qifan Wang, Li Yang, Bhargav Kanagal, Sumit K. Sanghai, D. Sivakumar, BinShu, Zac Yu, and Jonathan L. Elsas. 2020. Learning to Extract Attribute Valuefrom Product via Question Answering: A Multi-task Approach. Proceedings ofthe 26th ACM SIGKDD International Conference on Knowledge Discovery & DataMining (2020). Yuk Wah Wong, Dominic Widdows, Tom Lokovic, and Kamal Nigam. 2009.Scalable Attribute-Value Extraction from Semi-structured Text. 2009 IEEE Inter-national Conference on Data Mining Workshops (2009), 302307.",
  "Huimin Xu, Wenting Wang, Xin Mao, Xinyue Jiang, and Man Lan. 2019. Scalingup Open Tagging from Tens to Thousands: Comprehension Empowered AttributeValue Extraction from Product Title. In ACL": "Li Yang, Qifan Wang, Zac Yu, Anand Kulkarni, Sumit K. Sanghai, Bin Shu,Jonathan L. Elsas, and Bhargav Kanagal. 2021. MAVE: A Product Dataset forMulti-source Attribute Value Extraction. Proceedings of the Fifteenth ACM Inter-national Conference on Web Search and Data Mining (2021). Danqing Zhang, Zheng Li, Tianyu Cao, Chen Luo, Tony Wu, Hanqing Lu, YiweiSong, Bing Yin, Tuo Zhao, and Qiang Yang. 2021. QUEACO: Borrowing Trea-sures from Weakly-labeled Behavior Data for Query Attribute Value Extraction.Proceedings of the 30th ACM International Conference on Information & KnowledgeManagement (2021). Guineng Zheng, Subhabrata Mukherjee, Xin Dong, and Feifei Li. 2018. OpenTag:Open Attribute Value Extraction from Product Profiles. Proceedings of the 24thACM SIGKDD International Conference on Knowledge Discovery & Data Mining(2018). Tiangang Zhu, Yue Wang, Haoran Li, Youzheng Wu, Xiaodong He, and BowenZhou. 2020. Multimodal Joint Attribute Prediction and Value Extraction forE-commerce Product. In Conference on Empirical Methods in Natural LanguageProcessing.",
  "BPerformance on Long Product Titles": "To assess how well the models handle long-tail cases, we evaluatetheir performance on long product titles. Product titles consist offive words on average, with a standard deviation of two. Thus, wecreate a test set comprising 500 examples, each containing at leastseven words, for the evaluation process. In , we tabulate thescores obtained from manual evaluation, together with the taggedratio that is, the proportion of words in the product title thathave been marked with an attribute for various models. While Seq2Seq-AVE exhibits the highest precision at 95.3%, andGenToC without VP shows a notable recall of 90.3%, GenToC,stands out with the highest F1-score of 90.7%. This underscoresGenToCs superior balance in the precision-recall trade-off, evenin cases where the product titles are long. Its noteworthy thatwhen Markers are incorporated into the NER-AVE and Seq2Seq-AVE models, over 99% of the words in product titles are linked toan attribute. However, this high tagging ratio might not be ideal,particularly for lengthy queries, as not every word necessarilypossesses a relevant attribute. This is also reflected in the significantdecrease in precision values for these models when Markers areused a drop of over 22% compared to their counterparts withoutMarkers. Single-stage models, which have to perform value labelingalongside attribute extraction, face this issue when Markers areemployed, as they attempt to arbitrarily assign an attribute to everyword. However, since we apply markers only to the first stageof the GenToC model, it does not face this problem as there isno direct one-to-one mapping between the predicted attributesand input words. Finally, even the NER-AVE model trained withGenToC bootstrapping attains an F1-score thats comparable withGenToC, while having a faster response time. This shows that thefull potential of NER-AVE model is realized only with high-qualitytraining data.",
  "CPerformance on Long-tail Attributes": "To assess the efficacy of models in handling attributes with lowoccurrence rates, we measure their precision on attributes withinthe bottom 33% by frequency in the training dataset. These find-ings are illustrated in . Notably, the NER-AVE model, whentrained on the original dataset, exhibits a markedly inferior perfor-mance, with a difference of up to 19% compared to the GenToCmodel with the bottom-10% of attributes. This is likely due to theNER-AVE model treating each attribute name as an independentatomic label, which, combined with the limited training data forlong-tail attributes, makes learning difficult during training. Con-versely, Seq2Seq-AVE and GenToC employ compositional encodingfor attributes, enabling them to capture the semantic meaning of at-tribute names by considering the constituent words. This approach"
}