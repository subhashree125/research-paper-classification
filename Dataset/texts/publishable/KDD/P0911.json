{
  "ABSTRACT": "Mobile devices, especially smartphones, can support rich functionsand have developed into indispensable tools in daily life. With therise of generative AI services, smartphones can potentially trans-form into personalized assistants, anticipating user needs and sched-uling services accordingly. Predicting user intents on smartphones,and reflecting anticipated activities based on past interactions andcontext, remains a pivotal step towards this vision. Existing researchpredominantly focuses on specific domains, neglecting the chal-lenge of modeling diverse event sequences across dynamic contexts.Leveraging pre-trained language models (PLMs) offers a promis-ing avenue, yet adapting PLMs to on-device user intent predictionpresents significant challenges. To address these challenges, wepropose PITuning, a Population-to-Individual Tuning framework.PITuning enhances common pattern extraction through dynamicevent-to-intent transition modeling and addresses long-tailed pref-erences via adaptive unlearning strategies. Experimental resultson real-world datasets demonstrate PITunings superior intent pre-diction performance, highlighting its ability to capture long-tailedpreferences and its practicality for on-device prediction scenarios.",
  "Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "Device-cloud collaboration; Pretrained language model; Personal-ization; User intent": "ACM Reference Format:Jiahui Gong, Jingtao Ding, Fanjin Meng, Guilong Chen, Hong Chen, ShenZhao, Haisheng Lu, and Yong Li. 2024. A Population-to-individual TuningFramework for Adapting Pretrained LM to On-device User Intent Prediction. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discoveryand Data Mining (KDD 24), August 2529, 2024, Barcelona, Spain. ACM, NewYork, NY, USA, 12 pages.",
  "INTRODUCTION": "Nowadays mobile devices, especially smartphones, have become amajor object that individuals interact with in their daily lives. Forexample, users use their phones to monitor sleep, wake themselvesup, hail a car for commuting, watch short videos in rest time, paymoney at restaurants, etc., across most activities in one day. Empow-ered by the recent booming of generative artificial intelligence (AI)services (e.g., chatGPT ), the smartphone can further evolve intoa personalized assistant that can perceive user needs in advance andtimely schedule corresponding services. The key pathway towardthis future is the capability to predict smartphone users intents,which refers to what activity they intend to do, based on theirprevious action sequences and contextual information .Existing works mostly focus on predicting user intents withinone specific domain, for example, purchase intent in online plat-forms , search intent in search engines ,pedestrian intention for robots or autonomous vehicles .",
  "KDD 24, August 2529, 2024, Barcelona, SpainJiahui Gong et al": "To characterize complex dependencies between intent and context,they leverage specific network architectures including feature in-teraction networks or graph neural networks . Incontrast, predicting users daily activity intent when using smart-phones requires modeling diverse event sequences across dynamicchanging contexts, which generally rely on large-scale behavioraldata. However, with increasing concerns about data privacy leakageand real-time serving latency, real-world prediction applicationsusually adopt on-device model training and deployment, whichadds constraints on data scales and exacerbates the data lackingissue.Pretrained language models (PLMs) , on the other hand,provide a promising solution owing to their encoded knowledgeand commonsense reasoning capability acquired through exten-sive training on diverse datasets. For example, if someone talksabout going jogging every morning, a PLM can infer that the in-dividual values fitness, which might predict other health-relatedbehaviors. In this regard, PLMs have been successfully adaptedto other cross-domain tasks related to human behaviors, like rec-ommender systems and mobility trajectories .Therefore, we propose to leverage PLMs for on-device user intentprediction, i.e., adapting P LMs from the language domain intothe daily human behavior domain, which is non-trivial due to thefollowing three challenges: Population-level common behavioral patterns are hardto extract from the noisy aggregation of diverse eventsequences. Predicting user intent based on their previousaction events requires the characterization of common tran-sition patterns from event sequences to specific intent. How-ever, not all events correlate to the generation of intent, i.e.,information redundancy, and this changes with intent type.Although transformer-based architecture has proven its use-fulness in the sequential modeling of user events , itremains questionable whether common event-intent transi-tion patterns shared among the population can be extractedfrom the above noisy and redundant event sequences. Individual-level long-tailed preferences are hard tocapture by large LMs. Besides common behavioral patterns,individual preference also matters a lot in predicting userintent. For example, compared with public transport, car-hailing might be a long-tailed choice globally, while favoredby a few users. However, long-tailed individual preferencesare prone to be overtaken by population-level patterns thatdominate the populations behavioral data. This inevitablyleads to a biased model favoring those intents with a highproportion after tuning a PLM. Existing works on aligningLM for behavioral modeling tend to construct tuningtasks analogous to their counterparts in NLP like prompttuning or instruction tuning . Without a specificdesign, however, it is generally difficult to alleviate the abovebias problem of the long-tailed preferences given rather lim-ited individual behavioral data. Designing a practical LM tuning framework to sup-port on-device learning and inference of user intent isdifficult. Existing works have proposed a few cloud-devicecollaboration approaches to achieve on-device prediction or recommendation, mainly targeting device-side personaliza-tion. Differently, the expected tuning framework is tailoredfor pretrained LMs and should be able to leverage large-scalepopulation-level data efficiently and limited individual-leveldata effectively. In this paper, we propose a novel Population-to-Individual Tun-ing framework (named PITuning) for adapting pretrained LM to on-device user intent prediction. The core of the PITuning frameworkis the population-level behavioral data tuning on a pretrained LMthat produces a powerful but gigantic global predictor at the cloudside, and the individual-level tuning that adaptively distills this pre-dictor into a lightweight user-specific predictor at the device side.To solve the first challenge of extracting common behavioral pat-terns at the population level, PITuning is designed to better capturedynamic event-to-intent transition patterns, i.e., event-wise infor-mation enhancement by an auxiliary event-reconstruction loss andintent-wise attentive modeling on top of pretrained transformer.As for the second challenge of capturing long-tailed preferencedistribution at the individual level, PITuning is equipped with anovel unlearning strategy for each user that first identifies a set ofintents, which are under-represented in population data but empha-sizes unique preferences of this user and then remove the modelsmemorization on these intents. This further guarantees effectivelycapturing long-tailed preference by tuning on individual behavioraldata at the device side. To summarize, our main contributions areas follows.",
  "We provide a novel angle of adapting PLMs into the humanbehavioral domain and further resolve the longstanding issueof capturing long-tailed user preferences": "We design a population-to-individual tuning framework forPLM that extracts common behavioral patterns and capturesindividual unique patterns simultaneously, compatible withon-device prediction scenarios. Experiment results on two real-world datasets demonstratethe superiority of our PITuning over state-of-the-art base-lines in terms of intent prediction performance. Notably, theoutperformance regarding the macroscopic average of pre-cision and recall is 24%-37%, underscoring its capability ofcapturing long-tailed preference for individuals. Ablationstudies and in-depth analysis further support the rationalitybehind specific method design, as well as the high practical-ity in terms of efficiency and scalability.",
  "PRELIMINARY2.1Data Analysis": "We begin with a comprehensive data analysis. Initially, we ran-domly sample 1,000 users to calculate their intent distribution. Sub-sequently, we employ the KMeans method to cluster usersintent distribution and visualize the result using t-SNE , as il-lustrated in . Additionally, we present the population-levelintent distribution alongside the distribution for each cluster. Fromthe figure, we observe that intent distribution varies significantlybetween clusters. This discrepancy undoubtedly complicates thetask of user-personalized modeling.",
  "Problem Statement": "Now we give a formal definition of our research problem:Problem1 (User intent prediction). The behavior correspondingto the -th user intention can be represented as = (,,,),indicating that a specific event takes place involving user atlocation during time slot . Here, , , , and refer to theuser ID, location ID, time slot ID, and event ID, respectively. Weuse U, L, T, E to denote the sets of users, locations, time slots,and events, with their respective sizes given by , , , and. As outlined in the introduction, each user exhibits a particularintention associated with an event-related behavior . We defineI as the set of possible intentions, with its size represented by .The event encompasses specific instances involving users, such asthe use of app services, spatial trajectory occurrences, and system-related events. The intent captures the underlying goal, purpose,or objective driving these events, effectively grouping them intocategories. Therefore, the quantity of distinct intents, denoted by , is typically less than the total count of events, represented by.User intent prediction aims to forecast future user intent basedon its past event series, which can be formed as,",
  "METHOD3.1Framework Overview": "We introduce our PITuning framework for adapting PLM to on-device intent prediction, as depicted in . On the cloud side,we utilize aggregated behavioral data collected from a populationto fine-tune a global predictor, capturing population-level commonbehavioral patterns. Subsequently, we perform model distillation toobtain a lightweight predictor suitable for on-device deployment.On the device side, before further fine-tuning on individual data,we incorporate a novel unlearning strategy to identify and mitigatebiases resulting from uneven learning of intents during population-level tuning. Finally, after two stages of PITuning, we attain alightweight yet personalized model capable of accurate and efficientintent prediction on the device.",
  "Population-level Tuning": "We leverage population data alongside a PLM to model commonbehavioral patterns. The architecture of our model is depicted in(a), where we integrate parameters from GPT2 , an NLPpre-trained transformer model. Additionally, to enhance learningof event-to-intent transition patterns shared among the popula-tion, we introduce a masked event-reconstruction loss at the eventlevel and utilize intent-wise attentive modeling atop the pretrainedtransformer. Finally, we distill a lightweight predictor under theguidance of the global predictor to meet deployment requirementson the device. 3.2.1Embedding layer. Since we apply the NLP pre-trained modelto a new modality, We create four embedding layers to get thelocation embedding E R , weekday embedding E R ,time-slot embedding E R and event embedding E R",
  "respectively, where denotes the embedding size": "3.2.2Transformer block. In the global predictor, we employ theGPT2 model as the foundation for our transformer blocks. Trainedon various web data, the GPT2 model is imbued with extensiveknowledge, common sense, and fundamental principles, showing arobust capacity for generalization. We concat the location embed-ding, weekday embedding, time-slot embedding, and event embed-ding and put them into transformer blocks to obtain an implicitrepresentation of the historical event sequence R 4, whichcan be formed as,",
  "H = GPT2(concat(E, E, E, E)).(2)": "3.2.3Intent-aware attentive modeling. Notice that different intentsexhibit preferences for varying lengths of historical data. To addressthis, we have developed a novel Intention Attention Network (IAT)that introduces a novel designed local activation unit to adaptivelyweigh sequences of historical events, accommodating the uniquerequirements of each intent. We create the learnable intent embed-ding matrix E R 4 and feed it into IAT together with thehistory matrix.Specifically, we apply activation units to the features derivedfrom users historical behaviors. These units function through a",
  "=0 .(3)": "Through this approach, H changes across different intents, where() represents a feed-forward network that yields activation weights.These weights are then combined through an outer product opera-tion and integrated into the subsequent network layers to enhancerelevance modeling.Next, we use a Multilayer Perception (MLP) to be the predictionlayer, which can be formed as,",
  "where W, are the trainable weight matrix and the bias matrix. Theoutput of the MLP is the predicted intent distribution": "3.2.4Event-reconstruction auxiliary loss. To improve the modelsproficiency in accurately capturing event-to-intent transition pat-terns, we employ a masked event reconstruction loss , whichreconstructs the original event sequences based on the given par-tially observed signals, as shown in (b). Specifically, werandomly mask the event embedding , and input them into theGPT2 model according to 2. Next, we employ an MLP to be theevent reconstruction layer to reconstruct the event sequence. Thecross-entropy loss function is then used to assist model training.The loss function in population-level tuning can be formed as,",
  "where denotes the original event sequence, denotes the pre-dicted event sequence, and denotes the ground truth of input": "3.2.5Model distilling. To meet the requirement of deployment, weutilize the model distilling method, which is to train a smaller model(called the student model) to imitate the behavior of a larger model( called the teacher model). The details of the model distillationprocess are shown in Appendix A.To guide the training of the student model, we design the softloss for the soft targets, which is the Kullback-Leibler Divergencebetween the logit output of the teacher and the student network.Meanwhile, we also utilize the cross-entropy loss to ensure thestudent model learns the correct classifications. The loss functioncan be formed as follows,",
  "L = L + (1 ) L(7)": "where M, M denotes the logits output of the teacher and studentmodel respectively, and is a hyper-parameter, which means thetemperature to smooth the probability distribution, while is ahyper-parameter to balance the importance of two loss functions.By doing so, the student model learns both the fine-grained informa-tion from the teacher models output and the essential classificationability, resulting in a smaller, more efficient model that retains muchof the teacher models predictive power. Subsequently, the studentmodel is deployed on the device side.",
  ": Finetune the lightweight predictor": "individual intent distribution (as shown in our previous data anal-ysis in ), leading to a bias, particularly for some long-tailintents during the population tuning stage. Therefore we first de-sign an adaptive unlearning strategy to help the model disregardthese biases. After that, we can finetune a personalized model thatis both accurate and efficient. 3.3.1Adaptive unlearning on biased intents. Unlearning involvesintentionally disregarding or ignoring specific data or patterns in atrained neural network . Initially, we decide whether each usersintent should be forgotten or retained. We propose two methodsto identify the forgotten intents. First, we analyze the intent dis-tribution of the global predictor output at the population level. Ifthe proportion of an intent () is less than the threshold , it ispart of the static forgotten set ,",
  "L = L (M, ) L (M , ),(11)": "where M signifies the models output for the intent category des-ignated for forgetting, and is a hyper-parameter to balance thetrade-off between forgetting and retaining. Intuitively, during theunlearning process, the model is learned to minimize the loss be-tween the output from the updated model and the original model onthe intent to retain while maximizing the loss between the outputfrom them on the data to forget. 3.3.2Finetuning for personalized model. Finally, we utilize person-alized individual data to fine-tune the model for each user. Thisfine-tuning process enables the model to transition from capturingcommon behavioral patterns to reflecting a users unique prefer-ences, thereby enhancing the accuracy of the models predictions.We also use cross-entropy loss to guide model tuning.",
  "Datasets. We evaluate the performance of our model on twolarge-scale real-world activity datasets": "Honor Dataset. The Honor Dataset is sampled from the usagelog of the mobile phones. When a user uses mobile phones,various types of logs are generated, desensitized and reported(with user consent). We selected 114 types of events that arecommonly monitored in most mobile applications and classifiedthem into 18 intents, which cover the aspects of news, study,work, entertainment, sports, etc. We sampled two datasets be-tween June 1st and August 22nd, 2023 (the first) and August22nd and September 10th, 2023 (the second) which in totalcontain 4,500 and 5,000 anonymous users. Mobile Dataset. The Mobile Dataset consists of anonymoususer trajectory data collected by a major mobile network oper-ator in China in October. The dataset comprises 6,000 users, ofwhich, at the population level, we select 4,000 users for training,and at the individual level, we select the remaining users. Inthis dataset, we use the location category as the activity andintent type.",
  "ours0.53740.55990.46930.48400.73290.76260.87150.90020.84490.88020.95060.9537Improv.8.63%6.79%37.71%26.01%2.98%3.46%11.00%7.67%28.38%24.23%11.29%3.83%": "4.1.2Metrics. To assess model performance, we employ five widelyused metrics: weighted precision (), weighted recall (),macro precision (), macro recall (), and NDCG(N). Weightedmetrics and NDCG gauge classification accuracy and ranking qual-ity, respectively, while macro metrics evaluate the average predic-tion accuracy for each intent, indicating the models predictivequality across intents. A smaller gap between weighted and macrometrics implies consistent prediction accuracy across intents, re-flecting fairness. Conversely, a large gap suggests inadequate mod-eling of long-tail intents, leading to suboptimal outcomes. Refer toAppendix D for metric calculations. 4.1.3Baselines. We elaborately select the following nine repre-sentatives to be compared with our proposed algorithms, whichcover the meta-learning methods for personalized recommenda-tions (CLOVER , MetaBert4Rec ), LLM-based recommenda-tions (P5 , InstructRec , LSAT , One fits All (OFA) ,TallRec ) and device-cloud collaboration recommendations (EO-DRec , MPDA ). We provide the details of baselines inAppendix C. 4.1.4Implementation Details. Our model employs the Adam opti-mizer with a learning rate of 0.01 across two tuning phases. Andwe set the input length as 30. During the population-level tun-ing stage, we utilize the GPT2 small version for the transformerblocks, which features a 12-layer transformer architecture and a768-dimensional feature space, while on the individual-level tuningstage, we choose a transformer decoder with 4-layer and a 768-dimensional feature space to meet the deployment requirement. Asfor hyper-parameters , , and , we set 0.5, 1, and 1 respectively.Details of hyperparameters are shown in Appendix B. In the honordataset, one week is allocated for training, one day for validation,and four days for testing. In the mobile dataset, 60% of the data isused for training, with 10% for validation and 30% for testing. Thecode is available at",
  "Overall Performance": "In , we display the overall results of our model, meta-learningmethods (CLOVER, MetaBert4Rec), LLM-based recommendations(P5, InstructRec, LSAT, OFA, TallRec) and device-cloud collabora-tion recommendations (EODRec, MPDA) to predict the next userintention in two datasets. We list three metrics of all methods. Fromthe result, we have the following findings: Our framework steadily achieves the best performance.Our model gets superior results on both datasets and performsbetter than other compared algorithms. For example, the macrometrics improvement of our model is around 24% to 37% com-pared with the second-best performance model (MPDA). The improvement of our model is about 3% to 11%. Our model has the smallest difference between weightedmetrics and macro metrics. Weighted metrics and macro met-rics count the global accuracy and the average accuracy of eachintent respectively. A smaller difference suggests comparableprediction accuracy across different intents, indicating fairnessamong the intents. Our model utilizes adaptive unlearning toeffectively correct the long-tail intent learning bias caused bythe model in population-level tuning, and improve the accuracy. The method of LLM-based model with device-cloud col-laboration is necessary for user behavior modeling. MPDAutilizes the LLM-based model with the device-cloud collabo-ration method resulting in the best performance within thebaseline. However, MPDA fails to fully exploit the benefits ofdiverse user data available on the cloud side. In contrast, our pro-posed PITuning framework captures generalized user behaviorpatterns, leading to superior performance.",
  ": Comparing performance without pretrained LM": "The results of the ablation study are presented in . Weobserved that the absence of the Intention Attention Network (IAT)hindered the models ability to appropriately assign weights to eachintent, consequently impacting both and . Addition-ally, the event reconstruction loss played a pivotal role in guidingthe transformer block towards more accurate modelling of usershistorical event sequences, thereby enhancing the models perfor-mance. Furthermore, we noticed that the omission of the adaptiveunlearning compromised the models capacity to effectively handlelong-tail intents, resulting in a significant reduction in byapproximately 37%.",
  "Analysis of Population-level Tuning": "Performance improvement brought by pretrained LM.We assessed how LLM contributes to modeling population-levelcommon behavior patterns by replacing the LLM with transformerencoders of two sizes. One matches the size of GPT2 (Transformer-L), while the other matches the size of the lightweight predictor wedistilled (Transformer-S), allowing them to train from scratch. compares the prediction accuracy and loss among themodels. Our analysis underscores that without leveraging the PTM,the model lacked foundational common sense and rule-based guid-ance, leading to a significant decline in its ability to capture commonbehavioral patterns and accuracy. Additionally, the Transformer-S,with fewer parameters, encountered challenges in modeling com-plex user behaviors, resulting in inferior performance. Moreover,with the guidance of LLM, the model demonstrated faster conver-gence. Effectiveness of extracting common behavioral pattern.To highlight the effectiveness of IAT in capturing intent-awaretransition patterns in user event sequences, we visualize the at-tention map between intents and historical sequences. presents the resulting attention maps, highlighting the IATs abilityto discern each intents preference for historical sequence length. historical event sequence",
  ": Comparison of intent distribution generated byPITuning and OFA after population-level tuning": "Analysis of the attention map reveals that certain intents, such asshort video, game, and photo intents, predominantly rely on short-term historical sequences. Conversely, intents like checking theweather, taking a taxi, and exercising necessitate long-term histori-cal sequences. Additionally, some intents rely on both short-termand long-term historical sequences, such as checking the weather,music, and audiobook intents. These insights uncover users dailybehavior patterns, enabling researchers to construct more nuancedhistorical sequences and features to enhance accuracy.To showcase the effectiveness of the event reconstruction loss,we compare the difference between the intent distribution outputby our model and OFA during the population-level tuning stage. presents the results, demonstrating that our model couldwell model transitions from events to intents with the help of theevent reconstruction loss. The closer the output intent distributionis to the real distribution, the more conducive it is to capture thecommon behavior patterns in the population-level tuning.",
  "Analysis of Individual-level Tuning": "Choice of device model.To evaluate the efficiency of the lightweight predictor obtainedthrough model distillation, we compared it with the tree modelLightGBM , and two variants of the original population predic-tor at the cloud side, i.e., full-parameter tuned population predictor(FP), and partial parameter tuned population predictor (PP). Ad-ditional details about the tree model can be found in Appendix E.PP is inspired by the cross-domain adaptation techniques used inOFA , which argues that self-attention layers and feed-forwardneural networks encapsulate most learned knowledge and can befrozen during the finetuning process.",
  ": effectiveness of adaptive unlearning strategy com-pared with other class imbalance handling methods": "The device model results, shown in , indicate that thefull-parameter tuning method achieves higher performance. How-ever, its large parameter size makes it challenging to implement onthe device side. The partial parameter method struggles to transferindividual preferences from population-level common preferences,resulting in lower performance. Although LGBM has a smaller pa-rameter count, its stability is inferior, leading to decreased accuracy. Effectiveness of adaptive unlearning.To demonstrate the effectiveness of adaptive unlearning in en-hancing the accuracy of long-tail intents, we compared it withoversampling methods and focal loss . We focused on the threeintents with the smallest proportions in the datasets and evalu-ated recall, which effectively reflects the models performance inidentifying long-tail intents.The results, shown in , indicate although focal loss andoversampling methods show some improvement, their and still differ, indicating they fail to address the deviation causedby the disparity in intention distribution between population andindividual levels. Through adaptive unlearning, the model graduallyovercomes biases towards these long-tail intents in population-level tuning, resulting in significant improvements in precision andrecall.",
  "Practicability Study": "Sensitivity of individual data scale in individual-level tun-ing.In the individual-level tuning stage, particularly on the deviceside, there are limitations in storage and computing resources. Toinvestigate the impact of data size, we conducted experiments byvarying the data size in individual-level tuning and compared itwith the second-best model (MPDA).The results, shown in , indicate that increasing thedataset size leads to marginal performance enhancements acrossall models. This trend highlights our models capability to capture 03D5D1W2W3W",
  ": Influence of event seq. length on performance": "user behavior preferences. However, larger datasets significantly in-crease demands for computing power and storage resources. There-fore, to strike a balance between model effectiveness and computa-tional efficiency, we selected a one-week dataset size. sensitivity of event sequence length.To investigate the influence of the event sequence length, weconduct experiments by changing the input length of the historicalseries, and compared with the second-best model (MPDA). Theresults, illustrated in , show a slight improvement in per-formance across all models with increasing input length. This trendhighlights our models ability to capture long-term dependencies.However, longer input lengths substantially increase computationaldemands. Thus, to balance model performance and computationalefficiency, we selected an input length of 30.",
  "RELATED WORKS5.1User Intent Prediction": "User intent prediction model, a recommendation system, emphasizemodeling user-event interaction sequences. Recent works integrate transformers into various models. Yang et al. intro-duce intent-aware ranking with transformers, incorporating intent-aware utterance attention. Meanwhile, Wang et al. propose amasked-field framework for distinct representations per intent.Recent advancements focus on leveraging Graph Neu-ral Networks (GNNs) to model intent transitions and spatio-temporal features. Li et al. introduce AutoIntent, featuringdisentangled intent encoders and intent discovery decoders. Theyconstruct dual hyper-graphs to capture relationships and intentfeatures. Ping et al. propose an intent detection and predictionsystem combining human expert knowledge and consumption in-formation to capture user preferences and context. With the riseof large language models (LLM), researchers have begun to useLLM agents to simulate behavioral intents . Shao et al.",
  "A Population-to-individual Tuning Framework for Adapting Pretrained LM to On-device User Intent PredictionKDD 24, August 2529, 2024, Barcelona, Spain": "develop an LLM workflow named Chain-of-Planned Behaviour formobility behavior generation, which reflects the important spatial-temporal dynamics of human activities. To solve the problem ofinsufficient user data, Yuan et al. motivated Maslows needtheory, propose a knowledge-driven simulation framework basedon generative adversarial imitation learning.However, the above methods only cover some scenes in daily liferesulting in the user behaviors being discontinuous and incomplete.Therefore, they can not deeply explore the users common patternsand individual differences behind the user behavior sequences.",
  "On-device Recommendation Model": "Device-side recommender systems diverge from cloud-side recom-mendations by transferring model processing from the cloud to thedevice. This paradigm encompasses three primary approaches: (1)Device-side deployment, where models are trained in the cloud anddeployed directly onto devices . (2) Device-side learning, wheremodels are trained directly on devices, often employing collabora-tive learning . (3) Device-cloud collaboration, integrating deviceswith cloud-based models to enhance performance .Yan et al. propose MPDA, which augments the users local databy retrieving similar data from the clouds pool. Ding et al. intro-duce a collaborative learning framework that vertically divides thebase model into two submodels: a larger one for cloud-side samplesand a smaller one for device-side data, incorporating the output ofthe larger model.Recent studies integrate meta-learning into recommendations tolearn shared global meta-parameters to quickly adapt to individualuser-specific parameters. We et al. propose CLOVER, acomprehensive fair meta-learning framework, which introducesa multi-task adversarial learning scheme to satisfy fairness. Kimet al. propose a recommendation framework based on gradient-based meta-learning that captures the imbalanced rating distri-bution of each user and computes adaptive loss for user-specificlearning.However, the above methods do not consider the difference in thedistribution of cloud data and device data, which is not conduciveto personalized learning.",
  "Cross-domain Fine-tuning of Pretrained LM": "This year we have witnessed rapid advancements in NLP foundationmodels, with increasing applications of LLMs in recommendation.Two main paradigms emerge: (1) Prompt tuning, where contextualtokens guide the models response . Geng et al. propose P5first employ LLMs in a unified text-to-text approach. (2) Instructiontuning involves detailed text instructions to enhance zero-shotmodel performance . Bao et al. propose TALLRec, align LLMswith recommendations through data tuning, Wei et al. presentLLMRec, enhances systems via LLM-based graph augmentation.Moreover, the transformer, a fundamental component of LLM,tokenizes inputs into embeddings, endowing it with universal rep-resentation for cross-domain transfer. Lu et al. illustrates thatPLM enhances performance and computational efficiency in non-language downstream tasks. Tian et al. offers a unified frame-work for diverse time series tasks, showing that PLM yields compa-rable performance across main time series analysis tasks. Jin et al. introduce Time-LLM, a reprogramming framework for generaltime series forecasting, aligning time series with text prototypes toreconcile two modalities. Liu et al. propose UniTime for mul-tivariate time series forecasting, employing domain instructionsand a language-TS transformer to achieve zero-shot transferabilitythrough modality alignment.LLMs harness a rich dataset of human behaviors during training,encompassing prevalent patterns, common sense, and underlyingrules, yet the application of LLMs in simulating human behaviorand user intent prediction remains an unexplored territory.",
  "CONCLUSION": "Our research adapting PLMs into the human behavioral domainfor on-device user intent prediction. We propose a population-to-individual tuning framework, which contains two main stages. Inthe population-level tuning stage, we leverage a PLM to capturethe population-level common behavior patterns with the eventreconstruction loss to enhance the event-to-intent transition patternand obtain a lightweight predictor by model distillation. In theindividual-level tuning framework, we utilize adaptive unlearningto correct the bias in long-tail intents due to the inconsistencybetween the intent distribution on population-level and individual-level. Finally, we use the individual user data to finetune and derivea personalized intent prediction model.In future work, we aim to extend the number of intents anduse disentanglement methods to implement debiased learningto solve the problem of insufficient learning of long-tail intents.Besides, we aim to consider the semantics to enhance behaviorunderstanding and prediction by urban knowledge graph . This research has been supported in part by BNRist, NationalKey Research and Development Program of China under Grant2022YFB3104702; in part by the National Natural Science Founda-tion of China under Grant 62272262 and Grant U23B2030; in partby the joint project of Honor Inc. & Tsinghua University. Sarfraz Ahmed, M Nazmul Huda, Sujan Rajbhandari, Chitta Saha, Mark Elshaw,and Stratis Kanarachos. 2019. Pedestrian and cyclist detection and intent estima-tion for autonomous vehicles: A survey. Applied Sciences 9, 11 (2019), 2335. Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He.2023. TALLRec: An Effective and Efficient Tuning Framework to Align LargeLanguage Model with Recommendation (RecSys 23). Association for ComputingMachinery, New York, NY, USA, 10071014. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shot learners. Advances in neuralinformation processing systems 33 (2020), 18771901.",
  "Jiaao Chen and Diyi Yang. 2023. Unlearn What You Want to Forget: EfficientUnlearning for LLMs. ArXiv abs/2310.20150 (2023)": "Yucheng Ding, Chaoyue Niu, Fan Wu, Shaojie Tang, Chengfei Lyu, and GuihaiChen. 2023. DC-CCL: Device-Cloud Collaborative Controlled Learning for LargeVision Models. arXiv preprint arXiv:2303.10361 (2023). Chen Gao, Xiaochong Lan, Nian Li, Yuan Yuan, Jingtao Ding, Zhilun Zhou, FengliXu, and Yong Li. 2023. Large language models empowered agent-based modelingand simulation: A survey and perspectives. arXiv preprint arXiv:2312.11970(2023).",
  "Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2014. Distilling the knowledgein a neural network. In Neural Information Processing Systems 2014 Workshop onDeep Learning and Representation Learning": "Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi,Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, et al. 2023. Time-llm:Time series forecasting by reprogramming large language models. arXiv preprintarXiv:2310.01728 (2023). Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen, Weidong Ma,Qiwei Ye, and Tie-Yan Liu. 2017. Lightgbm: A highly efficient gradient boostingdecision tree. Advances in neural information processing systems 30 (2017). Minchang Kim, Yongjin Yang, Jung Hyun Ryu, and Taesup Kim. 2023. Meta-Learning with Adaptive Weighted Loss for Imbalanced Cold-Start Recommen-dation (CIKM 23). Association for Computing Machinery, New York, NY, USA,10771086.",
  "Brian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale forparameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691 (2021)": "Jiayu Li, Peijie Sun, Zhefan Wang, Weizhi Ma, Yangkun Li, Min Zhang, ZhoutianFeng, and Daiyue Xue. 2023.Intent-aware Ranking Ensemble for Person-alized Recommendation. In Proceedings of the 46th International ACM SIGIRConference on Research and Development in Information Retrieval (<conf-loc>,<city>Taipei</city>, <country>Taiwan</country>, </conf-loc>) (SIGIR 23). As-sociation for Computing Machinery, New York, NY, USA, 10041013.",
  "Tong Li, Yali Fan, Yong Li, Sasu Tarkoma, and Pan Hui. 2021. Understanding thelong-term evolution of mobile app usage. IEEE Transactions on Mobile Computing22, 2 (2021), 12131230": "Tong Li, Tong Xia, Huandong Wang, Zhen Tu, Sasu Tarkoma, Zhu Han, and PanHui. 2022. Smartphone app usage analysis: datasets, methods, and applications.IEEE Communications Surveys & Tutorials 24, 2 (2022), 937966. Yinfeng Li, Chen Gao, Xiaoyi Du, Huazhou Wei, Hengliang Luo, Depeng Jin, andYong Li. 2022. Automatically Discovering User Consumption Intents in Meituan.In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discoveryand Data Mining (Washington DC, USA) (KDD 22). Association for ComputingMachinery, New York, NY, USA, 32593269.",
  "Yu Liu, Zhilun Zhou, Yong Li, and Depeng Jin. 2023. Urban knowledge graphaided mobile user profiling. ACM Transactions on Knowledge Discovery from Data18, 1 (2023), 130": "Kevin Lu, Aditya Grover, Pieter Abbeel, and Igor Mordatch. 2022. Frozen Pre-trained Transformers as Universal Computation Engines. Proceedings of theAAAI Conference on Artificial Intelligence 36, 7 (Jun. 2022), 76287636. Zheqi Lv, Wenqiao Zhang, Shengyu Zhang, Kun Kuang, Feng Wang, YongweiWang, Zhengyu Chen, Tao Shen, Hongxia Yang, Beng Chin Ooi, et al. 2023. DUET:A Tuning-Free Device-Cloud Collaborative Parameters Generation Frameworkfor Efficient Device Model Generalization. In Proceedings of the ACM Web Confer-ence 2023. 30773085. Xingyu Pan, Yushuo Chen, Changxin Tian, Zihan Lin, Jinpeng Wang, He Hu,and Wayne Xin Zhao. 2022.Multimodal Meta-Learning for Cold-Start Se-quential Recommendation. In Proceedings of the 31st ACM International Con-ference on Information & Knowledge Management (Atlanta, GA, USA) (CIKM22). Association for Computing Machinery, New York, NY, USA, 34213430. Yukun Ping, Chen Gao, Taichi Liu, Xiaoyi Du, Hengliang Luo, Depeng Jin, andYong Li. 2021. User Consumption Intention Prediction in Meituan. In Proceedingsof the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining(Virtual Event, Singapore) (KDD 21). Association for Computing Machinery,",
  "New York, NY, USA, 34723482": "Chaoyi Pu, Zhiang Wu, Hui Chen, Kai Xu, and Jie Cao. 2018. A SequentialRecommendation for Mobile Apps: What Will User Click Next App?. In 2018IEEE International Conference on Web Services (ICWS). 243248. Yuhan Quan, Jingtao Ding, Chen Gao, Nian Li, Lingling Yi, Depeng Jin, and YongLi. 2023. Alleviating Video-length Effect for Micro-video Recommendation. ACMTransactions on Information Systems 42, 2 (2023), 124.",
  "Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and GabrieleMonfardini. 2009. The Graph Neural Network Model. IEEE Transactions on NeuralNetworks 20, 1 (2009), 6180": "Chenyang Shao, Fengli Xu, Bingbing Fan, Jingtao Ding, Yuan Yuan, Meng Wang,and Yong Li. 2024. Beyond Imitation: Generating Human Mobility from Context-aware Reasoning with Large Language Models. arXiv preprint arXiv:2402.09836(2024). Zezhi Shao, Zhao Zhang, Fei Wang, and Yongjun Xu. 2022. Pre-training EnhancedSpatial-temporal Graph Neural Network for Multivariate Time Series Forecasting.In KDD 22: The 28th ACM SIGKDD Conference on Knowledge Discovery and DataMining, Washington, DC, USA, August 14 - 18, 2022. ACM, 15671577.",
  "Neha Sharma, Chhavi Dhiman, and S Indu. 2022. Pedestrian intention predictionfor autonomous vehicles: A comprehensive survey. Neurocomputing (2022)": "Tianhao Shi, Yang Zhang, Zhijian Xu, Chong Chen, Fuli Feng, Xiangnan He, andQi Tian. 2023. Preliminary Study on Incremental Learning for Large LanguageModel-based Recommender Systems. ArXiv abs/2312.15599 (2023). Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep-resentations from transformer. In Proceedings of the 28th ACM internationalconference on information and knowledge management. 14411450. Jiaxi Tang and Ke Wang. 2018. Personalized Top-N Sequential Recommendationvia Convolutional Sequence Embedding. In Proceedings of the Eleventh ACMInternational Conference on Web Search and Data Mining (Marina Del Rey, CA,USA) (WSDM 18). Association for Computing Machinery, New York, NY, USA,565573.",
  "Jianling Wang, Kaize Ding, Ziwei Zhu, and James Caverlee. 2021. Session-basedRecommendation with Hypergraph Attention Networks. ArXiv abs/2112.14266(2021)": "Peng Wang, Jiang Xu, Chunyi Liu, Hao Feng, Zang Li, and Jieping Ye. 2020.Masked-field Pre-training for User Intent Prediction. In Proceedings of the 29thACM International Conference on Information & Knowledge Management (VirtualEvent, Ireland) (CIKM 20). Association for Computing Machinery, New York, NY,USA, 27892796. Shoujin Wang, Liang Hu, Yan Wang, Quan Z. Sheng, Mehmet Orgun, and Long-bing Cao. 2019. Modeling multi-purpose sessions for next-item recommendationsvia mixture-channel purpose routing networks. In Proceedings of the 28th Interna-tional Joint Conference on Artificial Intelligence (Macao, China) (IJCAI19). AAAIPress, 37713777. Tianxin Wei and Jingrui He. 2022.Comprehensive Fair Meta-learned Rec-ommender System. In Proceedings of the 28th ACM SIGKDD Conference onKnowledge Discovery and Data Mining (Washington DC, USA) (KDD 22). As-sociation for Computing Machinery, New York, NY, USA, 19891999. Wei Wei, Xubin Ren, Jiabin Tang, Qinyong Wang, Lixin Su, Suqi Cheng, JunfengWang, Dawei Yin, and Chao Huang. 2023. Llmrec: Large language models withgraph augmentation for recommendation. arXiv preprint arXiv:2311.00423 (2023). Xin Xia, Junliang Yu, Qinyong Wang, Chaoqun Yang, Nguyen Quoc Viet Hung,and Hongzhi Yin. 2023. Efficient On-Device Session-Based Recommendation.ACM Trans. Inf. Syst. 41, 4, Article 102 (mar 2023), 24 pages. Yikai Yan, Chaoyue Niu, Renjie Gu, Fan Wu, Shaojie Tang, Lifeng Hua, ChengfeiLyu, and Guihai Chen. 2022. On-Device Learning for Model Personalizationwith Large-Scale Cloud-Coordinated Domain Adaption. In Proceedings of the 28thACM SIGKDD Conference on Knowledge Discovery and Data Mining. 21802190.",
  "layer of transformer block4dimension of transformer block7681": "Liu Yang, Minghui Qiu, Chen Qu, Cen Chen, Jiafeng Guo, Yongfeng Zhang,W. Bruce Croft, and Haiqing Chen. 2020. IART: Intent-aware Response Rankingwith Transformers in Information-seeking Conversation Systems. In Proceed-ings of The Web Conference 2020 (Taipei, Taiwan) (WWW 20). Association forComputing Machinery, New York, NY, USA, 25922598. Jiangchao Yao, Feng Wang, Kunyang Jia, Bo Han, Jingren Zhou, and Hongxia Yang.2021. Device-cloud collaborative learning for recommendation. In Proceedingsof the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining.38653874.",
  "Yuan Yuan, Huandong Wang, Jingtao Ding, Depeng Jin, and Yong Li. 2023. Learn-ing to simulate daily activities via modeling dynamic human needs. In Proceedingsof the ACM Web Conference 2023. 906916": "Junjie Zhang, Ruobing Xie, Yupeng Hou, Wayne Xin Zhao, Leyu Lin, and Jirong Wen. 2023. Recommendation as Instruction Following: A Large LanguageModel Empowered Recommendation Approach. ArXiv abs/2305.07001 (2023). Ruiqi Zheng, Liang Qu, Tong Chen, Lizhen Cui, Yuhui Shi, and Hongzhi Yin.2024. Decentralized Collaborative Learning with Adaptive Reference Data forOn-Device POI Recommendation. arXiv preprint arXiv:2401.13448 (2024).",
  "ADETAILS OF MODLE DISTILLATION": "In the distillation process, the teacher model produces soft targets,essentially probability distributions across intents. The studentmodel is then trained to mimic these soft targets, rather than theactual outputs of the teacher model. This allows the student modelto learn from the teacher models knowledge without needing toreplicate the same level of computational complexity . shows the specific process of the model distilling.",
  "TP + FN(15)": "Where || represents the total number of classes, True Positives() denotes the number of samples correctly classified as class ,False Positives () represents the number of samples incorrectlyclassified as class , and False Negatives () stands for the num-ber of samples incorrectly classified as other classes instead of class. And Precision and Recall respectively refer to the precisionand recall of class .The formula for @ :",
  "objectivemulticlassboostinggbdtnum class18num iterations2000num leaves32max depth-1min data in leaf20feature fraction1early stopping round75_10_20random state42": "Please note that if the size of the dataset is less than 200, we willreduce the complexity of LightGBM by setting max depth=3, numleaves=3, _1=1, _2=1.Our feature Set is shown below:(1) Output probabilities of all categories from GPT-2.(2) Position features (whether in the top 10 frequent locations).(3) Current hour, current day of the week, current timestamp,and indicators for morning/afternoon/evening and week-day/weekend. (4) For each category (illustrated by event ), time difference 0between the current time and the time of the last occurrenceof event , time difference 1 between the time of the lastoccurrence of event and the time of the second-to-lastoccurrence of event . Given = (,,,), suppose event occurred times before the current event . The time of the occurrence of event is denoted as . The explanationof the mathematical formula for the time difference is asfollows0 = (17)1 = (1)(18)"
}