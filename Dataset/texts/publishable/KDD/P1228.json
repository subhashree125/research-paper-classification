{
  "ABSTRACT": "Transformer-based language models have achieved impressive suc-cess in various natural language processing tasks due to their abilityto capture complex dependencies and contextual information usingself-attention mechanisms. However, they are not without limita-tions. These limitations include hallucinations, where they produceincorrect outputs with high confidence, and alignment issues, wherethey generate unhelpful and unsafe outputs for human users. Theselimitations stem from the absence of implicit and missing contextin the data alone. To address this, researchers have explored aug-menting these models with external knowledge from knowledgegraphs to provide the necessary additional context. However, thead-hoc nature of existing methods makes it difficult to properlyanalyze the effects of knowledge infusion on the many movingparts or components of a transformer. This paper introduces a sys-tematic method for infusing knowledge into different componentsof a transformer-based model. A modular framework is proposedto identify specific components within the transformer architec-ture, such as the self-attention mechanism, encoder layers, or theinput embedding layer, where knowledge infusion can be applied.Additionally, extensive experiments are conducted on the GeneralLanguage Understanding Evaluation (GLUE) benchmark tasks, andthe findings are reported. This systematic approach aims to facili-tate more principled approaches to incorporating knowledge intolanguage model architectures.",
  "INTRODUCTION": "Language modeling has witnessed significant advancements withthe introduction of self-attention-based transformer architectures(e.g., GPT-3, ChatGPT, PaLM, etc.). These models have achievedremarkable success in a wide range of natural language process-ing tasks, demonstrating their ability to generate coherent andcontextually relevant text. By utilizing self-attention mechanisms,transformers excel at capturing long-range dependencies and estab-lishing meaningful relationships between words, enabling them togenerate high-quality, context-aware text. However, despite theirsuccesses, self-attention-based transformer models have limitationswhen it comes to capturing all the necessary context solely from the available data. Language models often struggle with comprehend-ing missing or implicit information, particularly in scenarios wherethe training data is incomplete or lack the desired context. Thislimitation can lead to generated text that is plausible but semanti-cally incorrect or inconsistent, diminishing the models ability tofully understand and generate language with nuanced meaning.To address these limitations, incorporating external knowledge intolanguage models can provide the missing and implicit context re-quired for accurate language generation. External knowledge, suchas factual information, world knowledge, or domain-specific exper-tise, can supplement the training data by offering additional contextthat may not be explicitly present in the data alone. By integratingexternal knowledge, language models can enhance their under-standing of complex concepts, disambiguate ambiguous statements,and generate more coherent and contextually accurate text.However, the existing methods used to incorporate externalknowledge into language models often lack a systematic and well-defined approach. These methods seem rather ad hoc, as they intro-duce knowledge at various components of the transformer architec-ture based mainly on empirical justifications related to improvedperformance in downstream tasks. Transformers comprise severalinterconnected components, including input embedding matrices,encoder layers, and self-attention operations. One concern is thataugmenting knowledge in an ad hoc manner may lead to the ex-ploitation of statistical artifacts by the numerous moving parts ofthe transformer. For instance, it could involve overfitting by uti-lizing additional parameters provided by the knowledge or fittingto task-specific hidden or spurious patterns to achieve high down-stream performance scores. Consequently, it remains unclear, basedsolely on performance metrics, to what extent such augmentationtruly enhances the language comprehension and understanding ofthe model.In light of these limitations, we propose a systematic approachto infusing knowledge in language models that adopts differentstrategies depending on the specific transformer component. Ini-tially, we categorize the architectural elements of a transformer intotwo groups: (i) inductive biases, such as the self-attention matrices,and (ii) latent representations, including the input embeddings andthe intermediate representations between encoder layers (illustrates this categorization). Subsequently, we introduce threedistinct categories of knowledge infusion: (i) shallow knowledge",
  "Kaushik Roy, Yuxin Zi, Vignesh Narayanan, Manas Gaur, and Amit Sheth": "infusion, which involves incorporating knowledge at the latent rep-resentations of the first transformer block; (ii) semi-deep knowledgeinfusion, where knowledge is also integrated at the self-attentionmatrix (inductive bias) of the first transformer block, and (iii) deepknowledge infusion, which interleaves knowledge incorporationat the latent representations and self-attention matrices (inductivebiases) of the various transformer blocks. In essence, these threemethods aim to infuse knowledge at either the level of inductivebiases, latent representations, or both. To evaluate the effectivenessof the three categories of knowledge infusion, we conduct exten-sive experimentation and ablation studies on various tasks fromthe General Language Understanding Evaluation (GLUE) bench-mark, reporting our findings. As mentioned earlier, due to thepotential exploitation of statistical artifacts by knowledge infusionmethods, traditional downstream task performance metrics can bean ineffective measure of knowledge infusion. Therefore, we alsointroduce new evaluation metrics for a more robust measurementof the effectiveness of knowledge infusion (see .2). Our re-sults indicate that deep knowledge infusion outperforms the othertwo categories of knowledge infusion using both traditional metricsof accuracy and F1-score, as well as the newly introduced metrics.",
  "KNOWLEDGE-INFUSED SELF-ATTENTIONTRANSFORMERS(a) Knowledge Graph Compression forKnowledge Infusion": "Since a transformer architecture consists of two distinct types ofcomponents, namely (i) inductive biases represented as matricesand (ii) latent representations represented as vectors (as depictedin ), the challenge lies in compressing external knowledgefrom knowledge graphs into one of these mathematical represen-tations. This compression process enables the infusion of externalknowledge into the transformer-based models. For this, we first obtain knowledge graph node embeddings (vectors) using a graphencoder network (e.g., numberbatch embeddings obtained by com-pression of the knowledge graph ConceptNet) and then computepair-wise inner products between the node embeddings to obtaina graph node embedding-based correlation matrix. (a)illustrates this knowledge compression process.",
  "(b) Defining Knowledge Infusion Operations": "Having obtained the knowledge graph representation in the formof matrices and vectors, we proceed to define two distinct infusionoperations. The first operation involves infusing knowledge at thelatent representations of a transformer block, which is achievedby adding the graph node embedding vectors to the existing latentrepresentations within the transformer block. The second operationpertains to infusing knowledge at the inductive biases of a trans-former block. In this case, the infusion entails adding the graph nodeembedding-based correlation matrix to the inductive bias, whichcorresponds to the self-attention matrix of the transformer block. (b) provides a visual depiction of these two operations.",
  "(c) Shallow Knowledge Infusion": "Shallow Infusion involves the operation of infusing the knowledgeat the latent representations of just the first transformer block of atransformer-based architecture. It is important to note that a singleblock usually consists of multiple heads, each associated with itsown set of latent representations. In such cases, the knowledgeinfusion operation is performed on all the latent representationscorresponding to the multiple heads. (c) visually representsthe shallow infusion approach.",
  "(d) Semi-deep Knowledge Infusion": "Semi-deep Infusion involves both the operations of infusing theknowledge at the latent representations and the inductive biasesof just the first transformer block. Similar to the shallow infusionmethod, if there are multiple heads present, the infusion opera-tions are performed across all heads. (d) provides a visualillustration of the semi-deep infusion approach.",
  "Operations": ": (a) Knowledge compression - Compressing the information in the knowledge graph into graph node embeddings(vectors) and graph node embedding-based correlations (matrices) for infusion in transformer architectures, namely at thelatent representations of the transformer (vectors), or the inductive biases (self-attention matrices). (b) Knowledge infusionoperations - Once compressed, we define the operation of knowledge infusion using vectors and matrices as summing theinductive biases (matrices) with the graph node embedding-based correlations and summing the latent representations (vectors)with the graph node embeddings. (c) Shallow infusion - Performing the knowledge infusion operation of adding the graph nodeembeddings to the latent representations of the first transformer block. (d) Semi-deep infusion - Performing the knowledgeinfusion operation of adding the graph node embedding-based correlation matrix to the inductive bias matrix of the firsttransformer block. (e) Deep infusion - Performing both adding the graph node embeddings and graph node embedding-basedcorrelations to the latent representations and inductive biases across all transformer blocks. Natural Language Inference (NLI) tasks. The GLUE tasks MNLI(Multi-genre Natural Language Inference), QNLI (Question An-swering Natural Language Inference), and WNLI (Winograd Natu-ral Language Inference) test NLI capabilities from varying angles.MNLI tests whether the model can appropriately judge if a sentencelogically follows from another, i.e., logical entailment. QNLI testssimilar logical entailment between question and statement pairs -does it make logical sense to ask a follow-up question? WNLI testslogical entailment in the presence of pronouns and the nouns theyreference. Textual Entailment (TE) tasks. The GLUE task RTE (RecognizingTextual Entailment) tests for logical entailment similar to the NLItask MNLI. However, RTE emphasizes on the meaning - given twotext fragments, whether the meaning of one can be entailed (or canbe inferred) from the other.",
  "Evaluation Metrics": "In , we discussed how ad hoc knowledge infusion tech-niques can lead to models exploiting statistical artifacts towardsachieving high downstream task performance. Therefore, to eval-uate the different knowledge infusion methods, in addition to thetraditional performance metrics of accuracy, F1-scores across GLUEtasks, we also devise the following metrics: 3.2.1Combined Graph Encoder and KSAT model Accuracy(CGKA). :This metric evaluates the combined accuracies of twocomponents. Firstly, it measures the accuracy of link predictionby the graph encoder on a separate test set that includes triplesfrom the knowledge graph it encodes. Link prediction is carriedout by summing the subject and predicate vectors and finding theclosest object vector in a (subject, predicate, object) triple (we checkif the similarity is greater than a threshold in our experiments, see",
  "Deep-Infusion80.992.390.9188.5390.4": ": Shows the comparison of accuracy across the different GLUE tasks from for the baseline XLNET model andits variants using the different kinds of knowledge infusion - Shallow, Semi-deep and Deep Infusion. We see that there is steadyimprovement as external knowledge is included at different components, i.e., latent representations and Inductive biases of atransformer-based model. .2). These triples were not used during runtime. Secondly,it calculates the average accuracy of the KSAT model across all theGLUE tasks. The underlying idea is that if we observe high scoreson conventional accuracy and F1-score metrics but low scores onthe CGKA metric, it suggests that the KSAT model has possiblylearned misleading patterns. A low CGKA score indicates a lack ofcapturing knowledge graph information by the graph encoder. 3.2.2Data Efficiency at K (DE@k). : This metric evaluates theperformance of the KSAT model after training it with only k%of the total available training data. The rationale behind this isthat effective knowledge infusion should result in improved datasufficiency. In other words, the additional context provided by high-quality knowledge should compensate for the need for a largevolume of data to achieve good performance.",
  "KNOWLEDGE GRAPHS, GRAPH ENCODERNETWORKS, AND TRANSFORMER MODELSUSED IN EXPERIMENTATION": "We use the knowledge graphs ConceptNet and WorNet in ourexperiments. For the graph encoder network to obtain graph nodeembeddings (see (a)), we use ConceptNet Numberbatchembeddings and ewise embeddings for ConceptNet and WordNet,respectively. We sum the graph node embeddings from bothConceptNet and WordNet for every input token to obtain a singlegraph node embedding per token. For the transformer models usingwhich we test knowledge infusion, we use the language models -BERT, XLNET, RoBERTa, ELECTRA, and Longformer.",
  "EXPERIMENTS5.1Traditional Performance Tests": "For all our experiments, we use the large version of the models. Allexperiments are run on a single A100 GPU. We use the standardconfigurations of the models (e.g., 12 heads per block and =12in BERT) Out of all the transformer-based models we experimentwith from among those listed in , XLNET performs thebest, both as a baseline and when used with various knowledgeinfusion techniques. shows this result.",
  "For the DE@K metric, we want to see if higher performance can beachieved using lesser data. So we plot results averaged across the": "GLUE tasks for each transformer-based model with the differentinfusion techniques using only 50% of the training data, i.e., also want to measure the combined accuracies on link predictionof the embeddings from ConceptNet and WordNet(summed) withthe average performance across the GLUE tasks. The method oflink prediction is as described in .2.1, i.e., to predict a linkbetween a subject and object in a (subject, predicate, object) triple,we check if the cosine similarity between the sum of subject andpredicate vectors, and the object vectors is greater than 0.5 (wetuned this number from the set {0, 0.25, 0.5, 0.75}. shows theresults.",
  "Longformer 78/67/61/79/75/7379/76/7278/76/74": ": Here, we see the performance (accuracy) of differ-ent models with deep-infusion/semi-deep infusion/shallow-infusion using the metrics introduced in . We seethat both metrics improve with the addition of externalknowledge using the infusion methods, with deep infusionperforming the best. Furthermore, we see that the accuracynumbers are already in the 70-80s with just 50% of the datapoints used (this is average accuracy measured across allGLUE tasks)",
  "CONCLUSION AND FUTURE WORK": "This paper introduces a systematic approach to knowledge infusionin transformer-based models. The findings indicate that incorpo-rating external knowledge indeed enhances the performance ofthe models on language understanding tasks. Even more so as theinfusion techniques operate on both the latent representations andinductive biases of the model across all transformer layers. Thisimprovement is observed through the evaluation of both traditionalmetrics and newly introduced evaluation metrics, validating theeffectiveness of knowledge infusion. For future research, we planto explore hybrid knowledge infusion, which involves selectively",
  "Knowledge-Infused Self Attention Transformers": "choosing the blocks where knowledge infusion occurs and deter-mining which knowledge to infuse. This differs from the currentsetup where graph node embeddings from WordNet and Concept-Net are summed. The analysis presented in this paper aims to lay thefoundation for more principled approaches to external knowledge-augmented language models in the future.",
  "This work is built on prior work , and supported by the Na-tional Science Foundation under Grant 2133842, EAGER: Advanc-ing Neuro-symbolic AI with Deep Knowledge-infused Learning\"": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. Language models are few-shot learners. Advances in neural infor-mation processing systems, 33:18771901, 2020. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, GauravMishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebas-tian Gehrmann, et al. Palm: Scaling language modeling with pathways. arXivpreprint arXiv:2204.02311, 2022. Chenguang Zhu, Yichong Xu, Xiang Ren, Bill Yuchen Lin, Meng Jiang, andWenhao Yu. Knowledge-augmented methods for natural language processing.In Proceedings of the Sixteenth ACM International Conference on Web Search andData Mining, pages 12281231, 2023. Xuhui Zhou, Yue Zhang, Leyang Cui, and Dandan Huang. Evaluating common-sense in pre-trained language models. In Proceedings of the AAAI conference onartificial intelligence, volume 34, pages 97339740, 2020.",
  "R Thomas McCoy, Ellie Pavlick, and Tal Linzen. Right for the wrong reasons:Diagnosing syntactic heuristics in natural language inference. arXiv preprintarXiv:1902.01007, 2019": "Emily M Bender and Alexander Koller. Climbing towards nlu: On meaning, form,and understanding in the age of data. In Proceedings of the 58th annual meetingof the association for computational linguistics, pages 51855198, 2020. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, andSamuel R Bowman. Glue: A multi-task benchmark and analysis platform fornatural language understanding. arXiv preprint arXiv:1804.07461, 2018.",
  "Iz Beltagy, Matthew E Peters, and Arman Cohan.Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150, 2020": "Kaushik Roy, Yuxin Zi, Manas Gaur, Jinendra Malekar, Qi Zhang, VigneshNarayanan, and Amit Sheth. Process knowledge-infused learning for clinician-friendly explanations. arXiv preprint arXiv:2306.09824, 2023. Kaushik Roy, Vedant Khandelwal, Raxit Goswami, Nathan Dolbir, JinendraMalekar, and Amit Sheth. Demo alleviate: Demonstrating artificial intelligenceenabled virtual assistance for telehealth: The mental health case. arXiv preprintarXiv:2304.00025, 2023. Kaushik Roy, Usha Lokala, Vedant Khandelwal, and Amit Sheth. \" is depres-sion related to cannabis?\": A knowledge-infused model for entity and relationextraction with limited supervision. arXiv preprint arXiv:2102.01222, 2021.",
  "Kaushik Roy, Qi Zhang, Manas Gaur, and Amit Sheth. Knowledge infused policygradients for adaptive pandemic control. arXiv preprint arXiv:2102.06245, 2021": "Parth Asawa, Manas Gaur, Kaushik Roy, and Amit Sheth. Covid-19 in spain andindia: comparing policy implications by analyzing epidemiological and socialmedia data. arXiv preprint arXiv:2010.14628, 2020. Kaushik Roy, Yuxin Zi, Vignesh Narayanan, Manas Gaur, and Amit Sheth. Ksat:Knowledge-infused self attention transformerintegrating multiple domain-specific contexts. arXiv preprint arXiv:2210.04307, 2022. Revathy Venkataramanan, Kaushik Roy, Kanak Raj, Renjith Prasad, Yuxin Zi,Vignesh Narayanan, and Amit Sheth. Cook-gen: Robust generative modeling ofcooking actions from recipes. arXiv preprint arXiv:2306.01805, 2023.",
  "Kaushik Roy, Tarun Garg, Vedant Palit, Yuxin Zi, Vignesh Narayanan, and AmitSheth. Knowledge graph guided semantic evaluation of language models foruser trust. arXiv preprint arXiv:2305.04989, 2023": "Manas Gaur, Kaushik Roy, Aditya Sharma, Biplav Srivastava, and Amit Sheth.who can help me?: Knowledge infused matching of support seekers and supportproviders during covid-19 on reddit. In 2021 IEEE 9th International Conference onHealthcare Informatics (ICHI), pages 265269. IEEE, 2021. Kaushik Roy, Manas Gaur, Misagh Soltani, Vipula Rawte, Ashwin Kalyan, andAmit Sheth. Proknow: Process knowledge for safety constrained and explainablequestion generation for mental health diagnostic assistance. Frontiers in big Data,5:1056728, 2023. Adam Tsakalidis, Jenny Chim, Iman Munire Bilal, Ayah Zirikly, Dana Atzil-Slonim, Federico Nanni, Philip Resnik, Manas Gaur, Kaushik Roy, Becky Inkster,et al. Overview of the clpsych 2022 shared task: Capturing moments of change inlongitudinal user posts. In Proceedings of the Eighth Workshop on ComputationalLinguistics and Clinical Psychology, pages 184198, 2022. Shrey Gupta, Anmol Agarwal, Manas Gaur, Kaushik Roy, Vignesh Narayanan,Ponnurangam Kumaraguru, and Amit Sheth. Learning to automate follow-upquestion generation using process knowledge for depression triage on redditposts. arXiv preprint arXiv:2205.13884, 2022.",
  "Nathan Dolbir, Triyasha Dastidar, and Kaushik Roy.Nlp is not enoughcontextualization of user input in chatbots. arXiv preprint arXiv:2105.06511,2021": "Vipula Rawte, Megha Chakraborty, Kaushik Roy, Manas Gaur, Keyur Faldu,Prashant Kikani, Hemang Akbari, and Amit Sheth. Tdlr: Top (semantic)-down(syntactic) language representation. UMBC Faculty Collection, 2022. Usha Lokala, Francois Lamy, Triyasha Ghosh Dastidar, Kaushik Roy, RamintaDaniulaityte, Srinivasan Parthasarathy, and Amit Sheth. edarktrends: Harnessingsocial media trends in substance use disorders for opioid listings on cryptomarket.arXiv preprint arXiv:2103.15764, 2021. Yuxin Zi, Kaushik Roy, Vignesh Narayanan, Manas Gaur, and Amit Sheth. Ierl:Interpretable ensemble representation learning-combining crowdsourced knowl-edge and distributed semantic representations. 2023."
}