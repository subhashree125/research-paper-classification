{
  "Abstract": "Online controlled experiments play a crucial role in enabling data-driven decisions across a wide range of companies. Variance re-duction is an effective technique to improve the sensitivity of ex-periments, achieving higher statistical power while using fewersamples and shorter experimental periods. However, typical vari-ance reduction methods (e.g., regression-adjusted estimators) arebuilt upon the intuitional assumption of Gaussian distributions andcannot properly characterize the real business metrics with heavy-tailed distributions. Furthermore, outliers diminish the correlationbetween pre-experiment covariates and outcome metrics, greatlylimiting the effectiveness of variance reduction.In this paper, we develop a novel framework that integrates theStudents -distribution with machine learning tools to fit heavy-tailed metrics and construct a robust average treatment effect es-timator in online controlled experiments, which we call STATE.By adopting a variational EM method to optimize the loglikehoodfunction, we can infer a robust solution that greatly eliminates the",
  "Both authors contributed equally to this research.Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain. 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08 negative impact of outliers and achieves significant variance reduc-tion. Moreover, we extend the STATE method from count metricsto ratio metrics by utilizing linear transformation that preservesunbiased estimation, whose variance reduction is more complexbut less investigated in existing works. Finally, both simulationson synthetic data and long-term empirical results on Meituan ex-periment platform demonstrate the effectiveness of our method.Compared with the state-of-the-art estimators (CUPAC/MLRATE),STATE achieves over 50% variance reduction, indicating it can reachthe same statistical power with only half of the observations, orhalf the experimental duration.",
  "Controlled Experiments, Variance Reduction, Heavy-Tailed, RobustEstimation, Causal Inference": "ACM Reference Format:Hao Zhou, Kun Sun, Shaoming Li, Yangfeng Fan, Guibin Jiang, Jiaqi Zheng,and Tao Li. 2024. STATE: A Robust ATE Estimator of Heavy-Tailed Metricsfor Variance Reduction in Online Controlled Experiments. In Proceedings ofthe 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining(KDD 24), August 2529, 2024, Barcelona, Spain. ACM, New York, NY, USA,10 pages.",
  "KDD 24, August 2529, 2024, Barcelona, Spain.Hao Zhou et al": "play a crucial role in enabling data-driven decisions across a widerange of companies, including Facebook , Airbnb ,Google , Microsoft and LinkedIn . These experimentsare critical for businesses, as even small differences detected in keymetrics can have significant implications for the total revenue .For example, a strategy that increases one users revenue by $0.1can result in millions of dollars in the total revenue for ten millionusers.In the typical settings of controlled experiments, online trafficis randomly partitioned into two groups: a treatment group and acontrol group. They keep almost the same configuration except thatthe treatment group receives an additional intervention (e.g., a newproduction version or a promotion email). The average treatmenteffect (ATE) measures the causal effect of a treatment or interven-tion, but its groundtruth is unknown. Thanks to the central limittheorem, the difference-in-means estimator (DIM) produces an un-biased estimation of ATE, which is calculated by the differencebetween the treatment and control group outcomes.Although DIM offers unbiased estimates, it still suffers fromhigh variance, further leading to poor sensitivity and low statisti-cal power. For online businesses, the sensitivity of experiments isparticularly important. With thousands of experiments run eachyear, any benefits of increased sensitivity will be amplified due toeconomies of scale. On the other hand, the improvement in sensi-tivity allows experiments to be run on a smaller user population orfor shorter durations while achieving the same statistical power. Itis significant for improving the product feedback cycle and agility.In mathematics, variance reduction techniques are used to ob-tain higher precision for the metric of interest and have been in-troduced to online controlled experiments recently. For examples,CUPED utilizes pre-experiment covariates to reduce metric vari-ability between the treatment and control groups, constructing anunbiased estimator with lower variance. However, the effectivenessis limited by the linear assumption and the correlation betweenthe covariates and outcome metrics. Hence, to develop a nonlinearmulti-covariate proxy that is highly correlated with the outcomemetric, several machine learning (ML) based estimators have beenexplored . CUPAC and MLRATE are twostate-of-the-art (SOTA) estimators in this class, both of which arebased on the regression-adjusted method. To tackle the optimal-ity, Yin has demonstrated that if ML predicators converge tothe conditional mean function, the asymptotic variance of ATEestimators can reach the semi-parametric variance lower bound.Notably, the discussion on optimality is conducted under theassumption that the regression residuals follow a Gaussian distri-bution. However the business metrics of interest are often heavy-tailed (e.g., watch time on video sites, user Gross Merchandise Vol-ume(GMV) on e-commerce platforms, the amount of live broadcastrewards, etc.). The observations for these metrics usually containsome outliers (observations far away from the bulk of the probabil-ity density). The significant impact of outliers on the squared lossmay lead to bias and high variance in the ATE estimates. As shownin , the residuals of user GMV on the Meituan food deliveryplatform exhibit a heavy-tailed distribution due to the presence ofusers with extremely high-priced orders. In the Gaussian distribu-tion, the probability of observations falling beyond six standard deviations should be extremely small (less than 0.0000002%). How-ever, it is obvious that a larger portion of the observations exceedssix standard deviation in . Therefore, the Gaussian distributiondoes not properly characterize heavy-tailed metrics. Gaussian distribution fitStudent s t distribution fitReal distribution 0.25% observations locate in [+ 6 , +) : The distribution of residuals for user GMV on theMeituan food delivery platform. The Y-axis represents thesample count. The X-axis represents the residuals betweenthe real value and the model predicted value, where the ex-tremely large values are clipped to the upper bound. To address this problem, we introduce the Students-distributionto variance reduction. The Gaussian distribution is a special case ofthe -distribution, corresponding to the situation where the degreeof freedom tend to infinity. As the degree of freedom decreases,the -distribution has heavier tails, giving non-zero probability toobservations that fall outside the bulk of the density. This char-acteristic endows the -distribution with an important propertycalled robustness. As is shown in , the GMV metric can bebetter characterized when the regression residuals are modeled asa generalized -distribution.In this paper, we mainly focus on the variance reduction ofATE estimation of heavy-tailed metrics, and propose an easy-to-implement robust ATE estimator, called STATE. Specifically, ourwork has the following key contributions. We integrate the machine learning regression adjustmentmethod with the Students -distribution to estimate ATE forcount metrics and derive a variational EM framework to inferparameters. The estimation procedure takes full advantageof both the powerful fitting ability of machine learning toolsand the robustness of the -distribution to outliers, therebysignificantly reducing the variance of ATE estimation inonline controlled experiments. We extend this method to ratio metrics, which are morecomplex but less investigated. We introduce linear transfor-mation for ratio metrics while preserve unbiased estimationand consistent variance, under which regression-adjustedmethods and the Students -distribution can be introducedto reduce variance and improve sensitivity.",
  "STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for Variance Reduction in Online Controlled ExperimentsKDD 24, August 2529, 2024, Barcelona, Spain": "verify the effectiveness of our method in this paper. Exten-sive experimental results demonstrate that when the met-rics follow Gaussian distribution, the STATE method per-forms equivalently to the state-of-the-art estimators (CU-PAC/MLRATE). When the metric is a heavy-tailed distri-bution, our method can reduce the variance by about 50%compared to the CUPAC and MLRATE. This indicates that wecan achieve the same statistical power in online controlledexperiments with only half of the observations, or half theexperimental duration.",
  "Setup and Related Work2.1Setup": "Let be the pre-experiment covariates, be the binary treat-ment variable, and , be two outcome variables. In an onlinecontrolled experiment, suppose that there are samples denotedby (,,,), which are drawn independently from an identicaldistribution. The treatment {0, 1} is assigned randomly andindependently of the covariates , where = 1 represents that the-th sample receives the treatment. Denote the number of sampleswith = 1 and = 0 by and , repectively. Following theRubin Causal Model (RCM) , let (1), (1), (0), (0) be thecorresponding potential outcome when the sample is assigned withthe treatment or not.The count metrics are defined as the sample means (e.g.,",
  "Related Work": "Variance reduction is a key technology and a longstanding chal-lenge to improve the sensitivity of online control experiments. Theoriginal literatures mainly discuss the univariate linear adjustmentmethod . For instance, the CUPED estimator, which is widely applied in industry, utilizes relevant covariate from thepre-experiment period to reduce the variability of the outcome met-ric, and shows that the higher correlation between covariate andoutcome, the better the performance of variance reduction. Alter-natively, an equivalent technique to CUPED is the linear regressionmethod, = 0 + 1 + 2 + , which assumes the outcome is alinear combination of the treatment effect and the covariate term.To overcome the limitations of the linear model, researchershave explored multivariate adjustment methods by introducing the cross-fitting technique and agnosticregression . Typically, they utilize many covariates in a ma-chine learning(ML) model predicting from to develop a proxyvariable (). Subsequently, estimate the ATE in a linear regressionmodel = 0 + 1 + 2() + . Since the proxy incorporatesmore prior information about the outcome, it generates furthervariance reduction gains.However, the regression-adjusted methods assume that the resid-ual follows a Gaussian distribution, which is not applicable tothe heavy-tailed metrics in online businesses. If outliers are notproperly dealt with, they may lead to bias and high variance inparameter estimation.Furthermore, the majority of variance reduction methods focuson count metrics. In fact, ratio metrics are equally important in prac-tice, and are more complex but less investigated. Existing solutionsfor ratio metric are mostly extensions to those of count metrics.For examples, researchers utilize the delta method to extend theCUPED estimator to the variance reduction of ratio metrics. Thestudy conducted by focuses on ratio metrics by separatelyminimizing the variances of the numerator and denominator, butdisregards their correlation. A novel work proposed in is theconsistent transformation, which transforms ratio metrics into user-level linear metrics. However, it is based on a strong hypothesiswhere the denominator in ratio metrics is extremely large and canbe approximatively taken as a constant.In this paper, we develop more efficient estimators for count met-rics and ratio metrics respectively. For count metrics, we propose arobust estimator called STATE by modeling the regression residualas a Students-distribution which was put forth and adopted as a ro-bust building block, for clustering and robust projections.The heavy-tailed nature of the -distribution makes it much less sen-sitive to outliers compared to the Gaussian distribution, resulting ina substantial reduction in the variance of the ATE estimate. For ratiometrics, we adopt the main idea of the transformation method while relaxing its assumptions, and introduce STATE method forratio metrics to decrease the negative influence of outliers.",
  "Robust Estimation for Count Metrics withSTATE3.1Robust Modeling": "Following the framework of typical regression adjustment tech-niques, our proposed ATE estimation procedure can be summarizedin two stages: machine learning stage and linear regression stage.Machine learning stage: utilize machine learning tools to cap-ture the relationship between the outcome metric and the covari-ates . Then, we can obtain a proxy variable composed",
  ")(5)": "without loss of generality, the expectation of the residuals is setto 0. G is the Gamma density, G(|,) =() 1, and ()represents the Gamma function.It should be noted that the maximum likelihood estimate of1 based on Eq. (3),(4) is the ATE estimation. Now we derive thelog-likelihood function of the observations in the following form.",
  "Computational Complexity": "Compared to the CUPAC and MLRATE estimators, STATE incursextra computational costs, primarily due to the implementation ofthe EM algorithm. Specifically, in each iteration, calculating theposterior distribution parameters {,}=1 and model parameters = {, 2, } each takes () operations. Consequently, theoverall computational complexity of EM algorithm amounts to(), where denotes the number of iterations. According tothe empirical experience on the Meituan experimental platform,the EM procedure typically requires 30 to 60 seconds to process500,000 observations.",
  "Consistent Transformation of Ratio Metrics": "The ratio metrics are also common in the industry, which can beregarded as the ratio of two count metrics. For example, the click-through rate is a ratio metric, which is a ratio of the click numberand the pageview number. Addressing the variance reduction ofratio metrics is more complex but much less investigated in existingworks. In this section, we will introduce consistent transformationso that STATE can be utilized to reduce variance of ratio metrics.Following the notations in Sec. 2.1, let ,,, be the corre-sponding count metrics, i.e.,",
  "[]2,": "where = / and the second equality holds due to .Since the analysis unit in ratio metrics does not match the ran-domization unit, the common regression-adjusted method and ro-bust estimation cannot directly perform variance reduction for ratiometrics . The work transformed ratio metrics = /to linear metrics = , where = (1 ) + . Aftersuch linear transformation, regression adjustment can be appliedfor variance reduction of = , and the significance level of can be obtained by performing student t test for . However,there are two crucial defects in this work. Firstly, it is showed that = ((1 ) + ). The coefficient (1 ) + is nota constant and thus the significance level of is not equivalentto that of . Secondly, the analysis for the variance of in thiswork is based on the hypothesis where the parameter is taken asa constant, but it actually consists of random variables and .In this section, we follow the main idea in (transformingratio metrics to linear metrics), but mitigate the above two defectssimultaneously. Specifically, we construct a new linear metric and let =",
  "[ (1)] [ (0)]": "[ (0)] is ATE of ratio metrics. Since is a constant, Property 1 guarantees that the significance level of is equivalent to that of . Although the value of isunknown in practice, we can obtain the significance level of bymaking hypothesis testing for . Based on Property 2, performingregression adjustment for will result in a consistent estimator of with smaller variance than . Furthermore, robust estimationcan be introduced and eliminate the influence of the atypical andoutlying observations.Construction of . For each sample, construct the new label",
  "Experimental Evaluation": "In this section, we construct large-scale experiments to demonstratethe effectiveness of STATE using both simulated data and real userdata from the Meituan food delivery platform. Firstly, we validatethe performance of various methods in reducing the variance ofcount metrics and ratio metrics in simulation data. For complete-ness, we also investigate the impact of the proportion of outliers inthe data set on STATE. Secondly, to show the magnitude of vari-ance reduction that can be achieved in practice, we perform a seriesof A/A tests on key metrics of interest for Meituan food deliverybusiness. Finally, we discuss limitations of the STATE estimator.",
  "Experimental Setup": "Simulation data. The generating process is almost the same as .Denote each sample by (,,,). The covariates is dis-tributed as N (, 55), where is generated from a uniformdistribution (0, 10). The outcome variables and are con-structed by = ()+()+ and = ()+()+respectively, where and are the error terms distributed as N (0, 252) , N (0, 102). Let () and () be nonlinearfunctions with the forms() = 10 sin(12) + 6 23 + 10|4| + 5|5| + 50,",
  "() = 22 + 3 log(1 + 4 + |5|)": "Additionally, in order to validate the performance of our STATEestimator in dealing with heavy-tailed metrics, we also add a certainproportion of outliers to the simulation data set. The outliers arerandomly generated from two uniform distributions ( +4, +20) and ( + 4, + 20), where and are the standarddeviation of and respectively.We generate 200K samples in total and perform 1000 simulationexperiments. In each simulation, we randomly choose 20K samplesand divide them equally into the treatment group and the controlgroup according to the treatment indicator which follows Bernoulli(0.5). Finally, we compare the variance of different ATEestimators in all the simulations.Real user data. The real user data is collected from Meituan fooddelivery platform, which contains over 2.3 million samples and58 covariates. Each sample records all the transaction informationfor a user during an experiment in this platform. To show theeffectiveness of the STATE estimator, we select two count metrics,the count of orders per user (orders in short) and GMV per user,and a ratio metric, the average price per order (AvgOrdPrice). Here,GMV refers to the total price paid by each user on the food deliveryplatform during the trial period. The average price per order iscalculated by dividing the sum of GMV of all users by the totalnumber of orders of all users.For each metric, we perform A/A tests by selecting 200k usersrandomly and assigning the treatment indicator Bernoulli(0.5)for each user. Similarly, the A/A test is also repeated 1000 times.Notice that the A/A test is a controlled experiment where treatmentis identical to control, hence the ground truth of ATE is 0.Benchmark. For both count and ratio metrics, multiple methods forvariance reduction are implemented and taken as the benchmarks.",
  "STATE. The robust regression-adjusted estimator for ratiometrics after consistent transformation": "Evaluation Metrics. We compare various variance reduction tech-niques on two primary evaluation metrics: bias and variance. Con-sistent with previous studies, we assess the bias by utilizingthe empirical coverage rate of the 95% confidence intervals (CI).The closer the empirical coverage rate is to the nominal cover-age rate(95%), the smaller the bias of the estimator. On the otherhand, for the variance metric, the smaller the value, the shorter theconfidence interval and the higher the efficiency of the estimator.",
  "Simulation Experiment": "In this section, we utilize simulation experiments to validate theeffectiveness of the algorithms proposed in this paper. First of all,, 2 and show the simulation results for count metricsand ratio metrics on the dataset with 0.5% outliers. Furthermore,we investigate the impact of the proportion of outliers on vari-ous variance reduction techniques. \"Var.Red%\" displays the vari-ance reduction gains for each method compared to DIM estimator.\"Emp.Cov%\" displays the empirical coverage of the 95% CIs.",
  "As shown in , the empirical coverage of all count metricestimators closely approximates the nominal coverage (95%), indi-cating that the biases associated with these estimators are minimal": "(a) depicts the probability density of ATE estimates, reveal-ing that STATEs ATE distribution is markedly more compact, withits variance being substantially reduced compared to that of othermethods. Specifically, the CUPED method reduces the varianceby 28.7% compared to the DIM estimator; CUPAC and MLRATEperform similarly and deliver additional gains relative to CUPED.It indicates that the proxy variable constructed by the ML modelhas a superior correlation with the outcome than a single covariate.In contrast, the performance of the STATE estimator is remarkable,achieving an over 80% variance reduction compared to the DIMestimator and significantly enhancing the precision of ATE estima-tion. Considering both the empirical coverage rate and estimatorvariance, STATE clearly emerges as the preferred ATE estimator.",
  "Ratio Metrics": "(b) and present the detailed experimental results ofvariance reduction for ratio metrics in simulation data. As is shownby , the empirical coverage of all the estimators are closeto the nominal coverage, in which STATE achieves the best per-formance on variance reduction. Specifically, CUPED only reduces6.7% of variance compared to DIM duo to the weak correlationbetween the pre-experiment covariates and the ratio metric. CTRMperforms much better, which achieves over 55.7% variance reduc-tion compared with DIM. However, the effectiveness of CTRM isalso limited by the correlation between the ML-based predictorsand the outcome metrics, which is easily influenced by big outliers.As a robust estimator, STATE can significantly decrease the neg-ative effects for variance caused by outliers, which contributes toover 90.1% variance reduction relative to DIM.",
  "Factors Affecting STATE Effectiveness": "Now lets look at the factors that affect the performance of STATE.Here, we discuss the problem from a general setting to specificsettings by constructing a Gaussian distribution dataset and addingdifferent proportions of outliers from 0 to 1%. (a) and (b)display the results of empirical coverage and variance reductionrespectively.From the (b), we can see that when the dataset does notcontain outliers, more precisely, the metrics follow a Gaussian distri-bution, STATE, CUPAC, and MLRATE perform similarly in variancereduction. As the proportion of outliers increases, STATE and base-line methods exhibit drastically different performance. The reasonis that the degree of variance reduction of typical methods such asCUPED, CUPAC and MLRATE depends on the correlation betweenthe constructed covariates or proxy variables and business metrics. ATE 0.0 0.2 0.4 0.6 0.8 1.0",
  ": Impact of proportions of outliers": "However, with the existence of outliers, correlation learning be-comes increasingly difficult. The result is that the performance ofthese typical techniques deteriorates gradually, degrading to thevariance scale of the DIM method. The STATE estimator we pro-posed is designed to address such challenges by modeling the noiseas a Students -distribution. Because of the excellent robustnessof the T estimate, the rate of variance increase of STATE is signifi-cantly slower than the DIM method with the increase of outliers.Consequently, the more pronounced the heavy tail phenomenon ofbusiness metrics, the more apparent the advantage of the STATEmethod in variance reduction.",
  "Empirical Results": "In this section, we perform two real experiments on the Meituanfood delivery platform, analyzing the count metrics and ratio met-rics, respectively. Here, we focus on the A/A tests, not the A/Btests running in production. This is because the true effect of theA/B tests is unknown, which makes it impossible to evaluate the empirical coverage rate of the confidence interval. Since the aver-age treatment effect (ATE) in online experiments is typically smalland unlikely to significantly change the relationship between theoutcomes and covariates, the reduction in variance in A/B testsshould be very similar to that in A/A tests. -0.15 -0.10 -0.05 0.000.050.100.15 ATE 0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 20.0",
  "AvgOrdPrice95.06.495.621.894.991.695.7": "users accidental consumption behavior. For example, a user orderstakeaway to treat friends to dinner, the consumption price of herorder may be a extremely large value relative to her historicalconsumption pattern. These sample points that fall on the tail (alsoknown as outliers) are not affected by treatment, but has greatimpact on the sensitivity of measuring ATE.To get a better sense of the magnitudes of variance reductionthat the STATE method might achieve in practice, we select twokey count metrics: orders per user and GMV per user, both of whichhave heavy-tail distributions. For each metric, we construct A/Atests. and show the empirical results. It indicatesthat the STATE performs substantially better than the CUPED,CUPAC and MLRATE estimators on both orders metric and GMVmetric. On average, the STATE estimator reduces the variance ofthe order metric and GMV metric by 70.5% and 80.7% respectivelycompared to the DIM method, whereas the analogous figures for thestate-of-the-art methods are about 54.6% and 44.4%. It demonstratesthat STATE can indeed considerably improve the sensitivity ofreal business metrics, which is of great significance for increasingbusiness profits and reducing the cost of experimental time.Furthermore, we compare STATE method with the typical win-sorization method and Huber regression for dealing withheavy-tailed metrics. and 5 display the results of winsoriza-tion at different thresholds(99% and 99.9% quantiles of the observa-tions). It is observed that estimation is sensitive to the threshold.A lower threshold results in more observations beyond thresholdbeing restrained, which consequently yields a reduced variance inparameter estimation. However, there is a concomitant decline inthe empirical coverage rate, suggesting an incremental increase inbias. Consequently, employing the Winsorization process necessi-tates a meticulous balance between the impact of bias and variance.As shown in and 4, the variance of the parameters estimatedby the Huber regression method is slightly smaller than that ofthe CUPAC and MLRATE methods (without winsorization). This isbecause Huber regression transforms the mean square loss functionof extreme observations into a linear form, thereby partially reduc-ing the impact of outliers. However, the results also show that therobustness of the Huber regression method is limited, exhibiting aconsiderable disparity when compared to the STATE method.",
  "Ratio metrics": "(c) and present the results for ratio metric namedAvgOrdPrice in real user data, which is calculated by dividing thesum of GMV of all users by the total number of orders. As is shownby , the empirical coverage of all the estimators convergesto 95%, and STATE still performs the best because of the strongcapacity of resisting disturbance for outliers that exactly exists inreal data. In summary, the variance reduction of STATE is about",
  "Limitations": "In the preceding discussions, STATE has achieved notable successin the application of variance reduction for both count metricsand ratio metrics. Now lets discuss the applicability of the STATEmethod. Inspired by section 5.2.3, we find the effectiveness of theSTATE method varies from metric to metric, depending on whetherthe distribution of the metric has a heavy tail. When metric followsa Gaussian distribution, the STATE method is comparable with thestate-of-the-art methods, but introduces extra computational cost.If the metric exhibits a heavy tail distribution, the STATE methoddemonstrates a strong advantage.",
  "Conclusion": "Variance reduction is the common technology to improve the sensi-tivity in online controlled experiments, which contributes to smalleruser population and shorter experimental period. However, typicalmethods cannot characterize the heavy-tailed distributions in realbusiness metrics, whose efficiency is greatly limited by the outlyingobservations. In this paper, we proposed a machine-learning-basedregression adjustment method with Students -distributed errorsto reduce the impact of outliers in variance reduction for countmetrics. Furthermore, we transform ratio metrics into a linear com-bination but preserve unbiased estimation and consistent variance,and apply the above method to the variance reduction of ratiometrics. Both synthetic and real data demonstrate a significantdecrease in variance for both count and ratio metrics comparedto state-of-the-art methods. It benefits from our robust estimatorthat is stronger to resist disturbance of outliers. We recommend touse the method especially in the experiments where the treatmenteffect is not very significant. In this case, the influence of outliersis relative larger but can be effectively mitigated by our method.As the method significantly improves the robustness of con-trolled experiment results, we would like to expand it to the esti-mation of individual treatment effects (ITE) in future works, whichalso suffers from the negative effects of outliers.",
  "Peter M Aronow and Joel A Middleton. 2013. A Class of Unbiased Estimatorsof the Average Treatment Effect in Randomized Experiments. Journal of CausalInference 1, 1 (2013), 135154": "Eytan Bakshy and Dean Eckles. 2013. Uncertainty in Online Experiments withDependent Data: An Evaluation of Bootstrap Methods. In ACM SIGKDD Interna-tional Conference on Knowledge Discovery and Data Mining (KDD). 13031311. Roman Budylin, Alexey Drutsa, Ilya Katsev, and Valeriya Tsoy. 2018. ConsistentTransformation of Ratio Metrics for Efficient Online Controlled Experiments. InACM International Conference on Web Search and Data Mining (WSDM). 5563.",
  "Anirban DasGupta. 2008. Asymptotic Theory of Statistics and Probability. Vol. 180.Springer": "Alex Deng, Michelle Du, Anna Matlin, and Qing Zhang. 2023. Variance ReductionUsing In-Experiment Data: Efficient and Targeted Online Measurement for Sparseand Delayed Outcomes. In ACM SIGKDD Conference on Knowledge Discovery andData Mining (KDD). 39373946. Alex Deng, Ya Xu, Ron Kohavi, and Toby Walker. 2013. Improving the Sensitivityof Online Controlled Experiments by Utilizing Pre-Experiment Data. In ACMInternational Conference on Web Search and Data Mining (WSDM). 123132. Alex Deng, Lo-Hua Yuan, Naoya Kanai, and Alexandre Salama-Manteau. 2023.Zero to Hero: Exploiting Null Effects to Achieve Variance Reduction in Experi-ments with One-sided Triggering. In ACM International Conference on Web Searchand Data Mining (WSDM). 823831.",
  "David A Freedman. 2008. On Regression Adjustments to Experimental Data.Advances in Applied Mathematics 40, 2 (2008), 180193": "Yongyi Guo, Dominic Coey, Mikael Konutgan, Wenting Li, Chris Schoener, andMatt Goldman. 2021. Machine Learning for Variance Reduction in Online Experi-ments. In Conference on Neural Information Processing Systems (NIPS). 86378648. Henning Hohnhold, Deirdre OBrien, and Diane Tang. 2015. Focusing on theLong-term: Its Good for Users and Business. In ACM SIGKDD InternationalConference on Knowledge Discovery and Data Mining (KDD). 18491858."
}