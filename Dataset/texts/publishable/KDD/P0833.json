{
  "ABSTRACT": "An up-to-date city-scale lane-level map is an indispensable infras-tructure and a key enabling technology for ensuring the safetyand user experience of autonomous driving systems. In industrialscenarios, reliance on manual annotation for map updates creates acritical bottleneck. Lane-level updates require precise change infor-mation and must ensure consistency with adjacent data while ad-hering to strict standards. Traditional methods utilize a three-stageapproachconstruction, change detection, and updatingwhichoften necessitates manual verification due to accuracy limitations.This results in labor-intensive processes and hampers timely up-dates. To address these challenges, we propose LDMapNet-U, whichimplements a new end-to-end paradigm for city-scale lane-levelmap updating. By reconceptualizing the update task as an end-to-end map generation process grounded in historical map data, weintroduce a paradigm shift in map updating that simultaneouslygenerates vectorized maps and change information. To achievethis, a Prior-Map Encoding (PME) module is introduced to effec-tively encode historical maps, serving as a critical reference fordetecting changes. Additionally, we incorporate a novel InstanceChange Prediction (ICP) module that learns to predict associationswith historical maps. Consequently, LDMapNet-U simultaneouslyachieves vectorized map element generation and change detection.",
  "These authors contributed equally to this work.Corresponding authors": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 25, August 37, 2025, Toronto, ON, Canada 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-1245-6/25/08...$15.00 To demonstrate the superiority and effectiveness of LDMapNet-U,extensive experiments are conducted using large-scale real-worlddatasets. In addition, LDMapNet-U has been successfully deployedin production at Baidu Maps since April 2024, supporting lane-level map updating for over 360 cities and significantly shorteningthe update cycle from quarterly to weekly, thereby enhancing thetimeliness and accuracy of lane-level map. The nationwide, high-frequency city-scale lane-level map has been instrumental in thedevelopment of the lane-level navigation product serving hundredsof millions of users, while also integrating into the autonomousdriving systems of several leading vehicle companies.",
  "Lane-Level Map Updating; End-to-End; Prior Map; Change Detec-tion": "ACM Reference Format:Deguo Xia, Weiming Zhang, Xiyan Liu, Wei Zhang, Chenting Gong, XiaoTan, Jizhou Huang, Mengmeng Yang, and Diange Yang. 2025. LDMapNet-U: An End-to-End System for City-Scale Lane-Level Map Updating. InProceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery andData Mining V.1 (KDD 25), August 37, 2025, Toronto, ON, Canada. ACM,New York, NY, USA, 10 pages.",
  "INTRODUCTION": "Lane-level map constitutes a foundational component for both navi-gation and autonomous driving, serving as an indispensable asset inenhancing driving safety and experience by providing comprehen-sive and highly precise road information. However, the widespreaddeployment of such maps is hindered by two primary challenges:1) How to cost-effectively generate lane-level map data for all citiesnationwide; and 2) How to maintain the currency (a.k.a., freshness,",
  "No change": ": LDMapNet-U presents an end-to-end automatedindustrial-grade approach for lane-level map updating. Ourproposed method uses BEV images and historical maps asinputs, achieving end-to-end prediction of vectorized resultsand change labels through the innovative design of the Prior-Map Encoding (PME) and Instance Change Prediction (ICP)modules. With these advancements, LDMapNet-U signifi-cantly enhances update efficiency and quality. timeliness, or temporal accuracy) of such a massive dataset. To ad-dress the initial challenge of generating lane-level map data at scale,we developed DuMapNet , an innovative end-to-end vectoriza-tion system for city-scale lane-level map generation. Successfullydeployed at Baidu Maps in 2023, DuMapNet achieved a 95% costreduction while generating detailed lane-level map data covering361 cities in China. The dynamic nature of urban environments,characterized by frequent lane configuration changes, poses a signif-icant obstacle to maintaining their accuracy. Effective and scalablesolutions for preserving the currency of city-scale lane-level mapdata remain elusive.Compared to road-level geo-object or visual change detection , industrial-grade lane-level map updating presents morecomplex challenges. First, accurately detecting changes at the in-stance level of individual lanes is fundamental. Second, preciselocalization of boundaries, including the start and end points ofchanges, and seamless integration of updates into the existing mapare critical. Moreover, the updated map must ensure geometric,topological, and semantic consistency with adjacent unchangedareas. Ultimately, the updated map must adhere to stringent indus-trial mapping standards, ensuring high accuracy for the rigoroussafety and user experience demands of autonomous driving andnavigation systems. Traditional methods utilize a three-stage ap-proachconstruction, change detection, and updatingwhich oftennecessitates manual verification due to accuracy limitations. Thislabor-intensive process is time-consuming and costly, often involv-ing manual redrawing of road elements according to the strict map-making standards. A more modern approach involves integratingcomputer vision technology into a multi-stage framework that com-bines perception and differential analysis components. While visualmodels are employed to recognize road elements,complex post-processing logic is necessary to compare and identifychanges. This multi-step process is prone to error accumulation andlacks automated integration of updated information into the his-torical maps. The intricate and dynamic urban traffic environment,characterized by frequent vehicle obstructions and lane deteriora-tion, significantly impedes the efficacy of vision-based detection algorithms. Additionally, the accurate and automated incorpora-tion of updated information into lane-level map databases whilepreserving topological and semantic integrity remains a criticalindustrial challenge.To advance the paradigm of lane-level map updating, we presentLDMapNet-U, an enhanced version of DuMapNet , providing anend-to-end automated industrial-grade solution. Unlike traditionalmulti-stage methods, our model reconceptualizes lane-level mapupdating as an end-to-end generation process based on historicalmap data and corresponding latest road observation birds-eye-view(BEV) images. By taking historical map data and the latest BEVimages as input, the model can directly generate standardized vec-torized lane-level maps that are consistent with the historical maps,while simultaneously identifying instance changes, thus avoidingthe problems of error accumulation and poor generalization inmulti-stage methods. To achieve this goal, a novel Prior Map En-coding (PME) module is introduced to effectively encode historicalmap information as prior knowledge for the model. On one hand,the PME module provides the model with rich historical road priorinformation, which helps to improve the accuracy of change detec-tion in complex road scenarios; on the other hand, the PME modulecontributes to improving the geometric, topological, and semanticconsistency between the generated map elements and the historicalmap data. Furthermore, we design an Instance Change Prediction(ICP) module to learn the correspondence and change types be-tween core geographic elements in the latest road observation dataand the historical maps. Additionally, by unifying the modeling ofpolyline-style and polygon-style map elements as a set of pointsand introducing multi-task joint learning for vectorized map ele-ment generation, LDMapNet-U simultaneously achieves end-to-endlane-level vectorized map generation and change detection.The key contributions to both the research and industrial com-munities are as follows: Potential impact: We propose an industrial-grade solution,named LDMapNet-U, for city-scale lane-level map updating.LDMapNet-U has already been deployed in production atBaidu Maps, supporting lane-level map updating for over 360cities, accelerating the update cycle from quarterly to weekly.Serving as a foundational component, this city-scale lane-level map empowers navigation for hundreds of millions ofusers and is integral to the autonomous driving systems ofseveral leading vehicle companies. Novelty: LDMapNet-U introduces a new paradigm for lane-level map updating that simultaneously generates vectorizedmaps and change information from BEV images and historicalmaps. The proposed approach leverage innovative technolo-gies at each stage, including unified vectorization modeling,Prior-Map Encoding (PME) module, and Instance ChangePrediction (ICP) module, to achieve a highly automated andcost-effective solution. Technical quality: Extensive qualitative and quantitativeexperiments on large-scale, real-world datasets demonstrateLDMapNet-Us superiority. Successfully deployed at BaiduMaps, supporting weekly updates for over 360 cities, under-scores LDMapNet-Us practicality and robustness for city-scale lane-level map updating.",
  "LDMapNet-U2.1Problem Setup": "The task of lane-level map updating is defined as follows: given aBEV image collected from vehicle-mounted sensors and the cor-responding historical vectorized map as the input, the networkis supposed to generate the updated vectorized map , while indi-cating changes to each lane instance, such as style change, instanceaddition, or deletion. Subsequent sections will describe the datapreparation and the detailed definition of lane instance changes.Data Preparation. As aforementioned, our LDMapNet-U takesBEV image and vectorized data from historical map database as in-puts. To enhance the timeliness of road observation data acquisition,we utilize data from autonomous driving vehicles as a crowdsourcedupdate source. To improve processing efficiency and meet high real-time demands, we have migrated a component of the BEV imagecreation pipeline from the cloud to the vehicle. This involves ini-tially conducting coarse-grained change detection using on-boardperception information from autonomous vehicles, followed by thecollection of road images and generation of BEV images for poten-tially changed road segments in the cloud. Notably, we adopt anadaptive strategy for image acquisition and BEV image generationbased on the number of lanes: single-trip collected image data issufficient for roads with three or fewer lanes, while multi-trips arefused for roads with more than three lanes. This approach effec-tively mitigates the uncertainty inherent in incomplete perceptionby solely relying on crowdsourced perceived vectorized map ele-ments for map updates. Note that this part is not the primary focusof this paper and will not be elaborated further.Next, we will detail the method of creating the dataset. Firstly,we constructed the dataset of sample pairs, each consisting of threecomponents: the latest BEV image , which provides the most recentobservation of the current road scene within region ; the historicalmap , representing the map information of the region prior toobtaining BEV image , and the updated map , reflecting the mapinformation after incorporating the latest observations from BEVimage . Following DuMapNet , the BEV image with resolution that covers /25 meters by /25 meters of a regionwith a certain geographic coordinate range. Both and areorganized in the form of map meshes, includes all instance infor-mation such as geometry, styles, geographic locations, and so on.Secondly, instances with key geographic features, including geome-try (i.e., sets of 2-d points) and style attributes, were extracted fromboth and . To align these features with the BEV image, wemapped their geometric shapes to the images pixel coordinate sys-tem. Subsequently, a two-phased labeling process was implementedto identify changes between the historical map and updated map : an initial automated stage employed instance matching andcomparison to generated preliminary change labels, followed byhuman expert refinement to ensure accuracy. More detailed typesof changes are described in the following section. Finally, to bolsterand validate the models generalization capabilities, we assembleda comprehensive dataset encompassing diverse urban landscapesacross China, characterized by varying road network layouts andcomplexities.Instance Change Definition. We define four types of laneinstance changes to the map updates as follows:",
  "Overall Architecture": "City-scale lane-level map updating presents intricate challenges,demanding precise detection of individual lane instance changesand seamless integration of changes into standardized vectorizedmaps. To address the limitations of traditional multi-stage methods,our LDMapNet-U proposes an end-to-end framework for city-scalelane-level map updating, realizing practical and effective industrialapplications.Specifically, a depicts the overall architecture of our pro-posed LDMapNet-U. Taking the latest BEV images and historicalmaps as input, LDMapNet-U simultaneously predicts vectorizedmap results and map changes, incorporating innovative Prior-MapEncoding (PME) and Instance Change Prediction (ICP) modules.To extract image features from the input BEV image, we utilize aconventional CNN-based backbone as the image encoder. Subse-quent subsections will illustrate each component of the proposedframework.",
  "Lane-Level Map Vectorizaiton": "In our paper, vectorized map = {{,}}=0 is a structuredrepresentation of a collection of map elements (e.g., open-shapelane lines), where and indicate the geometric information andstyle of each element, and is the number of elements. In orderto ensure generality, each element is uniformly defined as a fixednumber of vectorized point sets, specifically as = {{ }}=0,where represents the fixed number of points for each mapelement. Historical map is a vectorized map at a certain historicalmoment with same data structurre of .The primary objective is to convert BEV images into standard-ized, vectorized map elements in an end-to-end manner. The sys-tem begins with an image encoder, which utilizes a conventionalCNN-based backbone, such as ResNet50 or HRNet48, to extractfeatures from the input BEV image. The BEV image, collected fromvehicle-mounted sensors, provides a comprehensive view of theroad network, capturing essential details like lane lines, crosswalks,and other road elements.Following the image encoding, the feature decoder adopts thesame hierarchical queries architecture as in MapTRv2. Specifically,the hierarchical queries , includs instance queries andpoint queries. In addition, the decoder module is composed of sev-eral cascaded layers, and each layer integrates a self-attention layerand a cross-attention layer. That design allows hierarchical queriesto exchange information across the entire feature space when pass-ing through the self-attention layer, and interact with the BEVfeatures when passing through the cross-attention layer. After ob-taining the query embedding encoded by the decoder,classification and regression networks are respectively used to",
  "Prior-Map Encoding (PME)": "To leverage the rich contextual information embedded in historicalmap data, we introduce the Prior-Map Encoding (PME) module asa novel component of LDMapNet-U. As shown in b, thismodule encodes historical map data into a compact representationthat captures the geometric and semantic characteristics of road el-ements and their spatial relationships. Specifically, for the -th lane",
  "instance, we encode its coordinates { }=1 using sine and cosine": "position encoding to generate the position embedding { } ,and also encode its category using MLP to generate the semanticembedding { } . Naturally, we fuse the positional embed-dings and semantic embedding to initially represent historical laneline instances. Further we adopt map encoding layers which con-tains three multi-head self-attention operations to enhance themap representation learning. Taking the advantages of PME, thehistorical map data is able to serves as an effective prior, provid-ing a reference for the model to effectively detect lane instancechanges and update the map accordingly. Subsequently, we adopta cross-attention operation to fuse map embeddings with image embeddings , where is the number ofhistorical lane instances. Finally, the map-embedding enhancedfeature is fed to the decoder to realize both vectorizedmap and map change predictions.",
  "Instance Change Prediction (ICP)": "To effectively differentiate lane instance changes, predicting solelybased on instance geometry and style is insufficient. Since instancechanges inherently relate to historical maps, we reformulate thechange prediction task as one of associating predicted instanceswith existing historical instances. Based on the instance features from the image encoder and the historical instance features fromPME, we construct a affinity matrix to represent the associationsbetween the two lane instances, and then effectively generate thecorresponding change types. Associations Matrix Construction. As illustrated in c,we unify the feature space for the predicted and historical instanceusing distinct MLP networks, followed by an outer product to gener-ate a feature-level association matrix. Subsequently, a classificationnetwork constructs an initial association matrix A , ex-pressed as follows:",
  "A = F ( )(1)": "F denotes the classification operation.Finally, during inference, matched pairs of A with low confi-dence and inconsistent styles are filtered to enhance the reliabilityof the association matrix. Meanwhile, based on A, we introduce aHungarian matching strategy to establish the association matrixM , ensuring that each predicted lane instance can bematched with at most one historical lane instance and vice versa.Specifically, and represent the number of given historicalinstances and predicted instances, respectively. An element Mequals 1 if the corresponding predicted and historical lane instancesare associated, otherwise 0.Instance Change Generation. Based on the association matrixM, lane instance changes are categorized as follows: (1) No change:M = 1 and the styles of the -th predicted and the -th historicalinstance are consistent; (2) Style change: M = 1 and the styles ofthe -th predicted and the -th historical instance differ; (3) Instanceaddition: M = 0 for a predicted instance, indicating that the -thpredicted instance has no matching historical instance; (4) Instancedeletion: M = 0 for a historical instance, indicating that the -thhistorical instance does not match any predicted instance.",
  "End-to-End Training": "Matching. Given the tasks complexity, which encompasses laneinstance coordinate and style prediction alongside change typeprediction, we adopt a two-stage matching scheme. The first stageemploys hierarchical bipartite matching, similar to MapTR ,to partition samples into positive and negative sets for geometryand style prediction. In the second stage, we leverage known rela-tionships between ground truth and predicted instances, as well asbetween ground truth and historical instances, to indirectly derive",
  "All9,890164,840-": "associations between predicted and historical instances. If a pre-dicted lane instance does not match any historical lane instance, it isconsidered an instance addition and excluded from loss calculation.Map Elements Learning. Our approach can be viewed as amulti-task learning framework that encompasses lane instanceprediction and lane instance change prediction, as detailed below:",
  "L = L + L(2)": "Similar to DuMapNet , L is composed of three parts: (1) anL1 loss for lane instance coordinate regression, (2) a direction lossbased on cosine similarity to enforce lane instance smoothness, (3)an aligned classification loss to ensure accurate instance style andgeometric coordinate for each lane instance. For each predictedlane instance, the classification loss is specifically defined as:",
  "=1 (, 0) (3)": "where is the probability for the -th predicted lane instance, represents the 1 distance between the -th predicted lane instanceand its corresponding ground truth, and and denote thenumber of positive and negative elements, respectivelyInstance Change Learning. After filtering out predicted laneinstances classified as additions based on the matching strategy,we calculate the classification loss on the association matrix Aformed by the remaining predicted and historical lane instancefeatures. Specifically, for each predicted lane instance, it may beassociated with any one of the historical lane instances. Therefore,we treat the association relationship of each predicted lane instanceas an N-class classification task, expressed as follows:",
  "EXPERIMENTS3.1Experimental Settings": "Datasets. To evaluate the effectiveness of LDMapNet-U, we havecollected a large-scale real-world dataset, LD-U, consisting of BEVimages, piror map data and ground truth data from twelve cities:Guangzhou, Hangzhou, Huzhou, Jining, Lanzhou, Tianjin, Beijing,Chongqing, Dongguan, Harbin, Shaoxing, and Yantai. These citiesexhibit diverse geographical distributions, varying scales and dis-tinct road network configurations. Note that, the first six cities were divided into a training set and a validation set in a 9 : 1 ra-tio, whereas the rest cities were selected as the test set to evaluatethe performance of models. Statistically, LD-U contains 164, 840images, spanning 9, 890 kilometers, with each image at a resolutionof 1536 1536 pixels. More details can be found in . Addi-tionally, LD-U-L, a dataset containing 1.5 million samples, has beenintroduced to demonstrate the effectiveness of LDMapNet-U onlarger-scale data.Evaluation Metrics. In the map updating task, both the qualityof map construction and the effectiveness of map change detectionneed to be considered. To evaluate the quality of map construction,we follow DuMapNet to use the @1,0.8 = 80% to representthe recall at 80% precision. For assessing the effectiveness of mapchange detection, we utilize instance-level change recall ( ) andprecision ( ) as the evaluation metrics. In the evaluation pro-cess, style change, instance addition, and instance deletion are allconsidered as map changes.Implementation Details. Our model is trained using 16 NVIDIATesla V100 GPUs, with a batch size of 16. We utilize the AdamW optimizer with a weight decay of 0.01, and the initial learning rate isset to 6104 with cosine decay. The input images have a resolutionof 768 768 pixels. For our architecture, we employ ResNet50 and HRNet48 as the backbones. The default number of instancequeries, point queries and decoder layers are 50, 50 and 6, respec-tively. As for hyper-parameters of loss weight, we set and to1 and 1, respectively. The inference time is measured on a singleNVIDIA Tesla V100 GPU with batch size 1.",
  "Evaluation": "Comparison with Baselines. Extensive experiments are con-ducted on LD-U and LD-U-L. The quantitative comparisons of thequality of the generated elements are summarized in . Fromthe results, we observe that LDMapNet-U consistently brings sig-nificant improvements. Taking Beijing as an example, LDMapNet-U (R50) achieves better performance with +7.69% 15.76% recallgains on LD-U, indicating that our model performs better in terms ofgeometry and style. In addition, LDMapNet-U surpasses DuMapNetby a large margin (+7.06% 11.83% across six cities). This is reason-able since LDMapNet-U sufficiently learns from the input historicalvectorized map data, facilitating a precise and high-fidelity recon-struction of lane-level elements. Surprisingly, further improvement(+1.70%) is achieved by replacing the backbone with HRNet48, dueto the enhanced feature representation. Of particular interest, byaugmenting the data volume (i.e., LD-U-L), our method achievesan average recall of 92.62% across six cities, further substantiat-ing the powerful performance and scalability of the model. For",
  "(c) BEV Feature CA": ": Different fusion methods for historical map embeddings. (a) w/o Fusion indicates that the historical map embeddingsare not fused with the network before map association prediction. (b) Decoder Query CA refers to the fusion of historical mapembeddings with the decoder queries by leveraging multi-head cross-attention. (c) BEV Feature CA refers to the fusion ofhistorical map embeddings with the BEV features by leveraging multi-head cross-attention. computational efficiency, compared to previous methods that onlypredict maps without detecting lane changes (e.g., MapTR ), theincrease in inference cost of our model is nearly negligible. presents the comparisons of models in change detection.Notably, since baseline methods, including DuMapNet , can-not predict change labels in an end-to-end manner, we feed theirpredicted vectorized results into the existing industrial-grade post-processing logic to generate change labels. From the results, weobserve that LDMapNet-U consistently outperforms other methodswith validation precision gains of +1.49% 5.45% and recall gainsof +9.18% 13.84%. Compared to DuMapNet, LDMapNet-U shows the greatest improvement in the instance deletion category, withprecision and recall increasing by 1.5% and 13.95%, respectively. Inthe instance addition category, LDMapNet-U exhibits the smallestimprovement, with precision and recall increasing by 1.06% and7.63%, respectively. The main reason for this difference is that forinstance addition, it is essential not only to correctly predict thechange category but also to ensure that the added instances have thecorrect geometric information. These results convincingly demon-strates LDMapNet-Us superior performance in change detection.This can be attributable to the end-to-end paradigm, which directly",
  "w/o ICPR50LD-U83.5877.3881.74LDMapNet-UR50LD-U83.9577.8483.76": "predicts change labels through the introduced PME and ICP mod-ules, thereby eliminating the reliance on manually set thresholdsin post-processing.Analysis of generalization. As a deployed algorithm, its gen-eralization capability needed to be thoroughly evaluated. To thisend, as shown in , we select six cities for evaluation that donot overlap with the training set. These cities vary in scale and aredistributed across various regions of China. For example, Beijingis a first-tier city, while Shaoxing is a second-tier city; Harbin islocated in the northeast of China, whereas Chongqing is in thesouthwest, reflecting diverse geographical characteristics. From, LDMapNet-U exhibits superior generalization with lessfluctuation in performance across six cities. For instance, the maxi-mum deviation of LDMapNet-U (R50) across the six cities is 2.95%,significantly outperforming GeMaps 7.62% and MapTRs 7.80%.Ablation Studies. illustrates the three historical mapembeddings fusion methods, with their performance shown in Ta-ble 4. According to the experimental results, it is evident that fusinghistorical map embeddings with the network before map associa-tion prediction is crucial, as this enables the incorporation of priorstructural and semantic information. Compared to the DecoderQuery CA method, our proposed LDMapNet-U employs the BEVFeature CA method to introduce historical map embeddings at ashallower network level, resulting in improvements of 2.32%, 0.31%and 2.9% in @1,0.8 = 80%, and , respectively. Thesefindings demonstrate the effectiveness of the fused BEV features,which include not only semantic information from the images butalso prior information extracted from the historical maps. In addi-tion, illustrates the effectiveness of the proposed ICP module,which pioneers a pattern for end-to-end prediction of change labels,thereby addressing the reliance of earlier methods on complex post-processing logic. As can be seen, ICP has brought improvements inmap construction quality (@1,0.8 = 80% +0.37) and map changedetection ( +0.46, +2.02).",
  "Visualization": "illustrates qualitative comparisons between LDMapNet-U and a range of baseline methods. LDMapNet-U demonstratessignificant advantages in terms of both geometric accuracy andstyle fidelity of lane instances. This substantial improvement pri-marily arises from the joint training of the model on BEV imagesand historical vectorized data, which enables it to adaptively learn the representational relationship between the latent manifolds ofmulti-source data through the PME module. In essence, BEV imagesand historical vectorized data exhibit complementary and consistentcharacteristics in unchanged scenes while demonstrating robustdiscrimination capabilities in changed portions. As shown in thefirst row of , the upper-right lane changes from two lanesto three lanes. GeMap and DuMapNet fail to accurately output theconnection at the location of the lane change, whereas LDMapNet-U successfully predicted the geometry and change labels of thechanged lane lines, intuitively demonstrating the models capa-bility to achieve high-quality end-to-end change label predictionthrough the PME and ICP modules. Futher, as shown in the thirdand fifth rows of , LDMapNet-U exhibits better performancein occlusion scenarios, potentially due to the introduction of priormap information, which compensates for situations where imagefeatures are disrupted.",
  "Map Construction": "With the development of deep learning and BEV perception ,map construction can be considered as a task of generating mapsfrom sensor observations in a BEV space. The existing methodscan be categorized into two types: rasterized map construction andvectorized map construction. Rasterized map construction methods generate rasterized maps by performing BEV se-mantic segmentation. To address the limitations of rasterized mapsin lacking instance-level structured information, the vectorized mapconstruction methods are proposed and rapidly developed. HDMap-Net adopts a two-stage approach of segmentation followed bypost-processing to generate vectorized instances. As the first end-to-end framework, VectorMapNet utilizes an auto-regressive de-coder to predict points sequentially. MapTR proposes a unifiedshape modeling method based on a parallel end-to-end framework.MapTRv2 further introduces auxiliary one-to-many matchingand auxiliary dense supervision to speedup convergence. BeMapNet adopts a parameterized paradigm and constructs map elementsas piecewise Bezier curves. PivotNet utilizes a dynamic numberof pivotal points to model map elements, preventing the loss of es-sential details. GeMap end-to-end learns Euclidean shapes and",
  "(a) BEV Image(b) Historical Maps(c) GeMap(d) DuMapNet(e) LDMapNet-U(c) Ground Truth": ": Qualitative comparisons of our model with several state-of-the-art models. Instances addition, instance deletion, stylechange, and no change are highlighted in red, yellow, green, and light purple, respectively. Best viewed in color. relations of map instances beyond basic perception. Unlike existingmethods, our proposed LDMapNet-U not only takes sensor obser-vations as input but also enhances map construction performanceby incorporating the corresponding historical map information asguidance.",
  "LDMapNet-U: An End-to-End System for City-Scale Lane-Level Map UpdatingKDD 25, August 37, 2025, Toronto, ON, Canada": "Early works mostly relied on classical statistical techniques. Pan-nen et al. uses a particle filter approach with odometry, GlobalNavigation Satellite System (GNSS) and landmark readings to ob-tain distributions evaluated by a number of weak classifiers. Re-cently, a few efforts have been made to use deep learning for mapchange detection. Heo et al. directly maps an input image toestimated probabilities of HD map changes based on deep metriclearning. Bu et al. projects detections from 2D images onto theBEV space to detect crosswalk changes. Trust but Verify (TbV) is a dataset specifically designed for map change detection, and ithas been used to explore deep learning frameworks for map changedetection. However, the existing work only focuses on whetherthe map has changed, making it difficult to obtain more detailedinformation such as the location and category of the changes. Inorder to better support the lane-level map updating task, our pro-posed LDMapNet-U can detect lane-level changes, including theirlocations and categories.",
  "DISCUSSION": "As described in .1, our method employs BEV images as thelatest road observation data, rather than other data sources such asvectorized results transmitted from the vehicle or satellite images.This choice is due to the fact that, unlike conventional onboardperception systems, our deployed BEV image creation process canleverage comprehensive regional global information, such as geo-metric smoothness constraints and semantic associations. Moreover,compared to satellite images, BEV images primarily cover road ar-eas, while possessing the advantages of high flexibility and highresolution. For city-scale lane-level map updating task, BEV imagesoffer advantages such as high timeliness, global consistency, andthe ability to overcome inherent challenges of onboard perception,including precision bias, perceptual incompleteness, and dynamicocclusions . LDMapNet-U has greatly increased automationin large-scale commercial map systems, cutting operational costsby 95%, reducing the map update cycle from quarterly to weekly.Furthermore, high-quality lane-level maps will potentially benefita range of geospatial-related tasks, such as traffic condition pre-diction , estimated time of arrival prediction (ETA prediction,a.k.a., travel time estimation) , road extraction , andgeospatial foundation models .Despite the impressive achievements of LDMapNet-U, severalchallenges worth exploring in the future. For instance, due to theinherent challenges associated with lane-level map, including thedemand for high precision and the multitude of map elements, ourmethod relies on high-precision crowdsourced data, such as imagescollected by autonomous driving vehicles with decimeter-level orhigher localization accuracy. The challenge of utilizing lower pre-cision crowdsourced data to meet map-making standards remainsan open question. The fusion of multi-source data is expected tobe a valuable research area. For instance, combining trajectorydata with BEV images could enhance recognition performancein cases where image features are less pronounced. Furthermore,LDMapNet-U lacks efficiency in updating dynamic events, such asshort-term construction or traffic accidents, which often require",
  "CONCLUSIONS": "In this paper, we propose an effective industrial-grade solutionfor lane-level map updating. Specifically, the proposed LDMapNet-U employs the Prior-Map Encoding (PME) module to incorporatehistorical map data as one of its inputs. This approach provides crit-ical reference information for detecting changes while improvingthe quality of the predicted instances. Additionally, the introductionof the Instance Change Prediction (ICP) module enables the modelto directly predict change labels in a learning-based manner, thuseliminating the need for cumbersome post-processing logic. Ex-tensive quantitative and qualitative experiments conducted on thecollected large-scale real-world dataset from Baidu Maps demon-strate the effectiveness and superiority of LDMapNet-U. Since itsdeployment at Baidu Maps in April 2024, LDMapNet-U has suc-cessfully supported weekly updates for over 360 cities in China,realizing a nationwide, high-frequency lane-level map essential fornavigation and autonomous driving. This further demonstrates itscost-effectiveness and practicality as an industrial-grade solution.",
  "Tom Bu, Christoph Mertz, and John Dolan. 2023. Toward map updates withcrosswalk change detection using a monocular bus camera. In 2023 IEEE IntelligentVehicles Symposium (IV). IEEE, 18": "Pengxin Chen, Xiaoqi Jiang, Yingjun Zhang, Jiahao Tan, and Rong Jiang. 2024.MapCVV: On-cloud Map Construction Using Crowdsourcing Visual VectorizedElements towards Autonomous Driving. IEEE Robotics and Automation Letters(2024). Wenjie Ding, Limeng Qiao, Xi Qiu, and Chi Zhang. 2023. Pivotnet: Vectorizedpivot learning for end-to-end hd map construction. In Proceedings of the IEEE/CVFInternational Conference on Computer Vision. 36723682. Xiaomin Fang, Jizhou Huang, Fan Wang, Lihang Liu, Yibo Sun, and HaifengWang. 2021. SSML: Self-Supervised Meta-Learner for En Route Travel TimeEstimation at Baidu Maps. In Proceedings of the 27th ACM SIGKDD Conference onKnowledge Discovery & Data Mining. 28402848. Xiaomin Fang, Jizhou Huang, Fan Wang, Lingke Zeng, Haijin Liang, and HaifengWang. 2020. ConSTGAT: Contextual Spatial-Temporal Graph Attention Networkfor Travel Time Estimation at Baidu Maps. In Proceedings of the 26th ACM SIGKDDInternational Conference on Knowledge Discovery & Data Mining. 26972705. Yushan Han, Hui Zhang, Huifang Li, Yi Jin, Congyan Lang, and Yidong Li. 2023.Collaborative perception in autonomous driving: Methods, datasets, and chal-lenges. IEEE Intelligent Transportation Systems Magazine (2023).",
  "Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residuallearning for image recognition. In Proceedings of the IEEE conference on computervision and pattern recognition. 770778": "Minhyeok Heo, Jiwon Kim, and Sujung Kim. 2020. Hd map change detection withcross-domain deep metric learning. In 2020 IEEE/RSJ International Conference onIntelligent Robots and Systems (IROS). IEEE, 1021810224. Anthony Hu, Zak Murez, Nikhil Mohan, Sofa Dudas, Jeffrey Hawke, VijayBadrinarayanan, Roberto Cipolla, and Alex Kendall. 2021. Fiery: Future instanceprediction in birds-eye view from surround monocular cameras. In Proceedingsof the IEEE/CVF International Conference on Computer Vision. 1527315282.",
  "Junjie Huang, Guan Huang, Zheng Zhu, Yun Ye, and Dalong Du. 2021. Bevdet:High-performance multi-camera 3d object detection in bird-eye-view. arXivpreprint arXiv:2112.11790 (2021)": "Jizhou Huang, Zhengjie Huang, Xiaomin Fang, Shikun Feng, Xuyi Chen, JiaxiangLiu, Haitao Yuan, and Haifeng Wang. 2022. DuETA: Traffic Congestion Propaga-tion Pattern Modeling via Efficient Graph Learning for ETA Prediction at BaiduMaps. In Proceedings of the 31st ACM International Conference on Information &Knowledge Management. 31723181. Jizhou Huang, Haifeng Wang, Yibo Sun, Yunsheng Shi, Zhengjie Huang, AnZhuo, and Shikun Feng. 2022. ERNIE-GeoL: A Geography-and-Language Pre-trained Model and its Applications in Baidu Maps. In Proceedings of the 28th ACMSIGKDD Conference on Knowledge Discovery and Data Mining. 30293039.",
  "conference on computer vision. Springer, 118": "Bencheng Liao, Shaoyu Chen, Xinggang Wang, Tianheng Cheng, Qian Zhang,Wenyu Liu, and Chang Huang. 2022. Maptr: Structured modeling and learning foronline vectorized hd map construction. arXiv preprint arXiv:2208.14437 (2022). Bencheng Liao, Shaoyu Chen, Yunchi Zhang, Bo Jiang, Qian Zhang, Wenyu Liu,Chang Huang, and Xinggang Wang. 2023. Maptrv2: An end-to-end frameworkfor online vectorized hd map construction. arXiv preprint arXiv:2308.05736 (2023).",
  "David Pannen, Martin Liebner, and Wolfram Burgard. 2019. Hd map changedetection with a boosted particle filter. In 2019 International Conference on Roboticsand Automation (ICRA). IEEE, 25612567": "Lang Peng, Zhirong Chen, Zhangjie Fu, Pengpeng Liang, and Erkang Cheng.2023. BEVSegFormer: Birds Eye View Semantic Segmentation From ArbitraryCamera Rigs. In Proceedings of the IEEE/CVF Winter Conference on Applications ofComputer Vision. 59355943. Limeng Qiao, Wenjie Ding, Xi Qiu, and Chi Zhang. 2023. End-to-End Vector-ized HD-Map Construction With Piecewise Bezier Curve. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition. 1321813228.",
  "Andrew Tao, Karan Sapra, and Bryan Catanzaro. 2020. Hierarchical multi-scaleattention for semantic segmentation. arXiv preprint arXiv:2005.10821 (2020)": "Ashley Varghese, Jayavardhana Gubbi, Akshaya Ramaswamy, and P Balamuralid-har. 2018. ChangeNet: A deep learning architecture for visual change detection.In Proceedings of the European conference on computer vision (ECCV) workshops.00. Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, YangZhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, et al. 2020. Deephigh-resolution representation learning for visual recognition. IEEE transactionson pattern analysis and machine intelligence 43, 10 (2020), 33493364. Deguo Xia, Jizhou Huang, Jianzhong Yang, Xiyan Liu, and Haifeng Wang. 2022.DuARUS: Automatic Geo-object Change Detection with Street-view Imageryfor Updating Road Database at Baidu Maps. In Proceedings of the 31st ACMInternational Conference on Information & Knowledge Management. 35653574. Deguo Xia, Xiyan Liu, Wei Zhang, Hui Zhao, Chengzhou Li, Weiming Zhang,Jizhou Huang, and Haifeng Wang. 2022. DuTraffic: Live traffic condition pre-diction with trajectory data and street views at Baidu maps. In Proceedings ofthe 31st ACM International Conference on Information & Knowledge Management.35753583. Deguo Xia, Weiming Zhang, Xiyan Liu, Wei Zhang, Chenting Gong, JizhouHuang, Mengmeng Yang, and Diange Yang. 2024. DuMapNet: An End-to-EndVectorization System for City-Scale Lane-Level Map Generation. In Proceedingsof the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.60156024. Congxi Xiao, Jingbo Zhou, Yixiong Xiao, Jizhou Huang, and Hui Xiong. 2024.ReFound: Crafting a Foundation Model for Urban Region Understanding uponLanguage and Visual Foundations. In Proceedings of the 30th ACM SIGKDD Con-ference on Knowledge Discovery and Data Mining. 35273538. Jianzhong Yang, Xiaoqing Ye, Bin Wu, Yanlei Gu, Ziyu Wang, Deguo Xia, andJizhou Huang. 2022. DuARE: Automatic Road Extraction with Aerial Imagesand Trajectory Data at Baidu Maps. In Proceedings of the 28th ACM SIGKDDConference on Knowledge Discovery and Data Mining. 43214331."
}