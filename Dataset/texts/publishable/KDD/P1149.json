{
  "ABSTRACT": "It is commonly perceived that fake news and real news exhibitdistinct writing styles, such as the use of sensationalist versus ob-jective language. However, we emphasize that style-related featurescan also be exploited for style-based attacks. Notably, the adventof powerful Large Language Models (LLMs) has empowered mali-cious actors to mimic the style of trustworthy news sources, doingso swiftly, cost-effectively, and at scale. Our analysis reveals thatLLM-camouflaged fake news content significantly undermines theeffectiveness of state-of-the-art text-based detectors (up to 38%decrease in F1 Score), implying a severe vulnerability to stylisticvariations. To address this, we introduce SheepDog, a style-robustfake news detector that prioritizes content over style in determin-ing news veracity. SheepDog achieves this resilience through (1)LLM-empowered news reframings that inject style diversity into thetraining process by customizing articles to match different styles;(2) a style-agnostic training scheme that ensures consistent veracitypredictions across style-diverse reframings; and (3) content-focusedveracity attributions that distill content-centric guidelines fromLLMs for debunking fake news, offering supplementary cues andpotential intepretability that assist veracity prediction. Extensiveexperiments on three real-world benchmarks demonstrate Sheep-Dogs style robustness and adaptability to various backbones. 1",
  "KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08": "A 33-year-old father from the U.K. is completely cancer-free, but not because of chemotherapy or radiation. he successfully eliminated this cancer on his own by taking therapeutic doses of cannabis oil In a remarkable turn of events, a 33-year-old father from the United Kingdom has defied medical expectations and overcome terminal bowel cancer without the use of chemotherapy or radiation. took matters into his own hands and found an unconventional solution to his dire situation: therapeutic doses of cannabis oil",
  "INTRODUCTION": "Psychological theories, such as the Undeutsch hypothesis , sug-gest that genuine and fake statements exhibit distinct linguisticstyles. Indeed, reputable news sources uphold journalistic integrity,emphasize accuracy and fact-checking, and maintain a balancedtone . In contrast, unreliable outlets often resort to sensation-alism, lack credible sources, and may exhibit partisan biases .Building upon these stylistic differences, recent advances in auto-mated fake news detection have incorporated sentiment features to enhance the detector, and highlighted the significance ofstyles in discerning between hyperpartisan news and well-balancedmainstream reporting .While style-related features serve as key indicators in identify-ing fake news, they also offer a direct avenue for malicious usersto conduct style-based attacks. This problem is exacerbated bythe advent of powerful Large Language Models (LLMs) ,whose unprecedented capabilities for reasoning and generativetasks bridges the gap between machine-generated andhuman-written news. Consequently, malicious actors now possessthe capability to mimic the style of reputable news sources, in anattempt to evade automated detection. As shown in , using",
  "KDD 24, August 2529, 2024, Barcelona, SpainJiaying Wu, Jiafeng Guo, and Bryan Hooi": ": SheepDog significantly outperforms competitive baselines on four adversarial test settings under LLM-empoweredstyle attacks (formulated in .1), in terms of F1 Score (%) . Bold (underlined) values indicate the best overall (baseline)performance. Statistical significance over the most competitive baselines, computed using the Wilcoxon signed-rank test ,is indicated with ( < .01). (G1: text-based fake news detectors; G2: LMs fine-tuned to the fake news detection task; G3: LLMs)",
  "RELATED WORK": "Fake News Detection. Automated fake news detection has been ex-plored using a wide range of neural architectures . Apartfrom extracting lexical and sentiment features within thenews article text, many methods incorporate auxiliary featuresto supplement veracity prediction, including user comments ,news environments , knowledge bases , temporal pat-terns from users , and social graphs . Recent studiesalso seek to address challenges including temporal shift , en-tity bias and domain shift in fake news detectionscenarios. In this work, we adopt a text-based perspective, specifi-cally focusing on enhancing the robustness of fake news detectorsagainst stylistic variations.Adversarial Attack on Fake News Detectors. Investigating thevulnerabilities of fake news detectors is central to improving theirreal-world applicability. Hence, existing efforts have studied the impact of different attacks from multiple aspects,including manipulation of social engagements and userbehavior , fact distortion , subject-object exchange , andblocking of data availability . However, the impact of writingstyles remains underexplored. To bridge this gap, we investigatethe resilience of text-based detectors against LLM-empowered styleattacks, and propose a style-agnostic solution.LLM Capabilities and Misinformation. LLMs havedemonstrated remarkable reasoning capabilities that even match orsurpass human performance in certain scenarios . However,the impressive strengths of LLMs have also attracted increasingattention towards LLM-generated misinformation . Recent in-vestigations have found that LLMs can act as high-quality misin-formation generators , and that LLM-generated mis-information is generally harder to detect . On a related front,recent work explore the role of LLMs as fact-checkers and fake news detectors , and leverage the commonsense rea-soning capabilities to elicit supplementary explanations from LLMs that facilitate a wide range of tasks. Although wealso instruct an LLM to generate style-related adversarial articles,our goal is to simulate real-world scenarios where news are pre-sented in diverse styles. Additionally, instead of leveraging LLMsto make veracity judgments that distinguish false information fromthe truth , in this work, we investigate the role ofLLMs in enhancing the style robustness of text-based fake newsdetectors, specifically through injecting style-diverse reframingsand content-centric cues into the training process.",
  "Fake News in Sheeps Clothing: Robust Fake News Detection Against LLM-Empowered Style AttacksKDD 24, August 2529, 2024, Barcelona, Spain": ".3), we present a case study based on a fake news articlefrom the LUN test set. As shown in , the article falsely claimsthe effectiveness of cannabis oil in treating cancer, aiming to mis-lead readers, despite contradicting established medical knowledge.While the baseline RoBERTa detector correctly flags the original ar-ticle as fake news, it misclassifies two style-transformed adversarialarticles as real news. In contrast, SheepDog accurately identifies theoriginal article as fake news, a prediction that remains consistentfor its two adversarial counterparts. Remarkably, leveraging thesoftmax-converted probabilities from attribution-level predictionscores (Eq. 5), SheepDog consistently identifies \"false and mislead-ing information\" as the top-predicted attribution for debunking fakenews. This style robustness is invaluable for practitioners seekingto comprehend the rationale behind each flagged fake news, aidingin human verification and assessment of prediction reliability.",
  "Attack Formulation": "The impressive capabilities of LLMs enable malicioususers to disguise fake news with restyling prompts, resulting incamouflaged articles that closely resemble reliable sources. In thiswork, we explore a direct form of style-based attack utilizing newspublisher names (e.g., CNN). These names possess distinct stylesthat can be readily adopted by producers of fake news, makingthem a likely occurrence in real-world scenarios.To simulate the adversarial situations where news articles arerestyled in relation to various publishers, we manipulate the stylesof both trustworthy and unreliable news. Specifically, among thetest samples, we utlize an LLM to rephrase real news in the styleof tabloids, and fake news in the style of mainstream sources. Ourgeneral prompt format is shown as follows:",
  "Style-Related Detector Vulnerability": "Automated fake news detection becomes increasingly difficult againstLLM-empowered style attacks. In this subsection, we conduct pre-liminary analysis on real-world new articles to evaluate the influ-ence of writing styles on text-based detectors. Our analysis is basedon the FakeNewsNet benchmark (consisting of PolitiFact andGossipCop datasets) and the Labeled Unreliable News (LUN) dataset, with dataset descriptions relegated to .1.1 and .Specifically, we investigate the following question: To what extentcan text-based fake news detectors withstand LLM-empoweredstyle attacks?In , we examine 13 representative text-based detectorsunder both original and adversarial settings (detailed method de-scriptions are provided in .1.2). These detectors encompassthree categories: (1) text-based fake news detectors with diverse task-specific architectures, including Recurrent Neural Networks (RNNs), Convolutional Neural Networks (CNNs) , Graph Neural : Under LLM-empowered style attacks, existing text-based fake news detectors suffer severe performance deterio-ration in terms of F1 Score (%). (O: original; A (): gap betweenoriginal unperturbed performance and adversarial perfor-mance on the test set formulated in .1).",
  "GPT-3.5 69.6127.4856.3016.7179.9720.34InstructGPT 64.5920.6950.389.1368.1611.39LLaMA2-13B 63.1529.9153.5427.7570.9738.33": "Networks (GNNs) applied to document graphs , and Trans-formers ; (2) Fine-tuned LMs on the fakenews detection benchmark datasets; and (3) LLMs withzero-shot prompting. Few-shot and fine-tuned LLM experimentsare relegated to Appendix A.We evaluate the robustness of detectors against LLM-empoweredstyle attack based on their performance under the adversarial set-ting outlined in .1. Our empirical results in andAppendix A yield the following two implications: Observation 1 (Style-Related Vulnerability of Fake NewsDetectors). State-of-the-art text-based fake news detectors are sus-ceptible to LLM-empowered style attacks. This susceptibility resultsin substantial performance degradation,with an F1 Score decline ofup to 38.3% on the adversarial test set. Observation 2 (Insufficiency of LLMs as Fake News De-tectors). LLMs, despite their impressive zero-shot capabilities asgeneral-purpose foundation models, exhibit inferior detection perfor-mance compared to text-based fake news detectors and pre-trainedLMs fine-tuned specifically for fake news detection. Our two findings suggest a fundamental limitation of text-basedfake news detectors in achieving robust veracity predictions againststylistic variations. Detectors overly influenced by styles struggleto reliably differentiate between real and fake news, and even thepowerful LLMs may prove inadequate for the specific demands offake news detection. In the dynamic digital landscape, the styles ofnews articles evolve rapidly, while the accessibility for malicioususers to manipulate style using LLMs exacerbates these variations.Therefore, for effective deployment, a fake news detector mustprioritize the assessment of news content over style. This objectivemotivates our subsequent innovations toward a style-agnostic fakenews detection approach.",
  "PROPOSED APPROACH": "Building upon our empirical findings on the style-related vulnera-bility of text-based fake news detectors, we introduce SheepDog,a style-agnostic detector that reliably assesses news veracity. Asoverviewed in , SheepDog obtains style robustness fromtwo core objectives within a multi-task learning paradigm: (1) style-agnostic training, which flexibly adapts an LM to the fake newsclassification task, while ensuring consistent veracity predictionsacross a diverse array of LLM-empowered news reframings; and (2)content-focused veracity attribution prediction, which lever-ages veracity-related insights from LLMs to inform model pre-dictions. To enhance usability and composability, we design ourmethod to be simple and modular, allowing it to be integrated withany LM and LLM backbone.",
  "LLM-Empowered News Reframing": "As suggested by our Observation 1, text-based fake news detectorsfitted to style-consistent real and fake articles exhibit limited adapt-ability against stylistic variations. To overcome this limitation, ourkey idea is to inject style diversity into the training stage througha process we term reframing, where each news article is presentedin various styles.SheepDogs reframing strategy is driven by two sub-goals: (1) en-compassing a wide range of styles and (2) maintaining the integrityof the original news content. LLMs, capable of following complexreal-world instructions , inherently meet both criteria. This isfurther validated by our analysis in Appendix C, where LLMs gener-ally prove effective in transforming the tone of news articles whilepreserving content consistency. Hence, for each training article, wegenerate a series of prompts, each comprising the news article anda style-oriented reframing instruction. The general structure of theprompt is as follows, with a detailed example presented in :",
  "Rewrite the following article in a / an [specified] tone:[news article]": "To generate news expressions that simulate both reliable andunreliable sources, we establish a set of four general style-orientedadjectives for the prompt: objective and professional and neu-tral to emulate reliable sources, and emotionally triggering andsensational for unreliable sources. During the training stage, forlabeled news article P, we randomly select one reliable-stylereframing prompt and one unreliable-style reframing prompt togenerate diverse expressions. Through querying the LLM, we ob-tain two corresponding reframings: one reliable-style reframingdenoted as , and one unreliable-style reframing denoted as .",
  "Style-Agnostic Training": "A style-robust fake news detector must be capable of discerningthe veracity of news articles based on their content, without beinginfluenced by stylistic features. To this end, we introduce a stylealignment objective that ensures close alignment among the veracitypredictions of news article , its reliable-style reframing , and itsunreliable-style reframing . This objective is derived as follows.Let M be a pre-trained Language Model (LM) such as RoBERTa. Employing an LM as the backbone of the detector offers advan-tages, as LMs can be readily fine-tuned for the fake news detectiontask, which enables them to effectively extract salient task-specificfeatures from the news content. Through M, based on , and , we acquire article representations h R, and reframing repre-sentations h, h R:",
  "Content-Focused Veracity Attributions": "In addition to tuning the LM backbone with the style alignmentobjective, which discounts style-related features and encouragesstyle-robust predictions, we further propose to integrate auxiliaryveracity-related knowledge and reasoning to inform veracity pre-dictions. To achieve this goal, leveraging the impressive zero-shotreasoning capabilities of general-purpose LLMs serves as apromising solution.Specifically, we elicit content-focused veracity attributions froman LLM, which provides explanatory outputs on why each fakenews article in the training set is flagged as fake. Our promptconsists of a fake news article and a predefined set C of content-oriented rationales for debunking fake news (e.g., lack of crediblesources and false or misleading information; detailed rationalesare described in Appendix B.3). This prompt efficiently leveragesthe LLMs reasoning capabilities and prior knowledge to identifycharacteristics associated with fake news, referencing the rationalesin C. The general prompt format is as follows:",
  "Article: [fake news article]Question: [given a list of content-centric rationales fordebunking fake news, ask the LLM to identify rationalesfulfilled by the fake news article]": "Upon querying the LLM, we obtain a list of veracity attributionsbased on the input article. These attributions are then convertedinto |C|-dimensional pseudo-labels, where each rationale in C isrepresented by a distinct binary label. For a given news article P, this process yields pseudo-labels s R| C|, which con-tains supplementary veracity-related information. Similarly, forreframings and , we obtain pseudo-labels s, s R| C|, re-spectively. Notably, since C focuses solely on fake news indicators,the pseudo-labels for real news and its reframings are uniformlyset to all zeros.To distill the veracity-informed knowledge from these attribu-tions, we introduce a multi-label attribution prediction objective.",
  "Experimental Setup": "6.1.1Datasets. We evaluate our approach on three widely-usedreal-world benchmark datasets: the FakeNewsNet public bench-mark , which consists of the PolitiFact and GossipCop datasets,and the Labeled Unreliable News (LUN) dataset . de-scribes the dataset statistics. PolitiFact and LUN center on politicaldiscourse, while GossipCop focuses on celebrity gossip. For theLUN dataset, which further classifies unreliable news into threesub-categories: satire, hoax, and propaganda, we conduct binaryclassification between reliable (real) and unreliable (fake) news,and ensure an equal number of unreliable news from each of thesefine-grained categories. To better simulate real-world scenarios, wefollow prior work and adopt temporal data splitting on Politi-Fact and GossipCop, where temporal information is available. Themost recent 20% real and fake news articles constitute the test set,and the remaining 80% articles posted earlier serve as the trainingset. We adopt random 80/20 training / test splits on LUN. 6.1.2Baselines. We benchmark SheepDog against thirteen repre-sentative baseline methods, which can be categorized as:Text-based fake news detectors (G1) employ neural archi-tectures tailored specifically for the fake news detection task. dE-FEND\\c is a variant of dEFEND based on the news article text that adopts RNN-based hierarchical co-attention. SAFE\\v is a text-based variant of SAFE that leverages a CNN-based architectureto learn semantic features. SentGCN encodes veracity-relatedsentence interaction patterns within each article using a GNN, andDualEmo incorporates emotion features from news publishersand news comments. As our SheepDog approach does not involveuser comments, we implement DualEmo on a BERT-base back-bone with publisher emotion features for a fair comparison.Fine-tuned LMs (G2) adapts pre-trained LMs to the fake newsdetection task, and has proven effective in handling misinformationscenarios . In addition to three widely-recognized LMs, namelyBERT , RoBERTa , and DeBERTa , we include UDA, a representative BERT-based model that employs diverse textaugmentations to yield consistent model predictions against inputnoise. We also select two methods under the popular prompting par-adigm: PET , which converts textual inputs into cloze questionsthat contain a task description; and KPT, which expands thelabel word space with varied class-related tokens. For a fair compar-ison, as our proposed approach does not involve unlabeled articles,we implement UDA using consistency training on the supervisedtraining data, and exclude the self-training and PLM ensemble com-ponents for PET. All methods in this category are implementedwith base version LMs, in line with our approach.LLMs (G3) conduct zero-shot veracity prediction. We selectthree representative baseline LLMs: GPT-3.5 , InstructGPT, and LLaMA2-13B , detailed in Appendix B.1. 6.1.3Implementation Details. We implement SheepDog and itsvariants based on PyTorch 1.10.0 with CUDA 11.1. We utilize pre-trained RoBERTa-base weights from HuggingFace Transformers4.13.0 . The LM backbone for SheepDog was configured with amaximum sequence length of 512, a batch size of 4, and a learningrate of 2 105. We prompt GPT-3.5 to generate news reframings,",
  "Robustness Against Style Attacks": "We establish a series of LLM-empowered style attacks to assessSheepDogs robustness. Following our prompt template formulatedin .1, in the place of [publisher name], we select NationalEnquirer and The Sun to camouflage real news, and CNN andThe New York Times for fake news, according to publisher popu-larity. This yields 22 = 4 distinct adversarial test sets, labeled as Athrough D in . Note that we report the results of SheepDogon adversarial set A in all other subsections, unless otherwisespecified. compares the performance of SheepDog with competi-tive baselines across adversarial test sets A through D under LLM-empowered style attacks. We can observe that: (1) All baselinemethods are highly susceptible to LLM-empowered style attacks.This vulnerability suggests that existing methods exhibit a tendencytowards over-fitting on style-related attributes. (2) UDA, whichleverages back-translation to generate diverse text augmentations,consistently demonstrates higher robustness compared to its BERTbackbone. This suggests the efficacy of incorporating augmenta-tions. However, UDA still struggles to fully adapt to significantstylistic variances in the input articles. This limitation may be at-tributed to the fact that augmentations through back-translationalone cannot provide sufficient variance. (3) On the challengingadversarial test sets of LUN, CNN-based SAFE\\v and GNN-basedSentGCN are more robust than LM-based baselines, which suggeststhat LMs can be more prone to overfit to style-related features. (4)SheepDog outperforms the most competitive baseline by significantmargins. Across the three benchmarks, this improvement averagesto 2.59%, 2.77%, and 15.70% across the four adversarial test sets, interms of F1 score. The significantly greater improvements on LUNmight be attributed to dataset-specific stylistic attributes, towardwhich we present a detailed discussion in .8.",
  "Effectiveness on Unperturbed Articles": "A desirable fake news detector should achieve style robustnessunder adversarial settings without compromising its effectivenessunder the unperturbed setting. Our empirical results, presented in, demonstrate that SheepDog excels in this regard. Whentested on the original, unaltered articles, SheepDog consistentlymatches (on PolitiFact and GossipCop) or surpasses (on LUN) theperformance of the most competitive baseline, in terms of bothaccuracy and F1 score. Similar to our observation (4) in .2, : SheepDog achieves performance (%) that is compara-ble or superior to competitive baselines on the unperturbedoriginal test sets. Bold (underlined) values indicate the bestoverall (baseline) performance, and indicates < .01 usingthe Wilcoxon signed-rank test .",
  "Adaptability to LM / LLM Backbones": "To assess the flexibility of SheepDog, we evaluate the performanceof SheepDog combined with three representative LMs: RoBERTa,BERT and DeBERTa. We also evaluate RoBERTa-based SheepDogcombined with two representative LLMs: the closed-source GPT-3.5and the open-source LLaMA2-13B.As demonstrated in , SheepDog (1) substantially enhancesthe performance of each respective LM backbone. Additionally, asshown in , SheepDog (2) also achieves superior style ro-bustness when utilizing both closed-source and open-source LLMs.This adaptability highlights SheepDogs style robustness from style-invariant training and content-focused attribution prediction, im-plying its practical utility in real-world scenarios where differentLMs and LLMs may be preferred or more readily available.",
  "SheepDog-A, which excludes content-focused veracity attribu-tions and the attribution prediction component": "Results in suggest that: (1) SheepDog-R without news re-framings only yields slight improvements over fine-tuned RoBERTa,which suggests the key role of diverse reframings in SheepDogs ro-bustness. (2) While the improvement of SheepDog over SheepDog-A may seem slight, incorporating veracity attributions assists inguiding the model to prioritize content over style. Furthermore,SheepDogs attribution predictor equips the framework with ex-planatory outputs during inference stage, facilitating easier humanverification in real-world scenarios (see and .7 fora concrete illustration of this functionality). (3) SheepDog, utilizingone single layer for veracity prediction and attribution predictions,slightly outperforms the variant employing 2-layer MLPs. Thissuggests that the expressiveness of LMs, harnessed through ourproposed objectives, yields article representations that contain richindicators related to both attributions and veracity.",
  "SheepDog80.9974.4585.63w/ R179.0274.2277.42w/ R279.9374.1686.18w/ R380.3673.5576.77w/ R479.7174.0185.55": "A 33-year-old father from the U.K. is completely cancer-free, but not because of chemotherapy or radiation. he successfully eliminated this cancer on his own by taking therapeutic doses of cannabis oil In a remarkable turn of events, a 33-year-old father from the United Kingdom has defied medical expectations and overcome terminal bowel cancer without the use of chemotherapy or radiation. took matters into his own hands and found an unconventional solution to his dire situation: therapeutic doses of cannabis oil",
  "Discussion: Why is SheepDog YieldingGreater Performance Gains on LUN?": "SheepDog shows significantly greater performance improvementson LUN compared to PolitiFact and GossipCop in both adversarial(.2) and original unperturbed settings (.3). Specif-ically, it achieves [A] significant improvements on the originalunperturbed LUN test set while maintaining performance compara-ble to the best baseline on PolitiFact and GossipCop (); and[B] notably greater improvements on LUN compared to PolitiFactand GossipCop on style-based adversarial test sets ().These phenomena can be attributed to the unique style-relatedfeatures of LUN, which include distinct writing styles of (1) indi-vidual news publishers and and (2) different news types. (e.g., hoax).Unlike PolitiFact and GossipCop, LUNs publishers (i.e., news sites)in the training and test sets do not overlap , creating an inherentdistribution shift between training and test data. Furthermore, asdescribed in .1.1, the fake news articles in LUN encompasssatire, hoax, and propaganda with distinctive writing styles. As aresult, fake news detectors trained on LUN are expected to be morereliant on writing style.Recall that our Observation 1 reveals the heavy reliance of ex-isting text-based detectors on styles rather than news content forveracity prediction. Trained on LUN, the baseline models becomeoverly reliant on styles specific to both publishers and news types,which potentially explains [A] and [B]: On the original unperturbed LUN test set (), publisher-specific style features used by baseline models fail to generalizeto test articles, as test articles are produced by news sites notincluded in the training data. In contrast, SheepDog, being style-agnostic, remains unaffected by changes in news publisher stylesand yields significant improvements. On the adversarial LUN test sets (), both publisher-specificand news type-specific style features utilized by baselines failto generalize. Notably, LLM-empowered style attacks reversethe styles of both reliable and unreliable news (.1).These style variations make type-specific style features detri-mental for veracity prediction. In contrast, SheepDog achievesstyle robustness through LLM-empowered news reframings andcontent-focused veracity attributions, thereby reliably detectingfake news.",
  "CONCLUSION AND FUTURE WORK": "In this paper, we address the critical aspect of style-related ro-bustness in fake news detection. Motivated by our empirical find-ing on the susceptibility of state-of-the-art text-based detectors toLLM-empowered style attacks, we introduce SheepDog, a style-agnostic fake news detector that emphasizes content veracity overstyle. Jointly leveraging the strengths of task-specific LM backbonesand versatile general-purpose LLMs, SheepDog adopts a multi-tasklearning paradigm, which integrates style-agnostic training andcontent-focused veracity attribution prediction. Extensive experi-ments on three real-world benchmarks demonstrate SheepDogsrobustness and effectiveness across various style-based adversarialsettings, news reframing prompts, and representative backbones.Moving forward, SheepDog lays a solid foundation for developingmore resilient and adaptable models in the ever-changing onlinelandscape, and demonstrates promising potential to be further ex-tended to multi-modal scenarios.",
  "Beizhe Hu, Qiang Sheng, Juan Cao, Yuhui Shi, Yang Li, Danding Wang, and PengQi. 2024. Bad Actor, Good Advisor: Exploring the Role of Large Language Modelsin Fake News Detection. In AAAI. 2210522113": "Beizhe Hu, Qiang Sheng, Juan Cao, Yongchun Zhu, Danding Wang, ZhengjiaWang, and Zhiwei Jin. 2023. Learn over Past, Evolve for Future: ForecastingTemporal Trends for Fake News Detection. In ACL. 116125. Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Jingang Wang, Juanzi Li,Wei Wu, and Maosong Sun. 2022. Knowledgeable Prompt-tuning: IncorporatingKnowledge into Prompt Verbalizer for Text Classification. In ACL. 22252240. Shengding Hu, Ning Ding, Huadong Wang, Zhiyuan Liu, Jingang Wang, Juanzi Li,Wei Wu, and Maosong Sun. 2022. Knowledgeable Prompt-tuning: IncorporatingKnowledge into Prompt Verbalizer for Text Classification. In ACL. 22252240.",
  "Thai Le, Suhang Wang, and Dongwon Lee. 2020. MALCOM: Generating MaliciousComments to Attack Neural Fake News Detection Models. In ICDM. 282291": "Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, OmerLevy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: ARobustly Optimized BERT Pretraining Approach. arXiv:1907.11692 [cs.CL] Jason Lucas, Adaku Uchendu, Michiharu Yamashita, Jooyoung Lee, ShauryaRohatgi, and Dongwon Lee. 2023. Fighting Fire with Fire: The Dual Role of LLMsin Crafting and Detecting Elusive Disinformation. In EMNLP. 1427914305.",
  "Rowan Zellers, Ari Holtzman, Hannah Rashkin, Yonatan Bisk, Ali Farhadi,Franziska Roesner, and Yejin Choi. 2019. Defending Against Neural Fake News.In NeurIPS, Vol. 32": "Amy X. Zhang, Aditya Ranganathan, Sarah Emlen Metz, Scott Appling, Con-nie Moon Sehat, Norman Gilmore, Nick B. Adams, Emmanuel Vincent, JenniferLee, Martin Robbins, Ed Bice, Sandro Hawke, David Karger, and An Xiao Mina.2018. A Structured Response to Misinformation: Defining and Annotating Credi-bility Indicators in News Articles. In Companion Proceedings of WWW. 603612.",
  "ADISCUSSION: EFFECT OF REFRAMINGS ONLLM STYLE ROBUSTNESS": "This section investigates the effects of incorporating our style-diverse news reframings (.1) on LLM style robustness.Following the experimental setup for evaluating style robustness(), we report results on adversarial set A (formulationdescribed in ) unless otherwise specified. We explore twomethods for adapting LLMs to diverse news styles: (1) in-contextlearning and (2) fine-tuning, with prompt templates and LLMconfigurations detailed in Appendix B.1. To mitigate randomness,we present averaged metrics from three runs of each approach.In-Context Learning. compares a zero-shot GPT-3.5detector with the following three in-context learning variants:(1) GPT-3.5+ICL-2, which incorporates 2 randomly selected in-context samples (1 real and 1 fake). (2) GPT-3.5+ICL-2-R, whichincorporates the same 2 in-context samples as GPT-3.5+ICL-2, en-riched with style-diverse reframings. For each in-context sample,we randomly select one reliable-style reframing and one unreliable-style reframing. (3) GPT-3.5+ICL-4, which incorporates 4 ran-domly selected in-context samples (2 real and 2 fake).",
  "GPT-3.542.1339.5959.63+ ICL-238.5738.8857.51+ ICL-2-R41.7641.8360.29+ ICL-442.3541.4760.25": "Results in indicate three key findings: (1) LLMs benefitfrom more in-context samples, as GPT-3.5+ICL-4 outperforms GPT-3.5+ICL-2. (2) Incorporation of news reframings effectively enhancesLLM style robustness, as shown by the consistent gains of GPT-3.5+ICL-2-R over GPT-3.5+ICL-2. (3) On the fake news detection task,LLM in-context learning does not offer clear benefits over LLM zero-shot. The long sequence lengths of news articles limit the numberof in-context demonstrations, resulting in insufficient context andoverly lengthy prompts that LLMs struggle to process.Fine-Tuning. compares a zero-shot LLaMA2-13B de-tector with the following two fine-tuned variants: (1) LLaMA2-13B+FT, which fine-tunes LLaMA2 using the original trainingarticles. (2) LLaMA2-13B+FT-R, which fine-tunes LLaMA2 usingthe original training articles and their style-diverse reframings. Foreach article, we randomly incorporate one reliable-style reframingand one unreliable-style reframing as fine-tuning data.",
  "Both LLaMA2 variants are fine-tuned using QLoRA for 1epoch with a batch size of 16 and a learning rate of 1 104. From": ", we observe: (1) Fine-tuning generally enhances task-specificLLM capabilities on fake news detection, as indicated by consistentimprovements of LLaMA2-13B+FT over LLaMA2-13B. (2) Incorpo-rating style-diverse news reframings as fine-tuning samples furtherimproves style robustness, as indicated by consistent improvementsof LLaMA2-13B+FT-R over LLaMA2-13B+FT. (3) LLaMA2-13B+FT-R still falls short compared to GPT-3.5 on the LUN adversarial testset and performs worse than task-specific detectors and fully fine-tuned LMs in . This suggests the need for larger, task-specificcorpora for fully adapting LLMs to fake news detection, furtherhighlighting our motivation for leveraging LLM general-purposecapabilities in a zero-shot manner, which are reasonably strong andmore readily available.",
  "BLLM PROMPTING CONFIGURATIONSB.1LLM Baselines": "In section 6.1.2, we select three representative LLMs as fake news de-tection baselines: GPT-3.5 (model name: gpt-3.5-turbo-0301),InstructGPT (model name: gpt-3.5-turbo-instruct), andLLaMA2-13B (model name: Llama-2-13b-chat-hf).For GPT-3.5 and InstructGPT, we use their APIs from OpenAI,and set the temperature to 0 for stable veracity predictions. ForLLaMA2-13B, we employ model weights from HuggingFace Trans-formers version 4.31.0, with do_sample set to False for greedydecoding. All models adopt the following prompt for zero-shot fakenews detection:",
  "B.2Obtaining SheepDogs News Reframings": "Recall from .1 that we generate reliable-style reframingsand unreliable-style reframings with GPT-3.5 for each labeled newsarticle. Among the four prompt templates presented below, we usethe first two templates for reliable-style reframings, and the othertwo for unreliable-style reframings.During reframing generation, we set the temperature to 0.7 andlimit the maximum number of response tokens to 512. See for a detailed reframing example.",
  "B.3Obtaining SheepDogs Veracity Attributions": "In .3, we use an LLM to elicit auxiliary content-centric in-formation directly related to news veracity. Specifically, we promptthe LLM to provide explanatory outputs for each fake news articlein the training set, based on predefined content-focused rationalesaimed at debunking fake news.We draw from existing literature, which commonly emphasizestwo key aspects: (1) sources of information , and (2)correctness of news content . Inspired by these insights,we devise four rationales: Source-related rationales: [A] lack of credible sources; and [B]inconsistencies with reputable sources. These rationales are in-formed by prior research emphasizing the importance of rep-utable sources in validating conclusions and correcting falseinformation . Content-related rationales: [C] false or misleading information;and [D] biased opinion. Fake news, defined as intentionally andverifiably false information , often manipulates biasedopinions to exploit cognitive vulnerabilities in news consumers.Consequently, we devise [C] in alignment with the definition offake news, and [D] to represent a common strategy employedby fake news producers. Our four rationales cover the key aspects of source- and content-related indicators in debunking fake news. We utilize the followingprompt to obtain content-focused veracity attributions, and set thetemperature to 0 to ensure stability. An example is presented in. Article: [fake news article]Question: Which of the following problems does this article have?Lack of credible sources, False or misleading information, Biasedopinion, Inconsistencies with reputable sources. If multiple op-tions apply, provide a comma-separated list ordered from most toleast related. Answer No problems if none of the options apply.",
  "CANALYSIS ON CONTENT CONSISTENCY OFLLM-EMPOWERED NEWS REFRAMINGS": "LLM-empowered news reframings play a key role in achievingstyle robustness. provides a comparison between a newsarticle and its reliable-style reframing, illustrating concretely theimpressive capability of LLMs to introduce different tones whilepreserving the news content.To offer a more comprehensive assessment of content consis-tency between the original news article and its reframings, weinvestigate claim entailment for a straightforward and quantifiableestimation. Specifically, the original article should ideally entail thecentral factual claims within its reframing, and vice versa.Given that news articles exhibit significantly longer sequencesand more complex logical structures compared to the sentence pairsin natural language inference (NLI) benchmarks (e.g., SNLI andMultiNLI ), we opt against utilizing NLI models pre-trained onthese benchmarks. Instead, we instruct a GPT-3.5 model to extractclaims and infer claim entailment. The prompt template for claimextraction is as follows:",
  "Querying the LLM yields a succinct summarization of the arti-cles central factual claim, typically composed of several sub-claims.An example response is provided as follows:": "Response Example for Claim Extraction: Financial experts areconcerned about the negative impact of Chinas undervalued yuanon both Asia and the United States. They are calling on regionalgovernments and the Group of 20 leaders to take action to preventpotential currency and trade wars. The experts emphasize the needfor neighboring countries to urge China to relax its exchange ratecontrols in order to address the global current account imbalance.They also highlight the adverse effects of US monetary easingand Chinas low exchange rate on emerging market economies.The experts are urging the G20 to address the currency problemat its upcoming summit in South Korea and to oppose unilateraldevaluation moves and support currency stability.",
  "GossipCop86.2089.17LUN89.2287.53": "As shown in , the proportions of claim entailment rangefrom 86.20% to 89.22% across both datasets, suggesting a reasonablyhigh consistency between the central factual claims presented in theoriginal news articles and their reframings. This consistency furthervalidates the effectiveness of our reframing approach in preservingthe core content of news while injecting stylistic variations.",
  "At the Democratic National Convention, Michelle Obama triedto use her daughters as shining examples of just how far Amer-ica has come": "Recently, reports have emerged regarding the behavior ofMalia Obama, daughter of former President Barack Obamaand Michelle Obama. At the Democratic National Conven-tion, Michelle Obama showcased her daughters as symbols ofprogress in America. But the fact is that the young Obamas are pushing the limits asany teenager does and probably even further.However, it appears that the young Obamas, like manyteenagers, are testing boundaries and possibly going beyondthem.",
  "According to sources, Malia Obama was seen at a gatheringin Marthas Vineyard that was eventually disbanded by lawenforcement due to noise complaints": "The first daughter was immediately rushed from the party bySecret Service before the cops arrived.The first daughter was promptly escorted away from the sceneby the Secret Service before the arrival of the police. The West Tisbury police declined to confirm if Malia was there,citing national security.West Tisbury police have neither confirmed nor denied Maliaspresence at the event, citing national security concerns.",
  "This is just one incident in a string of wild behavior on Maliaspart.This incident is just one in a series of instances where Maliasbehavior has attracted attention": "Just a month ago the first daughter came under fire when photossurfaced of her smoking marijuana at a concert.Not long ago, she faced criticism when photos emerged showingher allegedly smoking marijuana at a concert. Malia is clearly using her gap year before Harvard to party andexperiment.It appears that Malia is utilizing her gap year before attendingHarvard University as a period for socializing and experimenta-tion.",
  "Were sure he had a few choice words for her.It can be assumed that the former president had some words ofadvice or guidance for his daughter": "Clearly, a lack of respect for the law runs deep in this family.It is evident that a lack of regard for the law seems to be a recur-ring issue within this family. In conclusion, recent events raiseconcerns about the behavior of Malia Obama. These incidents,including her presence at a party disbanded by the police andalleged marijuana use, suggest a period of exploration and acertain disregard for legal boundaries.",
  ": An example of content-focused veracity attributions extracted from GPT3.5, given a fake news article as input": "PROMPT: Article: BREAKING: Obamas Daughter BUSTED By The Cops For Doing This At the Democratic National Convention, MichelleObama tried to use her daughters as shining examples of just how far America has come. But the fact is that the young Obamas are pushingthe limits as any teenager doesand probably even further. According to new reports, Malia Obama was spotted at a party in Marthas Vineyardrecently. It was eventually broken up by police because of noise complaints. The first daughter was immediately rushed from the party bySecret Service before the cops arrived. The West Tisbury police declined to confirm if Malia was there, citing national security. But the truthsurfaced anyway. This is just one incident in a string of wild behavior on Malias part. Just a month ago the first daughter came under firewhen photos surfaced of her smoking marijuana at a concert. Malia is clearly using her gap year before Harvard to party and experiment.Later, Malia and Barack were spotted strolling around a pool together having a chat. Were sure he had a few choice words for her. Clearly, alack of respect for the law runs deep in this family. Question: Which of the following problems does this article have? Lack of credible sources, False or misleading information,Biased opinion, Inconsistencies with reputable sources. If multiple options apply, provide a comma-separated list ordered frommost to least related. Answer \"No problems\" if none of the options apply."
}