{
  "ABSTRACT": "Uplift modeling has been widely employed in online marketingby predicting the response difference between the treatment andcontrol groups, so as to identify the sensitive individuals towardinterventions like coupons or discounts. Compared with traditionalconversion uplift modeling, revenue uplift modeling exhibits higherpotential due to its direct connection with the corporate income.However, previous works can hardly handle the continuous long-tail response distribution in revenue uplift modeling. Moreover,they have neglected to optimize the uplift ranking among differ-ent individuals, which is actually the core of uplift modeling. Toaddress such issues, in this paper, we first utilize the zero-inflatedlognormal (ZILN) loss to regress the responses and customize thecorresponding modeling network, which can be adapted to differentexisting uplift models. Then, we study the ranking-related upliftmodeling error from the theoretical perspective and propose twotighter error bounds as the additional loss terms to the conven-tional response regression loss. Finally, we directly model the upliftranking error for the entire population with a listwise uplift rank-ing loss. The experiment results on offline public and industrialdatasets validate the effectiveness of our method for revenue upliftmodeling. Furthermore, we conduct large-scale experiments on aprominent online fintech marketing platform, Tencent FiT, whichfurther demonstrates the superiority of our method in real-worldapplications.",
  "Work done as an intern in FiT, TencentCorresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from , August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08...$15.00",
  "Revenue Uplift Modeling; Rankability; Online Marketing": "ACM Reference Format:Bowei He, Yunpeng Weng, Xing Tang, Ziqiang Cui, Zexu Sun, Liang Chen,Xiuqiang He, and Chen Ma. 2024. Rankability-enhanced Revenue UpliftModeling Framework for Online Marketing. In Proceedings of the 30th ACMSIGKDD Conference on Knowledge Discovery and Data Mining (KDD 24),August 2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages. Uplift modeling , aiming to predict the expected difference be-tween the treatment and control response, has been widely adoptedto identify the individuals among a targeted population who can re-act positively to a particular intervention. Recently, this techniquehas been successfully deployed in many scenarios, like healthcare,finance transactions, and online marketing . Generally,the uplift modeling in online marketing can be divided into twocategories : conversion uplift modeling and revenue uplift mod-eling. The latter one is the focus of this work considering its higherapplication value and broader application scenarios.Several methods have been proposed to perform uplift modelingto infer the causal effect of a specific treatment, such as price dis-count, repayment incentive, or coupon delivery. The most commonone is the Randomized Controlled Trial (RCT) like the A/Btest for marketing, where each individual is randomly assigned tothe treatment group or the control group, thereby being indepen-dent of other covariate features. However, RCT experiments areoften expensive, time-consuming, and even harmful to platforms inmany applications. Even worse, RCT can only estimate the averageuplift effect in the whole population, far from the individual uplifteffect estimation, which is the pursuit of the current online mar-keting. Therefore, most recent works focus on learning an uplift",
  "KDD24, August 2529, 2024, Barcelona, SpainBowei He, et al": "model from the experimental data and then directly deploying it toestimate the uplift effect for studied individuals. Among them, themeta-learner methods , like S-Learner and T-Learner are thepioneer works seeking to estimate the uplift effect of personalizedtreatments on different individuals. However, they can be easilymanipulated by the sample imbalance issue between the treatmentand control group. Several tree-based methods , like CausalForest, are proposed to address this issue by adapting the split-ting criteria of conventional decision trees. Representation learningmethods are another type of dominant approach to thisissue with the development of deep neural networks especially inrecent years. They mainly balance the representation distributionsof individuals in the treatment group and control group. : The histogram for the revenue frequency distri-bution of the A/B test in our deployment platforms onlinefintech application scenario. Left: raw revenue values; Right:revenue values after the logarithmic transformation. Though achieving acceptable performance in some idealizedexperiment environments or synthetic datasets, there are still someavenues to further improve the above methods. First, few of themfocus on revenue uplift modeling, where the response is a continuousvariable rather than a simple binary one. This obviously increasesthe difficulty of precise uplift modeling. Meanwhile, this type ofuplift modeling problem often has higher practical value though lessexplored, considering that practitioners hope to increase the return(continuous response) on marketing investments in many cases.Second, most of the existing methods only work well onsynthetic datasets, where the range of responses is limited, whichis far from the real production environments, especially in financescenarios. In such cases, the expected response, like the mutual fundsales revenue, can range from zero/several dollars to several millionor even billion dollars. If directly adopting previous uplift methodsto such tasks, some extreme data points can bring huge obstaclesto model learning, thus the performance can hardly be satisfactory.Besides, the distribution of revenue response can be extremelyimbalanced. In the above case, the sales revenue of most users hardlyexceeds 10,000 USD, while only a very tiny proportion of users mayspend over 500,000 USD. These two points can be concluded as the long-tail distribution challenge, which is pretty common inonline applications, like the one shown in . Last but notleast, almost all previous methods only care about the accuracyof the uplift effect prediction for different individuals, neglectingthe ranking accuracy among them. That is, the individuals withhigher true uplift values should obtain higher predicted uplift valuescompared with those lower-uplift value individuals, though theuplift value prediction is not so precise. In fact, the rankability ofuplift models is a more serious and meaningful problem in many real-world applications, because the ultimate purpose of utilizing theuplift models is to identify the individuals who are more susceptibleto the treatment and then intervene with them differently accordingto the ranking of their uplift values. Moreover, this problem is morechallenging in scenarios with long-tail responses. Because in thelearning phase, the model will mainly pay attention to individualswith high responses, and ignore the prediction accuracy of theindividuals with lower responses. Thus, the uplift ranking confusionfor these latter individuals can be exacerbated.To address the aforementioned challenges, we propose a Ranking-Enhanced Revenue Uplift Modeling (RERUM) framework. First,to overcome the continuous value and long-tail distribution chal-lenges, we replace the conventional Mean-Squared-Error (MSE)loss with a ZILN loss for revenue response regression in treatmentand control groups. Meanwhile, an accompanying regression net-work framework is proposed to adapt to ZILN loss. Second, wemake a theoretical analysis of the uplift ranking error and proposemore stringent error bounds as additional revenue response losses,which can help enhance the models uplift ranking ability from therevenue response ranking perspective. Finally, we directly considerthe uplift ranking among different individuals in the targeted pop-ulation and propose a listwise ranking loss to explicitly optimizethe uplift models rankability.To summarize, the main contributions of this work are as follows:",
  "To directly enhance the rankability of the uplift model over thewhole population, we provide a listwise uplift ranking loss": "To demonstrate the effectiveness of our method, we conduct ex-tensive offline experiments on both public and industrial datasets.Additionally, large-scale online experiments on a fintech market-ing platform with over 400 million users are also performed.2RELATED WORKS Uplift Modeling. The uplift modeling in online marketing typi-cally comprise of two types of problems: conversion uplift modelingand revenue uplift modeling. In conversion uplift modeling , the response label is a simple 0/1 binary variable indicatingif the individual purchases the goods or takes a specific action, likeclicking the advertisement. Most of previous research concentrateson this topic. Though achieving accepting performance in somescenarios, many of them are dedicated to the up-lift value prediction, neglecting the importance of uplift rankingamong the population, which is originally the core point. Revenueuplift modeling , however, differs from the traditional",
  "Rankability-enhanced Revenue Uplift Modeling Framework for Online MarketingKDD24, August 2529, 2024, Barcelona, Spain": ": Overall performance of different methods on different uplift-ranking related metrics in various datasets. The bestmethod and best baseline on each metric are marked as bold and underlined, respectively. refers to the improvement over thebest-performing baseline. indicates the improvements over baselines are statistically significant (-test, -value 0.05). Forease of illustration, the LIFT@30 for Product dataset has been divided by 10,000.",
  "PRELIMINARIES": "We follow the Neyman-Rubin potential outcome framework toformulate the revenue uplift modeling problem. In detail, we havethe observed sample set D = {(x,,)}=1. For each individual I (|I| = ), Y R is a continuous outcome (response),x X R is a vector of covariates, and T = {0, 1} denotesthe treatment (with = 0 as the control) intervened on individual. Y, X, and T are corresponding random variables, respectively.Furthermore, Y, X, and T are the general random variables thatindicate the response, covariate, and treatment, respectively, re-gardless of the specific individual. Thus, the uplift effect of thetreatment on individual is defined as:",
  "and X/ represent the covariate vector instances of users in the": "treatment/control group and their corresponding random variable,respectively. However, due to the non-simultaneous observability ofpotential responses, the uplift effect in the Neyman-Rubin potentialoutcome framework can hardly be accessed directly. An empiricalalternative is the Conditional Average Treatment Effect (CATE) which measures the response difference between the correspondingtreatment and the control, conditioned on the observed covariates.In this paper, following previous works , we estimate theCATE from the statistical perspective as the uplift effect, that is:",
  "METHODOLOGY": "In this section, we first introduce the uplift estimation model frame-work based on the previous related models and the newly designedzero-inflated lognormal loss for the revenue response regression.Second, we theoretically analyze the uplift modeling error fromthe ranking perspective and derive the tighter upper error boundsas the response ranking learning objectives. Then, motivated bythe listwise ranking research, we directly model the uplift rankingamong different individuals in the targeted population. Finally, weconclude the overall training objective for rankability-enhancedrevenue uplift modeling.",
  "Uplift Estimation Model Framework": "According to the uplift effect formulation (Eq. 2) in Sec. 3, con-ducting the accurate revenue response regression is undoubtedlycrucial to the uplift modeling. However, previous uplift models mainly rely on the MSE loss to learn response modelswhich can hardly adapt to the continuous long-tail distribution inrevenue uplift scenario, considering its sensitivity to outliers. Tobetter achieve the goal of accurate response regression, we firststudy the response distribution. From , we have two obser-vations: 1) small values, especially zeros occupy the main frequencyof the revenue response distribution, and 2) after the logarithmictransformation, except for such small (zero) values, the rest of thedata roughly follows a normal distribution.Motivated by the above observations, we refer to the relatedresearch in customer lifetime value research and propose thezero-inflated lognormal (ZILN) loss for response regression insteadof the conventional MSE loss. In detail, based on the previous obser-vation 1), the zero-inflation phenomenon, we first design a cross-entropy loss with the probability as the corresponding purchasingpropensity loss to help determine if the individual will spend money.Only the individuals that do spend money (payers) will engage intothe computation of the following payer expense loss. In this way,we can avoid the interference of such zero-value individuals in thepositive revenue response regression. Furthermore, based on theabove observation 2), we utilize the lognormal distribution withmean and standard deviation to model the positive revenueresponse from such payers and correspondingly derive its nega-tive log-likelihood as the payer expense loss for non-zero responseregression. In this lognormal loss, we conduct a logarithmic trans-formation to reduce the skewness of the response distribution. The",
  "Uplift Modeling Error Analysis": "To restore the correct ranking among the for different individ-uals, an intuitive approach is to ensure that the predicted upliftdistance between each possible individual pair (, ) is asclose as possible to their true uplift distance . Therefore, inthe following part, we focus on the uplift distance prediction error|( ) ( )| and theoretically prove that conventional MSEloss for response regression is a loose error bound which can hardlycapture the true uplift distance between individual pairs.",
  "(9)": "From the Eq. 7 and 9, we can find their last step | 1 1 | + | 1 1 | + | 0 0 | + | 0 0 | are just equivalent to the optimizationobjective of response MSE loss. This means that conventional MSEloss for response modeling is actually a looser upper error boundthan |( 1 1 ) (1 1 )| + |( 0 0 ) (0 0 )| and |( 1",
  ", ( 1/0 1/0) (1/0 1/0) 0": "(( 1/0 1/0) (1/0 1/0))2,.(10)In Eq. 10, for the individual pair (, ), if the relative order betweenpredicted responses differs from that between true responses, wepunish the uplift model with the above alignment loss. Addingthe within-group response ranking loss in the treatment groupL to the within-group response ranking loss in the controlgroup L , we can obtain the overall L :",
  "Uplift Ranking Learning": "In this section, we directly dive into the uplift ranking problem andexplicitly optimize the uplift models rankability. It can be easilynoted that this is inherently a learning-to-rank problem. The previ-ous solutions mainly include three types: pointwise, pairwise, andlistwise. The former two kinds consider the ranking problem fromthe perspective of a single individual or an individual pair, thus canhardly take all individuals into consideration at a glance. Besides,the pairwise approaches are mainly classification-based and thushave great difficulty distinguishing the inner-pair uplift distanceamong different pairs. Therefore, they are more suitable for binaryresponses, i.e., conversion uplift problems. If they are deployedin the revenue uplift scenario where the response is continuous,the performance can hardly be satisfying. The listwise approach,however, can directly minimize the overall ranking error of all indi-viduals in the population and discern the difference in continuousrevenue uplift values corresponding to different individuals.Therefore, we follow the listwise ranking procedure and firstmodel the uplift ranking process as a random process, which meanseach individual has the probability to be ranked in any positionof the whole population list. Here, the ranking probability on thehigher position for an individual should be positively related to heruplift score. To tackle this problem, we start from the probabilitythat an individual is ranked at the top-one position of the whole listand propose the loss function to measure the uplift model rankingerror. Then, we derive such loss function to an optimizable formwith the given data.",
  "where () is the ranking score function based on the uplift scorefor X. And it should possess the monotonically increasing property": "4.4.2Listwise Uplift Ranking Loss. With the above definition, giventhe list of true uplift score and the list of predicted uplift score by the model, we can measure the distance between them as theoverall ranking error. Here, we utilize the Cross-Entropy as themeasurement and define the listwise uplift ranking loss as follows:",
  "Datasets": "Hillstrom : This dataset is derived from an email merchan-dising campaign that involves 64,000 consumers. The datasetcontains three variables describing consumer activity in the fol-lowing two weeks after the delivery of the email campaign: visit,conversion, and spend. We select the spend as the response labelwhich indicates the actual dollar spent in the following two weeks,thus fitting our revenue uplift modeling problem setting. Theoriginal dataset has two types of treatment groups mens_email,",
  "* 16.83%": "womens_email, and a control group no_email. Following , wecombine the mens_email treatment group and no email controlgroup as the Hillstrom-Men dataset and conduct the similaroperation to the womens_email treatment group and no_emailcontrol group to obtain Hillstrom-Women dataset. Product: This is a product dataset that contains over 5,000,000individuals, collected from the online mutual fund marketingscenario of Tencent FiT. There are more than 1,800 covariatefeatures in the dataset and most of them are categorical. Theresponse label is the amount that an individual pays to purchasefunds. The treatment is an incentive coupon.",
  "For these datasets, we perform a 60%/10%/30% split to acquire thetraining set, validation set, and test set, respectively": "5.1.2Baselines. We compare our RERUM method with the fol-lowing baselines which are commonly adopted in uplift modeling:Causal Forest , S-Learner , T-Learner , TransformedResponse (TR) , TAR , CFR , StableCFR , CITE ,DragonNet . Note that in the following experiments, we mainlytake several prestigious deep learning-based uplift models as the backbones of our RERUM, considering their more competi-tive performance and wider application. We provide the detaileddescriptions for these baselines in Appendix B. 5.1.3Evaluation Metrics. In our experiments, we adopt the fol-lowing four metrics to evaluate the uplift ranking ability of differentmethods: Area Under the uplift curve (AUUC), Area Under the QINICurve (AUQC), Kendall Rank Correlation Coefficient (KRCC), andLIFT@h ( is set as 30). Following the previous work , we takethe jointly, absolute version of uplift/Qini curves and furtherformulate the corresponding AUUC and AUQC metrics. For eas-ier computation and fairer comparison, we utilize the normalized",
  "AUUC and AUQC approximated over 100 buckets. The detailedevaluation metric introduction is provided in Appendix C": "5.1.4Implementation Details. We conduct each experimentwith five different random seeds and take the average performanceas the final result. We use the Adam optimizer with the initiallearning rate as 0.001. The embedding size for each feature is setas 10 following the conventional design in industrial applications.We implement our method with PyTorch and run it on an NVIDIATesla V100 GPU with 32GB memory. Besides, we provide sourcecodes in",
  "Results and Analysis": "5.2.1Overall Performance (RQ1). We report the empirical re-sults of our RERUM and baselines on three offline datasets in .First, we can easily observe that deep learning-based uplift modelscan reach better performance than tree/meta learner-based modelsunder different settings, which validates the rationality that wetake them as the base models of our RERUM. Second, we can ob-serve that, though the uplift modeling capability differences amongthese base models, our four versions of RERUM with them can allachieve improvement over the best-performing baseline on mostmetrics and datasets. For example, our RERUM (DragonNet) im-proves the LIFT@30 metric by 21.98% on average in three datasets.Third, comparing each version of RERUM with its correspondingbase model, like RERUM (TAR) and TAR, our RERUM can consis-tently obtain significant performance gain. Taking the well-knownAUUC metric as an example, the RERUM (TAR) brings the 11.45%,10.82%, 5.70% improvement on Hilstrom-Men, Hillstrom-Women,and Product datasets, respectively. All these results demonstratethe effectiveness and applicability of our RERUM for rankability-enhanced revenue uplift modeling.",
  "AUUCAUQCKRCCLIFT@30AUUCAUQCKRCCLIFT@30AUUCAUQCKRCCLIFT@30": "RERUM (TAR) w/o wr-rank0.62030.62410.12931.19270.62140.62070.15610.83820.68250.70300.31841.0032RERUM (TAR) w/o cr-rank0.62280.62720.13851.23640.62560.62430.16200.85410.68390.70510.32071.0125RERUM (TAR)0.62990.63380.16171.34770.63600.63340.18060.87550.68630.70860.32691.0247 RERUM (CFR) w/o wr-rank0.63840.64010.11851.34250.64370.64300.14770.81330.74890.75760.35391.0986RERUM (CFR) w/o cr-rank0.64050.64220.12361.38610.64820.64890.15420.81920.75210.76050.35741.1133RERUM (CFR)0.64740.64970.13821.46020.65680.65590.16010.82610.75630.76790.36251.1302 RERUM (CFR) w/o wr-rank0.61880.62190.13951.17210.62880.62740.15830.81600.74480.75390.34871.1208RERUM (CFR) w/o cr-rank0.62150.62400.14671.22580.63130.62990.16160.81920.74830.75650.35121.1519RERUM (CFR)0.62420.62810.15811.30150.63740.63500.16920.82520.75540.76470.35881.2045 RERUM (DragonNet) w/o wr-rank0.66390.66720.12981.47630.64650.64820.15450.92870.70520.72740.35610.9852RERUM (DragonNet) w/o cr-rank0.66730.67010.13651.52720.65190.65280.16170.93400.70890.73020.35961.0324RERUM (DragonNet)0.67210.67530.14341.58450.65800.65660.16640.94010.71760.73590.36531.1016 improve the rankability of uplift models. This is actually consistentwith our discussion in Sec. 4.1. Second, we can also notice that in-tegrating each module into the overall framework can respectivelybring about improvement in ranking performance, which furtherverifies their effectiveness.To demonstrate that both within-group response ranking loss(wr-rank) and cross-group ranking loss (cr-rank) in Sec. 4.3 con-tribute positively to the final uplift ranking performance, we spe-cially remove them from the overall scheme respectively and ob-serve the corresponding results. The complete version of resultsare present in . From this table, we can first observe thatboth RERUM(X) w/o wr-rank and RERUM(X) w/o cr-rank achievelower ranking performance than RERUM(X), which demonstratesthat both wr-rank and cr-rank contribute positively to the final per-formance, i.e., both wr-rank and cr-rank are necessary. Besides, we",
  ": The hyperparameter sensitivity analysis results.The line chart corresponds to the AUUC metric and the col-umn chart corresponds to the LIFT@30 metric": "susceptible individuals to the treatment. Even utilizing ZILN in-stead of the conventional MSE to conduct the regression is alsofor improving ranking performance via accurate predicting therevenue response. Even though, investigating how such modules(especially UR and RR modules which are not specially designedfor response regression) fare on the underlying response regres-sion task can help provide the more comprehensive understandingto our methods. Therefore, we compare the performance of X (Xindicates the base model), X+ZILN, X+ZILN+UR, RERUM(X), onthe commonly used regression metric Mean Absolute PercentageError (MAPE) of the response prediction (lower is better). Notethat all base models X utilize the conventional MSE as the responseregression loss according to their original papers. The detailed ex-perimental results are provided in . From the , wecan find that X with ZILN as the regression loss can significantlyoutperform the X with the MSE as the regression loss on the MAPE",
  "DragonNet0.19550.20370.3754DragonNet+ZILN0.04830.05280.0986DragonNet+ZILN+UR0.05450.06170.1028DragonNet+ZILN+RR0.05160.05740.1001RERUM (DragonNet)0.06280.06540.1109": "metric. This demonstrates that the ZILN loss can effectively helppredict the revenue responses more accurately, thus finally benefit-ing the uplift ranking. Besides, the introduction of UR and RR willinfluence the performance on MAPE metric a little bit. Because theirmain goal is to increase the uplift ranking accuray instead of theresponse regression. As long as they can facilitate the uplift rankingperformance (shown in the of the paper), a small degreeof decrease in response regression is still tolerable. Even though,the regression performance (MAPE) of X+ZILN+UR, X+ZILN+RR,RERUM(X) is still better than X with MSE as the regression loss. 5.2.5Online Deployment (RQ5). This is a mutual fund salesscenario with the notification redpoint as the treatment in thewealth management business of our deployment platform, TencentFiT, one of the worlds largest online fintech marketing platforms.Here, the response variable is the sales revenue. We first identifythe top 2% ranked individuals from the whole population of around400 million users by the uplift model. Then, we randomly split suchpeople into the treatment group and control group. The differencebetween the average response in such two groups in the followingcertain length of period (1 month), also known as the sales revenueLIFT@2, reflects the rankability of the model. The online deploy-ment platform is illustrated in . To enhance the reliability andvalidity, we conduct three times of such marketing campaigns todemonstrate the effectiveness of our RERUM.Online Experimental Results Analysis. From the results shownin , we can observe that our RERUM achieves consistentimprovement over the state-of-the-art (SOTA) online base model",
  "CONCLUSIONS AND FUTURE WORK": "Revenue uplift modeling has been recognized as of great impor-tance for online marketing. Especially, the uplift ranking withinthe whole population is the core to identifying the sensitive indi-viduals to interventions. However, previous methods suffer fromthe low revenue response prediction precision and the neglectionto the uplift ranking accuracy among individuals. In this paper, wehave three contributions to address this problem: 1) modeling theresponse regression with a ZILN loss and a customized networkframework that can be adapted with different base uplift models; 2)analyzing the uplift ranking errors and using two tighter responseranking losses to augment the vanilla regression term; 3) directlymodeling the listwise uplift ranking among the whole population.The extensive experiments on both offline datasets and one of theworlds largest online fintech marketing platforms demonstrate theeffectiveness of our proposed method. In the future, we prepare toexplore the revenue uplift modeling with multiple treatments andits application in cross-domain scenarios. This work was supported by the Start-up Grant (No. 9610564), theStrategic Research Grant (No. 7005847) of the City University ofHong Kong, and the Early Career Scheme (No. CityU 21219323) ofthe University Grants Committee (UGC).",
  "Susan Athey and Guido W Imbens. 2015. Machine learning methods for estimat-ing heterogeneous causal effects. stat 1050, 5 (2015), 126": "Artem Betlei, Eustache Diemert, and Massih-Reza Amini. 2021. Uplift model-ing with generalization guarantees. In Proceedings of the 27th ACM SIGKDDConference on Knowledge Discovery & Data Mining. 5565. Karsten M Borgwardt, Arthur Gretton, Malte J Rasch, Hans-Peter Kriegel, Bern-hard Schlkopf, and Alex J Smola. 2006. Integrating structured biological data bykernel maximum mean discrepancy. Bioinformatics 22, 14 (2006), e49e57.",
  "Christopher JC Burges. 2010. From ranknet to lambdarank to lambdamart: Anoverview. Learning 11, 23-581 (2010), 81": "Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learningto rank: from pairwise approach to listwise approach. In Proceedings of the 24thinternational conference on Machine learning. 129136. Ziqiang Cui, Xing Tang, Yang Qiao, Bowei He, Liang Chen, Xiuqiang He, and ChenMa. 2024. Treatment-Aware Hyperbolic Representation Learning for Causal EffectEstimation with Social Networks. In Proceedings of the 2024 SIAM InternationalConference on Data Mining (SDM). SIAM, 289297.",
  "Yoav Freund, Raj Iyer, Robert E Schapire, and Yoram Singer. 2003. An efficientboosting algorithm for combining preferences. Journal of machine learningresearch 4, Nov (2003), 933969": "Robin Marco Gubela and Stefan Lessmann. 2020.Interpretable MultipleTreatment Revenue Uplift Modeling. In 26th Americas Conference on Infor-mation Systems, AMCIS 2020, Virtual Conference, August 15-17, 2020, Bon-nie Brinton Anderson, Jason Thatcher, Rayman D. Meservy, Kathy Chu-doba, Kelly J. Fadel, and Sue Brown (Eds.). Association for Information Sys-tems. Robin M Gubela, Stefan Lessmann, and Szymon Jaroszewicz. 2020. Responsetransformation and profit decomposition for revenue uplift modeling. EuropeanJournal of Operational Research 283, 2 (2020), 647661.",
  "Thorsten Joachims. 2002. Optimizing search engines using clickthrough data.In Proceedings of the eighth ACM SIGKDD international conference on Knowledgediscovery and data mining. 133142": "Kathleen Kane, Victor SY Lo, and Jane Zheng. 2014. Mining for the truly respon-sive customers and prospects using true-lift modeling: Comparison of new andexisting methods. Journal of Marketing Analytics 2 (2014), 218238. Sren R Knzel, Jasjeet S Sekhon, Peter J Bickel, and Bin Yu. 2019. Metalearners forestimating heterogeneous treatment effects using machine learning. Proceedingsof the national academy of sciences 116, 10 (2019), 41564165.",
  "Anpeng Wu, Kun Kuang, Ruoxuan Xiong, Bo Li, and Fei Wu. 2023. StableEstimation of Heterogeneous Treatment Effects. (2023)": "Fen Xia, Tie-Yan Liu, Jue Wang, Wensheng Zhang, and Hang Li. 2008. Listwiseapproach to learning to rank: theory and algorithm. In Proceedings of the 25thinternational conference on Machine learning. 11921199. Jun Xu and Hang Li. 2007. Adarank: a boosting algorithm for informationretrieval. In Proceedings of the 30th annual international ACM SIGIR conference onResearch and development in information retrieval. 391398. Hao Zhou, Shaoming Li, Guibin Jiang, Jiaqi Zheng, and Dong Wang. 2023. DirectHeterogeneous Causal Learning for Resource Allocation Problems in Marketing.In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 37. 54465454.",
  "We provide the detailed descriptions to all baselines as follows:": "Causal Forest : Causal Forest is a non-parametric RandomForest-based tree model that directly estimates the treatmenteffect, which is one of the most representative tree-based upliftmodels in many areas like economics and social science. S-Learner : S-Learner is a kind of meta-learner method thatuses a single estimator to estimate the response without giv-ing the treatment a special role. The uplift is estimated by thedifference between changed treatments with fixed covariates.",
  "T-Learner : T-Learner is another type of meta-learner method.Different from S-Learner, T-Learner uses two estimators for thetreatment group and control group respectively": "Transformed Response (TR) : TR is a special technique thattransforms the observed response to , such that the upliftequals the conditional expectation of the transformed responsefrom the expectation perspective. TAR : TAR is a commonly used deep learning-based upliftmodel. Compared with T-Learner, it omits the additional imputedtreatment effects fitting sub-models but introduces the sharedlayers for treated and control response networks. The sharednetwork parameters could help alleviate the sample imbalanceissue between the treatment and control groups. CFR : On the basis of TAR, CFR applies an additional lossto TAR, which forces the learned treated and control covariatedistributions to be closer. We report the CFR performance usingtwo distribution distance measurement loss functions, Wasser-stein (denoted as CFR) and Maximum Mean Discrepancy(MMD) (denoted as CFR). StableCFR : StableCFR upsamples the underrepresenteddata with uniform sampling and balances covariates by usingan epsilon-greedy matching mechanism to achieve higher uplifteffect estimation accuracy for the underrepresented population. CITE : CITE is based on the contrastive task designed forcausal inference, it fully exploits the self-supervision informationhidden in data to achieve balanced and predictive representationswhile appropriately leveraging causal prior knowledge. DragonNet : Dragonnet exploits the sufficiency of the propen-sity score for estimation adjustment, and uses a regularizationprocedure based on non-parametric estimation theory which canguarantee desirable asymptotic properties.",
  "We provide the detailed descriptions to our four uplift rankingevaluation metrics as follows:": "Area Under the Uplift Curve (AUUC): In uplift research, toevaluate the rankability of the uplift model , one can first plotan uplift curve which ranks individual samples descendinglyaccording to uplift (in X-axis) and cumulatively sumsthe uplift (in Y-axis) . The AUUC is then the areaunder this curve. There are actually multiple variants of upliftcurves proposed in the recent literature. Their differences mainlylie in 1) if ranking the data separately per group or jointly overall data, and 2) if expressing volumes in absolute or relativenumbers . In this work, we take the jointly, absolute upliftcurves in and formulate the AUUC. First, we denote thetotal number of treated and control instances, among the top-individuals (D,) ranked by uplift model over the wholedataset D as",
  "(27)We use the normalized AUQC to compare different methods": "Kendall Rank Correlation Coefficient (KRCC): The KRCC measures the similarity between the rank by predicted upliftscores and the rank by the approximated true uplift scores forall individuals. To facilitate the computation, we split the wholepopulation into 100 buckets and use the treatment and controlgroup data in each bucket to approximate the true uplift effect. LIFT@h: This metric measures the difference between the meanresponse of treated individuals and that of controlled individualsin top percentile of all individuals ranked by the uplift model. Ithas been widely employed in many industrial scenarios, becauseit can explicitly reflect the models rankability, especially for acertain proportion of targeted people. Here, we take as 30.",
  "DSUPPLEMENTARY ABLATION STUDY": "In addition to the ablation study conducted in Sec. 5.2.2, we also ad-just the module stacking order to further highlight the effect of eachmodule to the revenue uplift modeling. In detail, we incrementallyadd the ZILN regression module (ZILN), uplift ranking learningmodule (UR), and response ranking learning module (RR) to thevanilla base model X. The corresponding experimental results areillustrated in . First, it is evident that X+ZILN can achievebetter performance than vinalla X under almost all ranking-relatedmetrics and datasets, which implies that ZILN module can indeed"
}