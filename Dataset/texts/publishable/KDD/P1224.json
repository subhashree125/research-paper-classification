{
  "ABSTRACT": "Predicting node labels on a given graph is a widely studied prob-lem with many applications, including community detection andmolecular graph prediction. This paper considers predicting multi-ple node labeling functions on graphs simultaneously and revisitsthis problem from a multitask learning perspective. For a concreteexample, consider overlapping community detection: each com-munity membership is a binary node classification task. Due tocomplex overlapping patterns, we find that negative transfer isprevalent when we apply naive multitask learning to multiple com-munity detection, as task relationships are highly nonlinear acrossdifferent node labeling. To address the challenge, we develop analgorithm to cluster tasks into groups based on a higher-order taskaffinity measure. We then fit a multitask model on each task group,resulting in a boosting procedure on top of the baseline model.We estimate the higher-order task affinity measure between twotasks as the prediction loss of one task in the presence of anothertask and a random subset of other tasks. Then, we use spectralclustering on the affinity score matrix to identify task grouping.We design several speedup techniques to compute the higher-orderaffinity scores efficiently and show that they can predict negativetransfers more accurately than pairwise task affinities. We validateour procedure using various community detection and moleculargraph prediction data sets, showing favorable results comparedwith existing methods. Lastly, we provide a theoretical analysisto show that under a planted block model of tasks on graphs, ouraffinity scores can provably separate tasks into groups.",
  "Multitask Learning; Boosting; Modeling Task Relationships": "ACM Reference Format:Dongyue Li, Haotian Ju, Aneesh Sharma, and Hongyang R. Zhang. 2023.Boosting Multitask Learning on Graphs through Higher-Order Task Affini-ties. In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Dis-covery and Data Mining (KDD 23), August 610, 2023, Long Beach, CA, USA.ACM, New York, NY, USA, 16 pages.",
  "INTRODUCTION": "Given multiple node label prediction tasks on graphs, can we designa model to predict all of them simultaneously? For example, considersupervised, overlapping community detection : Given a set oflabels as a seed set, can we learn to predict whether another node ofthe graph belongs to a community? This is an example of multi-labellearning: The input involves labels of multiple communities. Thegoal is to predict community labels for the remaining nodes of eachcommunity. In this paper, we cast this multi-label classificationproblem into a more general formulation of multitask learning, which has numerous other applications in knowledgegraphs and protein-protein interactions . Traditionally,multitask learning works by fitting a single model on all tasks . By contrast, we investigate task relationships on graphs with ashared graph neural network. We observe notable negative transfersbetween various tasks. We address this challenge by designing aboosting procedure to cluster tasks into groups and then fit multiplegraph neural networks, one for each task group.Negative transfer refers to scenarios where learning multipletasks using a shared encoder can worsen performance comparedto single-task learning (STL) for one task , and this has beenobserved for various data modalities . The cause canoften be attributed to heterogeneity in input features or dataset sizes.Much less is known about graph data. Zhu et al. and Ju et al. identify structural differences for transfer learning on graphsdue to the graph diffusion process. These structural differencescan also cause negative interference in multitask learning. Thus,building multitask graph neural networks requires better modelingof structural differences between tasks. This modeling could alsobe used to identify task grouping .The classical multitask learning literature has studied task re-latedness through heuristics and theoretical perspectives .These results do not naturally apply to nonlinear neural networks.A naive solution to optimize multitask learning performance isto search through all possible combinations of tasks to select thebest subset. This is costly to compute for a large number of tasks.Prior work computes pairwise task affinity scores by trainingone model for every pair of tasks and approximates higher-ordertask affinities by averaging first-order affinity scores. Yu et al. and Fifty et al. compute first-order task affinities using gradi-ent similarity. These methods are much more efficient than naivesearch, but they ignore higher-order relationships among tasks,such as combining more than two tasks. This is critical as higher-order task affinities can exhibit more complexities. We observe thatthey cannot be reliably predicted from first-order affinity scores(cf. , .1) as transfer relationships are not mono-tone or submodular, meaning that adding more task data does notnecessarily help performance (see , .2). Moreover,",
  ". Measuring Task Affinity Scores": ": Overview of our boosting procedure: (1) We sample random subsets of tasks, each subset containing a fixed numberof tasks. (2) For each subset , for = 1, 2, . . . ,, we fit a multitask learning (MTL) model on the combined data sets of alltasks in , using a graph neural network (GNN) as the shared encoder. After fitting the MTL model, we evaluate its predictionperformance for each task , denoted as (). (3) We compute an affinity score , by averaging task s scores among allsubsets as in equation (1), where , is the number of subsets including both , . This results in a by affinity matrix, denotedas . (4) We apply spectral clustering on this matrix to find clusters of task groups and fit one GNN for each task group. naively computing all pairwise affinities requires fitting 2 modelsgiven tasks, which is costly even for tens of tasks.This papers main contribution is to design an efficient algorithmto cluster tasks into similar groups while accounting for higher-order transfer relationships. One can compare the performanceof a multitask model, such as a GNN trained on all tasks, againstseveral multitask GNNs, each trained for a task group. shows that this approach yields the best results among a wide setof baselines on various real-world datasets. Our method can beviewed as a boosting procedure and can be used on top of anygraph learning algorithm. Approach. We outline the overall procedure; See also for an illustration. Given tasks, we first compute a task affinityscore , for every pair of tasks and . A higher value of ,indicates task transfers better to task while also accountingfor the presence of other tasks. Conceptually, , is similar to thefeature importance score in random forests when hundreds of otherfeatures are available. This higher-order task affinity score can alsopredict whether a set of tasks transfer positively or negatively toa target task. Given the affinity score matrix , we use aspectral clustering algorithm to separate tasks into similargroups, which is more suitable for joint training. Specifically, ouralgorithm optimizes the sum of task affinity scores within groupsthrough spectral clustering.Next, we describe the steps to estimate the affinity score matrix.A naive approach is to compute each entry individually, requiring( 2) complexity. We design an efficient sampling procedure thatonly requires () complexity. Concretely, we sample = ()random subsets from {1, 2, . . . , } of a fixed size (in practice, = 5 suffices). We fit an MTL model for each subset and evaluateits prediction loss for each task in the subset; Let () denote theprediction loss of task , given a subset {1, 2, . . . , }, which weevaluate on a holdout set. Thus, () measures the informationtransfer from to . Then, we compute , as the average amongall subsets including , :",
  ": {, } (), for all 1 , .(1)": "To rigorously justify the rationale behind our affinity scores, weconduct a theoretical analysis in a stochastic block model stylesetting, where tasks follow a well-separated structure. We provethat under this planted model, the affinity score matrix exhibits a block-diagonal structure, each block corresponding toone cluster. This characterization shows that the spectral clusteringalgorithm recovers the underlying task structure. Summary of Contributions. The contribution of this work isthreefold. First, we design a task affinity score to measure higher-order task relationships and estimate the scores with an efficientsampling procedure, which only requires fitting () MTL models.Second, we propose a spectral clustering step to find task groupsbased on the affinity score matrix. We provide recovery guaranteesfor this clustering procedure and show that the affinity scores canbe used to provably group related tasks in a planted model. Third,we validate the benefit of our boosting approach using variouscommunity detection and molecular graph prediction datasets. Theexperimental results show that our approach improves test accuracyover different community detection and MTL baselines. Organization. The rest of this paper is organized as follows. Wefirst outline related work in . In , we provideempirical grounding for the claim that accounting for negativetransfer among tasks is crucial for MTL on graphs. Our boostingprocedure is described in , followed by a thorough empiri-cal study of its performance in . Finally, in , wedescribe the theoretical analysis of our algorithm. In Appendix A,we provide complete proofs for our theoretical results. In AppendixB, we describe additional experimental results left from the maintext.",
  "Boosting Multitask Learning on Graphs through Higher-Order Task AffinitiesKDD 23, August 610, 2023, Long Beach, CA, USA": "to the representations of all tasks can help encourage informationtransfer . These regularization schemes can be rigorously justi-fied for convex hypothesis classes . For nonconvex hypothesisspaces such as graph neural networks, explicitly regularizing thefeature spaces of all tasks is a non-trivial challenge . Ma et al. introduce a mixture-of-experts model to capture the task rela-tionships, with each expert being an MTL network. Yu et al. design gradient-based similarity measures that can be efficientlycomputed using the cosine similarity of gradients during training.This can be extended to measure the similarity between two sets oftasks by averaging the gradient of tasks in each set. Recent work points out that first-order affinity measures deteriorate asa transferability measure when applied to a large set of tasks. Task Grouping. Instead of sharing layers and model parametersacross all tasks, Kumar and Daume III proposes mitigatingnegative transfers by dividing tasks into several related groups. Ourpaper takes inspiration from Datamodels , which extrapolatesthe outcome of deep networks as influence functions. In particular,Ilyas et al. find that a linear regression method can accuratelyapproximate the outcome of deep nets trained with a subset ofsamples on popular image benchmarks. Our results (e.g., )show that the affinity scores can also accurately predict transfertypes in multitask learning.",
  "Transferable graph neural networks": "Graph neural networks have emerged as widely used tools forgraph learning. Ideally, we want to learn a powerful embeddingfor all downstream tasks . Zhu et al. analyzes the transferability of GNN from graph to graph andhighlights the complex correspondence between structural similar-ity and transferability between GNNs. Besides GNN, researchershave also observed negative interference while applying graph em-bedding to perform transfer learning on Graphs . Ju et al. show non-vacuous generalization bounds for graph neural net-works in the fine-tuning setting using Hessian. Our paper expandson these prior works in two aspects. First, we consider a multi-label learning setting involving as many as 1000 tasks, whereas thework of Zhu et al. and Gritsenko et al. focuses on transferlearning from graph to graph . Second, we consider multiplenode prediction tasks on a single graph, which is different fromgraph pretraining (e.g., Hu et al. and Qiu et al. ) and graphalgorithmic reasoning . Multitask Learning Applications for Graph-Structured Data.Combining multiple graph learning tasks jointly can potentiallyenhance the performance of single tasks. Our results support thisclaim in the context of supervised overlapping community detec-tion. Besides, we believe many graph learning tasks can be cast intothe multitask learning framework. For instance, consider extract-ing entity relationships on knowledge graphs; Each entity relationmay be viewed as one task. Wang et al. find that learning thedependencies of different relations through multitask representa-tion learning can substantially improve the prediction performance.There has also been some study on the trade-off between fairnessand accuracy in MTL . It is conceivable that the new tools wehave developed may benefit these related applications. This is apromising direction for future work.",
  "Overlapping community detection": "Identifying community structures is one of the most widely studiedproblems in network science . A common approach to findingcommunities given a seed set is to measure the local connectivityof a subgraph using spectral graph properties (e.g., the conductanceof a cut). Yang and Leskovec describe an efficient algorithmusing non-negative matrix factorization for finding overlappingcommunities. Whang et al. finds local clusters by identifyinglow conductance set near a seed. These approaches use the connec-tivity of edges to compute spectral properties. Besides, higher-orderstructures from hypergraphs are found to be useful for overlappingcommunity detection . Lastly, community detection can becast in the correlation clustering framework, which does not requirespecifying the number of communities .Our paper is closely related to the work of Chen et al. . Thedifference is that we formulate the problem of predicting com-munity labeling via multitask learning, whereas Chen et al. consider a multi-class classification setup. Our formulation is moresuitable when we are dealing with a large number of overlappingcommunities. This is a novel perspective on community detectionto the best of our knowledge. Our results, compared with strongbaselines including VERSE embedding and BigClam , sug-gest that modeling higher-order task relationships can significantlyimprove empirical performance for multitask learning.",
  "INVESTIGATING TASK RELATIONSHIPS": "We investigate task relationships in the setting of overlapping com-munity detection. We demonstrate that negative transfer is wide-spread across tasks and persists in large models. We show that taskrelationships are neither monotone nor submodular in the higher-order regime. Motivated by these considerations, we propose a taskgrouping problem for conducting MTL on graphs.",
  "Setup and background": "Problem setup. We conduct an empirical study using multiple over-lapping community detection tasks as a concrete example. Givena graph = (, ), we have a list of communities as subgraphsof . Let 1,2, . . . , denote the vertex set of these communities.We are given a vertex subset of each community during training asseed sets. For every = 1, 2, . . . ,, deciding whether a node belongs to is a binary classification task. Note that this formula-tion differs from supervised community detection but is moresuitable for overlapping community detection. This formulationis an example of multi-label learning, a particular case of multi-task learning (see, e.g., b of Zhang and Yang ). Castingmulti-label learning into this more general formulation providesnew perspectives in solving the problem.",
  "Acc. improvement (%)": ": This figure illustrates the widespread negative transfer effect among tasks by noting that MTL performance can dipbelow STL for four separate (randomly selected) target tasks. We fix a target task for each plot, then randomly pick ten sourcetasks (out of 100) and for each source task train an MTL with and ; we report the MTL accuracy for minus s STL accuracy.Thus, bars above zero indicate positive transfers from source to target tasks, while bars below zero indicate negative transfers. randomly sample 10% of the nodes from the community in thetraining set, together with 10% of nodes outside the community asnegative samples. We randomly sample another 20% of nodes asthe validation set and treat the rest as a test set. We evaluate theperformance of each task using the F1 score on the test set. See for details statistics of the four datasets. Models. We consider an MTL model that consists of a single en-coder to obtain shared representations and a separate predictionlayer for each task. We train this model by minimizing the averageloss over all tasks training data. Our experiments in this sectionuse the SIGN model as the encoder, which is more efficient totrain than GCN. The encoder involves 3 layers, each with a fixedwidth of 256 neurons. Our choice of this encoder is without lossof generality, and our observations also apply to other encoders.We construct the node features from the VERSE embedding ,which encodes personalized PageRank vectors known as valuablefeatures for community detection . Negative transfer on graphs. A common phenomenon with mul-titask learning is negative transfer , meaning that combiningone task with another worsens performance compared with train-ing a task separately. We show that negative transfer occurs duringMTL on graphs. We take 100 tasks from the YouTube dataset. First,we fix a randomly chosen task as the target task and use the rest assource tasks. Then, we train a GNN for task , and 99 MTL models,each combining one source task with task . The performance gapbetween the MTL and STL models indicates the transferability froma source task to task . above shows the results of this experiment, repeatedover four randomly chosen target tasks. The bars above zero corre-spond to positive transfers as MTL performance exceeds STL, whilebars below zero correspond to negative transfers. We observe thatboth positive and negative transfers appear in all four settings.",
  ": In each subfigure, we visualize the personalizedPageRank vectors of a set of nodes in one community. Theydiffer dramatically across non-overlapping communities": "Structural differences. Why do negative transfers happen duringmultitask learning on graphs? A common belief in the MTL com-munity is that this is due to differences in the task labels . We argue that graph neural networks involve another kind ofheterogeneity due to graph diffusion. We appeal to a connectionbetween GNN propagation and personalized PageRank (PPR) , positing that dramatically different PPR structures amongcommunities will induce different graph diffusion for GNNs. In, we visualize the PPR vectors of four randomly chosentasks from the YouTube dataset. Within each subfigure, each rowcorresponds to the PPR vector of one node that belongs to a partic-ular community. We plot the PPR vectors of a set of nodes from thesame community. Clearly, PPR vectors differ dramatically for nodesfrom different communities, suggesting that the diffusion processesare highly heterogeneous. We also observe that tasks yield positivetransfers tend to have higher similarity between their PPR vectors.Detailed results are described in Appendix B.1. Will larger models address negative transfers? A natural ap-proach to addressing negative transfers is to increase the modelsize, but this does not account for the above structural differences.We hypothesize that due to innate data heterogeneity, negativetransfers between tasks cannot be addressed by increasing themodel capacity. To verify this, we use the first target task from and select the source task in the rightmost bar with thestrongest negative transfer. We gradually increase the number ofneurons in the hidden layer from 32, 64, 128, 256, 512, 1024, to2048, corresponding to larger model capacities. a shows theresults. We observe consistent negative transfers, i.e., the accuracyimprovements stay negative, after increasing the model capacity.We have also observed the same result on a more powerful GNNwith attention, i.e., GAMLP . See Appendix B.2 for these results.",
  "How do task relationships behave?": "Next, we study the multitask learning performance involving morethan two tasks. At the extreme, this would involve 2 combina-tions of task subsets. To be precise, given any subset of tasks {1, . . . , }, let () denote the MTL performance of combiningdata from all tasks in , evaluated on task , for each . Q1: Is monotone? To better understand how behaves, we picka target task and measure ({}). Then, we add new tasks to becombined with . We only add a task , if task is beneficial for task, i.e., ({,}) ({}). b shows the result of applyingthe above setting to the first target task. We observe that after",
  "(c) is not submodular": ": (4a) We show a consistent negative transfer even after increasing the model size (measured by width). (4b) The -axisrefers to the number of added source tasks to train with the target task. The -axis refers to the difference in performancebetween MTL and STL (with the target task alone). We observe that the MTL performance of a target task starts to decreaseafter adding two or more source tasks, even though these are all positive source tasks (in the sense of pairwise transfer). (4c)Under the presence of a negatively interfering source task, the benefit of adding more positive tasks diminishes, implyingthat the () function is not submodular.",
  "adding more than two positive source tasks, the MTL performancedecreases. This shows that () is not monotone": "Q2: Is submodular? A function () is submodular if for anytwo subsets {1, 2, . . . , } and any single task , ({} ) () ({} ) (). We pick one negative source taskas and ask if adding positive source tasks mitigates the negativetransfer. In c, we find that adding positive tasks does notalways help, which implies that is not submodular. The scales of are also different compared to b, because the presence ofthe negative task reduces the effect of positive tasks. The takeawayis that is not monotone or submodular, motivating our approachto extrapolate via sampling.",
  "Task grouping for multitask graph learning": "We aim to obtain a set of networks where each network is trainedon a subset of tasks. The objective is to optimize the overall per-formance of all tasks after combining the networks. To approachthis problem, we consider finding subsets of tasks, namely taskgroups, to maximize the positive transfers of tasks within eachgroup. We want to divide {1, 2, . . . , } into possibly overlappingsubsets of tasks. Let S denote the collection of subsets. Given S,the performance of task is the highest one among all networks:",
  "(S) = max S ()": "Thus, the overall performance of all tasks on a solution is =1 (S).Suppose there is a limited inference budget , the number of MTLmodels we can deploy in inference. We want to find at most groups that achieve the highest performance: =1 (S).To address this problem, we need to evaluate the multitask learn-ing performance for all subsets of tasks, which total 2 combina-tions. Because task relationships are highly non-linear, we needa more efficient procedure to capture transfer relationships. Moregenerally, finding the optimal task groups is NP-hard via a reductionfrom the set-cover problem (see, e.g., ).",
  "We now present our approach to optimize multitask model per-formance through grouping tasks that utilize higher-order task": "affinities. Recall the steps in our pipeline from : (1,2) Re-peatedly sample a random subset of tasks, and evaluate the modelsperformance that combines the tasks in each subset. (3) Averagethe multitask learning performances over subsets that involve twospecific tasks, yielding the task affinity score. (4) Then, we usethese task affinity scores to group tasks using a spectral clusteringalgorithm on the matrix of task affinity scores.",
  "Estimating higher-order task affinities": "Notations. Suppose we are given a graph = (, ) where | | = and || = , with node features R . There are semi-supervised tasks on the graph. For each task , we are given a set ofnodes () with known labels (). The goal of task is to predictthe labels for the rest of the nodes on the graph / (). Note thatthe set (1), . . . , ( ) can be either overlapped or disjoint witheach other. The objective is to optimize the average predictionperformance over the tasks.Let be the encoder network shared by all tasks. Let 1, . . . ,be prediction layers for tasks 1, . . . , that map feature vectors totask outputs. When the input is a graph, we consider using graphneural networks as the encoder . Given {1, 2, . . . , }, let () and (), for , be the trained model on the combined dataset of. We evaluate the prediction loss on each tasks validation dataset.Let () denote a set of nodes in , which is used as a validation setfor the task . Let be an evaluation metric, e.g., the cross-entropyloss. We define multitask learning performance for any as:",
  "() () () (;), ()(2)": "Measuring task affinity scores. Our approach measures higher-order task affinities to indicate how well a task transfers anothertask when combined in a subset. We show that such task affinitymeasures can be estimated by training models, where onlyneeds to grow linearly to the number of tasks . Moreover, ourmeasure gives a more accurate prediction of higher-order multitasktransfer results than previous notions of task affinity.We view task affinity as a transferability measure from sourceto target tasks. Given a task {1, . . . , } as a target task, denotethe affinity of another task to as ,. To model the relations of",
  "KDD 23, August 610, 2023, Long Beach, CA, USADongyue Li, Haotian Ju, Aneesh Sharma, & Hongyang R. Zhang": "higher-order transfers. we define the task affinity score , as theaverage MTL prediction loss () on target task over subsets thatcontain both task and . We emphasize that the affinity scoresaccount for the presence of other tasks. Also note that a highervalue of , indicates higher usefulness of task to task .We estimate the task affinity scores through a sampling approach.Conceptually, this is analogous to graph embedding methods thatoptimize embeddings to approximate proximity scores. Similarly,we sample random subsets from tasks 1 to and estimate the taskaffinity scores on the sampled subsets using this procedure: (1) Sample subsets from tasks 1 to , denoted as 1, . . . ,.We sample each subset from the uniform distribution oversubsets with size . In other words, among all subsets of{1, 2, . . . , } with size (note there are of them), we pickone uniformly at random, with probability 1/.",
  "Finding task groups by spectral clustering": "Since the affinity scores serve as a proxy of higher-order task rela-tionships, we optimize MTL performance by finding task groupswith the highest task affinity scores within each group. Our taskgrouping algorithm, as described below, contains two major steps.The complete procedure is given in Algorithm 1. Algorithm 1 Task Grouping Using Higher-Order Task AffinitiesInput: tasks; Training and validation sets of the task.Require: The size of each subset ; Number of sampled subsets ;Inference budget ; Multitask learning algorithm .Output: trained multitask models.",
  ": Train multitask models for each task group 1, . . . ,": "First, we construct a transformed affinity score matrix for clus-tering. Since the sum of affinity scores between two tasks and within a group is (, + ,), we define a symmetric matrix1 = ( + )/2. Additionally, we find auxiliary source tasksfor each group that yield positive transfer to the group. This isachieved by viewing the matrix as directional task relationships,with source tasks represented along the rows and target tasks alongthe columns. To find a set of source tasks that yield the highest",
  "EXPERIMENTS": "We now evaluate our approach empirically on various communitydetection and molecular graph data sets. First, we show that ourtask affinity scores can be estimated efficiently to predict negativetransfers more accurately than first-order task affinities. Second,we apply our approach to overlapping community detection taskson several datasets with ground-truth community labels: our ap-proach outperforms the naive MTL by 3.98% and task groupingbaselines by 2.18%. Third, we evaluate our approach on molec-ular graph prediction tasks and show a 4.6% improvement overprior MTL methods. Lastly, we provide ablation studies to showthat our approach is stable under various settings. The code forreproducing our experiments is available at",
  "Results for predicting negative transfers": "Experiment setup. We use task affinity scores , for predictingnegative transfers as follows. Given a target task and a subsetof tasks containing , we predict whether the subset transfersnegatively to a task , i.e., the MTL prediction loss () of trainingtask with subset is worse than the STL loss of task .We set up the prediction as binary classification. For each task, input feature for a subset is the task affinity scores of tasks in to task : 1 [,1, . . . ,, ]. The label is whether the subset transfers negatively to a task . Then, we fit a logistic regressionmodel that maps the features to the binary labels. We fit modelsin total and evaluate the average F1-score over the models.We evaluate the above prediction on the YouTube dataset with = 100 tasks and estimate task affinities of order 5, 10, and 20(which means that the size of sampled subsets is = 5, 10, or 20).We use the transfer results on = 2000 task subsets to fit logisticregression models and evaluate the predictions on 500 new tasksubsets that do not appear in training. Results. First, we illustrate the convergence of 1-score of negativetransfer prediction when increasing the sample size , as shown inthe right of . We observe that with 2000 = 20, usinghigher-order task affinity scores predicts negative transfers with1-score above 80%. This result consistently holds for samplingsubsets of different sizes.Second, we compare our approach to two previous notions ofaffinity scores. One involves computing first-order task affinitythrough the effect of one tasks gradient on another tasks loss .Another approximates the higher-order task transfers by averagingthe first-order task affinity scores . on the left shows",
  "Task subset size = 5Task subset size = 10Task subset size = 20": ": We use task affinity scores from tasks in a subset to task to predict whether training with subset decreases theSTL performance of task . Left: Compared with two first-order task affinity scores, our higher-order task affinity scores achieveconsistently better F1-score for predicting negative transfers of combining up to = 20. Right: The F1-score for predictingnegative transfers converges when the sampled subsets reach 2000. Results consistently hold for different subset sizes.",
  "that the 1-score from previous measures gradually gets worse;Ours are accurate for subsets of size ranging from 2 to 20": "Run time analysis. Then, we present the run time of our approach.Our approach requires training networks, one for each randomsubset. We find that using 20 samples suffice for estimating thetask affinity scores to convergence. In contrast, previous methods estimate task affinities for every pair of tasks, resulting intraining on ( 2) task pairs. Concretely, we report the run time ofour approach in , evaluated on a single NVIDIA RTX GPU.Compared with the two previous methods, our approach requires3.7 less running time, averaged over the four data sets. Speed up training. In practice, we can further speed up trainingwith early stopping and downsampling. Our experiments foundthat this leads to a significant speed-up, and the overhead on top ofNaive MTL is only up to 2-3. In of Appendix B.3, we reportthe running time of our approach by incorporating the speed-upmethods, as compared with all MTL baselines.",
  "Averaging the first-order task affinity scores to approximatehigher-order task affinities": "We note that Fifty et al. and Standley et al. use a branch-and-bound algorithm to search for task groups but do not scale toone hundred tasks for the data sets. We use their task affinity scoresto compare these two methods but apply the spectral clusteringprocedure to find task groups. Implementations. We use a 3-layer SIGN model as the encoder forall MTL approaches, with a width of 256 neurons. We use the VERSEembedding as the input node features. We compare approaches forsplitting tasks into = 20 groups. We use the same amount ofmodel parameters for other MTL baselines. In the evaluation, wereport the macro F1-score of predicted communities to ground-truthcommunity labels on the test set.For our approach, we set the size of the subset as = 10 and thenumber of samples as = 2000. We ablate the two parameters in.4 and find that the performance of our approach remainsstable while varying them. We set the MTL performance metric () as the (negative) cross-entropy loss on the validation set. Weapply the spectral clustering algorithm in to find task groupson the symmetric adjacency matrix constructed from task affinityscores.",
  "Alg. 1 (Ours)0.067 0.0030.090 0.00129.73 0.12": "Results. reports the evaluation of four social networks withground-truth community labels. First, we find that VERSE embed-ding achieves the best performance among all the node embeddingmethods. Thus, we use the VERSE embedding as a node featurefor conducting MTL on graph neural networks. Due to the spaceconstraint, we report the results of other community detectionmethods in Appendix B.4. Benefit of task grouping: Compared with methods that opti-mize a joint model on all tasks, task grouping consistentlyperforms better than the naive MTL and Mixture of Experts.Our approach outperforms them by 3.98% on average. Benefit of modeling higher-order relationships: Compared withforward and backward selection, our approach achieves anaverage improvement of 2.18% over the datasets. Moreover,we compare our approach with clustering by two first-ordertask affinities. The results show that our approach outper-forms them by 2.49% on average. This validates the advan-tage of using higher-order task affinities over first-order taskaffinities. The results are shown in of Appendix B.4.",
  "Results for molecular graph prediction": "Next, we apply our approach to molecular graph prediction tasks,including two multi-task regression data sets from TUDatasets and one multi-task classification dataset from OGB . Inthe graphs, nodes represent 3D coordinates of atoms in molecules,and edges encode distances between atoms. Each task correspondsto predicting a specific molecular property. We use a 6-layer GINmodel as the encoder, with a width of 64. We evaluate the meanabsolute error (MAE) on the regression datasets and the averageprecision (AP) on the classification dataset. compares our approach with MTL baselines, includingnaive MTL, Mixture of Experts, and forward/backward selection.We find that on these three data sets, our method still outperformsthe baselines relatively by 4.6% on average.",
  "Ablation studies": "Number of task groups . We discuss how the number of taskgroups is determined in our approach. We hypothesize that a largernumber of task groups gives greater flexibility and tends to havebetter performance. Ideally, we can generate task groups, eachfor a particular target task, and select helpful source tasks for thetarget task in each group. We validate the hypothesis by varyingthe number of task groups between 5, 10, 20, and 100. The resultsvalidate that more group achieves better performance. Interestingly,we also find that using 20 groups achieves results comparable tothose of using 100 groups. Thus, we set = 20 in our experiments.The details are reported in Appendix B.5. Subset size . Recall that we collect MTL prediction losses throughsampling random subsets of a size . We evaluate the performanceof our approach by varying the size {5, 10, 20}. First, we observesimilar convergence results using different sizes, as shown in . Next, we apply algorithm 1 with different values of . We noticethat the performances are comparable. Using = 10 achievesslightly better performance than the other two. We posit that usinga larger does not help because the number of related tasks in ourcommunity detection data sets is limited. Number of samples . We further explore how affects the algo-rithm results. Our observation in is that collecting = 20is sufficient for task affinity scores to converge. Meanwhile, usinga smaller can also achieve near 80% F1-score for predicting neg-ative transfers. Thus, we test the performance of algorithm 1 byvarying {1000, 1500, 2000}. We observe that using = 1000 stillachieves comparable performance as using = 2000. The perfor-mance difference is within 0.5%.",
  "THEORETICAL ANALYSIS": "In this section, we aim to develop a principled understanding ofour higher-order affinity scores . To this end, we study aplanted model in a theoretical setup, where the tasks are assumedto follow a block structure. We note that planted models have beenwidely used to study graph clustering . In this setting, we ask:",
  "Could the affinity scores be used to successfully separaterelated tasks from each block?": "We provide a positive answer to both questions in a theoreticalsetup, where the labels of each task have been drawn from a linearmodel. Our finding is that for two tasks from the same group in theplanted model, their affinity scores will be provably higher thantwo tasks from different groups. To describe this result, we firstformally introduce the setup. Setup. Suppose we are learning tasks. For each task, from 1up to , let the node labels of this task be given by a vector (),all of which are observed on a set of nodes denoted as . Let denote the size of the observed set of nodes. We focus on regressiontasks in the analysis. Thus, the values of () are all real values. Tofurther simplify the analysis, we consider a one-layer linear graphdiffusion layer as (,) = , where (e.g., the normalizedgraph Laplacian matrix) denotes the diffusion matrix of the graphneural network, and denotes the matrix of node features. Weassume that is drawn from an isotropic Gaussian distribution,and is full rank. We measure the loss of this GNN against thelabel vector () using the Mean Squared Error (MSE):",
  ".(4)": "where denotes the propagation matrix restricted to the set ofnodes in . Based on our algorithm, we first show that the relevancescore , admits a structure that measures the distance between () and (). When we sample a set of tasks {1, 2, . . . , } witha total of tasks, then we average their per-task losses as",
  "( ).(5)": "Notations. We follow the convention of big-O notations for statingthe result. Given two functions () and (), we use () =O(()) or () () to indicate that () () for somefixed constant when is large enough. Characterization of affinity scores. Minimizing equation (4) over leads to a closed form solution on let us denote this as ,which we can then plug into task s loss ( ). We then averagethe value of ( ) for subsets 1,2, . . . , that include as partof the subset. This gives the relevance score ,:",
  "Now we are ready to state a structural characterization on theaffinity scores": "Theorem 6.3. Suppose the features and the label vectors of everytask are given based on the setup specified within this section andsatisfy Assumption 6.2. Assume that the propagation matrix isfull rank. Let be a fixed constant that does not grow with and ,and be a value that is less than one.When = 2 log4 log2(1)2, = log(1)2,and 2 2 4 log8 log4(1)4, then with probability atleast 1 over the randomness of the training samples, the affinityscores satisfy the following block structure: For any 1 , , such that , come from the same group, but , comefrom different groups, then",
  ".(10)": "Our result characterizes the block structure of the affinity scores.The affinity scores are lower within the block of nodes from thesame community. Conversely, the affinity scores would be higherfor any pair of nodes that cross two communities. Based on thischaracterization, it is clear that by applying a spectral clusteringalgorithm over , one could recover the group structuresspecified under Assumption 6.2. For future work, it would be inter-esting to strengthen our analysis with relaxed assumptions furtherand extend it to more general losses and planted models. The com-plete proof can be found in Appendix A.",
  "CONCLUSION": "This paper studied multitask learning on graphs and designed ageneric boosting procedure that improves MTL by finding relatedtasks and training them in groups. We first estimate higher-ordertask affinities by sampling random task subsets and evaluatingmultitask performances. Then, we find task groups by clusteringtask affinity scores. Experiments show that our higher-order taskaffinity scores predict negative transfers from multiple tasks toone task. Our approach improves over previous MTL methods onvarious community detection data sets. The theoretical analysisfurther demonstrates that using our task affinity scores provablyseparates related and unrelated tasks.Our work opens up interesting questions for future work. Forexample, can we incorporate various node or link prediction tasks toenhance community detection in multitask learning? Can we applyrecent developments in correlation clustering to determinethe number of clusters?Acknowledgement. Thanks to the anonymous referees for pro-viding constructive feedback that improved our work significantly.Thanks to Ruoxuan Xiong, Xiaojie Mao, and Yi Liu for fruitfuldiscussions during various stages of this work. D. L. is supportedby a start-up fund from Khoury College of Computer Sciences,Northeastern University.",
  "APROOF OF THEOREM 6.3": "Proof Sketch: The proof of Theorem 6.3 is by carefully examining the sampling structures of our algorithm. A key insight is that ,measures the relevance score of task to task while accounting for the presence of other tasks besides and . There are two steps in theproof. First, we show that , deviates from a population average that takes into account all subsets of size by an error of (1/2). This isbased on Hoeffdings inequality. See equation (16) in Appendix A. Second, since is a projection matrix based on equation (15), we havethat for any and ,",
  "log(1)2,(24)": "the following holds: For any = 1, 2, . . . ,, if comes from the same group as , but comes from a different group compared with , then, , /2.Thus, we have shown that there exists a block structure in the affinity scores matrix . The proof of Theorem 6.3 is nowcompleted.",
  "BADDITIONAL EXPERIMENTS": "In this section, we provide additional experiments to support our approach. First, we provide additional observations regarding taskrelationships. These include structural differences between tasks in terms of PPR vectors and studying the effect of model size on mitigatingnegative transfer. Second, we compare the running time of our approach with baselines. Third, we provide comparisons with other baselinemethods and ablation studies.",
  "B.1Comparing structural differences between tasks": "We study why negative transfers happen between two community assignment tasks when trained together. We hypothesize that thedifference in graph diffusion processes of the two tasks contributes to negative transfer in graph neural networks. If their graph diffusionprocesses are very different, using a shared GNN would lead to a negative transfer. Otherwise, we expect a positive transfer between the twotasks. To validate this hypothesis, we compute each tasks personalized PageRank (PPR) vector using its community labels as the seed set.Then, we measure the cosine similarity of the PPR vectors between tasks from the same group and tasks from different groups. We conductthis comparison based on the task groupings found by our method. Across four community detection datasets, tasks within the same groupexhibit 8.8 higher cosine similarities in their PPR vectors than tasks from different groups. reports the results. This suggests thatgraph diffusion processes of tasks clustered together are more similar. : This table reports the cosine similarity of PPR vectors between tasks from the same group and tasks from differentgroups. For tasks from the same group, their PPR vectors have higher cosine similarities than tasks from different groups.",
  "B.2Studying negative transfers by increasing the model size": "Previously in , we demonstrate that increasing the model size cannot address negative transfers between two tasks, using the SIGNmodel as the base model. We observe similar results of using a more powerful GNN with attention, i.e., GAMLP . We select one targettask and one source task whose joint MTL performance is worse than STL for the target task. Then, We vary the hidden width of a GAMLPmodel from 32 to 2048 and repeat MTL training. reports the 1 scores of the MTL and STL models on the target task. We observe thatthe MTL performance is consistently lower than STL, even as the width increases. This reaffirms our hypothesis that despite using largermodels as width increases, they still do not fix the negative transfers from the source task to the target task in multi-task learning. : This table reports the 1 score of a target task, comparing the STL and MTL with a source task that causes negativetransfer. Even after increasing the model size of GAMLP, there exists a consistent negative transfer.",
  "B.3Comparing the running time": "We provide a comparison of the running time of our approach with the baselines in terms of GPU hours evaluated on a single GPU. Wenotice that the running time of our approach is comparable to the naive MTL approach, using 3.5 running time on average compared to theNaive MTL. This is achieved by using early stopping and downsampling in our implementation to speed up the training of each MTL model,i.e., computing () on each subset . The results are reported in .",
  "B.4Comparison with additional community detection and task grouping methods": "We compare our approach with two other community detection methods, including MinCutPool and Deep Modularity Networks .These methods design GNN pooling methods for graph clustering. For each method, we train the pooling module together with the SIGNbase model. The results are shown in . We find that our approach can also outperform them by 5.8% on average.Furthermore, we compare our approach with clustering by two first-order task affinities, including the first-order task affinity andapproximating higher-order task affinity through averaging . The results are shown in . The results show that our approachoutperforms them by 2.5% on average. This validates the advantage of using higher-order task affinities over first-order task affinities. : Macro F1-score of community detection tasks on four social networks. We compare our approach with GNN-basedcommunity detection methods and two previous task grouping methods based on first-order task affinity. Each result is averagedover three random seeds.",
  "B.5Ablation study of Algorithm 1s parameters": "We discuss the three parameters in our approach: the number of task groups , the subset size , and the number of subsets . We find that alarger number of task groups yields better performance. Furthermore, our approach remains stable under the variation of subset size andnumber of subsets. The results are reported in .First, we ablate the number of task groups and vary it between 5, 10, 20, and 100. The results confirm our hypothesis that a largernumber of task groups leads to better performance. Moreover, = 20 yields comparable results to = 100, which achieves a 49.76 1 score.Therefore, we use = 20 in our experiments.Second, We vary the subset size between 5, 10, and 20. We observe similar performance for different task grouping settings, using = 10 slightly outperforming the other two. The result suggests that using a larger does not help because the number of related tasks incommunity detection applications is limited.Third, we vary the number of subsets between 1000, 1500, and 2000. We observe that using = 1000 still achieves comparableperformance as using = 2000. The performance difference is within 0.5%."
}