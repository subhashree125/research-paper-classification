{
  "ABSTRACT": "Graph neural networks (GNNs) are vulnerable to adversarial at-tacks, especially for topology perturbations, and many methodsthat improve the robustness of GNNs have received considerableattention. Recently, we have witnessed the significant success oflarge language models (LLMs), leading many to explore the greatpotential of LLMs on GNNs. However, they mainly focus on im-proving the performance of GNNs by utilizing LLMs to enhance thenode features. Therefore, we ask: Will the robustness of GNNs also beenhanced with the powerful understanding and inference capabilitiesof LLMs? By presenting the empirical results, we find that despitethat LLMs can improve the robustness of GNNs, there is still anaverage decrease of 23.1% in accuracy, implying that the GNNsremain extremely vulnerable against topology attacks. Therefore,another question is how to extend the capabilities of LLMs on graphadversarial robustness. In this paper, we propose an LLM-basedrobust graph structure inference framework, LLM4RGNN, whichdistills the inference capabilities of GPT-4 into a local LLM for iden-tifying malicious edges and an LM-based edge predictor for findingmissing important edges, so as to recover a robust graph structure.Extensive experiments demonstrate that LLM4RGNN consistentlyimproves the robustness across various GNNs. Even in some caseswhere the perturbation ratio increases to 40%, the accuracy of GNNsis still better than that on the clean graph. The source code can befound in",
  "Both authors contributed equally to this research. Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 25, August 37, 2025, Toronto, ON, Canada. 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-1245-6/25/08 ACM Reference Format:Zhongjian Zhang1, Xiao Wang2, Huichi Zhou3, Yue Yu1, Mengmei Zhang4,Cheng Yang1 and Chuan Shi1. 2025. Can Large Language Models Improvethe Adversarial Robustness of Graph Neural Networks?. In Proceedings ofthe 31st ACM SIGKDD Conference on Knowledge Discovery and Data MiningV.1 (KDD 25), August 37, 2025, Toronto, ON, Canada. ACM, New York, NY,USA, 14 pages.",
  "INTRODUCTION": "Graph neural networks (GNNs), as representative graph machinelearning methods, effectively utilize their message-passing mecha-nism to extract useful information and learn high-quality represen-tations from graph data . Despite great success, ahost of studies have shown that GNNs are vulnerable to adversarialattacks , especially for topology attacks ,where slightly perturbing the graph structure can lead to a dramaticdecrease in the performance. Such vulnerability poses significantchallenges for applying GNNs to real-world applications, especiallyin security-critical scenarios such as finance networks or med-ical networks .Threatened by adversarial attacks, several attempts have beenmade to build robust GNNs, which can be mainly divided into model-centric and data-centric defenses . From the model-centricperspective, defenders can improve robustness through model en-hancement, either by robust training schemes or new modelarchitectures . In contrast, data-centric defenses typi-cally focus on flexible data processing to improve the robustness ofGNNs. Treating the attacked topology as noisy, defenders primarilypurify graph structures by calculating various similarities betweennode embeddings . The above methods have receivedconsiderable attention in enhancing the robustness of GNNs.Recently, large language models (LLMs), such as GPT-4 , havedemonstrated expressive capabilities in understanding and infer-ring complex texts, revolutionizing the fields of natural languageprocessing , computer vision and graph . The per-formance of GNNs can be greatly improved by utilizing LLMs toenhance the node features . However, one question re-mains largely unknown: Considering the powerful understandingand inference capabilities of LLMs, will LLMs enhance or weaken theadversarial robustness of GNNs to a certain extent? Answering thisquestion not only helps explore the potential capabilities of LLMson graphs, but also provides a new perspective for the adversarialrobustness problem on graphs.Here, we empirically investigate the robustness of GNNs combin-ing six LLMs/LMs (language models), namely OFA-Llama2-7B ,",
  "KDD 25, August 37, 2025, Toronto, ON, Canada.Zhongjian Zhang, Xiao Wang and Huichi Zhou et al": "where S {1, 0, 1}|V||V| and S = S = 1 when the edgebetween nodes and is added. Conversely, it is removed ifand only if S = S = 1, and S = S = 0 implies that theedge remains unchanged. Here the added edges are consideredas negative edge set E, i.e., malicious edge set, and the removededges are considered as positive edge set E, i.e., important edgeset. Since the attack methods prefer adding edges over removingedges , to balance E and E, we sample a certain number ofclean edges from A to E. With E and E, we construct the queryedge set Eq = E E, which will be used to construct promptsfor requesting GPT-4.Next, based on E, we query the GPT-4 in an open-ended manner.This involves prompting the GPT-4 to make predictions on howmalicious an edge is and provide analysis for its decisions. Withthis objective, we design a prompt template that includes \"Systemprompt\", which is an open-ended question about how malicious theedge is, and \"User content\", which is the textual information of nodepairs , from E. The general structure of the template fol-lows: (where \"System prompt\" and \"User content\" also respectivelycorrespond to instruction and input in the instruction dataset.) System prompt: In the context of graph neural networks,attackers manipulate models by adding irrelevant edges or re-moving relevant ones, leading to incorrect predictions. Yourrole is crucial in defending against such attacks by evaluat-ing the relevance between pairs of nodes, which will help inidentifying and removing the irrelevant edges to mitigate theimpact of adversarial attacks on graph-based models. Giventextual information about two nodes, analyze the relevanceof these two nodes. Provide a concise analysis(approximately100 words) and assign an integer relevance score from 1 to 6,where 1 indicates completely irrelevant and 6 indicates directlyrelevant. Your response should be formatted in JSON, withtwo keys: \"Analysis\" for your written analysis and \"RelevanceScore\" for your numerical evaluation.User content: Node {Title, Abstract}.\\n\\nNode {Title,Abstract}. In the \"System prompt\", we provide background knowledge abouttasks and the specific roles played by LLMs in the prompt, which canmore effectively harness the inference capability of GPT-4 .Additionally, we require GPT-4 to provide a fine-grained rating ofthe maliciousness of edges on a scale from 1 to 6, where a lowerscore indicates more malicious, and a higher score indicates moreimportant. The concept of \"Analysis\" is particularly crucial, as it notonly facilitates an inference process in GPT-4 regarding predictionresults, but also serves as a key to distilling the inference capabilityof GPT-4 into local LLMs. Finally, the output of the instructiondataset is generated by GPT-4 as follows:",
  "Text-attributed Graphs (TAGs)": "Here, a Text-attributed graph (TAG), defined as G = (V, E, S), is agraph with node-level textual information, where V = {1, . . . , |V|},E = {1, . . . ,|E|} and S = {1, . . . ,|V|} are the node set, edge set, 55.063.071.079.087.0 Cora-Accuracy (%) GCN-SBert GCN-e5-large TAPE Vanilla GCN GCN-Llama2-7B OFA-SBert OFA-Llama2-7B 50.060.070.080.090.0 Pubmed-Accuracy (%) CleanAttack",
  ": The accuracy of different GNNs combiningLLMs/LMs against Mettack with a 20% perturbation rate": "and text set, respectively. The adjacency matrix of the graph G isdenoted as A R|V||V|, where A = 1 if nodes and areconnected, otherwise A = 0. In this work, we focus on the nodeclassification task on TAGs. Specifically, each node correspondsto a label that indicates which category the node belongsto. Usually, we encode the text set S as the node feature matrixX = {x1, . . . , x|V|} via some embedding techniques totrain GNNs, where x R. Given some labeled nodes V V, thegoal is training a GNN (A, X) to predict the labels of the remainingunlabeled nodes V = V \\ V.",
  "max minL( (G + ), yT),(1)": "where represents a perturbation to the graph G, which may in-clude perturbations to node features, inserting or deleting of edges,etc., represents all permitted and effective perturbations. yT isthe node labels of the target set T. L denotes the training loss ofGNNs, and is the model parameters of . Equation 1 indicates thatunder the worst-case perturbation , the adversarial robustnessof model is represented by its performance on the target set T.A smaller loss value suggests stronger adversarial robustness, i.e.,better model performance. In this paper, we primarily focus on therobustness under two topology attacks: (1) Targeted attacks ,where attackers aim to mislead the models prediction on specificnodes by manipulating the adjacent edges of , thus T = . (2)Non-targeted attacks , where attackers aim to degrade theoverall performance of GNNs but do not care which node is beingtargeted, thus T = test, where test denotes the test set.",
  "THE ADVERSARIAL ROBUSTNESS OF GNNSCOMBINING LLMS/LMS": "In this section, we empirically investigate whether LLMs enhanceor weaken the adversarial robustness of GNNs to a certain extent.Specifically, for the Cora and PubMed datasets, basedon non-contextualized embeddings encoded by BoW or TF-IDF , we employ Mettack with a 20% perturbation rate togenerate attack topology. We compare seven representative base-lines: TAPE utilizes LLMs to generate extra semantic knowl-edge relevant to the nodes. OFA employs LLMs to unify dif-ferent graph data and tasks, where OFA-SBert utilizes Sentence",
  "LLMGPT-4": "System prompt: In the context of graph neural networks Given textual information about twonodes, analyze the relevance of these two nodes Your response should be formatted in JSON,with two keys: \"Analysis\" for your written analysis and \"Relevance Score\" for your numericalevaluation. User content: Node !{Title, Abstract}. \\n\\n Node \"{Title, Abstract}.",
  ": Overall framework of LLM4RGNN": "Bert to encode the text of nodes, training and testing the GNNson each dataset independently. OFA-Llama2-7B involves traininga single GNN across the Cora, Pubmed, and OGBN-Arxiv datasets. Following the work , GCN-Llama2-7B, GCN-e5-large,and GCN-SBert represent the use of Llama2-7B, e5-large, and Sen-tence Bert as nodes text encoders, respectively. The vanilla GCNdirectly utilizes non-contextual embeddings. By reporting the nodeclassification accuracy on test to evaluate the robustness of modelsagainst the Mettack. As depicted in , we observe that underthe influence of Mettack, GNNs combining LLMs/LMs suffer froma maximum accuracy decrease of 37.9% and an average decrease of23.1%, while vanilla GCN suffers from a maximum accuracydecrease of 39.1% and an average accuracy decrease of 35.5%. Theresults demonstrate that GNNs combining LLMs/LMs remain ex-tremely vulnerable against topology perturbations. Another mean-ingful observation is that OFA-Llama2-7B, OFA-SBert, and TAPEhave significant performance improvements over vanilla GCN. Onepossible reason is that the introduction of additional knowledge canmitigate the impact of topology perturbations. Specifically, TAPEenhances node features by requesting LLMs to generate additionaltextual information. OFA incorporates other clean datasets andtasks through LLMs/LMs during the training to mitigate the impactof model poisoning.",
  "LLM4RGNN: THE PROPOSED FRAMEWORK": "In this section, we propose a novel LLM-based robust graph struc-ture inference framework, LLM4RGNN. As shown in ,LLM4RGNN involves three main parts: (a) instruction tuning alocal LLM, which distills the inference capability from GPT-4 into alocal LLM for identifying malicious edges; (b) training an LM-based edge predictor, which further distills the inference capability fromthe local LLM into LM-based edge predictor for finding missingimportant edges; (c) purifying the graph structure by removing ma-licious edges and adding important edges, making various GNNsmore robust.",
  "Instruction Tuning a Local LLM": "Given an attacked graph structure, one straightforward method isto query powerful GPT-4 to identify malicious edges on the graph.However, this method is extremely expensive, because there are|V|2 different perturbation edges on a graph. For example, forthe PubMed dataset with 19,717 nodes, the cost is approxi-mately $9.72 million. Thus, we hope to distill the inference capabil-ity of GPT-4 into a local LLM, to identify malicious edges. To thisend, instruction tuning based on GPT-4 is a popular fine-tuningtechnique , which utilizes GPT-4 to construct an instructiondataset, and then further trains a local LLM in a supervised fashion.The instruction dataset generally consists of instance (instruction,input, output), where instruction denotes the human instruction(a task definition in natural language) for LLMs, input is used assupplementary content for the instruction, and output denotes thedesired output that follows the instruction. Therefore, the key ishow to construct an effective instruction dataset for fine-tuning anLLM to identify the malicious edges.In the tuning local LLMs phase of (a), based on an open-source and clean graph structure A (TAPE-Arxiv23 ), we utilizethe existing attacks (Mettack , Nettack , and Minmax )to generate the perturbed graph structure A, thus we have themodification matrix S as follows:",
  "Analysis: {Analysis of predicted results}.Relevance Score: {Predicted integer scores from 1-6}": "In fact, it is difficult for GPT-4 to predict with complete accu-racy. To construct a cleaner instruction dataset, we design a post-processing filtering operation. Specifically, for the output of GPT-4,we only preserve the edges with relevance scores {1, 2, 3}from the negative sample set En, and the edges with {4, 5, 6} from the positive sample set Eq. The refined instruction datasetis then used to fine-tune a local LLM, such as Mistral-7B orLlama3-8B . After that, the well-tuned LLM is able to inferthe maliciousness of edges similar to GPT-4. We also provide casestudies of GPT-4 and the local LLM (Mistral-7B) in Appendix C.",
  "Training an LM-based Edge Predictor": "Now, given a new attacked graph structure A, our key idea is torecover a robust graph structure A. Intuitively, we can input eachedge of A into the local LLM and obtain its relevance score . Byremoving edges with lower scores, we can mitigate the impact ofmalicious edges on model predictions. Meanwhile, considering thatattackers can also delete some important edges to reduce modelperformance, we need to find and add important edges that do notexist in A. Although the local LLM can identify important edgeswith higher relevance scores, it is still very time and resource-consuming with |V|2 edges. Therefore, we further design an LM-based edge predictor, as depicted in (b), which utilizesSentence Bert as the text encoder and trains a lightweightmultilayer perceptron (MLP) to find missing important edges.Firstly, we introduce how to construct the feature of each edge.Inspired by , deep sentence embeddings have emerged as a pow-erful text encoding method, outperforming non-contextualized em-beddings . Furthermore, sentence embedding models offer alightweight method to obtain representations without fine-tuning.Consequently, for each node , we adopt a sentence embeddingmodel LM as texts encoder to extract representations h from theraw text , i.e., h = LM(). We concatenate the representationsof the node and as the feature for the corresponding edge.Then the edge label can be derived from as follows:",
  "1if > 40if 4 ,(3)": "here, we utilize the local LLM as an edge annotator to distill itsinference capability, and select 4 as the threshold to find the mostpositive edges. It is noted that there may be a label imbalanceproblem, where the number of positive edges is much higher thanthe negative. Thus, based on the cosine similarity, we select somenode pairs with a lower similarity to construct a candidate set.When there are not enough negative edges, we sample from thecandidate set to balance the training set.Next, we feed the feature of each edge into an MLP to obtain theprediction probability (, ) = MLP(h ||h). The cross-entropyloss function is used to optimize the parameters of MLP as:",
  "E = {(, ) | , A = 0, > and Top },(5)": "where (0, 1) is the threshold and is the maximum numberof edges. In this way, we can select the top neighbors for thecurrent node with predicted score greater than threshold , toestablish the most important edges for as possible. For all thenodes, we have the final important edge set Eadd = V E .",
  "Products": "0%79.860.1579.040.4278.750.2677.760.6278.450.2577.830.4875.870.3675.840.295%66.620.5676.340.3976.410.6076.700.6871.480.3575.200.2564.840.6072.670.6610%63.310.5275.800.2474.130.3775.480.7568.980.4174.750.3858.591.9771.800.4820%57.560.6476.570.4670.250.8274.980.5364.810.3174.320.3850.360.9673.710.81 4.3Purifying Attacked Graph StructureIn (c), the robust graph structure A is derived from thepurification of A. Specifically, new edges from Eadd will be addedin A. Simultaneously, with the relevance score of each edge, weremove the malicious edges in A by setting a purification threshold, i.e., edges with larger than are preserved, otherwise removed.The A is adaptive to any GNNs, making GNNs more robust.",
  "EXPERIMENTS": "5.1Experimental SetupDataset. We conduct experiments on four cross-dataset citationnetworks (Cora , Citeseer , Pubmed , OGBN-Arxiv )and one cross-domain product network (OGBN-Products ). Wereport the average performance and standard deviation over 10seeds for each result. More details refer to Appendix A.1.Baseline. First, LLM4RGNN is a general LLM-based framework toenhance the robustness of GNNs. Therefore, we select the classi-cal GCN and three robust GNNs (GAT , RGCN andSimp-GCN ) as baselines. Moreover, to more comprehensivelyevaluate LLM4RGNN, we also compare it with existing SOTA robustGNN frameworks, including ProGNN , STABLE , HANG-quad and GraphEdit1 , where GCN is selected as the objectfor improving robustness. More baseline introduction and imple-mentation details refer to Appendix A.2 and A.3, respectively.",
  "We report the accuracy (ACC ()) on representative transductivenode classification task. More results of inductive poisoning attacksrefer to Appendix B.1": "5.2.1Against Mettack. Non-targeted attacks aim to disrupt theentire graph topology to degrade the performance of GNNs onthe test set. We employ the SOTA non-targeted attack method,Mettack , and vary the perturbation rate from 0 to 20% with astep of 5%. We have the following observations: (1) From ,LLM4RGNN consistently improves the robustness across variousGNNs. For GCN, there is an average accuracy improvement of 24.3%and a maximum improvement of 103% across five datasets. For ro-bust GNNs, including GAT, RGCN and Simp-GCN, LLM4RGNNon average has 16.6%, 21.4%, and 13.7% relative improvements inaccuracy. Notably, despite fine-tuning the local LLM on the TAPE-Arxiv23 dataset, which does not include any medical or productsamples, there is still a relative accuracy improvement of 18.8%and 11.4% on the Pubmed and OGBN-Products, respectively. (2)Referring to , compared with existing robust GNN frame-works, LLM4RGNN achieves SOTA robustness, which benefits fromthe powerful understanding and inference capabilities of LLMs. (3)Combining and , even in some cases where the per-turbation ratio increases to 20%, after using LLM4RGNN to purifythe graph structure, the accuracy of GNNs is better than that on theclean graph. One possible reason is that the local LLM effectivelyidentifies malicious edges as negative samples, which helps train amore effective edge predictor to find missing important edges. 5.2.2Against DICE. To verify the defense generalization capabil-ity of LLM4RGNN, we also evaluate its effectiveness against anothernon-targeted attack, DICE . Notably, DICE is not involved in theconstruction process of the instruction dataset. Considering that",
  "%OOT79.230.3380.610.18-79.040.425%OOT76.240.4472.410.66-76.340.3910%OOT74.380.4069.880.86-75.800.2420%OOT72.210.4062.240.28-76.570.46": "DICE is not as effective as Mettack, we set higher perturbation ratesof 10%, 20% and 40%. The results are reported in and .Similar to the results under Mettack, LLM4RGNN consistently im-proves the robustness across various GNNs and is superior to otherrobust GNN frameworks. For GCN, GAT, RGCN and Simp-GCN,LLM4RGNN on average brings 8.2%, 8.8%, 8.1% and 6.5% relative im-provements in accuracy on five datasets. Remarkably, even in somecases where the perturbation ratio increases to 40%, the accuracyof GNNs is better than that on the clean graph. 5.2.3Against Nettack. Unlike non-targeted attacks, targeted at-tacks focus on fooling GNNs into misclassifying a particular node .Here, we employ the SOTA targeted attack, Nettack . Followingprevious work , nodes with a degree greater than 10 are selectedas the target nodes, and the number of perturbations applied to the",
  "%OOT79.230.3380.610.18-79.040.4210%OOT76.720.3277.060.29-77.660.2220%OOT75.150.2775.520.24-77.150.6240%OOT73.680.2669.010.17-77.020.56": "targeted node from 0 to 5 with a step of 1. As shown in and, results indicate that LLM4RGNN not only consistently im-proves the robustness of various GNNs, but also surpasses existingrobust frameworks, exhibiting exceptional resistance to Nettack. 5.2.4Against Adaptive Attack. Consider the worst-case sce-nario, where attackers have access to the well-tuned Mistral-7B.Thus, attackers can adaptively generate malicious edges that Mistral-7B rating >= 4, to avoid being removed. Based on Pubmed with moreedges, we control the perturbation ratios at 5% and 10%. As reportedin Tabel 6, the results indicate that LLM4RGNN effectively defendsagainst adaptive attack and consistently improves the robustnessof various GNNs. Although malicious edges {4, 5, 6} failed tobe removed, they are less aggressive than those {1, 2, 3}, andthe important edges can further mitigate their impact.",
  ": Node classification accuracy of LLM4RGNN underMettack-20% with different text perturbations": "CoraCiteseer PubmedArxiv Products GCN 30.0 40.0 50.0 60.0 70.0 80.0 90.0 Accuracy(%) CoraCiteseer PubmedArxiv Products GAT 30.0 40.0 50.0 60.0 70.0 80.0 90.0 Accuracy(%) CoraCiteseer PubmedArxiv Products RGCN 30.0 40.0 50.0 60.0 70.0 80.0 90.0 Accuracy(%) CoraCiteseer PubmedArxiv Products Sim-PGCN 30.0 40.0 50.0 60.0 70.0 80.0 90.0 Accuracy(%) Vanilla GCNLLM4RGNN w/o EPLLM4RGNN Full",
  "Model Analysis": "5.3.1Ablation Study. To assess the impact of key componentsin LLM4RGNN, we conduct ablation studies under Mettack witha 20% perturbation rate, where GCN is selected as training GNN.The results are depicted in , where \"Vanilla\" is without anymodifications to the attacked topology. The \"w/o EP\" only removesmalicious edges by the local LLM, while \"Full\" includes both remov-ing malicious edges and adding important edges. Across all settings,LLM4RGNN Full consistently outperforms other settings. Using thelocal LLM to remove most malicious edges can significantly reducethe impact of adversarial perturbation, improving the accuracy of",
  "GNNs. By employing the edge predictor to add important neighborsfor each node, additional information gain is provided to the centernodes, further improving the accuracy of GNNs": "5.3.2Impact of Text Quality. Considering that LLM4RGNN re-lies on textual information for reasoning, we analyze the impactof text quality on the models effectiveness. Specifically, againstthe worst-case scenario of 20% Mettack, we further add randomtext replacement perturbations to the Cora and Citeseer to reducethe text quality of nodes. As shown in , results show thatLLM4RGNNs performance varies by less than two points under10-40% perturbations, and surpasses existing robust GNN frame-works. A possible explanation is that LLMs have strong robustnessto text perturbations , and LLM4RGNN fully inherits it. 5.3.3Comparison with Different LLMs. To evaluate the gener-alizability of LLM4RGNN across different LLMs, we choose four pop-ular open-source LLMs, including Llama2-7B, Llama2-13B, Llama3-8B and Mistral-7B, as the starting checkpoints of LLM. We also",
  ": Analysis of instances number against Mettack-20%": "introduce a direct comparison using the closed-source GPT-3.5 andGPT-4. Additionally, the metric AdvEdge () is introduced to mea-sure the number and proportion of malicious edges remaining afterthe LLM performs the filtering operation. We report the resultsof GCN on Cora and Citeseer under Mettack with a perturbationratio of 20% (generating 1053 malicious edges for Cora and 845 forCiteseer). As reported in , we observe: (1) The well-tunedlocal LLMs are significantly superior to GPT-3.5 in identifying ma-licious edges, and the trained LM-based edge predictor consistentlyimproves accuracy, indicating that the inference capability of GPT-4 is effectively distilled into different LLMs and edge predictors.(2) A stronger open-source LLM yields better overall performance.Among them, the performance of fine-tuned Mistral-7B and Llama3-8B is comparable to that of GPT-4. We also provide a comprehensivecomparison between them in Appendix B.4. 5.3.4Hyper-parameter Analysis. First, we present the accu-racy of LLM4RGNN under different combinations of the probabilitythreshold and the maximum number of important edges in Fig-ure 6. The results indicate that the accuracy of LLM4RGNN variesminimally across different hyper-parameter settings, demonstratingits insensitivity to the hyper-parameters and . More results referto Appendix B.3. Besides, we report the accuracy and AdvEdge ofLLM4RGNN under different , the purification threshold of whetheran edge is preserved or not. As shown in , when the is setto 4, most malicious edges are identified and achieve optimal per-formance. This is because a low fails to identify malicious edgeseffectively, while a high removes more malicious edges but could remove some useful edges. Lastly, we set the number of instancesfor tuning the local LLM to 5000, 15000, and 26000, respectively, toanalyze the models effectiveness with different instance counts.As shown in , with only 5000 instances, the tuned localLLM can effectively identify malicious edges, surpassing the exist-ing SOTA method, which indicates that the excellent robustnessof LLM4RGNN can be achieved on a lower budget, approximately$46.7. Detailed tokens cost refer to Appendix A.4.",
  "Local LLM0.540.570.630.641.12Edge Predictor0.050.060.240.310.25": "5.3.5Efficiency Analysis. In LLM4RGNN, using 26,518 samplesto fine-tune the local LLM is a one-time process, controlled within 9hours. The edge predictor is only a lightweight MLP, with trainingtime on each dataset controlled within 3 minutes. The complexityof LLM inferring edge relationships is (|E|), and the edge pre-dictor is (|V|2), and their inference processes are parallelizable.We provide the average time for LLM to infer one edge and for thelightweight edge predictor to infer one node in . Overall, theaverage inference time for the local LLM and the edge predictor is0.7s and 0.2s, respectively, which is acceptable. Each experimentstotal inference time is controlled within 90 minutes. Here, we fur-ther discuss how to extend LLM4RGNN to large-scale graphs. Forthe local LLM with complexity (E|), we introduce the parallelinference framework vLLM and cache the edges inferred bythe LLM. For the edge predictor with complexity (|V|2), we infer",
  "VanillaLLM4RGNNVanillaLLM4RGNNVanillaLLM4RGNN": "0%68.330.0468.820.1464.990.1066.480.1664.503.5165.543.9410% 65.220.0569.260.0461.140.0867.850.1161.414.7667.252.9220% 62.130.0968.800.0757.770.1367.460.0859.394.6866.743.1640% 56.750.0568.400.0552.040.1166.780.0955.652.0966.262.90 only the top most similar nodes for each node (where |V|),to reduce the complexity to (|V|). As reported in , re-sults on complete OGBN-Arxiv (169,343 nodes and 1,166,243 edges)indicate the effectiveness of LLM4RGNN on the large-scale graph,with an average inference time of 7 hours (where is set to 2000). 5.3.6Purifying Edge Statistic. To analyze how LLM4RGNNdefends various attacks, we reported the number of edges added andremoved, and the percentage of malicious edges removed in .We find that LLM4RGNN removes an average of 82.4% of maliciousedges across five datasets, and mitigates the impact of remainingmalicious edges by adding massive important edges. An interestingobservation is that the LLM fine-tuned on TAPE-Arxiv performsbest at identifying malicious edges on OGBN-Arxiv, which indicatesthat using domain-specific LLMs can further enhance LLM4RGNN.",
  "Adversarial Attack and Defense on Graph": "Extensive studies have shown that attackerscan catastrophically degrade the performance of GNNs by mali-ciously perturbing the graph structure. For example, Nettack first to study the adversarial attacks on graph data, which pre-serves degree distribution and imposes constraints on feature co-occurrence to generate small deliberate perturbations. Subsequently,Mettack utilizes meta-learning while Minmax and PGD utilize projected gradient descent, to solve the bilevel problem un-derlying poisoning attacks. Threatened by adversarial attacks, manymethods have been proposed to defend against adver-sarial attacks. They are mainly categorized into model-centric anddata-centric. The methods of model-centric improve the robustnessthrough model enhancement, either by robust training schemes(e.g., adversarial training ) or designing new model architec-tures (e.g., RGCN , HANG , Mid-GCN). The methods ofdata-centric typically focus on flexible data processing. By treating the attacked topology as noisy, defenders primarily purify graphstructures by calculating various similarities between node embed-dings . For instance, ProGNN jointly trainsGNN and learns a clean adjacency matrix with graph properties.STABLE learns effective representations by unsupervised pre-training to refine graph structures.",
  "LLMs for Graph": "Recently, LLMs have been widely employed in graph-related tasks,which even outperform traditional GNN-based methods. Accordingto the role played by LLMs in graph-related tasks, some methodsutilize LLMs as an enhancer , to enhance the qualityof node features. Some methods directly use LLMs as a predic-tor , where the graph structure is described in natu-ral language for input to LLMs for prediction. Additionally, somemethods employ LLMs as an annotator , generator , and con-troller . Notably, recent GraphEdit is a data augmentationframework, which aims to improve the performance ceiling on theoriginal graph. In comparison, LLM4RGNN is a defense frameworkagainst topology attacks, which aims to improve the stability ofvarious GNNs under attack. Although both focus on utilizing LLMsfor graph structure learning, their motivations are distinct.",
  "CONCLUSION": "In this paper, we first explore the potential of LLMs on the graphadversarial robustness. Specifically, we propose a novel LLM-basedrobust graph structure inference framework, LLM4RGNN, whichdistills the inference capability of GPT-4 into a local LLM for identi-fying malicious edges and an LM-based edge predictor for findingmissing important edges, to efficiently purify attacked graph struc-ture, making GNNs more robust. Extensive experiments demon-strate that LLM4RGNN significantly improves various GNNs ro-bustness. Considering there are some graphs that lack textual in-formation, a plan is to extend LLM4RGNN to graphs without text. This work is supported by the National Key Research and Devel-opment Program of China (2023YFF0725103), the National Natu-ral Science Foundation of China (U22B2038, 62322203, 62172052,62192784), and the Young Elite Scientists Sponsorship Program(No.2023QNRC001) by CAST.",
  "Wayne Xin Zhao, Kun Zhou, Junyi Li, et al. A survey of large language models.arXiv preprint arXiv:2303.18223, 2023": "Qinkai Zheng, Xu Zou, Yuxiao Dong, et al. Graph robustness benchmark: Bench-marking the adversarial robustness of graph machine learning. Neural InformationProcessing Systems Track on Datasets and Benchmarks 2021, 2021. Huichi Zhou, Zhaoyang Wang, Hongtao Wang, et al. Evaluating the validity ofword-level adversarial attacks with large language models. In Findings of theAssociation for Computational Linguistics ACL 2024, 2024. Dingyuan Zhu, Ziwei Zhang, Peng Cui, et al. Robust graph convolutional net-works against adversarial attacks. In Proceedings of the 25th ACM SIGKDDinternational conference on knowledge discovery & data mining, 2019. Daniel Zgner, Amir Akbarnejad, and Stephan Gnnemann. Adversarial attackson neural networks for graph data. In Proceedings of the 24th ACM SIGKDDinternational conference on knowledge discovery & data mining, 2018.",
  "A.1Dataset": "In this paper, we select the TAPE-Arxiv23 with up-to-dateand rich texts to construct the instruction dataset, and use the fivepopular node classification datasets to evaluate model performance:Cora , Citeseer , Pubmed , OGBN-Arxiv and OGBN-Products . For each graph, following existing works , werandomly split the nodes into 10% for training, 10% for validation,and 80% for testing. Notably, for OGBN-Arxiv (with 169,343 nodesand 1,166,243 edges) and OGBN-Products (with 2 million nodes and61 million edges), in the main experiments, since we consider thestrongest Mettack and Nettack, with high complexity, construct-ing their attack topologies is not feasible. Thus, we adopt a nodesampling strategy to obtain their subgraph. We give detailedstatistics of each dataset in .",
  "A.3Implementation Detail": "For LLM4RGNN, we select Mistral-7B as our local LLM. Based onGPT-4, we construct approximately 26,518 instances for tuningLLMs and use the LoRA method to achieve parameter-efficientfine-tuning. To address the potential problem of label imbalance intraining LM-based edge predictor, we select the 4,000 node pairswith the lowest cosine similarity to construct the candidate set. We",
  ", 51815, 809, 9102, 970, 500$247.2": "set the hyper-parameters of LLM4RGNN as follows: For local LLMs,when no purification occurs, the purification threshold is selectedfrom {1, 2} to prevent deleting too many edges; otherwise, it isselected from {2, 3, 4}. For LM-based edge predictor, the threshold is tuned from {0.91, 0.93, 0.95, 0.97, 0.99} and the number of edges is tuned from {1, 3, 5, 7, 9}.We use DeepRobust, an adversarial attack repository, to im-plement all attacks as well as GCN, GAT, RGCN, and Sim-PGCN.We implement ProGNN, STABLE, and HANG-quad with the codeprovided by the authors. To facilitate fair comparisons, we tune allbaselines parameters using a grid search strategy. Unless otherwisespecified, we adopt the default parameter setting in the authorsimplementation. For GCN, the hidden size is 256 for OGBN-Arxivand 16 for others. For GAT, the hidden size is 128 for OGBN-Arxivand 8 for others. For RGCN and Sim-PGCN, the hidden size is 256for OGBN-Arxiv and 128 for others. For Sim-PGCN, we tune theweighting parameter is searched from {0.1, 0.5, 1, 5, 10, 50, 100}and is searched from {0.01, 0.1}. For STABLE, we tune the Jac-card similarity threshold 1 from {0.0, 0.01, 0.02, 0.03, 0.04, 0.05}, is tuned from {1, 3, 5, 7, 11, 13}, is tuned from 0.5 to 3. ForHANG_quad, we tune the time from {3, 6, 8, 15, 20, 25}, the hiddensize from {16, 32, 64, 128}, and dropout from {0.2, 0.4, 0.6, 0.8}. Forall experiments, we select the optimal hyper-parameters on thevalidation set and apply them to the test set.",
  "A.4Computing Environment and Resource": "The implementation of LLM4RGNN utilized the PyG module. WithGPT-4, the token costs for constructing different sizes of instructiondatasets are reported in , and it is \"spend once, use forever\".The minimum resource requirements for LLMs are as follows: The7B, 8B and 13B LLMs require 16G, 20G, and 32G for fine-tuning, and15G, 16G, and 26G for deploying. The experiments are conductedin a computing environment with the following specifications: OS: Linux ubuntu 5.15.0-102-generic. CPU: Intel(R) Xeon(R) Platinum 8358 CPU @ 2.60GHz. GPU: NVIDIA A800 80GB.",
  "B.1Defense against Inductive Poisoning Attack": "We further evaluate the generalization of LLM4RGNN under in-ductive poisoning attacks. We conduct inductive experiments withMettack on the Cora and Citeseer. Specifically, we randomly splitthe data into training, validation, and test sets with a 1:8:1 ratio.During training, we ensure the removal of test nodes and theirconnected edges from the graph. We perform Mettack on the vali-dation set, purify the attacked graph using LLM4RGNN, and usethe purified graph to train GNNs. The trained GNNs are then pre-dicted on the clean test set. As reported in , where we onlyreport the baselines that support the inductive setting, results showthat under the inductive setting, LLM4RGNN not only consistently",
  "B.2The Impact of Different Prompt Variant": "Recall that we utilize the ground truth of the query edge set to filterthe incorrect prediction of GPT-4, there is another alternative is todirectly take the ground truth as input of GPT-4. Specifically, werequire GPT-4 to provide analysis and edge ratings ranging from 4to 6 for a non-malicious edge, while providing edge ratings rangingfrom 1 to 3 for a malicious edge. Considering an instruction datasetwith a size of 7500, we compared the results of the aforementionedmethod (Auxiliary Label) with our method (Filter). As reported in, the performance variations of LLM4RGNN are minimal,demonstrating that LLM4RGNN is not sensitive to prompt design.Moreover, the reason why the lower performance of AuxiliaryLabel is that the edge label may be considered by GPT-4 during thegenerating analysis, but it is inaccessible during testing.",
  "CCASE STUDY": "LLMs have powerful understanding and inference abilities to com-plex text, thereby can effectively infer edge relations with texts.Here, we show some cases using GPT-4 and well-tuned Mistral-7Bto infer the relationships between nodes. We find that the well-tuned Mistral-7B possesses the edge relation inference ability ofGPT-4. They infer the edge relations and provide analysis by dis-cussing the background, problems, methods, and applications ofthe two nodes.",
  "C.1TAPE-Arxiv23 (GPT-4)": "User content: Node 1Title: when renewable energymeets building thermal mass a real time load managementscheme\\nAbstract: We consider the optimal power man-agement in renewable driven smart building MicroGridunder noise corrupted conditions as a stochastic optimiza-tion problem. We first propose our user satisfaction andelectricity consumption balanced (USECB) profit modelas the objective for optimal power management. We thencast the problem in noise corrupted conditions into theclass of expectation maximizing in stochastic optimizationproblem with convex constraints. For this task, we designa Bregemen projection based mirror decent algorithm asan approximation solution to our stochastic optimizationproblem. Convergence and upper-bound of our algorithmwith proof are also provided in our paper. We then conducta broad type of experiment in our simulation to test thejustification of our model as well as the effectiveness ofour algorithm.Node 2Title: hiding sound in image by k lsb muta-tion\\nAbstract: In this paper a novel approach to hidesound files in a digital image is proposed and implementedsuch that it becomes difficult to conclude about the exis-tence of the hidden data inside the image. In this approach,we utilize the rightmost k-LSB of pixels in an image toembed MP3 sound bits into a pixel. The pixels are so cho-sen that the distortion in image would be minimized dueto embedding. This requires comparing all the possiblepermutations of pixel values, which may would lead toexponential time computation. To speed up this, CuckooSearch (CS) could be used to find the most optimal solution.The advantage of using proposed CS is that it is easy toimplement and is very effective at converging in relativelyless iterations/generations. Analysis: The two nodes represent research in differentdomains: Node1 discusses renewable energy and buildingthermal mass in the context of smart grids, while Node2focuses on hiding sound files in images using k-LSB mu-tation and Cuckoo Search. There is no direct connectionbetween the optimization of renewable energy in buildingsand the embedding of sound files in images. The topics areunrelated, and the research methods and applications aredistinct.Relevance Score: 1 User content: Node 1Title: a multilingual view of un-supervised machine translation\\nAbstract: We present aprobabilistic framework for multilingual neural machinetranslation that encompasses supervised and unsupervisedsetups, focusing on unsupervised translation. In additionto studying the vanilla case where there is only monolin-gual data available, we propose a novel setup where onelanguage in the (source, target) pair is not associated withany parallel data, but there may exist auxiliary paralleldata that contains the other. This auxiliary data can natu-rally be utilized in our probabilistic framework via a novelcross-translation loss term. Empirically, we show that ourapproach results in higher BLEU scores over state-of-the-art unsupervised models on the WMT14 English-French,WMT16 English-German, and WMT16 English-Romaniandatasets in most directions. In particular, we obtain a +1.65BLEU advantage over the best-performing unsupervisedmodel in the Romanian-English direction.Node 2Title: explicit cross lingual pre training for unsu-pervised machine translation\\nAbstract: Pre-training hasproven to be effective in unsupervised machine transla-tion due to its ability to model deep context informationin cross-lingual scenarios. However, the cross-lingual in-formation obtained from shared BPE spaces is inexplicitand limited. In this paper, we propose a novel cross-lingualpre-training method for unsupervised machine transla-tion by incorporating explicit cross-lingual training signals.Specifically, we first calculate cross-lingual n-gram embed-dings and infer an n-gram translation table from them.With those n-gram translation pairs, we propose a newpre-training model called Cross-lingual Masked LanguageModel (CMLM), which randomly chooses source n-gramsin the input text stream and predicts their translation candi-dates at each time step. Experiments show that our methodcan incorporate beneficial cross-lingual information intopre-trained models. Taking pre-trained CMLM models asthe encoder and decoder, we significantly improve theperformance of unsupervised machine translation. Analysis: Both nodes discuss advancements in unsuper-vised machine translation, focusing on the use of cross-lingual data and methods to improve translation accuracy.Node1 introduces a probabilistic framework for multilin-gual neural machine translation, including a novel cross-translation loss term. Node2 proposes a novel cross-lingualpre-training method for unsupervised machine translation,emphasizing the importance of explicit cross-lingual train-ing signals. The common themes of unsupervised machinetranslation, cross-lingual data, and the pursuit of highertranslation accuracy suggest a high relevance between thetwo nodes.Relevance Score: 6",
  "C.2Cora (Mistral-7B)": "User content: Node 1Title: A Neural Network Model ofMemory Consolidation\\nAbstract: Some forms of memoryrely temporarily on a system of brain structures located inthe medial temporal lobe that includes the hippocampus.The recall of recent events is one task that relies cruciallyon the proper functioning of this system. As the eventbecomes less recent, the medial temporal lobe becomesless critical to the recall of the event, and the recollectionappears to rely more upon the neocortex. It has been pro-posed that a process called consolidation is responsiblefor transfer of memory from the medial temporal lobe tothe neocortex. We examine a network model proposed byP. Alvarez and L. Squire designed to incorporate some ofthe known features of consolidation, and propose severalpossible experiments intended to help evaluate the perfor-mance of this model under more realistic conditions. Fi-nally, we implement an extended version of the model thatcan accommodate varying assumptions about the numberof areas and connections within the brain and memorycapacity, and examine the performance of our model onAlvarez and Squires original task.Node 2Title: A Preliminary Investigation of Evolution asa Form Design Strategy\\nAbstract: We describe the prelim-inary version of our investigative software, GGE Genera-tive Genetic Explorer, in which genetic operations interactwith Au-toCAD to generate novel 3D forms for the archi-tect. GGE allows us to asess how evolutionary algorithmsshould be tailored to suit Architecture CAD tasks. Analysis: The two nodes represent research in differentdomains: Node1 discusses a neural network model of mem-ory consolidation in the brain, while Node2 focuses on asoftware tool for generating 3D forms in architecture us-ing evolutionary algorithms. There is no direct connectionbetween the brains memory consolidation process andthe evolution of 3D forms in architecture. The topics areunrelated, and the expertise required for each is distinct.Relevance Score: 1 User content: Node 1Title: Constructive Algorithms forHierarchical Mixtures of Experts\\nAbstract: We presenttwo additions to the hierarchical mixture of experts (HME)architecture. We view the HME as a tree structured clas-sifier. Firstly, by applying a likelihood splitting criteria toeach expert in the HME we \"grow\" the tree adaptivelyduring training. Secondly, by considering only the mostprobable path through the tree we may \"prune\" branchesaway, either temporarily, or permanently if they becomeredundant. We demonstrate results for the growing andpruning algorithms which show significant speed ups andmore efficient use of parameters over the conventionalalgorithms in discriminating between two interlocking spi-rals and classifying 8-bit parity patterns.Node 2Title: CLASSIFICATION USING HIERARCHICALMIXTURES OF EXPERTS\\nAbstract: There has recentlybeen widespread interest in the use of multiple models forclassification and regression in the statistics and neuralnetworks communities. The Hierarchical Mixture of Ex-perts (HME) has been successful in a number of regressionproblems, yielding significantly faster training throughthe use of the Expectation Maximisation algorithm. In thispaper we extend the HME to classification and results arereported for three common classification benchmark tests:Exclusive-Or, N-input Parity and Two Spirals. Analysis: Both nodes discuss the Hierarchical Mixtureof Experts (HME) architecture, with Node1 focusing onconstructive algorithms for HME and Node2 on extendingHME to classification tasks. The abstracts of both nodesmention the use of HME in classification problems, indicat-ing a direct relevance in the context of machine learningand classification techniques. The shared focus on HMEand its application in classification problems suggests ahigh relevance between the two nodes.Relevance Score: 6"
}