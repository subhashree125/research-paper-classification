{
  "ABSTRACT": "Urban spatio-temporal prediction is crucial for informed decision-making, such as traffic management, resource optimization, andemergence response. Despite remarkable breakthroughs in pre-trained natural language models that enable one model to handlediverse tasks, a universal solution for spatio-temporal prediction re-mains challenging. Existing prediction approaches are typically tai-lored for specific spatio-temporal scenarios, requiring task-specificmodel designs and extensive domain-specific training data. In thisstudy, we introduce UniST, a universal model designed for generalurban spatio-temporal prediction across a wide range of scenarios.Inspired by large language models, UniST achieves success through:(i) utilizing diverse spatio-temporal data from different scenarios,(ii) effective pre-training to capture complex spatio-temporal dy-namics, (iii) knowledge-guided prompts to enhance generalizationcapabilities. These designs together unlock the potential of buildinga universal model for various scenarios. Extensive experimentson more than 20 spatio-temporal scenarios demonstrate UniSTsefficacy in advancing state-of-the-art performance, especially infew-shot and zero-shot prediction. The datasets and code implemen-tation are released on",
  "INTRODUCTION": "Pre-trained foundation models have showcased remarkable suc-cess in Natural Language Processing (NLP) , particularlyexcelling in few-shot and zero-shot settings . However, simi-lar breakthroughs have not yet been achieved in the field of urbanspatio-temporal prediction . In this paper, our goal isto establish a foundation model for general urban spatio-temporalprediction specifically, to develop a universal model that offers su-perior performance and powerful generalization capabilities acrossdiverse spatio-temporal scenarios. This entails training a singlemodel capable of effectively handling various urban contexts, en-compassing various domains such as human mobility, traffic andcommunication networks across different cities.The significance of such a universal model lies in its ability toaddress prevalent data scarcity issues in urban areas. The varyinglevels of digitalization across domains and cities often result in im-balanced and incomplete datasets. Despite notable advancements inexisting spatio-temporal modeling approaches ,their effectiveness is typically confined to specific domains withina single city. The reliance on extensive training data further im-pedes the models generalization potential. Consequently, currentsolutions are still far from universality, and remain narrowlyapplicable.A universal spatio-temporal model must possess two essentialcapabilities. Firstly, it must be capable of leveraging abundant andrich data from different urban scenarios for training. The trainingof the foundational model should ensure the acquisition of ampleand rich information . Second, it should demonstrate robustgeneralization across different spatio-temporal scenarios. Especiallyin scenarios with limited or no training data, the model can stillwork well without obvious performance degradation .However, realizing the aforementioned capabilities encounterssignificant challenges specific to spatio-temporal data, which im-pede the direct application of current foundation models developedfor language and vision domains. The first challenge arises fromthe inherent diverse formats of spatio-temporal datasets. Unlikelanguages with a natural and unified sequential structure or imagesand videos adhering to standardized dimensions, spatio-temporaldata collected from different sources exhibit highly varied features.These include variable dimensions, temporal durations, and spatial",
  ": The transition from traditional separate deep learn-ing models to a one-for-all universal model for urban spatio-temporal prediction": "coverages that differ significantly, posing difficulties in standardiz-ing their structure. The second challenge arises from high variationsin data distributions across multiple scenarios. Faced with highly dis-tinct spatio-temporal patterns, the model may struggle to adapt tothese differences. Unlike language, which benefits from a sharedvocabulary, various scenarios of different domains and cities oftenoperate on entirely different spatial and temporal scales, lackingcommon elements for effective training and generalization.Although the displayed spatio-temporal patterns vary signifi-cantly, there are certain underlying laws that should be commonamong them. This principle arises from the intuition that humanactivity influences various spatio-temporal data generated in ur-ban settings, leading to the existence of universal patterns. Forexample, traffic speed and communication networks exhibit dis-tinct spatio-temporal patterns, yet both are influenced by humanmobility and therefore adhere to similar underlying principles. Ad-ditionally, while temporal periodic patterns vary across domains,they share fundamental concept of repetition. Furthermore, citylayouts vary considerably between different urban areas, but therelationships among various functional zones within cities mayexhibit shared characteristics. Therefore, the key to building a one-for-all model is to capture, align and leverage these shared whileunderlying characteristics effectively.To this end, we introduce UniST, a universal solution for ur-ban spatio-temporal prediction through advanced pre-training andprompt learning. Notably, UniST achieves three essential capabili-ties of:",
  "(3) utilizing spatio-temporal prompts to align underlying sharedpatterns across scenarios": "UniST achieves the above capabilities through its holistic de-sign driven by four key components: data, architecture, pre-training,and prompt learning. Firstly, we harness the rich diversity inherentin spatio-temporal scenarios by leveraging extensive data fromvarious domains and cities. Secondly, we design spatio-temporal patching to unify diverse data into a sequential format, facilitatingthe utilization of the powerful Transformer architecture. Thirdly,drawing inspiration from large language and vision models ,UniST adopts the widely-used generative pre-training strategy Masked Token Modeling (MTM). We further enhance the modelscapability to capture complex spatio-temporal relationships by em-ploying multiple masking strategies that comprehensively addressmulti-perspective correlations. Moreover, informed by the estab-lished domain knowledge in spatio-temporal modeling, we designan innovative prompt learning approach. The elaborated promptnetwork identifies underlying and shared spatio-temporal patterns,adapting dynamically to generate useful prompts. In this way, UniSTaligns distinct data distributions of various datasets and advancestowards developing a one-for-all universal model. We summarizeour contributions as follows: To our best knowledge, this the first attempt to address universalspatio-temporal prediction by investigating the potential of aone-for-all model in diverse spatio-temporal scenarios. We propose UniST that harnesses data diversity and achieves uni-versal spatio-temporal prediction through advanced pre-trainingand prompt learning. It has made a paradigm shift from tradi-tional separate deep learning methods to a one-for-all model. Extensive experiments demonstrate the generality and univer-sality of UniST. It achieves new state-of-the-art performanceon various prediction tasks, particularly, superior few-shot andzero-shot capabilities.",
  "RELATED WORK": "Urban Spatio-Temporal Prediction. Urban spatio-temporal pre-diction aims to model and forecast the dynamic patterns ofurban activities over space and time. Deep learning techniques haspropelled significant advancements. A spectrum of models, includ-ing CNNs , RNNs , ResNets , MLPs ,GNNs , Transformers , and diffusion mod-els , have been introduced to capture spatio-temporal pat-terns. Simultaneously, cutting-edge techniques like meta-learning , contrastive learning , and adversarial learning are also utilized. However, most approaches remain constrainedby training separate models for each specific dataset. Some stud-ies explore transfer learning between cities, however,a certain amount of data samples in the target city are still required.Current solutions are restrictive to specified spatio-temporal scenar-ios and require training data, while our model allows generalizationacross diverse scenarios and provides a one-for-all solution. Foundation Models for Spatio-temporal Data and Time Se-ries. Inspired by the remarkable strides in foundation models forNLP and CV , foundation models for urban predictionhave emerged recently. Some explorations unlock the potential oflarge language models (LLMs) in this context. Intelligent urban sys-tems like CityGPT , CityBench and UrbanGPT havedemonstrated proficiency in addressing language-based tasks. Addi-tionally, LLMs are utilized for describing urban-related images to benefit downstream tasks and predict user activities . More-over, the application of LLMs extends to traffic signal control ,showcasing their utility in tackling complex spatio-temporal prob-lems beyond languages. Recently, there also has been great progress",
  "(1) Whether can leverage diverse datasets with diverse formats.(2) Restricted in the same city": "in foundation models for time series . Unlike time se-ries characterized by a straightforward sequential structure, spatio-temporal data presents a more intricate nature with intertwineddependencies across both spatial and temporal dimensions. Whileexploring the integration of LLMs is promising, its important to rec-ognize that spatio-temporal data is not inherently generated by lan-guage. Thus, developing foundation models specifically trained onpure spatio-temporal data is also an important direction. In ,we compare the essential properties of UniST with other approachesemploying pre-training, prompt learning, or LLMs. UniST encom-passes all these essential capabilities, whereas other approacheshave certain limitations. Prompt Learning. Prompt learning has achieved superior perfor-mance in large models , with the goal of enhancingthe generalization capability of pretrained models on specific tasksor domains. Typically, language models usually use a limited num-ber of demonstrations as prompts and vision models often employa learnable prompt network to generate useful prompts, known asprompt learning. Our research aligns with prompt learning, wherespatio-temporal prompts are adaptively generated based on spatio-temporal patterns through a prompt network.",
  "METHODOLOGY3.1Preliminary": "Spatial and Temporal Partitions. We use a grid system for spatialpartitioning, dividing the city into equal, non-overlapping areasdefined by longitude and latitude on an map. For each area,the temporal dynamics are recorded at certain intervals.Spatio-Temporal Data. A spatio-temporal data is defined as afour-dimensional tensor with dimensions , where represents time steps, represents the number of variables, and represent spatial grids. , , , and can vary across differentspatio-temporal scenarios.Spatio-Temporal Prediction. For a specific dataset, given his-torical observations for the grid map, we aim to predict the future steps. The spatio-temporal prediction task can be formulated aslearning a -parameterized model F : [:+] = F ([: ]).Few-Shot and Zero-Shot Predictions. The model is trained onmultiple source datasets and then adapted to a target dataset. Infew-shot learning, it is fine-tuned with a small amount of target",
  "Pre-training and Prompt Learning": "Universal spatio-temporal prediction aims to empower a singlemodel to effectively handle diverse spatio-temporal scenarios, re-quiring the unification of varied spatio-temporal data within acohesive model. This necessitates addressing significant distribu-tion shifts across datasets of different scenarios. To achieve thisgoal, we propose a framework for pre-training and prompt learning,leading to a universal prediction model, UniST. shows theoverview architecture, detailing UniST with two stages: Stage 1: Large-scale spatio-temporal pre-training. Differentfrom existing methods limited to a single dataset, our approachutilizing extensive spatio-temporal data from a variety of domainsand cities for pre-training. Stage 2: Spatio-temporal knowledge-guided prompt learn-ing. We introduces a prompt network for in-context learning,where the generation of prompts is adaptively guided by well-developed spatio-temporal domain knowledge, such as spatialhierarchy and temporal periodicity.",
  "Base Model": "Our base model is a Transformer-based encoder-decoder archi-tecture. Through spatio-temporal patching, it can handle diversespatio-temporal data in a unified sequential format.Spatio-Temporal Patching. The conventional Transformerarchitecture is designed for processing 1D sequential data. However,spatio-temporal data possesses a 4D structure. To accommodate this,we first split the data into channel-independent instances, which are3D tensors. Then, we utilize spatio-temporal patching to transformthe 3D tensor, denoted as R , into multiple smaller 3Dtensors. If the original shape is , and the patch size is(,,), the resulting sequence is given by R , = , =",
  ", =": ".This transformation involves a 3D convolutional layer with akernel size and stride both set to (,,). The process can be ex-pressed as = Conv3 (), where represents the converted1D sequential data. The sequence length of is .Positional Encoding. As the original Transformer architecturedoes not consider the order of the sequence, we follow the commonpractice that incorporate positional encoding . To enhance gener-alization, we choose sine and cosine functions rather than learnableparameters for positional encoding. This encoding is separatelyapplied to the spatial and temporal dimensions.Encoder-Decoder Structure. The base model utilizes an encoder-decoder framework inspired by Masked Autoencoder (MAE) .It processes input patches with a certain masking ratio, where theencoder takes the unmasked patches and the decoder reconstructsthe image using the encoders output and the masked patches. Ourfocus is on capturing comprehensive spatio-temporal dependen-cies, including both high-level and low-level relationships, withthe goal of accurately predicting values at specific time and spacecoordinates. Unlike MAE, which uses a lightweight decoder for pre-training, our model employs a full-sized decoder that plays a crucialrole in both pre-training and fine-tuning. It can be formulated as:",
  "Spatio-Temporal Self-Supervised Pre-train": "In pretrained language models, the self-supervised learning task iseither masking-reconstruction or autoregressive prediction .Similarly, in vision models, visual patches are randomly maskedand the pre-training objective is to reconstruct the masked pix-els. To further augment the models capacity to capture intricatespatio-temporal relationships and intertwined dynamics, we intro-duce four distinct masking strategies during the pre-training phase,which are shown in the left box in the stage 1 of . Supposethe masking percentage is , we explain these strategies as follows: Random masking. This strategy is similar to the one used inMAE, where spatio-temporal patches are randomly masked. Itspurpose is to capture fine-grained spatio-temporal relationships.",
  "Spatio-Temporal Knowledge-Guided Prompt": "Prompt learning plays a critical role in enhancing UniSTs general-ization ability. Before delving into the details of our prompt design,it is essential to discuss why pre-trained models can be applied tounseen scenarios. 3.5.1Spatial-Temporal Generalization. In urban predictiontasks, the distributions of features and labels differ across domainsand cities, denoted as , , where and denotefeatures and labels, while and represent different cities or do-mains. Taken and as a simple example, generalization involvesleveraging knowledge acquired from the dataset and adapt it tothe dataset. The key point lies in identifying and aligning relatedpatterns between and datasets. While finding similar patternsfor an entire dataset may be challenging, we claim that identi-fying and aligning fine-grained patterns is feasible. Specifically,we provide some assumptions that applies to prompt-empoweredspatio-temporal generalization, which are expressed as follows:",
  "Based on these assumptions, our core idea is that for differentinputs with distinct spatio-temporal patterns, customized promptsshould be generated adaptively": "3.5.2Spatio-Temporal Domain Knowledge. Given the afore-mentioned assumptions, a critical consideration is how to define theconcept of similarity to identify and align shared spatio-temporalpatterns. Here we leverage insights from well-established domainknowledge in spatio-temporal modeling , encompassingproperties related to both space and time. There are four aspects toconsider when examining these properties: Spatial closeness: Nearby units may influence each other. Spatial hierarchy: The spatial hierarchical organization impactsthe spatio-temporal dynamics, requiring a multi-level perceptionon the city structure.",
  "Temporal period: Daily or weekly patterns exhibit similarities,displaying a certain periodicity": "For simplicity, we provide some straightforward implementa-tions, which are shown in the four networks in , i.e., Net,Net, Net, and Net. For the spatial dimension, we first em-ploy an attention mechanism to merge the temporal dimension intoa representation termed . Then, to capture spatial dependencieswithin close proximity, a two-dimensional convolutional neuralnetwork (CNN), i.e., Net, with a kernel size of 3 is employed.To capture spatial hierarchies, we utilize CNNs with larger ker-nel sizes, i.e., Net. These larger kernels enable the perception ofspatial information on larger scales, which facilitate to constructa hierarchical perspective. As for the temporal dimension, we em-ploy an attention network, i.e., Net, to aggregate the previousM steps denoted as . Regarding the temporal period, we selectcorresponding time points from the previous N days, denoted as .Subsequently, we employ another attention network, i.e., Net,to aggregate the periodical sequence, which captures long-termtemporal patterns. The overall process is formulated as follows:",
  "= Attention()": "It is essential to emphasize that the learning of , , , and is not restricted by our practice. Practitioners have the flexibilityto employ more complex designs to capture richer spatio-temporalproperties. For example, Fourier-based approaches can beutilized to capture periodic patterns. 3.5.3Spatio-Temporal Prompt Learner. Given the represen-tations of properties derived from spatio-temporal domain knowl-edge, the pivotal question is how to generate promptshow doesspatio-temporal knowledge guide prompt generation? Here we utilizeprompt learning techniques. While prompt learning in computer vi-sion often train fixed prompts for specific tasks such as segmen-tation, detection, and classification. Due to the high-dimensionaland complex nature of spatio-temporal patterns, training a fixedprompt for each case becomes impractical.To tackle this issue, we draw inspirations from memory net-works and propose a novel approach that learns a spatial mem-ory pool and a temporal memory pool. In the prompt learningprocess, these memory pools are optimized to store valuable in-formation about spatio-temporal domain knowledge. As shown in, the spatial and memory pools are defined as follows:",
  "= {(,0,,0), (,1,,1), ..., (, 1,, 1)},": "where ,,,,,,,, {0, 1, ..., 1} are all learnable pa-rameters, and the memory is organized in a key-value structurefollowing existing practice .Subsequently, useful prompts are generated based on these opti-mized memories. This involves using the representations of spatio-temporal properties as queries to extract valuable memory knowl-edge, i.e., pertinent embeddings from the memory pool. illustrates the process, and it is formulated as follows:",
  ",,,": "where , , , represent four representations related tofour types of spatio-temporal domain knowledge, and , , , are the extracted prompts. This allows the model to adaptively se-lect the most useful information for prediction. These prompts arethen integrated into the input space of the Transformer architecture,which are displayed in the upper part of .",
  "PERFORMANCE EVALUATIONS4.1Experimental Setup": "To evaluate the performance of UniST, we conducted extensiveexperiments on more than 20 spatio-temporal datasets.Datasets. The datasets we used cover multiple cities, spanningvarious domains such as crowd flow, dynamic population, trafficspeed, cellular network usage, taxi trips, and bike demand. Appen-dix and provide a summary of the datasets we used.These spatio-temporal datasets originate from distinct domains andcities, and have variations in the number of variables, samplingfrequency, spatial scale, temporal duration, and data size.",
  "UniST (one-for-all)19.836.714.252.263.561.31": "Results. presents the short-term prediction results, with aselection of datasets due to space constraints. The complete resultscan be found in and in Appendix E. As we canobserve from , UniST consistently outperforms all baselinesacross all datasets. Compared with the best baseline of each dataset,it showcases a notable average improvement. Notably, time seriesapproaches such as PatchTST and iTransformer exhibit inferiorperformance compared to spatio-temporal methods. This under-scores the importance of incorporating spatial dependency as priorknowledge for spatio-temporal prediction tasks. Another observa-tion is that PatchTST(one-for-all) performs worse than PatchTSTdedicated for each dataset, suggesting that the model struggles todirectly adept to these distinct data distributions. Moreover, base-line approaches exhibit inconsistent performance across diversedatasets, indicating their instability across scenarios. The consistentsuperior performance of UniST across all scenarios underscoresthe significant potential and benefits of a one-for-all model. More-over, it demonstrates UniSTs capability to orchestrate diverse data,where different datasets can benefit each other.",
  "Long-Term Prediction": "Setups. Here we extend the input step and prediction horizonto 64 following . This configuration accommodates pro-longed temporal dependencies, allowing us to gauge the modelsproficiency in capturing extended patterns over time. Similar tothe short-term prediction, UniST is directly evaluated across alldatasets, while specific models are individually trained for eachbaseline on respective datasets.",
  "UniST (zero-shot)": ": (a) Few-shot performance of UniST and baselines onCrowd and BikeNYC datasets using only 1% of the trainingdata. (b) Few-shot performance of UniST and baselines usingonly 5% of the training data. The Dashed red lines denote thezero-shot performance of UniST. the best baseline of each dataset, it yields an average improvementof 10.1%. This highlights UniSTs capability to comprehend tem-poral patterns effectively and its robustness in generalizing acrossextended durations. in Appendix E illustrates the completeresults.",
  "Few-Shot Prediction": "Setups. The hallmark of large foundation models lies in their ex-ceptional generalization ability. The few-shot and zero-shot evalua-tions are commonly employed to characterize the ultimate tasks foruniversal time series forecasting . Likewise, the few-shotand zero-shot prediction capability is crucial for a universal spatio-temporal model. In this section, we assess the few-shot learningperformance of UniST. Each dataset is partitioned into three seg-ments: training data, validation data, and test data. In few-shotlearning scenarios, when confronted with an unseen dataset duringthe training process, we utilized a restricted amount of trainingdata, specifically, 1%, 5%, 10% of the training data. We choose somebaselines with relatively good performance for the few-shot set-ting evaluation, We also compare with meta-learning baselines, i.e.,MAML and MetaST, and pretraining and finetuning-based timeseries method, i.e., PatchTST. Results. Appendix to illustrate the overall few-shot results. Due to the space limit, only illustrates the 1%few-shot learning results on two datasets. In these cases, UniST stilloutperforms all baselines, it achieves a larger relative improvementover baselines compared to long-term and short-term predictions.The transferability can be attributed to successful knowledge trans-fer in our spatio-temporal prompt.",
  "Zero-Shot Prediction": "Setups. Zero-shot inference serves as the ultimate task for assess-ing a models adaptation ability. In this context, after training ona diverse collection of datasets, we evaluate UniST on an entirelynovel dataseti.e., without any prior training data from it. The testdata used in this scenario aligns with that of normal prediction andfew-shot prediction. Results. also compares the performance of UniST (zero-shot) and baselines (few-shot). As observed, UniST achieves remark-able zero-shot performance, even surpassing many baselines trainedwith training data that are highlighted by red dashed lines. We at-tribute these surprising results to the powerful spatio-temporaltransfer capability. It suggests that for a completely new scenario,even when the displayed overall patterns are dissimilar to the dataencountered during the training process, UniST can extract fine-grained similar patterns from our defined spatial and temporalproperties. The few-shot and zero-shot results demonstrate thepowerful generalization capability of UniST.",
  "STUDY AND ANALYSIS ON UNIST5.1Ablation Study": "The prompts play an essential role in our UniST model. Here weinvestigate whether the designed spatial and temporal propertiescontribute to the overall performance. We use s to denote spatialcloseness and hierarchy, p for temporal periodicity, and c fortemporal closeness. we compare the overall design that incorporatesall three properties with three degraded versions that individually",
  "(c) Crowd dataset(d) Traffic speed dataset": ": (a) and (b): Comparison of the mean value of inputsin each memory embedding, where the inputs assign thehighest attention weight to the memory embedding. (c) and(d): Comparison of the attention weight on each memoryembedding for two distinct datasets. remove s, p, or c. (a) shows the results on four trafficspeed datasets. As we can observe, removing any property resultsin a performance decrease. The contributions of each spatial andtemporal property vary across different datasets, highlighting thenecessity of each property for the spatio-temporal design.Additionally, we explore how the number of embeddings in thememory pools affects the final performance. As seen in (b),increasing the number from 128 to 512 improves performance acrossthe four datasets. When further increasing the number to 1024, theperformance remains similar to 512, suggesting that 512 is theoptimal choice.",
  "Prompt Learner": "In this section, we conduct in-depth analyses of the prompt learner.To provide a clearer understanding, we leverage t-Distributed Sto-chastic Neighbor Embedding (t-SNE) to visualize the embeddings ofboth the spatial and temporal memory pools. Specifically, we plotthe initial state and the optimized state in . Notably, fromthe start state to the final optimized state, the embeddings graduallybecome diverged in different directions. This suggests that, through-out the optimization process, the memory pools progressively storeand encapsulate personalized information.Next, we delve into the memorized patterns of each embeddingwithin the temporal memory pool. Specifically, we first select theinputs based on the attention weights. For each embedding, weaggregate the corresponding input spatio-temporal data with the",
  ": (a) Training loss across five models with varyingparameter sizes. (b) Performance evaluation of masked patchreconstruction by increasing parameter sizes": "highest attention weight. Then, we calculate the mean value of theextracted spatio-temporal data. (a) and (b) illustratethe results for two datasets (Crowd and TrafficSH). As we cansee, the memorized patterns revealed in the prompt tool exhibitremarkable consistency across different urban scenarios. This notonly affirms that each embedding is meticulously optimized tomemorize unique spatio-temporal patterns, but also underscoresthe robustness of the spatial and temporal memory pools acrossdifferent scenarios.Moreover, we examine the extracted spatio-temporal promptsfor two distinct domains. Specifically, we calculate the mean at-tention weight for each embedding in the context of each dataset.(c) and (d) illustrate the comparison results. Aswe can observe, the depicted attention weight distributions for thetwo datasets manifest striking dissimilarities. The observed distinc-tiveness in attention weight distributions implies a dynamic andresponsive nature in the models ability to tailor its focus basedon the characteristics of the input data. The ability to dynamicallyadjust the attention weights reinforces UniSTs versatility and uni-versality for diverse datasets.",
  "Scalability": "Scalability is a crucial characteristic for universal models, therefore,we explore the scaling behavior of our UniST model. Our investiga-tion specifically concentrates on observing changes in training lossand prediction performance as we vary the model parameter size. depicts the training loss and testing RMSE of UniST withvarying parameter sizes. Regarding training loss (left figure), sev-eral key observations emerge: (i) across different parameter sizes,the training loss consistently decreases and gradually convergeswith increasing training steps; (ii) increasing the parameter sizeaccelerates the convergence of the training loss; (iii) there exist di-minishing marginal returns, suggesting that reducing the trainingloss becomes progressively harder as parameter size increases. Theright figure illustrates the reconstruction RMSE on the testing set,showing similar trends to the training loss.These observations indicate that UniST has shown scalabilitybehaviors,wherein larger models generally exhibit improved perfor-mance. However, unlike large language and vision models ,the scalability in spatio-temporal prediction shows diminishing",
  "CONCLUSION": "In this work, we address an important problem of building a univer-sal model UniST for urban spatio-temporal prediction. By leverag-ing the diversity of spatio-temporal data from multiple sources, anddiscerning and aligning underlying shared spatio-temporal patternsacross multiple scenarios, UniST demonstrates a powerful capa-bility to predict across all scenarios, particularly in few-shot andzero-shot settings. A promising direction for future work entailsthe integration of various spatio-temporal data formats, such asgrid, sequence, and graph data. Our study inspires future researchin spatio-temporal modeling towards the universal direction.",
  "This work was supported in part by the National Key Research andDevelopment Program of China under grant 2020YFA0711403 andthe National Natural Science Foundation of China under 62171260and 62272260": "Lei Bai, Lina Yao, Can Li, Xianzhi Wang, and Can Wang. 2020. Adaptive graphconvolutional recurrent network for traffic forecasting. Advances in neuralinformation processing systems 33 (2020), 1780417815. Yutong Bai, Xinyang Geng, Karttikeya Mangalam, Amir Bar, Alan Yuille, TrevorDarrell, Jitendra Malik, and Alexei A Efros. 2023. Sequential modeling enablesscalable learning for large vision models. arXiv preprint arXiv:2312.00785 (2023). Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shot learners. Advances in neuralinformation processing systems 33 (2020), 18771901. Defu Cao, Furong Jia, Sercan O Arik, Tomas Pfister, Yixiang Zheng, Wen Ye, andYan Liu. 2023. Tempo: Prompt-based generative pre-trained transformer for timeseries forecasting. arXiv preprint arXiv:2310.04948 (2023). Zheng Chang, Xinfeng Zhang, Shanshe Wang, Siwei Ma, Yan Ye, Xiang Xinguang,and Wen Gao. 2021. Mau: A motion-aware unit for video prediction and beyond.Advances in Neural Information Processing Systems 34 (2021), 2695026962. Changlu Chen, Yanbin Liu, Ling Chen, and Chengqi Zhang. 2022. Bidirectionalspatial-temporal adaptive transformer for Urban traffic flow forecasting. IEEETransactions on Neural Networks and Learning Systems (2022).",
  "KDD 24, August 2529, 2024, Barcelona, SpainYuan Yuan, Jingtao Ding, Jie Feng, Depeng Jin, and Yong Li": "Jiahui Gong, Jingtao Ding, Fanjin Meng, Guilong Chen, Hong Chen, Shen Zhao,Haisheng Lu, and Yong Li. 2024. A Population-to-individual Tuning Frameworkfor Adapting Pretrained LM to On-device User Intent Prediction. In Proceedingsof the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.Association for Computing Machinery, New York, NY, USA. Jiahui Gong, Yu Liu, Tong Li, Haoye Chai, Xing Wang, Junlan Feng, Chao Deng,Depeng Jin, and Yong Li. 2023. Empowering spatial knowledge graph for mobiletraffic prediction. In Proceedings of the 31st ACM International Conference onAdvances in Geographic Information Systems. 111. Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Dollr, and Ross Girshick.2022. Masked autoencoders are scalable vision learners. In Proceedings of theIEEE/CVF conference on computer vision and pattern recognition. 1600016009. Jiahao Ji, Jingyuan Wang, Chao Huang, Junjie Wu, Boren Xu, Zhenhe Wu, ZhangJunbo, and Yu Zheng. 2023. Spatio-Temporal Self-Supervised Learning for TrafficFlow Prediction. Proceedings of the AAAI Conference on Artificial Intelligence 37,4 (2023), 43564364.",
  "Menglin Jia, Luming Tang, Bor-Chun Chen, Claire Cardie, Serge Belongie,Bharath Hariharan, and Ser-Nam Lim. 2022. Visual prompt tuning. In Euro-pean Conference on Computer Vision. Springer, 709727": "Jiawei Jiang, Chengkai Han, Wayne Xin Zhao, and Jingyuan Wang. 2023.PDFormer: Propagation Delay-aware Dynamic Long-range Transformer for Traf-fic Flow Prediction. arXiv preprint arXiv:2301.07945 (2023). KyoHoon Jin, JeongA Wi, EunJu Lee, ShinJin Kang, SooKyun Kim, and YoungBinKim. 2021. TrafficBERT: Pre-trained model with large-scale data for long-rangetraffic flow forecasting. Expert Systems with Applications 186 (2021), 115738. Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi,Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, et al. 2023. Time-llm:Time series forecasting by reprogramming large language models. arXiv preprintarXiv:2310.01728 (2023). Ming Jin, Qingsong Wen, Yuxuan Liang, Chaoli Zhang, Siqiao Xue, Xue Wang,James Zhang, Yi Wang, Haifeng Chen, Xiaoli Li, et al. 2023. Large models fortime series and spatio-temporal data: A survey and outlook. arXiv preprintarXiv:2310.10196 (2023). Yilun Jin, Kai Chen, and Qiang Yang. 2022. Selective cross-city transfer learningfor traffic prediction via source city region re-weighting. In Proceedings of the 28thACM SIGKDD Conference on Knowledge Discovery and Data Mining. 731741. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess,Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. 2020.Scaling laws for neural language models. arXiv preprint arXiv:2001.08361 (2020). Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and YusukeIwasawa. 2022. Large language models are zero-shot reasoners. Advances inneural information processing systems 35 (2022), 2219922213.",
  "Lingbo Liu, Ruimao Zhang, Jiefeng Peng, Guanbin Li, Bowen Du, and Liang Lin.2018. Attentive crowd flow machines. In Proceedings of the 26th ACM internationalconference on Multimedia. 15531561": "Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, andGraham Neubig. 2023. Pre-train, prompt, and predict: A systematic survey ofprompting methods in natural language processing. Comput. Surveys 55, 9 (2023),135. Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, andMingsheng Long. 2023. itransformer: Inverted transformers are effective for timeseries forecasting. arXiv preprint arXiv:2310.06625 (2023).",
  "Yong Liu, Chenyu Li, Jianmin Wang, and Mingsheng Long. 2023. Koopa: LearningNon-stationary Time Series Dynamics with Koopman Predictors. arXiv preprintarXiv:2305.18803 (2023)": "Zhanyu Liu, Guanjie Zheng, and Yanwei Yu. 2023. Cross-city Few-Shot TrafficForecasting via Traffic Pattern Bank. In Proceedings of the 32nd ACM InternationalConference on Information and Knowledge Management. 14511460. Bin Lu, Xiaoying Gan, Weinan Zhang, Huaxiu Yao, Luoyi Fu, and Xinbing Wang.2022. Spatio-Temporal Graph Few-Shot Learning with Cross-City KnowledgeTransfer. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Dis-covery and Data Mining. 11621172.",
  "Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2022.A time series is worth 64 words: Long-term forecasting with transformers. arXivpreprint arXiv:2211.14730 (2022)": "Xiaocao Ouyang, Yan Yang, Wei Zhou, Yiling Zhang, Hao Wang, and Wei Huang.2023. CityTrans: Domain-Adversarial Training with Knowledge Transfer forSpatio-Temporal Prediction across Cities. IEEE Transactions on Knowledge andData Engineering (2023). Zheyi Pan, Yuxuan Liang, Weifeng Wang, Yong Yu, Yu Zheng, and Junbo Zhang.2019. Urban traffic prediction from spatio-temporal data using deep meta learning.In Proceedings of the 25th ACM SIGKDD international conference on knowledgediscovery & data mining. 17201730. Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen, Yunzhi Yao, Shumin Deng,Chuanqi Tan, Fei Huang, and Huajun Chen. 2022. Reasoning with languagemodel prompting: A survey. arXiv preprint arXiv:2212.09597 (2022). Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjrnOmmer. 2022. High-resolution image synthesis with latent diffusion models. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition.1068410695. Zezhi Shao, Zhao Zhang, Fei Wang, Wei Wei, and Yongjun Xu. 2022. Spatial-temporal identity: A simple yet effective baseline for multivariate time seriesforecasting. In Proceedings of the 31st ACM International Conference on Information& Knowledge Management. 44544458. Zezhi Shao, Zhao Zhang, Fei Wang, and Yongjun Xu. 2022. Pre-training EnhancedSpatial-temporal Graph Neural Network for Multivariate Time Series Forecasting.In KDD 22: The 28th ACM SIGKDD Conference on Knowledge Discovery and DataMining, Washington, DC, USA, August 14 - 18, 2022. ACM, 15671577. Sheng Shen, Shijia Yang, Tianjun Zhang, Bohan Zhai, Joseph E Gonzalez, KurtKeutzer, and Trevor Darrell. 2024. Multitask vision-language prompt tuning. InProceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision.56565667.",
  "Sainbayar Sukhbaatar, Jason Weston, Rob Fergus, et al. 2015. End-to-end memorynetworks. Advances in neural information processing systems 28 (2015)": "Cheng Tan, Zhangyang Gao, Lirong Wu, Yongjie Xu, Jun Xia, Siyuan Li, andStan Z Li. 2023. Temporal attention unit: Towards efficient spatiotemporalpredictive learning. In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition. 1877018782. Yihong Tang, Ao Qu, Andy HF Chow, William HK Lam, SC Wong, and Wei Ma.2022. Domain adversarial spatial-temporal network: a transferable frameworkfor short-term traffic forecasting across cities. In Proceedings of the 31st ACMInternational Conference on Information & Knowledge Management. 19051915. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-mine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-ale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXivpreprint arXiv:2307.09288 (2023).",
  "Xuhong Wang, Ding Wang, Liang Chen, and Yilun Lin. 2023.Build-ing Transportation Foundation Model via Generative Graph Transformer.arXiv:2305.14826 [cs.LG]": "Yunbo Wang, Zhifeng Gao, Mingsheng Long, Jianmin Wang, and S Yu Philip. 2018.Predrnn++: Towards a resolution of the deep-in-time dilemma in spatiotemporalpredictive learning. In International Conference on Machine Learning. PMLR,51235132. Yunbo Wang, Mingsheng Long, Jianmin Wang, Zhifeng Gao, and Philip S Yu. 2017.Predrnn: Recurrent neural networks for predictive learning using spatiotemporallstms. Advances in neural information processing systems 30 (2017). Yunbo Wang, Jianjin Zhang, Hongyu Zhu, Mingsheng Long, Jianmin Wang, andPhilip S Yu. 2019. Memory in memory: A predictive neural network for learninghigher-order non-stationarity from spatiotemporal dynamics. In Proceedings ofthe IEEE/CVF conference on computer vision and pattern recognition. 91549162. Zhenyu Wang, Yali Li, Xi Chen, Ser-Nam Lim, Antonio Torralba, HengshuangZhao, and Shengjin Wang. 2023. Detecting everything in the open world: Towardsuniversal object detection. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition. 1143311443. Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren,Guolong Su, Vincent Perot, Jennifer Dy, and Tomas Pfister. 2022. Learning toprompt for continual learning. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition. 139149.",
  "analysis. arXiv preprint arXiv:2210.02186 (2022)": "Fengli Xu, Jun Zhang, Chen Gao, Jie Feng, and Yong Li. 2023. Urban Genera-tive Intelligence (UGI): A Foundational Platform for Agents in Embodied CityEnvironment. arXiv preprint arXiv:2312.11813 (2023). Yibo Yan, Haomin Wen, Siru Zhong, Wei Chen, Haodong Chen, Qingsong Wen,Roger Zimmermann, and Yuxuan Liang. 2023. When Urban Region ProfilingMeets Large Language Models. arXiv preprint arXiv:2310.18340 (2023). Huaxiu Yao, Yiding Liu, Ying Wei, Xianfeng Tang, and Zhenhui Li. 2019. Learningfrom multiple cities: A meta-learning approach for spatial-temporal prediction.In The world wide web conference. 21812191. Cunjun Yu, Xiao Ma, Jiawei Ren, Haiyu Zhao, and Shuai Yi. 2020. Spatio-temporalgraph transformer networks for pedestrian trajectory prediction. In ComputerVisionECCV 2020: 16th European Conference, Glasgow, UK, August 2328, 2020,Proceedings, Part XII 16. Springer, 507523.",
  "Junbo Zhang, Yu Zheng, and Dekang Qi. 2017. Deep spatio-temporal residual net-works for citywide crowd flows prediction. In Proceedings of the AAAI conferenceon artificial intelligence, Vol. 31": "Xu Zhang, Yongshun Gong, Xinxin Zhang, Xiaoming Wu, Chengqi Zhang, andXiangjun Dong. 2023. Mask-and Contrast-Enhanced Spatio-Temporal Learn-ing for Urban Flow Prediction. In Proceedings of the 32nd ACM InternationalConference on Information and Knowledge Management. 32983307. Zijian Zhang, Ze Huang, Zhiwei Hu, Xiangyu Zhao, Wanyu Wang, Zitao Liu,Junbo Zhang, S Joe Qin, and Hongwei Zhao. 2023. MLPST: MLP is All You Needfor Spatio-Temporal Prediction. In Proceedings of the 32nd ACM InternationalConference on Information and Knowledge Management. 33813390. Zijian Zhang, Xiangyu Zhao, Qidong Liu, Chunxu Zhang, Qian Ma, Wanyu Wang,Hongwei Zhao, Yiqi Wang, and Zitao Liu. 2023. PromptST: Prompt-EnhancedSpatio-Temporal Multi-Attribute Prediction. In Proceedings of the 32nd ACMInternational Conference on Information and Knowledge Management. 31953205. Liang Zhao, Min Gao, and Zongwei Wang. 2022. St-gsp: Spatial-temporal globalsemantic representation learning for urban flow prediction. In Proceedings of theFifteenth ACM International Conference on Web Search and Data Mining. 14431451. Ling Zhao, Yujiao Song, Chao Zhang, Yu Liu, Pu Wang, Tao Lin, Min Deng, andHaifeng Li. 2019. T-gcn: A temporal graph convolutional network for trafficprediction. IEEE transactions on intelligent transportation systems 21, 9 (2019),38483858.",
  "Tian Zhou, Peisong Niu, Xue Wang, Liang Sun, and Rong Jin. 2023. One FitsAll: Power General Time Series Analysis by Pretrained LM. arXiv preprintarXiv:2302.11939 (2023)": "Zhilun Zhou, Jingtao Ding, Yu Liu, Depeng Jin, and Yong Li. 2023. TowardsGenerative Modeling of Urban Flow through Knowledge-enhanced DenoisingDiffusion. In Proceedings of the 31st ACM International Conference on Advances inGeographic Information Systems. 112. Zhengyang Zhou, Kuo Yang, Yuxuan Liang, Binwu Wang, Hongyang Chen,and Yang Wang. 2023. Predicting collective human mobility via counteringspatiotemporal heterogeneity. IEEE Transactions on Mobile Computing (2023).",
  "APPENDIXADATASETSA.1Basic Information": "Here we provide more details of the used datasets in our study.We collect various spatio-temporal data from multiple cities anddomains. summarizes the basic information of the useddatasets, and reports the basic statistics. Specifically, valuesfor Crowd and Cellular datasets in , , , and should be scaled by a factor of 103.",
  "STResNet : It is a spatio-temporal model for crowd flowprediction, which utilizes residual neural networks to model thetemporal closeness, period, and trend properties": "ACFM : Attentive Crowd Flow Machine model is proposed topredict the dynamics of the crowd flows. It learns the dynamicsby leveraging an attention mechanism to adaptively aggregatethe sequential patterns and the periodic patterns. STGSP : This model propose that the global information andpositional information in the temporal dimension are importantfor spatio-temporal prediction. To this end, it leverages a semanticflow encoder to model the temporal relative positional signals.Besides, it utilizes an attention mechanism to capture the multi-scale temporal dependencies. MC-STL : It leverages an state-of-the-art training techniquesfor spatio-temporal predition, the mask-enhanced contrastivelearning, which can effectively capture the relationships on thespatio-temporal dimension. MAU : Motion-aware unit is a video prediction model. it broad-ens the temporal receptive fields of prediction units, which canfacilitates to capture inter-frame motion correlations. It consistsof an attention module and a fusion module. PredRNN : PredRNN is a recurrent network-based model. Inthis model, the memory cells are explicitly decoupled, and theycalculate in independent transition manners. Besides, differentfrom the memory cell of LSTM, this network leverages zigzapmemory flow, which facilitates to learn at distinct levels. MIM : Memory utilize the differential information betweenadjacent recurrent states, which facilitates to model the non-stationary properties. Stacked multiple MIM blocks make it pos-sible to model high-order non-stationarity. SimVP : It is a simple yet very effective video predictionmodel. It is completely built based on convolutional neural net-works and uses MSE loss. It serves as a solid baseline in videoprediction tasks. TAU : Temporal Attention Unit is the state-of-the-art videoprediction model. It decomposes the temporal attention into twoparts: intra-frame attention and inter-frame attention, whichare static and dynamical, respectively. Besides, it introduces anovel regularization, i.e., differential divergence regularization,to consider the impact of inter-frame variations.",
  "spatio-temporal dimensions. It demonstrates that it is promis-ing to design efficient and effective models in spatio-temporalpredictions": "STNorm : It proposed two types of normalization modules:spatial normalization and temporal normalization. These twonormalization methods can separately consider high-frequencycomponents and local components. PatchTST : It first employed patching and self-supervisedlearning in multivariate time series forecasting. It has two essen-tial designs: (i) segmenting the original time series into patchesto capture long-term correlations, (ii) different channels are op-erated independently, which share the same network.",
  "DIMPLEMENTATION DETAILSD.1Evaluation Metrics": "We use commonly used regression metrics, Mean Absolute Error(MAE) and Root Mean Squared Error (RMSE), to measure the pre-diction performance. Suppose = 1, ..., are ground truth forreal spatio-temporal data, = 1, ..., are the predicted values bythe model, and is the number of total testing samples, These twometrics can be formulated as follows:",
  ": end for": "The pre-training learning rate is selected via grid searching in aset of {1 3, 3 4, 1 4}, and the fine-tuning learning rate isselected in a set of {1 4, 5 5, 1 5}. Both in pre-training andfine-tuning, we evaluate the models performance on the valida-tion set every ten epochs (all training instances). We choose themodel that performs best on the validation set for evaluations onthe testing set.",
  "D.3Prompt-Tuning": "The prompt-tuning stage aims to train a effective prompt network,which generates customized prompt for specific spatio-temporalpattern. We propose to leverage four types of spatio-temporalknowledge: (i) spatial closess (), (ii) spatial hierarchy (), (iii) tem-poral closeness (), and (iv) temporal period (). These knowledge-guided features are extracted from the input sequence. The input isthe historical spatio-temporal sequence, the output is the predictedfuture spatio-temporal sequence, and the objective is to minimizethe distance between the predicted results and real data. Specifically,we use the widely adopted mean squared error loss function with 2regularization on the parameters in UniST to prevent over-fitting,which can be formulated as follows",
  "D.4Baseline Implementation": "We compare UniST with a broad collection of state-of-the-art mod-els for spatio-temporal prediction, which can be categorized intofive groups as introduced in .1. If we consider the scala-bility to diverse data formats, i.e., different spatio-temporal datashapes, these baselines can be categorized into two groups: (i) ap-proaches that are scalable with different spatio-temporal scales,such as PatchTST, MAML, and MetaST, and (ii) approaches that arenon-scalable, including deep urban prediction approaches, videoprediction approaches, and iTransformer. Most baselines are notscalable to different data shapes because they require a fixed num-ber of spatial grids or variables, as seen in CNN-based approaches,MLP-based approaches, and multivariate time series models. Dueto the varied data shapes, non-scalable baselines cannot be trainedusing all datasets, so we train separate models for each dataset.For the scalable baseline, PatchTST , it utilizes a channel-independent patch time series Transformer architecture, allowingit to be applied to datasets with varied spatio-temporal shapes. Toensure a fair comparison, we train both separate models and asingle \"one-for-all\" model, as shown in .Notably, there are two baselines employ pretraining and fine-tuning: PatchTST and PromptST . However, PromptSTrequires a fixed number of nodes, limiting its flexibility acrossdifferent data formats. In contrast, the channel-independence ofPatchTST allows it to handle varied data shapes. While PromptSTis a state-of-the-art pre-training and prompt-tuning approach, itlacks generalization ability across different datasets.",
  "D.5Experimental Design": "In our experimental design, we incorporate four distinct predic-tion tasks: short-term prediction, long-term prediction, few-shotprediction, and zero-shot prediction. This design aligns with es-tablished practices in foundation models for time series forecast-ing . The short-term and long-term prediction tasksare conducted without transfer learning settings. In these tasks,the model is trained on a set of datasets and then evaluated onthe corresponding testing sets from these datasets. This setup en-ables us to directly assess the models performance across multipledatasets using a single universal model. Furthermore, the few-shot and zero-shot prediction tasks aredesigned to evaluate the models generalization capabilities. Inthese tasks, the model learns from a set of source datasets to builda pretrained model and a memory pool, which is then utilizedfor prediction on target datasets. The key difference between thefew-shot and zero-shot settings lies in the fine-tuning process onthe target dataset. In few-shot prediction, the model undergoes alimited fine-tuning process using a small percentage of the targetdatasets training data, while in zero-shot prediction, the modeldirectly applies the pre-trained model and memory pool to makepredictions on the target dataset without any fine-tuning.These four tasks collectively offer a comprehensive evaluation ofthe models performance and its ability to generalize across diversespatio-temporal datasets.",
  "(3) Datasets from Different Cities and Domains: This scenariohighlights the models ability to leverage knowledge learnedpreviously and generate useful prompts adaptively": "As shown in to , our analysis reveals com-pelling insights into the effectiveness of our prompting mechanismin handling distribution shifts. Specifically, we observed that similarprompts are consistently generated for datasets exhibiting similarspatio-temporal patterns. For instance, the prompts generated forthe training and testing sets of a single dataset, as well as for the test-ing sets of two datasets from different domains within the same city,are similar. This consistency in prompt generation suggests thatour model effectively captures and leverages the underlying spatio-temporal patterns shared between these datasets. Meanwhile, ourmodel generates distinct prompts for scenarios involving datasetsfrom different cities and domains, indicating its ability to adapt to",
  "E.2Performance under Noise Perturbations": "The models ability to handle noisy data is necessary to ensurereliable predictions. Therefore, we conduct experiments to evaluateUniSTs robustness against noisy data. Specifically, we introducedGaussian noise with varying levels of intensity to the input data andassessed UniSTs performance under these conditions. We consid-ered three levels of noise: Gaussian noise randomly sampled from a0.1% normal distribution, Gaussian noise randomly sampled from a1% normal distribution, and Gaussian noise randomly sampled froma 10% normal distribution. These noise levels represent varying",
  "Best baseline27.363.8516.483.930.742": "degrees of data corruption, simulating real-world scenarios wheredata can be noisy or contain irregularities.The results, as detailed in , demonstrate that UniST con-sistently outperforms baseline models even in the presence of noiseperturbations (where the best baseline has no noise perturbation).This suggests that UniST is capable of effectively handling noisydata, which is crucial for ensuring reliable predictions, especiallyin real-world scenarios where data can be messy or contain irregu-larities.Moreover, we examine how different positional encoding meth-ods affect the models robustness. We compare the use of two posi-tional encoding methods: learnable embeddings and sine-cosine en-coding. The results in show the performance with learnableembeddings, while shows the performance with sine-cosineencoding. Comparing these two sets of results, we observe thatsine-cosine encoding exhibits more robust performance againstnoise perturbations. Specifically, learnable embeddings show a sig-nificant performance reduction with increased noise perturbationand perform worse than the best baseline model.",
  "E.3Model Efficiency": "shows a detailed comparison of the computational andmemory costs of UniST against baselines. The results show that themodel size and memory cost of UniST are comparable to those ofother approaches. However, due to the multiple data pre-traininginvolved, the training time of UniST is longer compared to othermethods. Despite this, UniST consistently outperforms baselines onall datasets with just one model. Thus, we consider the additionaltraining time acceptable given the superior performance achieved.",
  "E.4Dataset Similarity": "To assess the similarities among the datasets used in our study, weemployed a two-step process. First, we reduced the dimension of thespatio-temporal data using t-SNE, a technique for dimension reduc-tion. This allowed us to visualize the datasets in a lower-dimensionalspace. Second, we applied the k-means clustering method to thereduced data to identify clusters of similar spatio-temporal patterns.The results of our visualization revealed interesting insights. Wefound that certain datasets, such as the Crowd data and Cellular datain Nanjing, exhibited similar spatio-temporal patterns. Similarly,the Bike data and Taxi data in New York City showed similaritiesin their patterns. However, most datasets from different cities ordomains exhibited distinct spatio-temporal patterns, indicatingsignificant distribution shifts. These observations highlight thepowerful generalization ability and universality of our approachacross datasets with significantly distinct spatio-temporal patterns.",
  "E.5Additional Ablation Studies": "E.5.1Masking Strategies. We investigated the contribution of eachof the four masking strategies by comparing the performance whenall four strategies are employed with the performance when oneof the strategies is removed. We conducted experiments on threespatio-temporal tasks: prediction, imputation, and spatial extrapo-lation, using the TrafficCD dataset.The results, shown in , indicate that training with allfour masking strategies achieved the best performance across all",
  ": Ablation studies on four types spatial and temporalknowledge extraction ,,, and": "three tasks. Removing the temporal masking strategy results in themost significant performance decrease for the prediction task, re-moving the random masking strategy leads to the most significantperformance decrease for the imputation task, and removing theblock masking strategy results in the most significant performancedecrease for the spatial extrapolation task. These results are reason-able as each masking strategy is designed to align with a specifictask objective.It is worth noting that despite the seemingly mismatched natureof some masking strategies with certain spatio-temporal tasks (e.g.,random masking vs. prediction, temporal masking vs. imputation,and temporal masking vs. spatial extrapolation), we find that thesemasking strategies still contribute to the performance of less relatedtasks. This indicates that the masking strategies not only benefittheir intended tasks but also have broader effects on the modelsgeneral learning of spatio-temporal dependencies and dynamics. For example, while random masking may seem unrelated to causalprediction tasks, it can help the model learn robust features thatgeneralize well across different time points. Additionally, tempo-ral masking can help the model better understand the temporaldynamics when performing spatial extrapolation. E.5.2Knowledge-Guide Prompts. The prompts play an essentialrole in our UniST model. Here we investigate whether the designedspatial and temporal properties ,,, and contribute to thefinal performance. We use to denote spatial closeness, to denotespatial hierarchy, for temporal periodicity, and for temporalcloseness.we compare the overall design that incorporates all three proper-ties with four degraded versions that individually remove ,,,or . shows the results on four traffic speed datasets. Aswe can observe, removing any property results in a performancedecrease. The contributions of each spatial and temporal propertyvary across different datasets, highlighting the necessity of eachproperty for the spatio-temporal design."
}