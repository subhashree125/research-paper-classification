{
  "ABSTRACT": "With the emergence of social networks, social recommendation hasbecome an essential technique for personalized services. Recently,graph-based social recommendations have shown promising resultsby capturing the high-order social influence. Most empirical studiesof graph-based social recommendations directly take the observedsocial networks into formulation, and produce user preferencesbased on social homogeneity. Despite the effectiveness, we arguethat social networks in the real-world are inevitably noisy (existingredundant social relations), which may obstruct precise user pref-erence characterization. Nevertheless, identifying and removingredundant social relations is challenging due to a lack of labels. Inthis paper, we focus on learning the denoised social structure tofacilitate recommendation tasks from an information bottleneckperspective. Specifically, we propose a novel Graph BottleneckedSocial Recommendation (GBSR) framework to tackle the social noiseissue. GBSR is a model-agnostic social denoising framework, thataims to maximize the mutual information between the denoisedsocial graph and recommendation labels, meanwhile minimizing itbetween the denoised social graph and the original one. This enablesGBSR to learn the minimal yet sufficient social structure, effectivelyreducing redundant social relations and enhancing social recom-mendations. Technically, GBSR consists of two elaborate compo-nents, preference-guided social graph refinement, and HSIC-basedbottleneck learning. Extensive experimental results demonstratethe superiority of the proposed GBSR , including high performancesand good generality combined with various backbones. Our codeis available at:",
  "Le Wu is the Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "INTRODUCTION": "Learning informative user and item representations is the key tobuilding modern recommender systems. Classic collaborative filter-ing paradigm factorizes user-item interaction matrix to learn userand item representations, which is widely researched but usuallylimited by sparse interactions. With the proliferation of social me-dia, social recommendation has become an important techniqueto provide personalized suggestions . Both user-item interac-tions and user-user social relations are availableon social platforms, prompting the development of various socialrecommendation methods designed to exploit these behavior pat-terns .Following the social homophily and social influence the-ory , many efforts are devoted to characterizing social relationeffects on user preferences. Early works mainly focus on exploitingfirst-order social relations, i.e., social regularization that assumessocially connected users share similar preference , and socialenhancement that incorporates user-trusted friends feedback asauxiliary for the target user . Recently, witnessed the power ofgraph neural networks (GNNs) on machine learning ,graph-based recommendations have attracted more and more atten-tion . Graph-based social recommendations achieve impressive progress in improving recommendation perfor-mances by formulating users high-order interest propagation andsocial influence diffusion with GNNs.Despite the effectiveness, current graph-based social recommen-dations rarely notice the social noise problem, i.e., social graphsare inevitably noisy with redundant social relations. Those redun-dant relations are caused by unreliable social relations and lowpreference-affinity social relations . Consequently, directlyusing the observed social graph may hinder precise user preferencecharacterization, leading to sub-optimal recommendation results.We conduct an empirical study to illustrate the social noise problem.As shown in , we compare LightGCN with current SOTA",
  ": Performance comparisons between LightGCN andSOTA graph-based social recommendation methods": "graph-based recommendation methods, including SocialLGCN and DiffNet++ . To avoid the effect of the message-passingmechanism of different methods, we additionally implement theextension of LightGCN, called LightGCN-S which additionally per-forms social neighbor aggregation for user representation learning.We can find that compared with LightGCN, graph-based social rec-ommendations do not present significant strength on both metrics,even worse on the Douban-Book dataset. This indicates that socialnetworks are usually noisy, its necessary to filter redundant socialrelations to enhance the robustness of social recommendations.However, identifying and removing redundant social relations isnon-trivial due to a lack of ground-truth labels. Besides, how canguarantee the recommendation accuracy while removing socialrelations?In this paper, we focus on learning the denoised social graphstructure to facilitate recommendation tasks from an informationbottleneck perspective. Specifically, we propose a novel Graph Bot-tlenecked Social Recommendation (GBSR) framework to tackle thesocial noise problem. Let G = {, S} denote the user-user socialgraph and R denote the user-item interaction matrix, where isuserset and S is social structure matrix. The optimal denoised socialgraph structure S should satisfy: the minimal from S yet efficientfor infer R. To achieve this goal, we first introduce user preferencesignals to guide the social graph denoising process, then optimizethe learning process via the Information Bottleneck (IB) principle.Specifically, GBSR maximize the mutual information between thedenoised social graph structure S and interaction matrix R, mean-while minimizing it between the denoised social graph structure S and the original S. Therefore, the learning objective is formulatedas: : (R; S) (S; S).Nevertheless, optimizing the objective of GBSR for social recom-mendation is still challenging due to the following two challenges.For the maximization of (R; S), social graph and sparse interac-tion matrix are two non-Euclidean data, which are hard to com-pare directly. For the minimization of (S; S), estimating the upperbound of MI is an intractable problem. Although some works leverage variational techniques to estimate the upper bound, theyheavily rely on the prior assumption. To address the above two chal-lenges, GBSR is implemented as follows. First, regarding the hard-comparable issue of (R; S), we take all nodes into intermediaryand derive the lower bound of (R; S) for maximization. Second, weintroduce the Hilbert-Schmidt independence criterion (HSIC) to replace the minimization of (S; S). HSIC is a statistic mea-sure of variable dependency, minimizing HSIC approximate theminimization of mutual information. Our contributions are sum-marized as follows: In this paper, we revisit the social denoising recommendationfrom an information theory perspective, and propose a novelGraph Bottlenecked Social Recommendation (GBSR) frame-work to tackle the noise issue.",
  "PRELIMINARIES2.1Problem Statement": "There are two kinds of entities in fundamental social recommenda-tion scenarios: a userset (| | = ) and an itemset (| | = ).Users have two kinds of behaviors, user-user social relations anduser-item interactions. We use matrix S R to describe user-user social structure, where each element = 1 if user followsuser , otherwise = 0. Similar, we use matrix R R todescribe user-item interactions, where each element r = 1 if user interacted with item , otherwise r = 0. Given user , item ,and social relation matrix S as input, graph-based social recom-menders aim to infer the probability user will interact with item: = G (,, S), where G denotes GNN formulation. Thus, theoptimization objective of graph-based social recommendation isdefined as follows:",
  "Information Bottleneck Principle": "Information Bottleneck (IB) is a representation learning principlein machine learning, which seeks a trade-off between data fit andreducing irrelevant information . Given input data , is the hidden representation, and is the downstream task label,which follows the Markov Chain < >. IB principle de-scribes that an optimal representation should maintain the minimal",
  "= arg max (;) (;),(4)": "where (;) denotes the mutual information between the hiddenrepresentation and label , (;) denotes the mutual informa-tion between the hidden representation and input data twovariables, is the coefficient to balance these two parts. IB prin-ciple has been widely applied in machine learning tasks, such asmodel robustness , fairness , and explainability . Inthis work, we introduce the IB principle to robust social denois-ing learning, which aims to seek the minimal yet sufficient socialstructure for recommendation tasks.",
  "THE PROPOSED GBSR FRAMEWORK": "In this section, we introduce our proposed Graph Bottlenecked So-cial Recommendation (GBSR) framework for social denoising basedrecommendation. Essentially, GBSR aims to learn the minimal yetefficient social structure to facilitate recommendation tasks, whichis guaranteed by the information bottleneck principle. Next, wefirst give the overall optimization objective of GBSR , then introducehow to implement each component of GBSR in detail. Finally, weinstantiate GBSR with LightGCN-S backbone.",
  "Overview of GBSR": "As shown in , we present the overall objective of our pro-posed GBSR framework for the social recommendation. Insteadof directly using the original social structure S, we aim to learn adenoised yet informative social structure S to enhance recommen-dation. Due to the lack of available prior for social denoising, weintroduce user preference signals to guide social graph denoising.To guarantee the trade-off between social denoising and recommen-dation tasks, we optimize GBSR via graph information bottleneckprinciple. Thus, the goal of GBSR is: : (R; S) (S; S). Dueto the intractability of (R; S), we take all nodes into an intermedi-ary for calculation. Thus, we obtain the final optimization objectiveof GBSR :",
  "Preference-guided Social Denoising": "To achieve the above objective of GBSR , we first need to refinethe denoised social graph. The challenge is that although the socialgraph has noisy relations, there are no available labels to guide thedenoising process. Based on social homogeneity social-connectedindividuals have more similar behavior similarity, we inject userpreference signals into the social denoising process, i.e., users withsimilar preferences are more likely to have social relations.Formally, we formulate the social denoising process as a graphedge dropout problem. Given the original social graph structure S,the denoised one is defined as:",
  "S = F (, S) = { },(6)": "in which () + denotes that each edge < , >will be dropped with the probability 1 + . Here, we add theparameter > 0 to represent the observation bias. Due to lackingprior information, we introduce task-relevant user preferences torefine social structure. Let E R denote user preferencerepresentations learned from the observed interactions, such asMatrix Factorization and LightGCN . For each observedsocial relation < , >, the link confidence is calculated as:",
  "(,,) D( (G(,, S) G(, , S))),": "(9)where G() is any graph-based social recommender as we men-tioned in the preliminaries, ()is the sigmoid activation, D ={(,, )| = 1 = 0} is all training data. Next, we intro-duce each derivation step as follows: (a) is the definition of mu-tual information; (b) is the non-negative property of (R); (c)",
  "KDD 24, August 2529, 2024, Barcelona, SpainYonghui Yang et al": "is that (|,, S) 1, and we split all samples into observedinteractions and non-observed interactions; (d) (G(,, S)) isthe variational approximation of ( = 1|,, S); (e) is due to(()) (()) (( )).According to the above derivation, we can find that the popularBPR ranking loss is the lower bound of mutual information (R;,, S). Therefore, we employ BPR loss as the objective ofmutual information maximization.",
  "Minimization of (S; S)": "Next, we introduce how to minimize (S, S), which aims to reducethe redundant social relations in the original graph. Estimatingthe upper bound of mutual information is an intractable problem.Although some works leverage variational techniques toestimate the upper bound, but heavily rely on the prior assump-tion. Therefore, we introduce Hilbert-Schmidt Independence Cri-terion (HSIC ) as the approximation of the minimization of (R; S).HSIC brief. HSIC serves as a statistical measure of dependency ,which is formulated as the Hilbert-Schmidt norm, assessing thecross-covariance operator between distributions within the Repro-ducing Kernel Hilbert Space (RKHS). Mathematically, given twovariables and , HSIC(,) is defined as follows:",
  "),(12)": "where is the parameter that controls the sharpness of RBF.HSIC-based bottleneck learning. Given the original and de-noised social graph structures S and S, we minimize (S; S)to replace the minimization of (S; S). However, social graphs arenon-Euclidean data, making it difficult to measure dependency.In practice, we adopt Monte Carlo sampling on all the noderepresentations for calculation:",
  "Instantiating the GBSR Framework": "In this section, we instantiate our proposed GBSR with specificgraph-based social recommender G (,, S). To avoid the effect ofdifferent message-passing mechanisms, we implement LightGCN-Sas the backbone model (we also realize GBSR with other backbones,refer to the generality analysis). Firstly, we formulate the availabledata and denoised social structure as a graph G = { , A}, where denotes the set of nodes, and A is the adjacent matrix definedas follows:",
  "E = (E0, E1, ..., E).(17)": "After obtaining the learned node representations through GCNs,LightGCN-S infers the propensity that user interacts with item by an inner product: =< , >. All the above process aresummarized as = G (,, S).Next, we give the illustration of graph-denoised social recommen-dation. We first use the initialized node embeddings to obtain userpreference representations P = E0[: ], then achieve the denoisedsocial structure S based on preference-guided social structure learn-ing (section 3.2). Given the learned denoised social structure S, weestablish graph-denoised social recommender = G, (,, S).Then, we select the pairwise ranking loss to optimize modelparameters:",
  "In this section, we analyze the proposed GBSR from model com-plexity and model generalization": "3.6.1Space Complexity. As illustrated in Algorithm 1, the parame-ters of GBSR are composed of two parts: graph-based social recom-mender parameters and social denoising parameters . Amongthem, = E0 are the general parameters equipped for backbonemodels (such as LightGCN-S). are the parameters of MLPs, whichare used to calculate the social edge confidence. Because are the",
  "Result: Optimal graph-denoised social recommenderG, ()": "1 Initialize recommender G, with random weights;2 while not converged do3Sample a batch training data D;4Compute social edge dropout probability viaEq.(7)-Eq.(8);5Refine the denoised social structure S via Eq.(6);6Obtain node representations E via G, (,, S);7Obtain node representations E via G (,, S);8Compute recommendation task loss L via Eq.(18);9Compute HSIC bottleneck loss L via Eq.(14);10Update model parameters according to Eq.(19);11 end12 Return the optimal G, ();",
  "shared parameters for all social edges, the additional parameters ofGBSR are ignorable compared with backbone models": "3.6.2Time Complexity. Compared with the backbone model (suchas LightGCN-S), the additional time cost is social graph denoisingand HSIC-bottleneck optimization. Social graph denoising is con-ducted on the observed social relations, which performs a sparsematrix. Besides, the time complexity of the HSIC-bottleneck regu-larizer lies in the number of the sampled nodes (refer to Eq.(13)). Inpractice, we adopt a mini-batch training strategy to reduce the timecost of bottleneck learning, and the additional time cost of GBSR isaffordable. Besides, as we remove redundant social relations, thedenoised yet informative social graph makes GBSR convergencemuch faster than the backbone model. Experiments also verify theefficiency of GBSR. 3.6.3Model Generalization. The proposed GBSR is designed for so-cial denoising under graph-based social recommendation scenarios.It does not depend on specific graph-based social recommenders,such as DiffNet++ and SocialLGN . Our proposed GBSR isa flexible denoising framework to enhance social recommendations,we also conduct experiments on four backbones to demonstrate thegeneralization. Besides the backbone model, the idea of introducingthe information bottleneck principle to graph denoising can alsobe generalized for different recommendation scenarios.",
  "Experimental Settings": "4.1.1Datasets. We conduct empirical studies on three public datasetsto verify the effectiveness of our proposed GBSR , including Douban-Book, Yelp, and Epinions. All datasets contain user-user social linksand user-item interactions. For the Douban-Book and Yelp datasets,we follow the released version in . For the Epinions dataset,we follow the released version in . Then, we sample 80% inter-actions as training data, and the remaining 20% as test data. Thedetailed statistics of all datasets are summarized in . 4.1.2Baselines and Evaluation Metrics. To evaluate the effective-ness of our proposed GBSR , we select state-of-the-art baselines forcomparisons. Specifically, these baselines can be divided into twogroups: graph-based social recommendation methods and social graph denoising methods , which are list asfollows: LightGCN : is the SOTA graph-based collaborative fil-tering method, which simplifies GCNs by removing the re-dundant feature transformation and non-linear activationcomponents for ID-based recommendation. LightGCN-S: We extend LightGCN to graph-based socialrecommendation, that each users neighbors include their in-teracted items and linked social users. LightGCN-S is a basicand lightweight model, considering our proposed GBSR isa model-agnostic social graph denoising method, we selectLightGCN-S as the backbone model.",
  "Impro.14.11%21.02%10.14%17.06%8.93%10.65%8.28%10.00%10.90%10.95%9.08%11.27%": "As we focus on implicit recommendation scenarios, we employtwo widely used ranking metrics: Recall@N and NDCG@N .Specifically, Recall@N measures the percentage of the recalled pos-itive samples for the Top-N ranking lists. Furthermore, NDCG@Nassigns higher scores for those items in the top-ranked positions. Inthe evaluation stage, we adopt a full-ranking strategy that views allnon-interacted items as candidates to avoid biased evaluation . For each model, we repeat experiments in 5 times and reportthe average values. 4.1.3Parameter Settings. We implement our proposed GBSR andbackbone with Tensorflow 1. For all baselines, we follow the origi-nal settings and carefully fine-tune parameters for fair comparisons.For latent embedding based methods, we initialize their embeddingswith a Gaussian distribution with a mean value of 0 and a standardvariance of 0.01, and fix the embedding size to 64. For model opti-mization, we use Adam optimizer with a learning rate of 0.001 anda batch size of 2048. We follow the mainstream ranking-based meth-ods , and randomly select 1 non-interacted item as the negativesample for pairwise ranking optimization. We search the GCN layerin , the regularization parameter in [0.0001, 0.001, 0.01].For the observation bias, we set = 0.5 for all datasets. For infor-mation bottleneck constraint coefficient , we use grid-search withdifferent scales over three datasets, and report detailed analysis inexperiments.",
  "Recommendation Performances": "4.2.1Overall Comparisons with Baselines. As shown in ,we compare our proposed GBSR with state-of-the-art methods onthree benchmarks. For a fair comparison, all denoising methodsare conducted on the LightGCN-S backbone. Given the empiricalstudies, we have the following observations: Compared with LightGCN, graph-based social recommenda-tion methods present slight improvements under most of thedatasets, i.e., DiffNet++ obtains a 2.24% improvement on theNDCG@20 metric for Yelp dataset. However, this is not al-ways the case, all social graph recommendations show a per-formance degradation on the Douban-Book dataset. While supported by social graphs, it is noteworthy that graph-basedsocial recommendation methods do not consistently outper-form LightGCN in terms of performance. These demonstratethat directly using social graphs may decrease recommenda-tion performance, its necessary to remove redundant socialrelations to enhance recommendation. Compared with directly using original social graphs, so-cial denoising methods present better performances in mostcases. This indicates that social noise is ubiquitous in real-world recommendation scenarios. All social denoising meth-ods are implemented on LightGCN-S backbone, we findthat GDMSR is the strongest baseline, which benefits frompreference-guided social denoising and self-correcting cur-riculum learning. However, these social denoising methodsdont present large-margin improvements compared withthe backbone model. The reason is that simple rule or as-sumption based denoising methods lack of theoretical guar-antee, its hard to seek an effective trade-off between socialdenoising and recommendation accuracy. Our proposed GBSR consistently outperforms all baselinesunder all experimental settings. Specifically, GBSR improvesthe strongest baseline .. NDCG@20 by 17.06%, 10% and11.27% on Douban-Book, Yelp, and Epinions datasets, respec-tively. Compared with the backbone model, GBSR achievesimpressive superiority over three benchmarks. These in-dicate that our proposed GBSR can significantly improvegraph-based social recommendations, demonstrating the ef-fectiveness of graph bottleneck learning to reduce redun-dant social relations. Compared with other social denoisingmethods, our GBSR can better obtain the trade-off betweenremoving social relations and recommendation tasks. 4.2.2Ablation study. We conduct ablation studies on three datasetsto explore the effectiveness of each component of the proposedGBSR framework. As shown in , we compare GBSR withcorresponding variants on Top-20 recommendation performances.GBSR-w/o HSIC denotes that remove the HSIC-based bottleneckregularization of GBSR , we only keep preference-guided socialdenoising module. From , we can find that GBSR-w/o HSICperforms worse in all cases, even worse than the backbone model.",
  "GBSR0.16940.15230.12430.07240.07930.0464": "This indicates that simple social structure learning without HSIC-based bottleneck regularization is useless for recommendation tasks.Furthermore, under the constraint of the information bottleneckprinciple, the learned social structure is meaningful, which caneffectively improve social recommendations on three datasets. 4.2.3Generality study of GBSR . As we mentioned in the modeldiscussion, the proposed GBSR is a model-agnostic social denois-ing framework. To better illustrate the generality of GBSR , weconduct experiments of GBSR on several graph-based social rec-ommendation backbones. As shown in , we implementGBSR under four backbones, including GraphRec , DiffNet++,SocialLGN , and LightGCN-S, and report their performancesof Top-20 recommendation task. From , we observe thatGBSR consistently outperforms each backbone by a large margin.For example, on the Yelp dataset, GBSR achieves 9.06%, 12.66%,8.87%, and 11.21% improvements of NDCG@20 compared withGraphRec, DiffNet++, SocialLGN, and LightGCN-S, respectively.Similarly, GBSR also obtains 5.48%, 9.87%, 8.78%, and 10.39% im-provements on the Recall@20 metric. Extensive experimental re-sults show that our proposed GBSR has a good generalization ability,which can easily coupled with current graph-based social recom-mendation methods and further enhancement.",
  "In this section, we further analyze GBSR from the following aspects:training efficiency, visualization of the denoised social graphs, andhyper-parameter sensitivity analysis": "4.3.1Training efficiency of GBSR. To analyze the training effi-ciency of GBSR , we compare the convergence speed of GBSR andcorresponding backbone (LightGCN-S). As shown in , wecompare the convergence process of both models. As the spacelimit, we only present the convergence process on Douban-Bookand Yelp datasets. We set gcn layer to 3 and keep all experimentalsettings the same. According to these figures, we can observe that",
  ": Convergence curves of GBSR and LightGCN-S onDouban-Book and Yelp datasets": "GBSR converges much faster than the backbone model. Particularly,GBSR reaches the best performances at the 82, the 67 epoch onDouban-Book and Yelp datasets. In contrast, LightGCN-S obtainsthe best results on 509, and 261 epoch, respectively. Empiri-cal evidence shows that GBSR convergence 2-3 times faster thanLightGCN-S. 4.3.2Visualization and statistics of the denoised social graphs. Herewe first present the visualization of the denoised social graph. Asshown in (a), we present the sampled ego-network fromDouban-Book datasets. The red node denotes the center user of thisego-network, and the blue nodes denote social neighbors. The depthof the node color denotes the probability of edge dropping, wherethe darker the color, the lower the dropping probability. We canobserve that user social neighbors perform different confidences ofsocial relations. Besides, we analyze the statistics of the denoisedsocial graphs. As shown in (b), we plot the mean and vari-ance values of social relation confidence on three datasets. We canobserve that Douban-Book presents the lowest mean value of so-cial confidence, which means that it has the most social noise overthe three datasets. This also explains the results of thatgraph-based social recommendations show a performance decreasecompared with LightGCN on the Douban-Book dataset. These re-sults demonstrate that the proposed GBSR can effectively refine theobserved social graph via information bottleneck, which providesinformative social structures to enhance social recommendations. 4.3.3Parameter Sensitivity Analysis. In this part, we analyze theimpact of different hyper-parameters of GBSR . There are two keyparameters, bottleneck loss coefficient and RBF sharpness pa-rameter 2. As both parameters determine the scale of bottleneck",
  ": Visualization and statistics of the denoised socialgraphs": "loss, we combine them to analyze the influence of recommenda-tion results. As shown in , we conduct careful grid-searchof (, 2) on three datasets. We can observe that GBSR reachesthe best performance when = 40, 2 = 2.5 on Douban-Book, = 2.0, 2 = 0.25 on Yelp, and = 3.0, 2 = 0.25, respectively.",
  "RELATED WORKS5.1Graph-based Social Recommendation": "With the emergence of social media, social recommendation hasbeen an important technique and has attracted more and moreresearch attention . Following the social ho-mophily and social influence theory , social recommenda-tions are devoted to characterizing social relation effects on userpreferences. Early efforts exploit social relations in a shallow form,such as co-factorization methods and regularization-basedmethods . For example, SoRec jointly co-factorize theinteraction and social matrices and then project interaction and so-cial contexts into the same semantic space. designs a social reg-ularization term that assumes two socially connected users shouldbe closer in preference space. Recently, with the great success ofgraph neural networks , graph-based social recommenda-tions have been widely researched and achieved impressive pro-cess . By formulating user-user social relationsas a graph, graph-based social recommendations inject high-ordersocial influences into user preference learning, vibrant the repre-sentation ability. For example, DiffNet models the high-order socialinfluence diffusion process to enhance user representation , andDiffNet++ further improves it by combining both social influencediffusion and user-item interest propagation with a hierarchical at-tention mechanism . Inspired by the architecture of LightGCN, proposes SocialLGN to model user interaction and social be-haviors. Instead of learning social graphs on Euclidean space, someworks attempt to introduce hyperbolic learning for graph-basedsocial recommendations . Despite the effectiveness of mod-eling high-order social influence to improve recommendation, theseworks are built on the clean social relation assumption. However,social graphs are inevitably noisy with redundant relations, andthese graph-based social recommendation methods are usually farfrom satisfactory. Instead of directly using the original social graph,",
  "Recommendation Denoising": "Recommendation denoising works mainly focus on implicit feed-back, which aims to refine implicit feedback to build robust rec-ommender systems . Most efforts are devotedto removing noise feedback, which is easily vulnerable to usersunconscious behaviors and various biases. For example, pro-poses to drop noisy feedback based on the observation that noisyfeedback has higher training loss, devises a bi-level optimiza-tion method to implement recommendation denoising. Besides,graph augmentation methods are proposed to realize recommenda-tion denoising . Different from the above feedback-baseddenoising works, we focus on social denoising for recommen-dations. Social graphs are inevitably noisy with redundant rela-tions, including unreliable relations and low preference-affinityrelations . Early works employ statistics to identify unstablesocial relations , or model different user influences withattention mechanism . Besides, fine-grained social leverag-ing and adversarial learning based methods have been pro-posed . Recently, GDMSR proposes a distilled socialgraph based on progressive preference-guided social denoising.Nevertheless, the above methods still face the challenge of lack-ing ground-truth. Whether rule-based or assumption-based socialdenoising is hard to guarantee the trade-off between social denois-ing and social recommendation. Distinguished by these denoisingmethods, we address the social denoising recommendation from anovel information bottleneck perspective, which seeks the denoisedyet informative social structure to enhance recommendations.",
  "Information Bottleneck and Applications": "Information Bottleneck (IB) is an effective representation learningprinciple in machine learning tasks, that the optimal representationshould satisfy the minimal yet efficient manner . In the eraof deep learning, calculating high-dimensional variables mutualinformation (MI) is the key challenge for IB. The general solution isestimating the upper/lower bounds instead of directly calculatingmutual information . Specifically, VIB leverages the vari-ational technique to estimate the bounds of mutual information.Besides, MINE , InfoNCE are proposed to estimate the lowerbound of MI. In contrast, a few attempts propose to estimate theupper bound of MI . Besides optimizing the bounds of MI,HSIC-based methods are proposed to implement IB learning,which employs the Hilbert-Schmidt Independence Criterion (HSIC)to replace mutual information for optimization. HSIC measures theindependence of two variables, which can approximate the mutualinformation objective . IB principle has been successfully ap-plied to many applications, such as image classification , textunderstanding , and graph learning . In this work, we in-troduce the HSIC-based bottleneck to the graph-denoised socialrecommendation, aiming to filtering redundant social relations forrobust recommendation.",
  "CONCLUSION": "In this paper, we investigate graph-denoised social recommenda-tions and propose a novel Graph Bottlenecked Social Recommen-dation (GBSR) framework. Specifically, GBSR aims to learn the de-noised yet informative social structure for recommendation tasks.To achieve this goal, we first design preference-guided social de-noising, then optimize the denoising process via the informationbottleneck principle. Particularly, we derive the lower bound ofmutual information maximization and introduce HSIC regulariza-tion to replace mutual information minimization. Extensive experi-ments conducted on three benchmarks demonstrate the effective-ness of our proposed GBSR framework, i.e., over 10% improvementson Top-20 Recommendation. Moreover, GBSR is a model-agnosticframework, which can be flexibly coupled with various graph-basedsocial recommenders. In the future, we will explore more potentialof leveraging the IB principle to recommendation tasks, i.e., self-supervised recommendation, fairness-aware recommendation, andLLM-enhanced recommendation. This work was supported in part by grants from the National Key Re-search and Development Program of China( Grant No.2021ZD0111802),and the National Natural Science Foundation of China( Grant No.U23B2031, 721881011).",
  "Mohamed Ishmael Belghazi, Aristide Baratin, Sai Rajeshwar, Sherjil Ozair, YoshuaBengio, Aaron Courville, and Devon Hjelm. 2018. Mutual information neuralestimation. In ICML. PMLR, 531540": "Miaomiao Cai, Lei Chen, Yifan Wang, Haoyue Bai, Peijie Sun, Le Wu, Min Zhang,and Meng Wang. 2024. Popularity-Aware Alignment and Contrast for MitigatingPopularity Bias. arXiv preprint arXiv:2405.20718 (2024). Miaomiao Cai, Min Hou, Lei Chen, Le Wu, Haoyue Bai, Yong Li, and Meng Wang.2024. Mitigating Recommendation Biases via Group-Alignment and Global-Uniformity in Representation Learning. ACM Transactions on Intelligent Systemsand Technology (2024).",
  "Yunjun Gao, Yuntao Du, Yujia Hu, Lu Chen, Xinjun Zhu, Ziquan Fang, and BaihuaZheng. 2022. Self-guided learning to denoise for robust recommendation. InSIGIR. 14121422": "Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard Schlkopf. 2005.Measuring statistical dependence with Hilbert-Schmidt norms. In Internationalconference on algorithmic learning theory. Springer, 6377. Adam Gronowski, William Paul, Fady Alajaji, Bahman Gharesifard, and PhilippeBurlina. 2023. Classification utility, fairness, and compactness via tunable in-formation bottleneck and Rnyi measures. IEEE Transactions on InformationForensics and Security (2023)."
}