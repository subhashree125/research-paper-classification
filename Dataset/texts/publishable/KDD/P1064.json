{
  "ABSTRACT": "Spatiotemporal time series forecasting plays a key role in a widerange of real-world applications. While significant progress hasbeen made in this area, fully capturing and leveraging spatiotem-poral heterogeneity remains a fundamental challenge. Therefore,we propose a novel Heterogeneity-Informed Meta-ParameterLearning scheme. Specifically, our approach implicitly capturesspatiotemporal heterogeneity through learning spatial and tem-poral embeddings, which can be viewed as a clustering process.Then, a novel spatiotemporal meta-parameter learning paradigm isproposed to learn spatiotemporal-specific parameters from meta-parameter pools, which is informed by the captured heterogeneity.Based on these ideas, we develop a Heterogeneity-Informed Spa-tiotemporal Meta-Network (HimNet) for spatiotemporal time se-ries forecasting. Extensive experiments on five widely-used bench-marks demonstrate our method achieves state-of-the-art perfor-mance while exhibiting superior interpretability. Our code is avail-able at",
  "Equal contribution.Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08 : Spatiotemporal heterogeneity. (a): Locations of twoselected areas. 1 is in the downtown region, while 2 isa residential area. (b): Illustration of spatial heterogeneity,with differing vehicle speed distributions between 1 and2. (c): Demonstration of temporal heterogeneity, showingdistinct patterns between different time periods. ACM Reference Format:Zheng Dong, Renhe Jiang, Haotian Gao, Hangchen Liu, Jinliang Deng, Qing-song Wen, and Xuan Song. 2024. Heterogeneity-Informed Meta-ParameterLearning for Spatiotemporal Time Series Forecasting. In Proceedings of the30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining(KDD 24), August 2529, 2024, Barcelona, Spain. ACM, New York, NY, USA,11 pages.",
  "KDD 24, August 2529, 2024, Barcelona, SpainZheng Dong et al": ": t-SNE visualization of the temporal and spatial meta-parameters. (a): Visualization for each day in a week whereevery cluster contains 24 points representing each hours temporal meta-parameter. (b): The cosine similarity matrix of themeta-parameters across 24 hours in a day. (c): Visualization for each sensors spatial meta-parameter in METRLA dataset. (d):Sensor points in (c) plotted on map, with only one lane of points shown for dual carriageways. (e): Clusters 3 and 13 are locatedon opposite lanes of the same road. (e): The one-week time series of clusters 3, 10, and 13. : The evolving ST-mixed meta-parameters. (a): Dis-tribution of clusters 3 and 6 around a crossroad area. (b): Thetraffic speed time series of the two clusters at peak hour andoff-peak hour. (c): A closer view of 10 sensors at the crossroad.(d): The cosine similarity of their ST-mixed meta-parametersacross three time periods. will enlarge its parameter size. In summary, our HimNet achievesdecent efficiency compared with other GCRU-based models, andoutperforms the Transformer-based baselines.We further analyze a variant HimNet- that removes meta-parameter pools and directly optimizes the three enlarged param-eter spaces. HimNet- contains over 10.9 billion parameters, un-available on any GPUs we can get. This is consistent with ouranalysis that directly optimizing the enlarged parameter spacesleads to intractable memory costs, which validates the necessityof our meta-parameter pool design to maintain efficiency whileenabling flexible parameterization.",
  "RELATED WORK2.1Spatiotemporal Forecasting": "Spatiotemporal forecasting has seen extensive research as it plays akey role in many real-world applications . Early approaches relied on traditional time series analysismethods such as ARIMA and VAR , as well as machinelearning techniques including -NN and SVM , but theyoften fail to capture complex spatiotemporal dependencies inherentto the data. Recent years have witnessed remarkable progress indeep learning methods. Recurrent Neural Networks (RNNs) likeLSTMs and GRUs achieved performance gains by effec-tively modeling the temporal dynamics. Convolutional networkssuch as WaveNet also found success via their long receptivefields. However, these models do not fully represent spatial de-pendencies critical to networked urban systems. To address thislimitation, Graph Convolutional Networks (GCNs) have been exten-sively explored for spatiotemporal forecasting. Pioneering workssuch as STGCN and DCRNN achieved better performanceby integrating GCNs with temporal models . Buildingon this foundation, many innovative methods have been proposedin recent years . Moreover, Trans-former has also revolutionized the field, motivating time seriestransformers that expertly capture spatiotemporal correla-tions or handle long sequences . Whileshowing impressive performance, existing work still lacks furtherexploration of spatiotemporal heterogeneity. Our study aims to fillthis gap through a novel HimNet that captures and leverages theheterogeneity for improved spatiotemporal forecasting.",
  "Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time Series ForecastingKDD 24, August 2529, 2024, Barcelona, Spain": "structural characteristics, even without the help of graph topology.Moreover, opposite lanes of the same road contain points fromdifferent clusters. (e) shows clusters 3 and 13 as an example.For visual clarity, we manually select one lane per road to draw(d). This exact matching between learned clusters and realroad topology demonstrates our methods ability to explicitly dis-tinguish spatial heterogeneity. Furthermore, we analyze the timeseries of clusters 3, 10, and 13 specifically. Cluster 10 corresponds toa major downtown road prone to severe congestion. Clusters 3 and13 are located on the opposite lanes of a minor road. As expected,their traffic speed time series in (f) show that clusters 3and 13 are closely matched while significantly differing from 10,consistent with our observations on the map and the latent space in(c). This validates that the spatial meta-parameters encodemeaningful contexts reflecting spatial heterogeneity.ST-Mixed Meta-Parameters. provides a case study ofthe evolving ST-mixed meta-parameters. Clusters 3 and 6 fromthe crossroad area in (a) are analyzed. Their traffic speedtime series are shown in (b) with three periods highlighted:midnight off-peak, morning peak, and noon off-peak. Ten nearbysensors (5 per cluster) on the crossroad are visualized in (c).For their ST-mixed parameters, we draw cosine similarity heatmapsacross the three time periods in (d). As expected, within-cluster similarity is generally higher than cross-cluster similarity.In detail, during midnight off-peak hours, both clusters exhibit sim-ilar traffic speed patterns, reflected by high cross-cluster similarity.However, during the morning peak, cluster 3 shows a sharp dropin speed while cluster 6 maintains a higher level. Their time seriesdiverge, resulting in lower cross-cluster similarity. At noon, thespeed patterns in both clusters become closer, leading to an increasein cross-cluster similarity again. Moreover, in , we conductanother case study on clusters 0 and 8. (a) shows five sen-sors each selected from the two clusters. As shown in (b),their time series diverge substantially over time. Correspondingly,as illustrated in (c), the cross-cluster similarity betweenthe ST-mixed meta-parameters associated with each sensor de-creases accordingly over the three selected time periods. Thesecase studies intuitively explain how our ST-mixed meta-parametersevolve spatially and temporally. Thus, the proposed approach hasstrong adaptability to various spatiotemporal contexts, with meta-parameters accurately capturing changes between different timeperiods for each location. Furthermore, this also confirms the powerof our method to jointly model spatiotemporal heterogeneity.",
  "PROBLEM DEFINITION": "Given a spatiotemporal time series ( 1): over the past timesteps, our goal is to forecast the values over the future timesteps. That is, we aim to map [( 1), ...,] [+1, ...,+ ],where each R represents the observations at the-th time stepfor time series, typically from sensors deployed at locations.",
  "METHODOLOGY": "In this section, we present details of our proposed Heterogeneity-Informed Meta-parameter Learning scheme along with the HimNetmodel, where the key components are depicted in . To betterillustrate our proposed method, we consider a minibatch dimension in the following discussions. For ease of understanding, can beassumed to be 1 without loss of generality.",
  "Spatiotemporal Heterogeneity Modeling": "A key aspect of modeling spatiotemporal heterogeneity is identify-ing and distinguishing input contexts across both temporal and spa-tial dimensions . Rather than relying on auxiliary data ,we employ learnable embeddings , which assign a uniquerepresentation to each spatiotemporal context.For the temporal dimension, we construct a time-of-day embed-ding dictionary R and a day-of-week dictionary R , where and are the embedding di-mensions, denotes the number of timesteps per day, and represents the number of days in a week. Given a minibatch ofinput samples R with historical length , the laststeps timestamp of each sample in the minibatch is used as thetime index to extract the corresponding time-of-day embedding R and day-of-week embedding Rfrom the dictionaries. The two embeddings are concatenated toobtain the overall temporal embedding R :",
  "= ||,(1)": "where = + represents the temporal embedding dimen-sion and || denotes concatenation operation. Time-of-day identifiesperiodic patterns with fine-grained time intervals, capturing phe-nomena like peak and off-peak hours. Day-of-week identifies mean-ingful longer-term patterns, such as the distinction in time seriesbetween weekdays and weekends. Leveraging these dictionaries,the temporal embedding aims to learn representations that canimplicitly recognize and account for such temporal heterogeneityover multiple timescales.For the spatial dimension, we utilize a spatial embedding matrix R , where denotes the total number of time series orspatial locations in the dataset (e.g. number of sensors) and isthe dimension of the embedding vector assigned to each location.Unlike the temporal dimension where the embeddings are extractedfrom learned dictionaries, here each of the spatial locations is di-rectly associated with a unique learnable spatial embedding vectorinitialized randomly in the embedding matrix. The goal of introduc-ing is to account for the inherent functional differences betweenlocations that can influence time series patterns, such as factorsrelated to infrastructure and urban design. It aims to learn latentrepresentations that can help distinguish such diverse contexts,without the need for auxiliary geographical data. This facilitatesmodeling the spatial heterogeneity present in each location.Furthermore, learning these embedding vectors essentially per-forms a dynamic clustering process. During model training, therepresentations within the embedding matrices gradually differen-tiate based on the input time series. Embedding vectors belongingto spatiotemporal contexts that exhibit similar trends in their timeseries will move closer in the latent space, and vice versa. As a re-sult, this dynamic adjustment of the embeddings can be viewed as aclustering process, where representations organically form clusters.Each distinct cluster captures a typical context in the spatiotempo-ral time series. Analogous to the NLP models where the learnedembeddings of \"man\" and \"woman\" can naturally be very close,this clustering process could be successfully achieved without in-volving any additional constraints like the way did in . Thisclustering perspective is what empowers the model to distinguish",
  "Spatiotemporal Meta-Parameter Learning": "To fully leverage the heterogeneity encoded in the spatiotemporalembeddings, we propose Heterogeneity-Informed Meta-ParameterLearning. It provides a simple yet effective way to improve modeladaptability and generalizability.We begin by introducing the general meta-parameter learningparadigm. For the models original parameter space with size ,our approach first extends it along a specific dimension to createan enlarged parameter space . Specifically, we can build three en-larged spaces for the temporal and spatial dimensions: temporal pa-rameter space RT, spatial parameter space R , andspatiotemporal joint space RT . Here, T represents thetotal number of timesteps and is the number of spatial locationsin the dataset. This extension aims to assign a unique parameterset to each spatiotemporal context, rather than sharing . Directlyoptimizing these enlarged parameter spaces is prohibitively expen-sive, as they become very huge, especially when T and are large,which will lead to exploding computational and memory costs. Toaddress this challenge, we maintain a small meta-parameter poolfor each parameter space, which contains parameter candidates.The pool size is defined to be much smaller than T and , butsufficiently large to encapsulate the variety of different contexts.For an incoming query representing a specific spatiotemporal con-text, we dynamically generate its meta-parameter as a weightedcombination of the pool candidates.For a meta-parameter pool R, given a query Q R, thegeneral formulation of our meta-parameter learning paradigm is:",
  "= Q ,(2)": "where R is the generated meta-parameter. By maintainingmeta-parameter pools, our approach alleviates this computationalburden by optimizing within the compact pools rather than thefull enlarged parameter spaces. Thus, the complexity is reducedfrom (T ) to (), where T . This makes the learningcomputationally feasible for large spatiotemporal datasets.Specifically, we leverage the embeddings proposed earlier thatencode spatiotemporal heterogeneity as queries to adaptively gen-erate the meta-parameters for each spatiotemporal context. Thisresults in a Heterogeneity-Informed Meta-Parameter Learningapproach. Based on Equation 2, three types of meta-parameters aregenerated for the respective enlarged parameter spaces.Temporal Meta-Parameters. We maintain a small temporal meta-parameter pool R containing candidates. Using thetemporal embedding R as queries, the temporal meta-parameters R are generated by:",
  "= .(4)": "ST-Mixed Meta-Parameters. To directly create a joint spatiotem-poral embedding is prohibitive, as its size would also be too largeto optimize effectively. Instead, we utilize the rich information in-herently contained within the input data itself , where the timeseries patterns naturally reflect spatiotemporal heterogeneity. Fora minibatch of input samples R , we encode it into aspatiotemporal embedding R as:",
  "= .(6)": "While we generate the meta-parameters based on the proposedembeddings, the underlying meta-parameter learning techniqueitself is not limited specifically to these embeddings. We presenta purely data-driven approach using only the intrinsic spatiotem-poral heterogeneity in the time series itself. However, other aux-iliary spatiotemporal features could also be utilized if available inthe dataset, such as POIs, weather patterns, or urban structuralcharacteristics. These supplemental contextual attributes could beencoded into the query representation to provide further instruc-tion for meta-parameter learning. Therefore, the method is flexibleand can leverage diverse contextual features to learn improvedmeta-parameters tailored to various application domains.",
  "Heterogeneity-Informed SpatiotemporalMeta-Network": "Leveraging our proposed techniques, we implement an end-to-end model called Heterogeneity-Informed Spatiotemporal Meta-Network (HimNet) for accurate spatiotemporal forecasting.Taking inspiration from GCNs, researchers have developed graphconvolutional recurrent networks which leverage bothgraph convolutions and recurrent transformations. By integratinggraph convolutions within recurrent cells, these models can effec-tively capture temporal dynamics while also accounting for thespatial relations in the graph. Therefore, our proposed HimNet ar-chitecture uses variants of the widely adopted Graph ConvolutionalRecurrent Unit (GCRU) as the fundamental building block.GCRU is formulated by:",
  "=0,(8)": "where R is the input, R is the output, and denotes the input channels. represents the topology of graph G,and R is the kernel parameter .By applying temporal meta-parameter learning to GCRU, wepropose a temporal meta-encoder. Referring to Equation 3, thegenerated temporal meta-parameters in this encoder take the form R. Similarly, we build a spatial meta-encoder via spatial meta-parameter learning, with generated spatial meta-parameters R by applying Equation 4. For the graphG used in the encoders, rather than relying on a static pre-definedadjacency matrix as in prior works , we follow the adap-tive graph learning design . Specifically, we leverage ourlearned spatial embeddings to dynamically generate the adja-cency matrix R as: = Softmax(ReLU( )).(9) In short, given an input R , the two encoders operatein parallel to encode it into two hidden representations based ontheir respective meta-parameters. These representations are thensummed to yield the final combined hidden encoding R .To decode the latent representation into predictions, we pro-pose a spatiotemporal meta-decoder that leverages ST-mixedmeta-parameters. Specifically, we first generate the correspondingspatiotemporal embedding R from :",
  "= + ,(10)": "where R and R are the linear projection pa-rameters. According to Equation 6, we then produce the ST-mixedmeta-parameters for GCRU as R using query. Moreover, inspired by , we apply a time-varying adaptivegraph G inferred from : = Softmax(ReLU( )),(11) where R . The decoder takes the initial hidden statefrom and iteratively generates predictions for each futuretimestep by applying the GCRU cell parameterized by .Given ground truth +1:+ , we mainly adopt the Mean Abso-lute Error (MAE) loss as our training objective to optimize multi-step predictions jointly. The loss function for HimNets multi-stepspatiotemporal time series forecasting can be formulated as:",
  "EXPERIMENT5.1Experimental Setup": "Datasets. Our proposed model is evaluated on the five most com-monly used spatiotemporal forecasting benchmarks. The METRLAdataset and PEMSBAY dataset contain traffic speed data recordedby traffic sensors in Los Angeles and the Bay Area, respectively. ThePEMS04, PEMS07, and PEMS08 datasets are three traffic flowdatasets collected from the California Transportation PerformanceManagement System (PeMS). The raw data has a fine temporal",
  "PEMS08": "AverageMAE34.6619.3616.0815.2214.4015.3216.4915.4114.2115.4113.5814.7513.57RMSE50.4531.2025.3924.1723.3924.4126.0824.7723.2824.6223.4123.7323.22MAPE21.63%12.43%10.60%10.21%9.21%10.03%10.54%9.76%9.27%9.94%9.05%9.48%8.98% granularity of 5 minutes between consecutive timesteps. Therefore,=288 and =7 in these benchmarks. Additional details regard-ing the five benchmarks can be found in . As part of datapreprocessing, we perform Z-score normalization on the raw inputsto rescale the data to have zero mean and unit variance. To ensure afair comparison to previous methods, we adopt the commonly useddataset divisions from prior works. For the METRLA and PEMSBAYdatasets, we use 70% of the data for training, 10% for validation, andthe remaining 20% for testing . In the case of the PEMS04,PEMS07, and PEMS08 datasets, we divide them into 60%, 20%, and20%, respectively . In this study, we ensured the ethicaluse of these five publicly available datasets.Settings. We performed hyper-parameter search on each dataset.The encoder and decoder each contain one layer =1 with a hid-den dimension =64 for the first four datasets, and =96 for thePEMS08 dataset. For the embeddings, the dimensions of the tempo-ral embedding , the spatial embedding , and the spatiotemporalembedding are all set to 16 for the first four datasets. And forPEMS08, the dimensions are 12, 14, and 10, respectively. The inputand prediction horizons are both set to 1 hour (= =12 timesteps).We use the Adam optimizer with an initial learning rate of 0.001and decay over training, and the batch size is 16. The maximum training epochs is 200, with an early stop patience set to 20. Forthe loss function, we employ MAE loss for METRLA and PEMS-BAY. For PEMS04, PEMS07, and PEMS08, we further employ Huberloss , a variant of MAE that is more robust. Model performanceis evaluated using MAE, Root Mean Square Error (RMSE), and MeanAbsolute Percentage Error (MAPE). All following experiments areconducted on NVIDIA GeForce RTX 3090 GPUs.Baselines. We compare our HimNet to several widely adoptedbaselines. HI is a standard statistical technique. GRU is awidely adopted univariate time series forecasting method. As forspatiotemporal forecasting, we select several typical models includ-ing STGCN , DCRNN , Graph WaveNet , AGCRN ,GTS , STNorm , STID , ST-WA , PDFormer andMegaCRN . Among them, DCRNN, GTS, and MegaCRN alsoapply GCRU-based architectures. AGCRN and ST-WA are meta-parameter learning methods closely related to our approach.",
  "Ablation Study": "In this section, we conduct ablation studies to validate key com-ponents of our proposed approach. We designed the followingvariants: (1) w/o : replaces the temporal embedding with a staticmatrix of all ones, thus removing temporal heterogeneity modeling.(2) w/o : replaces the spatial embedding with a static matrix ofall ones, thus removing spatial heterogeneity modeling. (3) w/o :replaces the spatiotemporal embedding with a static matrix of allones. (4) w/o TMP: removes temporal meta-parameters by down-grading to randomly initialized parameters. (5) w/o SMP: removesspatial meta-parameters in the same way. (6) w/o STMP: removesST-mixed meta-parameters in the same way. As shown in ,using identical queries decreases forecasting performance, demon-strating the effectiveness of our heterogeneity-informed approach.Moreover, removing meta-parameters leads to more substantialperformance degradation, highlighting the value of applying thespatiotemporal meta-parameters modulated by our method. Allthese validate that HimNet is complete and indivisible to achievesuperior spatiotemporal forecasting performance.",
  "We conduct experiments on our models sensitivity to key hyper-parameters, including the dimension of the temporal embedding ,": "the spatial embedding , and the spatiotemporal embedding . plots the average RMSE of predictions on the METRLAdataset when varying each embedding dimension from 4 to 24. In-terestingly, we find that our model is fairly robust to changes inthese hyper-parameters. Across the ranges tested, the RMSE differ-ence between the best and worst-performing configurations is onlyapproximately 0.1. An embedding size of 16 generally provides goodresults with a tractable parameter size. Still, some trends emergewhere decreasing a dimension too much begins to exhibit signs ofunder-fitting, while larger dimensions will substantially increaseparameter size but without notable improvement in performance.",
  "Efficiency Study": "We evaluate efficiency by comparing HimNet with 10 spatiotem-poral baseline models. reports the number of parameters,per-batch runtime, per-epoch runtime, and GPU memory usage onMETRLA (batch size =16).As shown in the table, models using TCNs, such as STGCN,GWNet and STNorm, perform relatively well because of the highcomputational efficiency of convolution. In comparison, the nextfour models with GCRU architecture show a notable efficiency gapdue to the iterative nature of RNNs that intrinsically presents adisadvantage. Additionally, Transformer-based models like ST-WAand PDFormer are even worse due to their quadratic computationalcomplexity. Among these, STID performs best as its backbone issimply linear layers. We also observe that HimNets memory usageis relatively high, because our design of the meta-parameter pools",
  ": The evolving ST-mixed meta-parameters of clusters0 and 8. As the time series diverge, they evolve accordingly": "each hour across the days of a week. With one day sampled at anhourly granularity, this results in a total of 168 data points embed-ded in the 2D latent space. As shown in (a), distinct tightclusters form for each individual day, demonstrating our methodsability to differentiate days of the week. Notably, weekdays andweekends are widely separated, underscoring our effectiveness incapturing the temporal heterogeneity between these day types.(b) shows the cosine similarity between the temporal meta-parameters of each hourly interval within a day. Higher similarity isobserved between adjacent hours, decreasing with increased tempo-ral distance as expected. Interestingly, the time periods when peopletravel frequently exhibit high similarity. For example, the periodsbetween 6-9am and 4-7pm show increased similarity, reflectingreal-world commuting behaviors. These examples demonstrate thatour proposed method successfully identifies and distinguishes thediverse temporal contexts associated with different time periods.Spatial Meta-Parameters. For the spatial meta-parameters, weanalyze the METRLA dataset as a case study. It contains 207 sensorlocations whose spatial meta-parameters are embedded in 2D latentspace as shown in (c). The 207 points naturally form into15 clusters marked with different colors. To interpret these clus-ters, we draw them onto a real map of Los Angeles in (d).Remarkably, each cluster precisely aligns with road segments, un-derscoring our models strong power to capture real-world urban",
  "CONCLUSION": "In this study, we proposed a novel Heterogeneity-InformedMeta-Parameter Learning scheme along with the state-of-the-artHeterogeneity-Informed Spatiotemporal Meta-Network (HimNet)for spatiotemporal forecasting. In detail, we captured spatiotem-poral heterogeneity by learning spatial and temporal embeddings.A novel meta-parameter learning paradigm was proposed to learnspatiotemporal-specific parameters from meta-parameter pools.Critically, our proposed approach can fully leverage the capturedspatiotemporal heterogeneity to inform meta-parameter learning.",
  "Extensive experiments on five benchmarks demonstrated Him-Nets superior performance. Further visualization analyses on meta-parameters revealed its strong interpretability": "This work was partially supported by the grants of National KeyResearch and Development Project (2021YFB1714400) of China,Jilin Provincial International Cooperation Key Laboratory for SuperSmart City and Zhujiang Project (2019QN01S744). Rafal A Angryk, Petrus C Martens, Berkay Aydin, Dustin Kempton, Sushant SMahajan, Sunitha Basodi, Azim Ahmadzadeh, Xumin Cai, Soukaina Fi-lali Boubrahimi, Shah Muhammad Hamdi, et al. 2020. Multivariate time seriesdataset for space weather data analytics. Scientific data 7, 1 (2020), 227. Lei Bai, Lina Yao, Can Li, Xianzhi Wang, and Can Wang. 2020. Adaptive graphconvolutional recurrent network for traffic forecasting. Advances in neuralinformation processing systems 33 (2020), 1780417815.",
  "Gary A Davis and Nancy L Nihan. 1991. Nonparametric regression and short-term freeway traffic forecasting. Journal of Transportation Engineering 117, 2(1991), 178188": "Jinliang Deng, Xiusi Chen, Renhe Jiang, Xuan Song, and Ivor W Tsang. 2021. St-norm: Spatial and temporal normalization for multi-variate time series forecasting.In Proceedings of the 27th ACM SIGKDD conference on knowledge discovery & datamining. 269278. Jinliang Deng, Xiusi Chen, Renhe Jiang, Xuan Song, and Ivor W Tsang. 2022. Amulti-view multi-task learning framework for multi-variate time series forecast-ing. IEEE Transactions on Knowledge and Data Engineering (2022). Jinliang Deng, Xiusi Chen, Renhe Jiang, Du Yin, Yi Yang, Xuan Song, and Ivor WTsang. 2024. Disentangling Structured Components: Towards Adaptive, Inter-pretable and Scalable Time Series Forecasting. IEEE Transactions on Knowledgeand Data Engineering (2024). Jiewen Deng, Jinliang Deng, Renhe Jiang, and Xuan Song. 2023. Learning Gauss-ian mixture representations for tensor time series forecasting. In Proceedings ofthe Thirty-Second International Joint Conference on Artificial Intelligence.",
  "Jiewen Deng, Renhe Jiang, Jiaqi Zhang, and Xuan Song. 2024. Multi-ModalitySpatio-Temporal Forecasting via Self-Supervised Learning.arXiv preprintarXiv:2405.03255 (2024)": "Yuchen Fang, Yanjun Qin, Haiyong Luo, Fang Zhao, Bingbing Xu, Liang Zeng,and Chenxing Wang. 2023. When spatio-temporal meet wavelets: Disentangledtraffic forecasting via efficient spectral graph attention networks. In 2023 IEEE39th International Conference on Data Engineering (ICDE). IEEE, 517529. Zheng Fang, Qingqing Long, Guojie Song, and Kunqing Xie. 2021. Spatial-temporal graph ode networks for traffic flow forecasting. In Proceedings of the27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 364373.",
  "Jiawei Jiang, Chengkai Han, Wayne Xin Zhao, and Jingyuan Wang. 2023.PDFormer: Propagation Delay-aware Dynamic Long-range Transformer for Traf-fic Flow Prediction. In AAAI. AAAI Press": "Renhe Jiang, Zhaonan Wang, Yudong Tao, Chuang Yang, Xuan Song, RyosukeShibasaki, Shu-Ching Chen, and Mei-Ling Shyu. 2023. Learning Social Meta-knowledge for Nowcasting Human Mobility in Disaster. In Proceedings of theACM Web Conference 2023. 26552665. Renhe Jiang, Zhaonan Wang, Jiawei Yong, Puneet Jeph, Quanjun Chen, Ya-sumasa Kobayashi, Xuan Song, Shintaro Fukushima, and Toyotaro Suzumura.2023. Spatio-temporal meta-graph learning for traffic forecasting. In Proceedingsof the AAAI Conference on Artificial Intelligence, Vol. 37. 80788086. Renhe Jiang, Du Yin, Zhaonan Wang, Yizhuo Wang, Jiewen Deng, Hangchen Liu,Zekun Cai, Jinliang Deng, Xuan Song, and Ryosuke Shibasaki. 2021. Dl-traff:Survey and benchmark of deep learning models for urban traffic prediction. InProceedings of the 30th ACM international conference on information & knowledgemanagement. 45154525. Ming Jin, Huan Yee Koh, Qingsong Wen, Daniele Zambon, Cesare Alippi, Geof-frey I Webb, Irwin King, and Shirui Pan. 2023. A survey on graph neural networksfor time series: Forecasting, classification, imputation, and anomaly detection.arXiv preprint arXiv:2307.03759 (2023). Yilun Jin, Kai Chen, and Qiang Yang. 2023. Transferable Graph Structure Learningfor Graph-based Traffic Forecasting Across Cities. In Proceedings of the 29th ACMSIGKDD Conference on Knowledge Discovery and Data Mining. 10321043. Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu. 2018. Modelinglong-and short-term temporal patterns with deep neural networks. In The 41stinternational ACM SIGIR conference on research & development in informationretrieval. 95104. Shiyong Lan, Yitong Ma, Weikang Huang, Wenwu Wang, Hongyu Yang, andPyang Li. 2022. Dstagnn: Dynamic spatial-temporal aware graph neural networkfor traffic flow forecasting. In International conference on machine learning. PMLR,1190611917. Hyunwook Lee, Seungmin Jin, Hyeshin Chu, Hongkyu Lim, and Sungahn Ko.2022. Learning to Remember Patterns: Pattern Matching Memory Networks forTraffic Forecasting. In International Conference on Learning Representations.",
  "Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion ConvolutionalRecurrent Neural Network: Data-Driven Traffic Forecasting. In InternationalConference on Learning Representations": "Fan Liu, Weijia Zhang, and Hao Liu. 2023. Robust Spatiotemporal Traffic Fore-casting with Reinforced Dynamic Adversarial Training. In Proceedings of the 29thACM SIGKDD Conference on Knowledge Discovery and Data Mining. Hangchen Liu, Zheng Dong, Renhe Jiang, Jiewen Deng, Jinliang Deng, Quan-jun Chen, and Xuan Song. 2023. Spatio-temporal adaptive embedding makesvanilla transformer sota for traffic forecasting. In Proceedings of the 32nd ACMInternational Conference on Information and Knowledge Management. 41254129. Xu Liu, Yutong Xia, Yuxuan Liang, Junfeng Hu, Yiwei Wang, Lei Bai, Chao Huang,Zhenguang Liu, Bryan Hooi, and Roger Zimmermann. 2023. LargeST: A Bench-mark Dataset for Large-Scale Traffic Forecasting. arXiv preprint arXiv:2306.08259(2023). Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, andMingsheng Long. 2023. iTransformer: Inverted Transformers Are Effective forTime Series Forecasting. arXiv preprint arXiv:2310.06625 (2023).",
  "Zhongjian Lv, Jiajie Xu, Kai Zheng, Hongzhi Yin, Pengpeng Zhao, and XiaofangZhou. 2018. Lc-rnn: A deep learning model for traffic speed prediction.. In IJCAI,Vol. 2018. 27th": "Xiaolei Ma, Zhimin Tao, Yinhai Wang, Haiyang Yu, and Yunpeng Wang. 2015.Long short-term memory neural network for traffic speed prediction using remotemicrowave sensor data. Transportation Research Part C: Emerging Technologies54 (2015). Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, OriolVinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.2016. Wavenet: A generative model for raw audio. arXiv preprint arXiv:1609.03499(2016).",
  "Bei Pan, Ugur Demiryurek, and Cyrus Shahabi. 2012. Utilizing real-world trans-portation data for accurate traffic prediction. In 2012 ieee 12th internationalconference on data mining. IEEE, 595604": "Zheyi Pan, Yuxuan Liang, Weifeng Wang, Yong Yu, Yu Zheng, and Junbo Zhang.2019. Urban traffic prediction from spatio-temporal data using deep meta learning.In Proceedings of the 25th ACM SIGKDD International Conference on KnowledgeDiscovery & Data Mining. 17201730. Zheyi Pan, Wentao Zhang, Yuxuan Liang, Weinan Zhang, Yong Yu, Junbo Zhang,and Yu Zheng. 2020. Spatio-temporal meta learning for urban traffic prediction.IEEE Transactions on Knowledge and Data Engineering 34, 3 (2020), 14621476.",
  "Chao Shang, Jie Chen, and Jinbo Bi. 2021. Discrete Graph Structure Learningfor Forecasting Multiple Time Series. In International Conference on LearningRepresentations": "Zezhi Shao, Fei Wang, Yongjun Xu, Wei Wei, Chengqing Yu, Zhao Zhang, Di Yao,Guangyin Jin, Xin Cao, Gao Cong, et al. 2023. Exploring Progress in Multivari-ate Time Series Forecasting: Comprehensive Benchmarking and HeterogeneityAnalysis. arXiv preprint arXiv:2310.06119 (2023). Zezhi Shao, Zhao Zhang, Fei Wang, Wei Wei, and Yongjun Xu. 2022. Spatial-temporal identity: A simple yet effective baseline for multivariate time seriesforecasting. In Proceedings of the 31st ACM International Conference on Information& Knowledge Management. 44544458. Chao Song, Youfang Lin, Shengnan Guo, and Huaiyu Wan. 2020.Spatial-temporal synchronous graph convolutional networks: A new framework forspatial-temporal network data forecasting. In Proceedings of the AAAI conferenceon artificial intelligence, Vol. 34. 914921.",
  "Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.Journal of machine learning research 9, 11 (2008)": "Lelitha Vanajakshi and Laurence R Rilett. 2004. A comparison of the performanceof artificial neural networks and support vector machines for the prediction oftraffic speed. In IEEE Intelligent Vehicles Symposium, 2004. IEEE, 194199. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,Aidan N Gomez, ukasz Kaiser, and Illia Polosukhin. 2017. Attention is allyou need. Advances in neural information processing systems 30 (2017). Qingsong Wen, Tian Zhou, Chaoli Zhang, Weiqi Chen, Ziqing Ma, Junchi Yan,and Liang Sun. 2023. Transformers in time series: A survey. In International JointConference on Artificial Intelligence(IJCAI). Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. 2021. Autoformer: De-composition transformers with auto-correlation for long-term series forecasting.Advances in Neural Information Processing Systems 34 (2021), 2241922430. Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, Xiaojun Chang, and ChengqiZhang. 2020. Connecting the dots: Multivariate time series forecasting with graphneural networks. In Proceedings of the 26th ACM SIGKDD international conferenceon knowledge discovery & data mining. 753763. Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. 2019.Graph wavenet for deep spatial-temporal graph modeling. In Proceedings of the28th International Joint Conference on Artificial Intelligence. 19071913. Yutong Xia, Yuxuan Liang, Haomin Wen, Xu Liu, Kun Wang, Zhengyang Zhou,and Roger Zimmermann. 2023. Deciphering Spatio-Temporal Graph Forecasting:A Causal Lens and Treatment. In Thirty-seventh Conference on Neural InformationProcessing Systems.",
  "Congxi Xiao, Jingbo Zhou, Jizhou Huang, Tong Xu, and Hui Xiong. 2023. SpatialHeterophily Aware Graph Neural Networks. arXiv preprint arXiv:2306.12139(2023)": "Junchen Ye, Leilei Sun, Bowen Du, Yanjie Fu, and Hui Xiong. 2021. Coupled Layer-wise Graph Convolution for Transportation Demand Prediction. In Proceedingsof the AAAI Conference on Artificial Intelligence, Vol. 35. 46174625. Bing Yu, Haoteng Yin, and Zhanxing Zhu. 2018. Spatio-temporal graph convolu-tional networks: a deep learning framework for traffic forecasting. In Proceedingsof the 27th International Joint Conference on Artificial Intelligence. 36343640.",
  "Conference on Knowledge Discovery and Data Mining": "Chuanpan Zheng, Xiaoliang Fan, Cheng Wang, and Jianzhong Qi. 2020. Gman: Agraph multi-attention network for traffic prediction. In Proceedings of the AAAIconference on artificial intelligence, Vol. 34. 12341241. Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong,and Wancai Zhang. 2021. Informer: Beyond efficient transformer for long se-quence time-series forecasting. In Proceedings of the AAAI conference on artificialintelligence, Vol. 35. 1110611115. Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin.2022. Fedformer: Frequency enhanced decomposed transformer for long-termseries forecasting. In International Conference on Machine Learning. PMLR, 2726827286. Zhengyang Zhou, Qihe Huang, Gengyu Lin, Kuo Yang, Lei Bai, and Yang Wang.2022. Greto: remedying dynamic graph topology-task discordance via targethomophily. In The eleventh international conference on learning representations. Zhengyang Zhou, Yang Wang, Xike Xie, Lianliang Chen, and Chaochao Zhu.2020. Foresee urban sparse traffic accidents: A spatiotemporal multi-granularityperspective. IEEE Transactions on Knowledge and Data Engineering (2020). Zhengyang Zhou, Kuo Yang, Yuxuan Liang, Binwu Wang, Hongyang Chen,and Yang Wang. 2023. Predicting collective human mobility via counteringspatiotemporal heterogeneity. IEEE Transactions on Mobile Computing (2023).",
  "A.3Efficiency Report": "All the experiments are performed on an Intel(R) Xeon(R) Silver4310 CPU @ 2.10GHz, 256G RAM computing server, equipped withNVIDIA GeForce RTX 3090 graphics cards. We report the totaltraining time and memory cost in . Even for the largestdataset PEMS07 (883 sensors), our memory usage is still under24GB, allowing running all benchmarks on a single RTX 3090 GPU."
}