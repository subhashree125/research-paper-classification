{
  "ABSTRACT": "Stock trend forecasting is a fundamental task of quantitative invest-ment where precise predictions of price trends are indispensable.As an online service, stock data continuously arrive over time. It ispractical and efficient to incrementally update the forecast modelwith the latest data which may reveal some new patterns recurringin the future stock market. However, incremental learning for stocktrend forecasting still remains under-explored due to the challengeof distribution shifts (a.k.a. concept drifts). With the stock marketdynamically evolving, the distribution of future data can slightly orsignificantly differ from incremental data, hindering the effective-ness of incremental updates. To address this challenge, we proposeDoubleAdapt, an end-to-end framework with two adapters, whichcan effectively adapt the data and the model to mitigate the effectsof distribution shifts. Our key insight is to automatically learn howto adapt stock data into a locally stationary distribution in favor ofprofitable updates. Complemented by data adaptation, we can con-fidently adapt the model parameters under mitigated distributionshifts. We cast each incremental learning task as a meta-learningtask and automatically optimize the adapters for desirable dataadaptation and parameter initialization. Experiments on real-worldstock datasets demonstrate that DoubleAdapt achieves state-of-the-art predictive performance and shows considerable efficiency. Ourcode is available at",
  "Yanyan Shen is the corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 23, August 610, 2023, Long Beach, CA, USA. 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0103-0/23/08...$15.00",
  "INTRODUCTION": "Stock trend forecasting, which aims at predicting future trends ofstock prices, is a fundamental task of quantitative investment andhas attracted soaring attention in recent years . Due to thewidespread success of deep learning, various neural networks havebeen developed to exploit intricate patterns of the stock marketand infer future price trends. As an online application, new stockdata arrive in a streaming way as time goes by. This gives rise to anincreasingly growing dataset that is enriched with more underlyingpatterns. It is of vital importance to continually learn new emergingpatterns from incoming stock data, in order to avoid the model agingissue and pursue higher accuracy in future predictions.To this end, a common practice named Rolling Retraining (RR) isused to periodically leverage the whole enlarged dataset to retrainthe model parameters from scratch. However, RR usually leaves outabundant recent samples for validation and fails to retrain the modelon the validation set, of which the patterns are often informativeand valuable for future predictions . Another fatal drawback ofRR lies in its expensive time and space consumptions. The trainingtime increases with the size of the enlarged training data, whichfurther causes an unbearable duration of hyperparameter tuningand retraining algorithm selection. An alternative way known asIncremental Learning (IL) is to fine-tune the model only with thelatest incremental data. In each IL task, the model is initialized byinheriting parameters from the preceding IL task that are expectedto memorize historical patterns, and then the model is consolidatedwith new knowledge in incremental data. The rationale behindit is that recent data may reveal some new patterns that did notappear before but will reoccur in the future. Moreover, IL is notonly dramatically faster but also occupies much smaller space thanRR.Despite its considerable efficiency and potential effectiveness,IL is still under-explored in stock trend forecasting mainly dueto the challenge of distribution shifts (a.k.a. concept drifts). ILperforms well only if there is always little difference between thedistributions of incremental data and future data. However, it is wellaccepted that the stock market is in a non-stationary environmentwhere data distribution irregularly shifts over time . Suchdistribution shifts can vary in direction and degree. For example,in , we visualize two real cases of distribution shifts in theChinese stock market. Given historical samples in the last month(e.g., 2019/09) as incremental data, we are meant to deploy a modelonline and do inference on the test samples in the next month (e.g.,2019/10), termed as test data. In the case of gradual shifts as shownin a, incremental data can reveal some future tendenciesbut its distribution still differs from the test data. A model that wellfits the incremental data may not perfectly succeed in the future.",
  "(b) Abrupt shift": ": Illustration of distribution shifts in CSI 300 stockset. The vector of each stock including dozens of technical in-dicators and the corresponding label is mapped via t-SNE to a 1-D point on the horizontal axis. We estimate the dis-tributions with a kernel density estimator. We plot the dis-tribution of the incremental data in one month in purple,the distribution of all the previous data in black, and thedistribution of the next months data in green. Moreover, incremental data could even become misleading whendistribution shifts abruptly appear, making a nonnegligible gapbetween the two data distributions, as shown in b. As longas distribution shifts exist, typical IL cannot consistently benefitfrom incremental data and may even suffer from inappropriateupdates. In a nutshell, the discrepancy between the distributions ofincremental data and test data could hinder the overall performance,posing the key challenge to IL for stock trend forecasting.Confronted with this challenge, it is noteworthy that the incre-mental updates stem from two factors: the incremental data andthe initial parameters. Conventional IL blindly inherits the parame-ters learned in the previous task as initial parameter weights andconducts one-sided model adaptation on raw incremental data. Toimprove IL against distribution shifts, we propose to strengthen thelearning scheme by performing two-fold adaptation, namely dataadaptation and model adaptation. The data adaptation aims toclose the gap between the distributions of incremental data and testdata. For example, biased patterns that only exist in incrementaldata are equivalent to noise with respect to test data and could beresolved through proper data adaptation. Our model adaptationfocuses on learning a good initialization of parameters for eachIL task, which can appropriately adapt to incremental data andstill retain a degree of robustness to distribution shifts. However,it is intractable to design optimal adaptation for each IL task. Aproper choice of adaptation varies by forecast model, dataset, pe-riod, degree of distribution shifts, and so on. Hence, we borrowideas from meta-learning to realize the two-fold adaptation, i.e.,to automatically find profitable data adaptation without human labor or expertise and to reach a sweet spot between adaptivenessand robustness for model adaptation.In this work, we propose DoubleAdapt, a meta-learning approachto incremental learning for stock trend forecasting. We introducetwo meta-learners, namely data adapter and model adapter, whichadapt data towards a locally stationary distribution and equip themodel with task-specific parameters that have quickly adapted tothe incremental data and still generalize well on the test data. Thedata adapter contains a multi-head feature adaptation layer and amulti-head label adaptation layer in order to obtain adapted incre-mental data and adapted test data that are profitable for incrementallearning. Specifically, the feature adaptation layer transforms allfeatures from the incremental data and the test data, while thelabel adaptation layer rectifies labels of the incremental data andits inverse function restores model predictions on the test data.By casting the problem of IL for stock trend forecasting as a se-quence of meta-learning tasks, we perform each IL task by solvinga bi-level optimization problem: (i) in the lower-level optimization,the parameters of the forecast model are initialized by the modeladapter and fine-tuned on the adapted incremental data; (ii) in theupper-level optimization, the meta-learners are optimized by testerrors on the adapted test data. Throughout the online inferencephase, both the two adapters and the forecast model will be updatedcontinually over new IL tasks.The main contributions of this work are summarized as follows.",
  "We propose DoubleAdapt, an end-to-end incremental learningframework for stock trend forecasting, which adapts both thedata and the model to cope with distribution shifts in the onlineenvironment": "We formulate each incremental learning task as a bi-level opti-mization problem. The lower level is the forecast model that isinitialized by the model adapter and fine-tuned using the adaptedincremental data. The upper level includes the data adapter andthe model adapter as two meta-learners that are optimized tominimize the forecast error on the adapted test data. We conduct experiments on real-world datasets and demonstratethat DoubleAdapt performs effectively against different kinds ofdistribution shifts and achieves state-of-the-art predictive per-formance compared with RR and meta-learning methods. Dou-bleAdapt also enjoys high efficiency compared with RR methods.",
  "DoubleAdapt: A Meta-learning Approach to Incremental Learning for Stock Trend ForecastingKDD 23, August 610, 2023, Long Beach, CA, USA": "x with opening price, closing price, and other indicators in recentdays. Its stock price trend is the corresponding label. Supposethe stock market comprises stocks. The collection of features andlabels of the stocks at date can be denoted as X( ) R andY( ) R, respectively. The goal of stock trend forecasting is tolearn a forecast model on historical data {(X( ), Y( ))}=1 andthen forecast the labels of future data {(X( ), Y( ))} =+1, where and are the end time of the historical data and the future data,respectively. The parameters of are denoted as .In online scenarios, new data are coming over time. Once theground-truth labels of new samples are obtained, we can updatethe forecast model to learn new emerging patterns. In this work,we focus on incremental learning (IL) for stock trend forecasting,where we periodically launch IL tasks to update the model only withincremental data, as illustrated in and defined as follows. Definition 2 (IL Task for Stock Trend Forecasting). Supposing a pre-trained forecast model is deployed online at date +1, we launchan IL task every dates, where is predetermined by practicalapplications. For the -th IL task at date ++1, we fine-tune themodel parameters 1 on incremental data Dtrain and predictlabels on test data Dtest in the following dates, where Dtrain =",
  "{(X( ), Y( ))}+=+(1)+1 and Dtest = {(X( ), Y( ))}+(+1)=++1. The": "outputs of the -th task are updated parameters and predictions{ Y( )}+(+1)=++1. The IL task expects the model to quickly adapt tothe incremental data, in order to make precise predictions on fu-ture data with similar patterns. We can evaluate the predictions bycomputing a loss function Ltest on Dtest, e.g., mean square error. Problem Statement. Given a predefined task interval , IL forstock trend forecasting is constituted by a sequence of IL tasks, i.e.,T = {(D1train, D1test), (D2train, D2test), , (Dtrain, Dtest), }. Ineach task, we update the model parameters, do online inference,and end up with performance evaluation on the ground-truth la-bels of the test data. The goal of IL is to achieve the best overallperformance across all test dates, which can be evaluated by ex-cess annualized returns or other ranking metrics of stock trendforecasting.Typically, IL holds a strong assumption that a model which fitsrecent data can perform well on the following data under the samedistribution. However, as the stock market is dynamically evolving,its data distribution can easily shift over time. Dtrain and Dtest arelikely to have two different joint distributions, i.e., Ptrain(x,) Ptest(x,), where Ptrain and Ptest denote the distributions of Dtrainand Dtest, respectively. The distribution shifts can be zoomed intothe following two cases :",
  "KEY INSIGHTS": "To tackle the distribution shift challenge, there are two importantdirections to follow. One is to close the gap between incrementaldata and test data so as to perform IL on more stationary distribu-tions. Another is to enhance the generalization ability of the modelagainst distribution shifts. Following both directions, we proposeto perform data adaptation and model adaptation for each IL task.We describe our key insights with the following details. Data Adaptation. A critical yet under-explored direction is toadapt data into a locally stationary distribution so as to mitigatethe effects of distribution shifts at the data level. Some RR methodsresample all historical data (e.g., 500 million samples) into a newtraining set that shares a similar distribution with future data .However, such a coarse-grained adaptation fails in IL where in-cremental data is of limited size (e.g., one thousand samples) andcontains deficient samples to reveal future patterns. To addressthis limitation, we propose to adapt all features and labels of theincremental data to mitigate the effects of distribution shifts ina fine-grained way. We argue that some shift patterns repeatedlyappear in the historical data and are learnable. For example, stockprices can overreact to some bullish news and emotional invest-ment, while the prices and the trend patterns tend to shift towardsnormal in future weeks. Thus, it is often desirable to retract theoverreacting features and labels to approach future tendencies. Inaddition, assuming the original incremental data is reliable, testdata of a different distribution can be deemed as a biased dataset.Adapting test data towards the distribution of incremental data hasa debiasing effect. Hence, we adapt both Dtrain and Dtest so as tonarrow the gap between their distributions.Technically, we cannot directly align Ptrain(x,) and Ptest(x,)because labels of test data are unknown at the inference time. Wethus decouple distribution shifts into covariate shifts and condi-tional distribution shifts, and address them separately, as illustratedin . First, we require a mapping function to transform thefeatures of Dtrain and Dtest in a fine-grained way, and we expect to adapt Ptrain(x) and Ptest(x) to an agent feature distributionPagent(x), alleviating covariate shifts. Second, we apply another",
  "fitting Pagent(|x) can precisely predict the adapted label for thetest data. Finally, we need to inversely map the model outputs fromPagent(|x) to Ptest(|x). As such, we narrow the gap between": "Ptrain(x) and Ptest(x) via feature adaptation, and narrow the gapbetween Ptrain(|x) and Ptest(|x) via label adaptation. This al-lows us to reduce the discrepancy between the joint distributions,alleviating the distribution shift issue. Model Adaptation. Typically, IL initializes the model by the param-eters learned in the previous task and updates the initial parameterson incremental data. Distribution shifts would hinder the test per-formance if the parameters after updates fall into a local optimumand overfit the incremental data. This motivates us to learn a goodinitialization of parameters for each IL task. On the one hand, theinitial parameters of each task is required to preserve historicalexperience and retain generalization ability against distributionshifts. On the other hand, the parameters in IL still need to effec-tively memorize task-specific information without being trappedin past experiences. Therefore, we emphasize another importantdirection where we optimize the initial parameters of each IL taskfor robustness and adaptiveness. Optimization via Meta-learning. Following our key insights, weaim to mitigate distribution shifts at the data level and enhance gen-eralization ability at the parameter level. Desirable data adaptationshould make the distributions of the two datasets more similar butstill informative for stock trend forecasting. Nevertheless, it is infea-sible to manually design proper data adaptation as numerous factorsshould be considered, e.g., forecast models, datasets, prediction time,degrees of distribution shifts, and so on. For model adaptation, itis also tough to reach a sweet spot between robustness and adap-tiveness. We thus introduce a meta-learning optimization objectiveto guide profitable data adaptation and parameter initialization.Though some normalization techniques in meta-learningcan reduce distribution divergences, they may destroy the originalstatistical indicators (i.e., mean and standard deviation), which arecritical task-specific information and deserve memorization in theonline settings. In light of this, we pioneer mitigating the distribu-tion shifts in meta-learning through neural networks rather thannormalization.",
  "METHODOLOGY4.1Overview": "depicts the overview of our DoubleAdapt framework,which consists of three key components: forecast model with pa-rameters , model adapter with parameters , and data adapter with parameters . contains a feature adaptation layer and a label adaptation layer , along with its inverse function 1. In particular, the implementation of can be realized by anyneural network for stock trend forecasting, such as GRU andALSTM .We cast IL for stock trend forecasting as a sequence of meta-learning tasks. For each task (Dtrain, Dtest), DoubleAdapt involvesfour steps as listed below.",
  "into the final prediction . We denote the adapted test datasetby Dtest that is obtained by transforming raw features in Dtest": "(4) Optimization of meta-learners. We calculate the final fore-cast error Ltest once we obtain all ground-truth labels in orderto optimize our meta-learners (i.e., and ) in the upperlevel. The parameters of meta-learners are updated from 1 and 1 to and , which are used for the next IL task.The meta-learning process is essentially a bi-level optimizationproblem, where the fine-tuning in Step (2) is the lower-level op-timization and Step (4) is the upper-level optimization. Formally,since we desire a minimal forecast error on Dtest, the bi-level opti-mization of the -th IL task is defined as",
  "Dtrain = (Dtrain ;1);Dtest = (Dtest;1).(4)": "Note that we only adapt features of Dtest because test labels areunknown during online inference time.Generally, the best incremental learning algorithm should lead tominimum accumulated errors on all test datasets throughout onlineinference. However, in the context of stock trend forecasting, weonly focus on improving the test performance of the current tasksince past predictions cannot be withdrawn and future datasets areunseen. Therefore, we greedily optimize and task by task in apractical scenario. Furthermore, we approximate Eq. (2) by one-stepgradient descent for the concern of training efficiency.In the following subsections, we elaborate the two adapters anddetail our upper-level optimization.",
  "Data Adapter": "Data adapter is a meta-learner to learn what data adaptation isfavorable for appropriate updates and promising test performance. consists of three mapping functions, i.e., feature adaptation ,label adaptation , and its inverse mapping 1.Following our insights, we propose a mapping function to mapPtrain(x) and Ptest(x) into an agent feature distribution Pagent(x),alleviating covariate shifts. We intuitively introduce a dense layeras a simple implementation of , which is defined as follows:",
  "x = Wx + b,(5)": "where x denotes the adapted feature vector, W R is theparameter matrix, and b R is the bias vector. Features fromDtrain and Dtest are thereby transformed onto a new commonhyperplane via the same affine transformation.The remaining concern is that one simple dense layer is notexpressive enough. Different types of feature vectors may requiredifferent transformations, for example, abnormal values need to bescaled or masked, trustworthy features just need identity mapping,and profitable signals need to be emphasized. Moreover, stock pricetrends tend to bear similar shift patterns when the stocks belongto the same concept (e.g., sector, industry, and business), and viceversa. Accordingly, an appealing solution is to employ differenttransformation heads and decide which candidate head is moresuitable for the input. We thus propose a multi-head feature adap-tation layer with multiple feature transformation heads, which isformally defined as follows:",
  "=1 exp /,(9)": "where is a positive hyperparameter to control softmax temper-ature. With the prototypes deemed as learnable embeddings ofhidden concepts in the stock market, the multi-head feature adap-tation layer can provide concept-oriented transformations for eachinput feature vector x.To cope with conditional distribution shifts, we adapt labels ofDtrain. We define a label transformation head as follows:",
  "where1( ) = ( )/.(13)": "One can seek further improvements on the implementation of eachlabel adaptation head by various normalizing flows , whichcomprise a sequence of invertible mappings. Empirically, we showthat the simple linear heads have already been effective in Sec. 6.3.To summarize, meta-parameters of the data adapter includethe parameters of and , i.e., = {W, b, p,, }=1. The dataadapter transforms features of Dtrain and Dtest by Eq. (6), andtransforms labels of Dtrain by Eq. (11). The adapted datasets Dtrainand Dtest in Eq. (4) can be formalized as",
  "= 1 Ltrain( Dtrain;1),(16)": "where is the learning rate of the forecast model and we onlyperform one-step gradient updates for fast adaptation. Next, wedeploy (;) online to make predictions on adapted test dataDtest.Note that DoubleAdapt is a generic framework for any imple-mentation of the model adapter. The one-step gradient update canalso be replaced by other model adaptation approaches, such ascontext-dependent gating and transfer network .",
  "= 1 Ltest( Dtest;),(20)": "where is the learning rate of . The difference between tra-ditional MAML and our method lies in that we only use onequery set at each time to update the meta-learner. We are devoted toimproving performance on the current test data because the stockmarket evolves and a large proportion of past data may not containpatterns that will reappear in the future. It is also practical in theIL setting where we only save samples of one task in memory.Similarly, we optimize according to actual test performance,using the following equation:",
  "TRAINING PROCEDURE": "In this section, we propose a two-phase training procedure of Dou-bleAdapt including an offline training phase and an online trainingphase. Pseudo-codes are shown in Alg. 1 and Alg. 2.Given all historical data {(X( ), Y( ))}=1 before deployment,we organize these offline data into incremental learning tasksto imitate online incremental learning. The -th IL task consistsof the -th incremental data Dtrain = {(X( ), Y( ))}=(1)+1 and the -th test data Dtest = {(X( ), Y( ))}(+1)=+1. We take the first0 tasks as meta-train set Ttrain and others as meta-valid set Tvalid.It is noteworthy that we can shuffle Ttrain to simulate arbitrarydistribution shifts in pursuit of robustness against extreme non-stationarity. Offline training. We pretrain the two meta-learners on Ttrain taskby task for epochs. At the end of each epoch, we continue incremen-tal learning on Tvalid for evaluation (Alg. 1, L6). The updates of themeta-learners on the meta-valid set are conducted on a temporarycopy of the meta-learners (Alg. 1, L5), in order to avoid informationleakage. We perform early stopping when the evaluation metric onTvalid decreases for consecutive epochs, in order to avoid overfit-ting. The meta-learners get ready for online service after they havebeen incrementally updated on the whole validation set (Alg. 1, L9). Online training. We deploy DoubleAdapt online at date and in-crementally update the meta-learners at the end of each online task(Alg. 2, L9). As a special case, the meta-learners could keep the orig-inal adaptation ability of traditional MAML when the learning rates and are always set to zero during the online training phase.However, as the stock market is dynamically evolving, it is criticalto continually consolidate the meta-learners with new knowledge,",
  "return , , { Y( )}(+1)=+1": "which is also empirically confirmed by our experimental results inAppendix B.In case the meta-learners encounter the catastrophic forgettingproblem, we can also restart offline training after a much largerinterval. For example, we incrementally update the meta-learnersevery week and fully retrain them on an enlarged meta-train setafter one-year incremental learning. Integrating the advantages ofIL and RR, DoubleAdapt is expected to achieve better performance.In this work, we focus on improving IL performance against dis-tribution shifts and leave the combination of DoubleAdapt and RRas future work. According to our experiments on two real-worldstock datasets, DoubleAdapt alone can outperform RR methods fora long period (e.g., over 2.5 years) and hence it is unnecessary tofrequently perform full retraining. Complexity analysis. When optimizing the meta-learners (Alg. 2,L9), we adopt the first-order approximation version of MAML to avoid the expensive computation of Hessian matrices. Therefore,both the time and memory costs per IL task are linearly proportionalto the size of incremental data. Formally, let denote the numberof stocks in the market and denote the number of training epochsfor RR methods till convergence. For the -th online task, boththe incremental data and the test data have samples, while RRtakes ( + ) historical samples to train the model from scratch.Hence, the time complexity of DoubleAdapt and RR is () and(( + )), respectively. The scalability of DoubleAdapt allowsfrequent updates on the forecast model, e.g., on a weekly basis.",
  "Experimental Settings": "6.1.1Datasets. We evaluate our DoubleAdapt framework on twopopular real-world stock sets: CSI 300 and CSI 500 in the China A-share market. CSI 300 consists of the 300 largeststocks, reflecting the overall performance of the market. CSI 500comprises the largest remaining 500 stocks after excluding the CSI300 constituents, reflecting the small-mid cap stocks.We use the stock features of Alpha360 in the open-source quanti-tative investment platform Qlib . Alpha360 contains 6 indicatorson each day, which are opening price, closing price, highest price,lowest price, volume weighted average price (VWAP) and tradingvolume. For each stock at date , Alpha360 looks back 60 days toconstruct a 360-dimensional vector as the raw feature of this stock.We use the stock price trend defined in Definition 1 as the labelfor each stock. Following Qlib, we split stock data into training set(from 01/01/2008 to 12/31/2014), validation set (from 01/01/2015to 12/31/2016), and test set (from 01/01/2017 to 07/31/2020). Thefeatures are normalized by moments of the whole training set, andthe labels grouped by date are normalized by moments of data atthe same date .",
  "( Y( )) (Y( )),(22)": "where Y( ) are the raw stock price trends and Y( ) are the modelpredictions at each date. We report the average IC over all test dates.ICIR is calculated by dividing the average by the standard deviationof IC. Rank IC and Rank ICIR are calculated by ranks of labels andranks of predictions. Besides, we also use two portfolio metrics,including the excess annualized return (Return) and its informationratio (IR). IR is calculated by dividing the excess annualized returnby its standard deviation. Our backtest settings adhere to Qlibsdefault strategy.We ran each experiment 10 times and report the average results.For all six metrics, a higher value reflects better performance.",
  "GRU": "RR0.06290.51050.05810.48560.09331.14280.06690.65880.05860.62320.12001.8629DDG-DA0.06230.50450.05890.48980.09671.16060.06660.65750.05820.62340.12641.9963IL0.06330.48180.05960.46090.11661.31960.06370.60930.06170.62910.16262.3352MetaCoG0.05600.44430.05450.45030.09921.10140.06030.57410.05850.57200.15872.2635C-MAML0.06380.50850.05950.48650.11211.32100.06460.64980.06000.64940.16932.5064DoubleAdapt0.06870.54970.06210.51100.12961.51230.06860.66520.06320.64450.17482.4578 MetaCoG : This method introduces a per-parameter mask toselect task-specific parameters according to the context. MetaCoGupdates the masks rather than the model parameters to avoidcatastrophic forgetting. C-MAML : This method follows MAML to pretrain slowweights that can produce fast weights to accommodate new tasks.At the online time, C-MAML keeps fine-tuning the fast weightsuntil a distribution shift is detected, and then the slow weightsare updated and used to initialize new fast weights.",
  "Note that there are few studies on incremental learning for stocktrend forecasting. We borrow MetaCoG and C-MAML from thecontinual learning problem as IL-based baselines": "6.1.4Implementation Details. The time interval of two consecutivetasks is 20 trading days . The batch size of RR-based methodsapproximates the number of samples in incremental data, i.e., 5000for CSI 300 and 8000 for CSI 500. We apply Adam optimizer with aninitial learning rate of 0.001 for the forecast model of all baselines,0.001 for our model adapter, and 0.01 for our data adapter. Weperform early stopping when IC decreases for 8 consecutive epochs.The regularization strength of DoubleAdapt is 0.5. The headnumber is 8 and the temperature is 10. Other hyperparametersof the forecast model (e.g., dimension of hidden states) keep thesame for a fair comparison. We use the first-order approximationversion of MAML for all meta-learning methods.",
  "Performance Comparison (RQ1)": "We instantiate the forecast model by four deep neural networks,including Transformer , LSTM , ALSTM , and GRU . compares the overall performance of all baselines. ThoughRR methods are strong baselines and often beat simple IL methods,our proposed DoubleAdapt framework achieves the best results inalmost all the cases, demonstrating that DoubleAdapt can makemore precise predictions in stock trend forecasting. Exceptionally,C-MAML sometimes achieves higher ICIR or Rank ICIR than Dou-bleAdapt on CSI 500. During the online training phase, C-MAMLmodulates the learning rate of its meta-learner according to thetest error and thus achieves more stable performance on daily IC.Note that this update modulation is orthogonal to our work andcan also be integrated into DoubleAdapt. We also observe thatMetaCoG is nearly the worst method that even performs worsethan nave IL. MetaCoG focuses on catastrophic forgetting issuesand selectively masks the model parameters, instead of consoli-dating the parameters with new knowledge acquired online. Thisobservation confirms the significance of online updates for stocktrend forecasting. As for the implementation of the forecast model,DoubleAdapt can consistently achieve better performance with astronger backbone.",
  "ICICIRRankICRankICIRICICIRRankICRankICIRICICIRRankICRankICIR": "IL0.06330.48180.05960.46090.06430.49360.06520.51610.06900.51340.06190.4581+0.06590.52790.06150.49930.07080.59380.06920.58970.06900.52710.06200.4677+0.06580.51600.06100.49100.07030.57030.06800.56860.06810.50850.06180.4594++0.06780.53600.06190.49780.07400.61550.07090.60600.06940.52240.06260.4672+++ 10.06600.52070.06140.49950.07140.58460.07010.59580.06800.50930.06160.4615++ (=1)0.06840.54620.06220.50740.07440.62270.07030.60290.07100.54300.06340.4822+MA+DA (=8)0.06870.54970.06210.51100.07550.63900.07130.62430.06990.53230.06200.4730 as the performance varies in different degrees of distribution shifts,we also evaluate the online predictions under different kinds ofshifts. To this end, we pretrain the model on the training set andadopt nave IL throughout the tasks. In the -th task of the test set,we first use to do inference on Dtest without training on Dtrain,resulting in a mean square error L1 . Then we update on Dtrainand infer the same test samples, resulting in a new mean squareerror L2 . The distribution shift in this task can be measured byL = L2 L1 which can reflect whether benefits from theincremental update. When Ptest is similar to Ptrain, L2 should besmaller than L1 , and vice versa. With all online tasks sorted byL in an ascending order, we take the first 25% tasks as cases ofgradual shifts and the last 25% tasks as cases of abrupt shifts. shows the average results over the two kinds of dis-tribution shifts on CSI 300, i.e., gradual shifts and abrupt shifts.Applying both and into IL, DoubleAdapt achieves the bestresults against different kinds of distribution shifts. In the cases ofgradual shifts, the multi-head version with better expressivenesssignificantly outperforms the single-head one. Nevertheless, themulti-head version performs worse in the cases of abrupt shiftsbecause its high complexity is a double-edged sword and may in-cur overfitting issues. As gradual shift is the major issue in stockdata , the multi-head version still achieves the best overall per-formance. Also, it is noteworthy that our proposed data adaptationeffectively facilitates model adaptation, and data adaptation alonealso beats one-sided model adaptation. On the other hand, the im-provement of DoubleAdapt over +, especially under abruptshifts, indicates that the initial parameters of each task are alsocritical to generalization ability.Moreover, either the data adaptation or the model adaptationoutperforms the most competitive methods (i.e., DDG-DA and C-MAML) in . Specifically, IL+DA outperforms DDG-DA by5.6% improvement on IC, and IL+MA outperforms C-MAML by3.3% improvement on IC. In terms of model adaptation, C-MAMLproposes additional modules to deal with catastrophic forgetting ingeneral continual learning problems. However, future stock trendsare mainly affected by recent stock trends, and it is more beneficialto learn new patterns from recent data rather than memorize long-term historical patterns. Thus, our simple variant IL+MA achievesbetter performance than C-MAML.",
  "Time Cost Study (RQ3)": "compares the total time costs in offline training and onlinetraining of different methods. IL methods show superior efficiencycompared with RR methods in either offline training or onlinetraining. As we adopt the first-order approximation of MAML, weavoid the expensive computation of Hessian matrices. Thus themeta-learning methods are not much slower than nave IL, andthe excess time cost is small enough to omit. It is practical formodel selection, hyperparameter tuning, and retraining algorithmselection. Moreover, the low time cost of DoubleAdapt in offlinetraining paves the way for collaboration with RR, e.g., periodicallyretraining the meta-learners once a year.",
  "RELATED WORK7.1Stock Trend Forecasting": "Profitable quantitative investment usually depends on precise pre-dictions of stock price trends. In recent years, great efforts have been devoted to designing deep-learningapproaches to capture intricate finance patterns, while only a fewworks study online learning for stock data. MASSER , whichmainly focuses on stock movement prediction in the offline setting,introduces Bayesian Online Changepoint Detection in online ex-periments to detect distribution shifts and updates its meta-learnerafter a detection. Such delayed updates can easily lead to inferiorperformance in online inference. DDG-DA , an advanced RRmethod, copes with distribution shifts by predicting the futuredata distribution and resampling the training data for a similar dis-tribution. DDG-DA adapts the training data by assigning samplesgrouped by periods with different weights before a distribution shifthappens. By contrast, our data adaptation transforms the featuresand the label of each sample in a fine-grained way.",
  "Meta-Learning": "Meta-learning aims to fast adapt to new tasks only with a fewtraining samples, dubbed support set, and generalize well on testsamples, dubbed query set. MAML is the most widely adopted tolearn how to fine-tune for good performance on query sets. Someworks extend MAML to online settings on the assumptionthat the support set and the corresponding query set come fromthe same context, i.e., following the same distribution. As such,the meta-learner will quickly remember task-specific informationand perform well on a similar query set. However, this assumptioncannot hold when discrepancies between the two sets are non-negligible. LLF studies MAML in an offline setting, proving thata predictor optimized by MAML can generalize well against conceptdrifts. However, the query sets are unlabeled in online settings, andone can only retrain the meta-learner after detecting a shift .Consequently, the predictions are still susceptible to distributionshifts. Some methods combine incremental learning andmeta-learning for recommender systems and dynamic graphs butignore distribution shifts. SML focuses on model adaptationand proposes a transfer network to convert model parameters onincremental data, which is orthogonal to our work.",
  "CONCLUSION": "In this work, we propose DoubleAdapt, a meta-learning approach toincremental learning for stock trend forecasting. We give two keyinsights to handle distribution shifts. First, we learn to adapt datainto a locally stationary distribution in a fine-grained way. Second,we learn to assign the forecast model with initial parameters whichcan fast adapt to incremental data and still generalize well againstdistribution shifts. Experiments on real-world datasets demonstratethat DoubleAdapt is generic and efficient, achieving state-of-the-artpredictive performance in stock trend forecasting.In the future, we will try to combine our incremental learningalgorithm and rolling retraining to avoid catastrophic forgettingissues after a long-period online incremental learning. We alsobelieve the idea of the two-fold adaptation can inspire other ap-plications that encounter the challenge of complex distributionshifts. This work is supported by the National Key Research and Devel-opment Program of China (2022YFE0200500), Shanghai MunicipalScience and Technology Major Project (2021SHZDZX0102), andSJTU Global Strategic Partnership Fund (2021 SJTU-HKUST). John Bronskill, Jonathan Gordon, James Requeima, Sebastian Nowozin, andRichard Turner. 2020. TaskNorm: Rethinking Batch Normalization for Meta-learning. In International Conference on Machine Learning. PMLR, 11531164. Massimo Caccia, Pau Rodrguez, Oleksiy Ostapenko, Fabrice Normandin,Min Lin, Lucas Page-Caccia, Issam Hadj Laradji, Irina Rish, Alexandre La-coste, David Vzquez, and Laurent Charlin. 2020.Online Fast Adapta-tion and Knowledge Accumulation (OSAKA): a New Approach to Contin-ual Learning. In NeurIPS.",
  "Yingjun Du, Xiantong Zhen, Ling Shao, and Cees G. M. Snoek. 2021. MetaNorm:Learning to Normalize Few-Shot Batches Across Domains. In International Confer-ence on Learning Representations": "Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. In Proceedings of the 34th Inter-national Conference on Machine Learning - Volume 70 (Sydney, NSW, Australia)(ICML17). JMLR.org, 11261135. Chelsea Finn, Aravind Rajeswaran, Sham Kakade, and Sergey Levine. 2019. OnlineMeta-Learning. In Proceedings of the 36th International Conference on MachineLearning (Proceedings of Machine Learning Research, Vol. 97), Kamalika Chaudhuriand Ruslan Salakhutdinov (Eds.). PMLR, 19201930.",
  "Sepp Hochreiter and Jrgen Schmidhuber. 1997. Long Short-Term Memory.Neural Computation 9, 8 (nov 1997), 17351780": "Min Hou, Chang Xu, Yang Liu, Weiqing Liu, Jiang Bian, Le Wu, Zhi Li, EnhongChen, and Tie-Yan Liu. 2021. Stock Trend Prediction with Multi-granularity Data:A Contrastive Learning Approach with Adaptive Fusion. In Proceedings of the30th ACM International Conference on Information & Knowledge Management.ACM. Ziniu Hu, Weiqing Liu, Jiang Bian, Xuanzhe Liu, and Tie-Yan Liu. 2018. Listeningto Chaotic Whispers: A Deep Learning Framework for News-oriented StockTrend Prediction. In Proceedings of the Eleventh ACM International Conference onWeb Search and Data Mining. ACM. Ivan Kobyzev, Simon J.D. Prince, and Marcus A. Brubaker. 2021. NormalizingFlows: An Introduction and Review of Current Methods. IEEE Transactions onPattern Analysis and Machine Intelligence 43, 11 (nov 2021), 39643979.",
  "Hao Li, Yanyan Shen, and Yanmin Zhu. 2018. Stock Price Prediction UsingAttention-based Multi-Input LSTM. In Asian Conference on Machine Learning": "Wendi Li, Xiao Yang, Weiqing Liu, Yingce Xia, and Jiang Bian. 2022. DDG-DA: Data Distribution Generation for Predictable Concept Drift Adaptation.Proceedings of the AAAI Conference on Artificial Intelligence 36, 4 (jun 2022),40924100. Zhige Li, Derek Yang, Li Zhao, Jiang Bian, Tao Qin, and Tie-Yan Liu. 2019. Individ-ualized Indicator for All: Stock-wise Technical Indicator Optimization with StockEmbedding. In Proceedings of the 25th ACM SIGKDD International Conferenceon Knowledge Discovery & Data Mining. ACM. Hengxu Lin, Dong Zhou, Weiqing Liu, and Jiang Bian. 2021. Learning MultipleStock Trading Patterns with Temporal Routing Adaptor and Optimal Transport.In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &Data Mining. ACM. Nicolas Y. Masse, Gregory D. Grant, and David J. Freedman. 2018.Alle-viating catastrophic forgetting using context-dependent gating and synap-tic stabilization.Proceedings of the National Academy of Sciences115, 44 (2018), E10467E10475.",
  "Xiao Yang, Weiqing Liu, Dong Zhou, Jiang Bian, and Tie-Yan Liu. 2020. Qlib: AnAI-oriented Quantitative Investment Platform. ArXiv abs/2009.11189 (2020)": "Jaemin Yoo, Yejun Soun, Yong chan Park, and U Kang. 2021. Accurate MultivariateStock Movement Prediction via Data-Axis Transformer with Multi-Level Con-texts. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery& Data Mining. ACM. Jiaxuan You, Tianyu Du, and Jure Leskovec. 2022. ROLAND: Graph LearningFramework for Dynamic Graphs. In Proceedings of the 28th ACM SIGKDD Con-ference on Knowledge Discovery and Data Mining (Washington DC, USA) (KDD22). Association for Computing Machinery, New York, NY, USA, 23582366. Xiaoyu You, Mi Zhang, Daizong Ding, Fuli Feng, and Yuanmin Huang. 2021.Learning to Learn the Future: Modeling Concept Drift in Time Series Predic-tion. In Proceedings of the 30th ACM International Conference on Information &Knowledge Management. ACM. Donglin Zhan, Yusheng Dai, Yiwei Dong, Jinghai He, Zhenyi Wang, and JamesAnderson. 2022. Meta-Adaptive Stock Movement Prediction with Two-Stage Rep-resentation Learning. In NeurIPS 2022 Workshop on Distribution Shifts: ConnectingMethods and Applications. Liheng Zhang, Charu Aggarwal, and Guo-Jun Qi. 2017. Stock Price Predictionvia Discovering Multi-Frequency Trading Patterns. In Proceedings of the 23rdACM SIGKDD International Conference on Knowledge Discovery and Data Mining.ACM. Yang Zhang, Fuli Feng, Chenxu Wang, Xiangnan He, Meng Wang, Yan Li, andYongdong Zhang. 2020. How to Retrain Recommender System?. In Proceedingsof the 43rd International ACM SIGIR Conference on Research and Development inInformation Retrieval. ACM.",
  "AIMPLEMENTATION DETAILS": "In practice, we employ shared transformation parameters for alltime steps of the features when the stock data are taken as timeseries. Formally, let x = {1,2, ,} represent the stock feature,where is the length of time series. Each element R is thefeature at step , where is the number of indicators at each timestep. The parameters of the -th transformation head is W R and b R. At each time step , we first calculate the cosinesimilarity between each pair of and p, where p R. Then,we perform softmax operation over the heads to obtain theconfidence score . As such, features of x at all time steps are fedinto the shared feature adaptation layer with different scores. It ispractical to avoid gradient vanishing issues in RNNs. Otherwise,the gradients of more previous steps are too small to train unsharedadaptation parameters.As for the label adaptation layer, we first employ a linear trans-formation matrix to cast x R into a low-dimensional vector v.The confidence score for head selection is calculated by the cosinesimilarity between v and p, where p is a specific prototype forlabel adaptation and has the same dimension with v.",
  "BHYPERPARAMETER STUDY": "In this section, we evaluate the performance of DoubleAdapt ondifferent values of hyperparameters. We only provide the results onCSI 300 with the forecast model implemented by GRU. The resultson CSI 300 are similar. Task interval . a shows that more frequent incrementallearning with a smaller interval (e.g., 5 trading days) can lead tobetter performance. This is because up-to-date patterns are moreinformative to future trends than previous ones, and it is beneficialto consolidate the forecast model and the meta-learners with newknowledge more timely. It is noteworthy that RR methods with asmaller will suffer from much more expensive time consumption.In contrast, DoubleAdapt shows superiority in its scalability and isapplicable to a small .",
  "Softmax temperature . As shown in b, DoubleAdaptachieves the worst performance when we set the softmax tem-perature to 0.5. We reason that the logits from softmax with a": "small temperature approximate a one-hot vector, i.e., one sample istransformed by merely one head. Thereby, the adaptation layersare trained by fewer samples and can suffer from underfitting is-sues. Fortunately, it is always safe to set the temperature with agreat value and even towards infinity, since a single-head versionof DoubleAdapt still achieves outstanding performance in . Number of transformation heads . As shown in c,almost all the multi-head versions of DoubleAdapt outperformthe single-head one. Exceptionally, the two-head version showslower average IC but achieves the highest ceiling value. With acarefully selected temperature (e.g., 1.0), the multi-head version canoutperform the single-head one by a larger margin. Note that ourincremental learning framework is efficient, and the time cost forhyperparameter tuning is durable. Besides, it is not recommendedto use too many heads which can result in more time cost and mayalso cause overfitting issues. Regularization strength. shows that DoubleAdapt with-out regularization achieves inferior performance, which verifiesour proposed regularization technique. Nevertheless, the IC per-formance gradually decreases with a larger regularization strengthwhich hinders the proposed label adaptation. Thus, it is desirableto set moderate regularization to train DoubleAdapt smoothly. Gen-erally, DoubleAdapt is relatively not sensitive to the regularizationstrength . Online learning rates and . As shown in b, weevaluate the performance on different learning rates of the twometa-learners during the online training phase, while we use thesame pretrained meta-learners before online deployment. Whenwe freeze the meta-learners online with both and set tozero, DoubleAdapt achieves the worst results. This confirms thatit is critical to continually consolidate the meta-learners with newknowledge acquired online. Nevertheless, DoubleAdapt still keepsthe best performance when we freeze the data adapter with a zero but fine-tune the model adapter with an appropriate (0.0005or 0.001). We conjecture that the pretrained data adapter has learnedhigh-level patterns of distribution shifts, which are shared by themajority of the meta-test set. By contrast, the forecast model shouldaccommodate the up-to-date trends of the stock markets whichmay not exist in the historical data. This requires the model adapter",
  "CAPPROXIMATION OF META-GRADIENTS": "Considering efficiency, we apply first-order approximation in theupper-level optimization of the meta-learners, avoiding the expen-sive computation of high-order gradients.To simplify notations, we omit the superscript of the parametersin the following derivations, i.e., for, for1, and for1.We further distinguish the parameters of the feature adaptationlayer and the label adaptation layer as and , respectively. Wealso use to represent .",
  "C.2Gradients of Data Adapter": "As shown in , the adaptation on features and predictions inthe test data involves first-order gradients which directly optimize and . Inspired by , we can also estimate the second-ordergradient of introduced by Ltrain. As we now focus on the second-order gradient, we leave out the first-order one in Ltest() inthe following derivations.First, we refomulate the task-specific parameter (i.e., ) by",
  ",(35)": "where we set as a hyperparameter. Thus the coefficient of gra-dients by Lreg is similar to which controls the regularizationstrength when Ltest() Ltest(). If otherwise, the updated pa-rameters result in a greater loss, meaning that the incremental datais noisy and perhaps we should make the adapted labels moredifferent from the original ."
}