{
  "ABSTRACT": "Cognitive Diagnosis (CD), which leverages students and exercisedata to predict students proficiency levels on different knowledgeconcepts, is one of fundamental components in Intelligent Educa-tion. Due to the scarcity of student-exercise interaction data, mostexisting methods focus on making the best use of available data,such as exercise content and student information (e.g., educationalcontext). Despite the great progress, the abuse of student sensitiveinformation has not been paid enough attention. Due to the impor-tant position of CD in Intelligent Education, employing sensitiveinformation when making diagnosis predictions will cause seri-ous social issues. Moreover, data-driven neural networks are easilymisled by the shortcut between input data and output prediction,exacerbating this problem. Therefore, it is crucial to eliminate thenegative impact of sensitive information in CD models. In response,we argue that sensitive attributes of students can also provide usefulinformation, and only the shortcuts directly related to the sensitiveinformation should be eliminated from the diagnosis process. Thus,we employ causal reasoning and design a novel Path-Specific CausalReasoning Framework (PSCRF) to achieve this goal. Specifically, we",
  "Corresponding authors": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain. 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 978-1-4503-XXXX-X/18/06...$15.00 first leverage an encoder to extract features and generate embed-dings for general information and sensitive information of students.Then, we design a novel attribute-oriented predictor to decouplethe sensitive attributes, in which fairness-related sensitive featureswill be eliminated and other useful information will be retained.Finally, we designed a multi-factor constraint to ensure the per-formance of fairness and diagnosis performance simultaneously.Extensive experiments over real-world datasets (e.g., PISA dataset)demonstrate the effectiveness of our proposed PSCRF.",
  "Data statistics0.47360.54480.64340.55160.3888NCD0.51400.58610.67890.59130.3293KaNCD0.47780.55890.66430.56500.3025NCD-PSCRF0.55450.57980.61550.58240.3321KaNCD-PSCRF0.52860.55810.62710.56800.3026": "Literately, researchers have designed enormous neural network-based methods to realize accurate diagnosis and student modeling.As illustrated in , existing models usually take multi-typeinformation (e.g., student-exercise interaction logs, students per-sonal information, exercise text) as the input, and predict studentsmastery of each concept. For example, Wang et al. have built adeep full connection neural network to capture the complex student-exercise interaction records. Wang et al. designed a novelKaNCD method to address the weak knowledge concepts cover-age problem. Besides, there are many other methods for high-orderstudent-exercise interaction modeling and graph-basedmodeling .Despite the great progress, these methods will inevitably intro-duce fairness issues while exploiting the full potential of studentdata. Taking as an example, by conducting statistical analy-sis, we can observe that students who are from more affluent fami-lies or in more developed areas usually have better performance onexercise (e.g., 0.6434 points for rich boys v.s. 0.4736 points for poorboys). In fact, this phenomenon occurs more because those stu-dents receive better support or training (e.g., more books, computeraccess opportunities, etc), rather than better family circumstances.However, if we do not constrain the model to exploit all the data,it will easily learn the connections between sensitive informationof students and student performance (e.g., using family wealth topredict the student proficiency level), which we name as spuriouscorrelations. From the results in , we can observe this typeof phenomenon. By using PISA data to train NCD and KaNCDmodels directly, they will overestimate these advantaged students(e.g., 0.565 for Australia v.s. 0.3025 for Brazil), showing that theyhave taken advantage of sensitive information and made unfairpredictions. If we apply the unfair results to real-world scenarios, itwill exacerbate social prejudices and conflicts, bringing about badsocial effects. More seriously, according to the results in ,even if we do not use sensitive attributes as model inputs, NCDand KaNCD models still can infer sensitive attributes of studentsfrom the interaction logs and abuse them for better performance.Therefore, it is crucial to exclude the abuse of student sensitiveattributes while ensuring the diagnosis performance. Recently, plenty of fairness-aware methods have been proposed,such as data reweighting (resampling) and adversarial learn-ing . However, these strategies still have unavoidableshortcomings. For example, data resampling methods usually in-crease/decrease weights of certain student-exercise interactionsto realize the fairness target. However, this strategy violates theprinciple in cognitive diagnosis that the same student should onlyrespond to the same exercise once, and is also dependent on thesensitive attributes . Meanwhile, adversarial learning uses anadditional classifier to predict the sensitive attribute from user em-beddings and eliminate corresponding information directly. Thisstrategy is too coarse-grained to distinguish available informationfrom sensitive information, leading to a decrease in model capability.To answer the above question, we propose that the fairness-relatedsensitive features from sensitive attributes should be eliminatedas comprehensively as possible while diagnosis-related featuresfrom sensitive attributes should be retained as much as possible.For example, family wealth cannot be used as an influencing factorin determining the student proficiency level, while the quality ofthe learning environment can. For this goal, causal inference isone promising direction. By distinguishing causation and correla-tions from biased real-world data, causal inference has made greatprogress in medicine , neuroscience , cognitive science ,etc. It also has been proven useful in addressing bias issues in vi-sion question answering , text classification tasks , anomalydetection , and so on.To this end, in this paper, we propose to employ causal infer-ence and design a novel Path-Specific Causal Reasoning Frame-work (PSCRF) for fairness-aware CD modeling. Specifically, weleverage a causal graph to describe the correlations and causationbetween different factors and student proficiency levels. Based onthe causal graph, we try to use PSCRF to calculate the path-specificeffect of different inputs to the output. We first leverage an encoderto extract features from student-exercise interaction logs and gen-erate embeddings for student IDs and sensitive attributes. Next,we design a novel attribute-oriented predictor (Decoupled Predic-tor (DP)) to realize the decoupling of sensitive attributes and usefulinformation, in which fairness-related sensitive feature embeddingsare used to predict the sensitive attributes and diagnosis-relatedfeature embeddings are used to predict the useful information fromsensitive attributes. Moreover, to ensure the quality of decoupling,we also design a multi-factor fairness constraint to restrict thedistance of different embeddings. Then, the fairness-aware infer-ence can be obtained by removing the fairness-related sensitivefeatures from the diagnosis process. Finally, we conducted extensiveexperiments over real-world diagnosis data in various settings. Ex-perimental results demonstrate that PSCRF can achieve impressivedebiased performance while maintaining the accuracy of studentproficiency level modeling. We also release the code to facilitatethe community1.In summary, our main contributions are reported as follows:",
  "Cognitive Diagnosis": "Cognitive Diagnosis (CD) is a fundamental and pivotal task in manyreal-world intelligent education scenarios . It requires anagent to predict students proficiency level of each knowledge con-cept through historical student-exercise interaction logs. DINA and IRT are two representative methods in this domain. DINAis a discrete CDM that assumes student mastery levels are binary(master the knowledge concept or not) . IRT characterizes stu-dents abilities as unidimensional and continuous latent traits anddesigns logistic-like interaction functions to model the probabilityof a student correctly answering an exercise .To improve the diagnosis performance, various methods havebeen proposed to extend the capability of DINA and IRT and exploit the potential of student and exercise data. For exam-ple, Cheng and Liu proposed a DIRT method to extract semanticfeatures from the content of exercise texts for high-quality repre-sentation generation. Wang et al. designed an NCD methodto exploit student-exercise interactions for accurate student pro-ficiency level modeling. Moreover, Zhou et al. proposed toimprove CD performance from the student perspective. They em-ployed context and culture information of students to enrich thestudent proficiency representation, which is in favor of improvingthe diagnosis performance. Besides, other data issues in CD arealso considered, such as weak knowledge concepts coverage prob-lems and non-interactive knowledge concepts problems .",
  "Fairness-aware User Modeling": "User modeling focuses on measuring user characteristics based onuser-related data, which plays a crucial role in plenty of scenarios,such as user preference modeling in recommender system anduser proficiency level modeling in Intelligent Education . Re-cent studies have demonstrated that user-related data may containstereotypes or biased data, which will mislead models to learn thespurious correlations and make vulnerable and unfair decisions.To alleviate this problem, plenty of fairness-aware user modelingmethods have been proposed, such as data reweighting ,regularization , and adversarial learning . Amongall these methods, causal inference-based methods are one promis-ing direction. For example, Zhao et al. proposed a disentangled framework TIDE based on path-specific causal reasoning to dealwith the popularity bias in user preference modeling in recommen-dations. Chen et al. designed a novel data augmentation strategyto balance the training data, so that sensitive-related informationwill be inactivated when modeling user preference. Apart from this,other types of biases are also hot research topics, such as selectionbias , exposure bias , and unfairness .However, due to the sparsity characteristic of student and exer-cise data in education, existing methods mainly focus on exploitingthe potential of data, ignoring the implicit sensitive informationabuse problem. Since education plays a crucial role in influenc-ing the trajectory of individuals adult lives , it is urgent tofocus more on this problem. Some works have made early attempts.For example, Yu et al. conducted an analysis to explore theequitable prediction of short-term and long-term college successusing various sources of student data. Li et al. proposed a Fair-LR algorithm to achieve accurate and fair AI prediction to helpto realize fair student modeling. Zhang et al. divided studentperformance into bias proficiency and fair proficiency, then usedonly fair proficiency to make predictions. For fairness-aware CDmodeling, enormous works remain unexplored, such as fair studentrepresentations, sensitive attribute utilization, and so on.Our Distinction. We focus on a more impactful issue: How toeliminate the abuse of student sensitive attributes from CD modelswhile ensuring the diagnosis performance? We argue that studentsensitive attributes can also provide useful information, so directlyremoving them from CD models is not optimal. Thus, we design anovel PSCRF to realize the debiased CD learning while retaining thediagnosis performance. Specifically, PSCRF decouples student sen-sitive attributes into sensitive-related information that should notbe used in diagnosis process, and sensitive-unrelated informationthat can be used to improve the diagnosis performance. Moreover,PSCRF leverages a multi-factor normalization to ensure the qualityof debiased learning and diagnosis performance simultaneously.",
  "KDD 24, August 2529, 2024, Barcelona, Spain.Dacao Zhang, Kun Zhang, Le Wu, Mi Tian, Richang Hong, Meng Wang": "This section explains the causal graph and causal effect calcula-tion mentioned, aiming to help readers understand the significanceand importance of the causal graph.Causal Graph. The causal graph is a Directed Acyclic Graph(DAG) G =< V, E >, which describes the causal relationshipsbetween different variables. V is the node set and E is the edge set.As illustrated in (A), the arrow indicates the direction ofcausality. For example, denotes that variable has a directeffect on . denotes that variable has indirecteffect on through mediator . Following these notations, assume = , then the value of can be calculated as follows:",
  "Total EffectDirect Effect(A)(B)": ": The causal graph used in our proposed PSCRF.Causal Effect Calculation. The causal effect is a comparisonof the potential outcomes of giving two different interventions tothe same variable. As shown in (A)-(B), assume that = is the treatment, then , denotes the potential outcome of thetreatment. Similarly, = is the no treatment, then , is thepotential outcome of no treatment. Along this line, the causal effectcan be calculated as follows:",
  "= , , = (|do( = )) (|do( = )), (2)": "where do( = ) and do( = ) is the intervention to the variable. Note that do() operation requires that only the treatment vari-able is intervened, all other variables are not intervened. To satisfythis requirement, the counterfactual operation is proposed.Counterfactual Notation. The counterfactual reason is toassume a scenario that all the other variables remain unchangedand only the treatment variable is changed. The causal effect ofthe treatment variable on the output variable can be calculated inthis scenario. For example, in (C), , = ( = , =( = )) denotes a typical counterfactual reasoning.",
  "PISA Data Introduction": "As mentioned above, the educational context of students can beused to obtain better student representations, which refer to thevarious features related to students learning process . OECDsProgramme for International Student Assessment (PISA) focused onthis topic and designed multiple questions to investigate and collectthese educational contexts, such as family wealth, education degreeof parents, and so on. For example, when investigating the highesteducation degree of students parents, five options (e.g., 1-Generalsenior, 2-Vocational senior, 3-Junior) are provided. Students canselect one option based on their situations. This information canbe used as student attributes. lists some examples of thesequestions. Moreover, this organization has developed exercises to measure 15-year-olds ability to employ reading, mathematics, andscience knowledge and skills to meet real-life challenges . Theyinvestigated students from different countries, and released the dataand technical reports on a three-year cycle, which is suitable forstudent attribute-aware cognitive diagnosis.: Educational Context examples from PISA dataset",
  "Whether students have a grade repetition experiencehow many days did students engage in out-school activities": "With the guidance of technical report , we select ESCS indexas the sensitive attribute example to tackle the problem in .Moreover, we leverage the Pearson Correlation Coefficient to selectthe useful but not sensitive attributes: 1) The number of books, 2) Thenumber of tablet computers, 3) A link to the Internet, 4) A computercan be used for school work, 5) The number of E-book readers. Theseselected attributes all exhibit strong correlations with ESCS index,which we have reported the results in and in theAppendix. However, they are not sensitive attributes and directlycontribute to the development of students abilities, which shouldbe considered in the diagnosis process.: Notations and explanations in our proposed PSCRF.",
  "TECHNICAL DETAILS OF PSCRF4.1Causal view of PSCRF": "Based on the motivation in , we use the causal graph in(A) to describe the causal relation among different paths.Specifically, denotes the general representation of one student(i.e., ID embeddings). is the corresponding sensitive attributerepresentation (e.g., ESCS embeddings). We argue that sensitiveattributes contain fairness-related sensitive features and diagnosis-related features. The former should not be used in the diagnosisprocess while the latter should be used to improve the diagnosisperformance. Therefore, we leverage the causal path to denote the effect of fairness-related sensitive features, whichshould be removed from the entire graph. A toy example is thatfamily wealth should not be considered in the diagnosis processsince it will introduce unfairness to vulnerable groups.Meanwhile, we use the causal path (, ) to denotethe effect of diagnosis-related features from sensitive attributes andgeneral information. one similar example is as follows: though fam-ily wealth cannot be used in the diagnosis process, we can exploitthe number of books or a link to the Internet to better model student",
  "Causal Implementation: PSCRF": "illustrates the overall architecture of PSCRF, which consistsof two main components: Representation Learning Module and De-coupled and Constraint Module. Next, we introduce each componentin detail. explains the notations in PSCRF. 4.2.1Representation Learning Module. Similar to previous works , we first embed input entities into latent embeddings, whichincluding student embeddings = [1, 2, ..., ] R , ex-ercise embeddings = [1, 2, ..., ] R, and sensitiveattribute embeddings = [1, 2, ..., ] R . is the embed-ding dimension. These embeddings are randomly initialized andwill be updated during model learning.After obtaining the embeddings of different entities, we intendto learn the representations of fairness-related sensitive features and diagnosis-related features , which is realized by our de-signed proficiency modeling module. Specifically, we employ afairness-related sensitive feature generator to obtain , which",
  "= ((1 ) + ).(8)": "4.2.2Decoupled and Constraint Module. In the above module, weaim to extract fairness-related sensitive features and diagnosis-related features from input data. However, there are no explicitsupervised signals. which poses a big challenge. In response, wedesign the following three modules. Next, we omit the student index for simplicity and introduce how we construct each module.(1) Decoupled Predictor (DP). First, we intend diagnosis-related feature embedding should include useful informationfrom sensitive attributes and maintain general information of stu-dents. Therefore, we leverage the educational context as the guid-ance, and identify top-k educational context questions most corre-lated with the sensitive attribute by computing the Pearson corre-lation coefficient between them. These educational contexts oftenrelate to students learning environments and do not involve sen-sitive attributes (e.g., the number of books), which can be used toenhance the student proficiency level modeling. Thus, we leverage",
  "=1CE(MLP( ), ),(9)": "Where represents the total number of non-sensitive attributes, represents the label of the th non-sensitive attribute, andCE denotes the cross-entropy function.Meanwhile, to ensure to focus only on the fairness-related sen-sitive features, we develop a novel sensitive attribute enhancementmodule. We first send to an MLP to predict sensitive attributes,so that can be better learned to represent sensitive attributes.Meanwhile, should not contain these sensitive attributes. Thus,we send to the same MLP to predict the counterfactual sensitiveattributes. Therefore, can only encode fairness-related sensitivefeatures that should not be used in the diagnosis process. will notinclude these sensitive features, which is in favor of fairness-awarediagnosis. This process can be formulated as follows:",
  "Lrev = L(SMLP(),) + L(SMLP( ),),(10)": "where L represents the loss function, which can be mean squarederror (MSE) for continuous values or cross-entropy for discretevalues. SMLP() denotes the shared MLP. represents the coun-terfactual sensitive attribute label, which we will give a detailedexplanation in the next section.(2) Path-specific Causal Reasoning. According to and .1, we need to remove the path to realizethe fairness-aware diagnosis. Following the principle of AverageTreatment Effect (ATE), we need to imagine a counterfactual world,which is shown in (B). In the counterfactual world, only thepath remains unchanged. We need to block the effectof the path (, ) . Thus, we use the counterfactualsensitive attributes to modify Eq.(7) and Eq.(8) as follows:",
  "= ((1 ) + ),(11)": "where {, } are the counterfactual student representation andcounterfactual fairness-related sensitive feature representation. Forimplementation, we use the mean representation of all studentrepresentations to realize , and use the mean representation ofcorresponding sensitive attributes to calculate . According tothe causal inference, this intervention can help PSCRF to calculatethe accurate effect of path . Then, we can obtainfairness-aware student proficiency level as follows:",
  "= ( ),(12)": "where is a learnable parameter to control the degree of debiasing. is used to realize the fairness-aware CD modeling.(3) Multi-factor Fairness Constraint. To facilitate better fairness-aware diagnosis, we introduce a Multi-factor Fairness Constraint.Specifically, we partition students into disadvantaged, general, andadvantaged groups based on the value of sensitive attributes. Since is the fairness-aware student proficiency level representation,we intend the variance of the predicted means for different groupsto be as low as possible. Meanwhile, since should incorporateunwanted sensitive information as much as possible, we maximize",
  "EXPERIMENTS5.1Experimental Setup": "Data preprocessing. We procured two prototypical datasets fromthe PISA-2015, representing Australia and Brazil, respectively, metic-ulously arranged in descending order based on their developmentalstatus and the mean scholastic attainment of students. In eachdataset, there are 28 different self-acquired features , such aslearning interests and self-efficacy. We used two representativesensitive attributes, namely ESCS (Index of Economic, Social, andCultural Status) and the fathers education level to evaluateour method. Specifically, based on the data provided by PISA ,we categorized students into three groups - disadvantaged, gen-eral, and advantaged - according to their sensitive attributes, forfairness-aware diagnosis. We filtered out students with fewer than10 exercise records to ensure sufficient data for training. The Basicstatistics of datasets are shown in . For each dataset, weperformed a 70%/10%/20% training/validation/testing split.",
  "Australia8,485184249,727Brazil5,777183143,314": "Evaluation Metrics. Based on the target, we select two types ofmetrics. For diagnosis performance, following previous works , we used widely used metrics: Area Under Curve (AUC) andAccuracy (ACC). Meanwhile, following the work , we also usethe Degree of Agreement (DOA) for validation.For fairness performance, since the abuse of sensitive attributeswill mislead models to underestimate or overestimate the students",
  "= Std(,,, ),(17)": "refers to True Positive Rates. Std() is the standard deviation.Since there are only two situations (i.e., correct and incorrect) forstudents answering questions, CD models should have equal capa-bility of predicting the probability of students answering exercisescorrectly across different groups. Along this line, sensitive attributescan be proved to be not used in the diagnosis process. Moreover,since predictions of CD models have a big social influence in real-world scenarios, we argue that the rights of vulnerable groupsshould be guaranteed. We should not be prejudiced against disad-vantaged groups and assume that they will perform less well. Basedon the principle of Equalized Odds , we propose the followingevaluation metric to evaluate the fairness performance of models:",
  "= ,(18)": "where {, } denote the False Negative Rates (FNRs)of disadvantaged and advantaged groups. The closer the value of is to 0, the better fairness performance the model is.Meanwhile, for disadvantaged groups, we should also identifythe top students as accurately as possible, so that they have op-portunities to access higher levels of education. Thus, we selectthe absolute metric F2-score to assess the proportion of high-achieving students of disadvantaged groups, which we name as",
  "(4 ) + .(19)": "where and denote the Precision andRecall of disadvantaged group. Note that the larger the value of is, the better performance the model has.Implementation Details. As our proposed method is model-agnostic, we apply PSCRF to four advanced CDMs to show itseffectiveness and flexibility. Moreover, we compare with severalrecent approaches, including regularization-based methods andadversarial-based methods: 1) Base: Basic cognitive diagnosis mod-els (i.e., IRT, MIRT, NCD, and KaNCD) that do not consider bias; 2): Basic Models with Sensitive Attributes; 3) Reg: Regularization-based models, by adding Equal opportunity as a regularization toCDMs ; 4) Adv: Adversarial learning methods to reducerelevance between sensitive attributes and student representationFor implementation, we set the learning rate to 0.001 and batchsize to 512. We apply Adam as the optimization algorithm to updatethe model parameters. To obtain the best performance, we tunehyper-parameters on validation sets to select the best. The balanceparameters in Eq.(16) are set to 1.0, 0.1, 0.5, and 1.0, respectively.",
  "Base0.03700.08870.71460.80170.72730.65840.04330.10580.51890.77930.72210.6046Base0.0510.12070.69380.80840.73100.71830.05550.13020.54340.78620.72560.6731": "Reg0.02510.05780.73640.80100.72740.66420.02880.06990.58260.77990.72420.6347Adv0.04050.09720.71440.80060.72780.66180.04190.10200.56090.78020.72390.6352PSCRF0.01140.02750.77680.80660.72690.70970.03400.07460.51300.79300.72780.6847 also exhibits more severe unfairness. All these suggest the urgencyto explore fairness-aware learning in CD models. Therefore, weevaluate the model performance from the following three aspects:For fairness performance (i.e., EO and underdisadv), we observe thatPSCRF outperforms most baselines, proving its effectiveness. More-over, Adversarial-based methods (Adv) show worse performancethan regularization-based (Reg) methods in most cases. One possi-ble reason is that the latter directly utilizes sensitive attribute grouplabels to optimize corresponding metrics. In contrast, PSCRF de-couples sensitive attributes and only eliminates the fairness-relatedsensitive features that should not be used in diagnosis process.For the trade-off between fairness and diagnosis performance, alldebiased baselines perform worse on diagnosis performance thanPSCRF, proving that they cannot retain diagnosis-related featuresfrom sensitive attributes, which causes a larger decrease in diag-nosis accuracy. PSCRF uses the newly designed DP module andmulti-factor constraint to retain diagnosis-related features as muchas possible, thus outperforming baselines.For the Identification capability (i.e., IR) of high-achieving stu-dents from disadvantaged groups, PSCRF still achieves impressiveperformance, which proves that PSCRF can effectively ensure therights of vulnerable groups. Moreover, by considering the resultson underdisadv metric, we can conclude that for different CD backbones,PSCRF can effectively balance fairness and diagnosis performance,demonstrating the flexibility and effectiveness of PSCRF.",
  "Ablation Study": "To verify the effectiveness of each component, we conduct an ab-lation study with ESCS and report results in . From theresults, when only using Lce, and cannot decouple sensitiveattributes effectively. Instead, they would introduce more bias, re-sulting in better diagnosis and worse fairness performances. Whenseparately introducing Lcls and Lrev, we observe improvements infairness performance with minimal impact on accuracy, provingthe effectiveness of learned and . When using only Lcons,PSCRF can learn how to remove fairness-aware sensitive features,achieving a substantial improvement in fairness. However, since still contains some factors affecting fairness, this component canonly generate a suboptimal outcome. Moreover, when removingeach component, we observe varying degrees of performance degra-dation. Among all components, removing Lcons causes the mostsignificant decrease in fairness performance and increase in diagno-sis performance. This phenomenon not only proves the importanceof multi-factor fairness constraint, but also shows PSCRF will abusesensitive attributes to improve diagnosis performance. Moreover,Lcons denotes the removal of constraints on for direct com-parison with regularization methods. The result proves that theabsence of constraints on severely impacts fairness performance,aligning its performance comparably with regularization methods.Furthermore, we observe that Lcls and Lrev have a positive im-pact on fairness performance, removing them will cause a decreasein fairness performance. In conclusion, these components are allnecessary for the superiority of PSCRF.",
  "Parameter Sensitive Test": "To conduct a deeper analysis on PSCRF, we also conduct parametersensitive test on the weights 1, 2, 3, 4 in Eq.(16), whose re-sults are summarized in . According to the results, we canobserve that with the increase of 4, the diagnosis performance ofPSCRF decreases slightly while the fairness performance increasesrapidly. This phenomenon is consistent with the results in ,proving the importance of Lcons. Moreover, with the weight 1increasing, the diagnosis performance of PSCRF increases while thefairness performance decreases rapidly and is unstable. This is in-tuitive since a large 1 will focus more on student data and imposemore biased information. With the increase of 2, both diagnosisperformance and fairness performance fluctuate considerably. Wespeculate one possible reason is that Lcls is relatively simple andits impact on PSCRF is relatively small. Thus, a large weight willlead PSCRF unable to learn useful information. For 3, a largervalue will improve the fairness performance while retaining thediagnosis performance, proving the effectiveness of Lrev. 0.20.40.60.8 w1 0.78 0.79 0.80 0.81",
  "Case Study": "To better illustrate the effectiveness of PSCRF, we visualize the pre-diction distributions of different models using FNR (underestimaterate) and FPR (overestimate rate). As shown in , we initiallyobserve a conspicuous prediction bias in the model, charac-terized by underestimation for the disadvantaged group and over-estimation for the advantaged group, displaying a distinct stepwisedistribution between different groups. When introducing sensitive DisadvMidAdv (a)FNR(underestimation rate) 0.10 0.15 0.20 0.25 0.30 0.35 BaseBase RegAdvPSCRF DisadvMidAdv (b)FPR(overestimation rate) 0.15 0.20 0.25 0.30 0.35 0.40 0.45 BaseBase RegAdvPSCRF",
  ": Visualization of the prediction distributions": "attributes, this unfairness is exacerbated (e.g., model). and methods can alleviate this unfairness to some extent. How-ever, their prediction distributions still exhibit a stepwise pattern.As a comparison, PSCRF shows nearly consistent levels of under-estimation and overestimation across different groups, achievingthe lowest overestimation rates among the various models. A com-parison with reveals that PSCRF has effectively mitigatedthe unfairness imposed on the disadvantaged group by a singlesensitive attribute. The only shortfall is that our approach does notreduce the underestimation rates. We speculate that there mightexist other sensitive attributes that are not considered.",
  "CONCLUSION": "In this paper, we argued that current CD models concentrated moreon the full exploitation of student-exercise interaction data, ignor-ing the potential risk of abuse of sensitive attributes. Moreover,we argued that student sensitive attributes could also provide use-ful information, so directly eliminating them was not optimal. Toachieve fairness-aware CD learning, we proposed to incorporatecasual inference and designed a novel PSCRF. By leveraging a newlydesigned attribute-oriented predictor to deal with the informationfrom sensitive attributes. PSCRF decoupled sensitive attributes intofairness-related sensitive features that should not be used in the di-agnosis process, and diagnosis-related features that should be usedto enrich the student proficiency level modeling. Thus, PSCRF couldachieve impressive fairness performance while retaining the diag-nosis performance. Moreover, we designed a multi-factor fairnessconstraint to ensure the fairness performance and diagnosis per-formance simultaneously. Finally, we conducted extensive experi-ments over real-world datasets and multiple advanced CD modelsto demonstrate the effectiveness of PSCRF.",
  "Avishek Bose and William Hamilton. 2019. Compositional fairness constraintsfor graph embeddings. In International Conference on Machine Learning. PMLR,715724": "Jiawei Chen, Hande Dong, Xiang Wang, Fuli Feng, Meng Wang, and XiangnanHe. 2023. Bias and debias in recommender system: A survey and future directions.ACM Transactions on Information Systems 41, 3 (2023), 139. Jiawei Chen, Yan Feng, Martin Ester, Sheng Zhou, Chun Chen, and Can Wang.2018. Modeling Users Exposure with Social Knowledge Influence and Consump-tion Influence for Recommendation. In Proceedings of the 27th ACM InternationalConference on Information and Knowledge Management. 953962. Lei Chen, Le Wu, Kun Zhang, Richang Hong, Defu Lian, Zhiqiang Zhang, JunZhou, and Meng Wang. 2023. Improving Recommendation Fairness via DataAugmentation. In Proceedings of the ACM Web Conference 2023. 10121020.",
  "Jimmy De La Torre. 2009. DINA model and parameter estimation: A didactic.Journal of educational and behavioral statistics 34, 1 (2009), 115130": "Divyaansh Devarriya, Cairo Gulati, Vidhi Mansharamani, Aditi Sakalle, and ArpitBhardwaj. 2020. Unbalanced breast cancer data classification using novel fitnessfunctions in genetic programming. Expert Systems with Applications 140 (2020),112866. Michael D Ekstrand, Mucun Tian, Mohammed R Imran Kazi, Hoda Mehrpouyan,and Daniel Kluver. 2018. Exploring author gender in book rating and recom-mendation. In Proceedings of the 12th ACM conference on recommender systems.242250.",
  "Lina Gao, Zhongying Zhao, Chao Li, Jianli Zhao, and Qingtian Zeng. 2022. Deepcognitive diagnosis model for predicting students performance. Future Genera-tion Computer Systems 126 (2022), 252262": "Weibo Gao, Qi Liu, Zhenya Huang, Yu Yin, Haoyang Bi, Mu-Chun Wang, JianhuiMa, Shijin Wang, and Yu Su. 2021. RCD: Relation map driven cognitive diagnosisfor intelligent education systems. In Proceedings of the 44th international ACMSIGIR conference on research and development in information retrieval. 501510. Weibo Gao, Hao Wang, Qi Liu, Fei Wang, Xin Lin, Linan Yue, Zheng Zhang,Rui Lv, and Shijin Wang. 2023. Leveraging Transferable Knowledge ConceptGraph Embedding for Cold-Start Cognitive Diagnosis. In Proceedings of the 46thInternational ACM SIGIR Conference on Research and Development in InformationRetrieval. 983992. Sahin Cem Geyik, Stuart Ambler, and Krishnaram Kenthapadi. 2019. Fairness-aware ranking in search & recommendation systems with application to linkedintalent search. In Proceedings of the 25th acm sigkdd international conference onknowledge discovery & data mining. 22212231.",
  "Judea Pearl, Madelyn Glymour, and Nicholas P Jewell. 2016. Causal inference instatistics: A primer. John Wiley & Sons": "Chen Qian, Fuli Feng, Lijie Wen, Chunping Ma, and Pengjun Xie. 2021. Coun-terfactual inference for text classification debiasing. In Proceedings of the 59thAnnual Meeting of the Association for Computational Linguistics and the 11thInternational Joint Conference on Natural Language Processing (Volume 1: LongPapers). 54345445. Bashir Rastegarpanah, Krishna P Gummadi, and Mark Crovella. 2019. Fightingfire with fire: Using antidote data to improve polarization and fairness of recom-mender systems. In Proceedings of the twelfth ACM international conference onweb search and data mining. 231239.",
  "Fei Wang, Qi Liu, Enhong Chen, Zhenya Huang, Yu Yin, Shijin Wang, and Yu Su.2022. NeuralCD: a general framework for cognitive diagnosis. IEEE Transactionson Knowledge and Data Engineering (2022)": "Hangyu Wang, Ting Long, Liang Yin, Weinan Zhang, Wei Xia, Qichen Hong,Dingyin Xia, Ruiming Tang, and Yong Yu. 2023. GMOCAT: A Graph-EnhancedMulti-Objective Method for Computerized Adaptive Testing. In Proceedings ofthe 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.22792289. Shanshan Wang, Zhen Zeng, Xun Yang, and Xingyi Zhang. 2023. Self-supervisedGraph Learning for Long-tailed Cognitive Diagnosis. In Proceedings of the AAAIConference on Artificial Intelligence, Vol. 37. 110118. Junfei Wu, Qiang Liu, Weizhi Xu, and Shu Wu. 2022. Bias mitigation for evidence-aware fake news detection by causal intervention. In Proceedings of the 45thInternational ACM SIGIR Conference on Research and Development in InformationRetrieval. 23082313. Le Wu, Lei Chen, Pengyang Shao, Richang Hong, Xiting Wang, and Meng Wang.2021. Learning fair representations for recommendation: A graph-based perspec-tive. In Proceedings of the Web Conference 2021. 21982208. Le Wu, Xiangnan He, Xiang Wang, Kun Zhang, and Meng Wang. 2022. A surveyon accuracy-oriented neural recommendation: From collaborative filtering toinformation-rich recommendation. IEEE Transactions on Knowledge and DataEngineering 35, 5 (2022), 44254445. Shangshang Yang, Haoyu Wei, Haiping Ma, Ye Tian, Xingyi Zhang, Yunbo Cao,and Yaochu Jin. 2023. Cognitive diagnosis-based personalized exercise groupassembly via a multi-objective evolutionary algorithm. IEEE Transactions onEmerging Topics in Computational Intelligence (2023). Mengfan Yao, Siqian Zhao, Shaghayegh Sahebi, and Reza Feyzi Behnagh. 2021.Stimuli-sensitive Hawkes processes for personalized student procrastinationmodeling. In Proceedings of the Web Conference 2021. 15621573.",
  "Celebration Conference-China. 133137": "Renzhe Yu, Qiujie Li, Christian Fischer, Shayan Doroudi, and Di Xu. 2020. TowardsAccurate and Fair Prediction of College Success: Evaluating Different Sources ofStudent Data. International educational data mining society (2020). Xiaoshan Yu, Chuan Qin, Dazhong Shen, Haiping Ma, Le Zhang, Xingyi Zhang,Hengshu Zhu, and Hui Xiong. 2024. RDGT: Enhancing Group Cognitive Diag-nosis with Relation-Guided Dual-Side Graph Transformer. IEEE Transactions onKnowledge and Data Engineering (2024). Zheng Zhang, Le Wu, Qi Liu, Jiayu Liu, Zhenya Huang, Yu Yin, Yan Zhuang,Weibo Gao, and Enhong Chen. 2024. Understanding and improving fairness incognitive diagnosis. Science China Information Sciences 67, 5 (2024), 152106. Zihao Zhao, Jiawei Chen, Sheng Zhou, Xiangnan He, Xuezhi Cao, Fuzheng Zhang,and Wei Wu. 2022. Popularity bias is not always evil: Disentangling benign andharmful bias for recommendation. IEEE Transactions on Knowledge and DataEngineering (2022). Yuqiang Zhou, Qi Liu, Jinze Wu, Fei Wang, Zhenya Huang, Wei Tong, HuiXiong, Enhong Chen, and Jianhui Ma. 2021. Modeling context-aware features forcognitive diagnosis in student learning. In Proceedings of the 27th ACM SIGKDDConference on Knowledge Discovery & Data Mining. 24202428. Ziwei Zhu, Jianling Wang, and James Caverlee. 2020. Measuring and mitigatingitem under-recommendation bias in personalized ranking systems. In Proceedingsof the 43rd international ACM SIGIR conference on research and development ininformation retrieval. 449458.",
  "A.2The Performance of PSCRF on Graph-BasedRCD Model": "Since our PSCRF focuses more on fairness-aware cognitive diag-nosis, we select fundamental and general CD models in the maintext. To further demonstrate the generality of PSCRF , we appliedPSCRF to the graph-based model RCD and report the results onAustralia dataset regarding the sensitive attribute ESCS in .It can be observed that PSCRF achieves similarly good performanceon the RCD model as well.",
  "A.3The relevant information about thelearnable parameters and": "We want to know the values of and after they have been learned,so we computed the mean and variance of their values after trainingon the Australia dataset using IRT model, as shown in .From the results, we can conclude that our proposed PSCRF realizesuser-specific debiasing according to the input users situation."
}