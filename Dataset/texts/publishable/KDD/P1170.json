{
  "ABSTRACT": "Financial time series have historically been assumed to be a mar-tingale process under the Random Walk hypothesis. Instead ofmaking investment decisions using the raw prices alone, variousmultimodal pattern matching algorithms have been developed tohelp detect subtly hidden repeatable patterns within the financialmarket. Many of the chart-based pattern matching tools only re-trieve similar past chart (PC) patterns given the current chart (CC)pattern, and leaves the entire interpretive and predictive analysis,thus ultimately the final investment decision, to the investors. Inthis paper, we propose an approach of ranking similar PC move-ments given the CC information and show that exploiting this asadditional features improves the directional prediction capacity ofour model. We apply our ranking and directional prediction model-ing methodologies on Bitcoin due to its highly volatile prices thatmake it challenging to predict its future movements.",
  "These authors contributed equally to this research.Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,to post on servers or to redistribute to lists, requires prior specific permission and/or afee. Request permissions from 2023, Aug 07, 2023, Long Beach, CA 2023 Association for Computing Machinery.ACM ISBN 978-X-XXXX-XXXX-X/YY/MM...$15.00",
  "INTRODUCTION": "Since the introduction of Bitcoin (BTC) in 2008 , the cryptocur-rency (crypto) market has grown significantly. As a result, it at-tracted many investors and researchers attempting to forecast themovement of these crypto assets in search of profits.Technical analysis is a discipline that analyzes the statisticaltransformation of the undelying financial price and volume timeseries. In this paper, we apply Balance of Power (BOP), Even Bet-ter Sinewave (EBSW), Chaikin Money Flow (CMF), Differencing(DIFF), and Inter Ratios (INTRA), which is technical analysis onthe historical Bitcoin prices and volume to help rank past chart(PC) movements given the current chart (CC) movements. In thiswork, we attempt to compare predictive capabilities of various rank-ing methodologies between PC patterns given CC patterns. Ourcontribution is mainly two folds:",
  "RELATED WORK": "There are numerous researches on how to detect chart patternssuch as and . However, it is challenging to find literaturethat uses detected chart patterns for further modeling or usingsuch information to devise a trading strategy. There are previousapproaches that use similar patterns for modeling but they do notapply these techniques specifically in the domain of finance, muchless crypto or BTC. Moreover, there are chart pattern detect-ing applications available for the traders such as those providedby TrendSpider 1 and BTC pattern calculator 2, but they simplydetect the patterns and do not take it a step further. Our research isalso closely related to CBITS as we incorporate our InformationRetrieval (IR) based feature engineering (FE) technique into theCBITS framework. Furthermore, we use one of the crypto languagemodels (LM) introduced in CBITS, crypto DeBERTa, a transformerbased LM that improves upon BERT by exploiting disentan-gled attention and enhanced mask decoder for our multimodalembedding based ranking method.",
  ": BTC price change within the next 4 hours is less than0.75% i.e +1 < 0.0075 and +1 > 0.0075": "The label 0 translates to long position, the label 1 translatesto short position and 2 translates to holding (taking no action).If both +1 >= 0.0075 and +1 <= 0.0075 occur for the next4 hours, then we gave the labeling priority to 0 (i.e. when bothtaking long or short results in at least 0.75% profit then we simplylabel that timestep as long).",
  "Dataset Description": "We collected 4 hourly BTC/USDT data from Binance 3, one of thelargest crypto exchanges, and we ended up with 11,812 data pointsranging from 2017-08-23 16:00:00 to 2023-01-15 20:00:00. After label-ing the data, we end up with a label distribution of approximately48.11% for 0, 29.40% for 1, and 22.49% for 2. Out of the 11,812 datapoints, we use the first 80% of the data as candidates (9,449 datapoints) for pattern matching and the rest for experimentation. 2,363data points ranging from 2021-12-18 04:00 to 2023-01-15 20:00:00were split into train/validation/test dataset in 8:1:1 ratio, and eachof these 2,363 data points were compared with the candidates tofind its similar counterparts in the past. For each of the 2,363 datapoints, we collected the top 30 similar chart patterns for each ofthe four different similarity calculation strategies.",
  "Modeling": "We employ XGBoost as our directional forecasting model as itis fast to train and is robust for tabular data based classificationtasks. To highlight some important hyper-parameters, we used200 for the number of boosting rounds with a learning rate of 0.3.The maximum tree depth for base learners was set to 6, and thetree method was set to \"gpu_hist\". We also considered the classweights of the train dataset when training XGBoost. Essentiallywe compare the performance of when we use similar past chartinformation or not. We will denote these two cases as a systemwith IR-based FE and a system without IR-based FE. The overallapproach is illustrated in . We compare the performancesof each method by calculating accuracy and weighted F1 score. 3.2.1Without IR-based FE. When we do not use IR-based FE wesimply use chart based features only as inputs to XGBoost fortraining. Most of the chart features that were used are featuresfocused on calculating volatility or simply ratios of the open, high,low, close and volume features. Although XGBoost does not require",
  "BIRP: Bitcoin Information Retrieval Prediction Model Based on Multimodal Pattern MatchingKDDMLF 2023, Aug 07, 2023, Long Beach, CA": "3.2.2With IR-based FE. We use the same chart features presentedin section 3.2.1 in addition to the vote information from past similarranked chart features. Given a timestep , we retrieve at most top30 timesteps that is the most similar to the timestep underone of the four ranking methods. Then we separately calculate theperformance of the models directional forecast when we use votinginformation from the top {5, 10, 15, 20, 25, 30} most similar pastpatterns. Given top similar , we count the number of caseswhen the labels were 0,1 or 2. For example, if = 10 and out ofthose top similar instances if 6 of them were 0, 3 were 1, and1 was 2, then the voting vector can be formed as (6, 3, 1). Beforewe use this as additional input features to the XGBoost model wesoftmax normalize these scores. For example, the count for 0 willbe normalized as follows:",
  "TS2Vec": "The timeseries to vector (TS2Vec) embedding method was firstproposed in and it has proved to effectively extract time se-ries representations that are task agnostic. There are two majorcomponents to the TS2Vec architecture: The TS2Vec encoder consists of the input projection layer,the timestamp masking layer and the dilated convolutionslayer in this order. The timestamp masking layer randomlybinary masks the latent vector and this idea was motivated by and to create augmented context views. The encoderis then optimized via the temporal contrast loss and instance-wise contrastive loss.",
  "The input time series is randomly cropped into two differ-ent time series with overlapping timesteps for positive paircreation in an unsupervised setting": "Due to its design the TS2Vec requires a time series of length > 1 and we set = 6, or 24 hours worth of time frame since we aredealing with 4 hourly chart data. We first train the TS2Vec encoderfor 100 epochs, batch size 16, learning rate 0.001, hidden dimensionsize 64 and output dimension size 128 on NVIDIA A100-80GB GPU.The TS2Vec encoder is trained only on the candidate pool and noton the train/validation/test dataset. Afterwards, we calculate theTS2Vec embeddings for the train/validation/test dataset and all theembeddings for the candidate pool, and calculate the cosine distancebetween the embeddings. We obtain the top 30 embeddings basedon the closeness of the cosine distances. Given that the query is = [5, ...,] and the candidate is = [5, ...,]:",
  "Multimodal": "The multimodal method of ranking involves the use of both chartand news data to generate the embeddings for the time series. Italso uses the same length = 6 and calculates the TS2Vec em-bedding of that time series first, then additionally computes theaverage news embedding between times 1 and by using CryptoDeBERTa. If the current timestep is then we use informationfrom timesteps [ 5, ...,] to calculate the TS2Vec embedding andgather all the news that were released in (not the entire24 hours but just the past 4 hours) to calculate the average newsembedding in this timeframe. We simply extract the [CLS] embed-ding of DeBERTas output for each news and average these [CLS]token representations. Then the average news embedding and theTS2Vec embedding are summed to create a multimodal embeddingand similar to 4.2, we use the cosine distances of these embeddingsto get the top 30 most similar past timesteps. Before summing theaverage news embedding and the TS2Vec embedding, we shrink thenews embedding dimension from 768 128 by applying uniformmanifold approximation and projection. For the news data weuse Coinness Korea4, which is also followed in . Multimodalembeddings should allow us to capture both the news sentimentsand chart dynamics when searching for past patterns.",
  "Random Sampling": "Given some query timestep , the random sampling samples fromall such that < randomly. We use random sampling to observethe differences in performance boost when using random samplingversus some other ranking method, thus verifying that our rankingmethods do indeed catch patterns from the past that in turn helpmodel BTC price movement. For each query, we randomly sampletop 30 past patterns 100 times and calculate the performance ofrandom sampling 100 times with these 100 sampling cases to get abetter idea of how random sampling performs.",
  "We can make interesting observations from the results in": "On average all of our IR-based FE improves over the baselineof no FE, with the multimodal strategy performing the best.Using the top 5 most similar multimodal embeddings hasthe best F1 score of 0.628 and we will be using this modelfor backtesting in section 5.2. The TS2Vec and multimodalstrategies may have improved performance had we used alonger , but we leave this investigation for future research. For our multimodal strategy, we separately calculated theaccuracy of the model for the cases when it predicts 0 or 1and when the ground truth action is also0 or1. Consideringthis case is important because when the model chooses 2it does nothing so it does not incur any profit or loss. If themodel chooses 0 or 1 but the ground truth is 2 then even ifthe models decision is wrong, it would not result in a hugeprofit or loss since the volatility for that time frame wouldbe small. Significant gains or losses happen when the modelpredicts 0 or 1 and when the ground truth action is also 0or 1. In this case the multimodal strategy outperforms theno IR-based FE baseline by more than 5% on average, whileusing the top 5 MultiModal IR-based FE outperforms no FEby close to 10%.",
  "Backtest on Test set": "The following assumptions were made for back testing: (1) We as-sume no take profit and a stop loss of 0.75%. (2) We use commissionrate of 0.04%, equivalent to the maker fee when trading BTC/USDTperpetual in Binance. As a result in figure 2 shows, our model out-performs buy and hold for the duration of the test set. It is notablethat the model predicts 1 (short) effectively when the BTC pricesare falling (e.g. around index 50), gaining edge over buy and hold.Also the model predicts 2 (hold) very well (e.g. around index 100)for periods when there is less volatility and also predicts 0 (long)around index 200 when the prices actually began to soar.",
  "CONCLUSION AND FUTURE WORK": "In this research, we investigated how chart pattern matching canbe incorporated into a BTC directional prediction model trainingframework. Among our proposed pattern matching methods, themultimodal embedding based method is the most effective. Overall,chart pattern matching based feature engineering seems promisingand it can be further explored or coupled with other modelingtechniques to more accurately forecast the volatile price movementof BTC.",
  "We are primarily focuses on creating machine learning based trad-ing bots and indicators for trading crypto assets": "Tianqi Chen and Carlos Guestrin. 2016. XGBoost: A Scalable Tree BoostingSystem. In Proceedings of the 22nd ACM SIGKDD International Conference onKnowledge Discovery and Data Mining (San Francisco, California, USA) (KDD 16).ACM, New York, NY, USA, 785794. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. 2020. Asimple framework for contrastive learning of visual representations. In Interna-tional conference on machine learning. PMLR, 15971607. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding. InProceedings of the 2019 Conference of the North American Chapter of the Associationfor Computational Linguistics: Human Language Technologies, Volume 1 (Long andShort Papers). Association for Computational Linguistics, Minneapolis, Minnesota,41714186.",
  "Guozhu Dong and Vahid Taslimitehrani. 2016. Pattern-aided regression modelingand prediction model analysis. In 2016 IEEE 32nd International Conference on DataEngineering (ICDE). 15081509": "Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.SimCSE: Simple Con-trastive Learning of Sentence Embeddings. In Proceedings of the 2021 Conferenceon Empirical Methods in Natural Language Processing. Association for Compu-tational Linguistics, Online and Punta Cana, Dominican Republic, 68946910. Xueyuan Gong and Yain-Whar Si. 2013. Comparison of subsequence patternmatching methods for financial time series. In 2013 Ninth International Conferenceon Computational Intelligence and Security. IEEE, 154158."
}