{
  "ABSTRACT": "The Sustainable Development Goals (SDGs) were introduced by theUnited Nations in order to encourage policies and activities thathelp guarantee human prosperity and sustainability. SDG frame-works produced in the finance industry are designed to providescores that indicate how well a company aligns with each of the 17SDGs. This scoring enables a consistent assessment of investmentsthat have the potential of building an inclusive and sustainableeconomy. As a result of the high quality and reliability required bysuch frameworks, the process of creating and maintaining them istime-consuming and requires extensive domain expertise. In thiswork, we describe a data-driven system that seeks to automatethe process of creating an SDG framework. First, we propose anovel method for collecting and filtering a dataset of texts fromdifferent web sources and a knowledge graph relevant to a set ofcompanies. We then implement and deploy classifiers trained withthis data for predicting scores of alignment with SDGs for a givencompany. Our results indicate that our best performing model canaccurately predict SDG scores with a micro average F1 score of0.89, demonstrating the effectiveness of the proposed solution. Wefurther describe how the integration of the models for its use byhumans can be facilitated by providing explanations in the form ofdata relevant to a predicted score. We find that our proposed solu-tion enables access to a large amount of information that analystswould normally not be able to process, resulting in an accurateprediction of SDG scores at a fraction of the cost.",
  "INTRODUCTION": "In 2015, the United Nations introduced the Sustainable Develop-ment Goals (SDGs) , a set of 17 objectives proposed to govern-ments and companies around the world aimed towards increasinghuman prosperity and sustainability. They address issues such aspoverty, food access, health, education, gender equality, workingconditions, climate change, energy, and life on land and water.In the financial industry, SDGs serve as a guideline to determinesuitable metrics for creating sustainable investment solutions. Thisrequires the establishment of frameworks for measuring the im-pact that a particular investment can have on SDGs . An SDGframework allows one to analyze a financial asset and produce anoverall score of its alignment with the SDGs, enabling the creationof investment portfolios that have a positive impact on society andthe environment.At Robeco1, we introduced the Robeco SDG score. With a frame-work that analyzes the impact of companies on the SDGs throughthe products they sell, the way they operate, and whether they areinvolved in controversies, companies receive an SDG score thatindicates a negative, neutral, or positive alignment.There are several challenges associated with producing SDGscores. First, substantial human effort is necessary to manuallyinvestigate reports, news, and other resources to unearth helpfulinformation for evaluating how sustainable a company might be.Thus, the process is time-consuming and expensive, since expertknowledge is required to judge the relevance of different sources.Second, the information sources for assessing the activities of acompany can often be fragmented, missing, or biased. For instance,only some businesses publish sustainability reports on their officialwebsites. Even when available, they might be subject to green-washing, which occurs when a company overstates the positiveenvironmental impact of their activities.Previous research has found that artificial intelligence (AI) hasthe potential to assist in meeting 79% of the targets of the SDGs .Further work has shown different uses of AI for analyzing climate-related texts and financial disclosures . Motivated by thesuccess of machine learning in tackling other challenging problems",
  "ClassierTraining": ": Illustration of our pipeline for predicting SDG alignment scores. On the left, we start with a set of companies, some ofwhich are labeled with SDG scores. We crawl the web for different textual and knowledge graph sources and filter them forrelevance. The resulting data is used to train classifiers, which allow us to predict labels for unlabeled companies. that involve heterogeneous data sources, we aim to employ it tohelp ease the burden of creating an accurate, scalable, and reliableSDG framework.In this work, we describe a system for automating obtainingSDG scores for a given set of companies. In particular,",
  "We discuss the performance of the classifiers in predictingSDG scores and its impact on an explainable applicationtowards automating the process of creating an SDG frame-work": "Our results show that the system can effectively extract therelevant data such that the classifiers predict net alignment SDGscores with an average micro F1 score of 0.89, demonstrating theeffectiveness of our proposed solution. We find that textual fea-tures are responsible for the performance of the classifiers, whileinformation from the graph is only beneficial when it is condensed.Lastly, we describe how we can explain predictions provided by theclassifiers, such that experts are better informed when using themas a guide for generating SDG scores, and we provide a discussionon the implications of our results.",
  "RELATED WORK": "SDG-related data sources. Previous works have advocated for thecreation of datasets that could be used in research on AI for SDG-aligned activities . These works focus on specific activitiesand documents that describe activities in different sectors of theeconomy. In our work, we consider a broader set of sources obtainedfrom the Web, that range from sustainability reports posted oncompany websites, news, Wikipedia descriptions, and a subset ofthe Wikidata KG. This allows us to take into account a varietyof factors to assess the impact of an organization on different SDGs.Furthermore, recent works obtain labels for training machinelearning models with automatic methods, such as weak supervision,instead of using gold labels from experts . This might leadto inconsistent SDG scores and may hinder the development ofa transparent and coherent SDG framework . We address thischallenge by using SDG scores produced by experts in the domain. Text-based methods for estimating SDG alignment. Previous workhas considered the application of natural language processing (NLP)techniques to evaluate the impact of a company on SDGs . Thetypes of methods can be categorized into i) keyword-based ap-proaches, ii) machine learning approaches based on hand-craftedfeatures, and iii) machine learning approaches that incorporate con-text and end-to-end learned features . The latter category hasgained popularity due to the outstanding performance of large pre-trained language models like BERT and GPT-3 on language-relatedtasks . Such models have been extended to the sustainabilitydomain, as in the case of ClimateBERT , which was pre-trainedon a corpus of climate-related text to identify sections in sustain-ability reports relevant to climate change. Knowledge graphs for SDGs. Network effects have been studiedin the field of finance , in areas such as portfolio diversifi-cation , portfolio selection , and the design of food supplychain networks to help achieve SDG goals . These studies mo-tivate incorporating domain specific networks, such as KGs containing information about companies, their activities, and stake-holders, among others, into SDG frameworks.Previous work has proposed a set of tools to aggregate andlink multiple resources relevant to the SDGs using SemanticWeb technologies , in some cases also considering the effect ofdifferent countries towards SDGs. In this work, we focus on thespecific case of companies, and in addition to collecting a relevantKG, we use it as an additional source of information in a machinelearning model that facilitates the estimation of SDG alignment.",
  "SYSTEM DESCRIPTION": "We address the problem of predicting how well aligned a company isto the SDGs, by using a collection of relevant data sources and labelsproduced by experts, and training a machine learning model toautomate the task. More formally, we are given a set C of companies,which is composed by two disjoint subsets C and C of labeledand unlabeled companies, respectively. Each of the companies inC is accompanied by a sequence of SDG scores (1, . . . ,17), whereeach is a number that denotes how well-aligned a company iswith each of the 17 SDGs. The goal consists of training a model topredict SDG scores for companies in C .To achieve this, we build a pipeline that consists of data collection,relevance filtering, and model training and evaluation, as illustratedin , which we describe next.",
  "Data Sources": "SDG scores. We employ the data in the Robeco SDG frameworkand extract a subset of 1,391 companies that have been scored byexpert analysts. The score is an integer that can take values between-3 and 3, indicating strongly misaligned and strongly aligned, respec-tively. For this subset we did not have access to enough training datarelated to SDGs 4, 10, and 17, which we omit in our experiments. Sustainability reports. In order to assess how the products of acompany might contribute to each of the SDGs, we scrape the Webin search for official sustainability reports. We make use of BingsWeb Search API to construct queries that first search for theofficial domain of a company, and then for sustainability reportswithin that domain. From the resulting web pages, we extract anyreports available in PDF format, and if no PDF file is found, we usethe content of the web page. Wikipedia descriptions and news. Relying on sustainability re-ports alone to evaluate the operations of a company might lead toa biased estimation of its impact on SDGs, due to issues such asgreen washing. To incorporate more diverse sources, we turn ourattention to Wikipedia pages and news. Similar to sustainabilityreports, we search for a Wikipedia page associated with each com-pany, and use the text in it as a source describing its operations.We then use the Wikipedia pages to link companies to entities inthe GDELT database . GDELT is an open-source project thatanalyzes news media in over 100 languages, in print, broadcast,and online formats. Since every entity in the GDELT database isassociated with a Wikipedia URL, we use it to retrieve any newsfrom 2021 associated with the companies of our interest. Knowledge Graphs. In order to leverage the structural relation-ships that exist between companies, we map each of them to anentity in the Wikidata KG . We then retrieve a subgraph aroundthe companies, by iteratively extracting neighboring nodes in thegraph until all companies are reachable with each other within 4edges. The resulting subgraph contains 74,840 nodes, 160,994 edges,and 610 different relation types. Examples of the relation types thatwe extract are country, headquartes location, subsidiary, languageused, owner of, industry, and owned by.We additionally construct a summary of the KG: an undirectedgraph where nodes are companies and an edge exists between themif they are within two steps in the original KG.",
  "Relevance filtering": "The dataset collected with the previous section provides differentviews from which to assess the impact of a company on SDGs.However, it also generates a vast amount of text that would increasethe cost of model training and hyperparameter optimization, whilecontaining several instances that are not relevant for the task. Toselect relevant sentences from Wikipedia pages, for each SDG, wecollect keywords related to them and concatenate them to forma sentence. We then use SBERT to map this sentence into asingle embedding. We also use SBERT to embed sentences from theWikipedia pages, and then select the top 5 sentences with highestsimilarity with the embedded keywords. To increase precision, wefollow this by BERT-NLI , a natural language inference modelthat we use to detect if a sentence is entailed from the description",
  "Models": "We treat the problem of SDG score prediction as a classification task,where the labels correspond to each of the integer scores between -3and 3. We leave more structured models such as ordinal regressionfor future work . As features for training predictive models,we use bag-of-words (BOW) representations extracted from all ourtextual data, as well as the KG or the summary graph for modelsthat can additionally process graph-structured data.The first model we consider is a Balanced Random Forest (BRF)that predicts from BOW features only , since it is a compu-tationally efficient model that can also deal with different classfrequencies in our data.As graph-based models, we consider the Graph ConvolutionalNetwork (GCN, ), which we train using the summary graph;and the Relational GCN (R-GCN, ) trained on the original KG.We train the models for 5,000 epochs with the Adam optimizer andlearning rate of 0.01. Both models use two layers with a hidden sizeof 16, and ReLU activation functions.",
  "(b) Graph features": ": Example of an explanation for predicting an alignment score for SDG 7 (affordable and sustainable energy), usingtextual features (a) and graph features (b). a: Given a bag-of-words representation of a company (left), thehighest probability (center) is assigned to score 3 (strongly aligned), with the terms wind and energy being responsible for theprediction (right). b: We highlight the edges selected that according to a graph explanation model, are responsible forclassifying the company Entra ASA as positively aligned with SDG7. false negatives are computed regardless of the class) and macro F1scores (computed for each class separately, and then averaged). Theresults are shown in .When inspecting the micro F1 scores, the highest value that weobtain is 0.89, corresponding to the BRF, closely followed by theGCN. This shows that the large amount of textual features that wecollected is responsible for the ability to predict SDG scores, andadding the graph (as in the GCN model) does not bring significantimprovements. In the case of the R-GCN, the KG can even yieldlower performance. We attribute this to the fact that in the KG usedby the R-GCN, only company nodes had textual features, whereasother nodes used learned embeddings that require additional train-ing. This is demonstrated by the better performance of the GCN,where the graph consists exclusively of companies associated withtextual features. We note that the macro F1 scores are much lower,since these treat all classes equally. In this case, the score decreasesafter being dominated by classes not commonly used by expertanalysts, for which there is not sufficient training data.",
  "Explainability": "In addition to a model that is successful at predicting SDG alignmentscores, we are interested in its deployment in an application forautomated SDG scoring where humans can use predictions as aguide that could inform their reasoning and decision. This motivatesthe implementation of a mechanism for providing explanations forthe predictions, such that they can be trusted and allow for theidentification of potential biases or systematic errors before theyoccur during deployment.To this end, we use LIME to generate a score that indicateshow relevant each of the terms in the BOW representation is re-sponsible for a particular prediction. This is illustrated in (a),where we explain a score predicted for SDG 7 (ensuring access toaffordable, reliable, sustainable and modern energy for all) for thecompany Vestas Wind Systems. We observe that the model assignsthe largest probability to a score of 3 (strongly aligned), which LIMEattributes to the terms wind and energy.Using a graph cluster algorithm , we cluster companies inthe company graph into 50 clusters. Each company is assigned itsSDG label, and the mean label for the cluster becomes the new label for all companies within it. For companies without an initialSDG label, GCN is utilized for label classification. To explicate theclassification results of the graph, we employ GNNExplainer ,which reveals insights through two dimensions: the significant sub-graph consisting of important neighbors and connections related tothe focal node, and the influential feature driving the classificationoutcomes for that node. (b) illustrates the pertinent subgraphexplaining the prediction of Entra ASA. It indicates that Entra ASAis categorized in the same group as CA Immobilien Anlagen AGand Jardine Matheson Holdings Ltd, rather than Equinor ASA. BothCA Immobilien Anlagen AG and Equinor ASA play a direct role indetermining the classification results for Entra ASA. CA ImmobilienAnlagen AG and Entra ASA operate in the Real Estate Manage-ment and Development sectors with a neutral product score, whileEquinor ASA belongs to the Oil, Gas, and Consumable Fuels sectorwith an extremely negative product score and operational (newssentiment) score.The use of LIME enables term relevance visualization, offeringinsights into the factors influencing model predictions. This notonly improves the transparency of our predictions, as exemplified inthe Vestas Wind Systems case, but also facilitates the identificationand mitigation of potential biases or systematic errors in our model.Hence, explainable AI techniques like LIME contribute to a morereliable and accountable AI-based SDG scoring process, promotinga nuanced understanding of a companys sustainability alignmentand enhancing the robustness of the overall system. Based on thesepromising qualitative findings, in future work we plan to carry outa rigurous evaluation that quantifies how useful the explanationsare to domain experts.",
  "DISCUSSION": "The opportunity set for Robecos investment products consists ofseveral thousands of companies in global developed and emergingmarkets, which is too large for analysts who have to continuouslyevaluate each company on their SDG alignment. Therefore, wehave been developing SDG scores using AI methods to significantlyincrease the number of companies with SDG score coverage. Thisautomated SDG scoring uses numerous data sources, includingtext data, to evaluate the impact of a companys products on SDGs",
  "Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring": "and whether they engage in controversial behavior. In addition,the automated SDG scores can be compared to the opinion of thedomain experts, who can incorporate new insights provided by theautomated SDG scores in their assessment.This project has explored an extended set of publicly availablesustainability data for creating SDG scores. The automated analysishas not only made it more efficient to transform the vast amount of(text) data into insights, but also unlock access to information thatanalysts normally would not be able to easily process themselves,such as news in multiple languages or complex relationships. Evenfor the most cases where we use the final verdict of the domainexpert, the additional data and the quality of processing it and link-ing it through the network leads to a better and easier explainableSDG score at a fraction of the cost.We see two possible directions for further improvement. First,we may want to explicitly search and adjust for possible corporategreenwashing . Second, most corporate reporting and news dealswith past corporate behavior, but forward-looking measures thatpredict future corporate behavior are even more relevant.",
  "CONCLUSION": "In this work, we presented a data driven procedure for tacklingreal-world business challenges in the sphere of impact investing.We demonstrate the efficacy of utilizing web data to address datascarcity issues for sustainability ratings. In addition, we demon-strate how contemporary NLP approaches can effectively identifyimportant SDG objectives in a huge volume of unstructured content.We validate the use of our dataset by predicting the existing SDGscores developed by the investing firm Robeco, achieving a highmicro F1 score performance, and we explore a method for explain-ing prediction in a way that expert analysts can interpret. In futurework we would like to explore improved methods for detectingbehavior such as green washing, as well as more expressive modelssuch as language models while preserving explainability.",
  "Florian Berg, Julian F Klbel, and Roberto Rigobon. 2022. Aggregate Confusion:The Divergence of ESG Ratings*. Review of Finance 26, 6 (05 2022), 13151344. arXiv:": "Robbert Biesbroek, Shashi Badloe, and Ioannis N Athanasiadis. 2020. Machinelearning for research on climate change adaptation policy integration: an ex-ploratory UK case study. Regional Environmental Change 20, 3 (2020), 113. Julia Anna Bingler, Mathias Kraus, Markus Leippold, and Nicolas Webersinke.2022. Cheap talk and cherry-picking: What ClimateBert has to say on corporateclimate risk disclosures. Finance Research Letters (2022), 102776. Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter,Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, IlyaSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.In Advances in Neural Information Processing Systems 33: Annual Conference onNeural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020,virtual, Hugo Larochelle, MarcAurelio Ranzato, Raia Hadsell, Maria-FlorinaBalcan, and Hsuan-Tien Lin (Eds.). Mike Chen, George Mussalli, Amir Amel-Zadeh, and Michael Oliver Weinberg.2021. NLP for SDGs: Measuring Corporate Alignment with the SustainableDevelopment Goals. The Journal of Impact and ESG Investing (2021). Tom Corringham, Daniel Spokoyny, Eric Xiao, Christopher Cha, Colin Lemarc-hand, Mandeep Syal, Ethan Olson, and Alexander Gershunov. 2021. BERTClassification of Paris Agreement Climate Action Plans. In ICML 2021 Workshopon Tackling Climate Change with Machine Learning. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT:Pre-training of Deep Bidirectional Transformers for Language Understanding.In Proceedings of the 2019 Conference of the North American Chapter of the Associ-ation for Computational Linguistics: Human Language Technologies, NAACL-HLT2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), JillBurstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computa-tional Linguistics, 41714186. David Friederich, Lynn Kaack, Sasha Luccioni, and Bjarne Steffen. 2021. Auto-mated Identification of Climate Risk Disclosures in Annual Corporate Reports.In ICML 2021 Workshop on Tackling Climate Change with Machine Learning.",
  "Yang Gao, Nicol Colombo, and Wei Wang. 2021. Adapting by Pruning: ACase Study on BERT. CoRR abs/2105.03343 (2021). arXiv:2105.03343": "Aidan Hogan, Eva Blomqvist, Michael Cochez, Claudia dAmato, Gerard deMelo, Claudio Gutirrez, Sabrina Kirrane, Jos Emilio Labra Gayo, Roberto Nav-igli, Sebastian Neumaier, Axel-Cyrille Ngonga Ngomo, Axel Polleres, Sabbir M.Rashid, Anisa Rula, Lukas Schmelzeisen, Juan Sequeda, Steffen Staab, and An-toine Zimmermann. 2021. Knowledge Graphs. Morgan & Claypool Publishers. Javid Jouzdani and Kannan Govindan. 2021. On the sustainable perishablefood supply chain network design: A dairy products case to achieve sustainabledevelopment goals. Journal of Cleaner Production 278 (2021), 123060. Elham Kheradmand, Didier Serre, Manuel Morales, and Cedric B Robert. 2021. ANLP-based Analysis of Alignment of Organizations Climate-Related Risk Dis-closures with Material Risks and Metrics. In NeurIPS 2021 Workshop on TacklingClimate Change with Machine Learning. Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification withGraph Convolutional Networks. In 5th International Conference on LearningRepresentations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference TrackProceedings. OpenReview.net.",
  "Shouwei Li and Chao Wang. 2021. Network structure, portfolio diversificationand systemic risk. Journal of Management Science and Engineering 6, 2 (2021),235245": "Alexandra Luccioni and Hector Palacios. 2019. Using natural language processingto analyze financial climate disclosures. In Proceedings of the 36th InternationalConference on Machine Learning, Long Beach, California. Prakamya Mishra and Rohan Mittal. 2021. NeuralNERE: Neural Named EntityRelationship Extraction for End-to-End Climate Change Knowledge Graph Con-struction. In ICML 2021 Workshop on Tackling Climate Change with MachineLearning. Jos Eduardo Eguiguren Palacios and Nelson Piedra. 2019. Connecting OpenData and Sustainable Development Goals using a Semantic Knowledge GraphApproach. In Proceedings of the XII Seminar on Ontology Research in Brazil andIII Doctoral and Masters Consortium on Ontologies, Porto Alegre, Brazil, September2nd-5th, 2019 (CEUR Workshop Proceedings, Vol. 2519), Joo Paulo A. Almeida,Marcello Bax, Rita Berardi, and Fernanda Baio (Eds.). CEUR-WS.org.",
  "Hu and Daza, et al": "Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embed-dings using Siamese BERT-Networks. In Proceedings of the 2019 Conference onEmpirical Methods in Natural Language Processing and the 9th InternationalJoint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, HongKong, China, November 3-7, 2019, Kentaro Inui, Jing Jiang, Vincent Ng, andXiaojun Wan (Eds.). Association for Computational Linguistics, 39803990. Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. \"Why Should ITrust You?\": Explaining the Predictions of Any Classifier. In Proceedings of the22nd ACM SIGKDD International Conference on Knowledge Discovery and DataMining, San Francisco, CA, USA, August 13-17, 2016. 11351144. Michael Sejr Schlichtkrull, Thomas N. Kipf, Peter Bloem, Rianne van den Berg,Ivan Titov, and Max Welling. 2018. Modeling Relational Data with Graph Con-volutional Networks. In The Semantic Web - 15th International Conference, ESWC2018, Heraklion, Crete, Greece, June 3-7, 2018, Proceedings (Lecture Notes in Com-puter Science, Vol. 10843), Aldo Gangemi, Roberto Navigli, Maria-Esther Vidal,Pascal Hitzler, Raphal Troncy, Laura Hollink, Anna Tordai, and Mehwish Alam(Eds.). Springer, 593607.",
  "Gerhard Tutz. 2022. Ordinal regression: A review and a taxonomy of models.Wiley Interdisciplinary Reviews: Computational Statistics 14, 2 (2022), e1545": "Jan Anton van Zanten and Rob van Tulder. 2021. Analyzing companies interac-tions with the Sustainable Development Goals through network analysis: Fourcorporate sustainability imperatives. Business Strategy and the Environment 30,5 (2021), 23962420. Ricardo Vinuesa, Hossein Azizpour, Iolanda Leite, Madeline Balaam, VirginiaDignum, Sami Domisch, Anna Fellnder, Simone Daniela Langhans, MaxTegmark, and Francesco Fuso Nerini. 2020. The role of artificial intelligencein achieving the Sustainable Development Goals. Nature communications 11, 1(2020), 110.",
  "CompanyProduct information": "SGL Carbon SEIt is one of the worlds leading manufacturers of products from 29 production sites around the globe (16 inEurope, 8 in North America and 5 in Asia), and a service network in over 100 countries, SGL Carbon is aglobally operating company Gerdau SAThese products are used in different sectors, such as industry, metallurgy, farming and livestock, civil construc-tion, automotive industries, petrochemicals, railway and naval sectors, in addition to orthodontic, medical andfood areas Bridgestone CorpToday, Bridgestone diversified operations encompass automotive components, industrial products, polyurethanefoam products, construction materials, parts and materials for electronic equipment, bicycles and sportinggoods MTS Systems CorpThe companys products and services support customers in research and development and QAQC testing ofproducts through the physical characterization of materials, such as ceramics, composites and steel Berkshire Hathaway IncMoore formulates, manufactures, and sells architectural coatings that are available primarily in the UnitedStates and 2001, Berkshire acquired three additional building products companies"
}