{
  "ABSTRACT": "Counterfactual explanations of Graph Neural Networks (GNNs)offer a powerful way to understand data that can naturally be rep-resented by a graph structure. Furthermore, in many domains, it ishighly desirable to derive data-driven global explanations or rulesthat can better explain the high-level properties of the models anddata in question. However, evaluating global counterfactual explana-tions is hard in real-world datasets due to a lack of human-annotatedground truth, which limits their use in areas like molecular sciences.Additionally, the increasing scale of these datasets provides a chal-lenge for random search-based methods. In this paper, we developa novel global explanation model RLHEX for molecular propertyprediction. It aligns the counterfactual explanations with human-defined principles, making the explanations more interpretable andeasy for experts to evaluate. RLHEX includes a VAE-based graph gen-erator to generate global explanations and an adapter to adjust thelatent representation space to human-defined principles. Optimizedby Proximal Policy Optimization (PPO), the global explanationsproduced by RLHEX cover 4.12% more input graphs and reduce thedistance between the counterfactual explanation set and the inputset by 0.47% on average across three molecular datasets. RLHEX pro-vides a flexible framework to incorporate different human-designedprinciples into the counterfactual explanation generation process,aligning these explanations with domain expertise. The code anddata are released at",
  "Graph Neural Network; Counterfactual Explanation; ReinforcementLearning": "ACM Reference Format:Danqing Wang, Antonis Antoniades, Kha-Dinh Luong, Edwin Zhang, MertKosan, Jiachen Li, Ambuj Singh, William Yang Wang, and Lei Li. 2024. GlobalHuman-guided Counterfactual Explanations for Molecular Properties viaReinforcement Learning. In Proceedings of the 30th ACM SIGKDD Conferenceon Knowledge Discovery and Data Mining (KDD 24), August 2529, 2024,Barcelona, Spain. ACM, New York, NY, USA, 10 pages.",
  "INTRODUCTION": "Graph Neural Networks (GNNs) have shown promise in fieldssuch as cheminformatics and molecular sciences . A crucialapplication of GNNs in these fields is molecule property predic-tion , where the task is to predict a molecules propertiesbased on its structural or functional groups. This is essential forvarious scientific research aspects, including drug discovery ,environmental monitoring , and materials engineering .However, the intricate complexity of Graph Neural Networks(GNNs) poses challenges in fully leveraging the rich informationembedded within the structural properties and feature representa-tions of nodes and edges . Moreover, it is challenging tointerpret and understand the underlying rationale behind GNNsprediction due to non-transparency. This complexity underlines agrowing need to understand GNN predictions, particularly withcounterfactual (CF) explanations, which present the conditions thatneed to change to alter the models decisions . They canhighlight the influential sub-graph affecting an individual graphs",
  "KDD 24, August 2529, 2024, Barcelona, Spain.Danqing Wang, Antonis Antoniades et al": "Decoder Based on how the graph is generated, there are two typ-ical types of graph decoder. One is to pre-define the number of nodes| | and then predict the node feature matrix and edge matrix. The other is to autoregressively generate nodes ( |<, ), {1, , | |} and then predict the edge between the nodes (,|).",
  "RELATED WORK": "Counterfactual Explanations of GNNs. Counterfactual reason-ing presents a necessary condition that would, if not met, alterthe prediction . Studies aimed at providing counterfactualexplanations for GNNs can be divided into two categories: localand global explainers. Local explainers select sub-structures froma given graph that contribute to its GNNs prediction ,whereas global explainers produce new graphs to illustrate themodel behavior across a set of graphs . There are two typi-cal ways to generate counterfactual explanations. One is to perturbnodes and edges of the input graph to get a different prediction. Forexample, Lucic et al. and Tan et al. learn a mask matrix toselect the sub-graph or feature from the input graph, while Kosanet al. and explore different graph edits. The other one isto model it as a generative task. For example, Yuan et al. , Nu-meroso and Bacciu and Ma et al. generates the key patternfor counterfactual explanations directly. However, the explanationscreated by previous methods are difficult to evaluate without theground-truth labels. In this paper, we align a graph generativemodel with human-designed principles to make the explanationsmore human-friendly. Graph-based Molecule Generation. Graph neural networks arewidely used in 2D molecule tasks . A molecule can be graph-ically represented with atoms as vertices and chemical bonds asedges. The atom-based generation methods take the atom as thebasic generation units , while the fragment-based meth-ods build their vocabulary based on the chemical substructure . The fragment-based generation is more likely to producemeaningful molecules with chemically desirable properties, whichare reflected in their substructure . Additionally, it can makethe edit-based sampling more effective and efficient . In thispaper, we use a fragment-based generative model to ensure that thegenerated global explanations are valid molecules, making themunderstandable for domain experts. Align Explainability with Humans. Aligning models to makethem helpful and friendly to humans has gained increasing at-tention recently, especially in large language models . Thealignment can be formulated in the reinforcement learning frame-work to optimize the model policy towards the reward functionsbased on human values or principles . explores theselective explanations based on what aligns with the recipientspreferences. Xu et al. investigates explainable metrics andaligns the explanation of the mistakes with humans by the failuremode summarized from human feedback. However, few studieshave investigated how to align the global interpretation of GNNswith the preferences of domain experts.",
  "PRELIMINARIES3.1Molecular Property Prediction": "A molecule can be intuitively represented as a graph = (, ),where R| | is a set of nodes corresponding to atoms and R| || | is a set of edges corresponding to chemical bonds.| | is the number of atoms. and are the feature dimensions ofthe atom and the bonds respectively. The functional groups of the",
  "PPO": ": RLHEX has three main parts - the VAE-based generation model, the adapter, and the reward module. The reward modulecontains several reward functions based on principles designed by humans, which make the generated explanations easier fordomain experts to interpret. The adapter modifies the latent representation by adding the delta , which is optimized usingPPO to align with the principles designed by humans. The RLHEX model uses the molecule to be explained as the input andcreates the CF explanations from the modified latent representation + . molecule are often denoted by a subgraph = (, ) of the graph, which satisfies and .The molecular property prediction can be modeled as a binarygraph classification task. It aims to predict whether the input mol-ecule has a certain chemical property, such as whether the mol-ecule is active against AIDS. Given a set of molecular graphsG = {0,2, ,} and the ground-truth labels {0,1, ,}where {0, 1}, the GNN classifier () is trained to predict theestimated label = () for each input graph .Typically, GNN learns the representation of each node R by aggregating the information of its neighbors () . is thedimension of the hidden state. By identifying different aggrega-tion functions M () and node update functions U (), the updatemechanism in each layer can be denoted as:",
  "GNN Counterfactual Explanation": "The explanation of the GNN classifier is to analyze and interprethow it makes predictions. A local counterfactual explanation (CFexplanation) of the GNN classifier () on the input moleculargraph is defined as an instance that () (). Here, can be the sub-graph of the original or another graph similar to .The optimal CF explanation is one that minimizes the distancebetween and the CF explanation . Ideally, the optimal CF explanation should be very close to the input graph and have a dif-ferent prediction. It reveals the minimal perturbation the classifierneeds to change its decision.For the global CF explanation, it aims to provide a set of instances C = {1,2, , } that can explain the global behaviorof the classifier. Different from the local CF explanations which isspecifically designed for each input molecule, the limited size ofthe global CF explanation set makes it easier for domain expertsto check the classifier behavior on large molecule datasets. Forexample, given an undesirable molecule property = 0 and a set ofmolecules { | () = 0, G}, the global CF explanation set isa set of instances { | () 0, {0, 1, , }}. Kosan et al. proposes that the global CF set should have a high coverage, alow cost and a small size.",
  "VAE-based Graph Generation": "Given the input graph = (, ), the variational auto-encodersfirst embed the graph into continuous latent representation Rby the encoder (|). is the dimension of the latent represen-tation. The graph decoder then outputs the graph from the sampledpoint in the latent space ( |) . The model is trained byminimizing the training objective:",
  "= (|) [log (|)] + KL( (|)||()).(4)": "Here, () is the prior distribution N (0, 1). It maximizes the like-lihood of the input graph and regularizes the latent space withthe KL divergence.Encoder The graph neural network is often used as the encoderto map the input graph into the latent representation . The hiddenrepresentation of the graph is obtained by Eqn 3. It is thenmapped to the and log variance of variational posteriorapproximation (|) for the reparameterization . The latentrepresentation is sampled from N (, |).",
  "METHODOLOGY": "In this section, we propose a novel global explanation frameworkRLHEX to align global CF explanations with human-designed prin-ciples. We first discuss several desirable properties for the optimalglobal CF explanation of molecules. Then we introduce the back-bone framework to generate CF candidates and use Proximal PolicyOptimization (PPO) to align the candidates with these human prin-ciples.",
  "(1) The generated explanations should be counterfactual to theinput molecules": "(2) The generated explanations should be valid molecule. .(3) The explanation set should be small enough for an expert tomanually evaluate while covering as many input molecules aspossible .The first one is the basic principle for CF explanation, requiringthe counterfactual explanation to have a different prediction withthe input molecule : () (). The second one ensures thatthe generated explanations are chemically meaningful structures tochemists. This interpretability is more compatible with the domainknowledge and easy for the chemists to understand. For example,the generated graphs should not violate the implicit valence andring information. The last one is derived from the definition of theoptimal local CF explanation. The CF explanation set should besimilar to the input molecule so that it can reveal the necessaryfeatures the GNN predictor relies on to change their prediction. Thesize of the explanation should also be small to ensure it is durablefor domain experts to check. Here we follow Kosan et al. tointroduce three metrics to formally define the requirement: cov,cost, and size. The size is denoted as |C|.Coverage is a measure of the proportion of input graphs G can be covered by explanations in C under a given distancethreshold :",
  "Adapter-enhanced Molecule Generator": "To align these human-designed principles with CF generation,we propose Reinforcement Learning via Human-guided EXplana-tions RLHEX, a flexible CF generation framework for molecules. Itformulates the search for an optimal global counterfactual expla-nation as a graph set generation task. Given the input graph set Gand the GNN classifier (), RLHEX generates a set of graphs C asits CF explanations.As shown in , RLHEX includes three modules: a VAE-based generation model, an adapter, and a reward module.",
  "Adapter module. It is a parameterized policy to steerthe generator into producing explanations that meet thehuman-designed principle": "Reward Module. It provides the reward signal based on thehuman-designed principles to guide the generation. Bothheuristic-based and parameterized criteria can be flexibly in-tegrated to meet specific experimental needs or to customizeexplanations as required. 4.2.1VAE-based Generation Model. We backbone our model witha fragment-based molecule generation model Principal SubgraphVAE (PSVAE) . It first mines principal subgraphs from themolecule datasets and then generates new molecules based on thesubgraphs. Essentially, principal subgraphs are frequent and largefragments. The sub-graph-based generation is more interpretableand chemically meaningful, resulting in valid molecules.PSVAE decomposes one molecule into a set of unordered non-overlapped principal sub-graphs . is the number ofsubgraphs. To generate a new molecule, PSVAE autoregressivelypredicts chemical sub-graphs ( |<, ). It then non-autoregressivelypredicts the inter-subgraph edges via GNN, where and arenodes from different sub-graphs. Therefore, the likelihood of thegenerated molecule can be formulated as:",
  "By replacing the first term of Eqn 4 with Eqn 7, we obtain thetraining objective of PSVAE. We use the pre-trained checkpoint ofPSVAE and freeze the parameters in the encoder and decoder": "4.2.2Latent Distribution Adaptor. To steer the molecule genera-tion model to create desired CF explanations, we add a lightweightadaptor as our parameterized policy to adjust the latent distri-bution. The adaptor can either be initialized as a copy of the initialPSVAE, denoted as , or as a randomly initialized model, in ourcase a lightweight transformer encoder . It takes the graphhidden state as the input and maps it to a shift on the mean ofthe latent distribution = (). The new latent representation is sample from the distribution N ( + , ). The decodertakes as the input to generate (|). The complete generativeprocess, starting from the input molecule and ending at the",
  "= ()(),(11)": "where and (), ()stand for the respective encoder and decoderof the PSVAE. This framework allows for the sequential genera-tion of molecules, with each step informed by the previous state,thus enabling a guided exploration of the molecular space that iscoherent with the desired properties encoded by the policy . 4.2.3Principle Modeling. We design our reward module basedon the principles in .1. For (1), we take the predictionprobability of the opposite class as the reward. For example, if theinput molecules are predicted as negative () = 0, we take",
  "maxC cov(C)..|C| = .(12)": "Here, the size of C is limited by k, and the cost is constrainedbased on the threshold in coverage. In practice, we first maximizethe local reward for each input molecule and get a set of CFexplanation C. Then we greedily select top- explanations from thecandidate set as C. The local reward () for each candidate isdefined as:",
  "Tailor Latent Distribution via PPO": "We formulate the alignment to the human-designed principles asa Markov decision process (MDP) M = (S, A, R, ), with statespace S, action space A, reward function R, and transition prob-ability matrix . The state S is the CF candidates, which areall molecules. The action is the modification of the latent distri-bution A R. is the dimension of the latent space.(|,) : S A S indicates the probability of CF candidatesbased on the new latent distribution. The reward R is the localreward function defined in Eqn 13.At each time step , RLHEX employs the VAE encoder to get theembedding of the input molecule , which is the state . It then",
  ":C C + {}": "uses (,) to sample the mean shift of the latent distribution(). The reward (,) is based on the scores from the human-designed principle (Eqn 13). Our goal is to learn a policy ()that can find the optimal latent distribution for the CF explanations.We leverage Proximal Policy Optimization (PPO) to generatemolecules that satisfy different principles. It has been extensivelyused to steer models into producing human-desired outputs in lan-guage models, using RLHF (Reinforcement Learning from HumanFeedback) , and we take inspiration from these methods tobuild a more flexible system within which many different forms ofhuman-guided principles can be used to optimize our explanationmodel.PPO operates by optimizing an objective that balances explo-ration and exploitation of the current policy old, to gain more re-ward and explore new policies . This balance is achieved throughclipped probability ratios, ensuring that updates do not deviatetoo far from the current policy. The standard PPO objective is thefollowing:",
  ",": "where is a hyperparameter that defines the clipping range, andE, represents the expectation for an on-policy batch sample. Wetrain an additional critic model () to estimate the actual rewardof the current state and action (,) during the training. Here(,) is the expected local rewards of the CF candidates sampledfrom the new latent distribution:(,) = E (|, ) [score()].score() is from Eqn 13. (,) denotes the advantage function,which is defined as (,) = (,) ().In our case, the property of a constrained policy update is es-sential to our goal of keeping newly generated molecules close indistribution to the original molecule distribution to ensure theirvalidity.",
  "Greedy Selection": "For each molecule in G, we apply RLHEX to optimize the localreward score() in Eqn 13 and get the CF candidate set C. To getan optimal CF candidate set C with size , we greedily choose thetop- candidates from C. Start from an empty set C0, we add thecandidate with the maximum gain, which is defined as:",
  "EXPERIMENT5.1Datasets": "We focus on molecule property prediction and conduct our experi-ments on three real-world molecule datasets: AIDS , Mutagenic-ity and Dipole . AIDS and Mutagenicity have been used inprevious works , however, qualitative evaluation of the coun-terfactuals generated for these tasks is challenging without domainexpertise. For that reason, we seek to formulate a task in which thechemical characteristics can be quickly evaluated by observing thestructure of the generated graphs. AIDS is a binary dataset wherethe label=0 indicates the molecule is active against AIDS. The ac-tivity is the desirable attribution for molecules, so we flip the labelto make the negative class correspond to the undesirable property.The mutagenicity dataset classifies molecules by whether they aremutagenetic and labels the mutagenetic with label 0. Dipole is abinary classification dataset we curated from a subset of moleculesreported by Pereira and Aires-de Sousa , in which the dipolemoment of each molecule is recorded. In particular, we extract asubset of the most polar molecules to form the positive class anda subset of the least polar molecules to form the negative class.Polarity is a comparably simpler chemical property to assess fromonly the molecular structure. Following previous work, we keepatom types that appear at least 50 times in the dataset, resulting in9 common atoms in AIDS and Dipole and 10 in Mutagenicity. 3 Forthe graph dataset AIDS and Mutagenicity, we convert the graphrepresentation to SMILES and remove the duplicated instances.We randomly split the dataset by 0.8:0.1:0.1 for training, vali-dation and testing. We follow Kosan et al. to train separateGNN-based predictors () on these datasets. We use 3 convolutionlayers as the aggregation function and add the message to the previ-ous node representation for update. One max pooling layer is usedto get the graph representation from the node representationand a full-connected layer is added on top of it for classification.The model is trained with the Adam optimizer and a learningrate of 0.001 for 1000 epochs. Detailed information is listed in .",
  "#Graphs156234613539#Nodes per graph15.7330.349.16#Edges per graph16.3230.8018.53#Atom Type9109#GNN Accuracy97.81%80.00%89.37%": "of graphs and a greedy summary to deliver high-coverage, low-cost candidate sets for input graphs. The maximum steps of therandom walk is set to 6000. Two non-RL generative baselines aretested: PSVAE and PSVAE-SA. PSVAE iteratively encodes the in-put molecule to the latent space and samples from the latent spaceto generate candidates. We terminate the sampling process whenits generation has a different prediction from the input molecule,or when it arrives at the maximum iteration. PSVAE-SA appliessimulated annealing to optimize the sampling process toward thereward function. For each iteration, it samples from the latent rep-resentation of the input molecule and accepts the new generationbased on the Metropolis criterion:",
  "),(17)": "Here, score represents the local reward at step defined in Eqn13, while is temperature, initially set at 0.1 and halved every 10steps. We follow the standard settings of other hyperparameters inoriginal papers. We check the validity of the generated candidate ex-planations and only keep valid molecules with opposite predictionsfor the final candidate set.",
  "Implementation and Evaluation": "We initialize the encoder and decoder of RLHEX based on PSVAE .We use the released checkpoint trained on ZINC250K andfreeze the parameters. Note that our method does not limit usto a specific architecture, allowing for the use of other modelsfor molecule generation purposes. We set the dimension of thelatent representation space as 56 and the hidden size of the adaptorto 400 for both the policy model and the critic model. We usethe Adam optimizer for training and set the learning rate to 1e-5.We use linear warmup and decay the learning rate to 1/10 of themaximum. To facilitate good explorations vs. exploitation strategy,we employ Upper Confidence Bound sampling Wang et al. ,which preferably samples input molecules according to the meanand variance of the scores they yield over episodes.We follow previous studies to use Tanimoto similarity to cal-culate the distance between molecules . It is a commonlyused similarity function to compare chemical structures based onfingerprints. We set the distance threshold as 0.87 based on thedataset distribution.We evaluate the model performance based on the coverage andcost described in .2.3. We set the coefficient in Eqn 13 to = 1, = 10 to balance the scale of the prediction probability and",
  "GCFExplainer0.8530.0080.9170.0460.9640.068PSVAE0.8540.0030.8360.0040.8390.005PSVAE-SA0.8470.0030.8160.0080.8320.002RLHEX0.8370.0010.8130.0060.8330.004": "the individual coverage. PSVAE-based baselines maintain a beamsize of 10 and a temperature of 1 for decoding. After getting thecounterfactual candidate set, we use the greedy algorithm to selecttop- counterfactual explanations as described in Alg. 1. The mainresults come from sampling = 20 iterations per input molecule.We use = 10 for the main experiment.",
  "and 3 show the coverage and cost on the test set of threedatasets with = 10 after 20 iterations. We ran the experiments5 times with different random seeds and calculated the average": "and standard deviations. Our method, RLHEX, performs better thanthe best baseline model, PSVAE-SA, with a gain of 8% increase incoverage and a cost reduction of 1.23% on AIDS. It also performsbest on Mutagenicity in terms of coverage and cost. Dipole has thehighest coverage with a similar cost. It means that the explanationsfrom RLHEX are similar to the input molecules with different GNNpredictions. This helps people understand the GNN predictorsbehaviors on the whole input dataset with limited molecules. shows how the candidate set size impacts performance.RLHEX has the highest coverage with different . When increases,the performance gap grows. All methods reach their maximumcoverage on the input graph set after = 25. The candidate setcovers almost the entire input graph set. Two generative baselines,PSVAE and PSVAE-SA, do better than GCFExplainer when is small.But GCFExplainer reduces the performance gap as the number ofcandidates grows.In general, RLHEX outperforms other baselines in cost. On AIDSand Dipole, GCFExplainer can match the input set at a lower costthan PSVAE and PSVAE-SA with = 50. This is similar to RLHEX.However, on Mutagenicity, our method RLHEX has a clear edge overthe other baselines for all . PSVAE-SA has a small cost at = 1 onthree datasets while it lags when grows larger. This means thatthe simulated annealing starting from individual input is good atfinding the local optima explanation but not at the global optima.However, RLHEX can find a better global explanation set closer tothe input set for different .",
  "Analysis": "Ablation Studies In , we further investigate the perfor-mance of our model with several ablation studies. These studiesdelve deeper into the fundamental components of the RLHEX modeland their contributions to the models overall effectiveness. Tobetter understand the role of the PSVAE in RLHEX, we consider avariant of RLHEX, namely RLHEX w/o PSVAE. This variant starts",
  "w/o PSVAE0.1680.9230.9000.7990.7130.846w/o Adapter0.6150.8570.8870.7910.8170.833": "with randomly initialized parameters and is trained from scratch.Noticeably, the absence of the pre-trained PSVAE results in a sig-nificant reduction in coverage on the AIDS and Dipole datasets.Nonetheless, it is still able to generate valid explanations because ofthe subgraph-based generation method. We also study the influenceof the trained adapter by examining a version of RLHEX (referred toas RLHEX w/o trained Adaptor) that includes a randomly initializedadapter without any further training. The adapter in this contextis directly used for inference with a random shift on the latentspace. The results highlight that the removal of the adapter leads todecreases in coverage and an increase in cost. This is primarily dueto the alignment mismatch with the human-designed principles.RLHEX achieves the highest coverage after one iteration Fig-ure 3 illustrates how the performance is impacted by the numberof iterations during the inference process. For the PSVAE-basedmodel, an iteration is defined as one pass over the set of inputgraphs, G. For GCFExplainer, the maximum step of the randomwalk is defined as |G|, where denotes the iteration number. Asshown in , RLHEX reaches optimal performance after oneiteration and maintains a stable performance after 20 iterations.However, GCFExplainer shows the best performance at the firstiteration. As the iteration number increases, other models startto outperform GCFExplainer. This performance decrease can beattributed to GCFExplainers process of exploring every possibleperturbation on nodes and edges for the current molecule at eachstep, which includes investigating up to 100,000 neighbors. In com-parison, PSVAE-based methods explore 10 candidates (beam size= 10) for each input graph. Consequently, GCFExplainers largesearch space at each step makes it more effective when the iterationnumber is small. However, as the number of iterations increases, itsperformance deteriorates due to its inefficient exploration strategy.Generated CF explanations are more interpretable displays two cases produced by RLHEX, specifically focusing onthe AIDS and Dipole datasets. In the AIDS dataset, the GNN pre-dictor classifies the input graphs as negative, or label=0, indicatingthat these molecules are inactive against AIDS. Conversely, in theDipole dataset, the input molecules are deemed non-polar, whilethe CF explanation shows them as polar. As seen in , the CFexplanation closely resembles these input molecules, as they shareseveral common chemical sub-graphs. This similarity allows RLHEXto encapsulate the behavior of the GNN predictor across variousinput molecules by grouping multiple negative molecules together.It further uncovers the necessary conditions that would promptthe GNN predictor to alter its prediction. Another highlight of ourwork is that by comparing the varying sub-graphs between the CFexplanation and the covered input molecules, domain experts can",
  "Expert Assessment on CF Explanation": "We also engaged molecular chemists to evaluate our CF explana-tions. Although the evaluations lacked empirical laboratory testing,the expert feedback was in general alignment with the explanationsabout specific classes of molecules. Through this procedure, thechemists could assess the efficacy of the GNN classifier throughits alignment with known chemical knowledge. Based on the caseshown in , chemists made the following observations:AIDS The CF candidate is predicted to be active against AIDS.Although the input negative molecules also have the fused aro-matic rings and hydroxyl (-OH) groups that could potentially formimportant interactions with viral targets, the fused 3-ring systemof the CF candidate increases its possibility of being against AIDS.The fused 3-ring system resembles known HIV integrase inhibitorpharmacophores .Dipole The CF candidate and the covered input molecules haveO-H and N-H bonds, which are polar due to the electronegativitydifference between oxygen and hydrogen. However, the CFcandidate has a bent geometry, which allows the bond dipoles toadd up and create a net molecular dipole .",
  "CONCLUSION AND DISCUSSION": "In this paper, we introduced RLHEX, a global counterfactual explana-tion method that strives to aid domain experts to better understandGNN predictions. Our proposed model aligns with the domainexperts criteria and uses Proximal Policy Optimization (PPO) togenerate chemically valid explanations that can cover the highestnumber of input molecules. Importantly, our method takes intoaccount the interpretability requirement of domain experts, an as-pect often overlooked in CF explanations, making it suitable forunderstanding molecular property predictions. Experimental re-sults show that RLHEX outperforms other strong baselines on threereal-world molecular datasets.",
  "Dipole": ": The counterfactual (CF) explanation generated for the closest input molecules from the AIDS and Dipole datasets.For each CF explanation, we compute the distance between it and the input molecules, selecting the top 5 input moleculesfor display. The generated CF explanation for AIDS exhibits a coverage of 0.231 over the input molecule set, while the CFexplanation for the Dipole dataset shows a coverage of 0.209. Further work can focus on the scalability of our method. We planto investigate RLHEXs performance on larger datasets and morecomplex molecular structures. Although the primary application ofour method is in cheminformatics, we anticipate that the underlyingprinciple of RLHEX could be broadly applied across various fieldsrequiring interpretability in the use of GNNs. Furthermore, morehuman-designed principles can be flexibly integrated into RLHEX toalign different preferences of domain experts.To conclude, RLHEX represents a significant step towards creatingmore interpretable and understandable GNN models. By generatingglobal counterfactual explanations through human-aligned princi-ples, RLHEX offers a promising avenue for domain experts to betterutilize and comprehend the findings of GNN predictions, partic-ularly in the evolving generative landscape. Through our work,we aspire to bridge the gap between the scale and complexity ofsequence-based prediction models and the intuitiveness requiredby experts to make new scientific discoveries.",
  "We gratefully acknowledge the support of the National ScienceFoundation (# 2229876) for funding this research": "Carlo Abrate and Francesco Bonchi. 2021. Counterfactual graphs for explain-able classification of brain networks. In Proceedings of the 27th ACM SIGKDDConference on Knowledge Discovery & Data Mining. 24952504. Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, NovaDasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022.Training a helpful and harmless assistant with reinforcement learning fromhuman feedback. arXiv preprint arXiv:2204.05862 (2022). Yuntao Bai, Saurav Kadavath, Sandipan Kundu, Amanda Askell, Jackson Kernion,Andy Jones, Anna Chen, Anna Goldie, Azalia Mirhoseini, Cameron McKinnon,et al. 2022. Constitutional ai: Harmlessness from ai feedback. arXiv preprintarXiv:2212.08073 (2022). Mohit Bajaj, Lingyang Chu, Zi Yu Xue, Jian Pei, Lanjun Wang, Peter Cho-HoLam, and Yong Zhang. 2021. Robust counterfactual explanations on graph neuralnetworks. Advances in Neural Information Processing Systems 34 (2021), 56445655.",
  "Paul Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, andDario Amodei. 2023. Deep reinforcement learning from human preferences.arXiv:1706.03741 [stat.ML]": "Kalyan Das, Paul J Lewi, Stephen H Hughes, and Eddy Arnold. 2005. Crys-tallography and the design of anti-AIDS drugs: conformational flexibility andpositional adaptability are important in the design of non-nucleoside HIV-1 re-verse transcriptase inhibitors. Prog Biophys Mol Biol 88, 2 (Jun 2005), 209231. Zijie Geng, Shufang Xie, Yingce Xia, Lijun Wu, Tao Qin, Jie Wang, YongdongZhang, Feng Wu, and Tie-Yan Liu. 2023. De novo molecular generation viaconnection-aware motif mining. arXiv preprint arXiv:2302.01129 (2023). Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George EDahl. 2017. Neural message passing for quantum chemistry. In Internationalconference on machine learning. PMLR, 12631272. Rafael Gmez-Bombarelli, Jennifer N Wei, David Duvenaud, Jos MiguelHernndez-Lobato, Benjamn Snchez-Lengeling, Dennis Sheberla, JorgeAguilera-Iparraguirre, Timothy D Hirzel, Ryan P Adams, and Aln Aspuru-Guzik.2018. Automatic chemical design using a data-driven continuous representationof molecules. ACS central science 4, 2 (2018), 268276.",
  "Yujia Li, Oriol Vinyals, Chris Dyer, Razvan Pascanu, and Peter Battaglia. 2018.Learning deep generative models of graphs. arXiv preprint arXiv:1803.03324(2018)": "Tairan Liu, Misagh Naderi, Chris Alvin, Supratik Mukhopadhyay, and MichalBrylinski. 2017. Break down in order to build up: decomposing small moleculesfor fragment-based drug design with e molfrag. Journal of chemical informationand modeling 57, 4 (2017), 627631. Ana Lucic, Maartje A Ter Hoeve, Gabriele Tolomei, Maarten De Rijke, and FabrizioSilvestri. 2022. Cf-gnnexplainer: Counterfactual explanations for graph neuralnetworks. In International Conference on Artificial Intelligence and Statistics. PMLR,44994511. Jing Ma, Ruocheng Guo, Saumitra Mishra, Aidong Zhang, and Jundong Li. 2022.Clear: Generative counterfactual explanations on graphs. Advances in NeuralInformation Processing Systems 35 (2022), 2589525907.",
  "Danilo Numeroso and Davide Bacciu. 2021. Meg: Generating molecular coun-terfactual explanations for deep graph networks. In 2021 International JointConference on Neural Networks (IJCNN). IEEE, 18": "Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, PamelaMishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schul-man, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Pe-ter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training languagemodels to follow instructions with human feedback. arXiv:2203.02155 [cs.CL]",
  "Kaspar Riesen, Horst Bunke, et al. 2008. IAM Graph Database Repository forGraph Based Pattern Recognition and Machine Learning.. In SSPR/SPR, Vol. 5342.287297": "Alexander Rives, Joshua Meier, Tom Sercu, Siddharth Goyal, Zeming Lin, Ja-son Liu, Demi Guo, Myle Ott, C. Lawrence Zitnick, Jerry Ma, and Rob Fergus.2021. Biological structure and function emerge from scaling unsupervised learn-ing to 250 million protein sequences. Proceedings of the National Academy ofSciences 118, 15 (2021), e2016239118. Jerret Ross, Brian Belgodere, Vijil Chenthamarakshan, Inkit Padhi, YoussefMroueh, and Payel Das. 2022. Large-Scale Chemical Language RepresentationsCapture Molecular Structure and Properties. arXiv:2106.09553 [cs.LG]",
  "John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.2017. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347(2017)": "Martin Simonovsky and Nikos Komodakis. 2018. Graphvae: Towards generationof small graphs using variational autoencoders. In Artificial Neural Networksand Machine LearningICANN 2018: 27th International Conference on ArtificialNeural Networks, Rhodes, Greece, October 4-7, 2018, Proceedings, Part I 27. Springer,412422. Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong Zhou, Zhenfang Chen,David Cox, Yiming Yang, and Chuang Gan. 2023. SALMON: Self-Alignment withPrinciple-Following Reward Models. arXiv:2310.05910 [cs.LG] Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen,David Cox, Yiming Yang, and Chuang Gan. 2023.Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision.arXiv:2305.03047 [cs.LG] Nathan J. Szymanski, Bernardus Rendy, Yuxing Fei, Rishi E. Kumar, TanjinHe, David Milsted, Matthew J. McDermott, Max Gallant, Ekin Dogus Cubuk,Amil Merchant, Haegyeom Kim, Anubhav Jain, Christopher J. Bartel, KristinPersson, Yan Zeng, and Gerbrand Ceder. 2023. An autonomous laboratory forthe accelerated synthesis of novel materials. Nature 624, 7990 (2023), 8691. Juntao Tan, Shijie Geng, Zuohui Fu, Yingqiang Ge, Shuyuan Xu, Yunqi Li, andYongfeng Zhang. 2022. Learning and evaluating graph neural network explana-tions based on counterfactual and factual reasoning. In Proceedings of the ACMWeb Conference 2022. 10181027. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,Aidan N Gomez, ukasz Kaiser, and Illia Polosukhin. 2017. Attention is allyou need. Advances in neural information processing systems 30 (2017). Xiang Wang, Yingxin Wu, An Zhang, Fuli Feng, Xiangnan He, and Tat-Seng Chua.2022. Reinforced causal explainer for graph neural networks. IEEE Transactionson Pattern Analysis and Machine Intelligence 45, 2 (2022), 22972309.",
  "Zhi Wang, Chicheng Zhang, and Kamalika Chaudhuri. 2022. Thompson Samplingfor Robust Transfer in Multi-Task Bandits. arXiv:2206.08556 [cs.LG]": "Oliver Wieder, Stefan Kohlbacher, Mlaine Kuenemann, Arthur Garon, PierreDucrot, Thomas Seidel, and Thierry Langer. 2020. A compact review of molec-ular property prediction with graph neural networks. Drug Discovery Today:Technologies 37 (2020), 112. Felix Wong, Erica J Zheng, Jacqueline A Valeri, Nina M Donghia, Melis N Anahtar,Satotaka Omori, Alicia Li, Andres Cubillos-Ruiz, Aarti Krishnan, Wengong Jin,et al. 2023. Discovery of a structural class of antibiotics with explainable deeplearning. Nature (2023), 19. Zhenxing Wu, Jike Wang, Hongyan Du, Dejun Jiang, Yu Kang, Dan Li, PeichenPan, Yafeng Deng, Dongsheng Cao, Chang-Yu Hsieh, et al. 2023. Chemistry-intuitive explanation of graph neural networks for molecular property predictionwith substructure masking. Nature Communications 14, 1 (2023), 2585. Yutong Xie, Chence Shi, Hao Zhou, Yuwei Yang, Weinan Zhang, Yong Yu, and LeiLi. 2021. MARS: Markov Molecular Sampling for Multi-objective Drug Discovery.In International Conference on Learning Representations. Wenda Xu, Danqing Wang, Liangming Pan, Zhenqiao Song, Markus Freitag,William Yang Wang, and Lei Li. 2023. Instructscore: Towards explainable textgeneration evaluation with automatic feedback. arXiv preprint arXiv:2305.14282(2023). Qiang Yang, Changsheng Ma, Qiannan Zhang, Xin Gao, Chuxu Zhang, andXiangliang Zhang. 2023. Counterfactual Learning on Heterogeneous Graphswith Greedy Perturbation. In Proceedings of the 29th ACM SIGKDD Conferenceon Knowledge Discovery and Data Mining (Long Beach, CA, USA) (KDD 23).Association for Computing Machinery, New York, NY, USA, 29882998. Jiaxuan You, Bowen Liu, Zhitao Ying, Vijay Pande, and Jure Leskovec. 2018.Graph convolutional policy network for goal-directed molecular graph genera-tion. Advances in neural information processing systems 31 (2018). Hao Yuan, Jiliang Tang, Xia Hu, and Shuiwang Ji. 2020. Xgnn: Towards model-level explanations of graph neural networks. In Proceedings of the 26th ACMSIGKDD International Conference on Knowledge Discovery & Data Mining. 430438.",
  "Ziwei Zhang, Peng Cui, and Wenwu Zhu. 2020. Deep learning on graphs: A survey.IEEE Transactions on Knowledge and Data Engineering 34, 1 (2020), 249270": "Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu,Lifeng Wang, Changcheng Li, and Maosong Sun. 2020. Graph neural networks:A review of methods and applications. AI open 1 (2020), 57present81. Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, DarioAmodei, Paul F. Christiano, and Geoffrey Irving. 2019. Fine-Tuning LanguageModels from Human Preferences. CoRR abs/1909.08593 (2019). arXiv:1909.08593"
}