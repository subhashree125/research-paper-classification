{
  "ABSTRACT": "Computational marketing has become increasingly important intodays digital world, facing challenges such as massive hetero-geneous data, multi-channel customer journeys, and limited mar-keting budgets. In this paper, we propose a general frameworkfor marketing AI systems, the Neural Optimization with AdaptiveHeuristics (NOAH) framework. NOAH is the rst general frame-work for marketing optimization that considers both to-business(2B) and to-consumer (2C) products, as well as both owned andpaid channels. We describe key modules of the NOAH framework,including prediction, optimization, and adaptive heuristics, provid-ing examples for bidding and content optimization. We then detailthe successful application of NOAH to LinkedIns email marketingsystem, showcasing signicant wins over the legacy ranking sys-tem. Additionally, we share details and insights that are broadlyuseful, particularly on: (i) addressing delayed feedback with life-time value, (ii) performing large-scale linear programming withrandomization, (iii) improving retrieval with audience expansion,(iv) reducing signal dilution in targeting tests, and (v) handlingzero-inated heavy-tail metrics in statistical testing.",
  "Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor prot or commercial advantage and that copies bear this notice and the full citationon the rst page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specic permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "Computational Marketing, Linear Programming, Lifetime Value,Audience Expansion": "ACM Reference Format:Changshuai Wei, Benjamin Zelditch, Joyce Chen, Andre Assuncao Silva TRibeiro, Jingyi Kenneth Tay, Borja Ocejo Elizondo, Sathiya Keerthi Selvaraj,Aman Gupta, and Licurgo Benemann De Almeida. 2024. Neural Optimizationwith Adaptive Heuristics for Intelligent Marketing System. In Proceedings ofthe 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining(KDD 24), August 2529, 2024, Barcelona, Spain. ACM, New York, NY, USA,16 pages.",
  "INTRODUCTION": "Compared with traditional media marketing, online digital mar-keting has become increasingly important for advertisers and mar-keters. With online digital marketing, marketers can reach cus-tomers more directly with personalized marketing messages. Manyof the current major internet companies build advertising plat-forms to better connect advertisers/marketers to customers, typi-cally through auction or bidding systems. From a marketers per-spective, there are paid social channels (e.g., Facebook) and paidsearch channels (e.g., Google). Besides these paid channels, there arealso owned channels like email, where marketers can connect withcustomers directly. There is much literature on building machinelearning (ML) systems from ads platforms perspective; however,few papers have discussed ML and optimization systematicallyfrom the marketers perspective. In fact, there are many uniquechallenges when building an intelligent marketing system from themarketers perspective:",
  "(2) The objective can be challenging to dene. The mar-": "keting life-cycle can be quite dierent across products. Formany to-consumer (2C) products, the interaction is typicallyonline and self-served, so the life-cycle from receiving themarketing message to conversion can be just a few days.For to-business (2B) products, the life-cycle can span weeksto months, including activities such as lead generation andsales involvement. As a result, these ML models face issuesassociated with delayed feedback.",
  "(3) The action space is complex. There are dierent types of": "actions to optimize the marketing outcome. These include(but are not limited to) at what time and frequency the mar-keting message should be sent, what content (e.g., picture,language) to use for the message, which audience to target,how much to bid for the marketing campaign(s) on vari-ous ads platforms. Unifying these actions under a generaloptimization framework would help build a more ecientmarketing system.",
  "(4) There are various types of constraints. Marketing typi-": "cally comes with cost. Some costs are explicit (e.g., billingfrom paid channels), while others are implicit (e.g., com-plaints or unsubscriptions from users on owned channels).Besides these cost constraints, there are also other opera-tional constraints within marketing systems, e.g., cappingon message frequency, minimum volume for various typeof products. An intelligent marketing system should be ableto determine optimal actions while respecting these con-straints.",
  "ML in Marketing Industry. The use of ML in marketing has": "been fertile over the last decades, given the wealth of data natu-rally produced by marketing and the capacity of ML tools/methodsto transform data into information that can be used for market-ing optimization and decision making. For instance, ML solutionshave been proposed and/or applied to multiple domains, for in-stance: customer segmentation in industries such as retail ,hospitality and banking ; customer life time value(LTV) in industries ranging from gaming , to e-commerce, to subscription services ; marketing attribution, in bothmulti-touch attribution and marketing mix modelling ; theoptimization of dierent marketing channels, such as email ,paid search bidding , display advertising , amongothers. For a comprehensive review of the use of ML in marketing,we recommend the work presented in .",
  "Optimization in Recommender Systems. A commonly used": "optimization approach for Recommender systems (RecSys) is theranking heuristic, where items are ranked by their relevance scoresand top-ranked items are shown/sent to users. To balance dierent(and sometimes conicting) objectives, the relevance score is oftena linear combination of multiple predicted objective values. While a large amount of research eort has gone into applying ML and AI topredicting the individual objective values, less work has been doneon how to choose the weights for an optimized linear combination.In recent years, Linear Programming (LP) has been emerging inRecSys for its capability of trading o multiple objectives.",
  "LP has been studied closely since the 1940s, and several commer-": "cial solvers such as Gurobi and GLPK can give high-qualitysolutions for small-moderate instances in reasonable time frames.However, they cannot scale to industrial-scale problems with bil-lions or trillions of variables due to memory or computationalconstraints. One approach to handle large-scale LPs is to devisealgorithms where certain key quantities can be computed in a dis-tributed manner. The alternating direction method of multipliers(ADMM) is one such approach; details how ADMM can beimplemented successfully for industrial-scale problems. Anotherapproach is the primal-dual hybrid gradient (PDHG) method fora class of problems in convex optimization. applies the PDHGmethod to a saddle-point formulation of LP and adds enhancementssuch as diagonal preconditioning, presolving, adaptive step sizesand adaptive restarting to make the algorithm more ecient inpractice.",
  "Our Approach": "NOAH is a general framework for intelligent marketing systemswhich consists of three major modules: 1) prediction module, 2)optimization module and 3) adaptive heuristics module. The predic-tion module provides predictions of business metrics given possiblemarketing actions. The optimization module chooses marketingactions that optimize the relevant business metrics. The adaptiveheuristics module connects various components of the system toform a better feedback loop. We rst go over more details of theNOAH framework in , including the three NOAH modulesand some illustrative high-level examples. We then walk through alarge scale application to LinkedIns marketing engine in . We also share the real A/B test win results with some learningsin and conclude in . We would like to highlighttwo major contributions of the paper:",
  "Marketing Ecosystem at LinkedIn": "LinkedIn is the worlds largest professional network and has prod-ucts that serve both 2C and 2B needs. As a result, the marketingsystem () needs to promote not only 2C products like Pre-mium but also various 2B products in Talents, Learning, Ads andSales lines of business. The marketing system is a heterogeneoussystem that involves both a rst-party system and integration withthird-party tools. Marketers interact with the marketing system todecide the optimal marketing actions for these 2B and 2C products,including whom the marketing message should be sent to, the besttiming and frequencies for the messages to be sent, what biddingprice or target the keywords or campaigns should be set at (on paidchannel). Once the actions are decided from the Marketing Engine,the marketing messages are delivered via various owned or paidchannels.",
  "Paid channels include paid search, paid social and other display": "ads on third-party platforms, where LinkedIn (as an advertiser) par-ticipates in ad bidding through various auction mechanisms. Mean-while, with owned channels, LinkedIn can promote its products onLinkedIn itself or use the email channel to have direct connectionswith customers. When a user clicks on a marketing message fromone of these channels, they are directed to an optimized landingpage where more detailed product information is shown. For 2Cproducts, the landing page is typically on LinkedIns main websiteand the purchase can be typically completed in a self-serve manner.On the other hand, for 2B products the landing page is typicallyLinkedins 2B micro-site (e.g., wherean inquiry form can be generated for LinkedIn sales personnel tofollow up.",
  "NOAH Modules": "In order to have a general framework that can handle dierent typesof entities and possible actions in owned and paid channels, we rstabstract out two denitions: marketing unit and a marketing action.A marketing unit is an entity that a marketing action can be appliedon. For example, in email marketing where we can directly connectwith members and collect engagement data, the marketing unit isa member and a marketing action (to be optimized) can be whetherto send a particular email to the member. In paid search channels,assuming marketers can get keyword-level data, the marketing unitcan be a keyword, and a marketing action can be the bid amountfor the keyword.",
  "NOAH is a human-in-the-loop system. Marketers with expert": "knowledge dene appropriate marketing units and marketing ac-tions in the relevant databases. A candidate retrieval process re-trieves the appropriate set of marketing units and actions fromthe databases and feeds them to the core engine. Marketers alsoprovide input parameters via an UI that can guide the core enginesbehavior. User engagement feedback and other contextual informa-tion are also collected as input to the core engine. The core engineprocesses these inputs through the three key modules to generateoptimized marketing actions.",
  "~ = 5 (GD,G0,G2),": "where G2 represents a feature vector for contextual informationother than marketing unit and action (e.g., location, device). Themetrics are typically marketing objectives and constraints relatedto user feedback. For example, we can build a functional mappingfor four metrics: click through rate (CTR), conversion rate, protper conversion and cost per click (CPC). With these metrics, wecan use the chain rule to connect these conditional probabilities toestimate the prot per impression and cost per impression, whichcan be further used in the optimization module. The functionalmapping 5 () can be learnt from user feedback data. Depending onthe amount of data available and the maturity of the system, we canuse dierent supervised learning methods to estimate 5 (). If theamount of data is small and the project is at the initial stage, a simple",
  "KDD 24, August 2529, 2024, Barcelona, SpainChangshuai Wei et al": "makes recent positive engagement unavailable for training (i.e., cen-sored observations). In order to overcome this issue, we make aux-iliary LTV predictions at shorter time windows (e.g., 1,3,6 months)and use the output of those models as features for the main 12-month LTV prediction. We found that this strategy increases pre-diction accuracy and allows the model to respond faster to evolvingbusiness trends.",
  "One key characteristic of the prediction module is the inclusion": "of the marketing action. If the metric prediction is conditionedon the marketing action, the prediction module can then generatemetric estimates for all possible marketing actions, from which theoptimization module can choose the best action. However, histor-ical data may not contain all possible marketing actions for eachunit, which may generate bias in inference. To reduce the bias,various causal ML methods can be used so that the 5 () learnt betterreects the causal relationship .",
  "Optimization Module. With the functional mapping of mar-": "keting actions and performance metrics, we then need to choosethe best action for a given marketing unit in the optimization mod-ule. The simplest, widely adopted approach is a ranking approach:choose the action with the largest ~ value, i.e., the largest estimatedmetric. While it can often work, this ranking approach ignoresmany limitations or constraints that can lead to sub-optimal andsometimes unacceptable performance.",
  "To address various constraints across marketing units, we can": "frame the problem as a constrained optimization problem. For eachmetric : = 0, 1, . . . , , let ~: = 5: (GD,G0D,G2) denote the estimatedvalue of metric : for marketing unit D under action 0D. Withoutloss of generality, let ~0 be the primary metric to be optimized, andlet the remaining ~: (: 1) be metrics that are subject to variouslimitations or business constraints with upper bound constraints:. Assuming no interaction eects across marketing units, we canformulate the optimization problem:",
  "The above optimization problem can be relaxed and solved with": "ecient linear programming (LP) algorithm in many cases; we de-tail some examples in .3 and .3. When latencyis a strong requirement, some compromises on accuracy need tobe made, for example, to use yesterdays dual solution for todaysprimal calculation. Fortunately, for marketing AI use cases, latencyis not a major problem as the systems are mostly oine. For exam-ple, in email marketing, marketers control the time and frequencyand typically limit the frequency to avoid spamming users. In paidmedia, marketers only need to change the non-impression-levelbid, e.g., cost-per-click (CPC) bid as the impression-level responseis taken care of by the ads platform. For these reasons, LP is wellsuited for marketing AI use cases.",
  "Besides the marketing cost and business constraints on the": "\"space\" dimensions, there are implicit constraints on the \"time\"dimension, particularly for each marketing unit. The time windowto attract and convert a potential user is typically limited. Moreover,a marketing action taken at a given time point can impact the statusand best marketing action to take at the next time point. We canleverage Reinforcement Learning (RL) to address optimization on\"time\" dimension. Contextual bandits can be used to balance theexploration and exploitation. Q-Learning can be used to help ndan optimal sequence of marketing actions to maximize value for agiven marketing unit.",
  "To summarize, the optimization module addresses the resource": "limitation problem. As a general principle, we recommend LP whenthe resource limitation across marketing units is strict and thereare less frequent marketing interactions, and recommend RL whenthere are more frequent marketing interactions and less constraintsacross marketing units (or these constraints can be taken care of byother parts of the system). We note that these two techniques are notmutually exclusive and can be combined. For example, we can focuson \"space\" constraints and use an LP formulation, while simplifyingthe time horizons resolution to an LTV prediction. We can alsofocus on \"time\" horizons and use an Q-learning formulation, whiletransforming the cost constraints implicitly to reward shaping. Weargue that the former combination are often preferred in marketing,since marketing use cases are typically less frequent interactionwith strict cost constraints.",
  "One important class of AH is Feedback Loop Controllers for busi-": "ness constraints (green boxes as shown in ). Since the mar-ket is dynamic and the marketing AI system can have errors (e.g.,prediction error), the observed cost 0 may be greater (violation) ormuch less (under-utilization) than the budget. To minimize under-or over-utilization, we can continuously monitor the performanceand build a lightweight controller, = 6(,0), to update asthe input to the optimization module instead of the original .",
  "Guidelines and Examples": "NOAH is a general framework for marketing AI systems. Ideally,we would like to perform joint optimization for multiple types ofmarketing actions, e.g., product, timing, frequencies and content.However, this is often infeasible due to reasons such as infrastruc-ture constraints, operational convenience, or limitations in the MLmodels or optimization solvers. As a workaround, we can use thesame NOAH framework and perform optimization in a cascad-ing/sequential manner for dierent types of marketing actions. Forexample, we can rst decide the product for each marketing unit,then optimize the timing and frequencies, and nally choose the",
  "Bidding Optimization Example. For bidding, advertisers can": "receive hourly or daily ads winning performance metrics G?, forexample, average position for each keyword, or impression winningpercentage for each campaign. One can build a series of modelsto predict: number of clicks ~clicks = 5clicks(GD,G?), cost per click~cpc = 5cpc(GD,G?), conversion rate ~cvr = 5cvr(GD) and revenueper conversion ~rpc = 5rpc(GD). Note that we can assume ~cvr and~rpc do not depend on ads winning performance as they happenafter users click the ad and land on the landing page. Typically, ad-vertisers want to maximize revenue while maintaining certain levelof return-on-ad-spends (ROAS). The corresponding constrainedoptimization formulation could be:",
  "D,? = 5clicks(GD,G?)5cpc(GD,G?)": "The constrained optimization problem can be solved with the ef-cient algorithm in Appendix A.1 if the scale is large. Once thedesired optimal G? is obtained, we can calculate the optimal CPCbid as 0D = 5cpc(GD,G?), which can be directly used in rst priceauction platforms, or as the expected-cost-per-click (ECPC) bid insecond price auction platforms.",
  "d1(~) = G)F + n,n # (0, V2),": "where G = (GD,G0,GD,0) is feature vector that includes features foruser GD, features for creative G0, and features for the user-creativeinteraction GD,0, d() is a link function, and ~ is observed reward.Online updates for the posterior distribution of F8 # (`F8, f2F8 )can be computed eciently using factor graph and expectationpropagation (see algorithm details in Appendix A.2). Thompsonsampling can then be employed to obtain predicted rewards fordierent creatives, and show users the creative with the largestreward on the landing pages.",
  "Email System": "We can think of the email marketing system as a two-stage recom-mender system: candidates retrieval followed by email optimization( in Appendix). In the candidate retrieval stage, marketerscreate email marketing campaigns for dierent products and denethe audience list for each campaign. In the email optimization stage,ML models are used to nd the best marketing emails for a selectedgroup of members, so as to optimize metrics while minimizingnegative member experiences like spamming. The whole systemruns in batches, with emails sent out at regular time intervals (e.g.,weekly). The system seeks to maximize value for LinkedIn while re-specting multiple business constraints. Some constraints are global,e.g., the total number of user unsubscriptions should be less thana certain value each week, while other constraints are local, e.g.,each member cannot receive more than certain number of emailseach week.",
  "Prediction with LTV": "LinkedIn faces distinct challenges in predicting marketing perfor-mance due to the dierent nature of 2C and 2B segments, particu-larly the extended decision-making processes and delayed feedbackfor 2B products. To overcome this, we create separate models forpredicting short-term metrics and LTV, then integrate the resultsto estimate the long-term metric. Here, the long-term metric @C is a numeric measure dened by marketers reecting marketingperformance over an extended period C, with short-term metricsrepresenting observable metrics within a brief timeframe, like con-version and unsubscription. Notably, conversion is typically deneddierently for 2B and 2C products. In 2B, it often refers to the sub-mission of a qualied lead, whereas in 2C, a conversion can bemarked by a customer signing up for a free trial.",
  "D,0= 5unsub(GD,G0,G2),": "where ~conv and ~unsub represent the predicted conversion prob-abilities and unsubscription probabilities respectively, GD denotesthe feature vectors of users capturing user proles, demographics,and other behavioral data, G0 symbolizes the marketing actions un-dertaken, including the decision to send specic marketing emailsto certain members, and G2 represents other relevant contextualinformation that might inuence the metrics.",
  "Formulating the Constrained Optimization Problem. In our": "legacy system, a ranking heuristic was used in the email optimiza-tion stage. For each member, all candidate emails were ranked by alinear combination of ~conv and ~unsub with xed coecient ^, i.e.,~conv ^~unsub, and top-ranked emails were sent to the memberwith a xed frequency cap. This approach did not optimize the busi-ness goal directly, and business constraints were only consideredimplicitly.",
  "Here we apply the constrained optimization formulation in": ".2.2 to this problem. Let D = 1, . . . ,* and 9 = 1, . . . , index the member and campaigns respectively, and let 0D,9 2{0, 1} denote the binary action decision of whether send email9 to member D. We can estimate the total expected long-term met-ric by",
  "We recognize the optimization problem as an integer linear pro-": "gram (ILP), which can be combinatorially dicult to solve .Instead, we relax the constraints on the 0D,9s to allow them to takeon values in the interval . The resulting problem is a linearprogram (LP) which is tractable (details in .3.2). We caninterpret non-integer 0D,9 as the probability with which we shouldsend an email about campaign 9 to member D.",
  "commercial solvers for solving LPs, the size of the LP for our ap-plication is too large for these solvers. Recall that the optimization": "variable 0 has dimension * , the product of the number of mem-bers and the number of campaigns. For a large social network likeLinkedIn, we could have 10-100 millions of members and hundredsof email campaigns, resulting in tens of billions of variables. Tosolve the LP, we turn to DuaLip , a large-scale LP solverthat we developed at LinkedIn. We briey outline the algorithmhere.",
  "min0~>0B.C.0 1,0D 2 BD, D 2 {1, . . . ,* },(3)": "where 0 = (01,1, ,01, , ,0*, ) 2 R* is the vector of decisionvariables, ~ is the coecient vector for the decision variables inthe objective, is the design matrix in the constraints, 1 is theconstraint budget vector, and BD are additional \"simple\" constraints,i.e., it is ecient to compute the Euclidean projection onto BD.In particular, 1 = (unsub, 2B, 2C), and 0 corresponds tothe left-hand side of the rst three constraints from the previoussection. BD corresponds to the remaining two constraints, i.e., box-cut constraints BD = {0D,9 : 0 0D,9 1 89,",
  ",(5)": "where BD () is the Euclidean projection operator onto BD, andfor a vector I with the same dimensions as decision variable 0, IDdenotes the sub-vector with indices corresponding to member D.Notice that the computation of 0(_) can be parallelized across mem-bers D and the box-cut projection BD can be computed ecientlyby leveraging Wolfes algorithm. As a result, r6W (_) can becomputed eciently. This allows us to use rst-order methods suchas accelerated gradient ascent and L-BFGS to obtain _W, thedual value that optimizes the dual function 6W. From this optimaldual value, we can obtain optimal primal values 0W via (5):",
  "Practical Tips for Implementation. We describe a couple of": "tips that make DuaLip converge much faster. (A) The choice ofW is associated with a critical trade-o: DuaLips solving of (4) isfaster if W is larger, whereas DuaLips approximate solution of (4)in a given number of iterations is closer to the solution of (3) if Wis smaller. For one run, we try a grid of W values and choose thelargest W value such that the regularizer part of the objective is",
  "With Dualip, the primal solution will fall on a vertex of BD": "with high probability when W is suciently small. This meansmajority of solutions are already binary, i.e., in {0, 1}. However,we still need to handle the cases when they are between 0 and 1.Simple rounding may violate the hard constraint fcap. We devise arandomization algorithm, basically sampling the campaign indexeswith probability calculated from the primal solution (Appendix A.3).The randomization also provide additional benet of balancingexploration-exploitation.",
  "Audience Expansion": "In the email marketing lifecycle, dedicated marketing teams fromeach business unit provide a list of candidate members for eachemail campaign. Historically, we have found these candidate mem-ber lists conservative in scope. To address this, we augment theprovided lists with additional members through an Audience Ex-pansion (AE) module in which we retrieve additional memberswho resemble the members provided by the marketing teams andappend them to the candidate lists. We nd such members via anapproximate nearest neighbors (ANN) algorithm.",
  "We have found that as we relax X, there is a trade-o between": "wider campaign reach through increased expansion audience sizeand diminished incremental expansion audience quality. If X istoo large, a portion of the incremental expansion members addedthrough AE are so dissimilar to the campaigns original membersthat they are never chosen by the LP to receive the marketingcampaign. Moreover, the computational runtime of both AudienceExpansion and the LP optimization increase in X, so choosing X toolarge can lead to additional runtime for minimal gain. This latterconcern about computational eciency is especially important at LinkedIns scale. On the other hand, if X is too small then theexpansion audience itself will be too small to produce a signicantgain in downstream metrics of interest. We tune X through oineevaluation to balance these trade-os (Appendix D.3).",
  "Analysis on LP. We nd that smaller W value leads to better": "optimality but can take longer to converge (Appendix D.2.1).We also validated the high probability of binary primal solu-tions (Appendix D.2.2). More importantly, we investigatedthe fallback strategy of using previous dual solution for cur-rent LP, and nd that we can maintain 99% value of theobjective if data distribution is stable (Appendix D.2.3).",
  "Online Test Design": "We design an online A/B test to compare the performance of theNOAH email system with that of the legacy system. In the test,we randomly assigned members to treatment arm (NOAH system)or control arm (legacy system). In addition, we included a thirdexperimentation arm for the legacy system equipped with AE toisolate the impact of increasing marketing email volume on its own.The ow of the test is visualized in .",
  "We compare the means of above metrics from dierent arms for": "statistical testing of treatment eects. It worth noting that long-term metrics exhibit characteristics of a zero-inated heavy-taildistribution (Appendix C.1). We performed simulations on type Ierror and power of t-test against these distributions, and found thatthe standard t-test is actually robust (Appendix C.2). We believethis result is broadly useful, as alternatives do not suit the needsof such testing: (1) Winsorization removes the large data pointsthat actually matter (if not more), (2) Non-parametric tests (e.g.,Mann-Whitney U test) lack a corresponding treatment eects.",
  "Overview. The A/B test results in major wins, one of the": "largest in Linkedin algorithmic marketing thus far. An overviewof the results is presented in . All the numbers in the tablesrepresent relative dierence over the control arm, i.e., ratio of thedierence (between the treatment and control arms) to the meanvalue in control. Results that are not statistically signicant aremarked either \"neutral\" or \"not stat sig\".",
  "Product Type Breakdown. Historically, we have faced chal-": "lenges in developing a unied marketing system which optimizesmarketing emails for a heterogeneous suite of 2C and 2B products.Our legacy marketing system tends to optimize for quick sign-up2C products in spite of these products relatively small lifetimevalues. On the other hand, campaigns associated with high-LTV 2Bproducts tend to be neglected.",
  "A breakdown of comparison between NOAH and control into": "2C and 2B product types is presented in . We observe thatNOAH is able to drive a large positive lift in both Surrogate Index(+13.21%) and total Conv (+13.30%) for high-LTV 2B products with-out sacricing these metrics for 2C products. It achieves this lift byincreasing total 2B conversions and shifting the distribution 2B con-versions toward those with higher Surrogate Index, as visualizedin Appendix .",
  "CONCLUSION": "In this paper, we introduce various challenges faced when buildingan intelligent marketing system and propose a general framework,NOAH, to address these challenges. We give guidelines on how toapply the NOAH framework and provided a few high-level exam-ples. In addition, we report a large-scale application of NOAH toLinkedIns email marketing use case. We discuss important innova-tions and learnings in the implementation and share results of themajor wins for the corresponding online A/B test.",
  "B.1Feedback Loop Controller": "Controllers can observe the feedback from the marketing units, andis able to adjust input to the main optimization module, so as tostabilize it when there are deviations on the constraints. This isparticularly useful when we have strict constraints, e.g., marketingbudgets/cost. Technically, this can be achieved either by a Propor-tionalintegralderivative (PID) controller and/or a lightweightreinforcement learning (RL) model. shows the overall ow.",
  "The model used in the objective is typically the revenue on bud-": "get changes ~0 = 50(GD,G0D,G2), where either traditional MediaMixed Models (MMM) or modern causal ML methods can be used.Among the constraints, the cost model ~1 = 51(GD,G0D,G2) can ei-ther use learned or rule-based 51(.) (e.g., assuming cost equals xedproportion of budget) depending on the maturity of the optimiza-tion engine. The constrained optimization problem is small-scale,so we can typically use o-the-shelf solvers to solve the originalinteger program without LP relaxation.",
  "The null model is simulated by setting = 0 and ? = 0. Besides": "varying the size of the test (U), we also (i) vary ?0 at 0.02 and at 0.8,(ii) vary distribution of - 0 at %obs and %ln. Here %obs is empiricaldistribution of positive Surrogate Index in AB test, and %ln is lognormal distribution with `(log(- 0)) = 2 and f(log(- 0)) = 2. Weperform t-test on the simulated samples and calculated the esti-mated type 1 errors. We can see type 1 errors are well controlled asshown in .",
  "models ~convD,0= 5conv(GD,G0,G2) and ~unsubD,0= 5unsub(GD,G0,G2)": "using standard oine metrics for binary classication models, suchas area under the ROC curve (AUC) and area under the precision-recall curve (AUPR). Average values for these metrics are providedin . ROC curves for representative training runs of 5convand 5unsub, respectively, are shown in . These models arere-trained on a regular cadence to account for distributional shiftsresulting from evolving member engagement patterns and updatedmarketing campaigns.",
  "We also evaluate the calibration performance of our propen-": "sity models, as their output estimates serve as the inputs to theLP. Miscalibration in these estimates can distort the LPs abilityto optimize accurately, leading to sub-optimal downstream per-formance. In practice, we nd varying calibration performancefrom our propensity models. To address this, we can include anadditional calibration layer via isotonic regression to improve cali-bration performance. We can then monitor oine metrics such asBrier score and log-loss before and after calibration to validate theimprovement. An example calibration plot for 5unsub is shown in.",
  "To handle \"censored observations\" for recent conversions, we": "leverage auxiliary tasks modeling metric observed for 1 month,3 month and 6 months, i.e., @1, @3 and @6, and use the predictedvalue from auxiliary tasks as input to the main task. We found thatmodel with auxiliary tasks has lower prediction error and moreimportantly, can respond faster to evolving trends on long-termmetric as shown in .",
  "0)/(1 + |18 |)} that says how much the 8-th": "constraint is violated. With many constraints, we can dene asingle violation score called feasibility as max8 E8. givesthe DuaLip trajectories (primal objective, feasibility) for various Wvalues. The vertical line denes the maximum allowed feasibilityviolation for our application. Thus, even though during a large partof an optimization trajectory the primal objective has large values,they are unacceptable from the feasibility angle. We would choosethe point having the largest primal objective among the acceptablefeasible points to the left of the vertical feasibility line. As expected,smaller W values yield much better solutions.",
  "shows the relative number of members that receives": "0, 1 and 2+ Emails. It worth noting that the comparison is basedon counterfactual audience from AE (details in 4.2). We can seethat the rate of sending \"0 Emails\" is much higher for the twoscenarios that utilized LP (+92% for NOAH without AE and +158%for NOAH). This indicates that LP optimization can make ecient\"not-send\" decision, so that it can reduce spamming and improvemember experience. In fact, the ranking heuristics itself cant make\"not-send\" decision at all.",
  "From , we can see that NOAH without AE can reduce": "Unsub rate by 9%, but only improved long-term metric by 2%. Thissuggests that LPs potential is limited by the original lists audiencecoverage. Meanwhile, with AE widens the top funnel, Legacy rank-ing system could not control Unsub rate (+9%). It is the combinationof LP and AE that realize the optimization of long-term metrics(+7%) without negatively impacting member experience."
}