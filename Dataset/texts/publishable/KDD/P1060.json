{
  "ABSTRACT": "As its availability and generality in online services, implicit feedbackis more commonly used in recommender systems. However, implicitfeedback usually presents noisy samples in real-world recommen-dation scenarios (such as misclicks or non-preferential behaviors),which will affect precise user preference learning. To overcomethe noisy sample problem, a popular solution is based on drop-ping noisy samples in the model training phase, which follows theobservation that noisy samples have higher training losses thanclean samples. Despite the effectiveness, we argue that this solu-tion still has limits. (1) High training losses can result from modeloptimization instability or hard samples, not just noisy samples.(2) Completely dropping of noisy samples will aggravate the datasparsity, which lacks full data exploitation.To tackle the above limitations, we propose a Double CorrectionFramework for Denoising Recommendation (DCF), which containstwo correction components from views of more precise sampledropping and avoiding more sparse data. In the sample dropping",
  "This work is produced during a research intern at Tsinghua University.Equal Contribution.Corresponding authors": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,to post on servers or to redistribute to lists, requires prior specific permission and/or afee. Request permissions from , August 25-29 2024, Barcelona, Spain 2024 Association for Computing Machinery.ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00 correction component, we use the value of the sample loss overtime to determine whether it is noise or not, increasing stability.Instead of averaging directly, we use the damping function to re-duce the bias effect of outliers. Furthermore, due to the highervariance exhibited by hard samples, we derive a lower bound forthe loss through concentration inequalities to identify and reusehard samples. In progressive label correction, we iteratively re-labelhighly deterministic noisy samples and retrain them to further im-prove performance. Finally, extensive experimental results on threedatasets and four backbones demonstrate the effectiveness and gen-eralization of our proposed framework. Our code is available at",
  "INTRODUCTION": "Recommender systems often use implicit feedback (e.g., click, watch,and purchase) to learn user interests and recommend items, whereusers implicit feedback is thought to reflect users true prefer-ences . However, here are some excep-tions. For example, a user may purchase and return an item or clickon a video but the dwell time is very short, thus the purchasingand clicking behavior may not represent users interests, whichis referred to noisy interaction by recent research . Recentresearch refer to this type of interaction as noisy interaction.Treating these noisy interactions as clean interactions may get sub-optimal performance . Therefore, how to eliminate the",
  "(b) Different strategies in their idealcases": ": (a) Illustration of unstable losses. We observe thatclean samples do not exhibit low loss in every epoch. Sim-ilarly, noisy samples do not always exhibit high loss. Also,hard samples exhibit high losses. However, the noisy sam-ples can be identified from the perspective of mean loss.(b) Different strategies in their ideal cases. Explain the dif-ference between our relabeling strategy and other strategiesunder ideal conditions. Here, the TP, TN of T stands for true.Similarly, F stands for false. adverse effects of noisy interactions has attracted a broad interestfrom the research community.Although some noisy interactions may be detected by multi-ple behaviors (e.g., explicit feedback), we cannot guarantee thatother behaviors validate every interaction due to the sparsity ofuser behavior. Additionally, the request for explicit informationis expensive as it may hurt the user experience. Thus, it is im-portant to discover noisy interactions based on their unique datapattern, which has also received much attention in recent years. Acommonly observed pattern, which is also the basis of most cur-rent work , is that the loss values for noisy interactionsare generally higher than for clean ones during training. Hence, astraightforward solution is to use loss values as a distinguishingfeature to process samples with high losses. For instance, directly and dynamically drops samples with high losses duringtraining, achieving notable results.Despite the notable performance, we argue that current meth-ods have two limitations that may hinder effectiveness.(1) They ignore that losses may not be highly correlated with noise,i.e., the instability of optimization and the hardness of clean inter-actions. Firstly, the instability in the optimization process may leadto sharp changes in the immediate loss values of the sample, whichmay show a contrary phenomenon to the above basis. As illustratedin (a), noisy samples also show lower training loss sometimes,and vice versa, which leads to incorrect dropping and may hurtthe performance. Secondly, hard samples also typically show highloss and could be dropped along with noisy samples. Abandoningthese hard samples may lead to suboptimal performance as they areinformative and beneficial for recommendation performance .(2) Simply dropping samples may lead to more sparse data. As illus-trated in (b), although the noisy interactions are mislabeled,they are still part of the training space. Merely dropping these noisy samples leads to sample wastage, as well as potentially causing thetraining space to be inconsistent with the ideal clean space.To address these limitations, we explore potential solutions andthe corresponding challenges. For the first point, we attribute thelow correlation between loss and noise to limited observations ofcurrent model predictions and the neglect to consider hard samples.Hence, we expect to stabilize the models predictions by extendingthe observation interval and aggregating loss values from multipletraining iterations. In addition, high-loss samples might be hardsamples beneficial for training. Therefore, we aim to identify andretain these hard samples to enhance recommendation performance.However, how to efficiently and simply identify hard samples isstill challenging. For the second point, we argue that even if noisysamples, have corresponding correct labels and cannot be merelydropped from the sample space, which would result in more sparsespace. Hence, we would like to relabel and reintroduce part of noisysamples that are highly determined to be noise into the trainingprocess. And we illustrate in (b) how relabeling addresses theissue of sample waste caused by drops. However, there is a practicalchallenge in determining which samples need to be relabelled andthe proportion of relabelling during model training.In this paper, we propose a Double Correction Framework forDenoising Recommendation (DCF). The core of this framework issample dropping correction and progressive label correction, whichare designed for the above two limitations respectively. Sampledropping correction combines confirmed loss calculation and cau-tious hard sample search to accurately drop noisy samples andretain hard samples. Specifically, we calculate the mean loss ofsamples over a time interval and robustly compute each loss valueusing damping functions to mitigate the effects of occasional out-liers. Inspired by , hard samples have a higher loss variance thanclean and noisy samples. In other words, the loss value of hardsamples has a lower bound in terms of the whole training process.Therefore, we use concentration inequalities to derive confidenceintervals for each samples loss value. Then we use the lower boundof the calculated confidence interval as a hard sample search cri-terion. In this way, hard samples are retained for training insteadof being dropped. In the progressive label correction component,we believe the stability of the model optimization process increasesgradually , so the models relabeling strategy should adapt tothis characteristic. Specifically, we initially relabel a small fractionof the samples and progressively increase the proportion of relabel-ing as training proceeds. Note that we still drop samples with highloss values and just relabel a fraction of the samples with highlydetermined to be noisy.To summarize, our main contributions are as follows: We analyze two limitations of the loss-based dropping recom-mendations, (1) loss values are not highly correlated with noise,and (2) complete dropping of noisy samples, which leads to moresparse data space.",
  "TASK DESCRIPTION": "We first give a formal description of the denoising recommendationtask. We use U to denote users, P to denote the item,and observed interaction matrix Y R|U|| P|. And where = 1means that the user interacted with the item, and = 0 meansno interaction. In previous work, the default assumption is thatwhenever = 1, it means that the user likes the item. However,user interactions may be due to various noises (i.e., clicking on avideo by mistake or clicking on a video for a very short time toexit), resulting in users not liking the interacted item. Therefore,the target of denoising recommendations is to develop a model with parameters to learn noise-free representation of users anditems from noisy data Y. The training of denoising recommendationmodel is formulated as follows:",
  "THE PROPOSED FRAMEWORK3.1Overview": "Our framework DCF (as shown in (c)) is developed on acommon observation: noisy samples usually incur high losses .However, on the one hand, the model optimization is usually un-stable, and hard samples also show high losses; on the other hand,some methods directly drop samples with high loss valuesfor simplicity. Such actions may lose feature information and de-grade performance. To mitigate these limitations, we design twocomponents (as shown in ): sample dropping correction and progressive label correction. The first component, sample droppingcorrection, aims to correct unstable loss values as model randominitialization parameters and unstable optimization processes. Inaddition, we also calculate the confidence intervals for each sampleloss and use the lower bound as our dropping strategy. This methodaims to retain hard samples because hard samples enhance modelperformance by exposing edge cases and revealing more profoundinsights into data patterns . Additionally, for those samplesthat are highly determined to be noise, the second component,progressive label correction, relabels these and adds them to thenext training iteration to improve performance further. Based onthese two components, our framework mitigates the adverse effectsof noisy interactions more effectively. The complete algorithmicprocess is at Algorithm 1.",
  "Sample Dropping Correction": "Due to the instability of the optimization process and randomness ofthe initial weights. As shown in (a), true positive interactionsmay exhibit high loss at some time points, while noisy interactionsmay exhibit low ones. Fortunately, we also observe that the sampleloss can be more stable by replacing the loss value at a singletime point with the mean loss over time. Thus, inspired by this,we estimate the sample loss using a confirmed approach. Besides,samples that perform with high loss may also be hard samples,which can enhance the model performance . In a word, our goalin this subsection is to drop the noisy samples more accurately, findthe hard samples, and retain them. 3.2.1Confirmed Loss Calculation. Relying only on empiricallosses calculated from a single training iteration may incorrectlydistinguish between noise and clean, thus degrading performance.Therefore, we consider the loss values across previous trainingiterations to mitigate misjudge. Specific practice is to use the meanof losses at different iterations.",
  ": Details of Loss & Label Correction": "where we calculate the mean loss value over time intervals priorto the -th training iteration (including the -th). And if the currentiteration is less than 1 times, is the mean of all losses up tothe current iteration . However, during the training process, themodel may encounter extreme loss values. Although this possibilityis unlikely, to avoid negative impacts when calculating means, weneed to take defensive measures for robust computation. Thus,instead of calculating the mean directly, we robustly process eachloss. After that, we obtain the mean as follows:",
  "=+1(()),(2)": "where, the non-decreasing damping function () is used to calcu-late mean values more robustly. The specific forms are as follows:() = log 1 + + 2/2 .The advantages of the damping function include: (1) Reduced impact of extremes. The damping function grows slowly at verylarge loss values because it is logarithmic. These large values maybe outliers due to unstable model predictions from noisy samples.Therefore, the effect of extreme values is reduced when the meanis calculated afterward. (2) Approximate linearity at small values.At small values, () can be approximated as linear function. Thismeans that near small values, () does not have side effects on theloss values, preserving the original. 3.2.2Cautious Hard Samples Search. We argue that droppingsamples with higher mean loss still leaves room for potential im-provements. This is because a higher mean sample loss does notnecessarily indicate noisy samples; they could be hard samples. point out that the hard samples contain more information than thesimple ones. Thus we aim to search and retain hard samples. Oursearch strategy is based on the observation that hard samplesexhibit higher variance in loss values during training. Consequently,we compute the lower confidence interval bound for the loss by Con-centration Inequalities . Because, for noisy samples, the lowerbound of the loss confidence interval usually closely matches theactual loss value. However, for hard samples with high variance,the confidence lower bound tends to be lower. Therefore, in oursample dropping and subsequent relabeling strategy, we use the",
  ",(3)": "with probability at least 1 2.There are other methods to filter out the hard samples, suchas gradient and cluster . Compared to these methods,our framework has the following advantages. (1) Intuition. Lowerbound, as a basic statistical concept, can intuitively reflect the de-gree of data dispersion. For hard samples, their loss values fluctuatemore during the training process, and thus the lower bound islower. (2) Computational efficiency. The low complexity of com-puting lower bound is suitable for large-scale datasets. Comparedto other selection methods, the lower bound of sample loss providesa simple and efficient strategy.Let, = 1",
  ",(4)": "where represents the number of times a sample has not beendropped. Intuitively, the smaller is, the lower the confidence inter-val bound will be. We prioritize reincorporating samples with lowerconfidence interval bounds (i.e., higher variance) into training. Inaddition, the search intensity is retained through an adjustmentfactor, 2, that reduces the noisy samples adverse effects and in-creases the model performance. It is important to note that we arenot selecting samples based on their loss values but rather basedon the lower bound.Through the sample dropping correction strategy, we achievehigher confirmed sample loss values and effectively search andretain hard samples, further enhancing the model performance.",
  "Progressive Label Correction": "Compared to directly dropping noisy samples. We argue that thesmall fraction of samples with the highest loss 1 can be leveraged ina relabeling way. Relabeling noisy labels preserves samples ratherthan dropping them, providing more training samples. This is valu-able for sparse recommendation datasets, which makes the entiretraining sample space and test set space more consistent. More-over, relabeling is a simple operation that does not require complexreweighting strategies or other processing techniques. Therebyfurther training the model adequately to improve its performance.In addition, since the predictive stability of the model improvesincrementally during training, we argue it is reasonable to relabelmore in the later stages and less in the earlier stages. From thebeginning to the end of the training, we progressively increasedthe percentage of relabeling.",
  ", ),(5)": "where denotes that the flipping rate remains constant after the-th epoch, and is the percentage we end up relabeling. This way,we get each epochs relabeled ratio . And the corresponding lossthreshold of the samples to be labeled is = [(1 )]. is a downward rounding operation. If the is greater than , theindicator I(,) is 1.",
  "= + I( ,) (1 2),(7)": "where we relabel the original label from to . After carefulprocessing, we relabel these noisy labels to ensure they are closer tothe true ones. This step not only enhances the data quality but alsoprovides more accurate labels for subsequent model optimization,which is expected to improve the effectiveness.Through the progressive label correction strategy, we have avoidedsample waste, thereby providing more data for the precise modelingof users and items.",
  "Model Discussion": "This section compare different recommendation models based ontheir space and time complexities. The comparison is summarizedin . In addition, we discuss the improved features of DCF tothe previous dropping approach T-CE . Space Complexity. The space complexity of each model is deter-mined by the number of parameters, denoted as . The base modeland T-CE model have the same space complexity of since T-CEdoes not add any new parameters or structures. However, BODincludes a weight generator with an encoder layer R2 and a decoder layer R1, where is the embedding size ofuser and item in the recommendation model, and is the hiddenlayer size of the generator. On the other hand, DCF introducesadditional computations like confidence bounds of the loss but doesnot add new model parameters, meaning its space complexity isalso . Time Complexity. Regarding time complexity, the base modelcomputes the loss directly in O() time, where is the number ofsamples. T-CE sorts the computed loss, resulting in a time complex-ity of O( log). BOD involves bi-level optimization, leading toa time complexity of O + + . Our proposed methodincludes multiple steps like computing confidence bounds, soft pro-cessing, and sorting. Sorting is the dominant factor here, leading toa time complexity of O( log).",
  "DCF (Ours)O( log)": "In-depth Comparison. The T-CE method overlooks the potentialof hard samples, possibly hindering model performance. Our cau-tious hard sample search, however, recognizes the value in thesesamples. By focusing on the lower bound of loss rather than justmean loss, we can better differentiate between noise and hard chal-lenges. This approach ensures we capture the full learning spectrum,addressing T-CEs limitation.",
  "Experimental Settings": "4.1.1Datasets. We conduct extensive comparative experimentson three public popular datasets: Adressa2 , Movie-Lens3 , Yelp2 . Detailed statistics of the datasetsare in . For getting clean test datasets, we only include inter-actions with a dwell time of at least 10 seconds, based on in Adressa. For MovieLens, we create a test set that only includesinteractions with a rating of five, following the setting from .Similarly, for Yelp, we refer to and only include interactionswith a rating higher than three in our clean test set.Note that to maintain consistency with the settings of previousdenoising works and ensure fair performance compar-isons. All ratings and dwell times filter the clean test set, while thetraining and validation sets are not filtered. 4.1.2Evaluation protocols. We follow to split datasetsinto the training set, validation set, and clean test set with theratio 8:1:1. Following existing works on denoising recommenda-tions , we report the results w.r.t. two widely used metrics:NDCG@K and Recall@K, where higher scores indicate better per-formance. For a comprehensive comparison of different models, weset K=5 and K=20 for all datasets. Each experiment is repeated fivetimes, as well as we conduct a significance test on the results of theexperiments. In addition, limited by the page length, we place thedetailed parameter setting at A.2. 4.1.3Baselines. Our goal in this paper is to weaken the adverse im-pact of noisy interactions on model performance. For this purpose,we choose four backbones based on implicit feedback: GMF : This generalized version of matrix factorization cap-tures the latent factors of users and items.",
  "Performance Comparison (RQ1)": "To validate the effectiveness and generalization of our framework,we conduct extensive experiments on four popular backbones andthree datasets. shows the results of our DCF with existingdenoising methods. Indices that perform the best are in bold, whilerunner-ups are underlined. According to , we can draw thefollowing observations and conclusions: DCF achieves good performance on all backbones and datasets.We attribute these improvements to the extended observationof sample loss values, searching for valuable hard samples, andrelabeling some highly discriminated noisy samples. After re-labeling, these samples can be utilized to avoid performancedegradation due to sparse sample space. However, baseline mod-els such as BOD and DeCA lack these capabilities, making themless effective than ours. We observe that T-CE is second only to us on most datasets andbackbone, whereas the other DeCA and BOD are not as goodas T-CE. T-CE directly drops the high loss samples, whereasDeCA and BOD do not utilize the high and low loss phenom-ena. The results are consistent with previous studies .Furthermore, DeCA is based on the prediction agreement ofthe two models, and BOD is based on bi-level optimization, andwe speculate that the suboptimal performance because they areboth unstable in training. Hence, we argue that using loss valuesis a straightforward and efficient method. In other baselines, the BOD is second only to us in Yelp. Wethink this is because the bi-level optimization of BOD requiresmore density data in order to better learn the weighting matrixinvolved. Whereas WRMF sometimes achieves good results, wespeculate it is because matrix factorization has better effectson sparse data. We also note that on the MovieLens dataset,other denoising methods do not outperform normal training.We argue this is because on sparse datasets, these reweightingor dropping strategies may be less effective due to inadequaterepresentation learning, which leads to true-positive samplesbeing mistakenly down-weighted or dropped.",
  "Model Investigation (RQ2)": "4.3.1Ablation Study. DCF consists of three components, Con-firmed Loss Calculation (CL), Hard Sample Search (HS), and Pro-gressive Label Correction (LC). We are eager to validate the effec-tiveness of each component and the combination between them onthe performance. Therefore, we conduct the following seven setsof ablation experiments (as shown in Tabel 4). However, due to thelength of the paper, we only show results on the MoiveLens dataset",
  "Double Correction Framework for Denoising RecommendationKDD24, August 25-29 2024, Barcelona, Spain": "Drop-based Methods. An intuitive idea is to pick out the clean in-teractions and send them for training. Then, distinguishing betweenthe characteristics of clean and noisy samples is critical. T-CE observe experimentally loss values of noisy samples are higherthan clean samples, and experiments using this observation find iteffective. Subsequent studies incorporate this observationinto the design of denoising recommendation models. For example,AutoDenoise considers the denoising work to consist of twobehaviors: searching and deciding. So they use reinforcement learn-ing to automate these two behaviors. Additionally, proposesto augment recommendation algorithms with noisy examples ofuser preferences and mitigate the challenge of data sparsity. Reweight-based Methods. In addition to selecting clean samples,some work reduce the weights on the noisy samples,which reduces the impact on model parameter updates and avoidsthe reduction of generalization ability. For example, R-CE uti-lizes the loss value as a denoising signal, thus assigning a smallweight to the noisy sample. AutoDenoise also utilizes the lossvalue as a denoising signal and fuses it with the user representationand item representation in the weight calculation with good results.BOD converts the learning of weights into a bi-level optimiza-tion problem and uses a simple and elegant solution to learn theweight parameters with relatively good results. Other Methods. First, methods inspired by the phenomenon ofnoisy samples during training. For example, DeCA observesthat different models have greater predictive divergence for noisysamples and lesser divergence for clean samples. SGDL ob-serve the memorization effect of noise, thus removing noise in thepre-training period. Thus based on this observation, an efficientdenoising recommendation model is designed and performs well.Second, there is also some work to denoise based on graph collabo-rative filtering, e.g., RGCF , RocSE . Their methods maindesign idea lies in removing noisy interaction edges. RocSE removes the noisy interactions from both graph structure denoisingand contrastive learning and performs well on graph collaborativefiltering. Third, some methods to denoise in specific recommen-dation scenarios, design denoising modules for scenarios such asmovies , music , and social . As well as exploring theremoval of noisy samples in sequential recommendation . Comparison with Our Method. We argue that the loss-basedmethod is a simple and effective approach but suffers from predic-tive instability due to random initialization of parameters. Further-more, both the dropped sample and reweighted sample strategiesbased on loss values design have inherent flaws. For example, itleads to misalignment of the training and testing spaces or the needfor complex methods to learn the weights. Therefore, we considera more robust loss value calculation as well as relabeling.",
  "DCF (Ours)0.12580.2274*0.0961**0.1315*0.0365*0.10500.0472*0.0659*0.0192*0.0523*0.0187**0.0296**": "and GMF, and other datasets are similar and omitted. In addition,we also conduct ablation experiments on damping function in A.3.1.We observe better results from more components, which alignswith our expectations. We analyze this trend in effectiveness asbeing attributable to each component playing its desired role. In thesingle component section, we observe the best results for DCFHS.This proves that we obtain hard samples by deriving a confidencelower bound on the loss. In addition, DCFLC also achieves goodperformance, which is attributed to the fact that we let the cor-rected samples be retrained to avoid sample wasting, as well asmisalignment of the training and testing sample spaces. Also, inthe combination of components, HS and LC achieved excellent re-sults, proving the effectiveness of the two-by-two combination. It isworth noting that the combination of CL and HS does not achievemore significant results. We hypothesize that the reason for this isthat the search for HS is a game of risk and benefit, and therefore,we have to tune the hyperparameters carefully. 4.3.2Parameters Sensitivity Analysis. We are eager to know thesensitivity of different critical parameters: (i) relabeling ratio ;(ii) discretion level 2 of searching hard samples; (iii) calculatingtime interval of mean losses. Experiments are conducted on theMovielens dataset. As shown in , we can find that:",
  "DCFALL0.0471(25.9%) 0.0789(7.5%) 0.0553(8.6%) 0.0621(5.1%)": "NDCG@5 and Recall@5 are affected by the hyperparameters,and the overall trend is up and then down. We observe that theperformance is not getting better as the flip rate increases. Wespeculate that this is because only a tiny fraction of the highestloss samples are strongly correlated with the noisy samples, andthus more flips may lead to more errors.",
  "Hard Sample Search Strategy (RQ3)": "Despite confirming the effectiveness of hard sample search in ourablation experiments, we aim to ascertain whether the identifiedsamples are indeed hard samples rather than noisy samples. There-fore, we design a comparative experiment. The first group is touse the searched samples for T-CE training. The second group isto randomly sample the same size of samples from the droppedsamples for training, and the third group is not to use the originaltraining of both samples to compare the performance of these three.Experiments are conducted on three datasets and two backbones.From , we observe that adding hard samples improves modelperformance, which is consistent with our expectations. This isdue to the efficient identification of noisy samples through ourlower bound on loss. In contrast, adding random samples from thedropped samples to the model does not enhance the recommenda-tion model performance but has a negative impact. : Comparison of flip accuracy between progressivelabel correction and fixed. For a clear presentation, we usea violin plot here. Additionally, we mark the average flipaccuracy of fixed with a red line to clearly highlight thesuperiority of our progressive strategy.",
  "Progressive Strategy in Label Correction(RQ4)": "We have demonstrated the effectiveness of progressive label correc-tion in the ablation section. However, we are interested in gaininga more detailed understanding of our strategys performance, par-ticularly regarding flip accuracy. We also wish to determine if ourprogressive relabeling approach is superior to fixed relabeling meth-ods. The results of the experiment are shown in . From the two figures, it can be observed that the flip accuracy ofprogressive label correction is significantly higher than that ofthe fixed strategy (red lines). We attribute this to our dynamicrelabeling ratio strategy, better suited for transitioning from in-stability to stability training characteristics. In the early stagesof training, the model may be more susceptible to the interfer-ence of noisy labels, which could impact its final performance.However, in the later stages, the accuracy of the progressiverelabeling decreases slightly. We presume that this is becausethe model already has enough information, and there is a slightoverfitting phenomenon. We also observe that the stability of the flip accuracy in theprogressive strategy increases as training iterations progress andultimately maintain a high level. Additionally, in the beginning,even if we flip a small proportion, the volatility is still high. Ifwe were to flip a larger proportion, there is a high likelihoodof introducing incorrect information. This further validates theeffectiveness of our strategy of gradually increasing the flip ratiofrom low to high.",
  "RELATED WORK": "Recommendation systems based on implicit feedback have attracteda lot of attention. However, recent studies point out implicit feed-back is easily vulnerable to users unconscious behaviors and vari-ous biases (e.g., popularity bias, position bias, etc.), which degradethe generalization ability. Thus to weaken the problem caused bynoisy implicit feedback, some denoising methods have been proposed, and they can be categorized into sampledrop , sample reweight ,and other methods designed with the help of other information.",
  "CONCLUSION": "In this paper, we present a novel framework named DCF, designedto mitigate the adverse effects of noisy samples on the representa-tion learning of users and items. The DCF contains two modules.The first module, sample dropping correction, achieves more sta-ble loss estimations by calculating the mean loss value of samples and focuses on identifying and retraining hard samples. The sec-ond module, progressive label correction, we relabel samples with ahigher likelihood of being noisy and reintegrate them into the learn-ing process. Extensive experiments on widely used benchmarksand datasets demonstrate the effectiveness and generalization ofour proposed framework. This work is supported by grants from the National Key Researchand Development Program of China (Grant No.2021ZD0111802)and National Science Foundation of China (Grant No.U23B2031,No.721881011, No.U21B2026).",
  "Haoyue Bai, Min Hou, Le Wu, Yonghui Yang, Kun Zhang, Richang Hong, andMeng Wang. 2023. GoRec: A Generative Cold-start Recommendation Framework.(2023)": "Haoyue Bai, Min Hou, Le Wu, Yonghui Yang, Kun Zhang, Richang Hong, andMeng Wang. 2024. Unified Representation Learning for Discrete Attribute En-hanced Completely Cold-Start Recommendation. IEEE Transactions on Big Data(2024), 112. Miaomiao Cai, Min Hou, Lei Chen, Le Wu, Haoyue Bai, Yong Li, and Meng Wang.2024. Mitigating Recommendation Biases via Group-Alignment and Global-Uniformity in Representation Learning. ACM Transactions on Intelligent Systemsand Technology (2024).",
  "Peng Chen, Xinghu Jin, Xiang Li, and Lihu Xu. 2021. A generalized catonism-estimator under finite -th moment assumption with (1, 2). ElectronicJournal of Statistics 15, 2 (2021), 55235544": "Quanyu Dai, Yalei Lv, Jieming Zhu, Junjie Ye, Zhenhua Dong, Rui Zhang, Shu-TaoXia, and Ruiming Tang. 2022. LCD: Adaptive Label Correction for DenoisingMusic Recommendation. In Proceedings of the 31st ACM International Conferenceon Information & Knowledge Management. 39033907. Jingtao Ding, Yuhan Quan, Quanming Yao, Yong Li, and Depeng Jin. 2020. Simplifyand robustify negative sampling for implicit collaborative filtering. Advances inNeural Information Processing Systems 33 (2020), 10941105. Jingtao Ding, Guanghui Yu, Xiangnan He, Fuli Feng, Yong Li, and Depeng Jin.2019. Sampler design for bayesian personalized ranking by leveraging view data.IEEE transactions on knowledge and data engineering 33, 2 (2019), 667681.",
  "Zeno Gantner, Lucas Drumond, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2012. Personalized ranking for non-uniformly sampled items. In Pro-ceedings of KDD Cup 2011. PMLR, 231247": "Yunjun Gao, Yuntao Du, Yujia Hu, Lu Chen, Xinjun Zhu, Ziquan Fang, andBaihua Zheng. 2022. Self-guided learning to denoise for robust recommendation.In Proceedings of the 45th International ACM SIGIR Conference on Research andDevelopment in Information Retrieval. 14121422. Yingqiang Ge, Mostafa Rahmani, Athirai Irissappane, Jose Sepulveda, Fei Wang,James Caverlee, and Yongfeng Zhang. 2023. Automated Data Denoising forRecommendation. arXiv preprint arXiv:2305.07070 (2023). Justin Gilmer, Behrooz Ghorbani, Ankush Garg, Sneha Kudugunta, BehnamNeyshabur, David Cardoze, George Dahl, Zachary Nado, and Orhan Firat. 2021. Aloss curvature perspective on training instability in deep learning. arXiv preprintarXiv:2110.04369 (2021).",
  "Mehryar Mohri, Afshin Rostamizadeh, and Ameet Talwalkar. 2012. Foundationsof Machine Learning. (Aug 2012)": "Rong Pan, Yunhong Zhou, Bin Cao, Nathan N Liu, Rajan Lukose, Martin Scholz,and Qiang Yang. 2008. One-class collaborative filtering. In 2008 Eighth IEEEinternational conference on data mining. IEEE, 502511. Wentao Shi, Jiawei Chen, Fuli Feng, Jizhi Zhang, Junkang Wu, Chongming Gao,and Xiangnan He. 2023. On the Theories Behind Hard Negative Sampling forRecommendation. In Proceedings of the ACM Web Conference 2023. 812822. Abhinav Shrivastava, Abhinav Gupta, and Ross Girshick. 2016. Training region-based object detectors with online hard example mining. In Proceedings of theIEEE conference on computer vision and pattern recognition. 761769. Peijie Sun, Yifan Wang, Min Zhang, Chuhan Wu, Yan Fang, Hong Zhu, YuanFang, and Meng Wang. 2024. Collaborative-Enhanced Prediction of Spending onNewly Downloaded Mobile Games under Consumption Uncertainty. WWW2024,Industry Track (2024). Peijie Sun, Le Wu, Kun Zhang, Xiangzhi Chen, and Meng Wang. 2023.Neighborhood-Enhanced Supervised Contrastive Learning for CollaborativeFiltering. IEEE Transactions on Knowledge and Data Engineering (2023).",
  "Yatong Sun, Bin Wang, Zhu Sun, and Xiaochun Yang. 2021. Does Every Data In-stance Matter? Enhancing Sequential Recommendation by Eliminating UnreliableData.. In IJCAI. 15791585": "Changxin Tian, Yuexiang Xie, Yaliang Li, Nan Yang, and Wayne Xin Zhao. 2022.Learning to denoise unreliable interactions for graph collaborative filtering. InProceedings of the 45th International ACM SIGIR Conference on Research andDevelopment in Information Retrieval. 122132. Menghan Wang, Yujie Lin, Guli Lin, Keping Yang, and Xiao-ming Wu. 2020.M2GRL: A multi-task multi-view graph representation learning framework forweb-scale recommender systems. In Proceedings of the 26th ACM SIGKDD inter-national conference on knowledge discovery & data mining. 23492358.",
  "Tianle Wang, Lianghao Xia, and Chao Huang. 2023. Denoised Self-AugmentedLearning for Social Recommendation. arXiv preprint arXiv:2305.12685 (2023)": "Wenjie Wang, Fuli Feng, Xiangnan He, Liqiang Nie, and Tat-Seng Chua. 2021.Denoising implicit feedback for recommendation. In Proceedings of the 14th ACMinternational conference on web search and data mining. 373381. Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.Neural graph collaborative filtering. In Proceedings of the 42nd international ACMSIGIR conference on Research and development in Information Retrieval. 165174. Yifan Wang, Peijie Sun, Weizhi Ma, Min Zhang, Yuan Zhang, Peng Jiang, andShaoping Ma. 2024. Intersectional Two-sided Fairness in Recommendation. InProceedings of the ACM on Web Conference 2024 (WWW 24). Association forComputing Machinery, New York, NY, USA, 36093620. Yifan Wang, Peijie Sun, Min Zhang, Qinglin Jia, Jingjie Li, and Shaoping Ma. 2023.Unbiased Delayed Feedback Label Correction for Conversion Rate Prediction.In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery andData Mining. 24562466.",
  "Proceedings of the ACM Web Conference 2022. 20152025": "Zongwei Wang, Min Gao, Wentao Li, Junliang Yu, Linxin Guo, and HongzhiYin. 2023. Efficient Bi-Level Optimization for Recommendation Denoising. InProceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery andData Mining. 25022511. Zitai Wang, Qianqian Xu, Zhiyong Yang, Xiaochun Cao, and Qingming Huang.2021. Implicit feedbacks are not always favorable: Iterative relabeled one-classcollaborative filtering against noisy interactions. In Proceedings of the 29th ACMInternational Conference on Multimedia. 30703078.",
  "Hongyi Wen, Longqi Yang, and Deborah Estrin. 2019. Leveraging post-clickfeedback for content recommendations. In Proceedings of the 13th ACM Conferenceon Recommender Systems. 278286": "Le Wu, Peijie Sun, Yanjie Fu, Richang Hong, Xiting Wang, and Meng Wang. 2019.A neural influence diffusion model for social recommendation. In Proceedingsof the 42nd international ACM SIGIR conference on research and development ininformation retrieval. 235244. Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun Yu, Gang Niu, andMasashi Sugiyama. 2021. Sample selection with uncertainty of losses for learningwith noisy labels. arXiv preprint arXiv:2106.00445 (2021).",
  "Dezhao Yang, Jianghong Ma, Shanshan Feng, Haijun Zhang, and Zhao Zhang.2023. IDVT: Interest-aware Denoising and View-guided Tuning for Social Rec-ommendation. arXiv preprint arXiv:2308.15926 (2023)": "Yonghui Yang, Le Wu, Kun Zhang, Richang Hong, Hailin Zhou, Zhiqiang Zhang,Jun Zhou, and Meng Wang. 2023. Hyperbolic Graph Learning for Social Recom-mendation. IEEE Transactions on Knowledge and Data Engineering (2023), 114. Haibo Ye, Xinjie Li, Yuan Yao, and Hanghang Tong. 2023. Towards robust neuralgraph collaborative filtering via structure denoising and embedding perturbation.ACM Transactions on Information Systems 41, 3 (2023), 128. Chi Zhang, Yantong Du, Xiangyu Zhao, Qilong Han, Rui Chen, and Li Li. 2022.Hierarchical item inconsistency signal learning for sequence denoising in sequen-tial recommendation. In Proceedings of the 31st ACM International Conference onInformation & Knowledge Management. 25082518. Honglei Zhang, Fangyuan Luo, Jun Wu, Xiangnan He, and Yidong Li. 2023.LightFR: Lightweight Federated Recommendation with Privacy-preserving Ma-trix Factorization. ACM Trans. Inf. Syst. 41, 4, Article 90 (mar 2023), 28 pages.",
  "A.2Parameter Settings": "All of the models use the Adam optimizer with a learning rate of0.001, batch size set to 1024, and embedding dimension set to 32.The number of graph convolution layers for LightGCN is set to3 without dropout. For every training example, we select one ob-served interaction and one random unobserved interaction to inputinto the model. The ratio of relabeled interactions is tuned in {0,0.01, 0.03, 0.09, 0.27}. 2 is tuned in {0, 0.001, 0.01, 0.1}. The timestep is tuned in {1, 2, 3, 4, 5}. Note that the purpose of using hyper-parameters 2 is to lessen the dependence on strong assumptions,helping our framework work better in practice. Our experimentsare based on RTX 2080 Ti GPU and PyTorch."
}