{
  "ABSTRACT": "Effective multi-intersection collaboration is pivotal for reinforcement-learning-based traffic signal control to alleviate congestion. Existingwork mainly chooses neighboring intersections as collaborators.However, quite an amount of congestion, even some wide-rangecongestion, is caused by non-neighbors failing to collaborate. Toaddress these issues, we propose to separate the collaborator selec-tion as a second policy to be learned, concurrently being updatedwith the original signal-controlling policy. Specifically, the selectionpolicy in real-time adaptively selects the best teammates accord-ing to phase- and intersection-level features. Empirical results onboth synthetic and real-world datasets provide robust validationfor the superiority of our approach, offering significant improve-ments over existing state-of-the-art methods. Code is available at",
  "The corresponding author": "Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08 ACM Reference Format:Jingqing Ruan, Ziyue Li, Hua Wei, Haoyuan Jiang, Jiaming Lu, XuantangXiong, Hangyu Mao, and Rui Zhao. 2024. CoSLight: Co-optimizing Collab-orator Selection and Decision-making to Enhance Traffic Signal Control. InProceedings of the 30th ACM SIGKDD Conference on Knowledge Discoveryand Data Mining (KDD 24), August 2529, 2024, Barcelona, Spain. ACM, NewYork, NY, USA, 24 pages.",
  "INTRODUCTION": "Traffic Signal Control (TSC) plays a critical role in managing ur-ban traffic flow and alleviating congestion. Over the past decade,multi-agent reinforcement learning (MARL) has emerged as a pow-erful tool for optimizing TSC . However, effectivelypromoting multi-intersection collaboration remains a persistentchallenge in applying MARL to TSC.Traditionally, researchers have treated geographically adjacentintersections as natural collaborators, and combined MARL meth-ods with graph neural networks (GNNs) and approaches multi-level embeddings tomodel multi-intersection collaboration. However, the collaborationamong intersections might be far beyond topological proximity inthe real world . For instance, during morning rush hours,signals from residential to business areas must be strategically co-ordinated to facilitate driving in town. As shown in (a),intersections in upper streams should regulate incoming traffic toprevent downstream congestion, requiring them to synchronizewith signals closer to business districts, which direct traffic towardsparking and alternate routes. This coordination goes beyond mereproximity, emphasizing the need for dynamic and non-adjacentcollaboration across the network. Likewise, during evening rushhours in (b), signals from business to residential areas alsoneed to cooperate for better driving out of town. The coordinationbetween areas of intersections in the morning and evening peaksmostly differ due to different origin-destination flows and otherfactors such as weather and trip purpose.",
  ": (a)-(b): The coordination between areas of intersec-tions during rush hours; (c)-(d): The collaboration policy and decision policy should be jointly optimized to preventsuboptimal": "In this paper, we propose CoSLight to investigate the collabo-ration among intersections beyond topological neighbors, whichcomes along with two questions: Whom to collaborate for better decisions? While existingmethods relying on heavy GNNs to learn whom to collaboraterequire information propagation within the whole network, in real-time, the collaborator selection must be light and agile. In this paper,we utilize a simple two-layer MLP structure for top- collaboratorselection, which not only reduces computational complexity but also achieves better performance in experiments. Insteadof counting on GNNs to learn the relationships by themselves,we incorporate two golden rules in the MLP collaboration matrix:that you are your biggest collaborator and mutual reciprocity,which penalize the diagonal to be the largest and the matrix to besymmetric. These rules significantly improve collaboration benefits. How to collaborate and optimize decisions? The goodnessof collaborator selection largely influences the goodness of the de-cision policy. For example, the traditional practice is to first selectcollaborators without training and then to decide the signal policy,as shown in (c), which comes with two drawbacks: (1) thedecision policy for one intersection might need a longer time to ad-just to its collaborators, (2) the decision policy is optimized towardsmaximizing the cumulative reward, while the collaborators areselected separately without acknowledgment of the performanceof decision policy. To address this challenge, in this paper, we de-sign a joint optimization scheme that simultaneously trains thecollaboration selection policy and decision policy to maximize thecumulative return through a joint policy gradient, reinforcing thestrong coupling between collaboration policy and decision policy.We conduct comprehensive experiments using both synthetic-and real data with different traffic flow and network structures.Our method consistently outperforms state-of-the-art RL methods,which shows that the effectiveness of collaborator selection andjoint optimization with decision policy. We further showcase thatthe selected collaborators are not necessarily geographic neighbors, and visualize several interesting collaboration strategies learned byour method to show that our collaborator selection is effective andgeneralizable to different road networks.In summary, our contribution is the following:",
  "CoSLight is the first work to decouple and co-optimize thecollaborator selection policy and signal planning policy": "Specifically, CoSLight combines a Dual-Feature Extractor,capturing both phase- and intersection-level features, with aMulti-Intersection Collaboration module designed to strate-gically choose cooperating intersections. Moreover, a jointoptimization strategy is derived to co-train the collaboratorselection and decision-making policies, which uses a jointpolicy gradient to enhance the cumulative return, empha-sizing the interdependence between collaboration selectionand decision-making.",
  "RELATED WORK": "In this section, we review existing approaches based on how theycollaborate: implicit and explicit collaboration.Implicit collaboration only accesses information from otheragents during the update phase to assist gradient backpropaga-tion. MPLight repurposes FRAP for a multi-agent context.IDQN , IPPO and MAPPO tackle TSC prob-lems directly from the MARL perspective. Works like extend the single-agent DQN solution to multi-agent scenarios us-ing the max-plus coordination algorithm. Other methods such asIntelliLight and PressLight enrich the state space by lever-aging different types of additional information, like image framesor max pressure, respectively. FMA2C and FedLight con-sider collaborative optimization from federated RL. However, thesemethods focus on multi-intersection information from an updatemechanism or gradient design perspective, while the decentral-ized execution leads to weak attention and may hinder efficientmulti-intersection collaboration.Explicit collaboration allows accessing other agents informa-tion during the decision-making process to enhance collaboration.To overcome the shortcomings of weak collaboration in implicitstrategies, explicit collaboration methods can be further catego-rized into two sub-classes. One line of research focuses on multi-intersection representation extraction, such as CoLight ,DynSTGAT , IG-RL , MaCAR , and MetaGAT , whichutilize GNNs as the feature extractor to model representations of thecurrent intersection and its neighbors. X-Light instead feeds theneighbors MDP information into a Transformer. However, thesemethods risk introducing noise, such as unrelated intersection fea-tures, into collaboration; it also suffers from the computationalcomplexity of matrix multiplication. Another line of research lever-ages group-based cooperation . MT-GAD , andJointLight uses heuristic grouping, which requires manual de-sign, while CGB-MATSC applies KNN grouping directly basedon state observation, a non-parametric method. GeneraLight utilizes-means to execute the flow clustering to learn diverse meta-parameters. GPLight utilizes mutual information and gatheringconstraints to derive latent representations, which are subsequently",
  "CoSLight: Co-optimizing Collaborator Selection and Decision-making to Enhance Traffic Signal ControlKDD 24, August 2529, 2024, Barcelona, Spain": "Wen, M., Kuba, J., Lin, R., Zhang, W., Wen, Y., Wang, J., and Yang, Y. Multi-agent reinforcement learning is a sequence modeling problem. Advances inNeural Information Processing Systems 35 (2022), 1650916521. Wu, L., Wang, M., Wu, D., and Wu, J. Dynstgat: Dynamic spatial-temporalgraph attention network for traffic signal control. In Proceedings of the 30thACM International Conference on Information & Knowledge Management (2021),pp. 21502159.",
  "(d) Phase Selection": ": (a) The illustration of intersection. (b) There are 12movements: [North, South, West, East (four approaches)] [Left, Go-through, Right (three directions)]. Usually, turningright isnt signal-controlled, so only 8 movements (indexfrom 1-8 in (a)) are signal-controlled. (c) A phase is two non-conflicting movements that can be released together. Thereare 8 phases, e.g., phase-A combines movements 1 and 5. (d)The signal-control policy is to select one phase for the nexttime step according to the traffic condition. Traffic Intersection. A traffic intersection, where multiple roadsintersect, uses traffic signals to control vehicle flow. depictsa four-arm intersection, equipped with lanes designated for leftturns, straight travel, and right turns. It features four roads andtwelve lanes for both entering and exiting traffic. We denote theincoming and outgoing lanes at intersection as L and L.Traffic Movement. It refers to the progression of vehicles acrossan intersection in a specific direction, namely, turning left, goingstraight, or turning right. As depicted in , twelve distincttraffic movements can be identified. Right-turning vehicles usuallyproceed regardless of the signal status.Signal Phase. It is a set of two traffic movements that can bereleased together without conflicts.As illustrated in , theintersection comprises eight distinct phases A-H.Multi-Intersection Traffic Signal Control (TSC). At each in-tersection, an RL agent is deployed to manage the traffic signalcontrol. During each time unit denoted as , the RL agent observes the state of the environment, represented as . It then determines the action , which dictates the signal phase for inter-section . The objective of the agent is to choose an optimal action(i.e., determining the most appropriate signal phase ) to maximizethe cumulative reward.Queue Length. The queue length at each intersection is definedas the aggregate length of vehicle queues in all incoming lanestoward the intersection, denoted as:",
  "=(), L,(1)": "where () is the queue length in the lane .Pressure. Pressure can be divided into intersection-wise andphase-wise categories. Intersection-wise pressure measures theimbalance between incoming and outgoing vehicle queues at anintersection, indicating traffic load discrepancies. Phase-wise pres-sure concerns a specific signal phase . Each signal phase permitsseveral traffic movements, each marked by (,). Let (,) sig-nify the vehicle count difference between lane and lane for amovement (,), and the phase-wise pressure () denotes the cu-mulative sum of the pressures of all permissible movements withinthat phase, i.e., (,) (,).Collaborator Matters. As shown in , we conductedexperiments on Grid 4 4 and Grid 5 5 to further substantiateour assertion: the optimal number and range of collaborating inter-sections vary across different scenarios. For instance, in Grid 4 4,the impact of collaboration remains largely consistent regardlessof increasing distances, suggesting that the benefits of collabora-tion might be distance-independent in this setting. Alternatively, itcould indicate that merely selecting topologically adjacent intersec-tions might not enhance the collaborative outcomes. In contrast,Grid 5 5 displays a negative impact with one-hop collaboration,whereas two-hop collaboration produces the greatest benefits. Thisunderscores the significance of precisely and judiciously select-ing collaborators, highlighting that not just the presence, but thequality and context of collaboration matters.",
  "Problem Statement": "Then, we formulate -intersection problem based on multiagentMarkov decision processes (MMDPs) as collaborator-basedMMDPs, which can be expressed as < {I}, S, O, {C}=1, {A}=1,P,, >. I is the intersection, is the number of inter-sections, and S, O are the global state space and local observa-tion space. C and A denote the selected collaborator and actionspace for the intersection. We label := (1, ..., ) Cand := (1, ..., ) A the joint collaborator identifiers and",
  "KDD 24, August 2529, 2024, Barcelona, SpainTrovato and Tobin, et al": "actions for all intersections. P(|, , ) is the transition dynam-ics. All intersections share the same reward function (, , ) :S C A R. (0, 1) denotes a discount factor. Here, wecan denote = (0, 0, 0,1, ...) as the trajectory induced by thepolicy = {{ }=1}, where denotes the collaborator se-lection policy, and is the decision policy. All the intersectionscoordinate together to maximize the cumulative discounted returnE=0 (, , ). We can define the overall joint pol-icy as the product of selection policy and decision policy basedon Bayesian chain rules.",
  "METHODOLOGY4.1Main Modules": "As shown in , the dual-feature extractor pre-processeseach intersection by obtaining phase- and intersection-level rep-resentations. Subsequently, the CoS identifies the most appropri-ate collaborators and collects their information to assist with thedecision-making process. 4.1.1Dual-Feature Extractor. To optimize policy-making in TSC,a comprehensive representation of traffic situations is vital. Whilephase-level features inform individual intersections, they lack broadercoordination insights from correlated intersections. Thus, we com-plement with intersection-level features to better capture network-wide traffic dynamics based on Transformer .At the phase level, we adopt FRAP to obtain the phase-level representation. The raw observations from the simulatorinclude features, such as the number of vehicles, queue length,the current phase, the flow, etc. For any traffic movement {1, ..., 8} in an intersection , the -th feature in the raw observa-tion can be denoted as ,. For brevity, the superscript is omit-ted hereinafter. The process can be summarized as follows: =||=1(MLP (,)), = FRAP(1, . . . , 8), = MLP(),where || is concatenation, is the activation function, and is theembedding of traffic movement. Then FRAP() module (details inAppendix B) is applied to extract the phase competition representa-tion , and we reshape as a vector through flatten operation.Finally, is the phase representation in the intersection .At the intersection level, we adopt the Transformer encoder as the backbone to model the relationship across multiple in-tersections: it takes in the phase representations = { }=1, R , is the input dimension. Attention can be calculated toobtain the intersection-level representation , attending to infor-mation from different intersections representations.",
  "The TransformerEnc is the standard Transformer encoder withmulti-head, followed by a feed-forward network": "In summary, by extracting features from both the phase- andintersection-level simultaneously, we are able to obtain a morecomprehensive insight to provide sufficient representation for sub-sequent modeling. 4.1.2Multi-Intersection Collaboration. The module facilitates co-operation among multiple intersections. By leveraging the richrepresentation , we design the CoS to select suitable collabora-tors for each intersection.As mentioned before, since the collaboration policy (CoS) willbe co-optimized with the decision policy, a lite and fast moduleis preferred to avoid becoming the computation bottleneck. Thus,we pursue minimalism: to use two-stacked MLPs. In computervision, MLP-Mixer is exclusively based on MLP and attainscompetitive scores as CNN-based methods or even ViT. In the spa-tiotemporal domain, MLPInit also proves that MLPs could be600 faster than GNN and achieves comparable results since MLPis free from matrix multiplication. GFS gives an insightful andtheoretically-rigid explanation: MLPs with general layer nor-malization provide similar functionality and effectivenessof aggregating nodes. Moreover, an ablation study by replacingMLPs with GNNs in .5 empirically confirms the effective-ness of MLPs.Thus, the top- Collaborator Selection (CoS) policy is imple-mented by two-stacked MLP layers, = () = MLP(),where represents the logits from the MLP. Then the probabilitydistribution can be constructed:",
  ",(4)": "from which the indices of the selected collaborators for the intersec-tion can be sampled. Here, we set the hyper-parameter as 5. Wecan sample the top- collaborator identifiers without replacementfrom P, which means sampling the first element, then renormal-izing the remaining probabilities to sample the next element. Let1, ..., be an (ordered) sample without replacement from theP, then the joint probability can be formulated as follows.",
  "I exp( ) ,(5)": "where 1, ..., = arg top-(P) is the sampled top- realizationof variables 1, ..., , and I = I\\{1, ...,1} is the domain(without replacement) for the -th sampled element. Summarizedas (), where Z1 refers to the indices of theselected collaborators for intersection , and represents the CoS,whose parameters are shared among all intersections.With and , we obtain the collaborators representations: = lookup(, ), where lookup operator extracts the vec-tor at index Z1 from matrix R , thus R. After that, mean-pooling is used to obtain the final collabora-tion representation. = mean-pooling(), R1.For the decision policy , it receives the intersection-level rep-resentation and collaborator representation and outputs the action for the intersection : = (|[ ||]).",
  ",(6)": "where = {1, ..., } and = {1, ..., } are joint CoS policyand decision policy, parameterized by {1, ..., } and {1, ..., },respectively.According to Bellman Equation , the Q-function providesan estimate to guide the agent toward the optimal policy that maxi-mizes cumulative rewards. Thus, the objective can be written:",
  "=1 ( | ) ( |, ) (, ),(7)": "where denotes the stationary distribution induced by pol-icy , is the joint action-value function, and is theindividual action-value function. Here, simplifies the learn-ing process by focusing on local state-action pairs rather than theglobal state, effectively mitigating the scalability issue in large-scaleenvironments. 4.2.2Optimizing CoS Policy. The CoS policy aims to chooseoptimal collaborators for intersections. We follow two rules: (a)Intersections should primarily focus on their own decisions. (b)They should also account for and collaborate with each othersdecisions. Thus, two key constraints are introduced to ensure theserules in the collaborator selection process.Firstly, we can denote the distributions of for all intersectionsas a collaborator matrix R , where each element inthe matrix signifies the probability of collaborator selection betweenthe intersections and .Rule 1: You are your biggest collaborator. Diagonal maxi-mization constraint is imposed. To prioritize its decision-making for each intersection, we enforce the diagonal maximization con-straint on the matrix , ensuring it remains a valid probabilitydistribution matrix. The main objective is to maximize the sum ofthe diagonal elements while complying with specific constraintsthat require the elements to be non-negative, and the row sumsmust equal to one:",
  "=1 = 1, .(8)": "Rule 2: Collaboration should be mutually reciprocal. Sym-metry constraint is enforced. To encourage collaboration andmutual consideration between intersections, we incorporate a sym-metry constraint into the training. The symmetry constraint, calcu-lated as the mean squared difference between the matrix andits transpose [] , guides the neural network to learn symmetriccollaborator selection. Mathematically, the symmetry constraint isformulated as follows:",
  ": end for": "Thus, incorporating these constraints into the CoS policy gra-dient optimization enables the policy to learn the optimal col-laborator composition progressively. As a result, the policy canpromote cooperative decision-making among intersections, result-ing in enhanced traffic signal control and improved traffic flowefficiency. 4.2.3Optimizing Decision Policy. Assumed we have toidentify the most appropriate collaborators and then to optimize themulti-agent decision policy as follows. For the decision policy,we can derive its gradient with the Eq. (7).",
  "where = + max (,) is the learning target, is thediscounted factor, and is the target network for intersection": "The joint optimization scheme ensures the CoS policy and thecollaborator-based decision policy converge in the same directionby optimizing the same objective function, which is to maximizethe cumulative discounted return in an end-to-end manner. Theproposed method facilitates effective decision-making and collab-oration among intersections, allowing the two policies to worktogether harmoniously toward achieving the overall goal.",
  "Algorithmic Framework": "Here we provide a detailed pseudocode to elaborate the overallinference and training process. In the inference process, we firstselect suitable teammate IDs for each intersection basedon its observations . Then we calculate the teammate vectors according to the teammate IDs and concatenate them tothe self vector to obtain the action for decision making, andfinally interact with the SUMO environment. In training, we usethe derived loss for backpropagation training. The detailed processis presented in Algorithm 1.",
  "EXPERIMENTS5.1Environments": "The evaluation scenarios come from the Simulation of Urban Mo-bility (SUMO)1, which contains three synthetic scenarios and tworeal road network maps of different scales, including Grid 4 4,Avenue 4 4, Grid 5 5, Cologne8, and Nanshan. In , wepresent detailed statistics including the total number of intersec-tions (#Total Int.), along with the quantity of 2-arm, 3-arm, and4-arm intersections in each scenario.As for each scenario, each individual episode lasts for a time spanof 3600 seconds, during which the action interval is = 15 seconds.The network design and hyper-parameter settings are provided inAppendix A.",
  "Baselines": "We analyze the performance of our method by comparing it withtwo conventional transportation techniques and six state-of-the-art(SOTA) RL/MARL algorithms.Conventional Methods: Fixed Time Control (FTC) with random offset executeseach phase within a loop, utilizing a pre-defined phase duration. MaxPressure greedily chooses the phase with the maxi-mum pressure, which is a SOTA transportation control method.RL-based Methods: IPPO controls each intersection with an independent PPOagent, which is trained with the data from the current intersection. MAPPO executes with an independent PPO agent and is",
  ": Intersection-wise evaluation. Our method constantlyachieves the best performance": "trained collectively using the data from all intersections, enablingan optimized coordinated traffic flow. MAT is a strong baseline in MARL with centralized train-ing with centralized execution paradigm, modeling the TSC as asequential problem. FRAP models phase competition and employs deep Q-networkagent for each intersection to optimize traffic phase operation. MPLight utilizes the concept of pressure as both state and re-ward to coordinate multiple intersections, which is based on FRAP. CoLight leverages a GAT to extract neighboring informa-tion, thereby assisting the agent in optimizing queue length. Advanced-CoLight combines advanced traffic state forthe traffic movement representation with a pressure of queuingand demand of running for vehicles with CoLight, to enhance thedecision-making process. MetaGAT leverages GAT-based context to boost cooperationamong intersections. DuaLight introduces a scenario-specific experiential weightmodule and a scenario-shared co-train module to facilitate the in-formation extraction of scenarios and intersections.",
  "Evaluation Metrics": "We utilize two evaluation metrics in our study. Firstly, at the sce-nario level , we compute the average delay, and average trip timeby tracking vehicles in the scenario. Specifically, delay signifies theholdup caused by signalized intersections (either stop or approachdelay) for a vehicle, and trip time denotes the complete duration ofa vehicles journey from its origin to its destination.Secondly, at the intersection level, we employ the external rewardof the environment as an evaluation criterion, including the averagedelay time, average wait time, average queue length, and averagepressure for each intersection. These metrics are calculated at eachindividual intersection by averaging the values across all vehicles.",
  "Main Results": "Scenario-wise evaluation. As illustrated in , the perfor-mances marked in boldface and underlined represent the best andsecond-best results, respectively. CoSLight consistently achievessubstantial performance improvements, reducing the average delaytime by 7.68%, the average trip time by 1.98%, which not only vali-dates the effectiveness of CoSLight but also highlights its potentialto efficiently manage and enhance multi-intersection collaborationin various traffic scenarios. Intersection-wise evaluation. shows CoSLight achievesthe best results in all scenarios. Compared to the second-best result,ours achieved a 7.71 % improvement on average. This consistent per-formance enhancement across intersection-wise evaluation metricsunderlines the robustness of our proposed method.Notably, these findings provide strong evidence that our al-gorithm performs well not only in terms of global cooperation(scenario-wise evaluation) but also from the perspective of bene-fits at individual intersections (intersection-wise evaluation). Thisdual-level efficacy showcases the effectiveness of our approach, sig-nifying its ability to foster overall road network performance whilesimultaneously optimizing individual intersection operations.",
  "Ablation Analysis of Three Settings": "Ablation of Components. Firstly, we selectively remove differ-ent modules, specifically the FRAP, Transformer, and Collaboratormodules, to validate the necessity of each component in CoSLight.In (a), (1) it is evident that the Transformer module thataggregates other intersections information and the Teammate CoSmodule that adaptively selects collaborators are the most impor-tant. (2) Moreover, to justify the MLP design for CoS, we replace itin CoS with GNNs, where we could observe a significant slowdownof convergence and performance drop in CoS with GNN, due toGNNs computational complexity as the bottleneck. (3) To justifyTransformer as a better design to aggregate other intersectionsinformation, we replaced the transformer module in the dual extrac-tor with GNNs (Dual with GNN). We see similar performance drops.Such a feature extractor encourages learning better embedding foreach agent and understanding them better, shown in . Ablation of the Collaborator Matrix. To further assess theimpact of the co-learned collaborator matrix, we conduct experi-ments where the matrix in the proposed CoS is replaced with bothfixed (as topological adjacency matrix) and random (freezing thecollaborator selection after randomly initializing top- selection)matrices. (b) shows that using co-learned collaborator ma-trices in CoS can boost performance, highlighting the critical roleof the dynamical collaboration matrix in achieving effective coordi-nation. Thus, the joint optimization of the collaborator matrix withdecision policies is key for optimizing cumulative rewards. Ablation of Constraints on Collaborator Matrix. In (c), we further evaluate the contributions of the constraints in Eq (8)and (9) by removing the Diagonal constraint, the Symmetry con-straint, or both. Removing the Symmetry constraint significantlydegrades performance, which underlines the symmetric interplaybetween each other is essential. Conversely, the Diagonal constrainthas a marginal impact, primarily enhancing the convergence speed.These insights highlight the value of the Symmetry constraint foroptimality and the Diagonal constraint for efficiency.In summary, the ablations provide empirical evidence that eachdimension of CoS is vital. The co-learning of the collaborator ma-trix, the adherence to specific constraints, and the integration ofcrucial components such as the FRAP, Transformer, and Collabo-rator modules all contribute to the robustness and effectiveness ofthe system. Through validation, we demonstrate that our modelleads to enhanced performance in complex environments.",
  "Visualization Analysis of Dual-feature": "We analyze the dual-feature embeddings from our Dual-FeatureExtractor. As shown in , we test 10 episodes for each inter-section in each scenario, resulting in 2400 dual-feature embeddingsvisualized using the t-SNE technique .These embeddings demonstrate a distinct clustering pattern, sug-gesting that our model captures unique features at each intersectioneffectively. This allows the model to group similar states together,adapting to variations in traffic conditions and intersection-levelcharacteristics. This adaptability is a crucial advantage of our ap-proach, contributing significantly to its performance improvement.More results of all five scenarios under the above settings are inAppendix D - I. In conclusion, through rigorous experiments andinsightful analysis, our study confirms that our method, which inte-grates dual-feature extraction and multi-intersection collaboration,provides an effective and efficient solution for the TSC.",
  ": Violin plots display the performance trade-offs atvarying numbers of collaborators": "shows the trade-off between the number of collabora-tors and performance. For example, in Avenue 44 ((a)), = 8 yields the best results, suggesting an optimal balance betweenuseful information and performance gains. Information from morecollaborators beyond this point does not guarantee improved resultsand may lead to higher resource usage. This finding poses a direc-tion for future work to dynamically determine the ideal number ofcollaborators, potentially enhancing the algorithms efficiency.",
  ": Saliency maps of collaborator matrix. The deeperthe color, the stronger the correlation. CoSLight has learneddiagonal maximization and symmetry constraints": "intersections) scenarios, respectively. The saliency maps in depict the state of the collaborator matrix at the beginning and theend of the training, respectively.Upon the conclusion of the training, we notice a deepening of thecolor along the diagonal elements of the saliency map. This signifiesan increased self-attention, indicating that the intersections haveadapted to pay more heed to their own states. Additionally, thesymmetry apparent in the saliency map suggests mutual awarenessamong intersections. As the training progresses, intersections notonly learn to focus on themselves but also pay attention to theirpeers, signifying a learned mutual collaboration.These observations validate the effectiveness of our approachin creating a collaborative environment among intersections, thusleading to enhanced performance.",
  "(b) K=1(c) K=3": ": Collaborator selection on Cologne8, showing self-selection and efficient cross-collaboration at (b) K = 1 withpredominantly solo dynamics, and (c) K = 3 with inter-agentcollaboration with not just the topological selection. depicts the collaborator selection process. For = 1 in (b), self-selection is prevalent; however, agent 0 displaysvaried collaboration patterns, likely due to the intricacy of its signalcontrol tasks (refer to (a)), which require engaging withmultiple collaborators for optimal traffic management. When increases to 3, as shown in (c), agents exhibit both self-selection and mutual collaboration, forming complex interactionnetworks. For example, agent 3 largely collaborates with agents2 (non-neighbor) and 4 (neighbor); Similarly, agent 4 with agents3 (neighbor) and 6 (neighbor); Also, agent 2 with agents 6 (non-neighbor) and 7 (non-neighbor). Specifically, agent 2 is quite farfrom 6 and 7, but they form a strong collaboration since agent 2is in the office building and agents 6 and 7 are in the communityresidential region.Overall, such learned patterns suggest strategic selection beyondtopological neighbors. Collectively, these results affirm that the col-laborator selection mechanism is adaptively responsive to both thecomplexity of traffic tasks and the benefits of strategic collaborationto optimize traffic flow.",
  "Average Inference and Training Time": "We collected 100 episodes over 100 training epochs to obtain the av-erage inference time for CoS and Decision policies per episode andaverage training time per epoch. We experimented on 4 NVIDIATITAN Xp GPUs(12G). In , across five scenarios, CoS in-ference and training times average 2.83% and 31.29%, respectively,while Decision policy averages 2.66% for inference and 63.21% fortraining. The CoS strategy adds a 34.42% time overhead, justifiableby its performance benefits.",
  "CONCLUSION": "In this paper, we introduce an innovative approach to traffic sig-nal control, employing a top- collaborator selection policy with adual-feature extractor. This unique strategy allows for the effectiveextraction of phase- and intersection-level representations whileadaptively selecting collaborators for enhanced multi-intersectioncollaboration. Moreover, we are the first to propose a joint optimiza-tion regime to train the CoS and decision policies simultaneouslyfor maximizing the cumulative discounted return. Comprehensiveexperiments on both synthetic and real-world datasets validate ourapproachs superiority. The extensive analysis further reinforcesthe effectiveness and efficacy of CoSLight.Future research could potentially explore an adaptive mecha-nism to efficiently determine the optimal number of collaborators,thereby enhancing the performance and effectiveness of traffic sig-nal control. Moreover, enhancing the explainability of collaboratorselection processes could provide valuable insights, potentially en-abling more intuitive and transparent decision-making to promotecooperation.",
  "Ault, J., Hanna, J. P., and Sharon, G. Learning an interpretable traffic signalcontrol policy. arXiv preprint arXiv:1912.11023 (2019)": "Ault, J., and Sharon, G. Reinforcement learning benchmarks for traffic signalcontrol. In Thirty-fifth Conference on Neural Information Processing SystemsDatasets and Benchmarks Track (Round 1) (2021). Bellman, R. Dynamic programming. Science 153, 3731 (1966), 3437. Bhmer, W., Kurin, V., and Whiteson, S. Deep coordination graphs. In Inter-national Conference on Machine Learning (2020), PMLR, pp. 980991.",
  "Boutilier, C. Planning, learning and coordination in multiagent decision pro-cesses. In TARK (1996), vol. 96, pp. 195210": "Chen, C., Wei, H., Xu, N., Zheng, G., Yang, M., Xiong, Y., Xu, K., and Li, Z.Toward a thousand lights: Decentralized deep reinforcement learning for large-scale traffic signal control. In Proceedings of the AAAI Conference on ArtificialIntelligence (2020), vol. 34, pp. 34143421. Da, L., Gao, M., Mei, H., and Wei, H. Prompt to transfer: Sim-to-real transfer fortraffic signal control with prompt learning. In Proceedings of the AAAI Conferenceon Artificial Intelligence (2024), vol. 38, pp. 8290. Da, L., Mei, H., Sharma, R., and Wei, H. Uncertainty-aware grounded actiontransformation towards sim-to-real transfer for traffic signal control. In 202362nd IEEE Conference on Decision and Control (CDC) (2023), IEEE, pp. 11241129. Devailly, F.-X., Larocqe, D., and Charlin, L. Ig-rl: Inductive graph rein-forcement learning for massive-scale traffic signal control. IEEE Transactions onIntelligent Transportation Systems 23, 7 (2022), 74967507. Du, W., Ye, J., Gu, J., Li, J., Wei, H., and Wang, G. Safelight: A reinforcementlearning method toward collision-free traffic signal control. In Proceedings of theAAAI conference on artificial intelligence (2023), vol. 37, pp. 1480114810. Du, X., Li, Z., Long, C., Xing, Y., Philip, S. Y., and Chen, H. Felight: Fairness-aware traffic signal control via sample-efficient reinforcement learning. IEEETransactions on Knowledge and Data Engineering (2024).",
  "Foerster, J., Farqhar, G., Afouras, T., Nardelli, N., and Whiteson, S. Coun-terfactual multi-agent policy gradients. In Proceedings of the AAAI conference onartificial intelligence (2018), vol. 32": "Han, X., Zhao, T., Liu, Y., Hu, X., and Shah, N. MLPInit: Embarrassingly simpleGNN training acceleration with MLP initialization. In The Eleventh InternationalConference on Learning Representations (2023). Hao, Q., Huang, W., Feng, T., Yuan, J., and Li, Y. Gat-mf: Graph attention meanfield for very large scale multi-agent reinforcement learning. In Proceedings of the29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (2023),pp. 685697. Jiang, H., Li, Z., Li, Z., Bai, L., Mao, H., Ketter, W., and Zhao, R. A gen-eral scenario-agnostic reinforcement learning for traffic signal control. IEEETransactions on Intelligent Transportation Systems (2024). Jiang, H., Li, Z., Wei, H., Xiong, X., Ruan, J., Lu, J., Mao, H., and Zhao, R.X-light: Cross-city traffic signal control using transformer on transformer asmeta multi-agent reinforcement learner. arXiv preprint arXiv:2404.12090 (2024).",
  "Kouvelas, A., Lioris, J., Fayazi, S. A., and Varaiya, P. Maximum pressurecontroller for stabilizing queues in signalized arterial networks. TransportationResearch Record 2421, 1 (2014), 133141": "Kuyer, L., Whiteson, S., Bakker, B., and Vlassis, N. Multiagent reinforcementlearning for urban traffic control using coordination graphs. In Machine Learningand Knowledge Discovery in Databases: European Conference, ECML PKDD (2008),pp. 656671. Labres, J. V., Bazzan, A. L., and Abdoos, M. Improving traffic signal controlwith joint-action reinforcement learning. In 2021 IEEE Symposium Series onComputational Intelligence (SSCI) (2021), pp. 0108. Liang, E., Su, Z., Fang, C., and Zhong, R. Oam: An option-action reinforcementlearning framework for universal multi-intersection control. In Proceedings ofthe AAAI Conference on Artificial Intelligence (2022), vol. 36, pp. 45504558. Liu, Y., Luo, G., Yuan, Q., Li, J., Jin, L., Chen, B., and Pan, R. Gplight: groupedmulti-agent reinforcement learning for large-scale traffic signal control. In Pro-ceedings of the Thirty-Second International Joint Conference on Artificial Intelligence(2023), pp. 199207. Lou, Y., Wu, J., and Ran, Y. Meta-reinforcement learning for multiple traf-fic signals control. In Proceedings of the 31st ACM International Conference onInformation & Knowledge Management (2022), pp. 42644268. Lu, J., Ruan, J., Jiang, H., Li, Z., Mao, H., and Zhao, R. Dualight: Enhancing trafficsignal control by leveraging scenario-specific and scenario-shared knowledge.arXiv preprint arXiv:2312.14532 (2023). Ma, J., and Wu, F. Feudal multi-agent deep reinforcement learning for trafficsignal control. In Proceedings of the 19th International Conference on AutonomousAgents and Multiagent Systems (AAMAS) (2020), pp. 816824. Mao, H., Liu, W., Hao, J., Luo, J., Li, D., Zhang, Z., Wang, J., and Xiao, Z. Neigh-borhood cognition consistent multi-agent reinforcement learning. In Proceedingsof the AAAI conference on artificial intelligence (2020), vol. 34, pp. 72197226.",
  "Mei, H., Li, J., Shi, B., and Wei, H. Reinforcement learning approaches for trafficsignal control under missing data. arXiv preprint arXiv:2304.10722 (2023)": "Oroojlooy, A., Nazari, M., Hajinezhad, D., and Silva, J. Attendlight: Universalattention-based reinforcement learning model for traffic signal control. Advancesin Neural Information Processing Systems 33 (2020), 40794090. Roess, R. P., Prassas, E. S., and McShane, W. R. Traffic engineering. 2004. Ruan, J., Du, Y., Xiong, X., Xing, D., Li, X., Meng, L., Zhang, H., Wang, J., andXu, B. Gcs: Graph-based coordination strategy for multi-agent reinforcementlearning. arXiv preprint arXiv:2201.06257 (2022).",
  "Sutton, R. S. Learning to predict by the methods of temporal differences. Machinelearning 3 (1988), 944": "Sutton, R. S., and Barto, A. G. Introduction to reinforcement learning. 1998. Tolstikhin, I. O., Houlsby, N., Kolesnikov, A., Beyer, L., Zhai, X., Un-terthiner, T., Yung, J., Steiner, A., Keysers, D., Uszkoreit, J., Lucic, M.,and Dosovitskiy, A. Mlp-mixer: An all-mlp architecture for vision. In Advancesin Neural Information Processing Systems (2021), pp. 2426124272.",
  "Varaiya, P. The max-pressure controller for arbitrary networks of signalizedintersections. Advances in dynamic network modeling in complex transportationsystems (2013), 2766": "Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,Kaiser, ., and Polosukhin, I. Attention is all you need. In Advances in NeuralInformation Processing Systems (2017), pp. 59986008. Vlachogiannis, D. M., Wei, H., Moura, S., and Macfarlane, J. Humanlight:Incentivizing ridesharing via human-centric deep reinforcement learning intraffic signal control. Transportation Research Part C: Emerging Technologies 162(2024), 104593. Wang, T., Cao, J., and Hussain, A. Adaptive traffic signal control for large-scale scenario with cooperative group-based multi-agent reinforcement learning.Transportation research part C: emerging technologies 125 (2021), 103046.",
  "Wei, H., Chen, C., Wu, K., Zheng, G., Yu, Z., Gayah, V., and Li, Z. Deepreinforcement learning for traffic signal control along arterials": "Wei, H., Chen, C., Zheng, G., Wu, K., Gayah, V., Xu, K., and Li, Z. Presslight:Learning max pressure control to coordinate traffic signals in arterial network.In Proceedings of the 25th ACM SIGKDD international conference on knowledgediscovery & data mining (2019), pp. 12901298. Wei, H., Xu, N., Zhang, H., Zheng, G., Zang, X., Chen, C., Zhang, W., Zhu, Y.,Xu, K., and Li, Z. Colight: Learning network-level cooperation for traffic signalcontrol. In Proceedings of the 28th ACM International Conference on Informationand Knowledge Management (2019), pp. 19131922.",
  "Wu, Y., Zhuang, D., Labbe, A., and Sun, L. Inductive graph neural networksfor spatiotemporal kriging. In Proceedings of the AAAI Conference on ArtificialIntelligence (2021), vol. 35, pp. 44784485": "Ye, Y., Zhao, W., Wei, T., Hu, S., and Chen, M. Fedlight: Federated reinforcementlearning for autonomous multi-intersection traffic signal control. In 2021 58thACM/IEEE Design Automation Conference (DAC) (2021), IEEE, pp. 847852. Yu, C., Velu, A., Vinitsky, E., Gao, J., Wang, Y., Bayen, A., and Wu, Y. Thesurprising effectiveness of ppo in cooperative multi-agent games. Advances inNeural Information Processing Systems 35 (2022), 2461124624. Yu, Z., Liang, S., Wei, L., Jin, Z., Huang, J., Cai, D., He, X., and Hua, X.-S.Macar: Urban traffic light control via active multi-agent communication andaction rectification. In Proceedings of the Twenty-Ninth International Conferenceon International Joint Conferences on Artificial Intelligence (2021), pp. 24912497.",
  "Zhang, B., Mao, H., Li, L., Xu, Z., Li, D., Zhao, R., and Fan, G. Stackelberg deci-sion transformer for asynchronous action coordination in multi-agent systems.arXiv preprint arXiv:2305.07856 (2023)": "Zhang, H., Liu, C., Zhang, W., Zheng, G., and Yu, Y. Generalight: Improvingenvironment generalization of traffic signal control via meta reinforcement learn-ing. In Proceedings of the 29th ACM International Conference on Information &Knowledge Management (2020), pp. 17831792. Zhang, K., Yang, Z., Liu, H., Zhang, T., and Basar, T. Fully decentralizedmulti-agent reinforcement learning with networked agents. In InternationalConference on Machine Learning (2018), pp. 58725881.",
  "Zhang, L., Wu, Q., and Deng, J. Attentionlight: Rethinking queue length andattention mechanism for traffic signal control. arXiv preprint arXiv:2201.00006(2021)": "Zhang, L., Wu, Q., Shen, J., L, L., Du, B., and Wu, J. Expression might beenough: representing pressure and demand for reinforcement learning basedtraffic signal control. In International Conference on Machine Learning (2022),PMLR, pp. 2664526654. Zheng, G., Xiong, Y., Zang, X., Feng, J., Wei, H., Zhang, H., Li, Y., Xu, K., andLi, Z. Learning phase competition for traffic signal control. In Proceedings of the28th ACM international conference on information and knowledge management(2019), pp. 19631972.",
  "BTHE DETAILS ABOUT FRAP": "At the phase level, we adopt FRAP to obtain the phase-wise representation. The raw observations from the simulator include features, such as the number of vehicles, queue length, the current phase, the flow, etc. For any traffic movement , {1, ..., 8} in anintersection , the -th feature in the raw observation can be denoted as ,. For brevity, the superscript is omitted hereinafter. First, theembedding of traffic movement is obtained by Multi-Layer Perceptron (MLP):",
  "= ||=1( (,)),(14)": "where || denotes concatenation, and is the activation function. Then FRAP module is applied to extract the phase competitionrepresentation, denoted as follows. = (1, ..., 8).(15)The process can be summarized as follows. (1) Phase embedding: Each phase consists of two movements 1,2, and we get the phase embedding = 1 + 2.(2) Phase pair representation: For any pair , from different phases, the pairwise relation vector is , = || . Gathering thevectors of all phase pairs can obtain the pair demand embedding volume . Then the phase pair representation can be denoted as = 11(), where 11 is the convolutional layer with 1 1 filters. (3) Phase competition: Let be phase competition mask, and the phase competition representation can be obtained by: =11( ), where is the element-wise multiplication. Here, we reshape as a vector through flatten operation.Finally, an MLP is utilized to mine the phase representation in the intersection as follows.",
  "CTHE DETAILS ABOUT EVALUATION SETTINGS": "In , we present detailed statistics including the total number of intersections (#Total Int.), along with the quantity of 2-arm, 3-arm,and 4-arm intersections in each scenario.In real-world traffic scenarios, many intersections dont conform to a standard four-arm structure, potentially having varied lane countsand orientations. To ensure the broad application of our method across diverse scenarios, we intentionally conducted experiments in twosettings that feature non-standard intersections: Cologne8 and Nanshan.These scenarios incorporate not just the typical four-arm intersections but also irregular ones where the number and direction of lanesdeviate from the standard. By running experiments in such environments, we demonstrate that our approach is effective not only in handlingstandard intersections but also excels in managing these irregularities. This further underscores the robustness and potential wide-scaleapplicability of our methodology.",
  "DADDITIONAL MAIN RESULTS OF INTERSECTION-WISE EVALUATIONS": "In the section, we provide the additional results with the intersection-level evaluation in Table A3. Our algorithm consistently yieldedfavorable results, even achieving superior evaluation improvements in many cases. This consistent performance enhancement acrossintersection-wise evaluation metrics underlines the robustness of our proposed method.Notably, these findings provide strong evidence that our algorithm performs well not only in terms of global cooperation but also fromthe perspective of benefits at individual intersections. This dual-level efficacy showcases the effectiveness of our approach, signifying itsability to foster overall road network performance while simultaneously optimizing individual intersection operations.Moreover, the consistent and superior performance across various intersection-wise evaluations signifies the algorithms ability to handledifferent traffic scenarios and dynamics effectively. Its worth noting that traffic scenarios can be widely varied and unpredictable, thus theadaptability shown by our model underscores its real-world application potential.",
  "EADDITIONAL ABLATION OF VARIOUS SETTINGSE.1Additional Ablation of Various Collaborator Matrix": "We conduct a comprehensive ablation study regarding different collaborator matrices. In this context, the fixed matrix signifies selectingthe nearest four intersections as neighbors based on the topology, centered around oneself, and keeping it constant throughout the experiment.Meanwhile, the random matrix refers to randomly choosing four intersections as collaborators at each instance, making it possible thatdifferent intersections to be selected at various times.The experimental results indicate that our approach, which jointly optimizes the selection of collaborators, is superior. For instance, inscenarios like Grid 4 4 and Grid 5 5, using a fixed or random collaborator matrix leads to performance degradation, with the performancedeteriorating even further in the latter stages of learning. Observing all five scenarios, both the fixed and random matrices demonstratesimilar performance trends. This suggests that such non-learning-based approaches may lack adaptability to the dynamic nature of trafficscenarios and cant effectively capture the intricate interactions among intersections. In contrast, our joint optimization paradigm is betterpositioned to leverage the interplay and achieve optimal collaboration for boosting traffic signal control.",
  "To assess the significance of the constraints in Equations (8) and (9), we conduct a thorough ablation study across five scenarios. Specifically:": "w/o Diagonal: The constraint for diagonal maximization is removed. w/o Symmetry: The symmetry constraint is omitted. w/o Both: Both the diagonal maximization and symmetry constraints are eliminated.From this setup, we aim to understand the individual and combined roles of these constraints in the overall performance and adaptability ofour model in various traffic situations.As depicted in Figure A2, for scenarios like Grid 4 4 and Grid 5 5, all these configurations can eventually achieve similar performancelevels. However, when incorporating the proposed constraints, theres a clear advantage in terms of quickly reaching peak performance, thusshowcasing faster convergence. Specifically, in the Grid 4 4 scenario, removing the diagonal maximization constraint results in significantperformance degradation in the early stages. This suggests that decisions in this scenario might rely more heavily on the features of theintersection itself. On the other hand, other scenarios display larger performance drops when the symmetry constraint is removed, indicatinga greater need to consider mutual characteristics for more decisive and interoperable decision-making. Both Cologne8 and Nanshan scenariosshow a trend of stagnating learning when constraints are removed. This implies that these constraints play a vital role in guiding the learning",
  "First, let us delineate the experimental setup for this section": "w/o FRAP: Remove the FRAP module from the dual-feature extractor, retaining only the intersection-level features. w/o Transformer: Eliminate the Transformer module from the dual-feature extractor, keeping solely the phase-level features. w/o Teammate: Remove the CoS module, resulting in no teammate coordination. CoS with GNN: Replace the MLPs in the CoS module with GNNs. In this section, we present multi-dimensional training curves for various evaluation metrics including average episode rewards, averagedelay time, average wait time, average queue length, and average pressure across different scenarios. These results supplement our mainablation studies and provide a more comprehensive understanding of the performance and robustness of our algorithm under variousconditions. Ablation analysis on average episode rewards. As shown in Figure A3, In experiments across Grid 4 4, Avenue 4 4, Grid 5 5, andCologne8, we observed a significantly slower convergence rate for CoS with GNN, taking much longer to reach a plateau compared toour algorithm. For the Nanshan map, which features an irregular topology with 28 intersections, the slowdown was less pronounced. Wespeculate that in such a complex scenario, GNNs might be better at capturing inherent dynamical information, thus resulting in a decentconvergence rate and performance. However, for this setting, training our CoS on a single seed (300k timestamps) took just 13.1 hours,whereas the GNN variant took a staggering 40.8 hours. In terms of GPU consumption for a single process, the MLP version of CoS peaked at1.5G, while the GNN version utilized nearly 12G. This clearly demonstrates that while achieving competitive performance, CoS with MLPssignificantly save on computational resources.The above is an evaluation of the training curve concerning the average episode reward. Subsequently, the training curves for fine-grainedevaluations in each scenario, including the average delay time, average wait time, average queue length, and average pressure, are provided. Ablation analysis on average delay time. As depicted in Figure A4, which presents the learning curves from the ablation study concerning theaverage delay time, our algorithm with all its modules demonstrates significant improvements in four out of the five scenarios. The oneexception was Nanshan, where the impact of our finely-designed modules appeared to be less substantial.",
  "Figure A3: Learning curves of the ablation study of the various components about the average episode rewards": "We hypothesize that this anomaly may be due to the larger scale of the Nanshan map. The complexity inherent in larger maps mightdilute the effects of our specialized modules when it comes to reducing delay times. However, the consistent improvements in the other fourscenarios underscore the overall effectiveness of our algorithm and its components, proving their value in optimizing traffic signal controlacross a majority of scenarios. Ablation analysis on average wait time. Figure A5 shows the learning curves of the ablation study about the average wait time. In terms ofaverage waiting time, our complete algorithm has shown consistent performance advantages across all maps. This indicates that the fullsuite of modules in our approach is highly effective in reducing wait times, a critical factor in traffic signal control. The uniform successacross all scenarios reinforces the robustness of our method and its potential for broad application in diverse traffic situations. Ablation analysis on average queue length. As illustrated in Figure A6, which displays the learning curves of the ablation study about theaverage queue length, our full algorithm showed consistent performance improvements in all scenarios, except for the Avenue 4 4. Webelieve that the complexity and high traffic flow of the Avenue 4 4 scenario may have resulted in the less noticeable improvement in queuelength by our algorithm.This suggests that while our method performs excellently across most scenarios, certain situations with high complexity and trafficdensity may present additional challenges. Despite this, the overall performance advantage in the majority of scenarios reinforces theeffectiveness of our approach, demonstrating its capability to manage queue length - an important factor in traffic flow control. Ablation analysis on average pressure. Figure A7 shows the learning curves of the ablation study about the average pressure. Our completealgorithm performed better in all situations, except for the Avenue 4 4 scenario. We conjecture that the high complexity and significanttraffic volume of the Avenue scenario may have led to a less noticeable effect in pressure reduction from our algorithm.This trend does shed light on a possible limitation of our method, which might yield smaller performance improvements in highly complexscenarios with dense traffic flow. However, this should not be seen as a significant shortcoming. When compared to baseline algorithms, ourmethod still displays substantial advantages. Additionally, our complete algorithm achieved significant and consistent improvements in allother scenarios, attesting to its robustness and general effectiveness in TSC.",
  "FADDITIONAL ANALYSIS OF COLLABORATOR NUMBER": "In this section, we present violin plots for all scenarios in Figure A8, demonstrating the effect of varying the number of collaborators. Notably,in the Grid 4 4 scenario, there is a clear trend of performance enhancement as the number of collaborators increases. This indicates that, insuch a straightforward grid environment, the performance improvements brought about by targeted collaboration between collaboratorsmay not be as significant as those from the incorporation of information from across the entire map. In this simple case, the informationis either not redundant, or the decision-making is not affected by any redundant information. In the Cologne8 scenario, the performanceimprovements brought about by increasing the number of collaborators are not apparent. This suggests that, in this extremely simplistic mapwith sparse traffic and only eight intersections, collaboration between collaborators may not be as crucial. In other maps, a balance similarto what we mentioned earlier is displayed. It signifies the nuanced relationship between the number of collaborators and the resultingperformance improvement.In each map, varying the number of collaborators can influence the performance differently, highlighting the importance of tailoringstrategies to specific scenarios. For instance, while Grid 4 4 benefits more from a holistic information integration across all intersections,Cologne8 sees limited gains from extensive collaborators due to its simplicity and sparse traffic. The analysis also underscores the fact thatthe environmental complexity and specific scenario factors heavily influence this relationship. This further highlights the importance ofadaptively determining the appropriate number of collaborators, a potential area for future exploration. The Number of Teammates 0.50 0.45 0.40 0.35 0.30 0.25",
  "GADDITIONAL VISUALIZATION ANALYSIS OF COLLABORATOR MATRIX": "In this section, we present an extended visualization analysis, incorporating heat maps across all scenarios in Figure A9 to provide amore comprehensive understanding of the learning dynamics. This additional material affirms the intriguing pattern that we have alreadydiscussed: intersections are not only learning to concentrate on their own states, but they also develop an awareness of their peers. Thisreveals a collaborative learning process among intersections.Each intersection manages to strike a balance between self-attention and peer attention, learning to recognize when collaborationcould bring about performance improvements. In this way, we see that our algorithm has fostered a learned mutual collaboration amongintersections. These observations offer a broader validation of the effectiveness of our approach in developing a collaborative environmentamong intersections, which ultimately leads to performance enhancement across different scenarios.",
  "Figure A9: Additional visualization of team matrix. The deeper the color, the stronger the correlation": "conditions and intricacies inherent to the location, the clustering pattern indicates that the model successfully interprets and distills theseunique characteristics into its decision-making process. This ability to learn and adapt to the unique features of each intersection is a keystrength of our approach and provides a significant contribution to performance improvement.",
  "IADDITIONAL VISUALIZATION ANALYSIS OF COLLABORATOR ASSIGNMENT": "In this section, we provide additional results for the visualization of the collaborator assignment. Specifically, we conducted tests on theCologne8 and Avenue 44 scenarios, with collaborator counts of 1, 2, 3, 4, and 5. We refrained from testing scenarios with a larger number ofintersections and collaborators due to the diversity of bar colors, which could complicate observation and prevent meaningful conclusions.",
  "In Figure A12, we present the evolution of the collaborator assignment on the Cologne8 dataset": "We have previously analyzed scenarios when the collaborator number K equals 1 and 3 in the main manuscript. For K=2, we observe an intriguing mutual selection trend among agents 2 and 3, as well as agents 4 and 5. Through the reconstructionof the original traffic flow, we identified traffic correlations between these agent pairs, further validating the efficacy of our adaptivemethod in selecting the most suitable collaborators. When K is increased to 4, agent 4 primarily chooses agents 4, 2, 1, and 5 as collaborators, agent 2 predominantly selects agents 2, 3, 1,and 6, while agent 1 mainly selects agents 1, 2, 4, and 0. This collaborative behavior suggests that our approach can manage morecomplex scenarios where multiple agents are involved. Upon further increasing K to 5, we observe an emergence of cross-collaboration within the virtual subareas, which solidifies ourearlier observations that our algorithm can effectively handle cross-topology collaborator selection.This cross-collaboration phenomenon also demonstrates the flexibility of our method in creating dynamic, adaptive collaborations, even incomplex environments with multiple agents. In summary, these results strongly indicate that our learning-based strategy can adaptivelyselect the optimal collaborators based on the intrinsic dynamics and the evolving nature of the traffic flow. This adaptive approach tocollaborator selection provides a more responsive and effective mechanism to manage the complexities of real-world traffic scenarios.Subsequently, in Figure A13, we present an examination of collaborator assignment on the Avenue 4 4 dataset to further substantiate theeffectiveness of our approach. At K=1, the vast majority of agents are capable of selecting themselves as collaborators. Interestingly, agent 0 consistently choosesagent 11 as its collaborator. Through the reconstruction of the original traffic network, we observed that agents 0 and 11 are situatedadjacent to each other on the network, with highly correlated traffic flow. This finding indirectly confirms our methods ability tolearn inherent traffic patterns. Other instances of mutual selection are occasionally observed, for example, between agents 4 and 5. When K is incremented to 2, agent 0 continues to select agent 11 and adds itself to the list of collaborators. A mutual selection trend isalso observed among agent pairs 5 and 10, 1 and 11, as well as 4 and 13. For K=3, agent 0 includes a new collaborator, agent 3, in addition to itself and agent 11. Correspondingly, agent 3 tends to chooseagents 3, 0, and 11 as its collaborators. Other agents also display mutual selection within their collaborative subareas.",
  "Figure A13: Visualization of the collaborator assignment on Avenue 44": "As K expands to 4, agent 0 adds another new collaborator, agent 6, to its previous collaborators (0, 11, 3). This pattern of incrementallyadding new collaborators as the number of options increases demonstrates our algorithms capacity to recognize the intrinsic trafficdynamics and interrelation among multiple intersections. With K=5, upon careful analysis, the aforementioned phenomena and supporting conclusions continue to hold.In conclusion, these results convincingly demonstrate that our approach is effective in selecting collaborators adaptively in different scenarios.Not only does it capture the intrinsic dynamics of the traffic but also discerns the inherent relations between multiple intersections, thusestablishing the value of our method in dealing with complex traffic scenarios."
}