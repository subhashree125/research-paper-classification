{
  "Abstract": "Collaborative Filtering (CF) often encounters substantial difficulties with popularity bias because of the skeweddistribution of items in real-world datasets. This tendency creates a notable difference in accuracy between itemsthat are popular and those that are not. This discrepancy impedes the accurate comprehension of user preferencesand intensifies the Matthew effect within recommendation systems. To counter popularity bias, current methodsconcentrate on highlighting less popular items or on differentiating the correlation between item representationsand their popularity. Despite their effectiveness, current approaches continue to grapple with two significantissues: firstly, the extraction of shared supervisory signals from popular items to enhance the representations ofless popular items, and secondly, the reduction of representation separation caused by popularity bias. In thisstudy, we present an empirical examination of popularity bias and introduce a method called Popularity-AwareAlignment and Contrast (PAAC) to tackle these two problems. Specifically, we utilize the common supervisorysignals found in popular item representations and introduce an innovative popularity-aware supervised alignmentmodule to improve the learning of representations for unpopular items. Furthermore, we propose adjusting theweights in the contrastive learning loss to decrease the separation of representations by focusing on popularity.We confirm the efficacy and logic of PAAC in reducing popularity bias through thorough experiments on threereal-world datasets.",
  "Introduction": "Contemporary recommender systems are essential in reducing information overload. Personalized recommendations frequentlyemploy collaborative filtering (CF) to assist users in discovering items that may interest them. CF-based techniques primarilylearn user preferences and item attributes by matching the representations of users with the items they engage with. Despite theirachievements, CF-based methods frequently encounter the issue of popularity bias, which leads to considerable disparities inaccuracy between items that are popular and those that are not. Popularity bias occurs because there are limited supervisory signalsfor items that are not popular, which results in overfitting during the training phase and decreased effectiveness on the test set. Thishinders the precise comprehension of user preferences, thereby diminishing the variety of recommendations. Furthermore, popularitybias can worsen the Matthew effect, where items that are already popular gain even more popularity because they are recommendedmore frequently. Two significant challenges are presented when mitigating popularity bias in recommendation systems. The first challenge is theinadequate representation of unpopular items during training, which results in overfitting and limited generalization ability. Thesecond challenge, known as representation separation, happens when popular and unpopular items are categorized into distinctsemantic spaces, thereby intensifying the bias and diminishing the precision of recommendations.",
  "Methodology": "To overcome the current difficulties in reducing popularity bias, we introduce the Popularity-Aware Alignment and Contrast (PAAC)method. We utilize the common supervisory signals present in popular item representations to direct the learning of unpopularrepresentations, and we present a popularity-aware supervised alignment module. Moreover, we incorporate a re-weighting systemin the contrastive learning module to deal with representation separation by considering popularity.",
  "Supervised Alignment Module": "During the training process, the alignment of representations usually emphasizes users and items that have interacted, often causingitems to be closer to interacted users than non-interacted ones in the representation space. However, because unpopular items havelimited interactions, they are usually modeled based on a small group of users. This limited focus can result in overfitting, as therepresentations of unpopular items might not fully capture their features. The disparity in the quantity of supervisory signals is essential for learning representations of both popular and unpopular items.Specifically, popular items gain from a wealth of supervisory signals during the alignment process, which helps in effectivelylearning their representations. On the other hand, unpopular items, which have a limited number of users providing supervision, aremore susceptible to overfitting. This is because there is insufficient representation learning for unpopular items, emphasizing theeffect of supervisory signal distribution on the quality of representation. Intuitively, items interacted with by the same user havesome similar characteristics. In this section, we utilize common supervisory signals in popular item representations and suggest apopularity-aware supervised alignment method to improve the representations of unpopular items. We initially filter items with similar characteristics based on the users interests. For any user, we define the set of items they interactwith. We count the frequency of each item appearing in the training dataset as its popularity. Subsequently, we group items based ontheir relative popularity. We divide items into two groups: the popular item group and the unpopular item group. The popularity ofeach item in the popular group is higher than that of any item in the unpopular group. This indicates that popular items receive moresupervisory information than unpopular items, resulting in poorer recommendation performance for unpopular items. To tackle the issue of insufficient representation learning for unpopular items, we utilize the concept that items interacted with by thesame user share some similar characteristics. Specifically, we use similar supervisory signals in popular item representations toimprove the representations of unpopular items. We align the representations of items to provide more supervisory information tounpopular items and improve their representation, as follows:",
  "Re-weighting Contrast Module": "Recent research has indicated that popularity bias frequently leads to a noticeable separation in the representation of item embeddings.Although methods based on contrastive learning aim to enhance overall uniformity by distancing negative samples, their currentsampling methods might unintentionally worsen this separation. When negative samples follow the popularity distribution, whichis dominated by popular items, prioritizing unpopular items as positive samples widens the gap between popular and unpopularitems in the representation space. Conversely, when negative samples follow a uniform distribution, focusing on popular itemsseparates them from most unpopular ones, thus worsening the representation gap. Existing studies use the same weights for positiveand negative samples in the contrastive loss function, without considering differences in item popularity. However, in real-worldrecommendation datasets, the impact of items varies due to dataset characteristics and interaction distributions. Neglecting thisaspect could lead to suboptimal results and exacerbate representation separation. We propose to identify different influences by re-weighting different popularity items. To this end, we introduce re-weightingdifferent positive and negative samples to mitigate representation separation from a popularity-centric perspective. We incorporatethis approach into contrastive learning to better optimize the consistency of representations. Specifically, we aim to reduce the riskof pushing items with varying popularity further apart. For example, when using a popular item as a positive sample, our goal isto avoid pushing unpopular items too far away. Thus, we introduce two hyperparameters to control the weights when items areconsidered positive and negative samples. To ensure balanced and equitable representations of items within our model, we first propose a dynamic strategy to categorize itemsinto popular and unpopular groups for each mini-batch. Instead of relying on a fixed global threshold, which often leads to theoverrepresentation of popular items across various batches, we implement a hyperparameter x. This hyperparameter readjusts theclassification of items within the current batch. By adjusting the hyperparameter x, we maintain a balance between different itempopularity levels. This enhances the models ability to generalize across diverse item sets by accurately reflecting the popularitydistribution in the current training context. Specifically, we denote the set of items within each batch as IB. And then we divide IBinto a popular group Ipop and an unpopular group Iunpop based on their respective popularity levels, classifying the top x% of itemsas Ipop:",
  "IB = Ipop Iunpop, i Ipop j Iunpop, p(i) > p(j),(2)": "where Ipop IB and Iunpop IB are disjoint, with Ipop consisting of the top x% of items in the batch. In this work, we dynamicallydivided items into popular and unpopular groups within each mini-batch based on their popularity, assigning the top 50% as popularitems and the bottom 50% as unpopular items. This radio not only ensures equal representation of both groups in our contrastivelearning but also allows items to be classified adaptively based on the batchs current composition. After that, we use InfoNCE to optimize the uniformity of item representations. Unlike traditional CL-based methods, we calculatethe loss for different item groups. Specifically, we introduce the hyperparameter to control the positive sample weights betweenpopular and unpopular items, adapting to varying item distributions in different datasets:",
  "LCLitem = LCLpop + (1 ) LCLunpop,(3)": "where LCLpop represents the contrastive loss when popular items are considered as positive samples, and LCLunpop represents thecontrastive loss when unpopular items are considered as positive samples. The value of ranges from 0 to 1, where = 0 meansexclusive emphasis on the loss of unpopular items LCLunpop, and = 1 means exclusive emphasis on the loss of popular itemsLCLpop. By adjusting , we can effectively balance the impact of positive samples from both popular and unpopular items, allowingadaptability to varying item distributions in different datasets. Following this, we fine-tune the weighting of negative samples in the contrastive learning framework using the hyperparameter .This parameter controls how samples from different popularity groups contribute as negative samples. Specifically, we prioritizere-weighting items with popularity opposite to the positive samples, mitigating the risk of excessively pushing negative samplesaway and reducing representation separation. Simultaneously, this approach ensures the optimization of intra-group consistency. Forinstance, when dealing with popular items as positive samples, we separately calculate the impact of popular and unpopular itemsas negative samples. The hyperparameter is then used to control the degree to which unpopular items are pushed away. This isformalized as follows:",
  "iIunpoplogexp(hihi/)jIunpop exp(hihj/) + jIpop exp(hihj/),(5)": "where the parameter ranges from 0 to 1, controlling the negative sample weighting in the contrastive loss. When = 0, it meansthat only intra-group uniformity optimization is performed. Conversely, when = 1, it means equal treatment of both popular andunpopular items in terms of their impact on positive samples. The setting of allows for a flexible adjustment between prioritizingintra-group uniformity and considering the impact of different popularity levels in the training. We prefer to push away itemswithin the same group to optimize uniformity. This setup helps prevent over-optimizing the uniformity of different groups, therebymitigating representation separation.",
  "L = LREC + 1LSA + 2LCL + 3||||2,(7)": "where is the set of model parameters in LREC as we do not introduce additional parameters, 1 and 2 are hyperparameters thatcontrol the strengths of the popularity-aware supervised alignment loss and the re-weighting contrastive learning loss respectively,and 3 is the L2 regularization coefficient. After completing the model training process, we use the dot product to predict unknownpreferences for recommendations.",
  "Baselines and Evaluation Metrics": "We implement the state-of-the-art LightGCN to instantiate PAAC, aiming to investigate how it alleviates popularity bias. Wecompare PAAC with several debiased baselines, including re-weighting-based models, decorrelation-based models, and contrastivelearning-based models. We utilize three widely used metrics, namely Recall@K, HR@K, and NDCG@K, to evaluate the performance of Top-K recommen-dation. Recall@K and HR@K assess the number of target items retrieved in the recommendation results, emphasizing coverage. Incontrast, NDCG@K evaluates the positions of target items in the ranking list, with a focus on their positions in the list. We usethe full ranking strategy, considering all non-interacted items as candidate items to avoid selection bias during the test stage. Werepeated each experiment five times with different random seeds and reported the average scores.",
  "Overall Performance": "As shown in , we compare our model with several baselines across three datasets. The best performance for each metricis highlighted in bold, while the second best is underlined. Our model consistently outperforms all compared methods across allmetrics in every dataset. Our proposed model PAAC consistently outperforms all baselines and significantly mitigates the popularity bias. Specif-ically, PAAC enhances LightGCN, achieving improvements of 282.65%, 180.79%, and 82.89% in NDCG@20 on theYelp2018, Gowalla, and Amazon-Book datasets, respectively. Compared to the strongest baselines, PAAC delivers betterperformance. The most significant improvements are observed on Yelp2018, where our model achieves an 8.70% increasein Recall@20, a 10.81% increase in HR@20, and a 30.2% increase in NDCG@20. This improvement can be attributedto our use of popularity-aware supervised alignment to enhance the representation of less popular items and re-weightedcontrastive learning to address representation separation from a popularity-centric perspective. The performance improvements of PAAC are smaller on sparser datasets. For example, on the Gowalla dataset, theimprovements in Recall@20, HR@20, and NDCG@20 are 3.18%, 5.85%, and 5.47%, respectively. This may be because,in sparser datasets like Gowalla, even popular items are not well-represented due to lower data density. Aligning unpopularitems with these poorly represented popular items can introduce noise into the model. Therefore, the benefits of usingsupervisory signals for unpopular items may be reduced in very sparse environments, leading to smaller performanceimprovements. Regarding the baselines for mitigating popularity bias, the improvement of some is relatively limited compared to thebackbone model (LightGCN) and even performs worse in some cases. This may be because some are specifically designedfor traditional data-splitting scenarios, where the test set still follows a long-tail distribution, leading to poor generalization.Some mitigate popularity bias by excluding item popularity information. Others use invariant learning to remove popularityinformation at the representation level, generally performing better than the formers. This shows the importance ofaddressing popularity bias at the representation level. Some outperform the other baselines, emphasizing the necessary toimprove item representation consistency for mitigating popularity bias. Different metrics across various datasets show varying improvements in model performance. This suggests that differentdebiasing methods may need distinct optimization strategies for models. Additionally, we observe varying effects of PAACacross different datasets. This difference could be due to the sparser nature of the Gowalla dataset. Conversely, our modelcan directly provide supervisory signals for unpopular items and conduct intra-group optimization, consistently maintainingoptimal performance across all metrics on the three datasets.",
  "Ablation Study": "To better understand the effectiveness of each component in PAAC, we conduct ablation studies on three datasets. presents acomparison between PAAC and its variants on recommendation performance. Specifically, PAAC-w/o P refers to the variant wherethe re-weighting contrastive loss of popular items is removed, focusing instead on optimizing the consistency of representations forunpopular items. Similarly, PAAC-w/o U denotes the removal of the re-weighting contrastive loss for unpopular items. PAAC-w/oA refers to the variant without the popularity-aware supervised alignment loss. Its worth noting that PAAC-w/o A differs from : Performance comparison on three public datasets with K = 20. The best performance is indicated in bold, while thesecond-best performance is underlined. The superscripts * indicate p 0.05 for the paired t-test of PAAC vs. the best baseline (therelative improvements are denoted as Imp.).",
  "Recall@20HR@20NDCG@20Recall@20HR@20NDCG@20Recall@20HR@20NDCG@20": "MF0.00500.01090.00930.03430.04220.02800.03700.03880.0270LightGCN0.00480.01110.00980.03800.04680.03020.04210.04390.0304IPS0.01040.01830.01580.05620.06700.04440.04880.05100.0365MACR0.04020.03120.02650.09080.10860.06000.05150.06090.0487-Adjnorm0.00530.00880.00800.03280.04090.02670.04220.04500.0264InvCF0.04440.03440.02910.10010.12020.06620.05620.06650.0515Adap-0.04500.04970.03410.11820.12480.07940.06410.06780.0511SimGCL0.04490.05180.03450.11940.12280.08040.06280.06480.0525PAAC0.0494*0.0574*0.0375*0.1232*0.1321*0.0848*0.0701*0.0724*0.0556*Imp.+9.78 %+10.81%+8.70%+3.18%+5.85%+5.47%+9.36%+6.78%5.90% SimGCL in that we split the contrastive loss on the item side, LCLitem, into two distinct losses: LCLpop and LCLunpop. This approachallows us to separately address the consistency of popular and unpopular item representations, thereby providing a more detailedanalysis of the impact of each component on the overall performance. From , we observe that PAAC-w/o A outperforms SimGCL in most cases. This validates that re-weighting the importance ofpopular and unpopular items can effectively improve the models performance in alleviating popularity bias. It also demonstrates theeffectiveness of using supervision signals from popular items to enhance the representations of unpopular items, providing moreopportunities for future research on mitigating popularity bias. Moreover, compared with PAAC-w/o U, PAAC-w/o P results in muchworse performance. This confirms the importance of re-weighting popular items in contrastive learning for mitigating popularitybias. Finally, PAAC consistently outperforms the three variants, demonstrating the effectiveness of combining supervised alignmentand re-weighting contrastive learning. Based on the above analysis, we conclude that leveraging supervisory signals from popularitem representations can better optimize representations for unpopular items, and re-weighting contrastive learning allows the modelto focus on more informative or critical samples, thereby improving overall performance. All the proposed modules significantlycontribute to alleviating popularity bias. : Ablation study of PAAC, highlighting the best-performing model on each dataset and metrics in bold. Specifically,PAAC-w/o P removes the re-weighting contrastive loss of popular items, PAAC-w/o U eliminates the re-weighting contrastive lossof unpopular items, and PAAC-w/o A omits the popularity-aware supervised alignment loss.",
  "Debias Ability": "To further verify the effectiveness of PAAC in alleviating popularity bias, we conduct a comprehensive analysis focusing on therecommendation performance across different popularity item groups. Specifically, 20% of the most popular items are labeledPopular, and the rest are labeled Unpopular. We compare the performance of PAAC with LightGCN, IPS, MACR, and SimGCLusing the NDCG@20 metric across different popularity groups. We use to denote the accuracy gap between the two groups. Wedraw the following conclusions: Improving the performance of unpopular items is crucial for enhancing overall model performance. Specially, on theYelp2018 dataset, PAAC shows reduced accuracy in recommending popular items, with a notable decrease of 20.14%compared to SimGCL. However, despite this decrease, the overall recommendation accuracy surpasses that of SimGCLby 11.94%, primarily due to a 6.81% improvement in recommending unpopular items. This improvement highlights theimportance of better recommendations for unpopular items and emphasizes their crucial role in enhancing overall modelperformance. Our proposed PAAC significantly enhances the recommendation performance for unpopular items. Specifically, we observean improvement of 8.94% and 7.30% in NDCG@20 relative to SimGCL on the Gowalla and Yelp2018 datasets, respectively.This improvement is due to the popularity-aware alignment method, which uses supervisory signals from popular items toimprove the representations of unpopular items. PAAC has successfully narrowed the accuracy gap between different item groups. Specifically, PAAC achieved the smallestgap, reducing the NDCG@20 accuracy gap by 34.18% and 87.50% on the Gowalla and Yelp2018 datasets, respectively.This indicates that our method treats items from different groups fairly, effectively alleviating the impact of popularitybias. This success can be attributed to our re-weighted contrast module, which addresses representation separation from apopularity-centric perspective, resulting in more consistent recommendation results across different groups.",
  "Hyperparameter Sensitivities": "In this section, we analyze the impact of hyperparameters in PAAC. Firstly, we investigate the influence of 1 and 2, whichrespectively control the impact of the popularity-aware supervised alignment and re-weighting contrast loss. Additionally, in there-weighting contrastive loss, we introduce two hyperparameters, and , to control the re-weighting of different popularity itemsas positive and negative samples. Finally, we explore the impact of the grouping ratio x on the models performance.",
  "Effect of 1 and 2": "As formulated in Eq. (11), 1 controls the extent of providing additional supervisory signals for unpopular items, while 2 controlsthe extent of optimizing representation consistency. Horizontally, with the increase in 2, the performance initially increases andthen decreases. This indicates that appropriate re-weighting contrastive loss effectively enhances the consistency of representationdistributions, mitigating popularity bias. However, overly strong contrastive loss may lead the model to neglect recommendationaccuracy. Vertically, as 1 increases, the performance also initially increases and then decreases. This suggests that suitablealignment can provide beneficial supervisory signals for unpopular items, while too strong an alignment may introduce more noisefrom popular items to unpopular ones, thereby impacting recommendation performance.",
  "Effect of re-weighting coefficient and": "To mitigate representation separation due to imbalanced positive and negative sampling, we introduce two hyperparameters into thecontrastive loss. Specifically, controls the weight difference between positive samples from popular and unpopular items, while controls the influence of different popularity items as negative samples. In our experiments, while keeping other hyperparameters constant, we search and within the range {0, 0.2, 0.4, 0.6, 0.8, 1}. As and increase, performance initially improves and then declines. The optimal hyperparameters for the Yelp2018 and Gowalladatasets are = 0.8, = 0.6 and = 0.2, = 0.2, respectively. This may be attributed to the characteristics of the datasets. TheYelp2018 dataset, with a higher average interaction frequency per item, benefits more from a higher weight for popular items aspositive samples. Conversely, the Gowalla dataset, being relatively sparse, prefers a smaller . This indicates the importance ofconsidering dataset characteristics when adjusting the contributions of popular and unpopular items to the model. Notably, and are not highly sensitive within the range , performing well across a broad spectrum. Performance exceeds thebaseline regardless of values when other parameters are optimal. Additionally, values from [0.4, 1.0] on the Yelp2018 datasetand [0.2, 0.8] on the Gowalla dataset surpass the baseline, indicating less need for precise tuning. Thus, and achieve optimalperformance without meticulous adjustments, focusing on weight coefficients to maintain model efficacy.",
  "Effect of grouping ratio x": "To investigate the impact of different grouping ratios on recommendation performance, we developed a flexible classificationmethod for items within each mini-batch based on their popularity. Instead of adopting a fixed global threshold, which tends tooverrepresent popular items in some mini-batches, our approach dynamically divides items in each mini-batch into popular andunpopular categories. Specifically, the top x% of items are classified as popular and the remaining (100 - x)% as unpopular, with xvarying. This strategy prevents the overrepresentation typical in fixed distribution models, which could skew the learning processand degrade performance. To quantify the effects of these varying ratios, we examined various division ratios for popular items,including 20%, 40%, 60%, and 80%, as shown in . The preliminary results indicate that both extremely low and high ratiosnegatively affect model performance, thereby underscoring the superiority of our dynamic data partitioning approach. Moreover,within the 40%-60% range, our models performance remained consistently robust, further validating the effectiveness of PAAC.",
  "Popularity Bias in Recommendation": "Popularity bias is a prevalent problem in recommender systems, where unpopular items in the training dataset are seldom recom-mended. Numerous techniques have been suggested to examine and decrease performance variations between popular and unpopularitems. These techniques can be broadly divided into three categories. Re-weighting-based methods aim to increase the training weight or scores for unpopular items, redirecting focus awayfrom popular items during training or prediction. For instance, IPS adds compensation to unpopular items and adjuststhe prediction of the user-item preference matrix, resulting in higher preference scores and improving rankings forunpopular items. -AdjNorm enhances the focus on unpopular items by controlling the normalization strength during theneighborhood aggregation process in GCN-based models. Decorrelation-based methods aim to effectively remove the correlations between item representations (or prediction scores)and popularity. For instance, MACR uses counterfactual reasoning to eliminate the direct impact of popularity on itemoutcomes. In contrast, InvCF operates on the principle that item representations remain invariant to changes in popularitysemantics, filtering out unstable or outdated popularity characteristics to learn unbiased representations. Contrastive-learning-based methods aim to achieve overall uniformity in item representations using InfoNCE, preservingmore inherent characteristics of items to mitigate popularity bias. This approach has been demonstrated as a state-of-the-artmethod for alleviating popularity bias. It employs data augmentation techniques such as graph augmentation or featureaugmentation to generate different views, maximizing positive pair consistency and minimizing negative pair consistencyto promote more uniform representations. Specifically, Adap- adjusts user/item embeddings to specific values, whileSimGCL integrates InfoNCE loss to enhance representation uniformity and alleviate popularity bias.",
  "Representation Learning for CF": "Representation learning is crucial in recommendation systems, especially in modern collaborative filtering (CF) techniques. Itcreates personalized embeddings that capture user preferences and item characteristics. The quality of these representations criticallydetermines a recommender systems effectiveness by precisely capturing the interplay between user interests and item features.Recent studies emphasize two fundamental principles in representation learning: alignment and uniformity. The alignment principleensures that embeddings of similar or related items (or users) are closely clustered together, improving the systems ability torecommend items that align with a users interests. This principle is crucial when accurately reflecting user preferences throughcorresponding item characteristics. Conversely, the uniformity principle ensures a balanced distribution of all embeddings across therepresentation space. This approach prevents the over-concentration of embeddings in specific areas, enhancing recommendationdiversity and improving generalization to unseen data. In this work, we focus on aligning the representations of popular and unpopular items interacted with by the same user and re-weighting uniformity to mitigate representation separation. Our model PAAC uniquely addresses popularity bias by combining groupalignment and contrastive learning, a first in the field. Unlike previous works that align positive user-item pairs or contrastive pairs,PAAC directly aligns popular and unpopular items, leveraging the rich information of popular items to enhance the representationsof unpopular items and reduce overfitting. Additionally, we introduce targeted re-weighting from a popularity-centric perspective toachieve a more balanced representation.",
  "Conclusion": "In this study, we have examined popularity bias and put forward PAAC as a method to lessen its impact. We postulated that itemsengaged with by the same user exhibit common traits, and we utilized this insight to coordinate the representations of both popularand unpopular items via a popularity-conscious supervised alignment method. This strategy furnished additional supervisory data forless popular items. It is important to note that our concept of aligning and categorizing items according to user-specific preferencesintroduces a fresh perspective on alignment. Moreover, we tackled the problem of representation separation seen in current CL-based models by incorporating two hyperparameters to regulate the influence of items with varying popularity levels when consideredas positive and negative samples. This method refined the uniformity of representations and successfully reduced separation. Wevalidated our method, PAAC, on three publicly available datasets, demonstrating its effectiveness and underlying rationale. In the future, we will explore deeper alignment and contrast adjustments tailored to specific tasks to further mitigate popularitybias. We aim to investigate the synergies between alignment and contrast and extend our approach to address other biases inrecommendation systems. This work was supported in part by grants from the National Key Research and Development Program of China, the National NaturalScience Foundation of China, the Fundamental Research Funds for the Central Universities, and Quan Cheng Laboratory."
}