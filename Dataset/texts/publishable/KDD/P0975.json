{
  "ABSTRACT": "Estimating cardinality, i.e., the number of distinct elements, of adata stream is a fundamental problem in areas like databases, com-puter networks, and information retrieval. This study delves intoa broader scenario where each element carries a positive weight.Unlike traditional cardinality estimation, limited research existson weighted cardinality, with current methods requiring substan-tial memory and computational resources, challenging for deviceswith limited capabilities and real-time applications like anomalydetection. To address these issues, we propose QSketch, a memory-efficient sketch method for estimating weighted cardinality instreams. QSketch uses a quantization technique to condense con-tinuous variables into a compact set of integer variables, with eachvariable requiring only 8 bits, making it 8 times smaller than previ-ous methods. Furthermore, we leverage dynamic properties duringQSketch generation to significantly enhance estimation accuracyand achieve a lower time complexity of (1) for updating estima-tions upon encountering a new element. Experimental results onsynthetic and real-world datasets show that QSketch is approxi-mately 30% more accurate and two orders of magnitude faster thanthe state-of-the-art, using only 1/8 of the memory.",
  "Equal Contribution. Corresponding Author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08 ACM Reference Format:Yiyan Qi, Rundong Li, Pinghui Wang, Yufang Sun, and Rui Xing. 2024. QS-ketch: An Efficient Sketch for Weighted Cardinality Estimation in Streams.In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discoveryand Data Mining (KDD 24), August 2529, 2024, Barcelona, Spain. ACM, NewYork, NY, USA, 12 pages.",
  "INTRODUCTION": "Real-world systems generate data in a streaming fashion. Exam-ples range from financial transactions to Internet of Things (IoT)data, network traffic, call logs, trajectory logs, etc. Computing thecardinality, i.e., the number of distinct elements, of such a streamis fundamental in research areas like databases, machine learning,and information retrieval. For example, online games and mobileapps usually use daily active users (DAU), i.e., the number of dis-tinct active users within a day, as a metric to measure the level ofengagement. Other examples include network security monitoring and connectivity analysis in the Internet graph .Due to the unknown or even unlimited size and the high-speednature of these data streams, it is infeasible to collect the entire datawhen the computation and memory resources of data collectiondevices (e.g., network routers) are limited. To solve this challenge,considerable attention has been paid to designing fast and memory-efficient cardinality estimating algorithms via sketching techniques. They build a compact data summary (i.e., sketch) onthe fly and then estimate the cardinality from the generated sketch.The above cardinality computing problem can be generalized toa weighted scenario, where each element e in the data stream isassociated with a positive weight R+. In this new scenario, thegoal is to compute the total sum of weights for all distinct elements,i.e., weighted cardinality. The weighted cardinality has variousapplications, including 1) In database systems, an example is a SQLquery like SELECT DISTINCT * FROM TABLE. In addition to thequerys cardinality, understanding the total size of the resultant setaids in optimizing performance and managing resources .Here, the weighted cardinality represents the total size (in bytes)of the query result, calculated as the cumulative size of all distinctrecords, weighted by their row size. 2) In a voting system, eachvoter may have a weight based on their expertise and we need it tofigure out the final voting result. 3) In an app or website, users with",
  "KDD 24, August 2529, 2024, Barcelona, SpainYiyan Qi et al": "more activity might be assigned higher weights. This metric allowsfor a more nuanced understanding of the app other than DailyActive User (DAU). Weighted cardinality computation is importantin scenarios where individual contributions vary in importance.Despite the plenty of works for estimating the regular cardi-nality, little attention has been paid to the problem of WeightedCardinality Estimation (WCE). Lemiesz conducts a formalstudy on the WCE problem. The proposed method maps each ele-ment in the data stream into exponential variables concerningthe elements weight. To guarantee estimation accuracy, is set tohundreds or thousands, making it infeasible to deal with real-timestreams. Zhang et al. proposed a method FastGM to decreasethe update time complexity of Lemieszs method. Instead of generat-ing variables independently, FastGM generates those exponentialvariables in ascending order and early stops the generation whenthe value is greater than the maximal value stored in the currentregisters. A recent method FastExp Sketch shares the same ideawith FastGM. The above three methods use 64-bit floating-point reg-isters to store these exponential variables. When a large value of isemployed for improved accuracy, it becomes memory-intensive fordevices with limited computational and storage resources. Addition-ally, they require () operations to estimate weighted cardinality,making them computationally expensive when aiming to provideanytime-available estimation for real-time applications.We develop a memory-efficient sketch, QSketch, to estimate theweighted cardinality of distinct elements in a data stream. QSketchgenerates independent exponential variables for each incomingelement in descending order. This process is employed to update the integer registers, and an early termination occurs when a gen-erated variable is smaller than the values in all registers. QSketchemploys a novel mapping strategy that transforms continuous expo-nential variables into discrete variables, using a small set of integerregisters to represent data streams with varying weighted cardinal-ities. Consequently, each register in our QSketch requires no morethan 5 bits, making it up to 13 smaller than both Lemieszs methodand FastGM. To reduce time cost and estimation error, we proposean extension of QSketch, QSketch-Dyn, to monitor the weighted car-dinality on the fly. QSketch-Dyn shares the same data structure asQSketch but only needs to compute one variable for each element. Itutilizes the dynamic property of our QSketch to reduce estimationerror significantly. We summarize our main contributions as: We propose a memory-efficient sketch method QSketch to es-timate the weighted cardinality of distinct elements in a datastream. QSketch employs a novel mapping strategy that trans-forms continuous exponential variables into discrete variables,using a small set of integer registers to represent data streamswith varying weighted cardinalities.",
  "PROBLEM FORMULATION": "We first introduce some notations. Let = e(1) e( ) denotea data stream, where an element e( ) arriving at time correspondsto one of the elements 1, . . . , and each , 1 has apositive weight > 0. Note that an element e may appear multipletimes in the stream. Denote ( )as the set of distinct elementsthat occurred in stream before and including time . Then, theweighted cardinality of stream at is defined as",
  "Existing Methods For WCE": "Lemieszs Method builds a sketch consisting of registers, . . . , []. Typically, is set to be thousands to guarantee thedesired accuracy. All registers are initialized to +. For each {1, . . . ,}, let ( ) [] denote the value of [] at time . Foreach e( ) arriving at time , Lemieszs method maps it into all registers independently and each register is updated as",
  "QSketch: An Efficient Sketch for Weighted Cardinality Estimation in StreamsKDD 24, August 2529, 2024, Barcelona, Spain": "follows an exponential distribution EXP( ( )), in which ( ) isthe weighted cardinality at time . Thus, the summation variable = =1 ( ) [] follows a gamma distribution (, ( )).According to , the inverse of the summation variable , i.e.,1/, has the inverse gamma distribution 1/ 1(, ( )),and we have",
  "gers 1, . . . ,. Once the current obtained random variable ln1 ( )": "is larger than all values in registers ( ) , . . . , ( ) [], there isno need to generate the following random variables because theyhave no chance to change the sketch. In detail, for each e( ) = ,1 , FastGM generates the first exponential variable as",
  ".(4)": "After generating a hash value (e( )), {1, . . . ,}, FastGMuses the Fisher-Yates shuffle to find its position {1, . . . ,}.Specially, let (1, . . . , ) be initialized to (1, . . . ,). To obtain theposition of the -th smallest hash value, FastGM randomly chooses aposition {, +1, . . . ,}, swaps and , and updates ( ) []with (e( )). FastGM uses an extra register to perform an earlystop to record the maximal values among registers. Registervalues in FastGM follow the same distribution as LM. They sharethe same weighted cardinality estimator and the same estimationerrors. Besides, we find that a recent method FastExpSketch shares the same idea with FastGM.",
  ": Basic idea of QSketch": "a stream . When we need a large for better accuracy or thereare many different streams, it is memory-intensive for devices (e.g.IoT devices or routers) with limited computational and storageresources. Therefore, reducing the number of bits for each registeris practical, saving storage space and improving the computationalefficiency for sketch operations . Time-consuming. Lemieszs method requires updating eachregister for element insertion, incurring an () time cost. WhileFastGM improves upon this by ordering register updates, it still de-mands () time in the worst-case scenario when element weightsgrow over time. Furthermore, the time complexity for the estimationprocess in both methods is quantified as (). Such a computa-tional demand poses challenges for providing consistent, real-timeestimations in applications that require immediate data availability.",
  "OUR METHOD": "In this section, we first introduce a compact sketch QSketch (Quan-tization Sketch) which utilizes the quantization technique (i.e.,mapping continuous infinite values to a small set of discrete values).We design a novel estimator to estimate weighted cardinality. Then,we exploit the dynamic properties of the register arrays over timeto significantly improve the estimation accuracy and reduce thetime cost to monitor the weighted cardinality on the fly.",
  "QSketch": "Data structure and update procedure. Denote as the sketchwith registers , . . . , [], and 1, . . . , as independenthash functions, each of them mapping to a random value in range(0, 1) uniformly, i.e., () Uniform(0, 1), 1 . Wheninserting e which is associated with i and weight , we generate variables 1(e), . . . ,(e) as",
  "[] max([], (e)).(6)": "Following , we generate variables 1 (e), . . . , (e) in anascending order, in which (1, . . . , ) is a random permutationof (1, . . . ,). As a result, 1 (e), . . . , (e) are generated in adescending order. The update procedure is shown in Algorithm 2.We use the Fisher-Yates shuffle (Line 11-12 in Algorithm 2)to quickly find the position to be updated and use to record",
  "arg min=1,..., [] ;": "the registers index that records the sketchs minimum values. Abrief introduction to the Fisher-Yates shuffle is in Appendix A.1.When the generated variable is smaller than [], we early stopthe generation procedure.Weighted Cardinality Estimation. Direct use of the estimator inEquation (2) yields a large estimation error since the quantizationleads to a loss of precision. Instead, we design a new estimatorwith the help of Maximum Likelihood Estimation (MLE). Beforethat, we first derive the probability distribution of a single register[], 1 . It has been proved that a register value (withoutquantization) follows an exponential distribution EXP() ,in which is the weighted cardinality of stream . In QSketch,according to Equation (5), we quantize the continuous register valueto discrete values. Particularly, continuous register values in therange (2(+1), 2] will be compressed into a discrete value .Then the probability distribution of a single register value [] is",
  "(0)= 11 2": "Since the register values in QSketch are the quantization of registervalues in FastGM, (0)can be viewed as an approximation of ,which is reasonable as an initial value to guarantee convergence.The above MLE-based estimator provides an asymptotically un-biased estimation. The approximate variance of the above estima-tor is based on the Cramr-Rao bound . Specifically, we haveVar 1",
  "( () )": "Through the quantization, all possible values of(e) are integers,i.e., (e) Z. In practice, we notice that most values of (e) areconcentrated in a small range and we can truncate these gener-ated variables by (e) = min(max((e),min),max). As a result,adjusting the probability distribution of the truncated value in eachregister is necessary, as shown in Equation (7).",
  "(+1) 2, otherwise": "By substituting the above probability to Equation (8), we get theweighted cardinality estimator under truncated values. Note thatthe estimator only fails to give an unbiased estimation when allregister values equal min or max as the likelihood function ()becomes monotonous without an extremum. Fortunately, in thefollowing theorem, we show that by properly setting min and max,the failure probability is extremely low.",
  "QSketch-Dyn": "QSketch has the same expected time complexity of ( ln + )as FastGM . However, it still suffers from the worst timecomplexity () under scenarios in which the weights of the ele-ments increase as time progresses. In addition, we have to solve theMLE problem whenever figuring out the latest weighted cardinality,which costs for real-time estimation. To improve the estimation ef-ficiency, we utilize the dynamic property of the sketch and proposeQSketch-Dyn to keep track of the weighted cardinality on the fly.Data structure and update procedure. QSketch-Dyn shares thesame data structure, i.e., a bit array of size , and the same setof hash functions 1, . . . , as Lemieszs method . The maindifferences are: 1) QSketch-Dyn introduces another hash function(), which uniformly maps to some integer in set {1, . . . ,}at random. 2) QSketch-Dyn maintains a tabular to record thefrequency of values in the sketch. Specifically, the tabular consistsof 2 counters, in which is the number of bits used by a register.Next, we introduce how to update an element e( ) correspond-ing to and . Instead of updating multiple register values as inother methods, QSketch-Dyn first randomly chooses one register[] with = (), 1 from the sketch, computes itsquantized hash value (e) = log2( (e)) (Equation 5), andupdate the register value [] max([], (e)) (Equation 6).Once the register value [] changes, we then update the tabular as [[]] [[]] 1 and [ (e)] [ (e)] + 1.",
  ";": "The computation of probability ( )needs summation over all registers, which is time-consuming when is set to a large value.To save time, we additionally maintain a tabular recording thehistogram of register values as mentioned above, where [[]]tracks the count of value [] in the current sketch. As discussedpreviously, each register occupies bits and the number of differentvalues is at most 2. Then, ( )is expressed as",
  "2 [[]] (2(+1) )": "We summarize the pseudo-code of the update and estimation pro-cedure of QSketch-Dyn in Algorithm 3.Complexity Analysis. The time complexity of updating an ele-ment for QSketch-Dyn is (1) since it only chooses one registerto update its value. Then it costs (2) time for QSketch-Dyn tocompute ( ) . Considering that is small, this part costs little time.Finally, QSketch-Dyn tracks the estimated cardinality over time,and it costs no time for estimation compared with QSketch. Forspace complexity, QSketch uses registers, in which each registeroccupies bits. Besides, QSketch-Dyn maintains a tabular with 2 counters. Since there are registers in the sketch, each counter oftabular occupies at most log2() bits. Therefore, the total spacecomplexity is + 2 log2().Error Analysis. For the estimated weighted cardinality ( )fromQSketch-Dyn, we first prove that our estimator is unbiased andthen derive the variance of ( ) .",
  "Datasets": "We conduct experiments on both synthetic and real-world datasets. Synthetic Datasets. We generate synthetic datasets with thefollowing distributions: Uniform distribution (0, 1), Gauss distri-bution (1, 0.1), and Gamma distribution (1, 2) For each type ofdistribution, we generate datasets with different sizes of elements,respectively. The name of the dataset is represented as distribution-#elements. For example, Uniform-1k represents the dataset with1, 000 elements, and the weight of each element follows the Uniformdistribution (0, 1). Each dataset is considered a single stream. Real-world Datasets. We use the following real-world datasets:Twitter , Real-sim , Rcv1 , Webspam , News20 Libimseti . Twitter is a dataset of following relation-ships between Twitter users. The above two datasets are treatedas single-stream datasets. Real-sim , Rcv1 , Webspam and News20 are datasets of web documents from differentresources, where each vector represents a document and each entryin the vector refers to the TF-IDF score of a specific word for thedocument. Libimseti is a dataset of ratings of different users,where each vector refers to a user and each entry records the usersrating. These six datasets are considered multi-stream datasets, andeach vector within the dataset is a single stream of elements with aweight. The details of these datasets are described in .",
  "Baselines": "We compare QSketch and QSketch-Dyn, with state-of-the-art meth-ods, Lemieszs method (represented as LM), FastGM andFastExp Sketch . All baseline methods maintain a sketch with 64-bit registers. QSketch and QSketch-Dyn are truncated withmin = 127 and max = 127, i.e., they all use 8-bit integer registersby default. We assign each algorithm the same number of registers, which means QSketch and QSketch-Dyn use about 1/8 of the mem-ory space of baseline methods. Following , we use a 32-bit wordto hold multiple short-bit registers. For example, with each registerset to 8 bits, a 32-bit word can hold 32",
  "Accuracy Analysis": "5.4.1Results on Real-World Datasets. shows the resultson accuracy concerning the number of registers in a sketch onreal-world datasets. Specially, we vary the number of registers ineach sketch {26, 27, 28, 29, 210, 211, 212}. For dataset Twitter andthe other 3 document datasets, we evaluate RRMSE and AARE w.r.t.the number of registers, respectively. Notably, QSketch demon-strates comparable performance to other baseline methods acrossall datasets. Conversely, QSketch-Dyn outperforms its competitors,leveraging the dynamic nature of the sketch. For example, on thedataset Twitter, our method QSketch-Dyn is 30% more accuratethan alternative methods with the number of registers = 28. Itis imperative to emphasize that QSketch and QSketch-Dyn utilizeonly 1/8 of the memory compared to LM and FastGM. 5.4.2Results on Synthetic Datasets. To comprehensively assess theefficacy of QSketch across diverse scenarios, we conduct a thoroughevaluation comparing its performance with that of other baselinemethods. This evaluation encompasses a range of factors includingdata distribution, dataset scale, register count, and register size.Performance under different data distribution. We compareour methods QSketch and QSketch-Dyn with other methods onsynthetic datasets from different distributions. illustratesthe comparative performance. Remarkably, QSketch-Dyn consis-tently outperforms other methods across all distributions, the sameas real-world dataset results.Performance under different dataset sizes. Next, we explorethe performance of our methodologies across varying dataset sizes.We generate datasets from three distributions at different scalesranging from 102 to 106. The results of the remaining two distri-butions are summarized in the Appendix. The number of registersfor all methods is fixed at 28. As shown in , QSketch, LM,FastGM, and FastExp Sketch estimation errors remain consistentacross all dataset scales. However, the performance of QSketch-Dyn",
  ": Accuracy of all methods under different data sizes on synthetic datasets": "shows a slight improvement with increasing dataset scale, with theestimation error stabilizing around 0.05 for dataset sizes exceeding104. This phenomenon primarily stems from the fact that, withsmaller dataset sizes, most registers in QSketch-Dyn are populatedby only one element, resulting in nearly exact counting.Performance under different register size. As mentioned inTheorem 1, the bit size of the sketchs registers also influences itsperformance. illustrates the estimation error of QSketchand QSketch-Dyn on the Uniform-10k distribution, considering themaximum value of the distribution ranging from 1010 to 1010 (i.e.,weighted cardinality ranging from 5107 to 51013). The number of registers of both methods is set to 28. It is evident that whenemploying 4- or 5-bit registers, both QSketch and QSketch-Dynoffer accurate estimations within a limited range. However, with abit size increase to 7 or 8, both methods consistently perform wellacross all values, aligning with the findings of Theorem 1.",
  ": Update throughput of all methods under different numbers of registers on real-world datasets": "5.5.1Results on Real-World Datasets. shows the results ofthe update throughput on real-world datasets. The throughput forLM, FastGM, FastExp Sketch, and QSketch demonstrates a decreasewith more registers in the sketch. Moreover, the update throughputfor FastGM and FastExp Sketch exhibits similarity and is faster thanLM. For QSketch, since it uses packed integers for implementation,it needs fewer memory accesses than FastGM and FastExp, whichleads to a large update throughput on most datasets. The updatethroughput for QSketch-Dyn remains nearly consistent across vary-ing numbers of registers. Specifically, on dataset Rcv1, the updatetime for QSketch-Dyn is approximately 2 to 3 orders of magnitudeshorter compared to FastGM and LM, respectively. 5.5.2Results on Synthetic Datasets. shows the experimen-tal results of update throughput on synthetic datasets with threedifferent distributions. Remarkably, the update throughput exhibitssimilar trends across all three distributions. Overall, QSketch-Dynemerges as the superior performer among all competitors, a trendconsistent with the results observed on real-world datasets. Specifi-cally, the update throughput for QSketch-Dyn is approximately 10and 100 times shorter compared to FastGM and LM, respectively. shows the estimation time of all methods on three syntheticdatasets. We omit similar results on other datasets. The estimation time of LM, FastGM, and FastExp Sketch is only related to the num-ber of registers in the sketch. QSketch needs several iterations forconvergence, which costs more time. Fortunately, in practical appli-cation scenarios, the estimation procedure may happen much lessfrequently than the update procedure, and the absolute estimationtime of QSketch is only 0.01s when using 4, 096 registers, whichis acceptable. Besides, QSketch-Dyn keeps track of the weightedcardinality on the fly, and it does not need an estimation procedure.",
  "RELATED WORK6.1Cardinality Estimation": "Harmouch et al. give a comprehensive review of existing sketchmethods of estimating the cardinality. Whang et al. introducethe LPC sketch using random hash functions for element map-ping. Various enhancements to LPCs estimation range were laterproposed . Flajolet and Martin develop the FM sketch,which was subsequently refined through methods like LogLog ,HyperLogLog , RoughEstimator , and HLL-TailCut+ ,reducing register size and employing multiple registers. Giroireet al. develop a sketching method MinCount (also known asbottom- sketch ) which stores the minimum hash values of",
  ": Estimation time of all methods under different numbers of registers on synthetic datasets": "elements in the set. Ting develops a martingale-based estimatorto improve the accuracy of the above sketch methods such as LPC,HyperLogLog, and MinCount. Chen et al. extend HyperLogLogto sliding windows. Besides sketch methods, two sampling meth-ods are also proposed for cardinality estimation. Recently,considerable attention has been given to developingfast sketch methods for monitoring the cardinalities of networkhosts over high-speed links. Ting developed methods to esti-mate the cardinality of set unions and intersections from MinCountsketches. Cohen et al. developed a method combining MinHashand HyperLogLog to estimate set intersection cardinalities. Karppaet al. optimized HyperLogLog by decomposing register valuesinto a base value and an offset vector, leading to more efficientstorage. Very recently, Wang et al. proposed a method namedHalf-Xor to handle element deletions in cardinality estimation.",
  "Weighted Cardinality Estimation": "To estimate the weighted cardinality, Considine et al. usedbinary representations to represent integer weights, which is notefficient for elements with large weights. Cohen et al. proposed aweighted estimator based on bottom- sketches. However, bottom- sketches require maintaining a sorted list of the smallest values,which needs more updating time and memory usage. Recently,Lemiesz presented a method that maps each element to ex-ponential distributed variables. Thus it needs () time to processan incoming element, which is infeasible for high-speed streams.Therefore, Zhang et al. proposed FastGM to accelerate .FastGM generates these exponential variables in ascending orderand stops the generation in advance if the generated value is greaterthan the maximal value in current registers. As a recent simultane-ous work, FastExpSketch shares the same idea with FastGM.However, these methods store generated values with 32-bit or 64-bitfloating-point registers. When we need a large to achieve better accuracy or there are many different streams, it is memory-intensivefor devices with limited computational and storage resources. Inaddition, these methods need () to estimate weighted cardinal-ity, and it is not efficient for them to provide anytime-availableestimation for real-time applications.",
  "CONCLUSIONS AND FUTURE WORK": "This paper introduces QSketch, a memory-efficient sketching tech-nique that leverages quantization methods to transform continuousregister values into discrete integers. Unlike traditional sketchingapproaches which allocate 64 bits per register, our QSketch achievescomparable performance using only 8 bits per register. The QSketchexperiences a worst-case time of ( ) where the weights ofelements increase over time, and it needs to solve an MLE prob-lem through the Newton-Raphson method, which introduces extracomputational overhead. Therefore, we further capitalize on thedynamic nature of sketches by proposing QSketch-Dyn, which en-ables real-time monitoring of weighted cardinality. This enhancedmethod reduces estimation errors and maintains a constant timecomplexity for updates. We validate our approach through experi-ments conducted on both synthetic and real-world datasets. Theresults demonstrate that our novel sketching approach outperformsexisting methods by approximately 30% while consuming only one-eighth of the memory. In the future, we aim to explore weightedcardinality in streaming scenarios, particularly focusing on han-dling element deletions and elements with negative weights.",
  "A.3Proof of Theorem 2": "Given the data stream the set of timestamps that each elementappears in the stream for the first time ( ), we first derive theexpectation. Let 1(( ) (1)) demote an indicator of whetherthe state of sketch has changed at time, i.e., 1(( ) (1)) = 1for ( ) (1) and 0 otherwise. We note that ( )only dependson (1) and then we have",
  "=( (,) 1) ( )max ( ) ,": "where ( )max = max () () and (,) is a function of num-ber of elements and number of registers .As an illustration, we consider a uniform distribution from theinterval (0, 1). depicts the variation in the functions valueacross different values of and . As a result, we can get an up-per bound of the variance together with the weighted cardinalityestimation.",
  "We further conduct experiments on the CAIDA dataset, whichconsists of streams of anonymized IP items collected from high-speed monitors by CAIDA in 2018. A 1-minute CAIDA network": "traffic trace contains about 27M packets. For each packet, we con-sider the tuple (source IP, target IP) as the identifier of the elemente, and the packet size as the weight of the element e. Experimentalresults are summarized in . We vary the number of regis-ters in each sketch {28, 210, 212, 214, 216, 218, 220}, and evaluatethe RRMSE as well as the update throughput. All methods achievebetter estimation accuracy when using more registers at the costof lower update throughput. Besides, we observe that: QSketch achieves similar estimation accuracy as LM, FastGM,and FastGM, and QSketch-Dyn performs best among all meth-ods. This is consistent with previous results. For example, whenusing = 220 registers, the estimation accuracy of QSketch-Dyn isabout twice that of other methods. The update throughput for QSketch-Dyn remains nearlyconsistent across varying numbers of registers and is higherthan other methods. This is also consistent with previous results.For example, when use = 219 registers, the update throughputof QSketch-Dyn is about 1 Mops, while the update throughputof FastGM, QSketch, and FastExp Sketch is only about 0.2 Mops,which means that QSketch-Dyn is about 5 faster."
}