{
  "ABSTRACT": "Pharmacies are critical in healthcare systems, particularly in low-and middle-income countries. Procuring pharmacists with the rightbehavioral interventions or nudges can enhance their skills, publichealth awareness, and pharmacy inventory management, ensuringaccess to essential medicines that ultimately benefit their patients.We introduce a reinforcement learning operational system to de-liver personalized behavioral interventions through mobile healthapplications. We illustrate its potential by discussing a series ofinitial experiments run with SwipeRx, an all-in-one app for phar-macists, including B2B e-commerce, in Indonesia. The proposedmethod has broader applications extending beyond pharmacy op-erations to optimize healthcare delivery.",
  "reinforcement learning, behavioral AI, e-commerce recommenda-tions, adaptive interventions": "ACM Reference Format:Ana Fernndez del Ro, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov,Aditya Rastogi, Moiz Hassan, Dexian Tang, and frica Periez. 2024. Adap-tive Behavioral AI: Reinforcement Learning to Enhance Pharmacy Services.In Proceedings of The First Worshop on AI Behavioral Science (AIBS 24). ACM,New York, NY, USA, 5 pages. Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).AIBS 24, August 25, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).",
  "INTRODUCTION": "Pharmacies are a crucial element of healthcare delivery everywhereand are often the first line of patient contact. For many patientsin low and middle-income countries (LMICs) who face signifi-cant barriers to accessing primary care facilities, pharmacies arethe only option for obtaining essential healthcare services suchas testing, drugs, and treatment advice. While the role of pharma-cies in promoting medication adherence and responsible usage, andproviding patient-centered care is unquestionable, pharmacies inmany LMICs face substantial challenges, including a shortage ofwell-trained pharmacists, adequate channels to remain connectedto the rest of the healthcare system and updated on emerging pub-lic health threats, medication availability and indications, and frag-mented and undercapitalized supply chains that complicate ade-quate restocking and inventory management .",
  "Nudges for Pharmacists and Public Health": "Pharmacists, and ultimately their patients, can hence benefit fromdigital tools and mobile applications that can help them managetheir stocks and order supplies, connect to other facilities and peers,refine their skills, and access updated public health news and drugreference guides with the latest information on applicability, clin-ical requirements, side effect prevalence, contraindications, andpharmacological substitutes. These tools can turn pharmacies fromdrug procurement points into health hubs where patients can gettreatment advice, testing, and health education.Equipping these tools with data-driven behavioral nudges con-tributes to keeping their users adequately engaged. It can providethem with additional timely support as needed, be that in the formof an adaptive continuous professional development program, re-stocking reminders based on demand prediction, patient-specificprescription recommendations, or actual incentives to reward ad-herence to medical guidelines (e.g., requiring a positive malaria testbefore dispensing antimalarials). We propose an Artificial Intelli-gence (AI) data-centric platform (described in .2) that can",
  "AIBS 24, August 25, 2024, Barcelona, SpainFernndez del Ro and Leong, et al": ": Difference between mean accumulated daily expenditure between users in the adaptive arm vs. control for all usersin XP2. Confidence intervals (90 %) are shaded. The black horizontal line is drawn across 0, and vertical lines represent theintervention periods beginning and end. : Impact metrics across experiments. T-test metricsrefer to comparing the daily accumulated expenditure (sincethe beginning of the experiment) between the adaptive in-tervention and pure control for significant days only. LMMrefers to the estimated parameters of a linear mixed effectsmodel on weekly values where all parameters are significant.Bandit metrics indicate the average percentage of the par-ticipants in the adaptive intervention assigned to treatmentacross the experiment and the fraction of decision pointswhere most users (> 50%) were sent the nudge. Successful rec-ommendations are those that result in purchases at a latertime during the experiment of the pairs item ordered infre-quently by the user. A significance level of 90% is used, and -indicates nonsignificant results.",
  "The AI Platform": "Architecturally, the platform consists of a Software Development Kit(SDK), which is embedded into mobile apps and digital tools; ana-lytics, model management, intervention, and adaptive experimen-tation frontend interfaces; and the backend server. The backend isthe backbone of the platform, responsible for log ingestion, data or-ganization, and labeling, scheduled dispatch of nudges (push notifi-cations, in-app messages, and adaptive UI components), as well ashosting predictive modeling and algorithmic decision-making en-gine and facilitating configuration thereof through the frontend UI.",
  "The App: SwipeRx": "SwipeRx is an all-in-one app for pharmacies in Southeast Asia. Itconnects over 235,000 professionals across 45,000 pharmacies inIndonesia, the Philippines, Malaysia, Thailand, Cambodia, and Viet-nam, providing them with online education, centralized purchas-ing, logistics and financing, news, drug directory, and adverse eventreporting, among other services. shows two screenshotsof the app. SwipeRxs community-driven B2B e-commerce modeluses medication demand data and bulk purchases to enable small,pharmacy-owned pharmacies (the majority in Southeast Asia) toremain well-stocked by offering medicines at competitive pricesand financing mechanisms.",
  "METHODOLOGY": "After integrating with the AI platform, the first interventions forSwipeRx users have been adaptive, personalized item (a pharma-ceutical product in this context) pair recommendations. These aimto increase the basket size by promoting products the user has sel-dom or never ordered through the app. Leveraging opportunitycosts can have positive spillover effects that improve the availabil-ity of relevant supplies in pharmacies. Different recommendationstrategies, such as demand forecast-based ones to prevent stock-outs, as well as interventions targeting specific public health con-cerns through other app functionalities, will be run in the future.",
  ": Screenshots of the SwipeRx application": "your area typically purchase A and B. Click here to order now! If theuser is inactive when the in-app message is scheduled, they willfind it on their homepage when reopening the app. Messages ex-pire after a week to prevent their accumulation. Users targeted arethose associated with pharmacies in Indonesia with only one or twoSwipeRx users, with the app language set to Bahasa, which haveconnected on average at least every week in the last two monthsand at least once in the previous 40 days. The top 20% spenderswere excluded. The total pharmacy expenditure on the six daysfollowing the recommendation was the objective metric used as areward for the sequential decision-making algorithm (see .2) that weekly assigns each user either to treatment (i.e., the mes-sage is sent) or control (i.e., the message is not sent). .5describes the particularities distinguishing the two concluded ex-periments run so far with this intervention.",
  "Contextual Bandits": "RL is the machine learning paradigm best suited to makesequential decisions and, thus, for adaptive intervention delivery.The full Markov Decision Process (MDP) will be required as theunderlying model for interventions where the reconciliation ofshort and long-term goals and the optimization of a sequence ofinterventions is critical, which is the case for complex inventorymanagement use cases . Multi-Armed Bandits(MABs) are, however, an adequate framework to deal with theinterventions described in this paper , with non-linearmodels and other extensions providing additional representationalcomplexity to drive the bandit towards regret minimization throughmore comprehensive personalization . Thealgorithm of choice for this intervention was a Gauss-Gamma linearbandit using Thompson sampling.Contextless or linear bandits are a natural setup foradaptive experimentation, allowing for the introduction of statis-tical power constraints to guide the decision process .",
  "Adaptive Behavioral AI: Reinforcement Learning to Enhance Pharmacy ServicesAIBS 24, August 25, 2024, Barcelona, Spain": "Fully randomized control trials (RCTs), however, remain the goldenstandard for experimentation in both their single- and multiple-assignment designs . We can consider ourexperiments to be combining elements of both. The adaptive inter-vention can be considered an adaptive experiment, particularly asthey were run for a relatively short period and with a linear modelon only a handful of basic metrics as context with the primary goalof facilitating knowledge extraction. However, a group of the tar-geted users was always left out altogether of the adaptive interven-tions to be used as pure control of an RCT intended to discern theimpact of the adaptive intervention.",
  "Item Pair Recommendation": "We use a rule-based pair recommendation algorithm that considersproducts typically purchased together, ranks the pairs by revenue,and retains the first 100 pairs, and of them, only those pairs that arecurrently in stock, creating a list of candidates. When determiningwhat to recommend to a specific user, the algorithm selects fromthis list of candidate pairs the one that includes one product theuser frequently buys and another the user has either not purchasedbefore or has purchased infrequently. Frequent or infrequent hereis determined by the average of each users purchasing history forthat item. Priority is given to recommending products the user hasnot purchased previously, else to those with a larger discrepancyin relative frequencies.",
  "The effectiveness of the recommendations is assessed as a combi-nation of three different perspectives": "2.4.1RCT angle. We compare participants average expenditure(among other engagement metrics) in the adaptive interventionwith those in pure control by performing t-tests comparing dailyand accumulated (since the beginning of the experiment) expendi-ture values and analyzing the evolution of significance, effect asgiven by Cohens d, and statistical power throughout the experi-ment. We also use logit regressions on the accumulated expendi-tures and linear mixed models (LMMs) on the longitudinal expendi-ture values to estimate the effect of the adaptive intervention withbaseline and other covariate adjustments. We probe for heteroge-neous effects through a combination of stratified t-tests and esti-mation of different effects through LMMs. 2.4.2Bandit angle. Within the adaptive intervention, we lookmainly into the evolution of the fraction of users assigned to eacharm (treatment or control) as dictated by the objective metric ob-served for these so far. We compute the sensitivity to contextualmetrics as the Jacobian of the arm probability based on Thompsonsampling approximation soft-thresholded using half the samplesstandard deviation and averaged across the participants to under-stand heterogeneous effects. We plot the t-distributed stochasticneighbor embedding (t-sne) visualization using the contex-tual traits of best arm assignments and the difference in assignmentprobabilities of the best arm and the second best arm, to gain intu-ition on whether the context as a whole was well chosen.",
  "Experiments": "Two experiments have been completed so far with the item pairrecommendations. Besides running over different periods (theyhave been run consecutively), they used different contexts for theadaptive arm. Sample sizes also differ, as all participants in theadaptive intervention of the first experiment (XP1) were excludedfrom the second one (XP2). The in-app message is sent at 6 am localtime on Monday for both experiments except for the first four weeksof XP1 when they were scheduled for 6 am Tuesday. This changewas made mid-experiment to match the day of recommendationwith the day of the week when a large part of all purchases andlogins happen. 2.5.1First item pair recommendation experiment (XP1). Ran for 8weeks between December 2023 and January 2024, with around 30%of cohort users assigned to pure control. Context used consisted inthe region (one-hot encoded), normalized days since the last nudge,days with purchase orders and expenditure in the last 90 days. 2.5.2Second item pair recommendation experiment (XP2). Ran for10 weeks between February and April 2024, with around 40% ofparticipants assigned to pure control. Context used consisted onaverage days between logins in the last 60 days, days since firstlogin, expenditure in the last month, days with orders in the last 30days, normalized days since last nudge, nudges opened in the last 2weeks, and time spent using the app in the last 30 days.",
  "RESULTS": "The experiments consistently indicate a small positive impact onpharmacy expenditure, stabilizing once the users are habituated.There is also evidence of delayed effects, i.e., recommendations notacted on immediately but purchased later. This section summarizesour main findings. The complete analysis is not included due tolength limitations but will be published elsewhere . col-lects a few impact metrics across the two experiments.While the t-test accumulated expenditure throughout XP1 wasnot significant at any point for the required level of confidence,it came close, particularly after the change in the nudge schedule.Some daily values were significantly higher in the adaptive armand for daily and accumulated values for certain strata, such aspharmacies in Jakarta. The LMM also estimated a significant posi-tive impact of being in the adaptive arm despite the bandit learningto assign decreasing numbers of users to treatment. The sensitiv-ity analysis suggests the context helped discriminate which userswould benefit from the recommendation, with the days since thelast nudge preventing fatigue effects and the purchasing frequencyhaving a large negative impact on the probability of assigning totreatment. All of this, together with the fact that this experimentran over the atypical Christmas period, encouraged an experimen-tal design for XP2 that mirrored that of XP1, with the schedulingon Monday since the beginning, with only a modified context.For XP2, despite the smaller sample sizes used, we see a growingimpact in accumulated values that reaches significance after a week",
  "XP1XP2": "T-test: days with significant effect0%57%T-test: largest effect-0.12T-test: largest statistical power-0.65T-test: average effect-0.10T-test: average statistical power-0.55LMM: adaptive intervention arm5.97-LMM: nudged that week15.9914.17LMM: baseline expenditure0.110.10Bandit: assigned to nudge26%70%Bandit: majority assigned to nudge1/88/9Successful recommendations18.2%22.9% and remains so for 40 days, as depicted in . Opposite to XP1,the bandit in XP2 learns to nudge most users after three assignments.This could be related to the allocation by chance at that decisionpoint of a large fraction of the top spenders to treatment, skewingits learning process. In turn, this appears to hinder the bandits capacity to adequately learn how to use its context, as indicatedby the sensitivity analysis, where, for example, most traits werenegligible and the impact of days since the last nudge the oppositeof XP1 and is reasonable to expect.The large correlation betweenbeing in the adaptive arm and being nudged close to every weekalso explains why, for XP2, the LMM only estimates the parameterassociated with the latter as significant (opposite to XP1).The faction of successful recommendations is very similar andrelatively large in both XP1 and XP2. The LMM baseline estimatedeffects are also consistent in both cases. Exploration of heteroge-neous effects through stratified analysis, LMM effect estimation,and sensitivity analysis indicate areas that should be explored inmore detail, such as regional effects and the impact of the userstypical purchasing frequency, as the pairs appear to be particularlyuseful in nudging both very frequent purchasers and extremely in-frequent purchasers.",
  "SUMMARY AND CONCLUSIONS": "We developed a framework to enhance digital tools for pharmaciesand healthcare providers with RL-based behavioral nudging. Ap-plied to SwipeRx, a leading app for Southeast Asian pharmacists,our approach is illustrated through interventions aiming to increasebasket size by helping pharmacists discover new products. The pos-itive impact observed in our experiments underscores the potentialof this approach to support and improve pharmacy services. The authors want to thank Susan Murphy for insightful discussions.This work was supported, in whole or in part, by the Bill & MelindaGates Foundation INV-060956. Under the grant conditions of theFoundation, a Creative Commons Attribution 4.0 Generic Licensehas been assigned to the Author Accepted Manuscript version thatmight arise from this submission.",
  "Raaz Dwivedi, Susan Murphy, and Devavrat Shah. 2022. Counterfactual inferencefor sequential experimental design. arXiv:2202.06891 [stat.ML]": "William Fedus, Prajit Ramachandran, Rishabh Agarwal, Yoshua Bengio, HugoLarochelle, Mark Rowland, and Will Dabney. 2020. Revisiting Fundamentals ofExperience Replay. In Proceedings of the 37th International Conference on MachineLearning. PMLR, Virtual Only, 30613071. ISSN: 2640-3498. Ana Fernndez del Ro, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov,Aditya Rastogi, Moiz Hassan, Dexian Tang, and frica Periez. 2024. AdaptiveInterventions for Improved Customer Journey in B2B Pharma E-Commerece.(2024). Work in progress, to be submitted to the 3rd Workshop on End-to-EndCustomer Journey Optimization. Ana Fernndez del Ro, Michael Brennan Leong, Paulo Saraiva, Ivan Nazarov,Aditya Rastogi, Moiz Hassan, Dexian Tang, and frica Periez. 2024. AdaptiveUser Journeys in Pharma E-Commerce with Reinforcement Learning: Insightsfrom SwipeRx. In Proceedings of the 3rd CJ ACM SIGKDD International Workshopon End-to-End Customer Journey Optimization. Association for Computing Ma-chinery, Barcelona, Spain. Husnain Hamid, Rizwan Ali Masood, Hira Tariq, Wahab Khalid, Muham-mad Ateeb Rashid, and Muhammad Usman Munir. 2020. Current pharmacy prac-tices in low- and middle-income countries: recommendations in response to theCOVID-19 pandemic. Drugs & Therapy Perspectives 36, 8 (may 2020), 355357. Geoffrey E Hinton and Sam Roweis. 2002.Stochastic Neighbor Em-bedding. In Advances in Neural Information Processing Systems, S. Becker,S. Thrun, and K. Obermayer (Eds.), Vol. 15. MIT Press, Vancouver,Canada, 857864. Eugene Ie, Vihan Jain, Jing Wang, Sanmit Narvekar, Ritesh Agarwal, Rui Wu,Heng-Tze Cheng, Morgane Lustman, Vince Gatto, Paul Covington, Jim McFadden,Tushar Chandra, and Craig Boutilier. 2019. Reinforcement learning for slate-basedrecommender systems: A tractable decomposition and practical methodology.arXiv:1905.12767 [cs.LG] Ifunanya Ikhile, Claire Anderson, Simon McGrath, and Stephanie Bridges. 2018.Is the Global Pharmacy Workforce Issue All About Numbers? American Journal ofPharmaceutical Education 82, 6 (aug 2018), 6818.",
  "Tor Lattimore and Csaba Szepesvri. 2020. Bandit Algorithms. Cambridge Uni-versity Press, Cambridge": "Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. 2010. A contextual-bandit approach to personalized news article recommendation. In Proceedings ofthe 19th international conference on World wide web (WWW 10). Association forComputing Machinery, New York, NY, USA, 661670. Timothy P. Lillicrap, Jonathan J. Hunt, Alexander Pritzel, Nicolas Heess, TomErez, Yuval Tassa, David Silver, and Daan Wierstra. 2019. Continuous controlwith deep reinforcement learning. arXiv:1509.02971 [cs.LG] Feng Liu, Ruiming Tang, Xutao Li, Weinan Zhang, Yunming Ye, Haokun Chen,Huifeng Guo, and Yuzhou Zhang. 2019. Deep reinforcement learning based recom-mendation with explicit user-item interactions modeling. arXiv:1810.12027 [cs.IR] Siqi Liu, Kay Choong, Kee Yuan, Leo Anthony, Xingzhi Sun, and Mengling Feng.2020. Reinforcement Learning for Clinical Decision Support in Critical Care:Comprehensive Review. Journal of Medical Internet Research 22, 7 (2020), e18477.",
  "Rosalind Miller and Catherine Goodman. 2016. Performance of retail pharmaciesin low- and middle-income Asian settings: a systematic review. Health Policyand Planning 31, 7 (mar 2016), 940953": "Ofir Nabati, Tom Zahavy, and Shie Mannor. 2021. Online Limited MemoryNeural-Linear Bandits with Likelihood Matching. In Proceedings of the 38thInternational Conference on Machine Learning. PMLR, Virtual Only, 79057915. ISSN: 2640-3498. frica Periez, Ana Fernndez del Ro, Ivan Nazarov, Enric Jan, Moiz Hassan,Aditya Rastogi, and Dexian Tang. 2024. The Digital Transformation in Health:How AI Can Improve the Performance of Health Systems. (2024). (Accepted forpublication). frica Periez, Kathrin Smchmitz, Lazola Makhupula, Moiz Hassan, MoetiMoleko, Ana Fernndez del Ro, Ivan Nazarov, Aditya Rastogi, and Dexian Tang.2024. Optimizing HIV Patient Engagement with Reinforcement Learning inResource-Limited Settings. In Proceedings of the 7th epiDAMIK ACM SIGKDDInternational Workshop on Epidemiology meets Data Mining and Knowledge Dis-covery. Association for Computing Machinery, Barcelona, Spain. Tianchen Qian, Ashley E. Walton, Linda M. Collins, Predrag Klasnja, Stephanie T.Lanza, Inbal Nahum-Shani, Mashfiqui Rabbi, Michael A. Russell, Maureen A. Wal-ton, Hyesun Yoo, and Susan A. Murphy. 2022. The microrandomized trial fordeveloping digital interventions: Experimental design and data analysis consid-erations. Psychological Methods 27, 5 (Oct. 2022), 874894. Carlos Riquelme, George Tucker, and Jasper Snoek. 2018. Deep Bayesian BanditsShowdown: An Empirical Comparison of Bayesian Deep Networks for ThompsonSampling. In International Conference on Learning Rrepresentations. PMLR, PlayaBlanca, Lanzarote, Canary Islands, Spain. Gerald L. Smith, Stanley F. Schmidt, and Leonar A. McGee. 1962. Application ofStatistical Filter Theory to the Optimal Estimation of Position and Velocity on Boarda Circumlunar Vehicle. Technical Report. NASA.",
  "Richard S. Sutton and Andrew G. Barto. 2018. Reinforcement Learning: An Intro-duction. A Bradford Book, Cambridge, MA, USA": "Ding Xiang, Rebecca West, Jiaqi Wang, Xiquan Cui, and Jinzhou Huang. 2022.Multi Armed Bandit vs. A/B Tests in E-Commerce - Confidence Interval andHypothesis Test Power Perspectives. In Proceedings of the 28th ACM SIGKDDConference on Knowledge Discovery and Data Mining (Washington DC, USA)(KDD 22). Association for Computing Machinery, New York, NY, USA, 42044214. Pan Xu, Zheng Wen, Handong Zhao, and Quanquan Gu. 2022. Neural Contex-tual Bandits with Deep Representation and Shallow Exploration. In The TenthInternational Conference on Learning Representations, ICLR 2022, Virtual Event,April 25-29, 2022. OpenReview.net, Virtual Only. Jiayu Yao, Emma Brunskill, Weiwei Pan, Susan Murphy, and Finale Doshi-Velez.2021. Power constrained bandits. In Proceedings of the 6th Machine Learning forHealthcare Conference (Proceedings of Machine Learning Research, Vol. 149), KenJung, Serena Yeung, Mark Sendak, Michael Sjoding, and Rajesh Ranganath (Eds.).PMLR, Virtual, 209259. Yantao Yu, Zhen Wang, and Bo Yuan. 2019. An Input-aware Factorization Machinefor Sparse Prediction. In Proceedings of the Twenty-Eighth International JointConference on Artificial Intelligence, IJCAI-19. International Joint Conferences onArtificial Intelligence Organization, Macao, China, 14661472."
}