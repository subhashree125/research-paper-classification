{
  "ABSTRACT": "Causality lays the foundation for the trajectory of our world. Causalinference (CI), which aims to infer intrinsic causal relations amongvariables of interest, has emerged as a crucial research topic. Nev-ertheless, the lack of observation of important variables (e.g., con-founders, mediators, exogenous variables, etc.) severely compro-mises the reliability of CI methods. The issue may arise from theinherent difficulty in measuring the variables. Additionally, in ob-servational studies where variables are passively recorded, certaincovariates might be inadvertently omitted by the experimenter.Depending on the type of unobserved variables and the specificCI task, various consequences can be incurred if these latent vari-ables are carelessly handled, such as biased estimation of causaleffects, incomplete understanding of causal mechanisms, lack ofindividual-level causal consideration, etc. In this survey, we providea comprehensive review of recent developments in CI with latentvariables. We start by discussing traditional CI techniques whenvariables of interest are assumed to be fully observed. Afterward,under the taxonomy of circumvention and inference-based meth-ods, we provide an in-depth discussion of various CI strategiesto handle latent variables, covering the tasks of causal effect esti-mation, mediation analysis, counterfactual reasoning, and causaldiscovery. Furthermore, we generalize the discussion to graph datawhere interference among units may exist. Finally, we offer fresh as-pects for further advancement of CI with latent variables, especiallynew opportunities in the era of large language models (LLMs).",
  "Causal inference; latent variable models; confounding analysis": "ACM Reference Format:Yaochen Zhu, Yinhan He, Jing Ma, Mengxuan Hu, Sheng Li, and JundongLi. 2024. Causal Inference with Latent Variables: Recent Advances andFuture Prospectives. In Proceedings of the 30th ACM SIGKDD Conference Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08.",
  "INTRODUCTION": "Our world is a woven web of causes and effects, where everythingthat occurs is the consequence of some prior actions . Forexample, my headache disappeared because of the aspirin I tookthis afternoon, and I gained muscle because I worked out regularlyevery day. From the levity of language, we may be under the illusionthat reasoning with causality from experiences can be simple andstraightforward. However, formal causal inference did not emergeuntil decades ago, which enabled rigorously derivation of causalrelationships of interest from the observational data .In hindsight, what prevented the emergence of formal causalinference (CI) is the lack of mathematical language to describecausality . One tempting choice is to use conditional dis-tributions from probability theory for causal reasoning . Forexample, if an event causes another event (where , = 1means that the event happened and 0 otherwise), we usually have( = 1| = 1) > ( = 1| = 0). However, if we use the converse,i.e., the increase of probability, to denote causality, correlation canbe easily mistaken for causation. For example, we can observe thatpeople eat more ice cream when they wear fewer clothes. However,the former is clearly not a cause for the latter, as both are causedby a third variable: hot weather. Here, the issue lies in the factthat = 1 in the conditional distribution means that is passivelyobserved, but what makes the relation between and causal isthat will happen if we make happen. That is why Rubin claimedthat \"there is no causality without intervention\" and introducedthe potential outcome ( = 1) to describe the event if = 1 ismade to happen for all population . Similarly, Pearl introducedthe do-operator, where ( |()) denotes the distribution of ifwe make the event happen instead of observing it passively .With new symbols defined to facilitate causal reasoning, vari-ous causal questions can be formed in a rigorous manner1. Onecommon CI task is average treatment effect (ATE) estimation ,which aims to estimate the expected influence of an event () onanother (), e.g., the change of recovery rate if drug is pre-scribed to all patients. Since ATE compares the outcomes of twointerventions, i.e., treatment/no treatment, it can be directly for-mulated as E[ ( = 1)] E[ ( = 0)] (via potential outcome) or",
  "arXiv:2406.13966v1 [cs.LG] 20 Jun 2024": "E[ |( = 1)] E[ |( = 0)] (via do-operator). In addition,causal mediation analysis is also feasible via the new symbols,which aims to determine the fine-grained causal effect of on mediated by other factors. For example, if we know that drug cures the disease by reducing the blood pressure but it also thick-ens the blood vessel wall, we can define the causal effects of on mediated by as the effect as if the drug has no side effect. Fur-thermore, the individual level causal effect also becomes tractable. For example, for Alice, who has received the treatment andsurvived, we can formulate the question \"would she also surviveif no treatment had been provided?\". Finally, we can even formu-late causal discovery with the new symbols , where causalrelations among variables of interest (e.g., treatment, mediators,individual factors) can be automatically discovered from data.Nevertheless, representing causal questions with new symbols isnot enough. After all, directly obtaining the causal estimand ()or ( |()) requires intervention upon , which is not alwaysfeasible. One strategy is to simulate interventions with randomizedexperiment (RE) , where the randomization ensures that treat-ment is the only contributor to the variation of . However, REcan be expensive and unethical (e.g., we cannot randomly decidewhether or not to give drugs to patients). Therefore, CI with obser-vational studies gains more attention, where the experimenter hasno manipulation over the treatment assignment. The aim is to showthat if certain assumptions hold for the data (i.e., identification cri-teria), causal estimand with causal symbols can still be calculatedwith conditional relations measurable in the collected data. Forexample, if all confounders (i.e., factors that simultaneously affectcause and effect ) are observed and recorded, backdoor adjust-ment and propensity score weighting can be used toestimate ATE. In addition, if the mediator of interest is measured,the path-specific effect of on mediated by can be obtained un-der certain identification criteria . If exogenous variables (e.g.,individual factors not considered as the main variables of interest)are known, individual-level counterfactuals can be calculated .Finally, if all variables of interest are known, mature algorithmssuch as the PC algorithm are off-the-shelf for causal discovery.However, important variables for CI can be latent, which hin-ders the reliability of existing CI techniques . The issue liesprimarily in two folds: (i) First, certain variables can be intrinsi-cally difficult to measure, e.g., the socioeconomic status of a patient,which is a crucial confounder for drug effect evaluation . (ii)In addition, in the observational study, important covariates for CImay not be recorded in the collected data . The consequencesof carelessly handling latent variables for CI can be multi-faceted.First, unobserved confounders can lead to bias in ATE estimation; for example, if the severity of disease is not considered, wemay erroneously conclude that an effective drug lowers the recov-ery rate, as more severe patients tend to be treated with the drug.In addition, missing important mediators could result in an incom-plete understanding of the causal mechanism . For example,the debate over the causal relation between tobacco smoking andlung cancer was not resolved until the mediator Tar deposit wasdetermined to cause lung cancer for smokers . Exogenous vari-ables are usually considered as noise and are not explicitly includedin the observational data . However, without them, individualdifferences in treatment effects cannot be estimated, which hinders personalized counterfactual analysis. Finally, if not all variables ofinterest are available, causal discovery would be impossible .Recent years have witnessed a plethora of works on causal in-ference with latent variables . Generally, the methods can becategorized into two classes: (i) Circumvention-based Methods and(ii) Inference-based Methods. Circumvention-based strategies es-chew direct modeling of latent variables; instead, they show thatunder certain stringent assumptions/conditions, latent variablescan be avoided while the causal estimand can still be identifiedwith observational data. However, there is no free lunch, and theprice being paid could be the requirement to measure more vari-ables (where errors could be introduced) and an increase inestimation variance . Inference-based methods, in contrast, ex-plicitly model the latent variables based on the observations. Thisusually includes proxy of the latent variables (e.g., their noisy ob-servations). However, latent variables may not be identifiable giventhe observed data, where bias can still remain in the causal estima-tions . In addition, the proxy of latent variables may containundesirable components, and carelessly ignoring them can ruin theestimation results . Both strategies on the main CI tasks, as wellas their generalization to graph data where interference exists, willbe thoroughly discussed in this survey. The distinctive contributionof us can be concretely summarized into three folds as follows:",
  "PRELIMINARIES2.1Symbol System": "For most CI tasks, there are two main variables of interest, i.e.,treatment and outcome , on which the causal relation is scruti-nized. We consider as a binary variable by default, but the casesof continuous/multiple/high-dimensional treatments will also becovered in detail. The outcome can be arbitrary results of interestunder the potential causal influence of . In addition, we use todenote other observed covariates in the system, which may havecertain causal relations with and depending on the context.",
  "Rubins Causal Model": "To study the causal relation between treatment and outcome ,Rubins causal model (SCM) starts by comparing individual-levelcounterfactuals, i.e., for unit , what the outcome is if the unit istreated ( = 1) or is not treated ( = 0). Although the two resultscannot be observed for the same unit simultaneously, we can stillhypothetically define them as potential outcomes as follows: Definition 2.1. (Potential Outcome). We use the notations { ( =1), ( = 0)} (which are shortened as (1), (0) if the treatmentis clear from the context) to denote the potential outcomes (PO) of for unit if the treatment = 1 or 0 is imposed on the unit.",
  ": Atomic structures of SCM, where mutually inde-pendent exogenous variables U are omitted for (b) and (c)": "Accordingly, R.V. ( = 1), ( = 0) reason with the distribu-tion of the POs if all units are uniformly treated or non-treated (i.e.,interventions). However, ( = 1), ( = 0) cannot be obtaineddue to lack of individual counterfactuals. To estimate ( = 1), ( = 0), most strategies need to collect the outcomes of twogroups of treated and non-treated units. Here, we use conditionalR.V. | = 1 and | = 0 to denote the distribution of for thetwo groups. Only in rare cases, e.g., randomized experiments, can | = provide an unbiased estimate for ( = ). In other cases,the purpose of RCM is to show that under certain assumptions,causal estimand with PO can be reduced to conditional relationsmeasurable in the data (usually involving other covariates ).",
  "Structural Causal Model": "Pearls structural causal model (SCM), in contrast, reasons withcausality via a pre-defined direct acyclic causal graph G that en-codes the belief of causal relations among variables of interest .Based on the causal graph, SCM can be formally defined as follows: Definition 2.2. (SCM). Structural causal model (SCM) can bedefined as a triplet of sets (U, V, F ), where U is the set of latentexogenous variables, V is a set of observed endogenous variables,and F is a set of structural equations. For an endogenous variable V, we have = (A ( ), A ( )), where A ( ), A ( )are the exogenous, endogenous parents of in G, respectively. In SCM, each unit is associated with a set of exogenous variablesU = U that causally determines the endogenous variables, e.g., ,, . The prior for U is (U). Mutually-independent exogenousvariables are usually ignored when average causal effects are con-sidered, but they are vital for counterfactual reasoning since theyrepresent unit variations. Three atomic structures exist in a causalgraph (): (i) chains , (ii) forks ,and (iii) V-structure . and are correlated if me-diator is not unobserved for chains (causal), confounder isnot observed for forks (not causal), and collider is observed forV-structures (not causal). Therefore, to distinguish causation fromcorrelation, Pearl introduces the do-operator, where ( |( = ))means that we set = as an intervention and calculate via ( = , A (), A ()/), regardless of observed parents of .",
  "Connections between SCM and RCM": "If an SCM is correctly specified, potential outcome ( = ) canbe derived by (i) replacing the structural equation in F with = (i.e., intervention), which results in a new set of structuralequations F , (ii) setting the exogenous variables U = U (i.e.,the individual factors for unit ), and (iii) calculating the outcome based on U and the new structural equations F . R.V. ( = )",
  "Overview of Causal Inference Tasks": "2.5.1Treatment Effect Estimation. Treatment effect estimationaims to quantitatively measure the causal influence of treatment (e.g., drug) on outcome (e.g., survival rate). The most commonlyused metric is the average treatment effect (ATE) , which isthe expected causal effect of on for the entire population. ATEcan be formulated via the two frameworks as follows:",
  "= E[ (( = 1), = 0))] E[ (( = 0), = 0)].(3)": "Here, (( = ), = 0)) is a nested potential outcome (NPO)denoting three interventions: (i) along the path ,(ii) 0 along the path , and (iii) ( = ) alongpath . NIE excludes the direct effect of along path ,while enabling the indirect effect of mediated by . Furthermore,NIE can be generalized to an arbitrary causal path, i.e., path-specificcausal effect, which can be defined in a similar way via NPO . 2.5.3Counterfactual Reasoning. Counterfactuals can be broadlydefined as causal estimands (represented by -operator or poten-tial outcomes) that contradict the factual observations (representedby conditional distributions). For example, the average treatmenteffect on the treated (ATT) is defined as follows:",
  "TREATMENT EFFECT ESTIMATION": "In this section, we discuss the treatment effect estimation with latentvariables. Specifically, we mainly focus on the latent confounders,which can systematically bias the estimation if handled carelessly.We first introduce traditional methods where confounders are as-sumed to be fully observed. We then discuss the circumvention-based and inference-based strategies to handle latent confounders.",
  "Combined with other common assumptions for CI (e.g., positivity,non-interference, etc. see ), ATE and CATE can be identifiedfrom observational data by controlling as follows:": "() = E[ | = 1,]E[ | = 0,], = E ( ) [()](5)From the SCMs perspective, blocks all backdoor paths that leadto spurious correlations between and (see .3), suchthat in each stratum of = , the correlation between and is causal. Based on Eq. (5), adjustment-based methods use non-parametric methods or fit parametric models (,) (whichwill be denoted as () if different models are used for different)to estimate E[ | = ,], including linear models , tree-basedmethods , and deep neural networks (DNN) . Another lineof methods reweights samples via inverse propensity score E[ =|], such that they can be viewed as pseudo-random samples.",
  "Circumvention-based Methods": "6.3.1Constraint-based Methods. If unobserved confoundersexist, the causal sufficiency assumption will not hold, and naiveindependence tests (i.e., correlation) cannot indicate causal relationsamong variables of interest. To address this issue, Spirtes et al. proposed the FCI algorithm, which extends the PC algorithm byintroducing three more relations (in addition to ) to modelthe uncertainty regarding confounders: (i) indicates thepresence of unmeasured confounders; (ii) representsthat either causes or there are unmeasured confounders; (iii) can represent any of the following scenarios: (1) causes, (2) causes , or (3) there are unmeasured confounders, wherea new orientation rule is used to orient edges.Subsequent research has been proposed to extend FCI from var-ious perspectives, such as with enhanced efficiency ,tailored for sparse causal graphs , improved scalability ,and incorporating different conditional independence tests .6.3.2Score-based Methods. Score-based algorithms, e.g., GESand Fast GES (FGES) , find optimal causal graph by greedilyadding and deleting edges based on predefined scores measuringthe fitness of a graph on observational data. However, they facechallenges when latent confounders exist (i.e., causal insufficiency).To address the issue, the recent trend is to use confounders-robustconstraint-based methods such as FCI to correct the bias. However,it underperforms when the sample sizes are small due to an inaccu-rate estimation of the independence relations . The Greedy FCI(GFCI) algorithm combines the strengths of both approaches.It uses GES to identify a supergraph of the skeleton, then employsFCI to prune the supergraph and determine the orientations tohandle unmeasured confounders. This integration enhances per-formance while maintaining asymptotic correctness under causalinsufficiency. However, GFCIs scoring function cannot be appliedto mixed variables, which is addressed by the Bayesian Constraint-Based Causal Discovery (BCCD) algorithm via utilizing a hy-brid constraint and score-based approach for causal search.",
  "() = E [ (0)| = 1,] E [ (0)| = 0,],(6)": "which measures the systematic difference of the expected baselinePO (0) between the treatment/non-treatment group in the obser-vational data. They further show that under the transportabilityassumption, i.e., the treatment effect is the same between the ran-domized samples and the treated samples in the observational data,the confounding bias () can be estimated as follows3:",
  ": SCM for IV methods and front-door adjustment": "with variance lower than direct estimation with randomized data.Recently, Wu and Yang improved over by adopting theR-learner to model the confounding function, which allowsflexible ML models such as trees and DNNs as the estimator.The advantage of using randomized data to tackle latent con-founding is that the randomized data are guaranteed to be unbiased(but with high variance due to small scale). However, these methodsfail in the case where even a small number of randomized samplescannot be obtained, e.g., when the dataset was collected in the past. 3.2.2Instrumental Variable. If randomized data are not pos-sible, we can use instrumental variables (IV) to \"extract\" pseudo-randomized data embedded inside the observational dataset to un-biasedly estimate ATE/CATE. Formally, IV is defined as follows:",
  "For a binary IV, ATE can be unbiasedly estimated via : = (E[ | = 1] E[ | = 0])/(E[ | = 1] E[ | = 0]), (8)": "if we view as the assigned treatment and as the treatment re-ceived, the numerator can be viewed as the intention-to-treat effectof the treatment assignment () on outcome (), and the denomina-tor as the compliance with the assigned treatment. General IV-basedmethods follow a similar two-stage procedure. Assuming linearcausal relations, the two-stage least squares algorithm (2SLS) (i)first calculates the conditional mean of the treatment given theIV , i.e., = E[ |], and (ii) regresses on , where the coef-ficient gives the causal relation between and . Afterward,efforts have been devoted to generalizing 2SLS to nonlinear cases. For example, Deep IV estimates the conditionaldensity in = E[ |,] from stage (i) with categorical distribution(for discrete ) or mixture of Gaussian distribution (for continuous) parameterized by DNN, and predicts the outcome in stage (ii)via another DNN = ( ,). However, to make the objectiveoptimizable, Deep IV assumes simple distributions, which fail whenthe treatment is high dimensional. To address this issue, Bennettet al. proposed to use a generalized method of moments toallow more flexible DNNs as treatment/outcome networks .However, finding suitable IVs is still difficult. Recently, Yuan et al. proposed the Auto IV, which finds IVs from candidates thatsatisfy Definition 3.1 by maximizing the mutual information (MI)between and to ensure relevance, and minimizing the conditionalMI between , given to ensure the restriction criteria.The advantages of IV-based methods are that (i) no randomizeddata are required to address latent confounding, and (ii) maturemethods exist with good theoretical properties. However, it is dif-ficult to find IV that satisfies the Definition 3.1. In addition, if theIV is weak, i.e., has mild influences on the received treatments, theestimation will have a high variance even with large data. 3.2.3Front-door Adjustment. In addition, if the causal mech-anism between the treatment and outcome is known, i.e., allmediators are observable and unconfounded with and , front-door adjustment can be used to address latent confounders .Specifically, based on the probability theory, we have",
  "E[ |()] = E(| ( )) [ |()].(9)": "Since no backdoor path exists between and , (|()) =(|). In addition, since blocks the backdoor path between and , ( |()) = E ( ) [( |,)], where Eq. (9) is reducedto conditional relations measurable from the data. However, similarto IV-based methods, mediators that satisfy the front-door criterionare difficult to find. Therefore, Xu et al. proposed to inferlatent mediators that satisfy the front criterion from the covariate with the identifiable variational auto-encoder (iVAE) . 3.2.4Multiple Causes. Finally, we consider the case of multipletreatments, where we are interested in estimating the combinedcausal effects of all the treatments in (e.g., prescribing bundleddrugs) on . If we can determine that the latent confounders areshared among different treatments (i.e., single-cause ignorability), various methods can be used to address the confoundingbias. The deconfounder-based methods prove that if latent vari-ables can be found that render different treatments conditionalindependent, controlling adjusts for the confounding bias due tomulti-cause confounders . The proof is simple and elegant:if are still active after conditioning on , they will render thetreatments dependent (see .3), which results in contra-diction. Linear models and DNNs are used toestimate from. Recently, Ma et al. proposed to learn latentwith latent clustering, which can well accommodate new treatments.Observing that under single-cause ignorability assumption, the datais unconfounded for every single cause, Qian et al. proposedto learn a single cause interventional model for each cause, andperturb the cause to generate counterfactually-augmented datasets,which they show are beneficial to learn multi-cause models.",
  "Inference-based Methods": "In other cases, when counterfactuals need to be calculated or bounded,inference-based methods become more useful . Observing thatexogenous variables satisfy exactly the non-descendant require-ment of while containing all individual information, Kusner et al. assumed linear structural equations and fitted linear additivemodels on the observed data, where the error terms are viewed asthe estimand of and used for fair predictions. Zuo et al. fur-ther generalized to the case of partially observed SCMs, underthe assumption that has no endogenous ancestor. Wu et al. proposed to bound Eq. (12) by dividing the space into equivalentregions via response functions , and search the upper and lowerlimit of Eq. (12) while making the response functions compatible",
  "E ( |=0, ) [ | = 0,, ],(10)": "which holds = 0 fixed on the direct path , and change from 0 to 1 on the indirect path . The natural directeffect (NDE) of on can be calculated as . In practice,the conditional distributions required by and can beestimated using various methods, such as linear regression ,logistic regression , or machine learning techniques , suchas decision trees and deep neural networks .",
  "Latent Confounders in CMA": "If latent confounders exist and are not included in , the sequen-tial ignorability assumption breaks and traditional methods thatrely on Eq. (10) to estimate will give biased results. To addressthe issue, various proxy-based methods are proposed. Here, an ex-emplar work is causal mediation analysis variational auto-encoder(CMAVAE) , which assumes that the latent confounder con-founds all pair-wise relations among,, , of which a noisy proxy can be observed (definition of proxy see .3.1). Inspired",
  "In this part, we discuss CMA with latent mediators, where Assump-tion 3 fails, and Eq. (10) cannot be used directly for estimation": "4.3.1Circumvention-based Methods. Circumvention-basedmethods are difficult in CMA with latent mediators. Nevertheless,Derkach at. al. proposed a method without any utilization ofobservable proxies of latent mediators. They made a strong assump-tion that the distribution of belongs to an exponential family (; , ) = [ ( )]/( ) + (, ), where and are modeled as functions of the latent mediator. They observethat can be represented by the parameters of the distribu-tion. Therefore, to estimate the , it is sufficient to estimatethe parameters of (; , ), which is solved via an expectation-maximization (EM) algorithm: In each iteration of the algorithm, theexpected latent mediators are first calculated, then the distributionparameters are updated via likelihood maximization. 4.3.2Proxy-based Methods. If the mediator of interest is notdirectly observed, utilizing its observed proxies is an effectivemethod for estimation. Kuroki et al. showed that the of treatment on an outcome could be identified in linearmodels given two independent proxies of an unobserved mediator.In addition, Albert et al. proposed a maximum likelihood-basedapproach to estimate causal mediation effects with a continuous la-tent mediator measured by multiple observed proxies. Their methodis based on fitting a generalized structural equation model (GSEM) using an approximate Monte Carlo EM algorithm. The fit-ted GSEM is then used to estimate natural direct and indirect ef-fects . In addition to the latent mediator, this approach alsoaccommodates mediator-outcome confounding and mixed contin-uous and categorical outcomes. However, it relies on parametricmodeling assumptions and may be computationally intensive. Re-cently, Sun et al. proposed a joint modeling approach thatincorporates multiple latent mediators and a survival outcome.Specifically, a Bayesian approach with a Markov chain Monte Carloalgorithm is developed to perform an efficient estimation of .",
  "Overview": "With a pre-defined SCM G, counterfactuals generally have thefollowing form: E[ ( = )|, = ], where is the evidence(observed values for variables in G) and = is the observedtreatment. Here, we use the subscript in ( = ) to denotethe dependence of the PO () on exogenous variables . Thecounterfactual inference involves three steps as follows:",
  "E[ ( = )| = , = ] ?= E[ ( = )| = , = ]. (11)": "Intuitively, Eq. (11) asks that given evidence = and = (where could be the sensitive features such as race, gender, etc.),whether the prediction would be the same for a unit if is set toanother value . Kusner et al. showed that Eq. (11) holds whenpredictor does not use any descendant of , which precludesthe dependence of on . Afterward, Chiappa proposed path-specific counterfactual fairness (PSCF), which allows the causalinfluence of on along certain causal paths. For example, in thesingle mediator case, we may allow while forbid , where is called a resolving variable . In this case, thecounterfactual question can be formulated via NPOs as follows:",
  "CAUSAL DISCOVERY": "Previous sections primarily focus on CI with a pre-defined causalgraph. However, when accurate causal relations cannot be obtained(e.g., lack of domain knowledge), it becomes imperative to automat-ically discover the causal relations from data via causal discovery(CD). In this section, we first introduce traditional CD methods, in-cluding constraint-based and score-based methods. We then discussCD strategies when unobserved confounders exist.",
  "Brief Review of Traditional Methods": "Causal discovery (CD) aims to infer causal relations among vari-ables of interest V from the observational dataset, with the goal ofconstructing a causal graph G = (V, E). Most traditional CD meth-ods rely on the assumptions of faithfulness and causal sufficiency(which assume away unobserved confounders) as follows: Assumption 4. (Faithfulness). If two disjoint sets of variables Mand N are independent in the distribution when conditioning onZ, then it implies that M and N are d-separated in the graphG conditioning on Z, denoted as: M N|Z = M G N|Z.",
  "Assumption 5. (Causal Sufficiency). For any two observed vari-ables and in the data, all common causes must also be observed": "Generally, CD methods can be categorized into two classes: (i)constraint-based and (ii) score-based methods . Constraint-based methods use conditional independence tests to identify edgesin the graph based on the faithfulness assumption. For example, thePeter-Clark (PC) algorithm and its variants first identify an undirected causal graph (i.e., skeleton) by removingedges from a complete causal graph with conditional independencetests, and then determine the edge direction by a set of orientationpropagation rules with V-structures and acyclicity property .For example, consider a path in the skeleton , where and are not adjacent. If and became dependent conditioning on ,then the PC algorithm orients the edges as based on theproperty of V-structures (see .3). In contrast, score-basedalgorithms aim to identify the best candidate graphby maximizing a fitness score, such as the Bayesian InformationCriterion (BIC), to discover the causal graph from the data.",
  "Proxy-based Methods": "There are a few proxy-based methods for CD with unobservedconfounders. Liu et al. studied causal discovery between twovariables , with a latent confounder . Assuming a proxy ,i.e., a causal descendant of , can be observed, they discretize and use introduced in .3.1 to estimate the causal effectand judge whether an edge exists between and . However, suchproxies may not exist in reality. Recently, introduced timeseries data to address the issue, where each variable is assumed tobe its causal parent in the next time step, serving as the proxy .",
  "On Theories and Model Design": "Firstly, there has been a growing interest in causal representationlearning , which aims to develop models capable of automat-ically extracting and representing causal concepts and relationsfrom data. An in-depth study of causal representation learning withlatent variables would be interesting in real-world applications.Additionally, integrating multi-modal information of the unit,such as textual , visual , and sensor data , offersopportunities to compensate for the absence of observation in a sin-gle modality, which also increases the chance of finding applicablecircumvention or inference methods to address the latent variable.Furthermore, improving the interpretation (especiallytowards latent variables) is essential to foster trust and transparencyin causal learning systems with latent variables, allowing users tocomprehend and validate causal conclusions effectively. Finally, exploring uncertainty quantification techniques , suchas conformal prediction , can provide valuable information onthe reliability and robustness of CI under latent variables, facilitatemore informed decision-making, and provide pessimistic/optimisticbounds when exact causal effects cannot be identified.",
  "Opportunities in the LLM Era": "Recently, large language models (LLM) exhibit remarkable in-contextlearning and reasoning capabilities . Al-though LLM itself is nowhere causal (after all, it still fits con-ditional distributions parameterized by transformer networks oncorpora ), recent research has shown some promising resultsof LLMs to facilitate CI, e.g., causal reasoning , counterfactualanalysis , and causal discovery . For example, Jinet al. showed that when provided with few-shot examples withchain-of-thought (CoT) causal reasoning steps in the prompts,LLMs can construct causal graphs, formulate causal questions withthe two frameworks and manage to solve it with observational data.Based on the above examples, we speculate that LLMs can alsoprovide opportunities to advance CI with latent variables. Here,we provide the following interesting future perspectives. (i) First,it is promising to see LLM facilitate the automatic identificationof important latent variables that could be neglected by humanbeings. As such, issues of neglecting important variables can beprevented in advance. (ii) In addition, if the absence of importantvariables is inevitable, LLM may have the potential to reason withnew strategies to circumvent or infer the variables from proxy basedon the reasoning ability to the causal relation of latent variablesand observed variables at hand (i.e., automatic causal discovery).(iii) Furthermore, LLM may provide a usable and user-friendlyinterpretation of latent variable models for CI , as well as howbiases are generated and eliminated. (iv) Finally, recent advances inmulti-modal LLM are also promising to systematically considermulti-modal features of a unit, where the more comprehensivecausal graph can be established by the LLM to increase the chanceof finding good solutions to address the latent variables.",
  "CONCLUSIONS": "In this survey, we review recent advances in causal inference (CI)with latent variables, covering four main CI tasks, i.e., causal effectestimation, causal mediation analysis, counterfactual reasoning,and causal discovery. We start by briefly reviewing CI methodswhere important variables are assumed to be observed. Then, underthe new taxonomy of inference-based and circumvention-basedmethods, we introduce methods that account for the absence ofcrucial variables. Furthermore, we generalize the above method tographs, an important area for machine learning. Finally, we discussfuture perspectives, especially the new opportunity in the LLM era. This work was supported in part by the National Science Foun-dation (NSF) under grants IIS-2006844, IIS-2144209, IIS-2223769,IIS-2316306, CNS-2154962, and BCS-2228534; the CommonwealthCyber Initiative Awards under grants VV-1Q23-007, HV-2Q23-003,and VV-1Q24-011; the JP Morgan Chase Faculty Research Award;the Cisco Faculty Research Award; and Snap gift funding.",
  "AGENERALIZATION TO GRAPH DATA": "Causal inference on graph data (e.g., social networks) naturallyfaces unique challenges compared with traditional tabular datadue to the intrinsic interconnection and interactions among unitsunder study. In the last few decades, there have been substantialefforts in marrying causal inference with graph mining , where latent variables still severely impede the robustnessand trustworthiness of causal conclusions. Here, we extend themethodology introduced in the main paper to graph data. Treatment Effect Estimation. Estimating treatment effect ongraphs inevitably requires particular method to handle the chal-lenges brought by the graph structure. Studies in this area mainlyinclude the following branches: (i) Proxies including graph struc-ture: although latent confounders on graphs are easily neglected byregular methods, fortunately, the graph structure itself can serveas proxies for the latent confounders in many cases . (ii)Circumvention-Based Methods: Under certain circumstances, graphstructure affects the treatment assignments and plays the role ofan instrumental variable . Therefore, IV-based causal effect es-timation approaches can be applied. (iii) Interference: one majorissue of treatment effect estimation on graphs is that there oftenexists interference between connected units (graph nodes), i.e., thetreatment of one unit may causally influence the outcome of otherunits. This, however, violates the SUTVA assumption in tra-ditional causal inference. There have been numerous explorations in this problem, covering different types of graphs. Counterfactual Analysis. On graphs, counterfactual reasoningtargets on generating a different graph under certain circumstancesdifferent from the factual one. As the graph structure is involved,counterfactual analysis on graphs often involves additional consid-erations regarding the causal relations among nodes, as well as thediscrete and unorganized structural space. Various investigationshave been conducted for this problem, including different goalssuch as generalization , explanation ,and fairness in many important applications.Causal Discovery. The nature of graphs makes them closely as-sociated with causal relations. Related causal discovery work inthis area mainly includes (i) methods based on classical graphi-cal models , which rely on causal graphical models and havebeen the mainstream of causal discovery; (ii) methods based onlearnable graph adjacency matrices in neural networks ,which discover the causal relations inside data by learning an adjacency matrix for a causal graph with variables; (iii) meth-ods based on graph neural networks (GNNs) , whichexplicitly leverage GNN techniques to facilitate causal discovery. Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu,Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U Ra-jendra Acharya, et al. 2021. A review of uncertainty quantification in deeplearning: Techniques, applications and challenges. Information Fusion 76 (2021),243297.",
  "Bengt Muthn and Tihomir Asparouhov. 2015. Causal effects in mediationmodeling: An introduction with applications to latent variables. Struct. Equ.Modeling (2015)": "Jessica A Myers, Jeremy A Rassen, Joshua J Gagne, Krista F Huybrechts, Sebas-tian Schneeweiss, Kenneth J Rothman, Marshall M Joffe, and Robert J Glynn.2011. Effects of adjusting for instrumental variables on bias and precision ofeffect estimates. American Journal of Epidemiology 174, 11 (2011), 12131222. Razieh Nabi and Ilya Shpitser. 2018. Fair inference on outcomes. In AAAI. Ignavier Ng, Shengyu Zhu, Zhitang Chen, and Zhuangyan Fang. 2019. A graphautoencoder approach to causal structure learning. arXiv (2019).",
  "Zhaozhi Qian, Alicia Curth, and Mihaela van der Schaar. 2021. Estimating multi-cause treatment effects via single-cause perturbation. In NeurIPS. 2375423767": "Vineet K Raghu, Joseph D Ramsey, Alison Morris, Dimitrios V Manatakis, PeterSprites, Panos K Chrysanthis, Clark Glymour, and Panayiotis V Benos. 2018.Comparison of strategies for scalable causal discovery of latent variable modelsfrom mixed data. International Journal of Data Science and Analytics 6 (2018),3345. Joseph Ramsey, Madelyn Glymour, Ruben Sanchez-Romero, and Clark Glymour.2017. A million variables and more: The fast greedy equivalence search algorithmfor learning high-dimensional graphical causal models, with an application tofunctional magnetic resonance images. International Journal of Data Scienceand Analytics 3 (2017), 121129."
}