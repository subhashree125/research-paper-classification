{
  "ABSTRACT": "Graph neural network (GNN) has been a powerful approach incollaborative filtering (CF) due to its ability to model high-orderuser-item relationships. Recently, to alleviate the data sparsityand enhance representation learning, many efforts have been con-ducted to integrate contrastive learning (CL) with GNNs. Despitethe promising improvements, the contrastive view generation basedon structure and representation perturbations in existing methodspotentially disrupts the collaborative information in contrastiveviews, resulting in limited effectiveness of positive alignment.To overcome this issue, we propose CoGCL, a novel frameworkthat aims to enhance graph contrastive learning by constructingcontrastive views with stronger collaborative information via dis-crete codes. The core idea is to map users and items into discretecodes rich in collaborative information for reliable and informativecontrastive view generation. To this end, we initially introduce amulti-level vector quantizer in an end-to-end manner to quantizeuser and item representations into discrete codes. Based on thesediscrete codes, we enhance the collaborative information of con-trastive views by considering neighborhood structure and semanticrelevance respectively. For neighborhood structure, we proposevirtual neighbor augmentation by treating discrete codes as virtualneighbors, which expands an observed user-item interaction intomultiple edges involving discrete codes. Regarding semantic rel-evance, we identify similar users/items based on shared discretecodes and interaction targets to generate the semantically relevantview. Through these strategies, we construct contrastive viewswith stronger collaborative information and develop a triple-viewgraph contrastive learning approach. Extensive experiments on",
  "Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from acronym XX, June 0305, 2018, Woodstock, NY 2018 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 978-1-4503-XXXX-X/18/06",
  "Recommendation, Collaborative Filtering, Graph Contrastive Learn-ing": "ACM Reference Format:Bowen Zheng, Junjie Zhang, Hongyu Lu, Yu Chen, Ming Chen, Wayne XinZhao , and Ji-Rong Wen. 2018. Enhancing Graph Contrastive Learningwith Reliable and Informative Augmentation for Recommendation. In Pro-ceedings of Make sure to enter the correct conference title from your rightsconfirmation emai (Conference acronym XX). ACM, New York, NY, USA,13 pages.",
  "INTRODUCTION": "In the literature of recommender systems, collaborative filtering (CF)based on graph neural network (GNN) has showcased significantsuccess in recommendation systems due to its ability to modelhigh-order user-item relationships . This approach typi-cally involves organizing user-item interaction data into a bipartitegraph and learning node representations that contain collaborativeknowledge from the graph structure. However, given the sparsityof user behaviors, GNN-based methods often struggle with limitedgraph edges and insufficient supervision signals. This challengehinders the ability to develop high-quality user and item represen-tations , which are vital for improving recommendation.To address this challenge, recent studies propose to integrate con-trastive learning (CL) with GNN-based CF to incorporateself-supervised signals.According to how the contrastive views are constructed, existingGraph CL-based methods can be divided into two categories: struc-ture augmentation and representation augmentation. Structureaugmentation perturbs the graph structure to create augmented",
  ": Comparison of current graph CL-based methods(e.g., SGL , SimGCL ) that disrupt collaborative infor-mation within contrastive views and the proposed approachthat enhances collaborative information": "graphs, which are subsequently used by the GNN to generate con-trastive node representations . As a representativemethod, SGL adopts stochastic node/edge dropout to constructaugmented graphs as contrastive views. Representation augmen-tation involves encoding additional representations of nodes fromthe interaction graph for CL . Particularly,SimGCL perturbs the node embedding by adding randomnoise to generate contrastive views. Despite their effectiveness,existing approaches still suffer from unexpected self-supervised sig-nals . Contrastive view generation based on perturbations po-tentially disrupt collaborative information within contrastive views.More precisely, in recommendation scenarios where user behaviorsare scarce, structural perturbations may lose key interactions ofsparse users . And the random noise added to node em-beddings may interfere with the implicit collaborative semanticsin node representations . In addition, the empirical analysisin .2 confirms that the alignment between positive pairsbased on perturbations is not as effective as expected, and the modelperformance significantly relies on the representation uniformityacross different instances facilitated by CL.Considering these issues, we aim to construct higher-qualitycontrastive views to enhance collaborative information. Specifically,we strive to maintain both reliability and informativeness for con-trastive view generation. For reliability, we anticipate that thestructural information introduced by graph augmentation is well-founded rather than arbitrary, that is, based on the observed user-item interactions. Our idea is to represent each user or item as atuple of discrete IDs (called codes in this paper) associated withcollaborative information. Given the user and item codes, as shownin , we can naturally expand a u-i interaction edge toseveral u-codes(i) and codes(u)-i edges. For informa-tiveness, this code-based augmentation can enhance neighborhoodstructure and effectively alleviate the sparsity of the interactiongraph by treating the codes as virtual neighbors. Furthermore, shar-ing discrete codes between different users/items indicates theirrelevance of collaborative semantics, such as and + in .To develop our methodology, we focused on (a) how to elegantly learn discrete codes associated with rich collaborative informationand (b) how to integrate the learned discrete codes into the graphCL framework to improve recommendation.In this paper, we propose CoGCL, a reliable and informativegraph CL approach aiming to construct contrastive views that implystronger collaborative information by introducing discrete codes.To map users and items into discrete codes rich in collaborativeinformation, we learn a multi-level vector quantizer in an end-to-end manner to quantize user and item representations encoded byGNN into discrete codes. Subsequently, the learned discrete codesare adopted to enhance the collaborative information of contrastiveviews in two aspects: neighborhood structure and semantic relevance.For neighborhood structure, we conduct virtual neighbor augmenta-tion by treating discrete codes as virtual neighbors based on existinginteractions. This process serves to enhance the nodes neighborinformation and alleviate interaction sparsity in contrasting views.For semantic relevance, we identify users/items that share discretecodes or interaction targets as semantically similar for positivesampling. By aligning users/items with semantic relevance via CL,we can further enhance the integration of collaborative semantics.Through the above strategies, we can generate various contrastiveviews with stronger collaborative information. Finally, a triple-viewgraph contrastive learning approach is proposed to achieve align-ment across the augmented nodes and similar users/items. Thecontributions in this paper can be summarized as follows: We present a reliable and informative graph CL approach,namely CoGCL, which constructs contrastive views that implystronger collaborative information via discrete codes. We propose an end-to-end method to elegantly learn discretecodes for users and items. These discrete codes are employed toenhance the collaborative information of contrastive views in termsof both neighborhood structure and semantic relevance. Extensive experiments on four public datasets show that our ap-proach consistently outperforms baseline models. Further in-depthanalyses illustrate the crucial role that our designed componentsplay in enhancing graph CL for recommendation.",
  "Given user and item sets U and I respectively, let R {0, 1}|U||I|": "represent the user-item interaction matrix, where R, = 1 if thereis an observed interaction between user and item , otherwiseR, = 0. Based on the interaction data R, GNN-based CF methodsconstruct a bipartite graph G = (V, E), where the node set V ={U I} includes all users and items, and E = {(,)| U, I, R, = 1} denotes the set of interaction edges.Typically, GNN-based CF methods utilize the neighboraggregation scheme on G to obtain informative node representa-tions, which can be formulated as follows:",
  "where denotes the number of GNN layers, and Z R|V|": "denotes the node representations at the -th GNN layer, capturingthe -hop neighbor information. Here, Z0 is the trainable ID embed-ding matrix. The readout function Readout() is used to summarizeall representations for prediction. Then, the predicted score is de-fined as the similarity between the user and item representations(e.g., inner product, = ). For the recommendation optimiza-tion objective, most studies use the pairwise Bayesian PersonalizedRanking (BPR) loss for model training, denoted as L.In addition, the graph CL-based methods propose tofurther improve the recommendation performance by performingcontrastive learning between two contrastive views. Specifically,given two view representations z and z of a node (e.g., obtainedby two augmented graphs ), the optimization objective of CLbased on InfoNCE loss is:",
  "(z,z)/ ,(4)": "where pos denotes the distribution of positive pairs, and datadenotes the overall data distribution. Intuitively, the first termmaintains the similarity of positive pairs, whereas the second termpushes negative pairs apart. These are formally defined as thealignment and uniformity of representations on the unit hyper-sphere . Here, we try to investigate the contributions of the",
  ": The overall framework of our CoGCL, which en-hances graph CL by constructing contrastive views that implystronger collaborative information via discrete codes": "above two terms by individually disabling their effects. Specifically,we conduct experiments on three representative graph CL-basedCF models: SGL , SimGCL , and LightGCL . For eachmodel, we introduce two variants: (a) w/o U stops the gradient ofsimilarity calculations for negative pairs in Eq. (2) (using detachfunction in Pytorch), which leads to the breakdown of uniformityin Eq. (4). (b) w/o A stops the gradient between positive pairs inEq. (2), resulting in the breakdown of alignment in Eq. (4). From theresults in , we can observe the following two phenomena: Disabling uniformity and only pulling the positive pairs to-gether does not yield a significant improvement compared to Light-GCN. Furthermore, SGL w/o U produces a decrease in performance. Disabling alignment leads to minimal negative impact andmight even result in a slight performance improvement.Generally, alignment between positive examples in the abovemethods could be ineffective or potentially harmful. We argue thatperturbation methods such as stochastic edge/node dropout (i.e.,SGL), random noise (i.e.,, SimGCL), and incomplete reconstructionof adjacency matrix by SVD (i.e., LightGCL) could disrupt the col-laborative information within contrastive views , andalignment based on these contrastive views may mislead modellearning in graph CL.",
  "Approach Overview": "As mentioned in Sections 1 and 2, our basic idea is to enhancecontrastive view generation and improve graph CL by introducingdiscrete codes associated with rich collaborative information. Tothis end, we make efforts in the following aspects: End-To-End Discrete Code Learning (.2): In orderto elegantly learn discrete codes associated with rich collaborative",
  "Conference acronym XX, June 0305, 2018, Woodstock, NYBowen Zheng, et al": "information to represent users and items, we present an end-to-end multi-level vector quantizer, which quantizes user and itemrepresentations encoded by GNN into discrete codes. Reliable and Informative Contrastive View Generation (Sec-tion 3.3): Given the learned discrete codes, we use them for reliableand informative contrastive views by proposing virtual neighboraugmentation and semantic relevance sampling, respectively. Triple-View Graph Contrastive Learning (.4):Based on the generated contrastive views, we finally introducetriple-view graph contrastive learning to achieve alignment acrossmultiple contrastive views, so as to integrate the stronger collabo-rative information contained in these views into model learning.",
  "End-To-End Discrete Code Learning": "As introduced before, we aim to learn discrete codes rich in col-laborative information for users and items to enhance contrastiveview generation. This involves (a) encoding user and item repre-sentations via GNN (.2.1), and (b) learning end-to-endmulti-level vector quantizer to map the encoded representationsinto discrete codes (.2.2). 3.2.1Representation Encoding via GNN. In line with previous works, we adopt LightGCN as the GNN encoder in ourframework to propagate neighbor information across interactiongraph due to its simplicity and effectiveness. Notably, unlike pre-vious implementations, we incorporate dropout on the input rep-resentation of each layer (instead of edge dropout on the graphstructure) to mitigate overfitting. The process can be written as:",
  "Z = GNN((Z1), G),(5)": "where () denotes the dropout operation. As for the readout func-tion, we follow SimGCL to skip Z0, which shows slight per-formance improvement in graph CL-based CF. Subsequently, theuser and item representations are denoted as and , respectively,which will be applied for joint learning of the recommendation taskand multi-level code. 3.2.2End-To-End Multi-Level Code Learning. Given user and itemrepresentations, common approaches for learning discrete codesinclude hierarchical clustering , semantic hashing , andvector quantization . Our CoGCL adopts the multi-levelvector quantization (VQ) method in an end-to-end manner, such asresidual quantization (RQ) and product quantization (PQ) .Next, we take discrete code learning for users as an example, anditem codes can be obtained analogously. At each level , there existsa codebook C = {e}=1, where each vector e is a learnablecluster center. And the total number of code levels is . Then thequantization process can be expressed as:",
  "=1 (z,e )/ ,(6)": "where is the-th code for the user, z denotes user representationat the -th level. RQ calculates residuals as representations for eachlevel, denoted by z+1= z e, and z1 = z. PQ splits z into sub-vectors z =z1; . . . ; z, each of dimension /. Here wedo not adopt the Euclidean distance commonly used in prior VQ works but cosine similarity, which is to synchronizewith the similarity measure in CL (Eq. (2)).Our optimization objective is to maximize the likelihood of as-signing representations to their corresponding centers via Cross-Entropy (CE) loss. Formally, the training loss for user discrete codelearning is:",
  "Reliable and Informative Contrastive ViewGeneration": "Compared to previous methods involving informationdisruption, our motivation to strengthen collaborative informationrequires us to develop a reliable and informative approach for con-trastive view generation via the learned discrete codes. Below, weintroduce virtual neighbor augmentation (.3.1) and seman-tic relevance sampling (.3.2) to enhance the neighborhoodstructure and semantic relevance of contrastive views, respectively. 3.3.1Virtual Neighbor Augmentation via Discrete Codes. In orderto generate reliable contrastive views with enhanced neighborhoodstructure, we use discrete codes for virtual neighbor augmentationin the graph. For instance, considering user , we select nodes fromthe users neighbors N with a probability of to create augmenteddata, denoted as Naug. Then we design two operators on graphstructure to augment the node neighbors, i.e., replace and add.The former replaces the neighbor items with their correspondingcodes, without retaining the original edges, while the latter directlyadds the codes as virtual neighbors. All augmentation operationsstrictly rely on observed interactions to ensure reliability. Formally,the augmented edge of can be expressed as:",
  "E = {(,)| N} E,(10)": "where E denotes the edges between user and discrete codes, Eis all interaction edges of the user with replace augmentation, andE is edges with add augmentation. In this case, discrete codescan be regarded as virtual neighbors of the user. The operationsdescribed above, which entail either replacing the original neighborwith several virtual neighbors or adding extra virtual neighbors,can bring richer neighbor information and effectively alleviate thesparsity of the graph. The graph augmentation for items can besymmetrically performed. To acquire a pair of augmented nodesfor CL, we perform two rounds of virtual neighbor augmentation.The augmented graphs are depicted as follows:",
  "Enhancing Graph Contrastive Learning with Reliable and Informative Augmentation for RecommendationConference acronym XX, June 0305, 2018, Woodstock, NY": "). E1 and E2 denote the edge sets resulting from the aforemen-tioned virtual neighbor augmentation for all users and items. Theaugmented nodes in the two graphs possess abundant (extensivevirtual neighbors) and homogeneous (substantial common neigh-bors) neighbor structural information. Alignment between the twoaugmented nodes is helpful to introduce more neighbor structureinformation into the model. Following SGL , we update the dis-crete codes and augmented graphs once per epoch during training. 3.3.2Semantic Relevance Sampling via Discrete Codes. In our frame-work, we not only consider different augmented views of the samenode as positive samples, but also regard distinct users/items withsimilar semantics as mutually positive, which leads to a more in-formative contrastive view. This emphasizes the alignment of sim-ilar instances, rather than indiscriminately distancing differentones . Notably, different from NCL , which learns clus-ter centers based on the EM algorithm as anchors, we measuresemantic relevance in a more fine-grained manner based on dis-crete codes. Specifically, we assess the semantic relevance of usersin two ways: (a) Shared codes: The discrete codes we learned arecorrelated with the collaborative semantics of user representations.Sharing codes between two users indicates fine-grained semanticrelevance. Thus, we identify users who share at least -1 codesas positive. (b) Shared target: When two users share a commoninteracted target, that is, they possess the same prediction label inthe dataset, we also consider them to be relevant. This supervisedpositive sampling method has shown its effectiveness in variousscenarios, including sentence embedding and sequential recom-mendation . Given the positive set combined by the instancesfrom the above two groups, we pair a sampled relevant instancewith each user for CL. Furthermore, semantically relevant positivesof items can also be obtained in a symmetrical way. By perform-ing CL within the sampled instances above, we aim to enhancethe clustering among similar users/items and improve semanticlearning.",
  "Triple-View Graph Contrastive Learning": "After the above contrastive view generation methods, we can obtainthree contrastive views with stronger collaborative information foreach node through virtual neighbor augmentation and semanticrelevance sampling: two augmented nodes with more abundantneighborhood structure and a semantically relevant user/item. Inthis part, we first introduce how to encode multi-view node rep-resentations, and then present our triple-view graph contrastivelearning approach to integrate structural and semantic informationeffectively. 3.4.1Multi-View Representation Encoding. For the two augmentedgraphs, we introduce additional learnable embeddings of user anditem discrete codes to serve as supplemental inputs, denoted asZ R(| C |+| C |). The input embedding matrix for augmentedgraphs is formed by concatenating ID embeddings with code embed-dings, denoted as Z0 = [Z0; Z]. Then we obtain representations ofdifferent views based on the same GNN encoder in .2.1:",
  "Z1 = GNN((Z11), G1),Z2 = GNN((Z12), G2),(12)": "where the initial representations are set as Z01 = Z02 = Z0. Afterapplying the readout function, we denote the representations ofthese two views as Z, and Z, respectively. As for the semanticallyrelevant user/item, we directly adopt the node representation ob-tained based on the initial interaction graph in .2.1 due tono structural augmentation. Moreover, the representation dropoutwe introduced can also be regarded as a minor data augmenta-tion. The distinct dropout masks applied during the two forwardpropagations result in different features . 3.4.2Alignment Between Neighbor Augmented Views. As detailedin .3.1, the two augmented nodes resulting from tworounds of virtual neighbor augmentation possess abundant neigh-bor structures. Therefore, we aim to incorporate more structuralinformation and improve model efficacy by aligning these neighboraugmented views. Formally, the alignment objective on the userside is as follows:",
  ",(13)": "where and are users in batch data B. z and z denote twodifferent user representations after virtual neighbor augmentations.The loss consists of two terms, representing the bidirectional align-ment of the two views. Analogously, we calculate the CL loss for theitem side as L. The total alignment loss between nodes with aug-mented views is the sum of them, denoted as L = L + L. 3.4.3Alignment Between Semantically Relevant Users/Items. Fol-lowing the semantics relevance sampling method in .3.2,we randomly select a positive example with similar collaborativesemantics for each user , denoted as +. Then we align these rele-vant users to incorporate more collaborative semantic informationinto the model. The alignment loss can be written as:",
  ",(14)": "where (,+) is a positive user pair, and B is the sampled datain a batch. The two components of the equation correspond tothe alignment between two augmented views and the similar user,respectively. Furthermore, combining the symmetric alignmentloss on the item side, the total alignment loss between similarusers/items is L = L + L. 3.4.4Overall Optimization. In the end, by combining the recom-mendation loss (i.e., BPR loss), discrete code learning objective (Eq. (7))and all contrastive learning loss (Eq. (13) and Eq. (14)), our CoGCLis jointly optimized by minimizing the following overall loss:",
  "Instrument48,45321,413427,67499.959%Office181,87867,4091,477,82099.988%Gowalla29,85840,9881,027,46499.916%iFashion300,00081,6141,607,81399.993%": "Structural augmentation methods typically generate contrastiveviews by perturbing the graph structure like stochastic node/edgedropout . Several recent efforts attempt to use well-foundedmethods for structural perturbations, such as SVD-based adjacencymatrix reconstruction and graph rationale discovery basedon masked autoencoding . However, perturbations on sparsegraphs can not construct more informative contrastive views. As acomparison, our approach is both reliable and informative, lever-aging discrete codes as virtual neighbors to reliably enhance nodeneighborhood structure and alleviate data sparsity. The alignmentbetween two augmented nodes with abundant neighbors is benefi-cial for the integration of further collaborative information. Representation augmentation methods involve modeling addi-tional node representations as contrastive views, such as learninghypergraph representations and adding random noise .However, limited by the low-rank hypergraph matrix and the noiseperturbation, the generated contrastive views also suffer from thesemantic disruption issue. Besides, these methods typically indis-criminately distinguish representations of different instances. Incontrast, we consider users/items with shared codes or interactiontargets as semantically relevant. By aligning users/items with simi-lar collaborative semantics, we can further unleash the potential ofCL and enhance the semantic learning of the model.",
  "EXPERIMENT4.1Experiment Setup": "4.1.1Dataset. We evaluate our proposed approach on four pub-lic datasets: Instrument and Office subsets from the most recentAmazon2023 benchmark , Gowalla , Alibaba-iFashion .For Instrument and Office datasets, we filter out low-activity usersand items with less than five interactions. For Gowalla dataset,we use 10-core filtering to ensure the data quality following priorworks . As for the sparser iFashion dataset, we employ thedata processed by , which randomly samples 300k users andtheir interactions. Our processed datasets vary in terms of domain,scale, and sparsity. Their statistics are summarized in . Foreach dataset, we split the observed interactions into training, vali-dation, and testing sets with a ratio of 8:1:1. 4.1.2Baseline Models. We adopt the following competitive base-lines for comparison with our CoGCL, which includes traditionalCF models: (1) BPR , (2) GCMC , (3) NGCF , (4)DGCF , (5) LightGCN , (6) SimpleX , as well as variousrepresentative CL-based models: (7) SLRec , (8) SGL , (9)NCL , (10) HCCF , (11) GFormer , (12) SimGCL ,(13) LightGCL . A more detailed introduction to the above base-line models is given in Appendix B.1. 4.1.3Evaluation Settings. To evaluate the performance of the abovemodels, we adopt two widely used metrics in recommendation:Recall@ and Normalized Discounted Cumulative Gain (NDCG)@.In this paper, we set to 5, 10, and 20. For the sake of rigorouscomparison, we perform full ranking evaluation over theentire item set instead of sample-based evaluation. 4.1.4Implementation Details. For all comparison models, we useAdam for optimization and set the embedding dimension to 64uniformly. The batch size is 4096, and the number of GNN layersin GNN-based methods is set to 3. To ensure a fair comparison,we utilize grid search to obtain optimal performance accordingto the hyperparameter settings reported in the original papers ofbaseline methods. For our approach, we employ RQ as the defaultdiscrete code learning method. The number of code levels = 4,and the temperature = 0.2. The codebook size is set to 256 forInstrument and Gowalla datasets, and 512 for Office and iFashiondatasets due to their larger scale. The hyperparameters are tunedin {5, 1, 0.5}, while and are tuned in {5, 1, 0.5, 0.2, 0.1, 0.05, 0.02,0.01, 0.005, 0.001}. The probabilities of replace and add in virtualneighbor augmentation are tuned in {0.01, 0.05, 0.1, 0.15, 0.2, 0.25,0.3, 0.4, 0.5, 0.6}. For experiments on hyperparameter tuning, pleaserefer to Appendix B.2.",
  "Overall Performance": "The overall results for performance comparison between CoGCLand other baseline models are shown in . From the results,we find the following observations:The CL-based methods (e.g., SGL, NCL, SimGCL, LightGCL)show consistent superiority over the traditional MF methods (e.g.,BPR, SimpleX) and GNN-based methods (e.g., NGCF, LightGCN).This performance improvement could be attributed to the self-supervised signals brought by contrastive learning, which helps toalleviate data sparsity and enhance representation learning. WithinCL-based methods, structure augmentation and representation aug-mentation exhibit distinct strengths in different scenarios. Specifi-cally, SimGCL, as a typical representation augmentation method,performs better than other baseline models on Instrument andGowalla datasets, thanks to the improved uniformity achieved byincorporating random noise. Conversely, the most competitive mod-els for Office and iFashion datasets are GFormer and LightGCL,respectively, both of which are structure augmentation methods.In contrast, SGL tends to underperform, indicating that stochas-tic edge/node dropout possibly interferes with crucial structuralinformation, leading to adverse impacts.Finally, our proposed CoGCL consistently maintains the bestperformance in all cases, achieving significant improvements overbaseline methods. Different from these baseline models, CoGCLunleashes the potential of CL by constructing contrastive viewsthat imply stronger collaborative information. Based on the learneddiscrete codes rich in collaborative information, we introduce vir-tual neighbor augmentation and semantic relevance sampling toenhance the neighborhood structure and semantic relevance of con-trasting views, respectively. Furthermore, triple-view graph con-trastive learning across the obtained contrastive views brings sup-plemental collaborative insights to the model. As a result, CoGCL",
  "Ablation Study": "In this part, we first investigate the contribution of various con-trastive view generation methods in the proposed approach, andthen conduct an in-depth ablation analysis of alignment and uni-formity of CL. 4.3.1Ablation Study of Data Augmentation. In order to explore thecontribution of data augmentation methods involved in CoGCL. weevaluate the performance of the following variants: (1) w/o Replaceremoves the replace operator in virtual neighbor augmentation.(2) w/o Add removes the add operator in virtual neighbor aug-mentation. (3) w/o Shared-C removes similar users/items sharedcodes in semantic relevance sampling. (4) w/o Shared-T removessimilar users/items shared interaction target in semantic relevancesampling. The results are shown in . We can observe thatthe exclusion of any data augmentation method would lead to a",
  "decrease in performance, which demonstrates that all data aug-mentation methods employed for contrastive view generation inCoGCL are useful for performance improvement": "4.3.2Ablation Study of Triple-View Graph Contrastive Learning.Apart from the above techniques, we further investigate how thealignment and uniformity of CL affect our approach. We disablethese two terms respectively in the CL losses (i.e., L and Lin .4) by applying the same gradient-stopping operationsin empirical analysis (.2). Specifically, we construct thefollowing variants for detailed exploration: (1) w/o A and (2) w/o Uare consistent with .2, denoting disabling alignment anduniformity in CL respectively, including both L and L. (3)w/o AA and (4) w/o AU only involve disabling the above two termsof L while keeping L constant. (5) w/o SA and (6) w/o SUare analogous variants for L and do not change L.As shown in , the absence of alignment (i.e., w/o A) oruniformity (i.e., w/o U) within both L and L leads to a no-table performance degradation. This observation verifies that thejoint effect of these two elements is crucial for the effectiveness of",
  ": Performance comparison of different discrete codelearning methods": "the proposed approach, rather than relying solely on uniformity.Furthermore, individually disabling uniformity within L (i.e.,w/o AU) and L (i.e., w/o SU) does not result in the significantadverse impact as conjectured. It could be attributed to the shareduniformity effect between the two CL losses in CoGCL, whichmay mutually reinforce each other. In contrast, the individual de-activation of alignment within L (i.e., w/o AA) and L (i.e.,w/o SA) incurs a pronounced decrease in performance. This pro-vides further evidence that our proposed alignment between thetwo types of positives brings enhanced collaborative informationbeyond uniformity.",
  "Further Analysis": "4.4.1Performance Comparison w.r.t. Different Discrete Code Learn-ing Methods. To verify the advancedness of the proposed end-to-end discrete code learning method, we compare it with the followingthree variants: (1) Non-Learnable Code uses Faiss library togenerate discrete codes based on trained LightGCN embeddings.The generated codes are non-learnable and remain unchanged dur-ing model training. (2) Euclidean Code adopts Euclidean distanceto measure the similarity between user/item representations andcodebook vectors in Eq. (6), which is consistent with the original RQmethod . (3) PQ Code employs PQ instead of RQ as a multi-levelquantizer for discrete code learning. We conduct experiments on In-strument and Office datasets, and the results are shown in .It can be seen that Non-Learnable Code is less robust compared tothe end-to-end learned discrete codes, which may stem from theinability to continuously improve the collaborative informationwithin discrete codes while optimizing the model. In comparisonto Euclidean Code and PQ Code, our proposed approach shows su-perior performance. Unlike Euclidean Code, our method utilizescosine similarity to synchronize with the similarity measure inCL. Compared with PQ Code, the RQ we applied establishes condi-tional probability relationships among codes at each level instead oftreating them as independent, which is conducive to the semanticmodeling of various granularities. 4.4.2Performance Comparison w.r.t. Data Sparsity. To verify themerit of our approach in alleviating data sparsity, we evaluateCoGCL on user groups with different sparsity levels. Specifically,following prior works , we divide users into five groups ac-cording to their number of interactions, while keeping the samenumber of users in each group constant. Subsequently, we evaluatethe performance of these five groups of users, and the results are Sparse > Dense0.030 0.035 0.040 0.045 0.050 NDCG@10",
  ": Performance comparison on user groups with dif-ferent sparsity levels": "shown in . We can see that CoGCL consistently outper-forms the baseline model across all sparsity levels. Furthermore,our model shows superior performance and significant improve-ment in the highly sparse user groups. This phenomenon indicatesthat CoGCL can achieve high-quality recommendation in scenar-ios with sparse interactions, which benefits from the additionalinsights brought by CL between contrastive views with strongercollaborative information.",
  "RELATED WORK": "GNN-Based Collaborative Filtering. Graph Neural Networks(GNNs) have become prominent in collaborative filtering (CF) dueto their effectiveness in modeling user-item relationships .The core approach involves organizing user-item interaction datainto a bipartite graph and learning node representations from thegraph structure. Earlier efforts extract the graph informationusing random walk strategies. With the development of GNNs, thecommon studies has shifted towards designing effective message-passing mechanisms to propagate user/item embeddings over thegraph . Subsequently, LightGCN and LR-GCCF propose eliminating transformation and non-linear activation tosimplify GNNs while improving performance. Furthermore, recentstudies are also devoted to enhancing GNNs with various advancedtechniques, such as disentangled representation learning ,hypergraph learning and contrastive learning . Contrastive Learning for Recommendation. Recently, con-trastive learning (CL) has demonstrated significant potential invarious recommendation scenarios like sequential recommenda-tion and knowledge graph-enhanced recommenda-tion . In the context of GNN-based CF, existing efforts canbe categorized into two main approaches according to how thecontrastive views are constructed. The first approach is to per-form data augmentation over graph structure Forinstance, SGL randomly drops nodes/edges within the interac-tion graph to construct augmented graphs. The second approachis to model additional view representations of users and itemsfor CL . Particularly, SimGCL generatescontrastive views by adding random noise to node embeddings. De-spite their success, the collaborative information within contrastiveviews may be disrupted in these methods, and thus the potentialof CL has not been fully exploited. In this paper, we propose to",
  "unleash the potential of CL by constructing contrastive views withstronger collaborative information via discrete codes": "User/Item ID Discretization in Recommendation. ID discretiza-tion involves employing a tuple of discrete codes as identifier torepresent a user/item instead of the vanilla single ID, achievedthrough methods like semantic hashing , vector quan-tization , etc. These methods allow similar users/items toshare certain codes, which can offer valuable prior knowledge forsubsequent recommendation models. Initially, the focus was on de-veloping memory- and time-efficient recommendation algorithmsby sharing code embeddings . Recently, discretecodes have gained popularity for improving recommendation qual-ity in various scenarios. They are particularly beneficial in alleviat-ing data sparsity and offering prior semantics, which has provenadvantageous in transferable recommendation , generative se-quential recommendation and LLM-based recom-mendation . Different from these studies, our work aimsto employ discrete codes for virtual neighbor augmentation andsemantic similarity sampling to enhance graph CL in CF.",
  "CONCLUSION": "In this paper, we proposed a novel framework to enhance graph CLby constructing reliable and informative contrastive views that im-ply stronger collaborative information. The core idea is to learn dis-crete codes associated with rich collaborative information for usersand items to generate contrastive views. Specifically, we presentan end-to-end multi-level vector quantizer to map users and itemsinto discrete codes. These codes are used to enhance the neigh-borhood structure and semantic relevance of contrastive views.Firstly, we generate dual augmented nodes with abundant neigh-borhood structures by replacing node neighbors with discrete codesor adding them as virtual neighbors relying on the observed in-teractions. Secondly, we consider users/items with shared discretecodes as semantically relevant and select similar positive examplesbased on this semantic relevance. Finally, we introduce a triple-view graph contrastive learning approach to align two augmentednodes and the sampled similar user/item. Extensive experiments onfour public datasets demonstrate the effectiveness of our proposedCoGCL. As future work, we attempt to improve the scalability of ourframework to extend it to other recommendation scenarios, suchas click-through rate prediction and sequential recommendation. Jan Van Balen and Mark Levy. 2019. PQ-VAE: Efficient Recommendation UsingQuantized Embeddings. In Proceedings of ACM RecSys 2019 Late-Breaking Resultsco-located with the 13th ACM Conference on Recommender Systems, RecSys 2019Late-Breaking Results, Copenhagen, Denmark, September 16-20, 2019 (CEUR Work-shop Proceedings, Vol. 2431), Marko Tkalcic and Sole Pera (Eds.). CEUR-WS.org,4650. Shumeet Baluja, Rohan Seth, D. Sivakumar, Yushi Jing, Jay Yagnik, ShankarKumar, Deepak Ravichandran, and Mohamed Aly. 2008. Video suggestion anddiscovery for youtube: taking random walks through the view graph. In Proceed-ings of the 17th International Conference on World Wide Web, WWW 2008, Beijing,China, April 21-25, 2008. ACM, 895904.",
  "-21, 2002, Montral, Qubec, Canada. ACM, 380388": "Lei Chen, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2020. RevisitingGraph Based Collaborative Filtering: A Linear Residual Graph ConvolutionalNetwork Approach. In The Thirty-Fourth AAAI Conference on Artificial Intelligence,AAAI 2020, The Thirty-Second Innovative Applications of Artificial IntelligenceConference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances inArtificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020. AAAIPress, 2734. Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey E. Hinton. 2020.A Simple Framework for Contrastive Learning of Visual Representations. InProceedings of the 37th International Conference on Machine Learning, ICML 2020,13-18 July 2020, Virtual Event (Proceedings of Machine Learning Research, Vol. 119).PMLR, 15971607. Wen Chen, Pipei Huang, Jiaming Xu, Xin Guo, Cheng Guo, Fei Sun, Chao Li,Andreas Pfadler, Huan Zhao, and Binqiang Zhao. 2019. POG: Personalized OutfitGeneration for Fashion Recommendation at Alibaba iFashion. In Proceedingsof the 25th ACM SIGKDD International Conference on Knowledge Discovery &Data Mining, KDD 2019, Anchorage, AK, USA, August 4-8, 2019. ACM, 26622670.",
  "Yongjian Chen, Tao Guan, and Cheng Wang. 2010. Approximate Nearest NeighborSearch by Residual Vector Quantization. Sensors 10, 12 (2010), 1125911273": "Eunjoon Cho, Seth A. Myers, and Jure Leskovec. 2011. Friendship and mobility:user movement in location-based social networks. In Proceedings of the 17th ACMSIGKDD International Conference on Knowledge Discovery and Data Mining, SanDiego, CA, USA, August 21-24, 2011, Chid Apt, Joydeep Ghosh, and PadhraicSmyth (Eds.). ACM, 10821090. Chen Gao, Yu Zheng, Nian Li, Yinfeng Li, Yingrong Qin, Jinghua Piao, YuhanQuan, Jianxin Chang, Depeng Jin, Xiangnan He, and Yong Li. 2023. A Survey ofGraph Neural Networks for Recommender Systems: Challenges, Methods, andDirections. Trans. Recomm. Syst. 1, 1 (2023), 151. Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021. SimCSE: Simple ContrastiveLearning of Sentence Embeddings. In Proceedings of the 2021 Conference on Em-pirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / PuntaCana, Dominican Republic, 7-11 November, 2021. Association for ComputationalLinguistics, 68946910. Marco Gori and Augusto Pucci. 2007. ItemRank: A Random-Walk Based ScoringAlgorithm for Recommender Engines. In IJCAI 2007, Proceedings of the 20thInternational Joint Conference on Artificial Intelligence, Hyderabad, India, January6-12, 2007, Manuela M. Veloso (Ed.). 27662771. Robert Gray. 1984. Vector quantization. IEEE Assp Magazine 1, 2 (1984), 429. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yong-Dong Zhang, and MengWang. 2020. LightGCN: Simplifying and Powering Graph Convolution Networkfor Recommendation. In Proceedings of the 43rd International ACM SIGIR confer-ence on research and development in Information Retrieval, SIGIR 2020, Virtual Event,China, July 25-30, 2020. ACM, 639648. Yupeng Hou, Zhankui He, Julian J. McAuley, and Wayne Xin Zhao. 2023. Learn-ing Vector-Quantized Item Representation for Transferable Sequential Recom-menders. In Proceedings of the ACM Web Conference 2023, WWW 2023, Austin,TX, USA, 30 April 2023 - 4 May 2023. ACM, 11621171.",
  "Yupeng Hou, Jiacheng Li, Zhankui He, An Yan, Xiusi Chen, and Julian J.McAuley. 2024. Bridging Language and Items for Retrieval and Recommen-dation. CoRR abs/2403.03952 (2024)": "Wenyue Hua, Shuyuan Xu, Yingqiang Ge, and Yongfeng Zhang. 2023. How toIndex Item IDs for Recommendation Foundation Models. In Annual InternationalACM SIGIR Conference on Research and Development in Information Retrieval inthe Asia Pacific Region, SIGIR-AP 2023, Beijing, China, November 26-28, 2023. ACM,195204. Piotr Indyk and Rajeev Motwani. 1998. Approximate Nearest Neighbors: TowardsRemoving the Curse of Dimensionality. In Proceedings of the Thirtieth AnnualACM Symposium on the Theory of Computing, Dallas, Texas, USA, May 23-26, 1998.ACM, 604613.",
  "Jeff Johnson, Matthijs Douze, and Herv Jgou. 2021. Billion-Scale SimilaritySearch with GPUs. IEEE Trans. Big Data 7, 3 (2021), 535547": "Wang-Cheng Kang and Julian John McAuley. 2019. Candidate Generation withBinary Codes for Large-Scale Top-N Recommendation. In Proceedings of the 28thACM International Conference on Information and Knowledge Management, CIKM2019, Beijing, China, November 3-7, 2019. ACM, 15231532. Yun-Yong Ko, Jae-Seo Yu, Hong-Kyun Bae, Yongjun Park, Dongwon Lee, andSang-Wook Kim. 2021. MASCOT: A Quantization Framework for Efficient MatrixFactorization in Recommender Systems. In IEEE International Conference on DataMining, ICDM 2021, Auckland, New Zealand, December 7-10, 2021. IEEE, 290299. Dongha Lee, SeongKu Kang, Hyunjun Ju, Chanyoung Park, and Hwanjo Yu.2021. Bootstrapping User and Item Representations for One-Class CollaborativeFiltering. In SIGIR 21: The 44th International ACM SIGIR Conference on Researchand Development in Information Retrieval, Virtual Event, Canada, July 11-15, 2021.ACM, 15131522. Chaoliu Li, Lianghao Xia, Xubin Ren, Yaowen Ye, Yong Xu, and Chao Huang. 2023.Graph Transformer for Recommendation. In Proceedings of the 46th InternationalACM SIGIR Conference on Research and Development in Information Retrieval,SIGIR 2023, Taipei, Taiwan, July 23-27, 2023. ACM, 16801689.",
  "Fionn Murtagh and Pedro Contreras. 2012. Algorithms for hierarchical clustering:an overview. WIREs Data Mining Knowl. Discov. 2, 1 (2012), 8697": "Ruihong Qiu, Zi Huang, Hongzhi Yin, and Zijian Wang. 2022. Contrastive Learn-ing for Representation Degeneration Problem in Sequential Recommendation. InWSDM 22: The Fifteenth ACM International Conference on Web Search and DataMining, Virtual Event / Tempe, AZ, USA, February 21 - 25, 2022. ACM, 813823. Shashank Rajput, Nikhil Mehta, Anima Singh, Raghunandan Hulikal Keshavan,Trung Vu, Lukasz Heldt, Lichan Hong, Yi Tay, Vinh Q. Tran, Jonah Samost, MaciejKula, Ed H. Chi, and Mahesh Sathiamoorthy. 2023. Recommender Systems withGenerative Retrieval. In Advances in Neural Information Processing Systems 36: An-nual Conference on Neural Information Processing Systems 2023, NeurIPS 2023, NewOrleans, LA, USA, December 10 - 16, 2023. Xubin Ren, Lianghao Xia, Jiashu Zhao, Dawei Yin, and Chao Huang. 2023. Dis-entangled Contrastive Collaborative Filtering. In Proceedings of the 46th In-ternational ACM SIGIR Conference on Research and Development in Informa-tion Retrieval, SIGIR 2023, Taipei, Taiwan, July 23-27, 2023. ACM, 11371146. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme.2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In UAI 2009,Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence,Montreal, QC, Canada, June 18-21, 2009. AUAI Press, 452461. Dinghan Shen, Qinliang Su, Paidamoyo Chapfuwa, Wenlin Wang, Guoyin Wang,Ricardo Henao, and Lawrence Carin. 2018. NASH: Toward End-to-End NeuralArchitecture for Generative Semantic Hashing. In Proceedings of the 56th AnnualMeeting of the Association for Computational Linguistics, ACL 2018, Melbourne,Australia, July 15-20, 2018, Volume 1: Long Papers. Association for ComputationalLinguistics, 20412050. Shaoyun Shi, Weizhi Ma, Min Zhang, Yongfeng Zhang, Xinxing Yu, Houzhi Shan,Yiqun Liu, and Shaoping Ma. 2020. Beyond User Embedding Matrix: Learningto Hash for Modeling Large-Scale Users in Recommendation. In Proceedingsof the 43rd International ACM SIGIR conference on research and development inInformation Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020. ACM,319328. Zihua Si, Zhongxiang Sun, Jiale Chen, Guozhang Chen, Xiaoxue Zang, Kai Zheng,Yang Song, Xiao Zhang, and Jun Xu. 2023. Generative Retrieval with SemanticTree-Structured Item Identifiers via Contrastive Learning. CoRR abs/2309.13375",
  "A Vasuki and PT Vanathi. 2006. A review of vector quantization techniques. IEEEPotentials 25, 4 (2006), 3947": "Chenyang Wang, Yuanqing Yu, Weizhi Ma, Min Zhang, Chong Chen, Yiqun Liu,and Shaoping Ma. 2022. Towards Representation Alignment and Uniformityin Collaborative Filtering. In KDD 22: The 28th ACM SIGKDD Conference onKnowledge Discovery and Data Mining, Washington, DC, USA, August 14 - 18, 2022.ACM, 18161825. Tongzhou Wang and Phillip Isola. 2020. Understanding Contrastive Represen-tation Learning through Alignment and Uniformity on the Hypersphere. InProceedings of the 37th International Conference on Machine Learning, ICML 2020,13-18 July 2020, Virtual Event (Proceedings of Machine Learning Research, Vol. 119).PMLR, 99299939. Wenjie Wang, Honghui Bao, Xilin Chen, Jizhi Zhang, Yongqi Li, Fuli Feng, See-Kiong Ng, and Tat-Seng Chua. 2024. Learnable Tokenizer for LLM-based Genera-tive Recommendation. CoRR abs/2405.07314 (2024). arXiv:2405.07314 Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019.Neural Graph Collaborative Filtering. In Proceedings of the 42nd InternationalACM SIGIR Conference on Research and Development in Information Retrieval,SIGIR 2019, Paris, France, July 21-25, 2019. ACM, 165174. Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua.2020. Disentangled Graph Collaborative Filtering. In Proceedings of the 43rdInternational ACM SIGIR conference on research and development in InformationRetrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020. ACM, 10011010. Yifan Wang, Suyao Tang, Yuntong Lei, Weiping Song, Sheng Wang, and MingZhang. 2020. DisenHAN: Disentangled Heterogeneous Graph Attention Networkfor Recommendation. In CIKM 20: The 29th ACM International Conference onInformation and Knowledge Management, Virtual Event, Ireland, October 19-23,2020. ACM, 16051614. Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, andXing Xie. 2021. Self-supervised Graph Learning for Recommendation. In SIGIR21: The 44th International ACM SIGIR Conference on Research and Developmentin Information Retrieval, Virtual Event, Canada, July 11-15, 2021. ACM, 726735.",
  "Shiwen Wu, Fei Sun, Wentao Zhang, Xu Xie, and Bin Cui. 2023. Graph NeuralNetworks in Recommender Systems: A Survey. ACM Comput. Surv. 55, 5 (2023),97:197:37": "Lianghao Xia, Chao Huang, Yong Xu, Jiashu Zhao, Dawei Yin, and Jimmy X.Huang. 2022. Hypergraph Contrastive Collaborative Filtering. In SIGIR 22:The 45th International ACM SIGIR Conference on Research and Development inInformation Retrieval, Madrid, Spain, July 11 - 15, 2022. ACM, 7079. Xu Xie, Fei Sun, Zhaoyang Liu, Shiwen Wu, Jinyang Gao, Jiandong Zhang, BolinDing, and Bin Cui. 2022. Contrastive Learning for Sequential Recommendation.In 38th IEEE International Conference on Data Engineering, ICDE 2022, KualaLumpur, Malaysia, May 9-12, 2022. IEEE, 12591273. Yonghui Yang, Zhengwei Wu, Le Wu, Kun Zhang, Richang Hong, Zhiqiang Zhang,Jun Zhou, and Meng Wang. 2023. Generative-Contrastive Graph Learning forRecommendation. In Proceedings of the 46th International ACM SIGIR Conferenceon Research and Development in Information Retrieval, SIGIR 2023, Taipei, Taiwan,July 23-27, 2023. ACM, 11171126. Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, Felix X. Yu, Ting Chen,Aditya Krishna Menon, Lichan Hong, Ed H. Chi, Steve Tjoa, Jieqi (Jay) Kang,and Evan Ettinger. 2021. Self-supervised Learning for Large-scale Item Recom-mendations. In CIKM 21: The 30th ACM International Conference on Informationand Knowledge Management, Virtual Event, Queensland, Australia, November 1 -5, 2021. ACM, 43214330. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L. Hamilton,and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-ScaleRecommender Systems. In Proceedings of the 24th ACM SIGKDD InternationalConference on Knowledge Discovery & Data Mining, KDD 2018, London, UK, August",
  "-23, 2018. ACM, 974983": "Junliang Yu, Xin Xia, Tong Chen, Lizhen Cui, Nguyen Quoc Viet Hung, andHongzhi Yin. 2024. XSimGCL: Towards Extremely Simple Graph ContrastiveLearning for Recommendation. IEEE Trans. Knowl. Data Eng. 36, 2 (2024), 913926. Junliang Yu, Hongzhi Yin, Jundong Li, Qinyong Wang, Nguyen Quoc Viet Hung,and Xiangliang Zhang. 2021. Self-Supervised Multi-Channel Hypergraph Convo-lutional Network for Social Recommendation. In WWW 21: The Web Conference2021, Virtual Event / Ljubljana, Slovenia, April 19-23, 2021. ACM / IW3C2, 413424. Junliang Yu, Hongzhi Yin, Xin Xia, Tong Chen, Lizhen Cui, and Quoc Viet HungNguyen. 2022. Are Graph Augmentations Necessary?: Simple Graph ContrastiveLearning for Recommendation. In SIGIR 22: The 45th International ACM SIGIRConference on Research and Development in Information Retrieval, Madrid, Spain,July 11 - 15, 2022. ACM, 12941303.",
  "Algorithms. ACM Trans. Inf. Syst. 41, 2 (2023), 32:132:41": "Bowen Zheng, Yupeng Hou, Hongyu Lu, Yu Chen, Wayne Xin Zhao, MingChen, and Ji-Rong Wen. 2023. Adapting Large Language Models by IntegratingCollaborative Semantics for Recommendation. CoRR abs/2311.09049 (2023). arXiv:2311.09049 Kun Zhou, Hui Wang, Wayne Xin Zhao, Yutao Zhu, Sirui Wang, Fuzheng Zhang,Zhongyuan Wang, and Ji-Rong Wen. 2020. S3-Rec: Self-Supervised Learningfor Sequential Recommendation with Mutual Information Maximization. InCIKM 20: The 29th ACM International Conference on Information and Knowl-edge Management, Virtual Event, Ireland, October 19-23, 2020. ACM, 18931902.",
  "Xin Zhou, Aixin Sun, Yong Liu, Jie Zhang, and Chunyan Miao. 2023. SelfCF: ASimple Framework for Self-supervised Collaborative Filtering. Trans. Recomm.Syst. 1, 2 (2023), 125": "Ding Zou, Wei Wei, Xian-Ling Mao, Ziyang Wang, Minghui Qiu, Feida Zhu, andXin Cao. 2022. Multi-level Cross-view Contrastive Learning for Knowledge-aware Recommender System. In SIGIR 22: The 45th International ACM SIGIRConference on Research and Development in Information Retrieval, Madrid, Spain,July 11 - 15, 2022. ACM, 13581368. Ding Zou, Wei Wei, Ziyang Wang, Xian-Ling Mao, Feida Zhu, Rui Fang, andDangyang Chen. 2022. Improving Knowledge-aware Recommendation withMulti-level Interactive Contrastive Learning. In Proceedings of the 31st ACMInternational Conference on Information & Knowledge Management, Atlanta, GA,USA, October 17-21, 2022. ACM, 28172826.",
  "ATIME AND SPACE COMPLEXITYA.1Time Complexity": "We analyze the time complexity of the following procedures inour CoGCL: (1) The neighbor information aggregation based onLightGCN consumes O( |E| ) time, where denotes thenumber of GNN layers, and is the dimension of user/item em-beddings. (2) The time consumption for user and item discretecode learning is O( ), where is the batch size, denotes the number of code levels, and represents the size ofcodebook. Thanks to the benefits of RQ or PQ allowing for a vastexpression space (i.e., ) with minimal codes , inreal-world applications, and typically satisfy |U|and |I| (e.g., 4*256). (3) To obtain contrastive view rep-resentations, it takes O( (|E1 | + |E2 |) ) time to encodenode representations based on the augmented graphs. After train-ing, only the time taken by the first part is retained for futurerecommendations, which is the same as LightGCN.",
  ": Performance comparison of different CL loss coef-ficients": "From the results, we can observe that too large or too small would lead to suboptimal performance, and too large would causea sharp drop in performance. The recommended values for onInstrument and Office datasets are 0.1 and 1, respectively, while theoptimal values of for these datasets are 0.02 and 0.2, respectively.Generally, the optimal value of is smaller than that of , and it isessential to tune these hyperparameters for the balance betweendifferent objectives.",
  "B.3Embedding Distribution w.r.t.Augmentation Ratio": "To more intuitively understand the contribution of CoGCL, wevisualize the learned embedding distribution under different dataaugmentation ratios in . We first map user embeddings totwo-dimensional space based on t-SNE . Then we apply Gauss-ian kernel density estimation (KDE) to plot the user embeddingdistribution in the two-dimensional space. w 2 and w 0.5 indicatethat probabilities (both replace and add) for virtual neighboraugmentation are adjusted to twice and half of the optimal valuesrespectively. From the results, we can find that the embedding dis-tributions learned by CoGCL and SimGCL are more uniform thanthat of LightGCN, thanks to the uniformity brought by CL. Com-pared with SimGCL, the embedding learned by CoGCL achieves agood trade-off between clustering and uniformity. In addition, itcan be seen that the embeddings exhibit a more clustered pattern asthe augmentation ratio rises, suggesting that higher augmentationprobabilities lead to a stronger tendency for clustering."
}