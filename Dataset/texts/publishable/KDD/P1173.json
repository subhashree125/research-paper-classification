{
  "ABSTRACT": "Graph Neural Networks (GNNs) are state-of-the-art models forperforming prediction tasks on graphs. While existing GNNs haveshown great performance on various tasks related to graphs, littleattention has been paid to the scenario where out-of-distribution(OOD) nodes exist in the graph during training and inference.Borrowing the concept from CV and NLP, we define OOD nodesas nodes with labels unseen from the training set. Since a lot ofnetworks are automatically constructed by programs, real-worldgraphs are often noisy and may contain nodes from unknown dis-tributions. In this work, we define the problem of graph learningwith out-of-distribution nodes. Specifically, we aim to accomplishtwo tasks: 1) detect nodes which do not belong to the known distri-bution and 2) classify the remaining nodes to be one of the knownclasses. We demonstrate that the connection patterns in graphs areinformative for outlier detection, and propose Out-of-DistributionGraph Attention Network (OODGAT), a novel GNN model whichexplicitly models the interaction between different kinds of nodesand separate inliers from outliers during feature propagation. Exten-sive experiments show that OODGAT outperforms existing outlierdetection methods by a large margin, while being better or compa-rable in terms of in-distribution classification.",
  "Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,to post on servers or to redistribute to lists, requires prior specific permission and/or afee. Request permissions from 22, August 1418, 2022, Washington, DC, USA. 2022 Association for Computing Machinery.ACM ISBN 978-1-4503-9385-0/22/08...$15.00 one of the most important tasks of GNNs is semi-supervised nodeclassification (SSNC) . In SSNC, GNNs aggregate informationfrom adjacent nodes and generate representations that are smoothwithin neighborhoods, alleviating the difficulty of classification.In recent years, many studies have begun to consider graph learn-ing tasks in realistic settings, such as graphs with label noise ,low labeling rates and distribution shifts . However, veryfew work has considered the scenario where out-of-distribution(OOD) nodes exist in the graph on which one performs SSNC. Byusing the term OOD, we borrow the notion from CV and NLP,which means samples with labels not seen in the training set. Inthe graph domain, this can be quite common as graphs are usuallyconstructed in an incremental way where new nodes are added dueto the connectivity with existing ones, and for most cases there isno guarantee that all nodes must connect to others from the samedistribution. For example, we want to classify papers in a citationnetwork into AI-related topics, e.g., deep learning, reinforcementlearning and optimization methods. The network is obtained usinga web crawler which adopts a breadth first search (BFS) strategyand keeps exploring papers referencing existing ones for a numberof iterations. When searching stops, the resulting network is notguaranteed to contain nodes only from the known categories, as itis common for a scientific paper to refer to articles in less relevantresearch areas, for example, an AI paper might cite papers in neu-roscience and mathematics. In real-world networks, the proportionof nodes from irrelevant categories may even be higher than thosefrom the classes of interest. Given a noisy graph as such, our task isto predict the label for nodes which correspond to one of the knownclasses, and identify nodes that do not belong to any of them.In CV and NLP, OOD detection has been a hot research area witha long history. demonstrates that neural networks tend to assignhigher softmax probabilities to in-distribution (ID) samples than toout-of-distribution (OOD) ones, and proposes to use the maximumsoftmax probability (MSP) produced by the neural network as thescore for OOD detection. Other approaches attempt to improvedetection performance by modifying the model structure ,employing customized uncertainty measures or exploitinglabeled outliers .Different from the above methods which only focus on identi-fying OOD samples at inference time, the presence of OOD nodesin graphs makes the task more challenging. First, in traditionalsettings of CV and NLP, outliers only occur in the test set, while inthe graph domain one is usually given the entire graph for trainingwhich consists of both inliers and outliers, transferring the prob-lem from detecting unknown-unknown to known-unknown. How toleverage the availability of outliers is the key to success. Second,the classifier in CV and NLP is usually trained in a fully supervisedmanner with abundant labeled data, while for graphs the most com-mon approach for node classification is to train a GNN with limited",
  "ID-1ID-2ID-3OOD-1OOD-2": ": An illustration of graph learning with out-of-distribution nodes. In this setting, we aim to accomplish twotasks: 1) separate ID nodes from OOD nodes and 2) classify IDnodes correctly. Colors of nodes indicate their labels, and theshaded areas represent a possible set of decision boundaries.Note that the connections exist not only within ID nodes,but also within OOD nodes, and in between. Unlike tradi-tional anomaly detection which assumes a small percentageof anomalies, in the graph domain, the OOD part may con-tain nodes that are comparable in size to the ID part. labeled data in a semi-supervised way. Due to the message-passingframework adopted by GNNs, the latent features of ID and OODnodes can be affected by each other. Therefore, it is important tostudy how the information flow between inliers and outliers canaffect the performance of in-distribution classification and outlierdetection. A similar question arises in , where the authors inves-tigate the performance of semi-supervised learning (SSL) methodswhen labeled and unlabeled data are drawn from different distri-butions. However, this problem remains unexplored in the fieldof graph-based SSNC. Third, since our purpose is to address nodeclassification and outlier detection in a joint framework, a naturalquestion is how to combine the two tasks into a unified model, andhow to balance the impact of one task on the other.In this work, we first analyze the impact of OOD nodes on graphlearning tasks with GNNs. We demonstrate that for graphs withhigh homophily, message-passing GNNs are inherently good atdetecting outliers due to the smoothness effect caused by featurepropagation. Furthermore, we find that removing inter-edges be-tween ID and OOD nodes while preserving intra-edges within eachcluster can lead to the overall best performance. Motivated by thesefindings, we propose a novel GNN model Out-of-Distribution GraphAttention Network (OODGAT) which utilizes attention mechanismand explicitly models the interaction between inliers and outliers.Experiments show that OODGAT outperforms all baselines in termsof both detection and classification, and even surpasses post-hocdetectors which are tuned directly on the test set.To the best of our knowledge, we are the first to formally definethe problem of graph learning with OOD nodes. considers asimilar setting where the graph also contains OOD nodes. Theydeveloped a Bayesian framework to detect outliers by calculatingmultiple uncertainty measures. Our work differs in that we analyze the fundamental advantages of GNNs from the perspective of net-work geometry, and exploit the information contained in the graphstructure to solve the problem in an efficient and elegant way.To summarize, our work makes the following contributions:",
  "RELATED WORKS2.1Graph Neural Networks": "Graph neural networks (GNNs) have shown great performance invarious applications related to graphs. In this work, we focus onthe problem of semi-supervised node classification (SSNC) .In SSNC, GNNs aggregate features from neighboring nodes andproduce a latent space where the similarity between node embed-dings corresponds to the connection patterns between nodes in thegeometry space. The most commonly used GNNs include graphconvolutional network (GCN) , graph attention network (GAT) and GraphSAGE .",
  "Outlier Detection": "Outlier detection, also known as OOD detection, has been a hotresearch area in various domains. Based on the availability of OODdata during training, OOD detectors can be classified into threetypes, namely unsupervised, supervised and semi-supervised meth-ods.Unsupervised Methods. Unsupervised methods only utilize in-distribution data to train the outlier detector. Among various tech-niques, the most commonly used ones include ODIN andMahalanobis-distance . These methods are called post-hoc de-tectors as they assume the classification network is already trainedon in-distribution data, and the detector is built on top of the pre-trained classifier by calibrating its output probabilities or exploitingits latent space. Other approaches like require trainingan additional model which is designed specifically for OOD detec-tion, apart from the original classification network. Unsupervisedmethods do not utilize the abundant unlabeled data during train-ing and can only find sub-optimal solutions since they treat theclassification and outlier detection as two independent tasks.Supervised Methods. Supervised methods assume access to a setof OOD samples during training . Such methods train theclassifier in an end-to-end fashion using cross-entropy loss on theID training data to minimize classification error, together with a con-fidence penalty loss on the labeled OOD data to maintain low pre-diction confidence. For example, applies a KL-divergence termto OOD samples to ensure their predictions are close to uniform dis-tribution. Supervised detectors generally outperform unsupervised",
  "Learning on Graphs with Out-of-Distribution NodesKDD 22, August 1418, 2022, Washington, DC, USA": "where is the attention weight for aggregating information from to . The difference between various graph attention networkslies in the way the attention values are calculated. For example, GAT proposes to compute the (unnormalized) attention weightsbetween and by = a Wh Wh, wherethey use a single layer neural network parameterized by a to outputattention weights. However, none of the previous approaches takesOOD nodes into account, and the attention coefficients obtainedfrom their methods are not guaranteed to contain knowledge abouthow to distinguish inliers from outliers.In OODGAT, we propose to explicitly model the interactionbetween inliers and outliers. Based on the discussion in ,we summarize three properties the attention mechanism shouldpossess : 1) allow messages to pass within in-distribution nodes,2) allow message passing within out-of-distribution nodes and 3)block information flow between inliers and outliers. Therefore, wepropose the following attention form:",
  "Semi-supervised Learning WithDistribution Mismatch": "Another way to understand the proposed task is to consider it as asemi-supervised learning problem on graphs. SSL assumes access toonly a small set of labeled data and a relatively large set of sampleswithout label information. Oliver et al. points out that existingSSL methods tend to degrade the original classification performancewhen there exists a class distribution mismatch between labeledand unlabeled data. Following their discovery, researchers havedeveloped SSL methods that are robust against OOD samples, withtheir performance being at least as good as fully-supervised learning. The key idea of such methods is straightforward: theyattempt to detect and remove the OOD part of the unlabeled dataand apply SSL techniques only on the remaining purified set. Thissetting resembles ours in that they also treat the problem as twotasks, i.e., semi-supervised learning on in-distribution data andoutlier detection on the unlabeled set, where each task has itsinfluence on the other. However, these approaches perform SSL byadding regularization terms to the original classification loss (e.g.,cross-entropy), like VAT and minimum entropy regularization, while in the graph domain, SSNC is usually done with GNNswhich achieve semi-supervised learning in an implicit way.",
  "Problem Formulation": "Consider a graph G = (V, E), where V denotes the set of nodesand E denotes the set of edges. The graph structure is representedby an binary adjacency matrix A {0, 1}|V||V|. Each node in the graph is associated with a feature vector x and a label ,and the overall feature matrix and class vector can be representedby X and y, respectively. In SSNC, the node set can be further divided into V = V V where V refers to the set of nodeswhose labels are accessible during training. Similarly, the featurematrix and class vector can be divided into X =X , X andy = [y y]. The aim of SSNC is to predict the labels for nodesin V using the training set (X, y), the unlabeled features Xand the graph structure A. Different from traditional close-worldSSNC which assumes that nodes in V and V are sampled from thesame distribution, we generalize the problem into a more realisticsetting where nodes in V may come from a different distributionthan nodes in V. Due to the distribution shift between labeled andunlabeled data, the class vector y may contain labels not seen iny, and the label space Y is enlarged by Y = Y Y. For simplicity,we denote nodes with labels from Y by ID nodes or inliers andnodes with labels from Y \\ Y by OOD nodes or outliers. We callthis setting graph learning with OOD nodes and the purpose is to 1)assign labels from B = {0, 1} to nodes in V where 0 stands for IDand 1 for OOD and 2) for nodes tagged as ID, we further classifythem to be one of the classes in Y. Note that for both tasks, weare presented with the whole graph G during training, leading to asemi-supervised and transductive setting. In the remaining of thearticle, we call the two tasks Semi-Supervised Outlier Detection(SSOD) and Semi-Supervised Node Classification (SSNC) for thesake of simplicity.",
  "Semi-supervised Outlier Detection": "Unlike previous outlier detection methods which are designed pri-marily for CV and NLP tasks and derive the detector using onlyin-distribution data, the uniqueness of graphs makes us wonder:can we leverage the unlabeled data X and the graph structure A forbetter OOD detection? To answer the question, we first take a briefreview at the most common task on graphs, namely, SSNC. In SSNC,a GNN is used to propagate information between adjacent nodesand produce a latent space where features are distributed smoothlyw.r.t. the graph structure . The smoothness is desirable due tothe widely adopted homophily assumption, i.e., connected nodestend to share the same label . We argue that, like SSNC, theconnection pattern between nodes can also provide informationfor distinguishing ID from OOD. We start by giving the followingproposition: Proposition. Given a graph G, the set of original labels Y =Y Y, and the set of identity labels B = {0, 1}. Assume that:(1) There exists a mapping : Y B which maps each label inY to be ID or OOD;(2) G is homophilic w.r.t. to Y, i.e., edges in G tend to connect nodeswith the same label in Y.Then, G is also homophilic w.r.t. B. The proof of the proposition is presented in Appendix A. Fromthe proposition, we make the following hypothesis: GNNs are anatural fit for SSOD because they are inherently equipped with aregularizer that pushes the predicted OOD scores to be close withindensely connected communities, which is helpful for graphs withhigh homophily. We illustrate this in . The left figure showsthe OOD scores obtained without considering the graph structure.Overall, the scores of OOD nodes are higher than ID nodes, withan exception in each community due to the weakness of modernneural networks . By smoothing features according to the graph",
  "(a) Before smoothing(b) After smoothing": ": Smoothness helps OOD detection. The border ofcircles represents the true identity of nodes, while the dark-ness of the inner color represents the predicted OOD score.Arrows indicate the smoothing effect of GNNs. structure (b), GNN manages to recover the true scoresof nodes from their neighbors (green arrows). However, we alsonotice the edges that connect different kinds of nodes, which leadto undesirable feature aggregation and compromise the separationbetween inliers and outliers (red arrows). Since the number of intra-edges significantly exceeds that of inter-edges (for graphs withhigh homophily), the overall performance should be better thannot utilizing structural information at all.To verify the hypothesis, we conduct an experiment on Cora using Multilayer Perceptron (MLP) and GCN as predictors,and calculate the entropy of the predicted class distribution as theOOD score as in . The higher the entropy, the morelikely the model considers the node to be OOD. The ROC curves forboth methods are plotted in a, from which we can see theGCN detector outperforms the MLP counterpart by a large margin,validating that the graph structure is useful for detecting outliers.To better understand the impact of different kinds of connections,we test the detection performance on graphs with different sub-sets of edges, and the results are shown in b. As expected,removing inter-edges from the graph leads to improved detectionperformance (green line vs. orange line). However, the performancedrops sharply when we further remove edges within ID (red line) orOOD (purple line) communities, indicating that smoothness withinthe same type of nodes is critical for successful detection.",
  "Semi-supervised Node Classification": "It is known that the distribution mismatch between labeled and un-labeled data can hurt the performance of semi-supervised learning. In graph-based SSNC, unlabeled nodes convey their influenceto model parameters through their connections to the labeled ones,so it is natural to expect the same performance drop observed in when the graph contains edges connecting inliers and out-liers. However, the problem here is more sophisticated. On the onehand, the information exchange between ID and OOD data mayintroduce noise to the interested distribution, making the modelprone to overfitting and leading to poor generalization; On the",
  "Cora92.092.592.7CoauthorCS92.892.693.0Amazon-Photo97.097.097.2Amazon-Computers81.281.583.2": "other hand, the addition of inter-connections can enhance the con-nectivity of the graph and facilitate the propagation of supervisionsignals among nodes. Moreover, the connection patterns betweeninliers and outliers may provide knowledge about how to classifyID nodes. Therefore, it is difficult to tell whether the presence ofinter-connections is beneficial or detrimental to SSNC. To find outthe impact of inter-connections, we conducted experiments onsome commonly used graph datasets using GCN as the classifierand report the mean accuracy across 9 runs in . For eachgraph, we test the classification accuracy in three cases: preservingall inter-edges (remove=0), randomly dropping half of them (re-move=0.5), and removing them all (remove=1.0). Empirically, remov-ing inter-edges can improve the generalization of in-distributionclassification, which is particularly true for certain datasets.",
  "= 1 |() ()|(2)": "where () and () are the attention scores for and , re-spectively. If we consider () as a binary classifier that assignsdifferent weights to inliers and outliers, we can find that Equation(2) satisfies all the properties discussed above. We illustrate this in. Without loss of generality, when and are large,say = = 1, and and are small, say = = 0, theattention weights for intra-edges become = = 1, while theweights for inter-edges become = = 0. We also note that,for any node , the weight with which it attends to itself is fixedto be = 1, i.e., the maximum value possible for all node pairs.This is desirable since maintaining more self-information can behelpful when the neighborhood may contain contaminated features.After obtaining , we normalize them in each neighborhood usingsoftmax to keep the embedding scale unchanged before and afteraggregation:",
  "The binary classifier () can be defined in various forms. Toavoid too many parameters and a complex model, we simply imple-ment it as a logistic regression classifier parameterized by a R": "over the latent space of a GNN layer, i.e., () = aWh, whereW R is the weight matrix of the GNN layer, h R is theinput of the layer, and is the sigmoid function. The classifier aimsto find a partition of the latent space such that inliers and outliersare well separated from each other. To enhance the expressivenessof the model, we extend the attention computation to a multi-headvariant, similar to :",
  "Regularizer": "Of course, the cross-entropy loss alone is not sufficient to makeOODGAT work in the expected way. In particular, we want theembedded binary classifier to learn knowledge about how to distin-guish inliers from outliers. Therefore, we propose three regularizersto guide the learning process of OODGAT, i.e., consistency loss,entropy loss and discrepancy loss. The architecture of OODGAT isshown in , which we will explain in detail in the followingsections.Consistency Regularizer. OODGAT integrates a binary classifierto measure the OOD score for nodes in the graph, and translatesthe node-level scores into edge-level attention weights for featureaggregation. Besides the scores predicted by the classifier, we canalso obtain the output distribution of nodes at the final layer of themodel, from which the entropy can be calculated as another kind ofOOD measurement. We denote the scores predicted by the classifieras , and the scores given by entropy as . To coordinate the rela-tionship between and , we design the following regularizationterm called consistency loss:",
  "Output": ": Architecture of OODGAT. Arrows of different colorsindicate different information to be extracted from the layerfor loss computation. Yellow and grey rectangles representlayers w/ and w/o gradients propagation, respectively. In Equation (6), we use cosine similarity to constrain the differ-ence between w and e, i.e., the two methods should give similarpredictions across all nodes. The intuition behind the consistencyregularizer is the causal relationship between the attention mecha-nism and the models final output. That is, when the scores givenby the classifier change, the attention weights used for aggregatingfeatures will also change, which in turn affects the final output ofthe model. If we regard the change of the classifier as the cause,then the change of the models output can be viewed as the effect.By aligning cause and effect, the hypothesis space of the modelis reduced and gradient descent is more likely to find solutionsthat are closer to ground truth. Imagine an extreme case wherethe classifier works perfectly and produces OOD scores close toground-truth. In this case, the attention weights of edges also be-come near perfect and the model becomes extremely powerful indetecting outliers as it smooths representations for all ID and OODclusters and prevents the information exchange between ID andOOD communities. As a result, the OOD scores computed fromentropy are also close to reality, making the angle between w and esmall. From another perspective, we can interpret the consistencyloss as a kind of supervised learning: the entropy provides super-vision to the classifier and vice versa. As training progresses, theclassifier not only learns from the final output, but also teaches themodel to produce more reliable predictions by differentiating IDand OOD better in the latent space. Thus, the two modules play achasing game and benefit each other.For OODGAT with two layers, the consistency loss is computedfor both layers, and in each layer, the score vector w is averagedacross all heads:",
  "(9)": "Entropy Regularizer. In OODGAT, we use entropy as the measureof predictive uncertainty. As training proceeds, the cross-entropyloss continuously pulls the outputs of labeled nodes toward one-hot distribution, pushing their entropy to the lowest level. Due tothe generalization ability of neural networks, nodes outside thetraining set may also produce low-entropy predictions, especiallythose with attributes similar to or closely connected to the labeled",
  "(a) Ordinary GNNs(b) OODGAT": ": Illustration of the latent space of ordinary GNNsand OODGAT. The proposed regularizers can help the atten-tion module to control the information flow between ID andOOD nodes, hence OODGAT is able to produce a clearer gapbetween inliers and outliers. ones, resulting in some low-entropy regions in the graph. In contrastto the classification loss, we want to keep the uncertainty of outliersas high as possible to counteract the entropy-reducing effect causedby cross-entropy. However, the true identities of nodes cannotbe obtained during training, so we take the predictions given bythe binary classifier as pseudo-labels, and make the outputs ofpseudo-OOD nodes close to uniform distribution to enhance thedistinguishability between inliers and outliers. Thus, we get thefollowing entropy loss:",
  "(12)": "where , and are the balance parameters of regularizers. Inaddition, is used to decay the weights of regularizers graduallyas training progresses so as to control the balance point betweenID classification and OOD detection. is a number between 0 and1, is a small number and is the iteration step. In the experiments,we set and to be 0.9 and 0.01, respectively. By combining thethree regularizers with cross-entropy, OODGAT not only learnsto classify in-distribution nodes, but also to separate inliers fromoutliers in the latent space, as shown in .",
  "Experimental Setup": "Evaluation Metrics. In the setting of graph learning with OODnodes, we aim to accomplish two tasks simultaneously, which are1) node classification and 2) outlier detection. For the first task,we adopt classification accuracy as the evaluation metric. For thesecond task, we calculate two metrics commonly found in the OODdetection literature, namely the area under ROC curve (AUROC)and the false positive rate when the true positive rate achieves95% (FPR@95). Note that in all experiments we view the outliersas positive. To comprehensively evaluate the performance of thetwo tasks, we consider them together as a multi-class classificationproblem with N+1 classes, i.e., N in-distribution classes and oneOOD class. We call this task joint classification, and the performancecan be evaluated by weighted-F11.Datasets. We test OODGAT on six commonly used graph datasets,i.e., Cora, AmazonComputers, AmazonPhoto, CoauthorCS, LastF-MAsia and Wiki-CS . For each dataset, we divide allclasses into in-distribution and out-of-distribution, such that theID part contains classes that are relatively balanced in node size,and the number of ID classes is at least three to avoid too easyclassification2. Similar to traditional SSNC, we randomly select 20nodes per ID class as the training set. Besides, we construct a smallvalidation set which contains 10 nodes from each ID class, andthe same number of outliers randomly sampled from OOD classes.Statistics for the datasets are listed in Appendix C.Methods. We compare the following methods: End-to-end Methods, which accomplish SSOD and SSNCin the same framework. Specifically, we choose MLP, GCN, GraphSAGE , GAT , and GATv2 as the end-to-end baselines. MLP is used to test the performance withoutconsidering graph topology, while the other four are rep-resentative GNN models w/ or w/o graph attention. For allmethods, we use the entropy of the predicted distribution asthe OOD score. Post-hoc OOD Detectors, which require training an addi-tional outlier detector on top of the pretrained classifier. Weemploy ODIN , Mahalanobis-distance , and CaGCN as the post-hoc detectors. ODIN uses temperature scal-ing and input preprocessing to calibrate the output distribu-tion, while Mahalanobis-distance leverages the latent spaceof the pretrained classifier to compute the distance betweentesting samples and known inliers. For each method, we usethe metric described in the original paper for OOD detection,i.e., MSP for and Mahalanobis-distance for . CaGCNis a recently published method for calibrating the outputconfidence of GNNs. Intuitively, we can use the calibratedconfidence as the score for outlier detection.",
  "The details of joint classification are explained in Appendix B.2See our Github for more details regarding the choice of ID and OOD classes": "to detect outliers on graphs. It proposes a multi-source un-certainty framework using various types of predictive un-certainties from both deep learning and belief theory, andshows that vacuity is the best metric for OOD detection. OODGAT, the method proposed in this paper. It has twoversions: OODGAT-ENT which uses the entropy of the pre-dicted distribution as the measure of outliers and OODGAT-ATT which uses the score given by the binary classifierinstead. Implementation Details. For all graphs, we perform 3 randomsplits to obtain training, validation, and test sets. For each split,we initialize the model with 3 random seeds.3 As a result, eachexperiment was performed 9 times. Unless specially mentioned,we tune the hyperparameters using grid search and select the bestperforming results according to the validation set. Specifically, wechoose the learning rate from [0.01, 0.1], the dropout probabilityfrom [0, 0.5]. For models with multi-head attentions, the numberof attention heads is chosen from , and the drop edge prob-ability is set to 0.6. It is known that weight decay is helpful inpreventing models from giving arbitrary high confidence, so wealso choose the weight decay factor from [0, 5e-5, 5e-4, 5e-3]. Weset the maximum iterations of training to be 1000 and performearly-stopping when ( + ) stops to increase for200 epochs. All experiments are done using PyTorch Geometric,and the source code is made publicly available on Github4.",
  "Main Results": "Comparison with End-to-end Methods. We first compare ourmethod with end-to-end approaches. The results are listed in . From the table, we make the following observations:1) On all datasets, GNNs outperform MLP in both SSOD andSSNC by a large margin, suggesting that the graph structure ishelpful for both tasks, as indicated in .2) GraphSAGE surpasses GCN in terms of AUROC on 5 out ofthe 6 datasets, which may be attributed to the strategy of separatingself and neighboring representations during feature propagation.3) Across all baseline models and datasets, GAT and/or GATv2achieve the best performance in outlier detection. The results showthat even the naive attention mechanism helps to distinguish nodesfrom different distributions.4) For SSOD, OODGAT outperforms all baselines on the sixdatasets by a considerable margin. On easy datasets such as Ama-zonPhoto and CoauthorCS, OODGAT achieves an AUROC of over0.98, while for difficult tasks like LastFMAsia and Wiki-CS, OODGATgreatly improves the detection ability and achieves decent perfor-mance, demonstrating the effectiveness of the proposed propaga-tion strategy.5) For SSNC, OODGAT achieves better or comparable resultsthan other approaches. For example, OODGAT outperforms GATand/or GATv2 by 3% and 1% in terms of classification accuracyon AmazonComputers and LastFMAsia. The results show that byremoving the interference brought by OOD data, the classifier ismore likely to converge to points with better generalization ability.",
  "(1) CE82.156.950.7(2) CE+con86.390.078.6(3) CE+ent82.953.548.9(4) CE+dis79.361.246.1(5) CE+con+ent85.992.881.3(6) CE+con+dis87.089.478.7(7) OODGAT86.693.182.2": "6) From the perspective of joint classification, OODGAT consis-tently outperforms all competitors, making it the most powerfulmethod for graph learning with OOD nodes.Comparison with Post-hoc OOD Detectors. We also compareOODGAT with ODIN , Mahalanobis-distance and CaGCN. The comparison is unfair as these methods either requireadditional data preprocessing or involve multiple training stages,while OODGAT accomplishes the mission without introducingadditional complexity. For all experiments except OODGAT, wepretrain a GAT as the base classifier, and employ different post-hoc detectors for OOD detection. Note that unlike the originalpaper, we tune the detectors directly on the test set to eliminate thepossibility of bad hyperparameter configurations. For OODGAT,we do not utilize the test set for training or tuning. reportsthe detection performance of all methods. As we can see, only in afew cases can the post-hoc detectors improve the detection ability(shaded cells). Apart from that, all methods lose their power due tothe characteristics of graph data such as lack of supervision and non-continuous input. By inspecting the last two columns, we find thatdespite being unfair, OODGAT outperforms all post-hoc detectorsby a large margin. The superiority of OODGAT comes from theend-to-end optimization strategy which simultaneously handlesfeature extraction and OOD detection, whereas other methods usea two-stage update framework which trains the classifier and thedetector separately and can only find sub-optimal solutions.Comparison with GKDE. We now compare OODGAT with GKDE. To ensure a fair comparison, we test our method on the samedatasets used in the original paper and adopt the same prepro-cessing procedures. (See Appendix C for details.) We report theAUROC and AUPR for outlier detection in , where the re-sults for GKDE are obtained from the original paper. As we cansee, although OODGAT is much more efficient than GKDE which requires multiple forward passes due to the Bayesian framework,it still outperforms GKDE in both AUROC and AUPR on all threedatasets. The results show that it is not enough to simply embedexisting GNNs into the framework of uncertainty computation.Instead, making better use of the information implicit in the graphstructure is the key to success.",
  "Ablation Study": "The success of OODGAT comes from the combination of the uniquepropagation strategy and the tailored regularizers for guiding thetraining process. In this section, we perform ablation analysis in to demonstrate the importance of each module proposedin .2. Experiments are done on AmazonComputers usingOODGAT-ATT, and the weight for each loss is the same as the best-performing result in . In (1), we train the model with onlycross-entropy loss. The AUROC for outlier detection is around 50%which is similar to random guessing, indicating the use of cross-entropy alone is not sufficient to learn the classification of ID andOOD. We then add one of the proposed regularizers in (2),(3) and (4),respectively. The results show that consistency loss can effectivelyimprove the discriminative ability of the binary classifier, whileentropy loss and discrepancy loss contribute little or negativelywhen used without the help of consistency regularizer. This isexpected since the other two losses rely on the accurate predictionof the binary classifier, which is learned through consistency loss.Comparing (2) and (5), we find that the entropy loss can furtherimprove the detection ability when used together with consistencyloss. Similarly, the comparison between (2) and (6) indicates thatthe addition of discrepancy regularizer can help the classification ofin-distribution samples. The best result is obtained in (7) where wecombine all three regularizers with cross-entropy loss. In summary,all regularizers contribute to the final performance, among which",
  "CONCLUSION": "In this paper, we propose and study the problem of graph learningwith OOD nodes. We demonstrate that GNNs are inherently suitablefor outlier detection on graphs with high homophily, and proposean end-to-end model OODGAT to tackle the problem of SSOD andSSNC. Extensive experiments show that while existing methodssuch as input preprocessing and temperature scaling cannot handlethe problem well, OODGAT consistently yields decent performancein both in-distribution classification and outlier detection. In thefuture, we aim to extend OODGAT to more realistic settings suchas few-shot learning and incremental learning.",
  "Yves Grandvalet, Yoshua Bengio, et al. 2005. Semi-supervised learning by entropyminimization. CAP 367 (2005), 281296": "Lan-Zhe Guo, Zhen-Yu Zhang, Yuan Jiang, Yu-Feng Li, and Zhi-Hua Zhou. 2020.Safe deep semi-supervised learning for unseen-class unlabeled data. In Interna-tional Conference on Machine Learning. PMLR, 38973906. William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representationlearning on large graphs. In Proceedings of the 31st International Conference onNeural Information Processing Systems. 10251035. Matthias Hein, Maksym Andriushchenko, and Julian Bitterwolf. 2019. Whyrelu networks yield high-confidence predictions far away from the training dataand how to mitigate the problem. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition. 4150.",
  "Pter Mernyei and Ctlina Cangea. 2020. Wiki-cs: A wikipedia-based benchmarkfor graph neural networks. arXiv preprint arXiv:2007.02901 (2020)": "Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. 2018. Virtualadversarial training: a regularization method for supervised and semi-supervisedlearning. IEEE transactions on pattern analysis and machine intelligence 41, 8(2018), 19791993. Avital Oliver, Augustus Odena, Colin A Raffel, Ekin Dogus Cubuk, and Ian Good-fellow. 2018. Realistic evaluation of deep semi-supervised learning algorithms.In Advances in Neural Information Processing Systems.",
  "Hongbin Pei, Bingzhe Wei, Kevin Chen-Chuan Chang, Yu Lei, and Bo Yang. 2020.Geom-gcn: Geometric graph convolutional networks. In International Conferenceon Learning Representations": "Jie Ren, Peter J Liu, Emily Fertig, Jasper Snoek, Ryan Poplin, Mark Depristo,Joshua Dillon, and Balaji Lakshminarayanan. 2019. Likelihood Ratios for Out-of-Distribution Detection. In Advances in Neural Information Processing Systems. Benedek Rozemberczki and Rik Sarkar. 2020. Characteristic functions on graphs:Birds of a feather, from statistical descriptors to parametric models. In Proceedingsof the 29th ACM International Conference on Information & Knowledge Manage-ment. 13251334.",
  "Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and StephanGnnemann. 2018. Pitfalls of graph neural network evaluation. arXiv preprintarXiv:1811.05868 (2018)": "Ke Sun, Zhouchen Lin, and Zhanxing Zhu. 2020. Multi-stage self-supervisedlearning for graph convolutional networks on graphs with few labeled nodes. InProceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 58925899. Jihoon Tack, Sangwoo Mo, Jongheon Jeong, and Jinwoo Shin. 2020. Csi: Nov-elty detection via contrastive learning on distributionally shifted instances. InAdvances in neural information processing systems.",
  "BJOINT CLASSIFICATION": "The joint classification includes two stages: first, it classifies nodesto be inliers or outliers according to the OOD scores predicted bythe model; then, it assigns in-distribution labels for nodes taggedas ID using their output distributions. An illustration is shown in. Since the first stage is a binary classification task, thevalue of weighted-F1 is dependent on the threshold chosen. Inthe experiments, we report the best F1 value under all possiblethresholds.",
  "EINFLUENCE OF HYPERPARAMETERS": "The training of OODGAT involves four hyperparameters: , , and . The former three are the balance parameters of regularizers,while the last is the threshold to determine the set of nodes forwhich the model encourages uniform distribution. Due to the spacelimitation, we only present the effect of hyperparameters on Ama-zonComputers, while similar trends are observed on other datasets.From a, we observe that consistency loss is the key to the success of OOD detection. In b, the performance is slightlyimproved when the weight of discrepancy loss reaches around 5e-3.The results in c show that while the addition of entropyregularizer can improve detection, it also leads to a decrease in theperformance of in-distribution classification. However, by choosingan appropriate trade-off parameter, OODGAT can achieve betterdetection capability without having too much impact on the clas-sification, thereby improve the overall performance. The effect ofthe threshold is shown in d. When the threshold is 0,the entropy loss simply forces all nodes to behave like outliersby increasing the uncertainty of predictions, regardless of theirtrue identity. When moving the threshold to an appropriate range,OODGAT manages to reduce the confidence level of outliers onlywhile leaving the in-distribution data unaffected, resulting in thehighest overall performance.",
  "(f) OODGAT": ": Visualization of GCN and OODGAT. Experimentsdone on Cora. (a) and (b): t-SNE plot of the latent space, (c) and(d): distribution of nodes predictive uncertainties, (e) and (f):training dynamics of the mean entropy of inliers and outliers.In (a) and (b), OODGAT shows a clearer boundary between IDand OOD classes. In (c) and (d), OODGAT produces scores withless overlap between ID and OOD. In (e) and (f), OODGATmaintains a larger gap between the entropy of inliers andoutliers throughout the training phase."
}