{
  "ABSTRACT": "Fraud detection presents a challenging task characterized by ever-evolving fraud patterns and scarce labeled data. Existing methodspredominantly rely on graph-based or sequence-based approaches.While graph-based approaches connect users through shared enti-ties to capture structural information, they remain vulnerable tofraudsters who can disrupt or manipulate these connections. Incontrast, sequence-based approaches analyze users behavioral pat-terns, offering robustness against tampering but overlooking theinteractions between similar users. Inspired by cohort analysis inretention and healthcare, this paper introduces VecAug, a novelcohort-augmented learning framework that addresses these chal-lenges by enhancing the representation learning of target userswith personalized cohort information. To this end, we first proposea vector burn-in technique for automatic cohort identification, whichretrieves a task-specific cohort for each target user. Then, to fullyexploit the cohort information, we introduce an attentive cohortaggregation technique for augmenting target user representations.To improve the robustness of such cohort augmentation, we alsopropose a novel label-aware cohort neighbor separation mechanismto distance negative cohort neighbors and calibrate the aggregatedcohort information. By integrating this cohort information with tar-get user representations, VecAug enhances the modeling capacityand generalization capabilities of the model to be augmented. Ourframework is flexible and can be seamlessly integrated with existingfraud detection models. We deploy our framework on e-commerceplatforms and evaluate it on three fraud detection datasets, and re-sults show that VecAug improves the detection performance of basemodels by up to 2.48% in AUC and 22.5% in , outperformingstate-of-the-art methods significantly.",
  "User Modeling, Cohort Analysis, Fraud Detection, Retrieval Aug-mented Detection, Personalized Cohort Augmentation": "ACM Reference Format:Fei Xiao, Shaofeng Cai, Gang Chen, H. V. Jagadish, Beng Chin Ooi, and Mei-hui Zhang. 2024. VecAug: Unveiling Camouflaged Frauds with CohortAugmentation for Enhanced Detection. In Proceedings of the 30th ACMSIGKDD Conference on Knowledge Discovery and Data Mining (KDD 24),August 2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages.",
  "INTRODUCTION": "Fraudulent transactions pose a serious threat to e-commerce plat-forms, as they cause economic losses, damage reputations, andharm user experiences . According to a recent report, fraudcosts 2.9% of global e-commerce revenue in 2023 1. This is especiallyconcerning for the fast-growing Southeast Asian market, which isexpected to have 140 million new consumers by 2030 2. However,detecting fraud in real-world scenarios remains challenging due tothe dynamic nature of fraud patterns and the scarcity of labeleddata .To address the sparse transaction data issue and identify poten-tial fraudsters among new users, numerous fraud detection systemshave been developed, leveraging advanced machine learning algo-rithms and integrating diverse data sources for comprehensive anal-ysis and detection. These systems typically fall into two categories:graph-based approaches and sequence-based methodologies . Graph-based systemsconnect users based on shared identity features, such as devices, IPs,and phones, and use graph neural networks (GNNs) to capture thestructural information. However, certain fraudsters employ sophis-ticated techniques, such as device information manipulation or VPNusage, to evade explicit connections. They also imitate the behaviorsof legitimate users, such as clicking on the same products or pages orusing similar IPs, to camouflage themselves . These fraudstersare hard to identify using graph-based methods and lower the effec-tiveness of GNN-based approaches. In contrast, sequence-based sys-tems analyze users behavioral sequences, which are more resilientto manipulation than individual features . Nonetheless,",
  ": A toy example depicting the behavioral sequencesof three users: User B and User C have similar behavior se-quences, whereas User A has quite different ones": "sequence-based models often overlook cross-user interactions be-tween the target user and similar peers, thus failing to fully exploitthe information from similar users. Therefore, we need tailoredapproaches to connect well-camouflaged fraudsters with similarusers and use their data for more accurate user representations.In this paper, we present VecAug, a novel learning-based co-hort augmentation framework for fraud detection using cohortinformation. Our framework is inspired by cohort analysis, whichis widely used in retention and healthcare applications to studythe relationships and behaviors of users based on their activitypatterns. Unlike traditional cohort analysis methods that groupusers into different cohorts based on a set of traits or a specificevent, our framework constructs implicit user cohorts based on therelevance of their behavioral sequences. In this manner, we canidentify potential fraudsters who exhibit similar fraudulent behav-iors, regardless of their identity features, such as devices, IPs, andphones. For example, illustrates the behavioral sequencesof three users, where User B and User C both search for the sameproducts, make quick payments, and leave positive reviews. Theycan be regarded as personalized cohort neighbors of each otherand their information can be shared to enhance the homophily forfraud prediction. In contrast, User A performs product searches andcomparisons before buying, behaving more like a normal user andshould not be included in their cohort neighbors.As illustrated in , VecAug has four phases: the vectorburn-in phase, the cohort identification phase, the cohort-augmentedtraining phase, and the prediction phase. In the vector burn-in phase,we use a novel technique to generate task-specific cohort vectorsfor all training samples and store them in a vector database Ealong with their fraud labels. This technique separates the opti-mization of embedding vectors from their use in the later cohortaugmentation, which improves the training efficiency and effective-ness. In the cohort identification phase, we select augmentationneighbors and negative neighbors for each target user from thevector pool, based on their similarity and label discrepancy. Theaugmentation neighbors are used to enrich the representation ofthe target user, while the negative neighbors are used to create acontrastive learning objective. In the cohort-augmented trainingphase, VecAug performs attentive neighbor aggregation to combinethe cohort information from the augmentation neighbors, and label-aware neighbor separation to push away the representations of thenegative neighbors. By doing so, VecAug learns a more robust and discriminative model for fraud detection. In the prediction phase,VecAug can rapidly retrieve the augmentation neighbors from thevector pool and use them to improve the prediction of the targetuser. In summary, we make the following contributions: We introduce VecAug, a pioneering cohort augmentation frame-work that improves the prediction performance of existing frauddetection methods by incorporating rich cohort neighborhoodinformation and task-specific embedding vectors.",
  "We propose a novel label-aware neighbor separation techniquethat reduces noise from neighbors of opposite classes and im-proves cohort-augmented learning robustness": "We test VecAug on the state-of-the-art deep learning models infraud detection and observe substantial performance improve-ment. VecAug enhances base models by up to 2.48% in AUC and22.5% in , with negligible computational overhead. We organize this paper as follows. introduces the frauddetection tasks and the cohort augmentation concept. explains VecAugs technical aspects and shows how personalizedcohorts help detect camouflaged fraudsters. presents ex-perimental results of integrating VecAug with four base models todemonstrate its effectiveness. discusses the related workon fraud detection, and section 6 concludes this paper.",
  "Fraud Detection": "Fraud Detection on Behavioral Data. For a target user U,a common fraud behavior detection system takes the users behav-ioral sequence as input: xi = {0,1, ,1}, where S rep-resents users action and is the length of the sequence. The frauddetection task over behavioral data aims to detect whether users en-gage in suspicious activities given their behavioral sequences. Eachuser is characterized by a corresponding behavioral sequence xiand a ground-truth label . Identifying fake reviews is a specificinstance of fraud behavior detection, where actions correspond topurchases of different products.",
  "Cohort Augmentation for Fraud Detection": "In the cohort augmentation framework VecAug, we retrieve a per-sonalized cohort for each user, aiming to exploit the implicit rela-tionships between target users and their hidden connections. Specif-ically, the personalized cohort comprises augmentation neighbors,which are utilized to enhance target user representations, and negative neighbors, which contribute to the creation of an effectivecontrastive loss for distinguishing neighbors with different labelsfrom the target user.",
  "Main Encoder": "4. Prediction Training User & Testing User : The proposed learning-based cohort augmentationframework VecAug. VecAug seamlessly integrates with anyexisting fraud detection models to uncover hidden connec-tions between users and utilize cohort information for en-hanced fraud detection. {1,2, ,} and the corresponding label y, the objective of co-hort augmentation is to pinpoint similar fraudulent users controlledby the same entity as the target fraud users, and to identify addi-tional normal users who resemble the target normal user, leverag-ing their information to enhance the predictive performance of themodel. We can formulate learning-based cohort augmentation as: y = ((x; W); e; E ; W ),(1)where () is the augmented learning function parameterized byW ; () is the representation learning function of the base modelwith parameters W; e and E are the vector of the target user andthe set of task-specific cohort augmentation neighbors in the vectorburn-in space respectively, derived by a separately trained vectorburn-in model;y represents the cohort-augmented prediction logit.The main motivation for introducing the personalized learning-based cohorts is to leverage the supplementary information ofsimilar samples E for enhancing the representation power androbustness of the representation learning function (). Definition 2. Augmentation Neighbors. The augmentationneighbors, denoted as N(, ), are training samples thathave similar fraud behaviors to the target sample , as measuredby the distance between their burn-in vectors. The augmentationneighbors can have the same or different labels as (fraudulentor non-fraudulent). The augmentation neighbors help to improvethe representation learning of the target sample by providing co-hort information. The set of burn-in vectors of the augmentationneighbors is denoted as E . Definition 3. Negative Neighbors. The negative neighbors, de-noted as N(, ), are training samples that have oppositelabels from the target sample but have similar fraud behaviors,based on the distance between their burn-in vectors. The nega-tive neighbors are used to improve the robustness and stability ofcohort-augmented learning by minimizing the mutual information",
  "Overall Framework": "The illustration of VecAug for enhanced fraud detection tasks in Fig-ure 2 presents the four main modules operating in distinct phases:the vector burn-in phase, the cohort identification phase, the aug-mented training phase, and the prediction phase. First, the vectorburn-in module will generate fraud-specific vectors e via an auxil-iary encoder () and store the resultant embedding vectors ofall training samples in the vector database E. For each user ,VecAug identifies its augmentation neighbor vectors E and negative neighbor vectors E from E. These vectors capture therelationship between users based on their fraud behaviors. Next, inthe augmented training phase as shown in , VecAug aggre-gates the information of E to augment the latent representation hof x obtained via the main encoder (). To address camouflagedfrauds, VecAug applies a label-aware neighbor separation mech-anism to push away the negative neighbors in the augmentedrepresentation space, which reduces the influence of fraudsterswho imitate normal users and improves detection accuracy. Finally,in the prediction phase, only the augmentation neighbor vectorsE will be retrieved to augment the target user representation hfor the final prediction. For clarity, the outputs of the auxiliaryencoder and the main encoder are called vector and representation,respectively.",
  "Vector Burn-in Phase": "To generate embedding vectors that can identify cohorts of fraud-sters, we propose a novel vector burn-in technique that capturesthe fraud behaviors within each sample. Specifically, we train anauxiliary encoder () and an output layer using back-propagation in a supervised manner to obtain embedding vectors,i.e., e = (x). These vectors encode fraud-related informationthat is useful for subsequent cohort-augmented learning. The aux-iliary encoder can leverage existing fraud detection models, suchas those proposed in or traditional sequence learningmethods in , to obtain the fraud-specific embedding of sam-ples and use a multilayer perceptron (MLP) as the output layer togenerate prediction logits: y = (e), : R R(2)where is the dimension of the embedding vectors. Binary crossentropy (BCE) is typically adopted as the objective function forthe fraud detection task and is optimized via gradient descent. Inthis way, task-specific embedding vectors can be generated, andthe corresponding latent embedding space is called vector burn-inspace, which will not be optimized in the augmented training phase.The novel vector burn-in technique effectively decouples cohortidentification from the base model training process, eliminatingearly training noise, and ensuring more accurate cohort neighbors.",
  "Cohort Identification Phase": "The embedding vectors of training samples, denoted as e, alongwith their corresponding labels y, are stored in a vector data-base E. To identify the cohorts specific to fraudulent activities,the target sample is fed into (), generating a vector query tosearch for augmentation neighbors in E. During this phase,the Euclidean distance metric is employed for retrieving the co-hort neighbors. However, cohort augmentation for fraud detectionfaces a key challenge: the potential degradation of prediction per-formance. This can occur when incorporating information fromwell-camouflaged fraudsters with that of normal users, or when ex-cessively integrating normal user behavior information to enhancethe representation learning of fraudsters. To mitigate this challenge,we adopt a strategy that involves retrieving both augmentationneighbors and negative neighbors for each target user duringtraining. This strategy enables the model to discern the behavior disparities between well-camouflaged fraudsters and normal users.We construct a tailored contrastive loss to achieve this goal, whichis illustrated in and explained in .6. Here, Eand E represent the augmentation neighbor vectors and negativeneighbor vectors, respectively. It is worth noting that during infer-ence for augmented learning, only the augmentation neighbors Eare retrieved, as the labels of testing samples are not available toidentify the negative neighbors E .",
  "Cohort-Augmented Training Phase": "To harness the potential of neighboring vector information andeffectively augment the target sample modeling, we perform an at-tentive neighbor aggregation for the augmentation neighbors andpropose a label-aware neighbor separation mechanism to distancethe negative neighbors. We first transform the augmentationneighbor vectors and the negative neighbor vectors to the aug-mented representation space, which is the new representation spacederived from the main encoder ():",
  "=1, h,(4)": "where h, is the representation of the -th augmentation neighborin the augmented representation space, and h is the new represen-tation of the target sample x obtained via the main encoder (),i.e., h = (x). W R is the bilinear attention weightmatrix, and , corresponds to the attention weight for h,. hand h will then be fused to generate the cohort-augmented logitsin the final prediction module.The incorporation of neighboring vector information can sub-stantially enhance the models learning capacity, but it may alsocompromise its disambiguation capability. As illustrated in , the neighboring samples for may encompass samples from op-posite classes. To mitigate the adverse effects of noisy informationfrom the augmentation neighbors, we build a contrastive objectiveto separate the negative neighbors in the augmented representationspace. Specifically, we adopt the same transformation layer to ob-tain representations H for the negative neighbors. Subsequently,we perform a pairwise summation of the target user representa-tion and the negative neighbors representations. These negative-neighbor-augmented user representations are then fed into themain output layer to generate negative-neighbor-augmented log-its for supervised contrastive learning. The construction of thesupervised contrastive loss will be elaborated in .6.",
  "VecAug: Unveiling Camouflaged Frauds with Cohort Augmentation for Enhanced DetectionKDD 24, August 2529, 2024, Barcelona, Spain": "y = (h + h ), : R R(5)We fuse the two representations via a summation, which empiricallyis more efficient and stable than concatenation. The output layer will capture the task-specific information from the targetsample and augmentation neighbors. Meanwhile, we can obtainthe negative-neighbor-augmented logits Y R by feedingthe sum of target user representation and the negative neighborsrepresentations into the main output layer.",
  "Ty((y )) + (1 y)(1 (y ))(6)": "where y and y are the ground truth label and cohort-augmentedprediction logit respectively. is the number of training samples,and () is the sigmoid function. With this objective function, Ve-cAug can be trained effectively via gradient-based optimizers. Task #2: Supervised Contrastive Learning. We introduce a label-aware neighbor separation mechanism to counter the negative effectof noisy information from augmentation neighbors. For this objec-tive function, any negative-neighbor-augmented logit y, in Yshould incur greater losses than y , considering the ground truthy of the target sample. Drawing inspiration from prior works ,we construct the contrastive loss on the prediction logits ratherthan the cohort-augmented representations, as presented below:",
  ") + =1 exp(d(y,y, )": ")(7)where d(y,y ) represents the distance of the ground-truth logitsand cohort-augmented logits, and is the temperature hyperpa-rameter. With low temperatures, the loss is dominated by closercohort-augmented logits. This method enables supervised con-trastive learning and prevents the cohort augmented representationfrom diverging too much from the original burn-in vector. In thismanner, the personalized cohort from the burn-in phase remainsuseful in the augmentation phase. Task #3: Latent Space Alignment. Since cohort identificationdepends on vector distances between the target sample and can-didates, it may deviate slightly from distances in the augmentedrepresentation space, potentially reducing the relevance of neighborinformation to the current prediction task. To rectify this inconsis-tency, we introduce auxiliary vector regularization for consistentdistances in both vector burn-in and cohort-augmented learningphases:",
  "L = L + L + L + 2(9)": "where and are the hyperparameters that control the weights ofthe contrastive loss and auxiliary reconstruction loss respectively, is the set of all model parameters, and is the weight regularizationstrength. Prediction Phase. In the final prediction phase, VecAug first ob-tains the burn-in vector of the target sample e as a query to retrievethe augmentation neighbors. Next, the augmentation neighbor vec-tors E are transformed into the augmented representation spaceH and fused with the new representations h of the target sample.Finally, the augmented representation is fed into the output layerto predict the fraud probability.",
  "EXPERIMENTS": "In our study, we integrate four established fraud detection mod-els with VecAug to assess the effect of the proposed label-awarecohort augmentation on detecting hidden fraudsters. Particularly,our experiments are devised to answer the key research questions(RQs) as follows: RQ1: Can VecAug improve the existing sequence-based frauddetection models performance without harming the legitimateusers activities?",
  "Experimental Setup": "4.1.1Datasets. We mainly use two private and one public datasetsto evaluate our proposed method. The private datasets are obtainedfrom Shopee 3, the largest online e-commerce platform in SoutheastAsia. Each user is assigned a risk score by a fraud detection modelbased on their daily activities or purchasing history. The publicdataset is the Amazon 4 dataset , which is widely usedfor fake review detection. Fake review detection is a specific caseof fraudulent behavior detection, where each action is a productreview. We compare the performance of the base models with andwithout VecAug on the three datasets to demonstrate its effective-ness. Shopee Dataset. The large-scale industrial datasets collected fromShopee adhere strictly to security and privacy protocols. Thesedatasets consist of historical activity logs originating from the samegeographical regions, albeit varying in size, designated as Shopee-large and Shopee-small, spanning a specified timeframe. provides an overview of the dataset statistics. For fraud behaviordetection, each user is represented by 300 records, each containing",
  "Amazon18k71982013.3M36.86%": "details such as actions taken, timestamps, and associated attributes.These actions encompass a spectrum of user interactions within theShopee platform, including \"visit-homepage\", \"refund-request\", and\"password-reset-request\". The fraud rate in the table is our sampledfraud rate for the experiments, not the actual fraud rate on Shopee.We also collected a user-device interaction graph from Shopee,comprising 100k users and 54k devices. This graph dataset servesto validate the effectiveness of VecAug in uncovering fraud camou-flage. We employ two graph neural networks for fraud detection onthis dataset. Subsequently, we integrate these GNNs with VecAug toobserve performance improvements. To simulate fraudsters camou-flage strategies, we sub-sample the Shopee graph by removing 3758edges between certain fraudulent accounts and devices. Finally, wecompare the performance of the two GNNs and their integrationwith VecAug on this sub-sampled Shopee graph. Amazon Dataset. The Amazon dataset comprises diverse prod-uct reviews from categories such as electronics, books, CDs, andmovies5. Extensive use case analyses conducted in previous studies have revealed patterns of fraudulent activities, includingrepeated purchases of identical items and the rapid submissionof reviews. Utilizing the filtering algorithms in , users arelabeled based on their helpful vote percentages, with those below20% as fake users and those above 80% as normal users. 4.1.2Baseline Methods. We integrate VecAug with four sequence-based fraud detection models and compare its performance to twoexisting neighbor augmented learning methods. Additionally, weutilize two graph neural networks to validate the effectivenessof VecAug in uncovering camouflaged fraud. Ablation tests arealso conducted to show the efficacy of the techniques proposed inVecAug. Sequence-based fraud detection base models. (1) BiLSTM applies bidirectional LSTM to capture the dependency informationamong sequential data for fraud detection. (2) LIC Tree-LSTM builds a behavior tree for the users behavioral sequence and stud-ies fraud transaction detection with local intention calibration. (3)HEN uses field-level extractor and action-level extractor to hi-erarchically learn users intentions and identify high-risk behaviorsequences. (4) MINT employs a time-aware behavior graph tomodel users behavioral data and utilizes a multi-view graph neuralnetwork to detect fraudulent behaviors. Graph-based fraud detection base models. (1) GraphSAGE performs inductive learning on graphs by sampling and aggregatingnode representations. (2) GeniePath integrates LSTMs intoGCN layers to adaptively aggregate neighborhood information.",
  "Amazon0.01 0.00001 0.01 0.00001 0.01 0.00001 0.001 0.00001": "Existing neighbor augmentation methods. (1) GRASP di-vides samples into different clusters and uses the cluster representa-tions to enrich sample representations. (2) CSRM dynamicallyretrieves different neighbors information during model trainingfor augmented learning. Ablations. VecAug is a variant of VecAug that adopts a vanillacohort augmentation architecture with a vector burn-in mechanism.VecAug is a variant of VecAug that only introduces the label-aware neighbor separation mechanism. 4.1.3Implementation Details. In our implementation, we utilizePyTorch for all models and Milvus to store embedding vectors.For the datasets, the split ratio of the training/validation/testing setis 60%/20%/20%. We employ the Adam optimizer and initialize modelparameters with Xavier initialization. Early stopping is applied ifthe validation performance does not improve for 20 epochs. Thesettings of the fraud detection task follow the practice in .The embedding dimension of users behavioral action is set to 64,the batch size to 128, the learning rate to 0.0001, and the maximumbehavioral sequence length to 300. The regularization strength isset to 1-5. The number of nearest neighbors is also set to fivefor all models and datasets.We used grid search to optimize three key hyperparameters forVecAug with different base models: the contrastive loss weight ,the auxiliary reconstruction loss weight , and the temperature .These hyperparameters control the importance of the contrastiveobjective, the balance between cohort-augmented learning andlatent space alignment, and the focus on close or far-away cohortneighbors, respectively. We search in (0.00001, 0.0001, 0.001, 0.01,0.1, 1.0), in (0.0000001, 0.000001, 0.00001, 0.0001, 0.001), and in(0.1, 0.3, 1.0, 3.0, 10.0). These ranges were chosen to cover a widespectrum of possible values for different fraud detection models.We found that = 1 was the best value for all models. showsthe values of and selected for VecAug with various base modelsand datasets. 4.1.4Evaluation Metrics. For fraud detection tasks, we evaluate allmethods with two widely used metrics: AUC (Area Under ROC) andR@P. AUC signifies the probability that positive cases predictionsare ranked ahead of negative cases. R@P represents the recallrate when precision equals . In our fraud detection scenario, thegoal is to identify as many suspicious entities as possible whilenot disrupting the regular operations of benign entities. We set to 0.9 for all experiments. A superior cohort-augmented learningframework is expected to achieve higher AUC values than base",
  "Effectiveness of Cohort Augmentation(RQ1)": "shows the fraud detection performance of four state-of-the-art baselines with and without VecAug. VecAug improves both theAUC and of the base models significantly. On the Shopeedatasets, the AUC increases by at least 0.89% and by morethan 4.31%. On the Amazon dataset, the AUC rises by at least 1.22%and by 5.81%. Notably, the substantial enhancement indicates that VecAug aids in identifying more fraudsterswho escape the detection of base models. These fraudsters mimicthe behavior of normal users to avoid being caught. VecAug usesthe task-specific embedding vectors of the base models to createpersonalized implicit user cohorts, linking camouflaged fraudstersimplicitly to other users who are controlled by the same individualsor groups. Unlike conventional GNN-based approaches vulnerableto intentionally masked identity features of fraudsters, our cohortidentification methods rely on learned user behavioral representa-tions to detect the camouflaged fraudsters effectively. For example,in Shopee, users with similar behavioral sequences may have simi-lar user representations learned by base models. However, the basemodels cannot adequately separate fraud from normal users dueto the presence of many camouflaged fraudsters. VecAug connectscamouflaged fraudsters to labeled fraud users and separates themfrom similar normal users using a label-aware neighbor separationmechanism, which enables better discrimination between suspi-cious and normal behaviors.",
  "We conduct ablation studies on VecAug to demonstrate the impactof vector burn-in cohort augmentation and label-aware neighborseparation on its performance": "4.3.1Vector Burn-in for Cohort Augmentation. demon-strates that the vector burn-in technique alone substantially im-proves base model performance. This indicates that the learning-based cohort approach is effective for fraud detection. By construct-ing event-based networks for each user, we can leverage the sim-ilarities among users to infer their labels. Moreover, we can linkunseen suspicious activities to existing samples, and obtain morerelevant information for prediction. Fraud detection is a binary task,but fraud behavioral patterns are diverse and complex. The userbehavioral representations learned from any base models will notform two clear clusters. Instead, they will form many clusters ofvarying sizes, especially for user accounts operated by the sameperson or group. Normal users representations are usually moredistinct from each other. Therefore, if we construct a personalizedcohort for each user, it will mainly affect fraud users and maketheir clusters more compact. Fraud users not affiliated with anycluster are connected to other fraud users who are similar to them.This has minimal impact on normal users, who are less likely tobe operated by a common entity, and whose cohort-augmentedrepresentation will not change much. As a result, we can detectmore fraudulent users without compromising the performance ofnormal users. 4.3.2Label-aware Neighbor Separation Mechanism. demon-strates a significant enhancement in both AUC and met-rics across both datasets upon integrating MINT with VecAug.While cohort augmentation fosters connections between variousfraudsters and enhances learned representations, it may inadver-tently link adept fraudsters with normal users exhibiting similarbehavioral patterns. This scenario introduces considerable noisethrough direct message passing between fraudulent and normalusers, thereby notably compromising model performance. To mit-igate this issue, the label-aware neighbor separation mechanismdeliberately distances these challenging negative neighbors duringcohort augmentation via a supervised contrastive loss. Given theoriginal base models inability to discern target users from theirdifficult negative counterparts, the contrastive objective functionserves to recalibrate the learning bias, prioritizing the treatment",
  "Comparison with Existing NeighborAugmentation Methods (RQ3)": "In this subsection, we compare the effectiveness of VecAug withtwo existing methods that use neighborhood information to en-hance target users: GRASP and CSRM . illustratesthe performance comparisons. GRASP clusters the samples intogroups based on the task-specific vectors using K-Means, and usesthe centroid vectors as group representations. It constructs a KNNgraph for different groups, with each user aggregating informa-tion from its group and other connected groups. However, GRASPfunctions as a three-layer graph neural network and passes exces-sive information from the neighbors to the target users, leadingto severe over-smoothing. Moreover, GRASP compromises userspersonalized behavioral patterns and performs worse than the basemodel on both datasets. CSRM dynamically retrieves the nearestneighbors for each user, demonstrating more effective neighboraugmentation than GRASP. However, CSRM encounters challengesin accurately utilizing the neighbors information in the early stagesof training, which can lead to erroneous results. It also fails to iden-tify the most useful augmentation neighbors for the target user. OurVecAug solves these problems by introducing a new vector burn-intechnique for more precise cohort identification and a label-awarecontrastive neighbor separation mechanism for mitigating the neg-ative effect of noisy information. From , we can see thatVecAug outperforms and is more consistent than both the previousneighbors-augmented learning methods in fraud detection.",
  "Influence of Cohort Size (RQ4)": "In this section, we investigate the impact of cohort size variationon the effectiveness of VecAug. The results obtained from twofraud detection models on the Shopee-small dataset are illustratedin . It is evident that the performance of the proposedlabel-aware cohort-augmented learning framework remains highlyrobust across varying cohort sizes once the cohort size exceeds a Cohort Size K 0.00% 0.50% 1.00% 1.50% 2.00% HEN w/ VecAug Cohort Size K 0.00% 0.50% 1.00% 1.50% 2.00% MINT w/ VecAug",
  ": Performance improvements of HEN and MINT onShopee-small after integration with VecAug, depicted in AUCacross various cohort sizes": "certain threshold. Specifically, AUC values demonstrate an increas-ing trend with cohort size, plateauing when reaches four. With asmaller cohort, meaningful information is aggregated from trainingsamples to enrich the representation of the target sample. However,as the cohort size increases, both valuable and noisy informationis introduced to the target users, resulting in performance gainsthat saturate at =4. Initially, most information learned from aug-mentation neighbors closely aligns with the target users, therebyenhancing their representation. Yet, with an increased cohort size,the likelihood of encountering augmentation neighbors with op-posite labels to the target users rises, potentially compromisingthe effectiveness of newly augmented neighbors. However, the im-plementation of a label-aware neighbor separation scheme helpsmitigate the adverse effects of noisy information introduced bythe negative neighbors. When the impacts of negative neighborsand the label-aware neighbor separation scheme are comparable,the performance of VecAug remains relatively stable across vary-ing cohort sizes. In summary, our proposed VecAug effectivelyenhances the learning capacity of base models and exhibits robustperformance, irrespective of cohort size variations.",
  "Studies of Unveiling Camouflaged Fraud(RQ5)": "To validate the VecAugs effectiveness in unveiling the camouflageof frauds, we simulate fraudsters camouflage strategies by selec-tively removing 3758 edges between certain fraudulent accountsand devices in the Shopee-graph dataset. We then compare the per-formance of GraphSAGE and GeniePath with and without VecAugintegration on both the original Shopee-graph and the sub-sampledShopee-graph datasets. The comparison results in revealthat both GraphSAGE and GeniePath experience severe degrada-tion when fraudster-device connections are deliberately removed.However, the integration of VecAug significantly enhances theeffectiveness of GraphSAGE and GeniePath on the sub-sampledShopee-graph. Specifically, VecAug enables GraphSAGE to recover86.3% (3242/3758) and GeniePath to recover 82.9% (3115/3758) ofthe deliberately removed connections. This leads to im-provements of 47.61% and 40.02%, highlighting VecAugs strengthin identifying more fraudulent users and thus unveiling the cam-ouflaged fraud. Furthermore, the comparison between the baseGNN models and their integration with VecAug demonstrates that",
  "Efficiency of VecAug with Integrating VectorDatabase": "We assess the training and inference efficiency of VecAug withand without Milvus in this subsection, integrating with MINTon the Shopee-large dataset. We performed experiments over 20epochs for both cases and measured the throughput (number oftraining/inference tuples processed per second) for both CPU andGPU. To ensure fair comparisons, we maintained a consistent batchsize of 512 across all experiments to maximize the GPU computa-tional capacity. For Milvus, we employed HNSW as the index forvector search, known for its high accuracy and efficient indexingcapabilities. In contrast, for the scenario without a vector data-base, we utilized PyTorchs built-in functions for cohort neighborsearches. The throughput comparison results, as depicted in Fig-ure 8, demonstrate that VecAug exhibits significantly improvedefficiencies when integrated with a vector database compared toVecAug operating without one. Specifically, the solution of VecAugwith Milvus achieves significantly higher training and inferenceefficiency, with speedups of up to 21.3x and 26.6x of CPU and GPUrespectively, and incurs no extra infra investment. Our experimen-tal results highlight VecAugs seamless integration with existingfraud detection methods and its effective combination with vectordatabases, providing a more efficient approach to fraud detection.",
  "RELATED WORK": "Fraud detection tasks analyze users behavioral data and transac-tion history to identify fraudulent activities, such as fake reviews,brushing, fraud payments, etc. Existing fraud detection systems fallinto two categories: graph-based and sequence-based. Graph-basedmethods use predefined featureslike devices, IPs, and purchase patterns to connect users, but thesefeatures may not reflect behavioral similarity and are easy to ma-nipulate by fraudsters . In contrast, sequence-based methodsuse recurrent neural networks (RNNs) orattention-based mechanisms to capture temporaland sequential behavior patterns, which are more robust againstmanipulation. For example, some studies utilize behavior trees",
  ": Throughput comparison of VecAug with and with-out vector database (with index HNSW)": "or Tree-LSTM to extract user intentions from sequences,while others propose hierarchical explainable networks to pre-dict payment risks using critical historical behavioral sequences.More recent works design a general user behavior modelingframework to pre-train users behavior data and learn the robustrepresentation for fraud detection. However, sequence-based meth-ods often neglect user interactions, which are crucial for detectingover-consistent behavior patterns in real-world fraud scenarios.To address this, we propose a learning-based cohort augmenta-tion method, which constructs personalized cohorts for each userbased on the relevance of their behavioral sequences. In this man-ner, we can capture the subtle and dynamic patterns of fraudulentbehaviors, and enhance the representation of each user.",
  "CONCLUSIONS": "This paper introduces VecAug, a label-aware cohort-augmentedlearning framework designed to enhance the fraud detection modelscapability in revealing camouflaged frauds. Unlike conventionalneighbor augmentation approaches, VecAug seamlessly integrateswith existing models, offering a versatile solution to enrich userrepresentations. VecAug incorporates a task-specific vector burn-in technique, enabling it to select augmentation neighbors andnegative neighbors automatically for each training user. To refinethe aggregated cohort information, VecAug employs a label-awareneighbor separation mechanism, effectively distancing the nega-tive neighbor representations in the augmented space. It addressesthe limitations of conventional fraud detection methods by usinglearned behavior similarity instead of identity features to buildconnections between users, effectively handling noise and outliers,and explicitly considering label information during augmentation.Comprehensive experiments and evaluations have demonstratedVecAugs effectiveness and advantages in real-world fraud detectiontasks. In summary, VecAug provides a robust approach to enhancethe distinguishing ability of existing fraud detection models, pro-viding a promising strategy for detecting camouflaged fraudsters. This research is supported by Shopee Singapore Private Limited, theSingapore Economic Development Board, and the Singapore Min-istry of Education Academic Research Fund Tier 3 under MOEs of-ficial grant number MOE2017-T3-1-007. The work of Meihui Zhangis supported by the National Natural Science Foundation of China(62072033).",
  "KDD 24, August 2529, 2024, Barcelona, SpainFei Xiao, Shaofeng Cai, Gang Chen, H. V. Jagadish, Beng Chin Ooi, and Meihui Zhang": "Yikun Ban, Xin Liu, Yitao Duan, Xue Liu, and Wei Xu. 2019. No place to hide:Catching fraudulent entities in tensors. The Web Conference 2019 - Proceedings ofthe World Wide Web Conference, WWW 2019 2 (2019), 8393. arXiv:1810.06230 Alex Beutel, Wanhong Xu, Venkatesan Guruswami, Christopher Palow, andChristos Faloutsos. 2013. CopyCatch: Stopping group attacks by spotting lockstepbehavior in social networks. WWW 2013 - Proceedings of the 22nd InternationalConference on World Wide Web (2013), 119129. Bernardo Branco, Pedro Abreu, Ana Sofia Gomes, Mariana S.C. Almeida,Joo Tiago Ascenso, and Pedro Bizarro. 2020. Interleaved Sequence RNNsfor Fraud Detection. Proceedings of the ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining (2020), 31013109. arXiv:2002.05988 Dawei Cheng, Sheng Xiang, Chencheng Shang, Yiyi Zhang, Fangzhou Yang, andLiqing Zhang. 2020. Spatio-Temporal Attention-Based Neural Network for CreditCard Fraud Detection. Proceedings of the AAAI Conference on Artificial Intelligence34, 01 (2020), 362369. Yingtong Dou, Zhiwei Liu, Li Sun, Yutong Deng, Hao Peng, and Philip S. Yu.2020. Enhancing Graph Neural Network-based Fraud Detectors against Camou-flaged Fraudsters. International Conference on Information and Knowledge Man-agement, Proceedings (2020), 315324. Yingtong Dou, Guixiang Ma, Philip S. Yu, and Sihong Xie. 2020. Robust SpammerDetection by Nash Reinforcement Learning. Proceedings of the ACM SIGKDDInternational Conference on Knowledge Discovery and Data Mining (2020), 924933. arXiv:2006.06069 Qingyu Guo, Pengrui Hui, Jiaming Huang, Zhao Li, Long Zhang, Bo An, andMengchen Zhao. 2019.Securing the deep fraud detector in large-scale e-commerce platform via adversarial machine learning approach. The Web Con-ference 2019 - Proceedings of the World Wide Web Conference, WWW 2019 (2019),616626. William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representationlearning on large graphs. In Advances in Neural Information Processing Systems,Vol. 2017-Decem. 10251035. arXiv:1706.02216 Mengda Huang, Yang Liu, Xiang Ao, Kuan Li, Jianfeng Chi, Jinghua Feng, HaoYang, and Qing He. 2022. AUC-oriented Graph Neural Network for Fraud Detec-tion. WWW 2022 - Proceedings of the ACM Web Conference 2022 (2022), 13111321. Meng Jiang, Alex Beutel, Peng Cui, Bryan Hooi, Shiqiang Yang, and ChristosFaloutsos. 2016. Spotting Suspicious Behaviors in Multimodal Data: A GeneralMetric and Algorithms. IEEE Transactions on Knowledge and Data Engineering28, 8 (2016), 21872200. Xurui Li, Wei Yu, Tianyu Luwang, Jianbin Zheng, Xuetao Qiu, Jintao Zhao, LeiXia, and Yujiao Li. 2018. Transaction Fraud Detection Using GRU-centeredSandwich-structured Model. Proceedings of the 2018 IEEE 22nd InternationalConference on Computer Supported Cooperative Work in Design, CSCWD 2018(2018), 761766. arXiv:1711.01434 Wangli Lin, Li Sun, Qiwei Zhong, Can Liu, Jinghua Feng, Xiang Ao, and Hao Yang.2021. Online Credit Payment Fraud Detection via Structure-Aware HierarchicalRecurrent Neural Network. In Proceedings of the Thirtieth International JointConference on Artificial Intelligence. International Joint Conferences on ArtificialIntelligence Organization, 36703676. Can Liu, Li Sun, Xiang Ao, Jinghua Feng, Qing He, and Hao Yang. 2021. Intention-aware Heterogeneous Graph Attention Networks for Fraud Transactions De-tection. Proceedings of the ACM SIGKDD International Conference on KnowledgeDiscovery and Data Mining (2021), 32803288. Can Liu, Qiwei Zhong, Xiang Ao, Li Sun, Wangli Lin, Jinghua Feng, Qing He, andJiayu Tang. 2020. Fraud Transactions Detection via Behavior Tree with LocalIntention Calibration. Proceedings of the ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining (2020), 30353043. Yang Liu, Xiang Ao, Zidi Qin, Jianfeng Chi, Jinghua Feng, Hao Yang, and QingHe. 2021. Pick and Choose: A GNN-based Imbalanced Learning Approach forFraud Detection. The Web Conference (WWW) (2021), 31683177. Ziqi Liu, Chaochao Chen, Longfei Li, Jun Zhou, Xiaolong Li, Le Song, and YuanQi. 2019. GeniePath: Graph Neural Networks with Adaptive Receptive Paths.Proceedings of the AAAI Conference on Artificial Intelligence 33, 0 (2019), 44244431. arXiv:1802.00910 Ziqi Liu, Jun Zhou, Chaochao Chen, Xiaolong Li, Xinxing Yang, and Le Song.2018. Heterogeneous graph neural networks for malicious account detection.International Conference on Information and Knowledge Management, Proceedings1 (2018), 20772086. arXiv:2002.12307",
  "Mike Schuster and Kuldip K. Paliwal. 1997.Bidirectional recurrent neuralnetworks.IEEE Transactions on Signal Processing 45, 11 (1997), 26732681": "Fengzhao Shi, Yanan Cao, Yanmin Shang, Yuchen Zhou, Chuan Zhou, and JiaWu. 2022. H2-FDetector: A GNN-based Fraud Detector with Homophilic andHeterophilic Connections. WWW 2022 - Proceedings of the ACM Web Conference2022 (2022), 14861494. Petar Velikovi, Arantxa Casanova, Pietro Li, Guillem Cucurull, AdrianaRomero, and Yoshua Bengio. 2018. Graph attention networks. 6th InternationalConference on Learning Representations, ICLR 2018 - Conference Track Proceedings(2018), 112. arXiv:1710.10903 Daixin Wang, Yuan Qi, Jianbin Lin, Peng Cui, Quanhui Jia, Zhen Wang, YanmingFang, Quan Yu, Jun Zhou, and Shuang Yang. 2019. A semi-supervised graphattentive network for financial fraud detection. Proceedings - IEEE InternationalConference on Data Mining, ICDM 2019-Novem, 1 (2019), 598607. arXiv:2003.01171 Haishuai Wang, Zhao Li, Peng Zhang, Jiaming Huang, Pengrui Hui, Jian Liao,Ji Zhang, and Jiajun Bu. 2021. Live-Streaming Fraud Detection: A HeterogeneousGraph Neural Network Approach. Vol. 1. Association for Computing Machinery.36703678 pages. Jianguo Wang, Xiaomeng Yi, Rentong Guo, Hai Jin, Peng Xu, Shengjun Li, Xi-angyu Wang, Xiangzhou Guo, Chengming Li, Xiaohai Xu, Kun Yu, YuxingYuan, Yinghao Zou, Jiquan Long, Yudong Cai, Zhenxiang Li, Zhifeng Zhang,Yihua Mo, Jun Gu, Ruiyi Jiang, Yi Wei, and Charles Xie. 2021.Milvus: APurpose-Built Vector Data Management System.Proceedings of the ACMSIGMOD International Conference on Management of Data (2021), 26142627. Meirui Wang, Zhumin Chen, Pengjie Ren, Jun Ma, Lei Mei, and Maarten De Rijke.2019. A collaborative session-based recommendation approach with parallelmemory modules. SIGIR 2019 - Proceedings of the 42nd International ACM SIGIRConference on Research and Development in Information Retrieval July (2019),345354. Shuhao Wang, Cancheng Liu, Xiang Gao, Hongtao Qu, and Wei Xu. 2017. Session-Based Fraud Detection in Online E-Commerce Transactions Using RecurrentNeural Networks. Lecture Notes in Computer Science (including subseries LectureNotes in Artificial Intelligence and Lecture Notes in Bioinformatics) 10536 LNAI(2017), 241252. Ziming Wang, Qianru Wu, Baolin Zheng, Junjie Wang, Kaiyu Huang, and YanjieShi. 2023. Sequence As Genes: An User Behavior Modeling Framework forFraud Transaction Detection in E-commerce. Proceedings of the ACM SIGKDDInternational Conference on Knowledge Discovery and Data Mining (2023), 51945203. Fei Xiao, Yuncheng Wu, Meihui Zhang, Gang Chen, and Beng Chin Ooi. 2023.MINT: Detecting Fraudulent Behaviors from Time-Series Relational Data. Pro-ceedings of the VLDB Endowment 16, 12 (2023), 36103623. Zhichao Yang, Shufan Wang, Bhanu Pratap Singh Rawat, Avijit Mitra, and HongYu. 2022. Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shotICD Coding. Findings of the Association for Computational Linguistics: EMNLP2022 (2022), 17671781. Jianke Yu, Hanchen Wang, Xiaoyang Wang, Zhao Li, Lu Qin, Wenjie Zhang,Jian Liao, and Ying Zhang. 2023. Group-based Fraud Detection Network one-Commerce Platforms. Proceedings of the ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining 1 (2023), 54635475. Chaohe Zhang, Xin Gao, Liantao Ma, Yasha Wang, Jiangtao Wang, and Wen Tang.2021. GRASP: Generic Framework for Health Status Representation LearningBased on Incorporating Knowledge from Similar Patients. 35th AAAI Conferenceon Artificial Intelligence, AAAI 2021 1 (2021), 715723. Dongyu Zhang, Liang Wang, Xin Dai, Shubham Jain, Junpeng Wang, Yujie Fan,Chin Chia Michael Yeh, Yan Zheng, Zhongfang Zhuang, and Wei Zhang. 2023.FATA-Trans: Field And Time-Aware Transformer for Sequential Tabular Data.International Conference on Information and Knowledge Management, Proceedings(2023), 32473256. Shijie Zhang, Hongzhi Yin, Tong Chen, Quoc Viet Nguyen Hung, Zi Huang,and Lizhen Cui. 2020. GCN-Based User Representation Learning for UnifyingRobust Recommendation and Fraudster Detection. Dl (2020), 689698. arXiv:2005.10150 Panpan Zheng, Shuhan Yuan, and Xintao Wu. 2019. SAFE: A neural survival analy-sis model for fraud early detection. 33rd AAAI Conference on Artificial Intelligence,AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelli-gence, EAAI 2019 (2019), 12781285. Yongchun Zhu, Dongbo Xi, Bowen Song, Fuzhen Zhuang, Shuai Chen, Xi Gu,and Qing He. 2020. Modeling Users Behavior Sequences with HierarchicalExplainable Network for Cross-domain Fraud Detection. The Web Conference2020 - Proceedings of the World Wide Web Conference, WWW 2020 (2020), 928938.",
  "APPENDICESAPSEUDO-CODE OF VECAUG": "Algorithm 1 provides a detailed pseudocode description of the vec-tor burn-in technique employed by VecAug. This technique rep-resents a fundamental aspect of VecAugs approach, effectivelyseparating the optimization of embedding vectors from their uti-lization in subsequent cohort augmentation. Additionally, VecAugstores the label information of training samples, a crucial elementthat plays a significant role in the subsequent negative neighborseparation process, enhancing its overall effectiveness.On the other hand, Algorithm 2 outlines the procedure for cohortidentification and subsequent cohort-augmented training withinthe VecAug framework. To enhance clarity, certain steps, includingcontrastive loss calculation, and vector regularization, have beenomitted for simplicity. During this process, its essential to notethat the parameters of auxiliary encoder () and the outputlayer used in the vector burn-in phase will remain fixed. This delib-erate decision ensures the preservation of task-specific relevancebetween the target sample and the neighboring vectors, therebyfacilitating the augmentation and separation of the representationsbetween neighbors and target samples. Furthermore, by retainingwell-trained neighborhood information, the augmented-trainingprocess becomes significantly more manageable in comparison todynamic neighbor identification and augmentation methods. Thisdesign choice not only promotes computational efficiency but alsocontributes to the stability and effectiveness of VecAug in enhanc-ing fraud detection.",
  "BMORE EXPERIMENTAL RESULTS": "We also conducted experiments on two more methods widely com-pared recently, i.e., IHGAT and FATA-Trans to verify theeffectiveness of VecAug. The results in show that VecAugconsiderably improves the detection performance of these two rep-resentative methods across all three datasets, with AUC (1% increaseis considered significant ) and improvements up to",
  "% and 6.83%, respectively. These new results further validatethe effectiveness of our cohort augmentation for fraud detection.CVISUALIZATION OF VECAUG": "We use t-SNE to visualize the user embeddings of a base modeland its augmented version by VecAug, as shown in . Weapply the same t-SNE settings for both cases, with a Euclideandistance metric and a perplexity of 30. Unlike most existing meth-ods that use contrastive loss on the encoder outputs, our proposedVecAug applies contrastive loss on the predicted logits. As a result,the cohort augmentation has a stronger effect on the first layeroutput of the output layer, which we use for visualization. From Fig-ure 9, we observe that fraudulent users do not always form a singlecluster, but rather are dispersed across multiple groups of varyingsizes. This shows the variety and complexity of fraud schemes anduser behaviors. Normal users also have different types of clusters,indicating their different preferences and habits. We also noticethat the augmented model forms more distinct and compact clus-ters than the original base model. This is because the personalized",
  "MINT w/o 0.8892 0.8892 0.8892 0.8892 0.8892 0.8892 0.8892w/ 0.8941 0.8953 0.8962 0.8971 0.8954 0.8937 0.8895": "cohort augmentation can capture the similarities and differencesamong users, and create more homogeneous and isolated smallclusters. Furthermore, the augmented model can better distinguishfraudulent cohorts from normal user groups, owing to both theenhanced clustering precision conferred by cohort augmentationand negative neighbor separation techniques. These techniquescan push away similar but negative neighbors during the cohort-augmented training process, and make each cluster more cohesiveand discriminative.",
  "DHYPER-PARAMETERS SETTINGS ONVECAUG": "The hyperparameters and play a crucial role in VecAugs ob-jective function. Specifically, they correspond to the weights ofthe supervised contrastive loss and auxiliary reconstruction loss,respectively. To provide a comprehensive understanding of howdifferent settings of these hyperparameters affect the performanceof VecAug, we conducted a detailed analysis. This analysis focusedon evaluating the changes in model performance when varying thevalues of and . The experiments utilize base models HEN and MINT with Shopee-small dataset. The results are sum-marized in and , and the analysis is presented asfollows: Study of : An increase in from its optimal value of 0.001to 0.01 results in a marginal performance decline for both HENwith VecAug and MINT with VecAug. A further increase of to 1.0 leads to a more pronounced drop, due to an overempha-sis on distinguishing training samples from negative neighbors,which could cause overfitting. On the other hand, a decrease in below 0.001 reduces the models ability to counteract noise",
  "from negative neighbors, which will negatively impact VecAugseffectiveness": "Study of : Adjusting the hyperparameter also alters VecAugsperformance. A higher diminishes the effectiveness of VecAugscohort augmentation by aligning the main encoder too closelywith the auxiliary encoder. This will limit the diversity and ro-bustness that cohort augmentation is intended to introduce. Con-versely, a reduction in leads to a slight decrease in effectiveness,which is mitigated by the use of burn-in vectors from augmenta-tion neighbors to enhance target sample representations. Theseburn-in vectors help to enhance the representations of the targetsamples by introducing additional contextual information, whichcompensates to some extent for the decreased influence of theauxiliary reconstruction loss.Overall, the performance of VecAug remains relatively stableacross different hyperparameter values. An value of 0.001 and 0.00001 achieve the best performance across different models.Hence, the objective function can be easily optimized without labo-rious hyperparameter tuning.",
  "ECOMPUTATIONAL COMPLEXITY ANALYSISOF VECAUG": "The computational complexity of VecAug involves both time andspace complexity. We denote the number of parameters , the num-ber of stored sample embedding vectors as , the dimensionality ofthe embeddings as , and the number of neighbors as . Time Complexity: The vector burn-in steps time complexity isdetermined by the base model, with a complexity of (). Thecohort-augmented learning steps time complexity is mainly dom-inated by the augmented learning model and the attentive neigh-bor aggregation layer, with a complexity of () and (2 ),respectively. It also includes the search time for augmentationneighbors using the HNSW index, with a complexity of ( ()). So the time complexity should be( +2+()). Space Complexity: The space complexity in the vector burn-in step is (). The cohort-augmented learning step involvesstoring burn-in vectors and constructing a graph-based index,leading to a complexity of (() + + ). Therefore, theoverall space complexity is (() + + ).Given that is set to 5, the embedding dimension is 64, and() is usually small, the time complexity is mainly determinedby the model rather than cohort neighbor searching. The spacecomplexity is dominated by the stored vector size and the modelsize, which are typically moderate in our anti-fraud system."
}