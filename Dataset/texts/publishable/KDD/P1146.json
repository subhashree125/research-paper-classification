{
  "ABSTRACT": "Recent years have witnessed the success of introducing deeplearning models to time series forecasting. From a data generationperspective, we illustrate that existing models are susceptible todistribution shifts driven by temporal contexts, whether observedor unobserved. Such context-driven distribution shift (CDS) in-troduces biases in predictions within specific contexts and poseschallenges for conventional training paradigms. In this paper, weintroduce a universal calibration methodology for the detection andadaptation of CDS with a trained model. To this end, we proposea novel CDS detector, termed the \"residual-based CDS detector\"or \"Reconditionor\", which quantifies the models vulnerability toCDS by evaluating the mutual information between predictionresiduals and their corresponding contexts. A high Reconditionorscore indicates a severe susceptibility, thereby necessitating modeladaptation. In this circumstance, we put forth a straightforwardyet potent adapter framework for model calibration, termed the\"sample-level contextualized adapter\" or \"SOLID\". This frameworkinvolves the curation of a contextually similar dataset to the pro-vided test sample and the subsequent fine-tuning of the modelsprediction layer with a limited number of steps. Our theoreticalanalysis demonstrates that this adaptation strategy can achievean optimal bias-variance trade-off. Notably, our proposed Recon-ditionor and SOLID are model-agnostic and readily adaptable toa wide range of models. Extensive experiments show that SOLIDconsistently enhances the performance of current forecasting mod-els on real-world datasets, especially on cases with substantial CDSdetected by the proposed Reconditionor, thus validating the effec-tiveness of the calibration approach.",
  "Both authors contributed equally to this research.Corresponding authors": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain. 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "time series forecasting, distribution shift, context-driven distribu-tion shift": "ACM Reference Format:Mouxiang Chen, Lefei Shen, Han Fu, Zhuo Li, Jianling Sun, and ChenghaoLiu. 2024. Calibration of Time-Series Forecasting: Detecting and AdaptingContext-Driven Distribution Shift. In Proceedings of the 30th ACM SIGKDDConference on Knowledge Discovery and Data Mining (KDD 24), August2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 15 pages.",
  "INTRODUCTION": "Time Series Forecasting (TSF) plays a pivotal role in numerousreal-world applications, including energy consumption planning, weather forecasting , financial risk assessment ,and web recommendation . Recent years have witnessedthe progress of introducing time series forecasting model to better capture the temporal dependencies by extracting andstacking multi-level features. Despite the remarkable architecturedesign, the distribution shift has become an unavoidable yethighly challenging issue, which engenders suboptimal performanceand hampers generalization with a fluctuating distribution.Generally, distribution shift signifies variations in the underlyingdata generation process, which is typically driven by some temporalobserved or unobserved factors, namely contexts. In this paper, wereveal two significant observed contexts within time series data:temporal segments (i.e., different temporal stages as the timeevolution), and periodic phases (i.e., the fraction of the periodcovered up to the current time), along with other unobservedcontexts. For example, in the scenario of electricity consumption,factors like economic trends over the years (temporal segments) andseasonal fluctuations (periodic phases) can affect electricity usage.We visualized the impact of these two contexts on data distributionin Appendix C.2. Moreover, sudden policy changes (unobservedcontexts) can also affect the usage. We refer to this phenomenon ascontext-driven distribution shift, or CDS.",
  "(b) (conditional) residual distribution": ": (a) Causal graph in the presence of context-drivendistribution shift. (b) Impact of CDS: Autoformers resid-ual distribution on the entire Illness dataset, along with theresidual distributions conditioned on two different periodicphases. In the presence of CDS, TSF models remain constrained owing totheir ignorance of contexts. Firstly, the training and testing datasetsare often generated under distinct contexts (i.e., temporal segments).This deviation from the conventional assumption of consistentdataset distributions between training and testing data can lead tosuboptimal prediction results. Secondly, even within the training set,these contexts essentially function as confounders factorsthat simultaneously influence the historical and future data, asdemonstrated in (a). Such confounders lead trained modelsto capture spurious correlations, causing them to struggle withgeneralizing to data from new distributions.To present the impact of CDS in practice, we trained an Auto-former on Illness and assessed its ability to fit sub-data in dif-ferent periodic phases. Residuals, the difference between a modelsprediction and the ground truth that can reflect the goodness offitting, were analyzed for the 47th and 32nd periodic phases, andthe entire dataset. The residual results are visualized in (b).Notably, it can be observed that the model provides an unbiasedestimation for the entire training dataset (i.e., the mean of residualsis zero). However, the estimation within two specific contexts isbiased since both their means of residuals deviate from zero. Thisobservation underscores the models limitations in fitting sub-datawithin a context, as it is susceptible to data from other contexts andlearns spurious correlations. It motivates us to calibrate the modelto achieve more accurate estimation within each context. Present work. In this paper, we introduce a general calibration ap-proach to detect and adapt to CDS with a trained model. Specifically,we first propose a metric to measure the severity of models suscep-tibility to CDS within the training data, namely Residual-basedcontext-driven distribution shift detector or Reconditionor, bymeasuring the mutual information between residuals and observedcontexts to quantify the impact of contexts on models prediction.A higher value from Reconditionor signifies a stronger CDS.Under this circumstance, we further propose a simple yet effec-tive adapter framework for further calibration. Given the inherentvariability in contexts across data samples, a one-size-fits-all adap-tation of the model is inherently unfeasible. Hence, we posit theneed to fine-tune the model at the individual sample-level. illustrates the comparison between the traditional method andour proposed sample-level adaptation framework. Notably, for each",
  "?Step : predict": "Step : contextualized adaptation model model Residual distribution Residual distribution CDS : Illustrations of the traditional framework (top) andthe proposed framework (bottom). By calibrating the modelvia contextualized adaptation before making each prediction,the context-driven distribution shift (CDS) can be alleviated. test sample, adapting the model solely based on that single instanceis intractable. As an alternative, we initiate a data augmentationprocess by curating a dataset comprising preceding samples char-acterized by akin contexts. Since the chosen samples can introducesignificant variance during the adaptation process, we restrict thefine-tuning to the models prediction layer with a limited number ofsteps. Our theoretical findings substantiate that this approach canattain an optimal bias-variance trade-off. We refer to this frameworkas Sample-level cOntextuaLIzed aDapter, or SOLID.Extensive experiments indicate that our proposed calibrationapproach consistently enhances the performance of 7 forecastingmodels across 8 real-world datasets. Notably, our Reconditionor reli-ably identifies cases requiring CDS adaptation with a high accuracyof 89.3%. Furthermore, our proposed SOLID yields an average im-provement ranging from 8.7% to 15.1% when addressing significantCDS situations as detected by Reconditionor. Even in cases withless pronounced CDS, SOLID still achieves an average improve-ment ranging from 0.3% to 6.3%. From an efficiency perspective, ourmethod introduces a 20% additional time overhead, a gap smallerthan the effects of dataset variability. Crucially, Reconditionorsmetric closely aligns with SOLIDs performance gains. These find-ings provide robust validation of the effectiveness of our calibrationapproach.The main contributions of this work are summarized as follows: We propose the concept of context-driven distribution shift (CDS)by studying the driving factors of distribution shifts and inves-tigating two observed contexts (temporal segments and periodicphases), as well as unobserved contexts. We propose an end-to-end calibration approach, including Re-conditionor, a detector to measure the severity of the modelssusceptibility to CDS, and SOLID, an adapter to calibrate modelsfor enhancing performance under severe CDS. Extensive experiments over various datasets demonstrate thatReconditionor detects CDS of forecasting models on the trainingdataset accurately, and SOLID significantly enhances currentmodels without substantially compromising time efficiency.",
  "RELATED WORK2.1Time series forecasting models": "With the successful rise of deep learning approaches, many re-cent work utilizes deep learning to better explore the non-linearityand multiple patterns of the time series and empirically show betterperformance. Some research introduces the Transformer to capturetemporal dependencies with the attention mechanism. Specifically,Informer proposes ProbSparse self-attention. Autoformer introduces Auto-correlation attention based on seasonal-trend de-composition. FEDformer proposes Fourier frequency enhancedattention. ETSformer leverages exponential smoothing atten-tion. Crossformer utilizes a two-stage attention to capture bothcross-time and cross-dimension dependency. PatchTST pro-poses patching and channel independence techniques for betterprediction. Different from the Transformer architecture, DLinear leverages linear models with decomposition or normalizationfor TSF tasks. In this paper, our proposed pipeline can be easilyapplied to these TSF models, regardless of the model architecture.",
  "Distribution shift in time series": "Distribution shift in time series refers to the phenomenon thatstatistical properties and data distribution continuously vary overtime. To better detect such distribution shifts, various methods havebeen proposed. Stephan et al. employs dimension reduction andproposes a two-sample hypothesis testing. Sean et al. proposesan expected conditional distance test statistic and localizes the exactfeature where the distribution shift appears. Lipton et al. uti-lizes hypothesis testing based on their proposed Black Box ShiftEstimation, thereby detecting the shift. However, these detectionmethods ignore the important context, and are mostly not appro-priate for time series data. In contrast, our proposed residual-baseddetector has sufficient ability to detect the influence of underlyingcontext on distribution shift.Meanwhile, addressing distribution shifts in time series fore-casting is also crucial. One approach is to employ normalizationtechniques to stationarize the data. For example, DAIN employsnonlinear networks to adaptively normalize time series. RevIN proposes a reversible instance normalization to alleviate series shift.AdaRNN introduces an Adaptive RNN to solve the problem.Dish-TS proposes a Dual-Coefficient Net framework to sepa-rately learn the distribution of input and output space, thus captur-ing their divergence. Other approaches combine statistical methodswith deep networks. Syml applies Exponential smoothing onRNN, to concurrently fit seasonality and smoothing coefficientswith RNN weights. SAF integrates a self-supervised learningstage on test samples to train the model before making the predic-tion. However, these methods are coupled to model architecture orrequire modification during or before the training process, whichlimits their application. In contrast, our proposed approach canefficiently adapt the given trained models solely during test timeand at the sample level.",
  "represent a sample at -th timestep. Given a historical sequence:": ": = R, where is the look-backwindow size, the task is to predict future values with forecastingwindow size: :+ = [, , + 1] R . The trainingobjective of a model is to find the best mapping from input tooutput sequence, i.e. :+ = (:). In this work, we assume is a deep neural network composed of two parts: a feature extractor : R R mapping the historical values to a -dimensionallatent representation, and a linear top named as prediction layermapping the representation to predicted future values. The specificdefinitions of and for different model architectures will beintroduced in Appendix B.4.",
  "CONTEXT-DRIVEN DISTRIBUTION SHIFT": "In this section, we introduce the limitation of traditional TSFmodels. As mentioned before, the data generation in time seriesis typically influenced by temporal external factors (i.e., context), such as temporal segments and periodic phases. Let , and denote the variables of historical data :, future data :+and context at time step , respectively. The generation of isdependent on and , characterized as ( | ,).Due to the ignorance of contexts, the model trained on thedataset learns a marginal distribution ( | ) = ( | , =)( = ). This introduces a confounding bias since context usually influences both the historical data and the future data, which is evident in Appendix C.2. To illustrate this concept,consider a simplified example in the domain of recommendation.In the winter season (context ), users who purchase hot cocoa(historical data ) also tend to buy coats (future data ). A modelmay \"memorize\" the correlation between and (a spurious corre-lation), and mistakenly recommend coats to a user who purchaseshot cocoa in summer. This confounding bias leads to suboptimalproduct recommendations. In our subsequent theoretical analysis( 6), we detail that such context consistently adds a bias term tothe model. The following defines this phenomenon formally.",
  "Residual-based CDS detector": "Our primary focus lies in assessing the models susceptibilityto CDS. Our evaluation predominantly centers around observedcontexts, as the analysis of unobserved contexts is computationallyinfeasible. Fortunately, for our empirical investigation, the utiliza-tion of observed contexts proves to be sufficient and effective.As visually demonstrated in (b), the presence of contextsintroduces a bias to the model estimation, causing variations in",
  "contexts": "? : Pipeline of our calibration framework to detect andadapt to context-driven distribution shift (CDS). We leverage1 residual-based context-driven distribution shift detector(Reconditionor) to assess how susceptible a trained model isto CDS. If we detect a significant susceptibility, we employ2 sample-level contextualized adapter (SOLID) to adapt themodel for each test sample using preceding data that sharesimilar contexts. residual distributions across different contexts. Based on it, wepropose a novel detector, namely Residual-based context-drivendistribution shift detector (or Reconditionor), by measuring themutual information (MI) between prediction residuals and theircorresponding contexts. The MI quantifies the extent of informationacquired regarding the residuals when observing the context, whichserves as a metric for evaluating the influence of contexts on themodel. MI can be computed by:",
  "= MI(;) = E [KL (( | ) ())] ,(1)": "where = () is the residuals of model , and KL() isKullbackLeibler (KL) divergence between distributions and .We reuse (b) to illustrate the concept behind Recondi-tionor when detecting the distribution shift based on the context ofperiodic phases. The marginal residual distribution () typicallyexhibits a mean close to zero after training. However, the residualdistributions conditioned on different contexts (e.g., the 47th phaseand the 32nd phase) ( | ) clearly show non-zero mean values.This increases the KL divergence between the two distributions,consequently elevating and indicating a strong CDS. Additionally,a non-zero mean in the conditional residual distribution suggeststhe model fails to adequately fit the data within each context,signaling the need for further adaptation. In summary, a high valueof for a model implies the necessity for adapting , which isalso empirically verified in 7.2.3.In practice, we assume that the residuals follow Gaussian distri-butions. This assumption is based on the utilization of MSE loss,which implicitly presupposes that the residuals adhere to additiveGaussian noise. This characteristic is also evident in (b).The adoption of this assumption expedites the calculation of KL",
  "return ;": "divergence because Gaussian distributions offer a straightforwardanalytical solution for it.We illustrate the full algorithm for Reconditinor in Algorithm 1.In lines 1-2, we initialize the sets of residuals for both the marginaldistribution () and the conditional distributions ( | ) foreach []. In lines 3-7, we update these sets with the residualscomputed by . We compute the mean and standard deviationvalues for () in line 8 and perform a similar computation for( | ) in line 11. Finally, in line 12, we compute and averagethe KL divergences between () and ( | ) to obtain thedetector score .",
  "Sample-level contextualized adapter": "A higher metric from Reconditionor signifies a stronger impactof CDS on a model. Given the nature of CDS, our primary conceptis to adjust the model to align with the conditional distribution( |,) instead of the marginal distribution ( |). However,noticing that the context is consistently changing at each timestep, a one-size-fits-all adaptation of the model is inherently unfeasi-ble. Therefore, we propose to carry out adaptations at the individualsample-level.For each test sample :, it is not viable to adapt the modelsolely relying on the input :. Therefore, we commence byimplementing data augmentation through the creation of a datasetderived from this specific sample, formulated as:",
  "Dctx = Select({(:, :+ ) : + }),(2)": "where Select operation involves the selection of preceding samplesthat share a similar context with the provided sample :, andwe will provide further elaboration on this operation in 5.3. Wedenote the resulting dataset as the contextualized dataset (Dctx).Specifically, before making prediction to the test sample :, weemploy Dctx to adapt the model to alleviate the influence of CDS.We refer to this step as Sample-level cOntextuaLIzed aDapter,or SOLID. Its worth noting that since adaptation takes place during",
  "Calibration of Time-Series Forecasting: Detecting and Adapting Context-Driven Distribution ShiftKDD 24, August 2529, 2024, Barcelona, Spain": ": Performance comparison. \"24 / 96\": prediction length is 24 (Illness) or 96 (other datasets), applicable similarly to \"36 /192\", etc. \"\": average improvements achieved by SOLID compared to the baseline. \"\": metrics given by Reconditioner in twoobserved contexts: periodic phases () and temporal segments ( ), in the form of log10 & log10 . RED highlights a strongCDS in periodic phases (i.e., log10 3.2), while BLUE highlights a weak CDS in periodic phases (i.e., log10 < 3.2).",
  "Contextualized dataset selection": "As we mentioned previously, the core of adaptation involvescreating the contextualized dataset Dctx for the sample at . In thissection, we introduce the Select operation in Eq.(2). Note that dueto the unavailability of the true context governing the data gen-eration process, it is not feasible to select samples with preciselythe same context. To address this issue, we design a comprehen-sive strategy based on the observable contexts (temporal segmentsand periodic phases), and employ sample similarity as a proxy forunobserved contexts. 5.3.1Temporal segments. The data generation process typicallyevolves over time . Consequently, we claim that the temporalsegment is a critical context. Therefore, we focus on samples thatare closely aligned with the test samples in the temporal dimension,formally,",
  "where controls the time range for selection. When samples aretoo distant from , we conclude that they are in distinct temporalsegments and consequently exclude them from selection": "5.3.2Periodic phases. Furthermore, its worth mentioning thattime series data often exhibit periodic characteristics. The datageneration process can vary across different phases. Therefore, weclaim that the periodic phase constitutes another critical context.To find the samples with similar phases, we need to detect theunderlying periods. Specifically, we follow ETSformer andTimesNet to employ the widely-used Fast Fourier Transform(FFT) on the training dataset Rtrain with length-train and variables, formulated as:",
  "=train/arg max{2,...,[train/2]}=1 Ampl(FFT()).(3)": "Here, is the sequence of the -th variables in , FFT() andAmpl() denote the Fast Fourier Transform (FFT) and amplituderespectively. To determine the most dominant frequency, we sumthe amplitudes across all channels and select the highest value,which is converted to the periodic length .Next, we employ the periodic length to select samples withclosely aligned phases. Particularly, for the given test sample attime step , we select samples that display minimal difference in",
  ",": "where mod and mod are the phases of the test sample andpreceding samples, respectively. is a hyperparameter controllingthe threshold for the acceptable phase difference. If the differenceexceeds a certain threshold, the preceding samples will not beconsidered to share the same context as the test sample. 5.3.3Address unobserved contexts through sample similarity. Eventhough the strategies introduced in 5.3.1 and 5.3.2 efficientlyidentify potential samples with similar contexts, we cannot guar-antee a consistent mapping relationship for these samplesdue to the existence of unobserved contexts. To further enhance thequality of selection and address this issue, its essential to recognizethat context typically influences input data through a causal effect , which suggests a correlation between contexts and inputs.Inspired by this insight, we assume that when samples havesimilar inputs , they are more likely to share a similar context. Consequently, we incorporate sample similarity as a proxy ofunobserved contexts. The calculation of the similarity can be anymeasurement of interest, and we employ the Euclidean distance asthe chosen metric. Specifically, we select the top- similar samples,where serves as a hyperparameter governing the number ofsamples to be chosen. 5.3.4Full algorithm for SOLID . Finally, we combine the abovestrategies for the Select operation, by first filtering the temporalsegments and periodic phases ( 5.3.1 and 5.3.2) and then selectingtop- samples based on sample similarity ( 5.3.3).We illustrate the full algorithm for SOLID in Algorithm 2. Wefirst compute the periodic length on the training dataset (Eq.(3)).During the testing stage, for a given test sample, we perform thefollowing steps: In lines 1-7, we filter the time steps based on the",
  "THEORETICAL ANALYSIS": "In this section, we provide a formal theoretical analysis to es-timate the generalization error, before and after considering con-text, to illustrate the influence from CDS ( 4), as well as the bias-variance trade-off during the fine-tuning process ( 5.2). Given ourfine-tuning targets the prediction layer with the feature extractorremaining frozen, our theoretical analysis centers on the latentrepresentation space () rather than the raw data . To startwith, we first make the following assumption for the generationprocess of : Assumption 1 (Contextualized generation process). As-sume that the input latent representations () on the training setcan be divided into context groups based on different contexts:(1, ,), where R and is the number of data pointsin the -th group. For each , there exists a parameter vector R",
  "where = , and = (=1)1(=1). The quantity|| || is the Mahalanobis distance norm, defined as 2 =": "The bias part in Theorem 1 indicates that GLR is unbiased onlywhen the data generation parameters are identical across allgroups. However, if they differ due to the influence of contexts, theregressor is biased regardless of the amount of data, i.e., CDS. In the next, we explore a straightforward approach to addressCDS: discarding the existing biased regressor and training a new in-dividual regressor for each context group ( []) to eliminatethe bias. We refer to this ensemble of regressors as contextualizedlinear regressors (CLR), as follows:",
  "Experiment settings": "Datasets. We conduct the experiments on 8 popular datasets forTSF: Electricity, Traffic, Illness, Weather , and 4 ETT datasets(ETTh1, ETTh2, ETTm1, ETTm2) . We follow the standardpreprocessing protocol and partition the datasets intotrain/validation/test sets by the ratio of 6:2:2 for ETT and 7:1:2for the other datasets. Appendix B.1 contains more dataset details.",
  "Results of ETTm1, ETTm2 and Weather datasets are included in of Appendix C.1, due to space limit": "Baseline models. As aforementioned, our proposed approachis a general framework that can calibrate many deep forecastingmodels. To verify the effectiveness, we utilize several forecastingmodels for the detection and adaptation, including Informer ,Autoformer , FEDformer , ETSformer , Crossformer, DLinear and PatchTST . Appendix B.2 contains moredetails about the baselines.Experimental details. For a fair comparison, we set the predic-tion length of {24,36,48,60} for the Illness dataset, and {96,192,336,720}for the others, which aligns with the common setting for TSF tasks. Additionally, for other hyper-parameters, we follow theprimary settings proposed in each respective paper .For our SOLID, we employ gradient descent to fine-tune the pre-diction layer on Dctx for one epoch. Appendix B.3 contains moredetails about the hyper-parameters. Evaluation metrics. Consistent with previous research , we compare the performance via two widely-used metrics:Mean Squared Error (MSE) and Mean Absolute Error (MAE). SmallerMSE and MAE indicate better forecasting performance. We alsocompute the proposed Reconditionor as a metric for detecting theextent of models susceptibility to CDS based on the two observedcontexts, periodic phase () and temporal segment ( ). For ,the number of contexts equals to the periodic length, detailed inEq.(3). For , we partition the training set into five equal segments,with each one representing a distinct temporal segment. Larger and indicate a stronger CDS for the given model and dataset.",
  "Effectiveness of SOLID": "SOLID enhances the performance of all models across variousdatasets by effectively addressing the CDS issue. Particularly,Informer, which is relatively less powerful, experiences a signifi-cant enhancement of 10%-60% in MSE. One explanation is thatCDS has a more detrimental effect on weaker models, as theystruggle to learn diverse patterns under different contexts. For datasets and models showing significant CDS under thecontext of periodic phases (i.e., log10 3.2), SOLID achievesa considerable improvement. Specifically, it yields an averageimprovement of 15.1% for Illness, 9.9% for Traffic, and 8.7% forElectricity in terms of MSE on these cases. This highlights theeffectiveness of SOLID in addressing severe CDS issues. On the cases of weak CDS under the context of periodic phases(i.e., log10 below the 3.2 threshold), SOLID still achieves aconsistent improvement ranging from 0.3% to 6.7% across dif-ferent datasets. This observation underscores the widespreadpresence of CDS in time series.",
  "Effectiveness of Reconditionor": "Our Reconditionor effectively assesses the magnitude of CDS andaligns with the enhancement achieved by SOLID. When employ-ing the 3.2 threshold for log10 to ascertain whether MAEimprovement surpasses 1%, the classification accuracy reaches89.3% (50 out of 56). This demonstrates that this detector is univer-sally applicable and unaffected by different datasets and models. One exception is that Informer consistently achieves an improve-ment above 1%, irrespective of Reconditionor metrics. As afore-mentioned, one explanation is that Informer is relatively weaker,making it more amenable to improvement by SOLID. When theresults of Informer are excluded, the classification accuracy forReconditionor rises to 93.8% (45 out of 48).",
  "In addition, explains the performance improvement betterthan . We will give a possible conjecture in the followingsubsection to elucidate this observation": "7.2.3Correlation of Reconditionor and SOLID. To further investi-gate the correlation between Reconditionor and the improvementsachieved by SOLID, we plot and MAE improvements in Fig-ure 4 based on the results of and in Appendix C.1.To depict the trend more effectively, we have excluded the dataof Informer as previously explained. Notably, we have observeda pronounced and consistent upward trend between and MAE improvement in . This trend is highly evident, with a Spear-man correlation coefficient of 0.7998. This finding indicates that can serve as a valuable metric for estimating and explainingperformance improvements. We also elaborate on the relationshipbetween and MAE improvement in detail in Appendix C.3.",
  "In this section, we conducted additional experiments to furtheranalyze SOLID. presents partial results, with the full resultsreported in Appendix C.1": "7.3.1Ablation studies. We conducted ablation studies to investi-gate the relationship between performance and each componentin the selection strategy, particularly each observable or unobserv-able context we propose in 5.3. The investigation involves a pro-gression of strategy components. Specifically, we commence fromoriginal forecasts that ignore any contexts, denoted as \"/\". We thencreate contextualized datasets with various selection variations.For a fair comparison, all datasets are constructed by selecting samples from nearest ones. We first consider Temporal seg-ment context by selecting the nearest samples, denoted as \"T\".Then we take Periodic phase into consideration, and select nearest samples with phase differences less than , denoted as\"T+P\". Finally, we add sample Similarity and select the top-similar samples from nearest samples with phase differences lessthan . This strategy mirrors SOLID and is denoted as \"T+P+S\".Based on the results in (a) and 5(b), we showcase that eachcomponent leads to a consistent improvement in both MSE andMAE. These findings provide compelling evidence supporting theeffectiveness of all components utilized in our selection strategy aswell as the SOLID method. 7.3.2Comparative studies on adapting only prediction layer or en-tire model. All our previous experiments are performed solely byadapting the prediction layer while keeping the crucial parametersof bottom feature extractor layers unchanged. Nevertheless, it isimperative to conduct comparative experiments to validate thisperspective. Specifically, we compare the results achieved by solelyadapting the prediction layer against adapting the entire model. Theexperimental results are presented in (c). It indicates thatsolely adapting the prediction layer consistently yields superiorperformance. One explanation is that it reduces the risk of over-fitting. Moreover, solely adapting the prediction layer significantlyfaster the speed of inference. 7.3.3Comparison studies against other approaches addressing dis-tribution shifts. In this section, we compared two widely used base-lines, RevIN and Dish-TS which also address distributionshifts in time series forecasting. It is worth mentioning that theyare strategies that work during training, which differs from ourSOLID acting as a post-calibration method during the test process.Also, both RevIN and Dish-TS adapt the input data to better suitthe model, whereas SOLID adapts the model to match the datadistribution of the current context. Therefore, these methods arecomplementary and not exclusive. We explored their joint use onAutoformer, shown in Figures 5(d) and 5(e). We can observe thatSOLID consistently improves performance, regardless of whethermodels were trained with RevIN or Dish-TS. Moreover, in many",
  "(f) Speed": ": Further analysis of SOLID. (a)(b) Ablation studies for three contexts, temporal segment (T), periodic phase (P), andsample similarity (S). (c) Studies on tuning strategies to explore adaptation on prediction layer (PL) only vs. entire model (EM).(d)(e) Comparison studies against RevIN (R.IN) and Dish-TS (D.TS). (f) Efficiency studies on the prediction speed.",
  "cases, combining them achieves the best performance, suggestingthe orthogonality of Context-driven DS (CDS) with other types ofDS addressed by them": "7.3.4Efficiency analysis. Furthermore, we analyze the practicalefficiency of the proposed framework. For Reconditionor, it con-ducts a one-time analysis of residuals during the training process,thus not incurring any additional overhead during deployment. ForSOLID, it incurs two steps of overhead for each prediction sam-ple: (1) constructing the contextualized dataset, and (2) fine-tuningthe model. Step (1) can be optimized using some engineering tech-niques, such as pre-caching intermediate embeddings and buildingefficient vector indexing. For step (2), since only the prediction layeris fine-tuned, the computational cost will not be too high. To furtherassess SOLIDs efficiency, we report the additional time overheadintroduced by SOLID to FEDFormer across various datasets in Fig-ure 5(f). The results indicate that SOLIDs inference speed is about80% of traditional methods, a gap smaller than the variability intro-duced by different datasets, which suggests that our method doesnot significantly reduce inference speed. 7.3.5Parameter sensitivity analysis and case study. We adjustedthe hyperparameters within SOLID across multiple datasets andmodels to assess their impact on performance and conducted a casestudy to visualize the improvement. From the results, we discoverthat SOLID is insensitive to , which controls the time range ofpreceding data for selection, and , which governs the acceptablethreshold for periodic phase difference. But concerning , whichdetermines the number of similar samples to be selected for modeladaptation, and , which regulates the extent of adaptation onthe prediction layer for the models, they exist an optimal valueand should be well selected. The detailed results are reported inAppendix C.4 and Appendix C.5.",
  "CONCLUSION": "In this paper, we introduce context-driven distribution shift(CDS) problem in TSF and identify two significant observed con-texts, including temporal segments and periodic phases, along withunobserved contexts. To address the issue, we propose a general calibration framework, including a detector, Reconditionor, to eval-uate the degree of a models susceptibility to CDS and the necessityfor model adaptation; and an adaptation framework, SOLID, forcalibrating models and enhancing their performance under severeCDS. We conduct extensive experiments on 8 real-world datasetsand 7 models, demonstrating the accuracy of Reconditionor in de-tecting CDS and the effectiveness of SOLID in adapting TSF modelswithout substantially compromising time efficiency. This adapta-tion consistently leads to improved performance, which can be wellexplained by Reconditionor. Limitations and future work. (1) Despite demonstrating consis-tent performance improvements, SOLID introduces an approximateadditional 20% time overhead during the testing phase. Employingfurther engineering optimizations to narrow this efficiency gapwill be investigated in future work. (2) While Reconditionor proveseffective in leveraging observed contexts to ascertain the impactof CDS, whether unobserved context can be used for detectionis an interesting open question. (3) The selection of contextuallysimilar samples relies on heuristic rules in this paper. Investigatingfurther contexts or developing more generalized selection criteriarepresents a promising area of research.",
  "Research work mentioned in this paper is supported by StateStreet Zhejiang University Technology Center. We would also liketo thank Yusu Hong for the valuable discussion of the theory": "Mohsen Ahmadi, Saeid Ghoushchi, Rahim Taghizadeh, and Abbas Sharifi. 2019.Presentation of a new hybrid approach for forecasting economic growth usingartificial intelligence approaches. Neural Computing and Applications 31 (12 2019),86618680. Rafal Angryk, Petrus Martens, Berkay Aydin, Dustin Kempton, Sushant Mahajan,Sunitha Basodi, Azim Ahmadzadeh, Xumin Cai, Soukaina Filali Boubrahimi,Shah Muhammad Hamdi, Michael Schuh, and Manolis Georgoulis. 2020. Multi-variate time series dataset for space weather data analytics. Scientific Data 7 (072020), 227.",
  "KDD 24, August 2529, 2024, Barcelona, Spain.Mouxiang Chen, Lefei Shen, Han Fu, Zhuo Li, Jianling Sun, and Chenghao Liu": "Chirag Deb, Fan Zhang, Junjing Yang, Siew Eang Lee, and Kwok Wei Shah. 2017.A review on time series forecasting techniques for building energy consumption.Renewable and Sustainable Energy Reviews 74 (2017), 902924. Funda Demirel, Selim Zaim, Ahmet Caliskan, and Pinar Gokcin Ozuyar. 2012.Forecasting natural gas consumption in Istanbul using neural networks andmultivariate time series methods. Turkish Journal of Electrical Engineering andComputer Sciences 20 (01 2012), 695711. Yuntao Du, Jindong Wang, Wenjie Feng, Sinno Pan, Tao Qin, Renjun Xu, andChongjun Wang. 2021. AdaRNN: Adaptive Learning and Forecasting of TimeSeries. In CIKM. Association for Computing Machinery, New York, NY, USA,402411. Wei Fan, Pengyang Wang, Dongkun Wang, Dongjie Wang, Yuanchun Zhou, andYanjie Fu. 2023. Dish-TS: a general paradigm for alleviating distribution shift intime series forecasting. In AAAI, Vol. 37. 75227529. Yan Hu, Qimin Peng, Xiaohui Hu, and Rong Yang. 2015. Web Service Recom-mendation Based on Time Series Forecasting and Collaborative Filtering. In 2015IEEE International Conference on Web Services. 233240.",
  "Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2022.A Time Series is Worth 64 Words: Long-term Forecasting with Transformers. InICLR": "Nikolaos Passalis, Anastasios Tefas, Juho Kanniainen, Moncef Gabbouj, andAlexandros Iosifidis. 2019. Deep adaptive input normalization for time seriesforecasting. IEEE transactions on neural networks and learning systems 31, 9 (2019),37603765. Andrew Patton. 2013. Chapter 16 - Copula Methods for Forecasting MultivariateTime Series. In Handbook of Economic Forecasting, Graham Elliott and AllanTimmermann (Eds.). Handbook of Economic Forecasting, Vol. 2. Elsevier, 899960. Judea Pearl. 2009. Causality. Cambridge university press. Stephan Rabanser, Stephan Gnnemann, and Zachary Lipton. 2019. Failingloudly: An empirical study of methods for detecting dataset shift. NeurIPS 32(2019). Vijendra Pratap Singh, Manish Kumar Pandey, Pangambam Sendash Singh, andSubbiah Karthikeyan. 2020. An Econometric Time Series Forecasting Frameworkfor Web Services Recommendation. Procedia Computer Science 167 (2020), 16151625. International Conference onComputational Intelligence and Data Science. Vijendra Pratap Singh, Manish Kumar Pandey, Pangambam Sendash Singh, andSubbiah Karthikeyan. 2020. Neural Net Time Series Forecasting Frameworkfor Time-Aware Web Services Recommendation. Procedia Computer Science 171(2020), 13131322. Third Interna-tional Conference on Computing and Network Communications (CoCoNet19).",
  "BDETAILS OF EXPERIMENTSB.1Datasets details": "We conduct our experiment on 8 popular datasets followingprevious researches . The statistics of these datasets aresummarized in , and publicly available at and ETTh1/ETTh2/ETTm1/ETTm2. ETT dataset contains 7indicators collected from electricity transformers from July 2016 toJuly 2018, including useful load, oil temperature, etc. Data pointsare recorded hourly for ETTh1 and ETTh2, while recorded every15 minutes for ETTm1 and ETTm2.(2) Electricity. Electricity dataset contains the hourly electricityconsumption (in KWh) of 321 customers from 2012 to 2014.(3) Traffic. Traffic dataset contains hourly road occupancy ratedata measured by different sensors on San Francisco Bay area free-ways in 2 years. The data is from the California Department ofTransportation.(4) Illness. Illness dataset includes 7 weekly recorded indicatorsof influenza-like illness patients data from Centers for DiseaseControl and Prevention of the United States between 2002 and2021.(5) Weather. Weather dataset contains 21 meteorological indica-tors, like temperature, humidity, etc. The dataset is recorded every10 minutes for the 2020 whole year.",
  "B.2Baseline models": "We briefly describe our selected baseline models:(1) Informer utilizes ProbSparse self-attention and distilla-tion operation to capture cross-time dependency.(2) Autoformer utilizes series decomposition block archi-tecture with Auto-Correlation to capture cross-time dependency.(3) FEDformer presents a sparse representation withinthe frequency domain and proposes frequency-enhanced blocks tocapture the cross-time dependency.(4) ETSformer exploits the principle of exponential smooth-ing and leverages exponential smoothing attention and frequencyattention.(5) Crossformer utilizes a dimension-segment-wise em-bedding and introduces a two-stage attention layer to capture thecross-time and cross-dimension dependency.(6) DLinear proposes a linear forecasting model, along withseasonal-trend decomposition or normalization operations.(7) PatchTST utilizes Transformer encoders as model back-bone, and proposes patching and channel independence techniquesfor better prediction.",
  "B.3Hyper-parameters": "For all experiments, during the training process, we use the samehyper-parameters as reported in the corresponding papers , e.g., encoder/decoder layers, model hidden dimensions, headnumbers of multi-head attention and batch size.As for hyper-parameters for adaptation process, there exists 4major hyper-parameters for SOLID, including , , , (Wereport the ratio /train between adaptation learning rate and thetraining learning rate train as an alternative). We select the settingwhich performs the best on the validation set. The search range forthe parameters is presented in .",
  "To demonstrate the influence of context on data distribution, weutilized the Autoformer to extract latent representations from": ": Extended table of . \"\": average improve-ments achieved by SOLID compared to the original forecast-ing results. \"\": metrics given by Reconditionor in two ob-served contexts: periodic phases () and temporal segments( ), presented in the form of log10 & log10 . RED high-lights a strong CDS in periodic phases (i.e., log10 3.2),while BLUE highlights a weak CDS in periodic phases (i.e.,log10 < 3.2).",
  "-3.356 & -2.879-3.471 & -1.454-3.986 & -1.573": "the ETTh1 dataset and applied PCA for dimensionality reductionand visualization. This ensures the spatial positions of the datapoints in the figure represent their original distribution.We marked two observed contexts temporal segments and pe-riodic phases on the figures. Unobserved contexts, being difficultto visualize, are not displayed. (a) reveals a progressive out-ward shift in data distribution with increasing temporal segments.Similarly, (b) shows that changes in the periodic phase leadto a rotational shift in data distribution. Note that if CDS doesntexist, different colors (denoting contexts) should be scattered andrandomly mixed in the figure since colors are independent of spatialpositions, which is not the case shown in . Therefore, it isevident that these contexts markedly affect data distribution.",
  ": The relationship log10 (X-axis) and MAE improve-ments achieved by SOLID (Y-axis) for 8 datasets and 6 models": "Despite showing an increasing trend in , the Spearmancorrelation coefficient is merely 0.2129. This implies that, whilethere is evidence of CDS stemming from temporal segments asdetected by Reconditionor, SOLID is comparatively less effectiveat mitigating it when compared to CDS caused by periodic phases.One possible explanation is that data generated within the samephase tends to follow a more predictable pattern, while data withinthe same temporal segment exhibits greater diversity and uncer-tainty, which may limit the utility of selecting data from the samesegment to address CDS caused by temporal segments. We leavefurther investigation of it to future work.",
  "C.4Parameter sensitivity analysis": "Within our proposed approach, several crucial parameters arepresented, including , which controls the time range of precedingdata for selection; , which governs the acceptable threshold forperiodic phase difference; , which determines the number of similar samples to be selected for model adaptation; And , whichregulates the extent of adaptation on the prediction layer for themodels. The search range for these parameters is presented in. The results of parameter sensitivity analysis are visuallypresented in .Firstly, we discover that our proposed SOLID is insensitive to and parameters, based on the results obtained. Regarding the parameter, the selection of insufficient samples would increase thevariance during adaptation due to the data shortage. Conversely, se-lecting excessive samples carries the risk of including samples withunobserved irrelevant contexts, thereby deteriorating the modelsperformance. Lastly, For parameter , a very small leads to in-adequate model adaptation, preventing the model from effectivelyaddressing CDS and resulting in a bias towards the test sample(Theorem 1). Conversely, a too large value for can lead to exces-sive adaptation, which also risks bringing in substantial varianceto the model (Theorem 2). Therefore, a well-selected learning ratewill contribute to an optimal trade-off between bias and variance.",
  "C.5Case study": "In addition, we conduct a case study and visualize our proposedmethod on various cases across different datasets and models, aspresented in .Specifically, we plot the figures on these combinations: Illness(timestep 120 & 160, variate 7) on Crossformer, Traffic (timestep200 & 550, variate 862) on FEDformer, Electricity (timestep 1500 & 3000,variate 321) on Autoformer, and ETTh1 (timestep 250 & 650, variate7) on Informer, corresponding to (a)-(h). The visualizationvividly illustrates the effectiveness of our approach in improvingforecasting performance.",
  "(h) Traffic-": ": Case study and visualization of our proposed methods on various cases across different datasets and models, whereBLUE lines represent ground-truth, ORANGE lines represent original forecasting results, and GREEN lines represent theforecasts after employing our approach. Besides, 120 denotes this case is sampled at timestep-120 in the test set, and so on. GroundTruthBefore adaptationAfter adaptation"
}