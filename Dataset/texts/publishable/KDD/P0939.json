{
  "Abstract": "The public sharing of user information opens the door for adver-saries to infer private data, leading to privacy breaches and facilitat-ing malicious activities. While numerous studies have concentratedon privacy leakage via public user attributes, the threats associ-ated with the exposure of user relationships, particularly throughnetwork structure, are often neglected. This study aims to fill thiscritical gap by advancing the understanding and protection againstprivacy risks emanating from network structure, moving beyond di-rect connections with neighbors to include the broader implicationsof indirect network structural patterns. To achieve this, we first in-vestigate the problem of Graph Privacy Leakage via Structure (GPS),and introduce a novel measure, the Generalized Homophily Ratio,to quantify the various mechanisms contributing to privacy breachrisks in GPS. Based on this insight, we develop a novel graph privateattribute inference attack, which acts as a pivotal tool for evaluat-ing the potential for privacy leakage through network structuresunder worst-case scenarios. To protect users private data fromsuch vulnerabilities, we propose a graph data publishing methodincorporating a learnable graph sampling technique, effectivelytransforming the original graph into a privacy-preserving version. State Key Laboratory of Blockchain and Security. The author is also at HangzhouHigh-Tech Zone (Binjiang) Institute of Blockchain and Data Security, Hangzhou, China.This work was done when the author was a visiting student at Fudan University.Corresponding author. Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08 Extensive experiments demonstrate that our attack model poses asignificant threat to user privacy, and our graph data publishingmethod successfully achieves the optimal privacy-utility trade-offcompared to baselines.",
  "Graph privacy protection, data release, adversarial learning": "ACM Reference Format:Hanyang Yuan, Jiarong Xu, Cong Wang, Ziqi Yang, Chunping Wang, KetingYin, and Yang Yang. 2024. Unveiling Privacy Vulnerabilities: Investigatingthe Role of Structure in Graph Data. In Proceedings of the 30th ACM SIGKDDConference on Knowledge Discovery and Data Mining (KDD 24), August2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 14 pages.",
  "Introduction": "In the era of big data, with the increasing involvement of personaldata in information technology and shared on the web, privacy pro-tection has emerged as a crucial concern . In real-worldscenarios, individuals often share some information publicly whilesafeguarding their private attributes. However, publicly availableuser information gives adversaries opportunities to infer private at-tributes, resulting in privacy breaches . Furthermore, theinferred private data can facilitate malicious activities. For instance,in the 2010s, Cambridge Analytica collected personal data from 87million Facebook users to infer their political stands, which werefurther used for political advertising, resulting in a scandal withover $100 billion in economic losses . This incident emphasizesthe urgent need for privacy protection mechanisms.To prevent the exposure of user privacy, traditional works typi-cally focus on privacy leakage through users public attributes [21,",
  "ProximityStructure-roleCombination": ": (a) Illustration of privacy leakage mechanisms:proximity homophily highlighted in pink, structure-rolehomophily in blue, alongside the privacy protection strategydepicted in orange. (b) The results of private attribute infer-ence attacks accounting for proximity homophily, structure-role homophily, and a combination of both on Pokec-n. 49, 50]. However, these methods often overlook the privacy risksstemming from the public relationships among users .For example, in an online social platform like Facebook, users oftenpublicly display their followers or friends, where these relation-ships collectively form a network. This network structure can alsogive rise to potential privacy leakage .This work delves into the problem of Graph Privacy leakagevia Structure (GPS), aimed at unveiling various mechanisms bywhich network structure can lead to privacy exposure. Extantworks on privacy breach through network structure are primarilypremised in social homophily theory that posits users withsimilar private attributes tend to connect with each other. Hence,they study privacy leaks through direct connections with neigh-bors . However, user privacy in networks can also becompromised through more complex structural patterns, extendingbeyond direct neighbors. (a) illustrates that privacy risksfor user A arise not only from direct neighbors (i.e., proximityinformation), but also from users like B who, despite not being di-rect connections, exhibit similar local structures (i.e., structure-roleinformation). An example of structure-role information in socialnetworks is the observation that younger and older users tend tomaintain social circles of different sizes . This dimension ofprivacy leakage, facilitated by such local structures, has not beenthoroughly investigated in existing studies. To fill this research gap,we aim to develop a graph data publishing method aimed at compre-hensively protecting against potential privacy breaches arising fromthe network structure. Nevertheless, achieving this goal presentsseveral challenges.The first challenge lies in how to measure the extent of privacyexposure through network structures. Previous research mainly fo-cus on privacy leakage through direct connections between nodes,using homophily to quantify proximity-related exposure .However, this approach falls short in assessing privacy risks fromstructure-role information. In this study, we introduce the Gener-alized Homophily Ratio (GHRatio), a novel measure to quantifyprivacy risks associated with network structures. The GHRatiois a general form that is adaptable to various structural features. We explore two prevalent casesproximity homophily, structure-role homophily and their combination that contribute to privacyleakage.The second challenge stems from the necessity to develop aprivate attribute inference attack model that utilizes proximity ho-mophily, structure-role homophily, and their combination to launchattacks. Given that existing attack strategies merely exploit proxim-ity homophily , suboptimal results are yielded (as depictedby the red bar in (b)). To overcome this challenge, our modelis designed to account for all identified privacy breaches througha data-centric strategy. This strategy involves providing a graphneural network (GNN) with various data forms, thus enhancing itscapacity to learn from different types of homophily. Consequently,our attack model effectively behaves like a worst-case adversary,as evidenced by the green bar in (b).The last challenge lies in how to design a graph data publish-ing approach that can effectively defend the worst-case privateattribute inference attack. Previous efforts in graph data publishinghave primarily focused on differential privacy (DP) andgraph sampling , but DP often compromises the utility ofthe data . In addition, many sampling methods are rule-basedand reliant on domain-specific knowledge , which restrictstheir applicability. We therefore propose a learnable graph samplingmethod for privacy protection, employing a generative networkthat selectively samples edges to block privacy leakage (as illus-trated byin (a)). This method ultimately produces asampled graph suitable for publication.Our contributions are summarized as follows: Problem and measure: Our work pioneers a comprehensiveinvestigation into the problem of Graph Privacy leakage via Struc-ture (GPS), introducing the innovative Generalized HomophilyRatio (GHRatio) as a measure of privacy leakage. This helps usunveil all identified mechanisms by which the network structurecan lead to privacy breaches in a quantitative manner. Attack model: We introduce a novel private attribute inferenceattack leveraging a data-centric strategy to exploit all identifiedprivacy breaches. By feeding a GNN various data forms, it gainsthe ability to learn from multiple homophily types that result inprivacy risks.",
  "Unveiling Privacy Vulnerabilities:Investigating the Role of Structure in Graph DataKDD 24, August 2529, 2024, Barcelona, Spain": "in enhancing privacy protection . Therefore, this work par-ticularly focuses on a privacy-preserving graph data publishingproblem with a specific emphasis on the network structure.In this study, we refer to privacy as a particular attribute thatnodes choose to keep hidden, which aligns with previous works . Let graph = (, ,) denote an undirected network, where = {1, ..., } is the node set, is the edge set, and R is the node attribute matrix. R is the adja-cency matrix of , where = 1 if there exists an edge (, ) ,otherwise = 0. Each node is associated with a known/un-known private attribute . Here, = , where denotes publicly available private attributes, and representshidden private attributes. In this context, privacy in the graph isdefined by the set of hidden private attributes . Let us consider the following attack scenario. In a public socialnetwork, some users choose to conceal their private attributes,while others make them public. The adversary aims to infer thesehidden private attributes. The adversary is assumed to have accessto the network structure, node attributes (typically non-private),and publicly available private attributes. Publicly available privateattributes can come from users who do not consider this informationprivate or who seek to maximize visibility by sharing extensivepersonal information.",
  "that predicts the hidden private attribute": "The primary objective of this work is to tackle the problem ofprivacy-preserving graph data publishing against the aforemen-tioned graph private attribute inference attack. Specifically, insteadof directly releasing the original graph, the data publisher is en-couraged to generate a sampled graph for publishing, such thatthe sampled graph can defend against graph private attribute in-ference attack. Based on the above definition, we formulate ourprivacy-preserving graph data publishing problem as follows. Problem 2 (Privacy-preserving graph data publish-ing). Given graph = (, ,) and the publicly available pri-vate attributes , the data publisher aims to sample a new graph = (, ,) by selectively removing edges in , resulting in anew edge set . The sampled graph is expected to simultaneouslyachieve the following two objectives:Objective 1: privacy preservation. The adversary with and cannot accurately infer the private attribute , i.e.,",
  "Graph Privacy-leakage via structure (GPS)": "In this section, we delve into the problem of GPS, examining how thestructure of a graph can potentially lead to privacy breaches. We aimto introduce a novel measure to quantify the various mechanismscontributing to privacy breach risks in GPS.We start with an exploratory analysis using the NBA and Pokec-ndatasets, two widely adopted datasets for graph privacy-preservinglearning . We calculate (1) proximity-related fraction: thefraction of a nodes neighbors sharing the same private attribute;and (2) structure-related fraction: the fraction of nodes with similarlocal structures and the same private attributes to the total nodeswith similar local structures for a specific node. Here, similar lo-cal structures are defined where the structural similarity betweennodes ego networks exceeds a set threshold, assessed using degreecentrality. From the results shown in , we derive two keyobservations:Observation 1: The necessity for node-level analysis. In (a), despite similar mean values for both fractions, their local dis-tributions differ. (b) shows that even when the mean ofthe proximity-related fraction dominates, some nodes have signif-icantly lower values of the proximity-related fraction. This chal-lenges the graph-level homophily ratios from prior studies, whichrely on mean values as indicators , underscoring the needfor node-level analysis.Observation 2: Proximity, structure, and their combination shouldbe simultaneously considered. We find that in (a), there arenodes in which both fractions are relatively high; and in (b), there are instances where the proximity-related fractions ofcertain nodes are small, while the structure-related fraction mayprovide supplementary information. These observations emphasizethe importance of simultaneously considering proximity, structure,and their combination when addressing privacy concerns.In light of the insights gained from the exploratory analysis, wepropose a novel measure known as the Generalized HomophilyRatio (GHRatio), which is a generalized form that can be used inconjunction with different definitions of structural features associ-ated with graph privacy. Subsequently, we instantiate three formsof GHRatio: proximity homophily, structure-role homophily, andtheir combination. They represent the main pathways in graphstructure through which privacy can be leaked.",
  "KDD 24, August 2529, 2024, Barcelona, SpainHanyang Yuan et al": "Generalized Homophily Ratio. As our goal is to investigatehow network structure discloses privacy, we begin by defining ho-mophily indicator, which can be used to characterize the structuralcharacteristic or relation between two nodes. Definition 1 (Homophily indicator). A homophily indicator(, ,) assesses whether node and exhibit a shared structuralcharacteristic or relation . For example, when signifies similar localstructure, we have (, ,) = 1 if the similarity of and exceedsa certain threshold, and 0 otherwise; when considering as the relationof adjacency, (, ,) = 1 if node and are directly connected,and 0 otherwise.",
  "where and are private attributes of node and , respectively": "Two prevalent cases of GHRatio. Given the general form ofGHRatio, we further delve into two prevalent cases of it: proximityhomophily, structure-role homophily, by defining specific graphstructural feature associated with GHRatio.(1) Proximity homophily ratio. By defining the in homophilyindicator(, ,) as the relation of adjacency, we have(, ,) =1 if and are connected, and 0 otherwise; We name this specificcase of GHRatio as Proximity Homophily Ratio (GHRatioprox):",
  "|{| N ()}|,(4)": "where N () denotes s neighborhood, and | | denotes the car-dinality of a set. In fact, GHRatioprox aligns with the node-levelhomophily ratio defined in existing works .(2) Structure-role homophily ratio. We define in the ho-mophily indicator (, ,) as the similar local structure. Then, wehave (, ,) = 1 if the similarity between the local structures of and exceeds a certain threshold, and 0 otherwise. We name thiscase of GHRatio as Structure-Role Homophily Ratio (GHRatiorole):",
  "|{|() ()}|,(5)": "where () is the ego network of node , () () denotes thatthe ego networks () and () are sufficiently similar (e.g., thissimilarity can be understood in terms of structural similarity, specif-ically when the structural similarity between () and () exceedsa predetermined threshold). Empirically, we adopt the degree cen-trality to characterize the similarity between ego networks, whichhave been validated for its strong effectiveness and efficiency inprevious studies .",
  "Private Attribute Inference Attack": "This section introduces a novel private attribute inference attackmodel that leverages proximity homophily, structure-role homophilyand their combination to disclose private information. We adopta data-centric approach, feeding varied data forms into a GNN toextract the representations related to different homophily types(see 4.1). Then, a routing operator is introduced for the adaptiveintegration of these homophily-related representations (see 4.2).See (a) for an overview of our proposed attribute inferenceattack.",
  "Enhancing GNNs with Data-Centric Strategy": "Developing a GNN model capable of learning representations tai-lored to different homophily types is challenging. Existing workspredominantly learn representations based on proximity informa-tion or high-order node dependencies , which cannot adequately learn structure-role information. Although somenetwork representation methods are designed to learnfrom node structure roles, their expressive power is limited.In this work, we introduce a data-centric strategy designed toenhance GNNs capacity to learn representations tailored to prox-imity homophily and structure-role homophily. This is achieved byfeeding different forms of data into GNNs. An illustrative exampleis provided in . Our key insight is:(1) Feeding the entire graph to a GNN enables it to learn proximityhomophily;",
  "prox = GNNprox () .(6)": "Learning structure-role homophily from subgraphs. Thisapproach first extracts -hop ego networks for each node, resultingin a set of subgraphs. These subgraphs are subsequently fed to aGNN encoder. The resulting subgraph representation, which en-capsulates the aggregated features of its constituent nodes, servesas the representation for the subgraphs central node.This benefits the GNNs ability to learn structure-role homophilyfor two main reasons: First, by concentrating on subgraphs, thecentral nodes representation becomes exclusively reflective of itslocal structural context, isolating the central node from externalinfluences of nodes outside the subgraph. Secondly, GNNs are partic-ularly adept at learning structural information of smaller subgraphs.Although GNNs can identify structural patterns, comprehendingcomplex structures in larger graphs remains challenging, as ob-served in . Ultimately, this process allows the GNN to bring therepresentations of nodes with similar local structures closer in thelatent space.Specifically, we process the -hop ego network of node , de-noted as = (,,), and feed the subgraph to a GNN encoderGNNrole. The node representation roleis computed as the sub-graph representation, which is the mean of the representations ofall nodes in the subgraph:",
  "where Pooling is the mean pooling operator": "Theoretical analysis of learning from subgraphs. While cap-turing proximity homophily from the entire graph is widely ac-knowledged , few works explore learning structure-rolehomophily from subgraphs. We therefore theoretically investigatewhether GNNs fed with subgraphs can learn structure-role ho-mophily. The following theorem suggests that nodes with similarlocal structures can obtain similar node representations. Theorem 1. Let and be two k-hop subgraphs induced fromnode and . After employing a -layer GNN encoder with a 1-hop graph filter (L) on each subgraph, the representations of thecenter node and are obtained via a pooling function, i.e., role=Pooling(GNNrole()) and role= Pooling(GNNrole()). Withoutloss of generality, assume that the attribute of each node is a vector ofones, roleand rolesatisfy:",
  "where 2 denotes 2 norm of matrix or vector, denotes a constantdepending on GNNrole, L denotes the normalised Laplacian matrixof": "In Theorem 1, the term L L 2 measures the difference oflocal structure around and . As similar local structures bringsmaller differences in Laplacian matrices, the upper bound of noderepresentation distance is reduced. Consequently, nodes with simi-lar local structures become closer in the latent space. The proof ofthis theorem can be found in Appendix A.2.",
  "Routing Operator": "After obtaining the two types of representations, the challengearises in determining the optimal method to integrate them, espe-cially given the uncertainty about the extent of information thatshould be merged from each type. To tackle this issue, we intro-duce a routing operator that leverages our proposed GHRatio toeffectively combine these representations.Since GHRatioprox and GHRatiorole serve to quantify the extentto which proximity and structural role disclose privacy, respectively.Utilizing these ratios, we can integrate the two types of representa-tions, aiming for a balanced and informed combination that reflectsthe significance of both proximity and structural information inrevealing privacy. However, calculating these ratios requires theknowledge of the private attributes of all nodes, which presentsanother difficulty. To address this, our approach involves estimatingthe ratios by employing the pseudo-labels of private attributes.Formally, we apply Multilayer Perceptrons (MLPs) to obtaininference results from proximity-based representation prox andstructure role-based representation role. Then we use the esti-mated GHRatios as the proportions to integrate them. The inte-grated result in turn serves as the pseudo-labels. Due to theinterdependence between pseudo-labels and GHRatios, we initial-ize GHRatios with constants and iteratively update them duringtraining. The above process can be described as follows:",
  "Learnable Graph Sampling": "To generate a sampled graph with adjacency matrix , we firstfeed the graph into a GNN encoder to obtain node representationsamp:samp = GNN().(10)Given any connected node pair {, }, an MLP with sigmoid acti-vation takes the concatenation of their node representations sampand sampas input to compute the probability T of preservingthe edge between {, }:",
  "T = (MLP(samp samp)),(11)": "where denotes sigmoid activation, and represent the concate-nation operation. With an edges T calculated, we sample whetherto retain the edge in the synthetic graph according to this prob-ability, where Bernoulli(T).(12)In particular, the Gumbel-Softmax reparameterization trick is utilized to tackle the non-differentiable nature of the samplingprocess. In doing so, we obtain a continuous sampling result, i.e., = ((log log (1 )+log T)/), where Uniform(0, 1).As the temperature hyper-parameter tends to zero, the reparam-eterized result smoothly converges to binary values, while main-taining the relative order of each Gumbel .",
  "Optimization Problem": "We propose three optimization objectives for training learnableparameters within the graph sampling procedure: one aimed atdefending against worst-case attacks, one designed for a broaderspectrum of attacks, and another dedicated to preserving essentialgraph properties. These objectives collectively ensure that the sam-pled synthetic graph maintains user privacy while simultaneouslyachieving desirable data utility. Defending Against Worst-Case Attack. Given the proposedinference attack, the most straightforward and effective approachis to defend against this attack under the worst-case. Specifically, toobtain the worst-case attack, we maximize the performance of theattack model, and subsequently, we defend against such an attack.This can be formulated as",
  "where and denote the parameters of the sampling componentand the attack model respectively. determines by influencing": "Defending Against a Broad Spectrum of Attacks via GHRatio.Eq. (13) ensures that our publishing method can defend againstthe proposed worst-case attack. However, in real-world scenarios,the released graph may face various attacks, and not all of them necessarily reach the worst case . In such scenarios, wedevise a universal protection strategy via GHRatio, which servesas a measure independent of a specific attack.Essentially, GHRatio quantifies how much information the net-work structure can disclose for inferring the private attribute. Byminimizing GHRatio, we can mitigate the risk of privacy leakagein an attack-agnostic manner:",
  "GHRatio () GHRatio0 ,(14)": "where GHRatio () represents the new GHRatio of the sampledgraph . GHRatio0 represents ( = ), indicating the probabil-ity that nodes and any node ( ) have the same private at-tribute. When dis = 0, the structural characteristic in GHRatio ()provides no benefits for attribute inference.Note that since is given, we have GHRatio0 = (). In prac-tice, we propose to optimize the two prevalent cases of GHRatio,GHRatioprox and GHRatiorole, being described as:",
  "min max = adv + dis + reg,(17)": "where ,, > 0 are hyper-parameters.For different scenarios, we can also modify Eq. (17) to obtaindifferent variants. If the goal is to protect against the proposedworst-case attack, only retaining adv and reg would be sufficient.On the other hand, if the goal is not specifically for the worst casebut to be effective against a broad range of attacks, retaining disand reg is suitable.",
  "Training Algorithm": "In the training phase, the parameters of the sampling componentand the parameters of the proposed attack model are jointlytrained. Specifically, The training algorithm iterates through thefollowing main steps: (1) Learn to minimize adv, reg and diswhile keeping fixed, and (2) Learn to maximize adv whilekeeping fixed. Repeat these steps until the maximum iteration isreached. The detailed training algorithm and complexity analysisare summarized in Appendix A.3.",
  "Experiment Setting": "Datasets. We conduct attribute inference and data publishingexperiments on three datasets: Pokec-n, Pokec-z, and NBA .Following prior works , we treat country as the private attributein NBA, and region as the private attribute in Pokec-n and Pokec-z.Additionally, we also treat users age as another private attribute inPokec-n and Pokec-z, categorizing it according to the split in :Young (18-24), Young-Adult (25-34), Middle-aged (35-49), and Senior(> 49). All private attributes are randomly split, with 10% publiclyavailable and the remaining 90% hidden. In the experiments of datapublishing, we also consider salary as the label in NBA and workingfield as the label in Pokec-n and Pokec-z . We conduct nodeclassification on these labels as downstream tasks (using a training-testing split of 0.1:0.9), and assess the utility of published graphsby evaluating the performance of these tasks. The statistics of thethree datasets are summarized in . Implementation details. All experiments are conducted on amachine of Ubuntu 20.04 system with AMD EPYC 7763 (756GBmemory) and NVIDIA RTX3090 GPU (24GB memory). All modelsare implemented in PyTorch version 2.0.1 with CUDA version 11.8and Python 3.8.0. Each experiment is repeated 5 times to report theaverage performance with standard deviation.For the attack model, the encoder GNNprox and GNNrole areimplemented by two 2-layer GIN encoders, with the samemodel architecture. The hidden dimensions are set to 128 in Pokec-z, Pokec-n, and 64 in NBA. The two MLPs are both implementedby 1-layer linear transformations. The model is trained by AdamWoptimizer with a learning rate of 0.001 for 300 epochs in Pokec-n,Pokec-z, and 500 epochs in NBA. For the defensive model, the sam-pling component consists of a two-layer Graphsage encoderand a two-layer MLP. The hidden dimension of the Graphsage en-coder is 64, and the hidden dimension of the MLP is 32 in all datasets.The model is trained by AdamW optimizer with a learning rate of0.002 for 200 epochs in Pokec-n, Pokec-z, and 100 epochs in NBA.The weight decay is consistently set as 0.0005. Both models useReLU as the non-linear activation function. For hyper-parameterssettings. We perform a grid search of the degree similarity threshold(see Eq. 5) in with a step size of 5 in all datasets. We set to1, and vary and (see Eq. 17) within in NBA and (0,20] inPokec-z and Pokec-n, with a step size of 5. Our codes are availableat",
  "Experiments on Private Attribute Inference": "Baselines. We compare with the following attack models, whichare divided into three types: (1) MLP: multilayer perceptions; (2)GCN , GAT , GraphSAGE, Mixhop and H2GCN :three foundational GNNs and two heterogeneous GNNs, used ascomparisons to evaluate the effectiveness of the proposed attackmodel in capturing privacy leakage from both proximity homophilyand structure-role homophily; (3) AttriInfer , ComInfer ,AI-N2V, AI-DW : four methods designed for private inference",
  "Ours66.69 (1.03) 89.39 (0.35) 68.80 (0.89) 90.01 (0.36) 83.32 (1.36)": "Baselines. We evaluate the performance of the proposed defensivemodel with five baselines, including: (1) Rand.: randomly droppingedges; (2) Deg./Betw. : dropping edges based on the degree orbetweenness centrality in descending order; (3) RABV : an edgeperturbation method that satisfies -edge local differential privacy,where each pair of symmetric bits in the adjacency matrix is per-turbed one and only one bit; (4) NetFense : a data publishingmethod against GNN-based inference attack on binary private at-tribute, the goal is to maintain data utility and protect privacy. Weadopt the multi-target setting as suggested in the paper. Comparative results. Utilizing our attack model as a worst-caseadversary due to its superior performance in prior tests, we exam-ine the privacy preservation performance by evaluating the attackmodels trained on the graphs generated by our defensive model andbaselines. For data utility, we assess downstream task performance.Specifically, a GNN-based classifier (the same implementation asGNNprox and MLP in 6.1) is employed to conduct node classifica-tion of each datasets label on the perturbed graphs. To ensure afair comparison, we fix the hyper-parameters for our attack modeland downstream classifier, while tuning the hyper-parameters ofeach defensive method to explore their privacy-utility trade-offs.We select the best three trade-off points for each method and vi-sualize them in . The upper-left corner of each sub-figurerepresents the ideal performance, with higher downstream perfor-mance and lower attack performance. Note that we also report thetrade-off performance of the two variants of our defensive model,namely (1) Ours-adv: only retaining adv and reg in Eq. (17) and(2) Ours-dis: only retaining dis and reg in Eq. (17). demonstrates that our defensive model consistentlyachieves the best privacy-utility trade-off on the five private at-tributes. Our variants Ours-adv and Ours-dis also demonstrate acommendable trade-off, such as in NBA country, Pokec-n age, and",
  "Ours0.192 0.118 1.759 0.945 0.392 0.073 3.279 0.694 2.498 0.998": "Pokec-z age. In contrast, methods such as Rand., Deg., and Eigen.do not take the private attribute into account during perturba-tion, thus compromising data utility. RABV exhibits suboptimalprivacy preservation effects when introducing additional noise tothe network structure. NetFense fails to adequately capture pri-vacy leakage from both structure-role homophily and proximityhomophily, thereby achieving less optimal trade-offs. In addition,it presents higher computational complexity. Evaluation of graph property change. To evaluate from abroader perspective, we characterize the utility by measuring theextent to which the sampled graph deviates from the original graph.Specifically, the properties of the published graph should closelyresemble those of the original graph. Therefore, we employ theMaximum Mean Discrepancy (MMD) distance as our evaluationmetric, comparing the degree distribution and clustering coefficientdistribution of the original graph with those of the published net-work under our model and baselines. To ensure fairness, we tunethe hyperparameters of these models to achieve comparable resultsin terms of privacy-preserving performance. The MMD scores in (the smaller, the better) demonstrate that our model outper-forms others on each dataset except for the Pokec-z region. Theseresults suggest that our model, while eliminating edges associatedwith privacy breaches, optimally preserves the remaining graphstructure, effectively maintaining data utility.",
  "Ours62.02 (0.19)31.92 (0.63)59.78 (0.11)60.86 (0.55)": "Evaluation of transferability. As our defensive model adoptsthe proposed inference as the worst-case adversary during training,we aim to assess its transferability. In other words, we evaluatewhether the defensive model can perform effectively against otherattribute inference attack models. reports the performanceof our defensive model compared with other baselines on Pokec-nage. The results show that our defensive model outperforms othermethods in protecting against various attack models, demonstratingits outstanding transferability.",
  "Related Work": "Private attribute inference. Early approaches to attribute in-ference have primarily focused on using user-individual publicattributes. These attributes include profile labels , textualcontent , and location information from users public posts. These approaches heavily rely on the correlation between pub-lic and hidden private attributes to build inference models. Despitetheir demonstrated effectiveness, these methods often overlookvaluable information from the connections between users, result-ing in a noticeable performance decline.Subsequent explorations of attribute inference leverage networkstructure and involve the utilization of graph propa-gation algorithms, such as GCN and MRF , to facilitate thepropagation of information across connected nodes. These mod-els aggregate information from adjacent nodes , leveragecommunity structures , or random walk to infer privateattributes. While they underscore the exploitation of proximityhomophily , they often overlook the other crucial aspect ofstructure-role homophily, thereby achieving less than optimal per-formance. Privacy-preserving learning on graph. In recent years, increas-ing attention has been given to the security and privacy issues ofgraph-based learning , among which privacy-preserving techniques play a crucial role in graph data publishing.Defense methods based on anonymization , sampling ,model training and differential privacy have been proposed. The anonymization methods face con-straints due to the need to mitigate operational complexities and often compromise privacy and utility for efficiency. The sampling-based method proposes an edge perturbation technique todefend against GNN-based inference on binary private attributes.However, it fails to consider privacy leaks from structural infor-mation and has high computational complexity. Regarding modeltraining-based defense methods , they often fall short whendealing with complex scenarios that require direct processing ofgraph data. In addition, differential privacy (DP) is a common pri-vacy protection technique. Early efforts extend DP tocorrelated settings, where data records are assumed to be correlatedwith each other (e.g., network structure). They primarily rely onnoise injection for privacy preservation. In contrast, our methodsystematically addresses the attack-defense problem by consideringthe complex relationships and structural patterns encompassed ingraph data. Recently, DP-DGAE perturbs the objective functionof graph auto-encoders to prevent attackers from re-identifyingnodes. Local DP allows individuals to locally perturb their graphmetrics, such as node degree and adjacency list before aggregationto mitigate the risk of privacy leakage . Striking a balancebetween utility and privacy remains a challenge for them in graphdata publication. Note that our method differs from DP in two keyaspects: first, the determination of the edge sampling probabilityin DP is established according to predetermined mechanisms withrespect to network structure. In contrast, our method learns thesampling probability based on the risks associated with GPS. Sec-ond, DP aims to preserve membership privacy, that is, altering onesample (e.g., node or edge) doesnt significantly change the outputdistribution, while the privacy we investigate in this work pertainsto attribute-wise privacy.",
  "Conclusion": "In this work, we delve into the problem of GPS and uncover theunderlying mechanisms, including structure-role homophily, prox-imity homophily, and their intricate interplay. Based on this un-derstanding, we introduce a novel data-centric approach for graphprivate attribute inference, capable of capturing privacy leaks fromthese mechanisms. Serving as the worst-case adversary, this methodprovides a comprehensive evaluation of potential privacy risks. Tocombat GPS, we propose a learnable graph sampling model forprivacy-preserving data publishing. Our model enhances privacysecurity by learning the risks associated with each edge in GPS. Ex-tensive experiments validate the effectiveness of our attack methodand demonstrate the advantageous balance achieved by our defen-sive model between privacy preservation and utility retention. This work was supported in part by NSFC (62206056, 92270121,72271059, 62322606, 62441605, 72101007), SMP-IDATA Open YouthFund, CCF-Tencent Rhino-Bird Open Research Fund, Joint Funds ofZhejiang Provincial NSFC (LHZSD24F020001), Zhejiang ProvinceLingYan\" Research and Development Plan Project (2024C01114),and Zhejiang Province High-Level Talents Special Support ProgramLeading Talent of Technological Innovation of Ten-Thousands Tal-ents Program\" (2022R52046).",
  "Rui Chen, Benjamin CM Fung, Philip S Yu, and Bipin C Desai. 2014. Correlatednetwork data publication via differential privacy. The VLDB Journal 23 (2014),653676": "Graham Cormode, Somesh Jha, Tejas Kulkarni, Ninghui Li, Divesh Srivastava,and Tianhao Wang. 2018. Privacy at scale: Local differential privacy in practice.In Proceedings of the 2018 International Conference on Management of Data. 16551658. Enyan Dai and Suhang Wang. 2021. Say no to the discrimination: Learning fairgraph neural networks with limited sensitive attribute information. In Proceedingsof the 14th ACM International Conference on Web Search and Data Mining. 680688.",
  "Enyan Dai and Suhang Wang. 2022. Learning fair graph neural networks with lim-ited and private sensitive attribute information. IEEE Transactions on Knowledgeand Data Engineering (2022)": "Ameya Daigavane, Gagan Madan, Aditya Sinha, Abhradeep Guha Thakurta,Gaurav Aggarwal, and Prateek Jain. 2021. Node-level differentially private graphneural networks. arXiv preprint arXiv:2111.15521 (2021). Xiaofeng Ding, Cui Wang, Kim-Kwang Raymond Choo, and Hai Jin. 2019. Anovel privacy preserving framework for large scale graph data publishing. IEEEtransactions on knowledge and data engineering 33, 2 (2019), 331343. Yuxiao Dong, Yang Yang, Jie Tang, Yang Yang, and Nitesh V Chawla. 2014. In-ferring user demographics and social strategies in mobile social networks. InProceedings of the 20th ACM SIGKDD international conference on Knowledge dis-covery and data mining. 1524. Vasisht Duddu, Antoine Boutet, and Virat Shejwalkar. 2020. Quantifying privacyleakage in graph embedding. In MobiQuitous 2020-17th EAI International Con-ference on Mobile and Ubiquitous Systems: Computing, Networking and Services.7685.",
  "Jim Isaak and Mina J Hanna. 2018. User data privacy: Facebook, CambridgeAnalytica, and privacy protection. Computer 51, 8 (2018), 5659": "Jinyuan Jia and Neil Zhenqiang Gong. 2018. {AttriGuard}: A practical defenseagainst attribute inference attacks via adversarial machine learning. In 27thUSENIX Security Symposium (USENIX Security 18). 513529. Jinyuan Jia, Binghui Wang, Le Zhang, and Neil Zhenqiang Gong. 2017. Attriinfer:Inferring user attributes in online social networks using markov random fields. InProceedings of the 26th International Conference on World Wide Web. 15611569.",
  "Jiwei Li, Alan Ritter, and Dan Jurafsky. 2014. Inferring user preferences by prob-abilistic logical reasoning over social networks. arXiv preprint arXiv:1411.2679(2014)": "Kaiyang Li, Guangchun Luo, Yang Ye, Wei Li, Shihao Ji, and Zhipeng Cai. 2020.Adversarial privacy-preserving graph embedding against inference attack. IEEEInternet of Things Journal 8, 8 (2020), 69046915. Muyuan Li, Haojin Zhu, Zhaoyu Gao, Si Chen, Le Yu, Shangqian Hu, and Kui Ren.2014. All your location are belong to us: Breaking mobile social networks forautomated user location tracking. In Proceedings of the 15th ACM internationalsymposium on Mobile ad hoc networking and computing. 4352. Tiancheng Li and Ninghui Li. 2009. On the tradeoff between privacy and utility indata publishing. In Proceedings of the 15th ACM SIGKDD international conferenceon Knowledge discovery and data mining. 517526.",
  "Junlong Liao, Wenda Fu, Cong Wang, Zhongyu Wei, and Jiarong Xu. 2024. Valueat Adversarial Risk: A Graph Defense Strategy Against Cost-Aware Attacks.(2024)": "Derek Lim, Felix Hohne, Xiuyu Li, Sijia Linda Huang, Vaishnavi Gupta, OmkarBhalerao, and Ser Nam Lim. 2021. Large scale learning on non-homophilousgraphs: New benchmarks and strong simple methods. Advances in Neural Infor-mation Processing Systems 34 (2021), 2088720902. Hongyi Ling, Zhimeng Jiang, Youzhi Luo, Shuiwang Ji, and Na Zou. 2022. Learn-ing fair graph representations via automated data augmentations. In The EleventhInternational Conference on Learning Representations. Xiangyu Liu, Chenghao Deng, Yanchao Sun, Yongyuan Liang, and Furong Huang.2024. Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies. arXiv preprint arXiv:2402.12673 (2024). Yang Liu, Xiang Ao, Fuli Feng, and Qing He. 2022. UD-GNN: Uncertainty-awareDebiased Training on Semi-Homophilous Graphs. In Proceedings of the 28th ACMSIGKDD Conference on Knowledge Discovery and Data Mining. 11311140.",
  "Mark EJ Newman. 2003. The structure and function of complex networks. SIAMreview 45, 2 (2003), 167256": "Nnamdi Johnson Ogbuke, Yahaya Y Yusuf, Kovvuri Dharma, and Burcu A Mercan-goz. 2022. Big data supply chain analytics: ethical, privacy and security challengesposed to business, industries and society. Production Planning & Control 33, 2-3(2022), 123137. Jahna Otterbacher. 2010. Inferring gender of movie reviewers: exploiting writ-ing style, content and metadata. In Proceedings of the 19th ACM internationalconference on Information and knowledge management. 369378.",
  "Anurag Ranjan, Joel Janai, Andreas Geiger, and Michael J Black. 2019. Attackingoptical flow. In Proceedings of the IEEE/CVF international conference on computervision. 24042413": "Delip Rao, David Yarowsky, Abhishek Shreevats, and Manaswi Gupta. 2010.Classifying latent user attributes in twitter. In Proceedings of the 2nd internationalworkshop on Search and mining user-generated contents. 3744. Leonardo FR Ribeiro, Pedro HP Saverese, and Daniel R Figueiredo. 2017. struc2vec:Learning node representations from structural identity. In Proceedings of the 23rdACM SIGKDD international conference on knowledge discovery and data mining.385394. Sina Sajadmanesh, Ali Shahin Shamsabadi, Aurlien Bellet, and Daniel Gatica-Perez. 2023. Gap: Differentially private graph neural networks with aggregationperturbation. In USENIX Security 2023-32nd USENIX Security Symposium. Salman Salamatian, Amy Zhang, Flavio du Pin Calmon, Sandilya Bhamidipati,Nadia Fawaz, Branislav Kveton, Pedro Oliveira, and Nina Taft. 2015. Managingyour private and public data: Bringing down inference attacks against your",
  "privacy. IEEE Journal of Selected Topics in Signal Processing 9, 7 (2015), 12401255": "Reza Shokri, George Theodorakopoulos, and Carmela Troncoso. 2016. Privacygames along location traces: A game-theoretic framework for optimizing locationprivacy. ACM Transactions on Privacy and Security (TOPS) 19, 4 (2016), 131. Susheel Suresh, Vinith Budde, Jennifer Neville, Pan Li, and Jianzhu Ma. 2021.Breaking the limit of graph neural networks by improving the assortativityof graphs with local mixing patterns. In Proceedings of the 27th ACM SIGKDDConference on Knowledge Discovery & Data Mining. 15411551.",
  "Petar Velikovi, Guillem Cucurull, Arantxa Casanova, Adriana Romero, PietroLio, and Yoshua Bengio. 2017.Graph attention networks.arXiv preprintarXiv:1710.10903 (2017)": "Binghui Wang, Jiayi Guo, Ang Li, Yiran Chen, and Hai Li. 2021.Privacy-preserving representation learning on graphs: A mutual information perspective.In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &Data Mining. 16671676. Song Wang, Yushun Dong, Binchi Zhang, Zihan Chen, Xingbo Fu, Yinhan He,Cong Shen, Chuxu Zhang, Nitesh V Chawla, and Jundong Li. 2024. Safety inGraph Machine Learning: Threats and Safeguards. arXiv preprint arXiv:2405.11034(2024). Le Wu, Yonghui Yang, Kun Zhang, Richang Hong, Yanjie Fu, and Meng Wang.2020. Joint item recommendation and attribute inference: An adaptive graphconvolutional network approach. In Proceedings of the 43rd International ACMSIGIR conference on research and development in Information Retrieval. 679688. Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, andS Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEEtransactions on neural networks and learning systems 32, 1 (2020), 424. Jiarong Xu, Yizhou Sun, Xin Jiang, Yanhao Wang, Chunping Wang, Jiangang Lu,and Yang Yang. 2022. Blindfolded attackers still threatening: Strict black-boxadversarial attacks on graphs. In Proceedings of the AAAI Conference on ArtificialIntelligence, Vol. 36. 42994307. Jiarong Xu, Yang Yang, Junru Chen, Xin Jiang, Chunping Wang, Jiangang Lu, andYizhou Sun. 2022. Unsupervised adversarially robust representation learning ongraphs. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 36.42904298. Jiarong Xu, Yang Yang, Shiliang Pu, Yao Fu, Jun Feng, Weihao Jiang, JiangangLu, and Chunping Wang. 2021. Netrl: Task-aware network denoising via deepreinforcement learning. IEEE Transactions on Knowledge and Data Engineering35, 1 (2021), 810823. Jiarong Xu, Yang Yang, Chunping Wang, Zongtao Liu, Jing Zhang, Lei Chen, andJiangang Lu. 2020. Robust network enhancement from flawed networks. IEEETransactions on Knowledge and Data Engineering 34, 7 (2020), 35073520.",
  "Bin Yang, Issei Sato, and Hiroshi Nakagawa. 2015. Bayesian differential privacy oncorrelated data. In Proceedings of the 2015 ACM SIGMOD international conferenceon Management of Data. 747762": "Liang Yang, Wenmiao Zhou, Weihang Peng, Bingxin Niu, Junhua Gu, ChuanWang, Xiaochun Cao, and Dongxiao He. 2022. Graph neural networks beyondcompromise between attribute and topology. In Proceedings of the ACM WebConference 2022. 11271135. Qingqing Ye, Haibo Hu, Man Ho Au, Xiaofeng Meng, and Xiaokui Xiao. 2020. LF-GDPR: A framework for estimating graph metrics with local differential privacy.IEEE Transactions on Knowledge and Data Engineering 34, 10 (2020), 49054920. Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He,Yanming Shen, and Tie-Yan Liu. 2021. Do transformers really perform badlyfor graph representation? Advances in Neural Information Processing Systems 34(2021), 2887728888. Hang Zhang, Yajun Yang, Xin Wang, Hong Gao, and Qinghua Hu. 2022. MLI: AMulti-level Inference Mechanism for User Attributes in Social Networks. ACMTransactions on Information Systems 41, 2 (2022), 130. Qinkai Zheng, Xu Zou, Yuxiao Dong, Yukuo Cen, Da Yin, Jiarong Xu, Yang Yang,and Jie Tang. 2021. Graph robustness benchmark: Benchmarking the adversarialrobustness of graph machine learning. arXiv preprint arXiv:2111.04314 (2021).",
  "Nannan Zhou, Shigong Long, Hai Liu, and Hai Liu. 2022. StructureAttributeSocial Network Graph Data Publishing Satisfying Differential Privacy. Symmetry14, 12 (2022), 2531": "Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and DanaiKoutra. 2020. Beyond homophily in graph neural networks: Current limitationsand effective designs. Advances in neural information processing systems 33 (2020),77937804. Tianqing Zhu, Ping Xiong, Gang Li, and Wanlei Zhou. 2014. Correlated differentialprivacy: Hiding information in non-IID data set. IEEE Transactions on InformationForensics and Security 10, 2 (2014), 229242.",
  "NotationDefinition": ",, Graph, node set, and edge set,Attribute matrix and adjacency matrix,Known/hidden private attributes, Sampled graph and sampled edge set()Homophily indicatorN (),()Neighborhood and ego networkGNNprox, GNNroleGNN encodersprox, roleNode representations, LInduced subgraph and Laplacian matrix()1-hop graph filter, Model parameters, ,Hyper-parametersInferred private attributesNumber of private attributes classesT,Sampling probability, sampled adjacency(), ()Probability and its empirical estimationSigmoid functionConcatenation operation",
  "A.3Training Algorithm and ComplexityAnalysis": "We divide our data publishing method into four computationalsteps, and we provide an analysis of the time complexity for eachstep.(1) Preprocessing: In this phase, we extract the subgraphs of allnodes. Let graph = (, ,), the complexity of extractionis ( ), where is the number of hops, is the number ofnodes, is the average degree of nodes. This step is computedonly once. (2) Sampling: In this phase, we compute the sampling probabilityfor each edge and perform graph sampling. The complexity ofobtaining node representations for each node through Graph-SAGE is (), where is the number of sampled neighbors, is the number of layers, and is the number of iterations. Here,we omit the time complexity of matrix operations. Then, obtain-ing edge sampling probability and performing sampling has acomplexity of (), where represents the number of edges.Therefore, the total complexity of this step is ( + ). (3) Inference: In this phase, we perform attribute inference on thesampled graph. Firstly, the time complexity of obtaining pre-dictions using GIN on the entire graph is (). To mitigatethe time overhead caused by repeated subgraph extraction, westore the global masks of corresponding edges in each nodes-hop subgraph during the preprocessing step. After each sam-pling step, we only need to determine which edges in the -hopsubgraph of each node are retained based on these masks. Andusing GIN on the subgraph for prediction has a time complex-ity of ( ). Thus, the overall complexity of this step is( ). (4) Loss calculation: the complexities of computing adv, dis, andreg are (), (( + )), and (), Where denotes theaverage degree (number of neighbors) for a node, and denotesthe average number of nodes with a similar degree to a givennode. The overall complexity of this step is (( + ) + )",
  ": Average sampling probabilities among differentsub-structures in Pokec-z": "further analyze how different local structures contribute to privacyinformation exposure. Based on the learned sampling probabili-ties of each edge, we calculate average edge sampling probabilitieswithin eight common sub-structures (as depicted in ). Ourfinding reveals a higher sampling rate for sub-structures with intri-cate topological characteristics, such as chordal cycles and 4-cliques.This pattern might be explained by the fact that these sub-structurescontain densely connected nodes, which makes disrupting themhave a pronounced impact on the entire network . Influence of graph size and quality. We evaluate the influenceof graph size and quality on the performance of our attack methodcompared to a competitive baseline, GraphSAGE.We first investigate the effect of graph size on the performance.We employ the Louvain community detection algorithm to partitionthe nodes in the NBA dataset into communities of various sizes.Specifically, we select two communities covering approximately 70%and 40% of the original graph. We then compare the performanceof the two methods on these subsets. The results are reported in. We find that the attack performance decreases as the graphsize shrinks, and our method consistently maintains an advantageover GraphSAGE.",
  "NBA country83.20 (0.83)82.85 (1.16)82.57 (0.95)83.32 (1.36)": "Evaluation on different downstream tasks. We chose link pre-diction as another downstream task. We set the training-testingedge ratio as 0.7:0.3 and use ROC-AUC as the metric. We reportedlink prediction performance under similar privacy-preserving per-formance. shows the comparison results on NBA of ourmodel and the most competitive baseline, Netfense. The resultsshow that our model achieves much higher link prediction perfor-mance while ensuring comparable privacy preservation. Evaluation of transferability We provide supplementary resultsto highlight our models transferability. As shown in , ourdefensive model can achieve the best protection result in most cases,and the second-best in the rest, confirming its notable transferability.",
  "Private attributeAdv. modelRand.Deg.Betw.RABVNetFenseOurs": "Pokec-z ageAttriInfer61.67 (0.79)62.31 (0.61)62.25 (0.86)61.31 (0.73)61.46 (1.17)61.02 (0.49)ComInfer37.91 (1.24)36.47 (0.07)37.37 (0.11)36.42 (0.29)36.85 (1.59)36.10 (0.63)AI-N2V59.03 (0.23)58.70 (0.78)58.64 (0.71)58.24 (0.61)58.91 (0.30)58.53 (0.48)AI-DW57.60 (0.46)58.64 (0.88)58.70 (0.51)57.72 (0.32)57.66 (0.71)57.40 (0.43) Pokec-n regionAttriInfer61.42 (0.48)60.17 (0.29)60.01 (0.82)59.52 (1.06)60.41 (0.46)58.99 (0.38)ComInfer61.20 (0.06)57.40 (0.17)60.91 (0.11)60.26 (0.07)59.39 (0.13)51.69 (0.47)AI-N2V69.54 (0.66)68.54 (0.43)67.92 (0.82)68.05 (1.98)68.65 (0.99)67.06 (0.65)AI-DW70.33 (1.12)67.79 (1.02)66.73 (0.46)68.61 (0.62)67.58 (0.95)65.29 (0.89) Pokec-z regionAttriInfer61.93 (0.31)60.32 (0.43)60.86 (0.44)59.01 (0.48)58.59 (0.64)58.66 (0.34)ComInfer52.20 (0.02)52.40 (0.11)51.99 (0.28)51.01 (0.21)51.87 (0.06)50.81 (0.41)AI-N2V66.23 (0.40)64.42 (0.55)66.12 (0.56)64.87 (0.57)65.93 (0.38)63.92 (1.22)AI-DW70.01 (1.82)65.75 (0.90)69.66 (0.81)67.09 (0.95)66.44 (1.56)63.07 (1.06) NBA countryAttriInfer63.12 (1.12)58.87 (1.24)62.17 (1.77)62.42 (0.92)63.41 (1.29)57.80 (0.33)ComInfer63.45 (0.56)63.54 (1.24)62.81 (0.59)63.45 (1.01)63.19 (1.84)61.48 (1.91)AI-N2V69.40 (1.58)67.98 (0.89)69.44 (1.22)67.97 (1.37)68.93 (2.66)66.43 (1.33)AI-DW68.60 (2.32)67.89 (3.09)69.37 (1.06)68.92 (1.95)66.87 (2.86)65.41 (2.03)"
}