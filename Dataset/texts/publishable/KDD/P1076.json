{
  "ABSTRACT": "Collaborative filtering recommender systems (CF-RecSys) haveshown successive results in enhancing the user experience on socialmedia and e-commerce platforms. However, as CF-RecSys strug-gles under cold scenarios with sparse user-item interactions, re-cent strategies have focused on leveraging modality informationof user/items (e.g., text or images) based on pre-trained modalityencoders and Large Language Models (LLMs). Despite their effec-tiveness under cold scenarios, we observe that they underperformsimple traditional collaborative filtering models under warm sce-narios due to the lack of collaborative knowledge. In this work,we propose an efficient All-round LLM-based Recommender sys-tem, called A-LLMRec, that excels not only in the cold scenariobut also in the warm scenario. Our main idea is to enable an LLMto directly leverage the collaborative knowledge contained in apre-trained state-of-the-art CF-RecSys so that the emergent abilityof the LLM as well as the high-quality user/item embeddings thatare already trained by the state-of-the-art CF-RecSys can be jointlyexploited. This approach yields two advantages: (1) model-agnostic,allowing for integration with various existing CF-RecSys, and (2) ef-ficiency, eliminating the extensive fine-tuning typically required forLLM-based recommenders. Our extensive experiments on variousreal-world datasets demonstrate the superiority of A-LLMRec invarious scenarios, including cold/warm, few-shot, cold user, andcross-domain scenarios. Beyond the recommendation task, we alsoshow the potential of A-LLMRec in generating natural languageoutputs based on the understanding of the collaborative knowledgeby performing a favorite genre prediction task. Our code is availableat",
  "Both authors contributed equally to this research.Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain. 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "Recommender System, Large Language Models, Collaborative Fil-tering": "ACM Reference Format:Sein Kim, Hongseok Kang, Seungyoon Choi, Donghyun Kim, Minchul Yang,and Chanyoung Park. 2024. Large Language Models meet CollaborativeFiltering: An Efficient All-round LLM-based Recommender System. In Pro-ceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery andData Mining (KDD 24), August 2529, 2024, Barcelona, Spain. ACM, NewYork, NY, USA, 12 pages.",
  "INTRODUCTION": "With the recent exponential growth in the number of users anditems, collaborative filtering models encounter thelong-standing cold-start problem , stemming from the in-herent sparsity of user-item interaction data. In other words, forusers/items with few interactions, it becomes challenging to con-struct collaborative knowledge with other similar users/items, lead-ing to suboptimal recommendation performance, especially in thecold-start scenarios. To overcome this issue, recent studies have fo-cused on leveraging modality information of users/items (e.g., userdemographics, item titles, descriptions, or images) to enhance rec-ommendation performance under cold-start scenarios. Specifically,MoRec utilizes pre-trained modality encoders (e.g., BERT or Vision-Transformer ) to project raw modality features ofitems (e.g., item texts or images), thereby replacing the item em-beddings typically used in collaborative filtering recommendationmodels. Similarly, CTRL considers tabular data and its tex-tual representation as two different modalities and uses them topre-train collaborative filtering recommendation models through acontrastive learning objective, which is then fine-tuned for specificrecommendation tasks.Despite the effectiveness of modality-aware recommender sys-tems in cold scenarios, the recent emergence of Large LanguageModels (LLMs), known for their rich pre-trained knowledge andadvanced language understanding capabilities, has attracted signif-icant interest in the recommendation domain to effectively extract 1An item is categorized as warm if it falls within the top 35% of interactions, and if itfalls within the bottom 35%, it is classified as a cold item.2After training each model using all the available data in the training set, we separatelyevaluate on cold and warm items in the test set.",
  "KDD 24, August 2529, 2024, Barcelona, Spain.Sein Kim, Hongseok Kang, Seungyoon Choi, Donghyun Kim, Minchul Yang, and Chanyoung Park": "Himan Abdollahpouri, Robin Burke, and Bamshad Mobasher. 2017. ControllingPopularity Bias in Learning-to-Rank Recommendation. In Proceedings of theEleventh ACM Conference on Recommender Systems (Como, Italy) (RecSys 17).Association for Computing Machinery, New York, NY, USA, 4246. Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He.2023. Tallrec: An effective and efficient tuning framework to align large languagemodel with recommendation. arXiv preprint arXiv:2305.00447 (2023).",
  "RELATED WORK2.1Collaborative Filtering": "Collaborative Filtering (CF) is the cornerstone of recommenda-tion systems, fundamentally relying on leveraging users historicalpreferences to inform future suggestions. The key idea is to relyon similar users/items for recommendations. The emergence ofmatrix factorization marked a significant advancement in CF, asevidenced by numerous studies , demonstrating its supe-riority in capturing the latent factors underlying user preferences.",
  "Large Language Models meet Collaborative Filtering: An Efficient All-round LLM-based Recommender SystemKDD 24, August 2529, 2024, Barcelona, Spain": "This evolution continued with the introduction of Probabilistic Ma-trix Factorization (PMF) and Singular Value Decomposition(SVD) , which integrate probabilistic and decompositiontechniques to further refine the predictive capabilities of CF models.AutoRec and Neural Matrix Factorization (NMF) utilizeddeep learning to enhance CF by capturing complex user-item in-teraction patterns. Recently, proposed modeling col-laborative filtering based on sequential interaction history. Caser and NextItNet utilize Convolutional Neural Networks(CNNs) to capture the local sequence information, treating anitem sequence as images. While these methods effectively captureuser preferences using interaction history, including user and itemIDs, they overlook the potential of the modality information of theuser/item, which could enhance model performance and offer adeeper analysis of user behaviors.",
  "Modality-aware Recommender Systems": "Modality-aware recommenders utilize modality information suchas item titles, descriptions, or images to enhance the recommen-dation performance mainly under cold scenarios. Initially, CNNswere used to extract visual features, modeling human visual pref-erences based on Mahalanobis distance . With advancementsin pre-trained modality encoders like BERT andResNet/Vision-Transformer , modality-aware recommendersystems have accelerated research by utilizing modality knowledgeon recommendation tasks. For example, NOVA and DMRL proposed non-invasive fusion and disentangled fusion of modality,respectively, by carefully integrating pure item embeddings andtext-integrated item embeddings using the attention mechanism.MoRec leverages modality encoders to project raw modalityfeatures, thereby replacing item embeddings used in collaborativefiltering models. As for the pre-training based models, Liu et al. constructs user-user and item-item co-interaction graphs to extractcollaborative knowledge, then integrates with user/item text infor-mation through attention mechanism in an auto-regressive manner,and CTRL pre-trains the collaborative filtering models usingpaired tabular data and textual data through a contrastive learn-ing objective, subsequently fine-tuning them for recommendationtasks. Most recently, RECFORMER proposed to model userpreferences and item features as language representations based onthe Transformer architecture by formulating the sequential recom-mendation task as the next item sentence prediction task, wherethe item key-value attributes are flattened into a sentence.",
  "LLM-based Recommender Systems": "Recently, research on LLMs has gained prominence in the field ofmodality-aware recommendation systems, with LLM-based recom-mendations emerging as a significant area of focus. The pre-trainedknowledge and the reasoning power of LLMs based on the advancedcomprehension of language are shown to be effective for recommen-dation tasks, and many approaches have been proposed leveragingLLM as a recommender system. More precisely, utilizeLLMs with In-context Learning , adapting to new tasks or in-formation based on the context provided within the input prompt.For example, Sanner et al. employs In-context Learning forrecommendation tasks, exploring various prompting styles such as completion, instructions, and few-shot prompts based on itemtexts and user descriptions. Gao et al. assigns the role of arecommender expert to rank items that meet users needs throughprompting and conducts zero-shot recommendations. These studiesempirically demonstrated the potential of LLMs using its rich iteminformation and natural language understanding in the recommen-dation domain. However, these approaches often underperformtraditional recommendation models , due to the gap be-tween the natural language downstream tasks used for trainingLLMs and the recommendation task . To bridge this gap, TALL-Rec employs the Parameter Efficient Fine-Tuning (PEFT) method,also known as LoRA . This methodology enables TALLRec todemonstrate enhanced efficacy, surpassing traditional collaborativefiltering recommendation models, particularly in mitigating thechallenges posed by the cold start dilemma and in navigating thecomplexities of cross-domain recommendation scenarios. However,it is important to note that since TALLRec simply converts the con-ventional recommendation task into an instruction text and uses itfor fine-tuning, it still fails to explicitly capture the collaborativeknowledge that is crucial in warm scenarios.",
  "PROBLEM FORMULATION": "In this section, we introduce a formal definition of the problemincluding the notations and the task description.Notations. Let D denote the historical user-item interaction dataset(U, I, T, S) D, where U, I, T, and S denote the set of users,items, item titles/descriptions, and item sequences, respectively.S = (1,2, ,, |S |) S is a sequence of item interac-tions of a user U, where denotes the -th interaction of user, and this corresponds to the index of the interacted item in theitem set I. Moreover, each item I is associated with title anddescription text (,) T.Task: Sequential Recommendation. The goal of sequential rec-ommendation is to predict the next item to be interacted with by auser based on the users historical interaction sequence. Given a setof user historical interaction sequences S =S1, S2, , S|U|,where S denotes the sequence of user , the subset S1: S represents the sequence of user from the first to the -th itemdenoted as S1: = (1,2, , ). Given an item embedding matrixE R| |, the embedding matrix of items in S1: is denoted byE1: = (E1 , E2 , ..., E ) R, where E denotes the -th rowof E. This sequence embedding matrix is fed into a collaborativefiltering recommender (e.g., SASRec ) to learn and predict thenext item in the user behavior sequence S1: as follows:",
  "=1 (+1|S1:; )(1)": "where (+1|S1:; ) represents the probability of the ( + 1)-thinteraction of user conditioned on the users historical interactionsequence S1:, and denotes the set of learnable parameters of thecollaborative filtering recommender (CF-RecSys). By optimizing to maximize Equation 1, the model can obtain the probability ofthe next items for user , over all possible items.It is important to note that although we mainly focus on the se-quential recommendation task in this work, A-LLMRec can also be",
  "PROPOSED METHOD: A-LLMREC": "In this section, we propose A-LLMRec, a novel LLM-based recom-mender framework that aligns a frozen pre-trained collaborativefiltering recommender (CF-RecSys) with a frozen LLM aiming toenhance the recommendation performance not only in the coldscenario but also in the warm scenario. To bridge the modalitygap, A-LLMRec aligns collaborative knowledge of the CF-RecSyswith the token space of the LLM. Our approach involves two pre-training stages: (1) Aligning collaborative and textual knowledgewith a frozen CF-RecSys (.1), and (2) Recommendationstage with a frozen LLM (.2) in which the joint collabora-tive and textual knowledge is projected onto the LLM.",
  "Alignment between Collaborative andTextual Knowledge (Stage-1)": "In this section, we introduce how to align the item embeddingsfrom a frozen CF-RecSys with their associated text information tocapture both collaborative and textual knowledge. We employ a pre-trained Sentence-BERT (SBERT) model, which is fine-tunedduring training, to extract text embeddings from textual informa-tion associated with items3. Then, we introduce two encoders, i.e.,item encoder and text encoder , each containing a 1-layerMulti-Layer Perceptron (MLP), to align the item embeddings froma frozen CF-RecSys with the text embeddings from SBERT. Givenan item , the item encoder : R R encodes an itemembedding E R into a latent item embedding e R, i.e.,e = (E), while the text encoder : R768 R encodes atext embedding Q R768 from SBERT, whose output dimensionsize is 768, into a latent text embedding q R, i.e., q = (Q).Then, we perform latent space matching between item embeddingsand text embeddings as follows:",
  "Although using a larger language model, such as OPT and LLaMA , wouldfurther enhance the quality of the text embeddings, we adopt SBERT for efficiency": "where Q = SBERT( : , : ) denotes the en-coded representation of item text (i.e., item title and description)by SBERT, and is the mean squared error loss. That is, wematch the item embeddings from a frozen CF-RecSys and the textembeddings from SBERT in the latent space of the encoders, so asto align the semantics of items and their associated texts for lateruse in the LLM. 4.1.1Avoiding Over-smoothed Representation. On the other hand,simply optimizing the latent space matching loss defined in Equa-tion 2 would result in over-smoothed representations, i.e., the en-coders would be trained to produce similar outputs (i.e., e q)to minimize Lmatching. In an extreme case, the output of the en-coders would be collapsed to a trivial representation by assigningtheir weights to all zeros. Hence, to prevent this issue and preservethe original information of the item and its associated text em-bedding, we add a decoder to each of the encoders and introducereconstruction losses as follows:",
  "Lstage-1 = Lmatching + Litem-recon + Ltext-recon + Lrec(6)": "where and are the coefficients that control the importance ofeach term. Note that for efficiency in training, we only consideredthe last item in S for each user to minimize Lstage-1. However,considering all items in the sequence further enhances the recom-mendation performance, which will be shown in .4.2. 4.1.4Joint Collaborative-Text Embedding. Having trained the au-toencoder based on Equation 6, we consider e = (E) as thejoint collaborative-text embedding (shortly joint embedding) ofitem , which will be passed to the LLM as input. The joint embed-ding introduces the collaborative and textual knowledge to LLMs,which will be described in .2.It is important to note that when encountering new items thathave not been seen during the training of the collaborative filter-ing recommender, we can instead rely on the text encoder toextract the joint collaborative-text embedding, i.e., q = (Q).Since the two encoders and are jointly trained to matchtheir latent spaces, we expect the joint embedding q to not onlycapture the textual knowledge but also to implicitly capture the col-laborative knowledge. In summary, we use e = (E) as the jointcollaborative-text embedding by default, but we use q = (Q)when item lacks interactions, i.e., cold item, few-shot, and cross-domain scenarios, which will be demonstrated in the experimentsin .2.2, .2.4, and .2.5, respectively.",
  "Alignment between Joint Collaborative-TextEmbedding and LLM (Stage-2)": "Recall that in Stage-1 we obtained the joint collaborative-text em-beddings by aligning the collaborative knowledge with item textualinformation. Our goal in Stage-2 is to align these joint embeddingswith the token space of the LLM (.2.1), and design a promptthat allows the LLM to solve the recommendation task by leverag-ing the learned collaborative knowledge (.2.2). shows the overall architecture of Stage-2. Note that the componenttrained in Stage-1, which is also utilized in Stage-2, i.e., , isfrozen in Stage-2. 4.2.1Projecting collaborative knowledge onto the token space ofLLM. We first project the user representations x R and thejoint collaborative-text embeddings e R obtained from Stage-1onto the token space of LLM, i.e., Rtoken. By doing so, we allowthe LLM to take them as inputs. More precisely, we introduce two2-layer MLPs, i.e., : R Rtoken and : R Rtoken, toproject the user representations and the joint collaborative-textembeddings to the token space of LLM, respectively, as follows:",
  "O = (x ), O = (e )(7)": "where O Rtoken and O Rtoken are the projected embeddingsof the representation of user and the joint collaborative-textembedding of item , and they can now be used as inputs to LLMprompts, which allow the LLM to perform recommendation withoutany fine-tuning. [User Representation] is a user representation.This user has watched [HISTORY (Item Titles, Item Emb)]in the past. Recommend a movie for this user to watch next from the following set of movie titles, [CANDIDATE (Item Titles, Item Emb)]. The recommendation is",
  ": An example prompt of A-LLMRec designed for theAmazon Movies dataset. For other datasets, we keep the sameformat but adjust the verbs and nouns to fit the context (e.g.,watched bought, movie item)": "4.2.2Prompt Design for Integrating Collaborative Knowledge. Promptengineering helps in understanding the capabilities and limitationsof LLMs, enabling them to perform complex tasks such as questionanswering and arithmetic reasoning . Recent studies on LLM-based recommender systems have shown that carefully craftedprompts enhance the performance of LLMs . However, asexisting LLM-based recommender systems focus on cold scenarioswith few user-item interactions, their prompts mainly considerways to incorporate modality information (e.g., item descriptiontext), while overlooking the collaborative knowledge. To this end,we introduce a novel approach to prompt design for LLM-based rec-ommender system, which combines collaborative knowledge withrecommendation instructions (See ). This is done by directlyincorporating user representations O and joint collaborative-textembeddings O into the textual prompts in the token embeddingspace. In other words, as O and O have been projected into theLLM token space, they can be considered as ordinary tokens usedby the LLM and readily incorporated within a prompt. To facilitatethe understanding of the LLM regarding the given user, which iscrucial for personalized recommendation, we place the projecteduser representation O at the beginning of the prompt to providethe LLM with the information about users, which is analogous tosoft prompts . Moreover, we add the projected joint embeddingof an item O next to its title. This structured prompt then serves asan input to the LLM, with the expected output being recommenda-tions tailored to the user. The learning objective of Stage-2 is givenas follows:",
  "=1(,( |, < ))(8)": "where denotes the learnable parameters of and , is thefrozen parameters of LLM, and are the input prompt and thenext item title of user , respectively. is the -th token of and< represents the tokens before . Note that we only use the lastitem of each user sequence to train Equation 8 for efficiency.",
  "Movies and TV To evaluate the models on a large scale, weselect about 300K users and 60K items. Following existing stud-ies , we removed users and items with fewer than 5interactions": "Video Games To evaluate the models on moderate-scale data,which is smaller than the Movies and TV dataset, we selectabout 64K users and 33K items, removing users and items withfewer than 5 interactions, as in the Movies and TV dataset. Beauty To compose a small and cold dataset, we select about9K users and 6K items, removing users and items with fewerthan 4 interactions. To retain some information from user-itemfeedback, we categorized user ratings by treating items above3 as positive and all others including non-interacted items asnegative. Toys For the evaluation of the models where the number ofitems is larger than number of users, unlike other datasets, weselect about 3K users and 6K items, with the number of itemsbeing twice as large as the number of users, and remove usersand items with fewer than 4 interactions. Similar to the Beautydataset, to preserve some information from user-item feedback,we categorize positive and negative items with the criterion ofrating 3. Baselines. We compare A-LLMRec with the following baselinesthat can be categorized into three types: collaborative filteringrecommender systems (NCF , NextItNet , GRU4Rec andSASRec ), modality-aware recommender systems (MoRec ,CTRL , and RECFORMER ), and LLM-based recommendersystems (LLM-Only, TALLRec and MLP-LLM). For more detailregarding the baselines, please refer to Appendix A Evaluation Setting. We divide user sequences into training, val-idation, and test sets. For each user sequence, the most recentlyinteracted item, denoted as |S |, is used as the test set, while thesecond most recent user interaction item, |S |1, is used as the",
  "Toys0.00010.0001501280.50.2": "validation set. The remaining sequence of items is used as the train-ing set. To evaluate the performance of sequential recommendationmodels, we add 19 randomly selected non-interacted items to thetest set, so that the test set of each user contains 1 positive itemand 19 negative items. For quantitative comparison, we employ awidely used metric, Hit Ratio at 1 (Hit@1) for all experiments. Implementation Details. Although A-LLMRec is model-agnostic,in this work, we adopt OPT-6.7B as the backbone LLM andSASRec as the pre-trained CF-RecSys. For fair comparisons,we also used OPT-6.7B as the backbone LLM for other LLM-basedmodels (i.e., LLM-Only, TALLRec and MLP-LLM). Moreover,we use SASRec as the CF-RecSys in other modality-aware models(i.e., MoRec and CTRL ), and fix the dimension of itemand model embeddings to 50 for all the methods and datasets. ForRECFORMER , we follow the paper and employ Longformer as the backbone network. We set the batch size to 128 for all col-laborative filtering-based and modality-aware models. Moreover,the batch size is set to 32 for Stage-1 of A-LLMRec, and 4 for MLP-LLM, TALLRec, and Stage-2 of A-LLMRec. We trained Stage-1 ofA-LLMRec for 10 epochs, and Stage-2 of A-LLMRec for 5 epochs,and TALLRec is trained for a maximum of 5 epochs. We use theAdam optimizer to train the models in all datasets. For hyperpa-rameters, we tune the model in certain ranges as follows: learningrate 1,2 in {0.01, 0.001, 0.0005, 0.0001} for the training stage each,coefficient , in {0.1, 0.2, 0.5, 0.75, 1.0} for each, we report the best-performing hyper-parameters for each dataset in . We usefour NVIDIA GeForce A6000 48GB for the Movies and TV datasetto train LLM-based models, and one NVIDIA GeForce A6000 48GBfor other datasets including LLM-based and other models.",
  "Performance Comparison": "For comprehensive evaluations of A-LLMRec, we perform evalu-ations under various scenarios, i.e., general scenario (Sec. 5.2.1),cold/warm item scenario (Sec. 5.2.2), cold user scenario (Sec. 5.2.3),few-shot training scenario (Sec. 5.2.4), cross-domain scenario (Sec. 5.2.5). 5.2.1Overall Performance. The results of the recommendationtask on four datasets are given in . We have the followingobservations: 1) A-LLMRec outperforms other LLM-based recom-mender systems that do not consider the collaborative knowledge",
  "A-LLMRec (SBERT)0.57720.68020.43590.57920.55910.6405": "from user-item interactions (i.e., LLM-Only and TALLRec), imply-ing that the collaborative knowledge is crucial for improving theperformance of recommendation in general. 2) We observe thatMLP-LLM, which replaces the alignment module of A-LLMRec witha simple MLP, underperforms A-LLMRec. This implies that bridgingbetween CF-RecSys and LLM is a challenging problem and thatour proposed two-stage alignment module is beneficial. 3) LLM-Only performs the worst among the LLM-based models, implyingthat naively adopting an LLM based on a prompt designed for therecommendation task is not sufficient. Note that the prompt usedby LLM-Only is exactly the same as the prompt shown in Fig-ure 3 without user representation and item embeddings. This againdemonstrates the importance of incorporating collaborative knowl-edge into the LLM for improving the recommendation performance.4) While TALLRec fine-tunes the LLM for the recommendation task,it underperforms a collaborative filtering model, SASRec. This high-lights that the text information alone may not generate sufficientknowledge for capturing collaborative knowledge effectively evenwith fine-tuning the LLM. This again demonstrates the superiorityof our alignment module. 5) Although the modality-aware models(MoRec and CTRL) use SASRec as the backbone CF-RecSys, theyunderperform SASRec. Moreover, RECFORMER struggles to out-perform SASRec despite using Longformer for item text attributes,due to the emphasis on textual information in similarity matchingbetween user and item sentences. This shows that the modalityknowledge might hinder the learning of collaborative knowledge,leading to performance degradation. 5.2.2Cold/Warm Item Scenarios. This section evaluates the mod-els under cold/warm item scenarios. Items are labeled as warm ifthey belong to the top 35% of interactions, while those in the bottom35% are labeled as cold items. After training each model using allthe available data in the training set, we separately evaluate coldand warm items in the test set (). We make the followingobservations: 1) A-LLMRec outperforms all other baselines acrossboth scenarios, which demonstrates that our alignment networkindeed allows the LLM to understand and utilize the collaborativeknowledge. 2) On the other hand, TALLRec outperforms SASReconly under cold scenario, whereas SASRec outperforms TALLReconly under warm scenario. This demonstrates the importance ofcapturing both the collaborative knowledge and the text informa-tion to excel in both cold/warm scenarios. 3) A-LLMRec (SBERT)outperforms A-LLMRec under the cold item scenario, while A-LLMRec generally outperforms A-LLMRec (SBERT) under the warmitem scenario. As discussed in .1.4, this implies that the",
  "Movies and TV Video Games0.05060.06240.08470.07850.09010.1203": "5.2.5Cross-domain Scenario. To further investigate the general-ization ability of A-LLMRec, we evaluate the models on the cross-domain scenario, where the models are evaluated on datasets thathave not been used for training (). Specifically, we pre-trainthe models on the Movies and TV dataset and perform evaluationson the Video Games dataset. We have the following observations:1) A-LLMRec outperforms all the baselines in the cross-domainscenario, and A-LLMRec (SBERT) particularly performs well. Thisis again attributed to the text encoder that becomes useful whencollaborative information is lacking. 2) SASRec underperformsmodality-aware models and LLM-based models, indicating that us-ing textual knowledge is crucial for the cross-domain scenario dueto the lack of collaborative information.",
  "Freeze SBERT0.61730.55650.1720": "5.3.1Effect of Components in Stage-1. This section presents theexperimental results showing the benefit of each component duringthe Stage-1. Across all datasets, the exclusion of any loss resultedin decreased performance. We make the following observations:1) Removing Lmatching from in Equation 2 results in a significantperformance decline across all datasets. This implies that the align-ment between the item and the text information is effective andthat the LLM can comprehend item textual information in jointcollaborative-text embeddings to enhance recommendation capa-bilities. 2) Removing Litem-recon and Ltext-recon leads to perfor-mance drop, owing to the risk of over-smoothed representations(i.e., e q), as discussed in .1.1. 3) We observe that remov-ing Lrec leads to performance drop. Since L is introduced toexplicitly incorporate the collaborative knowledge while informingthe model about the recommendation task, the performance dropindicates the reduction of collaborative knowledge between itemsand users, which is crucial for recommendation tasks. 4) Lastly,we kept SBERT frozen while training A-LLMRec. We observe thatfreezing SBERT leads to poor performance across all datasets. Thisimplies that fine-tuning SBERT facilitates the text embeddings toadapt to the recommendation task.5.3.2Effect of the Alignment method in Stage-2. Recall that a userrepresentation and item embeddings are injected to the LLM prompt",
  "(4)A-LLMRec with random joint embedding0.12000.47290.54270.0776": "as shown in . In this section, we verify the benefit of in-jecting them into the prompt (rows (2-4) in ). We have thefollowing observations: Across all datasets, 1) the absences of ei-ther the user representation (row (2)) or the joint embedding (row(3)) from the prompt led to a reduction in performance. Notably,the exclusion of the joint embedding results in a more substantialdecrease, underscoring its significant role in transferring collab-orative knowledge. Moreover, as joint embeddings also capturethe textual information about items, their exclusion is particularlydetrimental. 2) When we replace the joint embedding with a ran-domly initialized embedding (row (4)), which means A-LLMRec istrained with item embeddings without collaborative knowledge,we observe performance degradation across all datasets. This indi-cates the importance of leveraging the collaborative knowledge forrecommendation.",
  "Model Analysis": "5.4.1Train/Inference Speed. Recall that A-LLMRec requires thefine-tuning of neither the CF-RecSys nor the LLM. Specifically, A-LLMRec efficient in that the alignment network is the only trainableneural network, while TALLRec requires the fine-tuning of theLLM with LoRA. In this section, we compare the training and theinference time of A-LLMRec and TALLRec. As for the trainingtime, we measured the total time spent until the end of training,and as for the inference time, we measured the time spent permini-batch. shows that A-LLMRec exhibits significantlyfaster training and inference time compared with TALLRec. No-tably, a more substantial improvement is observed in training time,since A-LLMRec does not require the LLM to be fine-tuned unlikeTALLRec, which demonstrates the applicability of LLM in large-scale recommendation datasets. Moreover, the faster inference timedemonstrates the practicality of A-LLMRec in real-world scenar-ios, especially in the context of real-time recommendation serviceswhere inference time is critically important. 5.4.2Training with all items in each sequence. Recall that for effi-ciency in training, we used only the last item of each user sequencewhen optimizing the final loss in Stage-1 (Equation 6) and Stage-2(Equation 8) of A-LLMRec. In this section, we report the recommen-dation performance in terms of Hit@1 and train/inference speedwhen using all items in each user sequence for optimization (seeA-LLMRecall in ). We observe that as expected the recom-mendation performance is further improved when using all itemsin each user sequence. However, considering that the training timealso increased approximately 3 times, the improvement seems mar-ginal. It is important to note that since vanilla A-LLMRec is trainedbased on only the last item in each user sequence, there is a largeamount of unseen/new items that appear in the test set4. However,",
  "valilla A-LLMRec still showed comparable performance with A-LLMRecall, implying the generalization ability of A-LLMRec": "5.4.3A-LLMRec is Model-Agnostic. Although A-LLMRec adoptsSASRec as the backbone CF-RecSys, it can be replaced with anyexisting collaborative filtering recommender systems, thanks to themodel-agnostic property. Hence, we adopt three other collaborativefiltering recommender systems including two sequential recom-menders (i.e., NextItNet and GRU4Rec), and one non-sequentialrecommender (i.e., NCF) to A-LLMRec. We make the followingobservations from . 1) Adopting the SASRec backbone per-forms the best, which is expected since SASRec outperforms otherCF-RecSys in their vanilla versions. This implies that transferringhigh-quality collaborative knowledge can enhance the performanceof A-LLMRec. 2) Adopting A-LLMRec to any backbone improvesthe performance of the vanilla model. This implies that if the SOTAmodel changes in the future, our framework has the potential tofurther improve performance by replacing the existing CF-RecSysin the framework. 3) We observe that while the performance differ-ence between SASRec and NCF is nearly double when they operateas standalone CF-RecSys, the integration with A-LLMRec, whichleverages the modality of item text information and the intensivecapabilities of LLM, reduces this performance gap.",
  ": A-LLMRec v.s. LLM-Only on the favorite genre pre-diction task (Movies and TV dataset used)": "5.4.4Beyond Recommendation: Language Generation Task (Favoritegenre prediction). To validate whether A-LLMRec can generate natu-ral language outputs based on the understanding of users and itemsthrough the aligned collaborative knowledge from CF-RecSys, weconduct a favorite genre prediction task (). That is, giventhe same prompt format, we ask the LLM-based models (i.e., A-LLMRec and LLM-Only) using the same backbone LLM, which isOPT-6.7B, to predict the movie genres that a given user would enjoywatching. The only difference in the prompt is that while LLM-onlyis only given titles of movies watched by the user in the past, A-LLMRec is given the user representation and item embeddings alongwith the movie titles. In , we observe that A-LLMRec in-deed generates proper answers, while LLM-Only fails to do so. Weattribute this to the fact that the item embeddings of the CF-RecSysare well aligned with the token space of the LLM, which enablesthe LLM to understand and utilize collaborative knowledge. Notethat although we also experimented with TALLRec, we were notable to obtain valid outputs. We conjecture that since the LLM inTALLRec is fine-tuned via an instruction-tuning process that makesthe model provide responses as part of the recommendation task,generating valid natural language outputs has become a non-trivialtask. Please refer to Appendix B for the results of TALLRec.",
  "CONCLUSION": "In this paper, we propose a novel LLM-based recommender system,named A-LLMRec. The main idea is to enable LLMs to utilize thecollaborative knowledge from pre-trained CF-RecSys. By doingso, A-LLMRec outperforms existing CF-RecSys, modality-awarerecommender systems, and LLM-based recommenders under vari-ous scenarios including cold/warm items, cold user, few-shot, andcross-domain scenarios. Moreover, we also demonstrate that thetwo advantages originated from fine-tuning neither pre-trainedCF-RecSys nor LLMs, i,e, Model-agnostic and efficiency. Lastly, weshow the potential of A-LLMRec in generating natural languagetasks based on the understanding of collaborative knowledge fromCF-RecSys. For future work, we plan to further enhance the abilityof the LLM in A-LLMRec based on advanced prompt engineeringsuch as chain-of-thought prompting .Ethics Statement To the best of our knowledge, this paper alignswith the KDD Code of Ethics without any ethical concerns. Thedatasets and codes employed in our research are publicly available. This work was supported by NAVER Corporation, the NationalResearch Foundation of Korea(NRF) grant funded by the Korea gov-ernment(MSIT) (RS-2024-00335098), and National Research Foun-dation of Korea(NRF) funded by Ministry of Science and ICT (NRF-2022M3J6A1063021).",
  "Iz Beltagy, Matthew E Peters, and Arman Cohan. 2020. Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150 (2020)": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shot learners. Advances in neuralinformation processing systems 33 (2020), 18771901. Allison JB Chaney, David M Blei, and Tina Eliassi-Rad. 2015. A probabilistic modelfor using social networks in personalized item recommendation. In Proceedingsof the 9th ACM Conference on Recommender Systems. 4350. Jiawei Chen, Hande Dong, Yang Qiu, Xiangnan He, Xin Xin, Liang Chen, Guli Lin,and Keping Yang. 2021. AutoDebias: Learning to Debias for Recommendation(SIGIR 21). Association for Computing Machinery, New York, NY, USA, 2130. Chen Cheng, Haiqin Yang, Michael R. Lyu, and Irwin King. 2013. Where youlike to go next: successive point-of-interest recommendation. In Proceedings ofthe Twenty-Third International Joint Conference on Artificial Intelligence (Beijing,China) (IJCAI 13). AAAI Press, 26052611.",
  "Robert G. Cooper and Scott J. Edgett. 2012. Best Practices in the Idea-to-LaunchProcess and Its Governance. Research Technology Management 55, 2 (2012), 4354": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.BERT: Pre-training of Deep Bidirectional Transformers for Language Under-standing, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Associationfor Computational Linguistics, Minneapolis, Minnesota, 41714186. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, GeorgHeigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby. 2021. An Image isWorth 16x16 Words: Transformers for Image Recognition at Scale. In InternationalConference on Learning Representations. Xiaoyu Du, Zike Wu, Fuli Feng, Xiangnan He, and Jinhui Tang. 2022.In-variant Representation Learning for Multimedia Recommendation. In Pro-ceedings of the 30th ACM International Conference on Multimedia (<conf-loc>,<city>Lisboa</city>, <country>Portugal</country>, </conf-loc>) (MM 22). As-sociation for Computing Machinery, New York, NY, USA, 619628. Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and JiaweiZhang. 2023. Chat-rec: Towards interactive and explainable llms-augmentedrecommender system. arXiv preprint arXiv:2303.14524 (2023). Ruining He and Julian McAuley. 2016.Ups and Downs: Modeling the Vi-sual Evolution of Fashion Trends with One-Class Collaborative Filtering. InProceedings of the 25th International Conference on World Wide Web (Mon-tral, Qubec, Canada) (WWW 16). International World Wide Web Confer-ences Steering Committee, Republic and Canton of Geneva, CHE, 507517. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and MengWang. 2020. Lightgcn: Simplifying and powering graph convolution network forrecommendation. In Proceedings of the 43rd International ACM SIGIR conferenceon research and development in Information Retrieval. 639648.",
  "Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech-niques for recommender systems. Computer 42, 8 (2009), 3037": "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. ImageNet Clas-sification with Deep Convolutional Neural Networks. In Advances in NeuralInformation Processing Systems, F. Pereira, C.J. Burges, L. Bottou, and K.Q. Wein-berger (Eds.), Vol. 25. Curran Associates, Inc. Jiacheng Li, Ming Wang, Jin Li, Jinmiao Fu, Xin Shen, Jingbo Shang, and JulianMcAuley. 2023. Text Is All You Need: Learning Language Representations forSequential Recommendation (KDD 23). Association for Computing Machinery,New York, NY, USA, 12581267.",
  "Xiangyang Li, Bo Chen, Lu Hou, and Ruiming Tang. 2023. CTRL: Connect Tabularand Language Model for CTR Prediction. arXiv preprint arXiv:2306.02841 (2023)": "Xiang Lisa Li and Percy Liang. 2021. Prefix-Tuning: Optimizing ContinuousPrompts for Generation. In Proceedings of the 59th Annual Meeting of the Associa-tion for Computational Linguistics and the 11th International Joint Conference onNatural Language Processing (Volume 1: Long Papers). Chang Liu, Xiaoguang Li, Guohao Cai, Zhenhua Dong, Hong Zhu, and LifengShang. 2021. Noninvasive self-attention for side information fusion in sequentialrecommendation. In Proceedings of the AAAI Conference on Artificial Intelligence,Vol. 35. 42494256.",
  "Chih-Chao Ma. 2008. A guide to singular value decomposition for collaborativefiltering. Computer (Long Beach, CA) 2008 (2008), 114": "Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton van den Hengel.2015. Image-Based Recommendations on Styles and Substitutes (SIGIR 15).Association for Computing Machinery, New York, NY, USA, 4352. Julian McAuley, Christopher Targett, Qinfeng Shi, and Anton Van Den Hengel.2015. Image-based recommendations on styles and substitutes. In Proceedingsof the 38th international ACM SIGIR conference on research and development ininformation retrieval. 4352.",
  "Nils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddingsusing siamese bert-networks. arXiv preprint arXiv:1908.10084 (2019)": "Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factor-izing personalized Markov chains for next-basket recommendation. In Proceedingsof the 19th International Conference on World Wide Web (Raleigh, North Carolina,USA) (WWW 10). Association for Computing Machinery, New York, NY, USA,811820. Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, and Lucas Dixon.2023. Large language models are competitive near cold-start recommenders forlanguage-and item-based preferences. In Proceedings of the 17th ACM conferenceon recommender systems. 890896. Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-basedcollaborative filtering recommendation algorithms. In Proceedings of the 10thinternational conference on World Wide Web. 285295. Suvash Sedhain, Aditya Krishna Menon, Scott Sanner, and Lexing Xie. 2015.Autorec: Autoencoders meet collaborative filtering. In Proceedings of the 24thinternational conference on World Wide Web. 111112. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep-resentations from transformer. In Proceedings of the 28th ACM internationalconference on information and knowledge management. 14411450. Jiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommenda-tion via convolutional sequence embedding. In Proceedings of the eleventh ACMinternational conference on web search and data mining. 565573. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-AnneLachaux, Timothe Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, et al. 2023. Llama: Open and efficient foundation language models. arXiv",
  "Lei Wang and Ee-Peng Lim. 2023. Zero-Shot Next-Item Recommendation usingLarge Pretrained Language Models. arXiv preprint arXiv:2304.03153 (2023)": "Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, SebastianBorgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al.2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682(2022). Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi,Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting elicits reasoningin large language models. Advances in Neural Information Processing Systems 35(2022), 2482424837. Yinwei Wei, Xiang Wang, Liqiang Nie, Xiangnan He, Richang Hong, and Tat-SengChua. 2019. MMGCN: Multi-modal Graph Convolution Network for PersonalizedRecommendation of Micro-video (MM 19). Association for Computing Machin-ery, New York, NY, USA, 14371445. Likang Wu, Zhi Zheng, Zhaopeng Qiu, Hao Wang, Hongchao Gu, Tingjia Shen,Chuan Qin, Chen Zhu, Hengshu Zhu, Qi Liu, et al. 2023. A Survey on LargeLanguage Models for Recommendation. arXiv preprint arXiv:2305.19860 (2023). Jieyu Yang, Liang Zhang, Yong He, Ke Ding, Zhaoxin Huan, Xiaolu Zhang, andLinjian Mo. 2023. DCBT: A Simple But Effective Way for Unified Warm and ColdRecommendation. In Proceedings of the 46th International ACM SIGIR Conferenceon Research and Development in Information Retrieval (SIGIR 23). Association forComputing Machinery, New York, NY, USA, 33693373. Fajie Yuan, Alexandros Karatzoglou, Ioannis Arapakis, Joemon M Jose, and Xi-angnan He. 2019. A simple convolutional generative network for next itemrecommendation. In Proceedings of the twelfth ACM international conference onweb search and data mining. 582590. Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, YunzhuPan, and Yongxin Ni. 2023. Where to Go Next for Recommender Systems? ID-vs. Modality-based Recommender Models Revisited (SIGIR 23). Association forComputing Machinery, New York, NY, USA, 26392649. Susan Zhang, Stephen Roller, Naman Goyal, Mikel Artetxe, Moya Chen, ShuohuiChen, Christopher Dewan, Mona Diab, Xian Li, Xi Victoria Lin, et al. 2022. Opt:Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068(2022).",
  "(2) Modality-aware recommender systems": "MoRec employs a pre-trained SBERT to utilize the textinformation of items to generate the initial embeddings foritems that will be used in collaborative filtering models. Weutilize SASRec as the backbone model of MoRec. CTRL employs a two-stage learning process: the firststage involves contrastive learning on textual informationof items to initialize the backbone model, and the secondstage, fine-tunes the model on recommendation tasks. We useSASRec as the backbone model of CTRL. RECFORMER models user preferences and item featuresusing the Transformer architecture, transforming sequentialrecommendation into a task of predicting the next item as ifpredicting the next sentence, by converting item attributesinto a sentence format.",
  "LLM-Only utilizes an open-source LLM model OPT withprompts related to recommendation tasks as shown in .In our experiments, we adopt the 6.7B size version of OPT forall LLM-based recommendations": "TALLRec is our main baseline, which learns the recom-mendation task based on prompts consisting solely of text andfine-tunes the LLMs using the LoRA. Their approach involvesproviding user interaction history and one target item anddetermining whether a user will prefer this target item. Thissimpler task necessitates only a brief prompt for the LLMs.",
  "A-LLMRec": "In contrast, our recommendation task requires a more exten-sive prompt. Even though this adjustment results in a smallerbatch size, the same as A-LLMRec, for training TALLRec. Weuse the prompt shown in . MLP-LLM is an additionally designed LLM-based recommen-dation model for analysis. Compared with A-LLMRec, thismodel directly connects the user and item embeddings fromfrozen CF-RecSys and LLM using only MLP layers, insteadof the auto-encoders in A-LLMRec that involve various tech-niques to align the collaborative knowledge of CF-RecSyswith the LLM. Note that we use the prompt shown in .BLANGUAGE GENERATION TASK In , we present additional favorite genre prediction taskresults for experiment in shown in .4.4. As mentioned in.4.4, TALLRec could not generate valid natural languageoutputs due to the fine-tuning via instruction tuning process, whichmakes the LLM of TALLRec being able to answer only with someparticular prompts used in instruction tuning process. The addi-tional results indicate that A-LLMRec can generate the favoritegenres for the users based on the understanding of the aligned userrepresentation and item embeddings while LLM-only fails to do so.CREPRODUCIBILITY For implementing the baseline, we followed the official codes pub-lished by authors as detailed in . Refer to our source codeand instructions to run code for reproducing the results reportedin the experiments."
}