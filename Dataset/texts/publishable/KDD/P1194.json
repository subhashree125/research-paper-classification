{
  "Chenyang Qiu, Guoshun Nan, Member, IEEE, Hongrui Xia, Zheng Weng, Xueting Wang, MengShen, Member, IEEE, Xiaofeng Tao, Senior Member, IEEE, Jun Liu": "AbstractNetwork-based intrusion detection system (NIDS)monitors network traffic for malicious activities, forming thefrontline defense against increasing attacks over informationinfrastructures. Although promising, our quantitative analysisshows that existing methods perform inconsistently in declaringvarious known or unknown attacks (e.g., 31% F1 for theBackdoor and 93% F1 for DDoS by a GCN-based state-of-the-art method), and perform poorly in few-shot intrusion detections(e.g., dramatically drops from 91% to 36% in 3D-IDS, anddrops from 89% to 20% in E-GraphSAGE). We reveal thatthe underlying cause is entangled distributions of flow features.This motivates us to propose DIDS-MFL, a disentangled in-trusion detection method to handle various intrusion detectionscenarios. DIDS-MFL involves two key components to addressthe performance inconsistency and few-shot detection perfor-mance deterioration, respectively: a double Disentanglement-based Intrusion Detection System (DIDS) and a plug-and-playMulti-scale Few-shot Learning-based (MFL) intrusion detectionmodule. Specifically, the proposed DIDS first disentangles trafficfeatures by a non-parameterized optimization based on mutualinformation, automatically differentiating tens and hundreds ofcomplex features of various attacks. Such differentiated featureswill be fed into a memory model to generate representations,which are further disentangled to highlight the attack-specificfeatures. Our DIDS additionally uses a novel graph diffusionmethod that dynamically fuses the network topology for spatial-temporal aggregation in evolving data streams. Furthermore, theproposed MFL involves an alternating optimization frameworkto address the entangled representations in few-shot trafficthreats with rigorous derivation. MFL first captures multi-scale information in latent space to distinguish attack-specificinformation and then optimizes the disentanglement term tohighlight the attack-specific information. Finally, MFL fuses andalternately solves them in an end-to-end way. To the best ofour knowledge, DIDS-MFL takes the first step toward dynamicintrusion detection in practice under various scenarios. Equippedwith DIDS-MFL, administrators can effectively identify variousattacks in encrypted traffic, including known, unknown ones, andthe few-shot threats that are not easily detected. Experimentsshow the superiority of our proposed DIDS-MFL. For few-shot NIDS, our DIDS-MFL achieves a 73.59% - 139.53%improvement in average F1-score over 11 baselines and showsversatility in multiple baselines and multiple tasks. Our code isavailable at",
  "I. INTRODUCTION": "C. Qiu, G. Nan, H. Xia, Z. Weng, X. Wang, X. Tao were with NationalEngineering Research Center for Mobile Network Technologies, BeijingUniversity of Posts and Telecommunications, Beijing, 100876, China.E-mail:{cyqiu,nanguo2021,kphchrls,wengzheng,wxtyuki,taoxf}@bupt.edu.cnM. Shen was with Beijing Institute of Technology, Beijing, 100081, China.E-mail: . Liu was with Singapore University of Technology and Design, Singapore.E-mail: author: G. Nan (email: ).Manuscript received April 19, 2021; revised August 16, 2021.",
  "Read-onlyRead-only": ".Illustration of two network attacks DoS and MITM. DoS floodsthe target with massive traffic to overwhelm an online service, and MITMeavesdrops on the communication between two targets and steals privateinformation. An NIDS can be easily deployed in a single location to collectstatistical features and alert administrators for potential threats. UNAUTHORIZED attempts like password cracking ,man-in-the-middle attacks (MITM) , and denial-of-service (DoS) are known as the network attacks ,targeting an organizations digital assets with the intentionof data leakage or the execution of harmful deeds. Theseattacks are frequently perceived as network anomalies dueto their distinct characteristics that differ from standard trafficpatterns. An alarming statistic notes that 31% companiesacross the globe experience a daily average of at least onecyber attack, a frequency amplified by the proliferation ofmobile online business endeavors. The situations necessitate anintelligent system deployment to assist network administratorsin the automated segregation of these anomalies from the vastsea of internet traffic. A network-based intrusion detectionsystem (NIDS) , which monitors network traffic and identi-fies malicious activities, facilitates administrators to form thefrontline defense against increasing attacks over informationinfrastructures (e.g., sensors and servers). Hence, NIDS iswidely applied in many information systems of governmentsand e-commercial business sectors . demonstrateshow NIDS builds a frontline defense against two networkattacks, protecting systems from potential cyber threats.Existing NIDS can be categorized into two types, i.e.,signature-based ones and anomaly-based ones . The former detects network attacks based on pre-definedpatterns or known malicious sequences stored in a database,such as the number of bytes in traffic. These patterns in theNIDS are referred to as signatures. The latter anomaly-basedNIDS learns to track attacks with machine learning techniques.Early statistical approaches , , such as Support VectorMachine (SVM), Logistic Regression (LR), and DecisionTree (DT), rely on carefully designed handcrafted featuresto learn classification boundaries. Recent deep learning-basedmethods , use millions of neural parameters to mine",
  "(f) Representation correlation map of DDoSattacks": ". Quantitative analysis on CIC-TON-IOT. (a) Comparisons of detecting various attacks, which are regarded as an unknown type in evaluation. Specifically,we train an SVM model without using the data points of these attacks, and evaluate the instances of these attacks on the test set. (b) and (c) show the featuredistributions of two attacks, MITM and DDoS, respectively. (d) Comparisons of detecting various known attacks on the previous state-of-the-art deep learningmodel E-GraphSAGE, (e) and (f) are correlation maps of representations of the two attacks, where the representations are generated by E-GraphSAGE. E-GraphSAGE EULERTGNDIDS0 F1-Score (%) Normal size Few-shot",
  "(b)": ".(a) Performance comparisons among different intrusion detectionmethods with normal-size traffic and few-shot traffic. (b) F1-score compar-isons between DIDS few-shot learning and two SOTA few-shot learningbaselines. We repeat the above comparisons 10 times. the knowledge underlying the training samples, and haveachieved great success in automatically modeling complexcorrelations for tens and thousands of features. The state-of-the-art E-GraphSAGE employs graph convolution net-works (GCNs) to learn the feature representations for betterprediction.Although promising, existing NIDS approaches face twochallenges in detecting traffic threats accurately: Challenge 1. The existing NIDS methods yield ex-tremely inconsistent results in identifying distinct at-tacks. For statistical methods, (a) demonstratesthat the detection performance of an SVM-based method for an unknown attack 1 can be as low as 9% interms of F1 on the CIC-ToN-IOT dataset. While themodel achieves 40% F1 in declaring another unknownthreat (DDoS) on the same benchmark. Regarding thedeep learning-based methods, (d) demonstratesthat E-GraphSAGE achieves a lower than 20% F1 scorefor MITM attacks and a higher than 90% F1 score forDDoS on the CTC-ToN-IOT dataset. Challenge 2. The existing NIDS approaches struggle todetect few-shot traffic threats accurately. In practicalscenarios, the strengthening of defensive measures andthe consequent escalating trend of cyber threats have in-evitably caused the rise of new-type attacks with a limited",
  "The unknown attacks referred to in this paper are never appeared new typeof attacks in training set": "instance number, referred to as few-shot traffic threats.However, our empirical observations reveal that the NIDSmethods have dramatic performance deterioration in few-shot scenarios, as shown in (a), e.g., our previouswork DIDS dramatically drops from 91.57% undersupervised learning setting to 36.12% under the few-shot learning setting over the CIC-ToN-IoT dataset, andsimilarly, EURLER and E-GraphSAGE have an averageF1-scores lower to 36.26% under the few-shot learningsetting. For the first challenge, we depict feature distributions andvisualize the representations to investigate the underlyingcause of why existing methods perform inconsistently for var-ious attacks, including unknown ones and known ones. (b) and (c) depict statistical distributions of the two unknownattacks for the SVM-based model during testing. We observethat feature distributions of MITM attacks are entangled, whilethe ones of DDoS are more separated. It can be inferred thatstatistical distributions of traffic features are one of the mainunderlying causes of performance variations. Separated distri-butions benefit the unknown attack identification, while entan-gled ones are indistinguishable and unable to help the NIDSto make accurate decisions. We refer to such a phenomenon asthe entangled distribution of statistical features. To analyzethe reason for performance variations of acknowledged attacksduring testing, we use Pearson correlation heat map tovisualize the representations of MITM and DDoS respectively,where the representations are generated by the encoder of E-GraphSAGE. (e) and (f) demonstrate the twocorrelation maps. Interestingly, we observe that the coefficientsof MITM representations are much larger than those of DDoS.We further compare MITM with other attacks, includingBackdoor and Dos, and find those high coefficients in therepresentation will lead to lower intrusion detection scores. Werefer to such a phenomenon as the entangled distribution ofrepresentational features, which can be considered as anothermain cause for the degradation of attack classification.For the second challenge, we observe that the NIDS ap-",
  ". The correlation map and the t-SNE visualization of representationsgenerated by DIDS and BSNet on CIC-ToN-IoT dataset": "proaches still perform poorly when combining the state-of-the-art few-shot learning methods, as shown in (b).For the meta-learning-based MBase , we attribute the poorperformance to the limited anomaly types in network traffic.Effective meta-learning approaches typically necessitate vasttypes of few-shot anomalies, which are more aligned withthe field of computer vision and natural language processing. Therefore, we focus on the similarity-based methodBSNet and uncover why BSNet outperforms DIDS. Wedepict the t-SNE visualizations of their respective learnedrepresentations. As shown in (a) (b), we observe thatthe representations of BSNet in different attack types are moreseparated in the latent space. It can be inferred as one of themain causes of higher F1 scores in BSNet. Following thisthread, we further depict their representation correlations viacorrelation heatmaps. We have found that the representationsof BSNet are more entangled than DIDS as shown in (c)(d). Aligning with the disentanglement studies in Challenge 1,we attribute the main obstacle to the performance improvementof BSNet to the entangled representations.In light of the discussions, we raise two critical questions:",
  "Q1: How can an intrusion detection model automaticallyaddress the first challenges, i.e., two entangled distribu-tions, to benefit the detection of both unknown and knownattacks": "Q2: Can a few-shot intrusion detection method automat-ically learn the representations as separated in latentspace, simultaneously as disentangled among represen-tation elements?Achieving Q1 is challenging. To mitigate the issue of thefirst entangled distribution, we need to differentiate tens andthousands of features involved in real-time network traffic,without prior knowledge of the statistical distributions. Such aproblem is largely under-explored in the field of NIDS. For thesecond entangled distribution, there are some remotely relatedmethods in other fields, including computer visionand natural language processing. However, these approaches mainly focus on object-level representation learning, andhence they are hardly directly applied to intrusion detection totackle this challenge.Second, the difficulties of Q2 lie in two aspects: 1. tacklingQ2 involves two optimization terms, a disentanglement term,and a latent space term. How to optimize them into an end-to-end framework is under-explored in NIDS and few-shot learn-ing. 2. As for latent space optimization, existing similarity-based methods , , mainly focused on utilizing theoriginal-scale information of representations, while ignoringtheir multi-scale information to help few-shot traffic separatedin latent space.To address the above two questions, we propose anovel model called Disentangled dynamic Intrusion DetectionSystem with Multi-scale Few-shot Learning (DIDS-MFL).Specifically, DIDS-MFL has two critical components: DIDSand MFL. The former DIDS disentangles the statistical flowfeatures with a non-parametric optimization, aiming to auto-matically separate entangled distributions for representationlearning. We refer to this step as statistical disentanglement.Then DIDS further learns to differentiate the representationsby a regularization function, aiming to highlight the salientfeatures for specific attacks with smaller coefficients. We referto this step as representational disentanglement. DIDS finallyintroduces a novel graph diffusion module that dynamicallyfuses the graph topology in evolving traffic. The latter MFLis a flexible plug-and-play module for few-shot detectionmatching multiple NIDS baselines. We first optimize themulti-scale traffic representations in latent space to distinguishattack-specific information. Then we propose an element-wise disentanglement term to highlight the attack-specificinformation. Finally, we alternately solve them in an end-to-end framework.Extensive experiments on five benchmarks show the supe-riority of our DIDS-MFL. The main contributions are: We propose DIDS-MFL, aiming to mitigate the entan-gled distributions of flow features for NIDS in variouspractical scenarios, e.g., known, few-shot, and unknownattacks 2. To the best of our knowledge, we are the firstto quantitatively analyze such an interesting problem andempirically reveal the underlying cause in the intrusiondetection field. As for DIDS, we present a double disentanglementscheme for differentiating the general features of vari-ous attacks and highlighting the attack-specific features,respectively. We additionally introduce a novel graphdiffusion method for dynamic feature aggregation. As for MFL, we propose a fusion-based frameworkby capturing multi-scale information and disentanglingrepresentations. We alternately solve them with rigorousderivation for few-shot intrusion detection. As a plug-and-play module, MFL also shows versatility in multiplebaselines and downstream tasks.",
  "A. Network Intrusion Detection System": "Existing NIDS can be classified into two groups, i.e.,signature-based ones and anomaly-based ones , . Signature-based intrusion detection systems (IDS)rely on identifying known attack patterns or signatures. Thesesystems are adept at recognizing established threats, wherethe attack signatures are predefined, employing rule sets tomatch against network traffic for indicative malicious ac-tivities. However, their dependency on signature databasesposes a limitation, as they are typically ineffective againstnovel or zero-day attacks that do not yet have a definedsignature. In contrast, the anomaly-based ones do not rely onprior knowledge of attack signatures. They leverage machinelearning or statistical techniques to model normal networkbehavior and flag deviations as potential threats. Anomalydetection holds the advantage of identifying unknown attacksand adapting to new threat patterns. The anomaly-based onesinvolve statistical methods , and deep learning-basedones , . Early deep learning studies model the trafficas independent sequences . Recent popular studiesrely on GCN to aggregate traffic information . Mostrelated to our work is Euler , which builds a series of staticgraphs based on traffic flow and then performs informationaggregation. Our DIDS differs from the above methods intwo aspects: 1) We build dynamic graphs rather than staticones, and such a dynamic aggregation can capture fine-grainedtraffic features for attack detection. Furthermore, we fusethe network layer information into our graph aggregation.2) We introduce a double disentanglement scheme, includingstatistical disentanglement and representational one, to benefitthe detection of both known and unknown attacks.",
  "B. Disentangled Representation Learning": "Disentanglement aims to learn representations that separatethe underlying explanatory factors responsible for variation inthe data. Previous studies focus on the generativemodels by employing constraints on the loss functions, suchas -VAE modifying the VAE framework to empha-size the independence of latent variables. Beta-VAE achievesdisentanglement by introducing a trade-off term between re-construction and KL divergence, while FactorVAE in-troduces a total correlation penalty. CausalVAE takes asignificant step by integrating causal reasoning, allowing forinterventions in the generative process. Disentangled GraphNeural Networks are another active area, where methods aimto learn independent node representations decoupled from thegraph structure, e.g., GD-GAN employs a GAN frameworkto disentangle the latent factors of variation in graph data,allowing for controllable generation of new graph structuresand node features. Some recent approaches capturethe intrinsic factors in graph-structured data. Most relatedto our work is DisenLink, which disentangled theoriginal features into a fixed number of factors, with selective factor-wise message passing for better node representations.While our DIDS uses a double disentanglement method, whichfirst disentangles the statistical features via non-parametricoptimization, and then learns to highlight the attack-specificfeatures with a regularization.",
  "C. Dynamic Graph Convolution Networks": "Dynamic graph convolution networks (GCNs) focus onevolving graph streams. There is a line of early studiesin GCNs on dynamic graphs, which incorporate temporalinformation into graphs. These methods can be categorizedinto the spatio-temporal decoupled ones , , andthe spatio-temporal coupled ones , . The formeremploys two separate modules to capture temporal and spatialinformation, e.g., DynGCN performs spatial and temporalconvolutions interleaved, updating model parameters to adaptto new graph snapshots, DIDA Handles spatio-temporaldistribution shifts by discovering invariant patterns and usingintervention mechanisms to eliminate spurious impacts. Thelatter incorporates spatial-temporal dependencies by proposinga synchronous modeling mechanism, e.g., AST-GCN adapts the graph structure and convolutional filters based onthe temporal context to capture the evolving relationshipsin dynamic graphs, TD-GCN uses temporal differencelearning to update spatial-temporal graph convolutional filters,capturing the changes in graph structure and node states overtime. Our DIDS is mainly inspired by the GIND , whichadaptively aggregates information via a non-linear diffusionmethod. The key difference between our GCN approach andGIND is: we introduce the non-linear graph diffusion methodinto a multi-layer graph that considers the network topologyfor dynamic intrusion detection.",
  "D. Few-shot Learning": "Few-shot learning is a machine learning paradigm designedto enable a model to learn from a small number of traininginstances and generalize effectively to unseen data. The exist-ing few-shot learning methods can be divided into two cate-gories: meta-learning-based ones , including meta-learning-based NIDS approaches , and similarity-based ones. Meta-learning-based methods focus on learninga model that can adapt to new tasks with limited data. Thesemethods often involve a meta-training phase where the modellearns to learn from a variety of tasks, followed by a meta-testing phase where the model rapidly tunes to a new task.In contrast, the similarity-based ones rely on measuring thesimilarity or distance between the query instances and thesupport set to make predictions without necessitating vasttypes of few-shot samples. The similarity-based ones can alsobe grouped into augmentation-based ones , metriclearning-based ones , , and other similarity-basedfew-shot learning methods . Recent popular few-shotlearning methods mainly focused on utilizing multiple learningmetrics, or prototype completion. The most related to us isBSNet . Ours differs from it in two aspects: first, weemphasize the importance of preserving multi-scale intrinsic",
  "A SUBMISSION TO IEEE TRANSACTION ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE5": "representation information, rather than optimizing the original-scale information; second, we propose a joint optimizationscheme to generate separated and disentangled representationsto make few-shot threats distinguishable.Finally, this work is an extension version form . In ,we address the performance inconsistency issue caused byentangled features on sufficient training data. More practicalscenarios is collecting attack traffic with limited instances. It ismore challenging compared to with involving double op-timization goals. To this end, this paper proposes an alternatingoptimization framework MFL to address the entangled repre-sentations in few-shot traffic threats with rigorous derivation.The proposed MFL is also a plug-and-play few-shot intrusiondetection module that is compatible with other NIDS methods.",
  "A. Multi-Layer Graphs": "To model the sophisticated traffic network topology, weformally define the multi-layer graphs. First, we consider asingle-layer network modeled by a graph G = (V, E, ),where V is the set of nodes and E V V is the set ofedges. Here : V V R is an edge weight function suchthat each edge euv E has a weight uv. Then the multi-layergraph can be defined as follows:",
  "Eij(t) = (vi, li, vj, lj, t, t, Fij(t)).(2)": "First, we concatenate the source IP and source port in theoriginal traffic flows as the source identity for the device i.Similarly, we can obtain the destination identity for the devicej. We denote vi and vj as the source and destination nodesrespectively. Secondly, li denotes the layer of device i, andli = 0 indicates that i is a terminal device such as a PC, aserver, or an IoT device. Here li = 1 indicates that i is anintermediate device such as a router in the communicationlink. Specifically, we assign devices with the router address192.168.0.1 or with many stable connections in layer 1. Thent refers to the timestamp of traffic and t indicates the trafficduration time. Finally, Fij(t) is the traffic features.",
  "C. Problem Formulation": "1) Dynamic Traffic Intrusion Detection: We first define thedevices as nodes and the communications with timestampsbetween any pair of devices as edges. We use T to representthe maximum timestamp. An Edge sequence E is denoted by{Et}Tt=1, where each Et represents a network traffic. Also,after each edge, there is a corresponding multi-layer graph,then the corresponding multi-layer graph stream G takes theform of {Gt}Tt=1, where each Gt = (Vt, Et) represents themulti-layer graph at timestamp t. A multi-layer adjacencymatrix AtRmn represents the edges in Et, where(i, j, w) Et, At[i][j] = wij and wij is the weight of thematrix. The goal of intrusion detection is to learn to predict theedge Et as a benign traffic or an attack in binary classification,and a specific type under the multi-classification.2) Few-shot Intrusion Detection: Given a few-shot intru-sion detection task T = {Ctr, Cte}, where Ctr is a training setwith few-shot traffic, and Cte is a test set. Our goal is to designa few-shot module to accurately classify the samples in Cte byfew-shot learning on Ctr. Ctr includes two key components,support set and query set. The former provides the few-shottraffic information to the model, and the latter contains newinstances for model evaluation and optimization. The queryset can be sampled from the support set for the traffic-limitedscenarios. Specifically, we conduct N-way K-shot intrusiondetection, N-class traffic with K samples, i.e., 5, in the supportset. The few-shot intrusion detection model aims to conductaccurate detection in the query set, while the only availablereference is the few-shot traffic in the support set.",
  "A. Statistical Disentanglement": "As we discussed in Section I, statistical distributions oftraffic features are one of the main underlying causes ofperformance variations. i.e., separated distributions benefitthe unknown attack identification, while entangled ones areindistinguishable and thus unable to help the NIDS to makeaccurate decisions. Therefore, our aim is there to disentanglethe traffic features and make them distinguishable.To separate the features of traffic without any prior knowl-edge, we formulate the differentiation as a constrained non-parametric optimization problem and approximate the optimalresults by solving the Satisfiability Modulo Theory (SMT). We perform a min-max normalization on the edge featureFij(t). For convenience, we denote the normalized edgefeature as F, and Fi is the i-th normalized element.We need a weight matrix w to generate the disentangledrepresentation of F. Our key optimization objectives are tominimize the mutual information between the elements oftraffic features and also bound the range of w when weperform aggregation. We start by constraining the weight",
  "A SUBMISSION TO IEEE TRANSACTION ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE6": ". Overview of the proposed DIDS-MFL, which consists of five modules. 1) Edge construction module builds edges based on traffic flow. 2) Statisticaldisentanglement module differentiates values in vectors to facilitate the identification of various attacks. 3) Representational disentanglement module learnsto highlight attack-specific features. 4) Multi-Layer graph diffusion module fuses the network topology for better aggregation over evolving dynamic traffic.5) Multi-scale few-shot learning module aims to few-shot traffic threats detection. Finally, traffic classifier takes the traffic representation as an input to yieldthe detection results. DIDS takes the first four steps and flows through the yellow arrows to the classifier, while DIDS-MFL takes the five steps by flowingthrough the blue arrows to the classifier.",
  "(7)": "The subjection in Eq. 7 ensures variants ranges and the order-preserving property of generated representation. It also ensuressymbols when removing the absolute value sign. The detailedexplanation of why Eq. 6 can generate the disentangledrepresentation is available in Apeendix 11.Specifically, we employ Eq. 6 as an optimization objective,i.e., loss function, and utilize Adam optimizer to solve it. Thenwe can generate the disentangled edge representation hi,j,which can be expressed as hi,j = w F, where the symbol represents the Hadamard product.Equipped with the above non-parametric optimization, wecan differentiate tens and hundreds of complex features of var-ious attacks, mitigating the entangled distribution of statisticalfeatures. Such statistically disentangled features facilitate ourmodel to be more sensitive to various attacks.",
  "B. Representational Disentanglement": "So far we have constructed edges and statistically differen-tiated the features of traffic flows hi,j = w F. This modulegenerates contextualized node representations X from edgerepresentations hi,j by using the temporal information. Thisinvolves three steps:1) Generating updating messages: For an incoming trafficflow, we will build an edge or update the correspondingedge, which may lead to a dramatic change in the noderepresentations involved in this interaction. We can updatethe node representations by utilizing this change. Therefore,",
  "cj(t) = Msgmjt, mit, t, t, li, lj, hi,j,(9)": "where hi,j is the disentangled edge representation. t is theedge duration time, li, lj is the layer marks of edge, mi(t)is the historical memory of the two interacting nodes, wheret is a historical time point, compared to the existing timepoint t, Msg is a learnable function, and we use RNN. Theinitial memory mi(0) is 0, i V . Specifically, RNN aimsto generate the new memory message c(t) combining thehistorical memory m(t) and disentangled representation hijby learnable weight matrices and gating mechanism.",
  "mi(t) = Memci(t), mit,(10)": "where Mem is an encoder, and here we use GRU. We similarlyupdate the memory of node j via (10). Specifically, GRUintroduces Reset Gate and Update Gate to better generatethe updated node memory mi(t) by fusing historical memorymi(t) and new memory message ci(t). GRU considers bothlong-term and short-term dependencies, thus mitigating thevanishing gradient issue in temporal models. 3) Generating second disentangled node representations:We can generate the node representation by utilizing theupdated memory in (10), and the representation of node iin time t can be expressed as xi(t) = xi(t) + mi(t),where xi(t) is the historical representation of node i. In thisway, we obtain the dynamic node representations of trafficin an evolving time flow. The representation of node j canalso be generated in a similar way. The initial value of noderepresentations X(0) is 0. We aim to preserve the disentangled property in noderepresentations. However, the update operations above mayentangle them at the element level again. Therefore, we pro-pose the second representational disentanglement, which aimsto highlight the attack-specific features in node representationsin the following end-to-end manner. It also ensures that theelement-wised representations are close to orthogonal.",
  "F .(11)": "The above regularization encourages the model to learnsmaller coefficients between every two elements of node rep-resentations. Such representations can be more differentiated.As the module is supervised by the signal of a specific attack,it can learn to highlight the attack-specific features, so as toimprove the detection accuracy, as discussed in Section I. Bydoing so, we are able to mitigate the entangled distribution ofrepresentational features as mentioned at the beginning.",
  "C. Multi-Layer Graph Diffusion": "So far, we have generated the dynamic disentangled noderepresentations with temporal information. For further fusingthe multi-layer topological structure information, we proposea multi-layer graph diffusion module. Please note that westill preserve the disentangled property by the following cus-tomized designs.We utilize the following graph diffusion method to fuse thetopological information in evolving graph streams, which cancapture the fine-grained spatial-temporal coupled information.The previous dynamic intrusion detection methods may losethis information in separated time gaps, due to the employedtime-window or snapshots-based methods. More discussionson the dynamic and superiority of the proposed graphdiffusion approach compared to the previous methods, areavailable in Appendix 14.2. tX = F (X, )X(0) = 0,(12) where F is a matrixvalued nonlinear function conditionedon graph G, and is the tensor of trainable parameters. Theabove Eq. 12 establishes the foundation for spatial-temporalcoupled information modeling.Specifically, we aim to amplify the important dimensionsof disentangled representations and depress the influence oftrivial feature elements in the diffusion process. To formulatethis process, we consider PM (PeronaMalik) diffusion , atype of nonlinear filtering. It can be expressed as:x(u,t)",
  "t= div[g(|x(u, t)|)x(u, t)]x(u, 0)= 0,(13)": "where div is the divergence operator, is the gradientoperator, and g is a function inversely proportional to theabsolute value of the gradient.Before formally formulating the multi-layer graph diffusion,we propose the following spatial-temporal influence coefficientsij S between nodes i,j in tij time. The coefficientmatrix considers the information changes over spatial-temporalcoupled traffic data. Specifically, different layers and topologystructures over traffic networks and the traffic feature interac-tions at different times will influence the node representationsdynamically:",
  "f(x) = W(2) ReLUW(1)x,(15)": "where || is a concatenate operator, () is a generic timeencoder to generate temporal representations, W(1) andW(2) are the parameters of the first and second layer MLP.Now we formally propose the multi-layer graph diffusionmodule. We first define a differential operator on the multi-layer graph, aiming to transfer the above continuous PMdiffusion in Eq. 13 to multi-layer graphs. As known fromprevious literature , the gradient operator correspondsto the instance matrix M, while the divergence operatorcorresponds to the matrix M, and we can compute the matrixM by the equation MT M = DA, where D is the diagonal",
  "D. Classifier and Loss Function": "For DIDS, we make the two-step predictions for intrusiondetection. We utilize the first MLP to classify whether thetraffic is benign or anomalous and utilize the second MLP todetect the specific type of attack. When an unknown attackinvades, the direct multi-classifications will be easy to fail toassign the anomalous label thus leading to poor performance.In contrast, through the first-step binary classification, DIDSwill focus more on inconsistencies with normal behavior toimprove the performance of detecting unknown attacks. Thefollowing second multi-classification will further alert theadministrators that what kind of attack it is more similar toso that similar mitigation measures can be taken. Specifically,the intrusion loss can be expressed as:",
  "LInt = mi=1(log(1 pnor,i) + log(patt,i) + Kj=1 yi,k log(pi,k))": "(18)where m is the batch size, K is the number of attack classes,pnor,i is the probability of normal, patt,i is the probabilityof attack. Additionally, the adjacent time intervals may causeadjacent times embedding to be farther apart in embeddedspace, due to the learning process independency. To addressthis problem, we constrained the variation between adjacenttimestamps embedding by minimizing the Euclidean Distance:",
  "E. Multi-scale Few-shot Learning": "So far we have proposed DIDS for supervised intrusion de-tection. Furthermore, we propose the following MFL to detectfew-shot threats accurately, e.g., 5 samples of each attack type.We first denote the learned representations Xt+t in Eq. 17 asZ RLN, where L is the length of representations, and Nis the few-shot sample number. The few-shot learner aims togenerate a coefficient matrix S as a learned similarity matrix",
  "minH = Z ZH2F + 1H2F , s.t.diag(H) = 0,(21)": "where | |2F is the Frobenius matrix norm (F-norm) anddiag(H) denotes the diagonal entries of H. H can be directlyderived by solving Eq. 21. Specifically, we directly employEq. 21 as a loss function and utilize backpropagation andoptimizer, e.g., Adam, to solve it.The above self-expressive optimization only focuses onpreserving the original-scale information of Z. The multi-scale information of Z can also provide necessary informationto make few-shot traffic samples distinguishable. To thisend, we proposed a transform-based algorithm to generatecoefficient matrix Q by using Zs multi-scale information.This process can be considered as an augmentation ofthe original representations Z in the latent space, aiming tocapture the invariant attack-specific features across differentscales. Finally, we fuse the obtained coefficient matrices Hand Q. We refer to the above model as Multi-scale Few-shot learning (MFL). Equipped with the fusion of generatedmatrices, MFL can effectively utilize few-shot representationsacross different scales, i.e., under the original and transformedscale, thus benefiting the distinction of few-shot traffic threats.We have the following principles to achieve MFL and clarifythe motivations behind these designs: 1. MFL should encourage the representations under dif-ferent scales to be close in latent space, thus capturingthe attack-specific features and benefiting the distinctionof traffic samples in different types, which is motivatedby the empirical studies in (a)(b) 2. MFL should ensure the disentanglement among theelements of the learned representation, thus highlightingthe attack-specific information, which is motivated by theempirical studies in (c)(d)Toachievetheabovegoals,wefirstproposeatransformation-based learning scheme by projecting the rep-resentations Z to a latent space, aiming to discover theattack-specific invariant features across different scales. Thenwe introduce a regularization term to disentangle the few-shot representations. Finally, we propose an alternating op-timization algorithm to derive Q in an end-to-end way. Theimplementation involves the following three steps:1) Generating Representation Transformation.We denote Zo = Z as the original representations, andZt = G(Z) as the transformed representations, where G isa transformation operator. Specifically, we introduce a scalingoperator S as follows:",
  "A SUBMISSION TO IEEE TRANSACTION ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE9": "s2 = ... = sL = , S is an equal-rate scaling operator with therate of . Hence, the transformation can be rewritten as Zt =G(Z) = SZ = IZ = Z. By the equal-rate transformation,we generate transformed representations while preserving theircontent, e.g., scaling up an image by the rate of 2, will notchange the content we see.2) Generating Multi-scale Coefficient Matrix.So far, we have generated the transformations of Z. In step2, we propose a constraint term to encourage the representa-tion to be close between the original and transformed scale.Furthermore, we introduce a learnable projection operatorP to uncover the attack-specific invariant information, thusbenefiting the distinction of few-shot traffic threats.",
  "F ,(25)": "where Z+jo R(L1)N repeats the j-th row of Zo andZjt R(L1)N denotes the transformation matrix by re-moving the j-th row. The above disentanglement regularizationterm Eq. 25 corresponds to design principle 2 and is motivatedby the empirical studies in (c)(d), aiming to highlightthe attack-specific information.Combining the above key formulations Eq. 24 and Eq. 25,we can rewrite the optimization problem as:",
  "s.t. PZ = PZQ, Q = Q,(26)": "where f(P) =2 (f1(P) + f2(P)), and are trade-offhyperparameters, Q is a auxiliary variable, and is scalingrate hyperparameter.Since the optimization problem in Eq. 26 is not convex withthe unknowns {P, Q}, we solve Q by iteratively updatingvariables while fixing another. We propose the followingalternating solution to derive the coefficient matrix Q.Alternating Solution for MFLWe solve Eq. 26 by converting the original problem to theaugmented Lagrange minimizing problem, as Eq. 26 involving",
  "Q = H + Q(35)": "where Q contains fine-grained multi-scale information tohelp few-shot traffic threats distinguishable.Finally, we can generate the coefficient matrix of MFLby S =|Q| + |Q|T /2. Given the noise informationand outliers in the obtained S, in practical implementations,we further conduct SVD decomposition of S to filter noisyinformation and generate a normalized matrix S. The detailedimplementation pseudo-code of generating S is available inthe Appendix 15.DIDS-MFL LossThe DIDS-MFL loss consists of two components, a multi-scale few-shot learning term and a regularization term. The for-mer uses a cross-entropy loss, aiming to match the predictionto the query set via the generated multi-scale coefficient matrixS. In the few-shot intrusion detection task, S is derived fromthe representations of support and query samples. The latterenforces the representations Z to be close to the original-scalerepresentations in latent space. Finally, we introduce a trade-off hyperparameter to control the regularization intensity.The specific DIDS-MFL loss is as follows:",
  "j=1Yi,j log(Pi,j) + ZH Z(36)": "where N is the category number of attacks, Q is samplenumber of query set in each category, Yi,j and Pi,j are ground-truth and prediction, respectively, Pij is query samples meansimilarity score derived from the coefficient matrix S, is atrade-off hyperparameter. In Eq. 36, the first term discovers themulti-scale information of Z, while the second term preservesthe information under the original scale via the coefficientmatrix H. We can fine-tune to control these two terms.",
  "EdgeIIoT: It is collected from an IoT/IIoT system thatcontains mobile devices and sensors. This dataset in-cludes 1, 692, 555 flows, with 21.15% attack samples and78.85% benign samples": "NF-UNSW-NB15-v2: It is NetFlow-based and generatedfrom the UNSW-NB15 dataset, which has been expandedwith additional NetFlow features and labeled with respec-tive attack categories. This dataset includes 2, 390, 275flows, with 3.98% attack samples and 96.02% benignsamples. NF-CSE-CIC-IDS2018-v2: It is a NetFlow-based datasetgenerated from the original pcap files of CSE-CIC-IDS2018 dataset. This dataset includes 18, 893, 708 flows,with 11.95% attack samples and 88.05% benign samples.Configurations: All experiments and timings are conductedon a machine with Intel Xeon Gold 6330@ 2.00GHz,RTX3090 GPU, and 24G memory. We use the Adam optimizerwith a learning rate of 0.01, the learning rate schedulerreducing rate as 0.9, with weight decay being 1e5. We trainall the models with 500 epochs.Baselines: To evaluate the performance of the proposed DIDS,we select 10 deep learning based-models as baselines, includ-ing 3 sequence models (i.e., MLP , MStream , LUCID), 4 static GCN models (i.e., GAT and E-GraphSAGE, SSDCM , DMGI ), where SSDCM and DMGIare designed for static multi-layer graphs, 4 dynamic GCNmodels (i.e., TGN , EULER , AnomRank , Dy-nAnom ). Additionally, we choose 3 rule-based baselinesto compare with the proposed DIDS, (i.e., ML , AdaBoost, and Logistic Regression).Metrics: We follow the previous works to evaluate theperformances of all baselines by two commonly used metricsin intrusion detection including F1-score (F1) and ROC-AUCscore (AUC).",
  "B. Main Results": "1) Comparisons of binary classification: Under this set-ting, we classify a traffic flow as an attack or a benignone. We categorize the baselines into three groups, includ-ing dynamic GCNs at the top of Table I, static GCNs atthe middle of the table, and another three baselines at thebottom. It should be noted that AnomRank and DynAnomare two popular baselines for anomaly detection. We runour experiment 5 times and report the mean and variancevalues. The comparison results in Table I show that ourDIDS consistently performs the best among all baselinesover the five benchmarks, which shows the superiority of",
  ". Comparisons of multi-classification. Here indicates that the results are directly copied from the previous works": "our method for intrusion detection. Specifically, comparedto the E-GraphSAGE, the previous state-of-art GCN-basedapproach, our method achieves a 4.80% higher F1-score overthe CIC-BoT-IoT dataset. Our DIDS outperforms AnomRank,the previous state-of-the-art method for anomaly detection onF1, by 15.27 points over the EdgeIIoT dataset. We attribute theabove results to the gains of our statistical disentanglement,representational disentanglement and dynamic graph diffusionmethod.2) Comparisons of multi-classification: We compare theperformance of our method to four baselines in declaring thespecific attack type. These baselines include E-GraphSAGE, TGN , ML , and AdaBoost , as they arerepresentative of different types of intrusion detection modelsand have been widely used in previous studies. shows that the proposed DIDS consistently achieves the bestresults among all others over five datasets. For example, ours yields higher classification accuracy of up to 25 pointscompared to the baseline TGN for detecting Injection attacks.The existing graph-based methods, including E-GraphSAGE,ML, and AdaBoost, perform inconsistently in the identificationof complex attacks (e.g., MITM, Uploading, and XSS). Wealso observe that some attacks that are not easily detectedby the baseline approaches, can be identified by the proposedDIDS with high F1 scores. For example, E-GraphSAGE onlyachieves 18.34% and 30.7% F1 scores on CIC-ToN-IoT forMITM and Backdoor attacks, respectively, while our DIDS isable to obtain higher than 23% F1 score for each attack. Theseresults further show the superiority of the proposed DIDS. Wealso find that the average scores of our method on CIC-BoT-loT and CIC-ToN-loT are lower than the ones on the otherthree datasets. The underlying reason is the unbalanced attackdistributions in the training set, where the dominant type maymislead the classifications. Such a finding aligns with previous",
  "F1NMIF1NMIF1NMIF1NMIF1NMI": "MBase 41.743.2235.812.8438.523.5827.893.8451.13 2.3155.61 2.0541.743.2235.812.8463.744.1468.763.16MTL 30.793.1329.813.5837.805.6625.102.6952.64 5.6955.41 4.1644.18 4.2235.85 2.7945.38 5.8847.04 4.82TEG 29.92 2.1722.64 2.2229.62 3.7425.71 2.8226.34 2.4527.58 2.6427.80 2.1421.44 1.7425.20 3.1723.48 3.97 CLSA 17.21 3.6345.01 2.8338.54 3.4951.70 4.9018.84 3.1044.25 3.2717.53 1.9545.67 4.1319.19 2.9049.76 3.46ESPT 36.76 4.3738.51 3.2939.41 5.3734.66 3.4961.28 8.3453.77 6.9146.58 5.9449.37 6.5841.37 4.9846.52 6.71ICI 55.67 5.1447.80 3.7771.32 3.3557.51 4.5049.74 4.6551.30 5.2739.17 3.6631.81 2.2176.53 9.4379.00 6.20",
  "Ours(DIDS-MFL)97.471.1794.272.6296.641.8891.273.9492.732.5788.213.2597.391.4194.322.8493.933.2790.983.69": "work in the field of computer vision . Nevertheless, theproposed DIDS is still the best under such distributions. Weleave this interesting observation as our future work.3) Comparisons of unknown attacks: To further investigatethe performance of detecting unknown attacks, we conductexperiments on the four attack types by discarding the cor-responding instances in the train set and detecting them inthe test set. From this perspective, the unknown attacks arethe new-type attacks that do not belong to the existing typesof attacks in the training set. We run our experiments 5times and report the mean and variance values with differentrandom seeds. Table III reports the classification results onthe CIC-ToN-IOT dataset. It shows that the statistical rule-based method Logistic Regression can only achieve as low asa 1.68 F1 score for DDoS attacks, this confirms our analysis atthe very beginning that rule-based methods can hardly detectunknown attacks. The score of graph-based E-GraphSAGE ismuch smaller than DIDS, e.g., 6.05% for MITM, indicatingthe limitations of the static graph in detecting unknownattacks. We also observe that TGN performs better than E-GraphSAGE, although both of them are graph-based methods.We attribute the improvement to the dynamic module for TGN.Nevertheless, our DIDS outperforms all these methods by alarge margin, with an average score of 33.65% on the fourattacks. The results also suggest that our method is moreconsistent in detecting various unknown attacks, showing theeffectiveness of the two disentanglements. We further provideempirical studies on more datasets in Appendix 16 to showcasethe unknown detection ability of DIDS.",
  "DDoS1.680.6726.731.2110.201.4632.841.0341.780.26MITM2.170.8412.821.906.050.3515.320.5434.910.91Injection0.000.3415.731.7312.370.8822.830.3525.630.93Backdoor3.131.3320.850.639.510.4623.101.0332.290.81": "4)Comparisons under few-shot settings:Task Setting: We first conduct the DIDS pretraining overthe known benign and attack traffic. Then we conduct a N-way-K-shot learning for the few-shot attack traffic. Specifi- cally, N is the category number of few-shot traffic, and K isthe training number of each category, referred to support set.In our few-shot experiments, we set K as 5. We also constructa query set for our few-shot task, with 15 sample numbersfor each category. The query set can be sampled from thecategory samples, or augmented from the support set. We splita 5-fold cross-validation set from the training set, with 20% ofsupport and query set. Taking CIC-TON-IoT as an example,we conduct a five-way-five-shot learning and five-classificationtest with 100 training samples. We repeat the above training,validate, test ten times, and report the average performance.Each times training and validation samples are randomlyselected from our existing traffic data, thus simulating the few-shot learning setting in real-world scenarios. Baselines: To evaluate the performance of the proposedfew-shot learner, we select 11 few-shot learning models toincorporate into DIDS as baselines, including 3 meta-learningbased models (i.e., MBase , MTL , TEG ), whereTEG is designed for graph-structure-based few-shot learning,4 augmentation-based models (i.e., CLSA , ESPT ,ICI , KSCL , where CLAS and ESPT are based oncontrastive augmentation, ICI and KSCL are based on instanceaugmentation), 4 metric learning-based models (i.e., BSNet, CMFSL , TAD , PCWPK ).",
  "Performance metrics: We follow the previous work using F1 scores and NMI metrics for multi-classificationcomparison": "As shown in Table II, our MFL consistently performs betteramong 11 baselines under the five benchmarks, showing thesuperiority of our proposed MFL module in few-shot intru-sion detection. Specifically, our MFL achieves reproducibleaverage results of 95.63% and 91.81% in F1-score and NMIvalue over five public datasets. The results gain 97.87% -126.99% and 73.59% - 139.53% improvements in averageF1-score and NMI value of 11 baselines over five publicdatasets, respectively. We attribute the superior and impressivereproducible results of MFL to our multi-scale representationinformation using and disentanglement among few-shot trafficrepresentations. The RQ5 and RQ6 in the discussion sectionfurther verified our attributions. Furthermore, we also discussthe practical time cost of DIDS-MFL and the superiority of",
  "C. Ablation Study": "1) DIDS: In this section, we conduct an ablation studyon the CIC-ToN-IoT dataset to evaluate the effectiveness ofeach component. We remove our statistical disentanglementand denote it as \"w/o SD\". We use \"w/o RD\" and \"w/oMLGRAND\" to refer to the model that removes represen-tational disentanglement and the multi-layer graph diffusionmodule, respectively. Table IV reports the comparison results.It shows that removing the multi-layer graph diffusion moduleleads to the most significant performance degradation, e.g.,an 18.33 points decrease in AUC, indicating that it is thekey component for the accuracy of the proposed DIDS. Oursecond disentangled memory is also non-trivial to the overalldetection accuracy, as removing this component can decreasethe performance by 12.47 points in AUC. We observe that theSD module also benefits the model performance. The aboveablation study further confirms the effectiveness of the threekey components.",
  "DIDS(ours)97.780.3298.060.4397.920.2696.040.25": "2)MFL: Furthermore, we conduct an ablation study onthe CIC-TON-IOT dataset to evaluate the effectiveness ofour designed multi-scale few-shot learning (MFL) module.We denote our model without multi-scale latent optimizationspace as \"w/o LOS\" and \"w/o DR\" as our model without thedisentanglement regularization term. For the model withoutboth of the above components, we denote it as \"SE\", whichdegenerated into a naive self-expressiveness model. Table Vshows that removing both LOS and DR leads to dramaticperformance degradation, i.e., 9.92% and 9.75% drop inF1-score and NMI, respectively, indicating the effectivenessof our designed MFL. Furthermore, we observed that eachcomponent of MFL, e,g. LOS or DR is necessary for perfor-mance improvement, cause removing one of them will leadto performance degradation, i.e., 22.21%-23.16% and 8.63%-9.24% drop in F1-score and NMI, respectively. Without anyone of these two components, the performance will be poorerthan the base model SE. Results showcase the complementaryrelationships of the proposed two modules. The LOS providesa latent optimization space across multi-scale representations,which is the foundation of the DR term. Then the DRterm generates effective disentangled representations acrossmultiple scales based on LOS.",
  "MFL(ours)97.681.0997.501.1897.471.1794.272.62": "RQ1: How does the statistical disentanglement help thedetection of various attacks? To answer this question, wevisualize the distributions of features before and after thestatistical disentanglement. shows the visualizationsof the two distributions respectively. We can observe thatthere is less overlap between distributions of features afterthe disentanglement compared with the original data, whichdemonstrates this module could decrease the mutual referencebetween features and enable them to be distinguishable. Wealso observe that the distributions gradually shift to the rightside, representing the order-preserved constraints within ourdisentangling method. 0.00.20.40.60.81.0 0.0 0.1 0.2 0.3 0.4 0.5",
  ". Statistical disentanglement of traffic features": "RQ2: How does the representational disentanglement ben-efit \"highlighting the attack-specific features\"? To answerthis question, we track several Injection attack data in the CIC-ToN-IoT dataset and obtain the representation of these data inDIDS and E-GraphSAGE. Meanwhile, we calculate the abovetwo methods average values of embeddings for the benigntraffic. As shown in , the representation values ofE-GraphSAGE are much closer to the normal. It illustratesthat as nodes aggregate, the discrepancies in features becomeblurred, leading to inaccurate classification. While benefitingfrom the representational disentanglement, each dimension offeatures in DIDS can effectively preserve its own properties,deviating from the averages. Especially for the attack-specificfeatures Fwd Pkt Len Max and Fwd Pkt Std, etc., these attack-specific features are significantly highlighted in (a), thusimproving the accuracy of detection. The result proves theeffectiveness of the proposed DIDS in maintaining a disentan-gled representation during the aggregation process, ensuringthe presence of discrepancies, thus highlighting the attack-specific features and leading to more accurate classificationfor attacks.RQ3: How does the multi-layer diffusion module performeffectively for intrusion detection? We have illustrated theprinciple of multi-layer diffusion in Section IV-C. In this part,we take the MITM attack as an example to illustrate the",
  "(b) E-GraphSAGE. The comparison of node representation of the Injection attack aftergraph aggregation of our DIDS and E-GraphSAGE. The grey line presentsbenign data": "effectiveness of spatial-temporal in intrusion detection. (a) shows a deep learning-based NIDS. When aMITM attack occurs, it is difficult to detect the intrusion sincethe spatial and temporal information of those packets is notconsidered. There are also some methods that only considera single aspect of spatial and temporal information, such asE-GraphSAGE and MStream. In this case, for example, E-GraphSAGE mainly focuses on the spatial relationship ofthe set nodes and extracts features from them. However, weobserve that different streams have their own timestampsfrom Table VI, so the lack of temporal information makesit impossible to analyze the dynamic structural changes of theedge. Similarly, taking the temporal information as the onlyeffect factor will also get incomplete characteristics that donot contain spatial information (IP address). Moreover, somemethods that take both the spatial and temporal informationinto account, such as Euler, take the snapshot method tocapture the feature of the flow which does not achieve thesynchronous update for spatial and temporal information. Asshown in (b), intuitively, we can quickly detect thatUE6 is an intrusion device of layer 1 when the flow changesfrom SW2SW3 to SW2UE6 and UE6SW3 consid-ering SW2, SW3 are layer 2 devices. Also, we have noticedthe changes in dynamic graph structure with a multi-Layergraph diffusion module to realize spatio-temporal coupling andsynchronous updating. Overall, DIDS performs best amongthese baselines in detecting various attacks.",
  "TimeTimeStampSrc IPDst IP": "t125/04/2019 05 : 18 : 37 pm183.68.192.1681.169.216.58t225/04/2019 05 : 18 : 42 pm1.169.216.5825.162.192.168t325/04/2019 05 : 18 : 42 pm1.169.216.58230.158.52.59t425/04/2019 05 : 18 : 49 pm230.158.52.5925.162.192.168t525/04/2019 05 : 18 : 52 pm25.162.192.16869.151.192.168t625/04/2019 05 : 19 : 00 pm177.21.192.168230.158.52.59 RQ4: How does the disentanglement facilitate the explain-ability of DIDS? For this question, we rely on (a) asan example to recover the possible traffic features of a pass-word attack. Since the original features are retained after thedisentanglement, we can find some feature values that deviatesignificantly from the normal values in the node embedding.In the password attack, we observe that the deviated featuresafter disentanglement are \"Fwd Pkt Std\" and \"Fwd Pkt LenMax\". It aligns with our common sense for the main causes",
  ". Spatial-temporal coupling in intrusion detection": "of password attacks and further benefits the explainability ofDIDS.MFL:RQ5: How does multi-scale transform-based MFL ben-efit the distinction of few-shot traffic threats? To answerthis question, we visualize the learned representations of DIDSand the few-shot learning module MFL on the CIC-TON-IoTdataset via t-SNE technology. As shown in (a) (b), theMFLs representations are highly separated and distinguish-able for different few-shot attacks, i.e., the red square box,compared to the representation generated by DIDS, i.e., thered round box. It verifies the effectiveness of our proposedmulti-scale few-shot learning framework, i.e., multiple coef-ficient matrices fusion and multi-scale transformation. Theydiscover the attack-specific invariant features among few-shottraffic in latent space, thus improving the distinction of attackrepresentations.",
  ".The t-SNE visualization of representations on the CIC-TON-IoTdataset generated by DIDS and MFL": "RQ6: Can MFL disentangle the representations of few-shot samples? To answer this question, we visualize thelearned representations of DIDS and MFL on the CIC-TON-IoT dataset via correlation heatmaps. As shown in (a)(b), the visualization results significantly reveal that MFL cangenerate highly disentangled representations via our designedregularization term. Specifically, MFL generates a block diag-onal heatmap with high correlations and non-diagonal areaswith very low correlations. It verifies that MFL disentanglesthe few-shot traffic representations and highlights the attack-specific ones, making them more distinguishable.RQ7: Can MFL be served for other intrusion detectionmethods to strengthen their few-shot learning ability? To",
  ". The correlation map and the t-SNE visualization of representationsgenerated by DIDS and DIDS-MFL with MFL": "answer this question, we use MFL as a plug-and-play moduleto incorporate into other intrusion detection methods, i.e.,E-GraphSAGE, EULER, and TGN. We follow our few-shotsetting to conduct experiments on these methods with andwithout MFL. The methods with MFL significantly outperformthe ones without MFL by 17.45%-544.77%, as shown inTable VII. It demonstrates the effectiveness of our proposedMFL as a plug-and-play module to strengthen the few-shotlearning ability of other NIDS. Additionally, the underlyingcause of the slight improvement of E-GraphSAGE and EULERwith MFL is interesting for future few-shot NIDS designs. Theperformance differences between E-GraphSAGE and TGNlie in the generated representation qualities of respective ap-proaches, with more details available in Appendix 18. We alsoprovide the visualizations of different baselines to showcasethe disentangle representation ability of MFL in Appendix 19.",
  "Original20.140.1552.380.2914.250.33MFL26.700.2161.520.3791.880.14": "RQ8: Can MFL improve the performance of DIDS? Sofar, we have verified the effectiveness of MFL in few-shottraffic intrusion detection, including serving as a plug-and-playmodule for other methods. To further study the applicabilityof MFL in large-scale traffic, we conduct DIDS training withMFL and report the multi-classification results, as shown inTable VIII. DIDS with MFL achieves a 2.31% to 15.82% F1-score improvements among three datasets. The results revealthe effectiveness of MFL when serving as a multi-classificationmodule for normal-size traffic training. Our designed multi-scale transform-based framework also sheds light on the futureintrusion detection model design.RQ9: Network intrusion detection and Large languagemodel (LLM). Recently, there has been a significant surge inthe development and application of Large Language Models(LLMs) cross various domains, including Natural Lan-guage Processing (NLP) , Computer Vision (CV) ,and multimodal tasks. However, the existing LLMs, e.g. GPT-3.5, GPT-4 struggle to detect traffic threats accurately and",
  "DIDS83.561.1888.341.7593.550.97DIDS-MFL96.781.7291.223.4595.715.89": "efficiently. As shown in Table IX, the F1-score of the existingLLM is significantly lower than our SOTA method DIDS. Itmay lie in the hallucinations of existing neural language-based LLM, which struggle to comprehend the intrinsic attackfeatures in traffic data. Second, the LLM necessitates moretime to process the input traffic data and may fail as the size ofthe input traffic increases. It may be attributed to the numericalvalues of the traffic data involved. To sum up, the futuredirections to empower NIDS via LLM can be: 1. Aligningencrypted traffic data with the input requirements of LLMs,thus speeding the intrusion detection via LLM; 2. Determiningthe necessary volume of traffic data and corresponding trafficmining technology to unlock the powerful inference capabili-ties of LLM.",
  "VI. CONCLUSION": "This paper quantitatively studies the inconsistent perfor-mances of existing NIDS under various attacks and revealsthat the underlying cause is entangled feature distributions.Furthermore, we delve into the deeper reasons for the poorfew-shot intrusion detection performance of existing NIDS.These interesting observations motivate us to propose DIDS-MFL. The former is a novel method that aims to benefitknown and unknown attacks with a double disentanglementscheme and graph diffusion mechanism, and the latter isa transform-based multi-scale few-shot learner to help few-shot traffic threats distinguishable. The proposed DIDS firstemploys statistical disentanglement on the traffic featuresto automatically differentiate tens and hundreds of complexfeatures and then employs representational disentanglementon the embeddings to highlight attack-specific features. DIDSalso fuses the network topology via multi-layer graph diffusionmethods for dynamic intrusion detection. Finally, the proposedMFL uses an alternating optimization framework to separateand disentangle the few-shot traffic representations. Extensiveexperiments on five benchmarks show the effectiveness and thepractical employment potential of our DIDS-MFL, includingbinary classifications, multi-classifications, unknown attackidentification, and few-shot intrusion detection. Future work",
  "K. M. Prasad, Dos and ddos attacks: defense, detection and trace-back mechanisms-a survey, Global Journal of Computer Science andTechnology, vol. 14, no. E7, pp. 1532, 2014": "B. Bhushan and G. Sahoo, Recent advances in attacks, technicalchallenges, vulnerabilities and their countermeasures in wireless sensornetworks, Wireless Personal Communications, vol. 98, pp. 20372077,2018. X. Li, F. Bian, M. Crovella, C. Diot, R. Govindan, G. Iannaccone,and A. Lakhina, Detection and identification of network anomaliesusing sketch subspaces, in Proceedings of the 6th ACM SIGCOMMconference on Internet measurement, 2006, pp. 147152.",
  "C. Wueest, Targeted attacks against the energy sector, SymantecSecurity Response, Mountain View, CA, 2014": "S. Kumar, A. Viinikainen, and T. Hamalainen, Machine learningclassification model for network based intrusion detection system, in2016 11th international conference for internet technology and securedtransactions (ICITST).IEEE, 2016, pp. 242249. H. Zhao, N. Zheng, J. Li, J. Yao, and Q. Hou, Unknown malwaredetection based on the full virtualization and svm, in 2009 Interna-tional Conference on Management of e-Commerce and e-Government.IEEE, 2009, pp. 473476.",
  "M. Masdari and H. Khezri, A survey and taxonomy of the fuzzysignature-based intrusion detection systems, Applied Soft Computing,vol. 92, p. 106301, 2020": "N. T. Van, T. N. Thinh et al., An anomaly-based network intrusiondetection system using deep learning, in 2017 international conferenceon system science and engineering (ICSSE). IEEE, 2017, pp. 210214. S. Aljawarneh, M. Aldwairi, and M. B. Yassein, Anomaly-based intru-sion detection system through feature selection analysis and buildinghybrid efficient model, Journal of Computational Science, vol. 25, pp.152160, 2018. M. Eskandari, Z. H. Janjua, M. Vecchio, and F. Antonelli, Passban ids:An intelligent anomaly-based intrusion detection system for iot edgedevices, IEEE Internet of Things Journal, vol. 7, no. 8, pp. 68826897,2020. Z. Ahmad, A. Shahid Khan, C. Wai Shiang, J. Abdullah, and F. Ahmad,Network intrusion detection system: A systematic study of machinelearning and deep learning approaches, Transactions on EmergingTelecommunications Technologies, vol. 32, no. 1, p. e4150, 2021.",
  "V. Sharma and R. N. Mir, A comprehensive and systematic lookup into deep learning based object detection techniques: A review,Computer Science Review, vol. 38, p. 100301, 2020": "B. Xi, J. Li, Y. Li, R. Song, D. Hong, and J. Chanussot, Few-shot learning with class-covariance metric for hyperspectral imageclassification, IEEE Transactions on Image Processing, vol. 31, pp.50795092, 2022. [Online]. Available: M. Hu, H. Chang, Z. Guo, B. Ma, S. Shan, and X. CHEN,Understanding few-shot learning: Measuring task relatedness andadaptation difficulty via attributes, in Thirty-seventh Conference onNeural Information Processing Systems, 2023. [Online]. Available: R. Samrin and D. Vasumathi, Review on anomaly based networkintrusion detection system, in 2017 international conference on electri-cal, electronics, communication, computer, and optimization techniques(ICEECCOT).IEEE, 2017, pp. 141147. L. Ma, Y. Chai, L. Cui, D. Ma, Y. Fu, and A. Xiao, A deeplearning-based ddos detection framework for internet of things, in ICC2020-2020 IEEE International Conference on Communications (ICC).IEEE, 2020, pp. 16. N. Hu, Z. Tian, H. Lu, X. Du, and M. Guizani, A multiple-kernelclustering based intrusion detection scheme for 5g and iot networks,International Journal of Machine Learning and Cybernetics, vol. 12,no. 11, pp. 31293144, 2021. Y. Li, R. Li, Z. Zhou, J. Guo, W. Yang, M. Du, and Q. Liu, Graphddos:Effective ddos attack detection using graph neural networks, in 2022IEEE 25th International Conference on Computer Supported Cooper-ative Work in Design (CSCWD).IEEE, 2022, pp. 12751280. R. Doriguzzi-Corin, S. Millar, S. Scott-Hayward, J. Martinez-del Rin-con, and D. Siracusa, Lucid: A practical, lightweight deep learningsolution for ddos attack detection, IEEE Transactions on Network andService Management, vol. 17, no. 2, pp. 876889, 2020.",
  "I. J. King and H. H. Huang, Euler: Detecting network lateral move-ment via scalable temporal link prediction, Network and DistributedSystems Security (NDSS) Symposium, 2022": "L. H. Gilpin, D. Bau, B. Z. Yuan, A. Bajwa, M. Specter, and L. Kagal,Explaining explanations: An approach to evaluating interpretability ofmachine learning, arXiv preprint arXiv:1806.00069, p. 118, 2018. M. W. Gondal, M. Wthrich, . Miladinovic, F. Locatello, M. Breidt,V. Volchkov, J. Akpo, O. Bachem, B. Schlkopf, and S. Bauer, Onthe transfer of inductive bias from simulation to the real world: a newdisentanglement dataset, Advances in Neural Information ProcessingSystems 32, vol. 20, pp. 15 66115 672, 2020. F. Locatello, B. Poole, G. Rtsch, B. Schlkopf, O. Bachem, andM. Tschannen, Weakly-supervised disentanglement without compro-mises, in International Conference on Machine Learning.PMLR,2020, pp. 63486359.",
  "C. Xu, J. Shen, and X. Du, A method of few-shot network intrusiondetection based on meta-learning framework, IEEE Transactions onInformation Forensics and Security, vol. 15, pp. 35403552, 2020": "Y. Ouyang, B. Li, Q. Kong, H. Song, and T. Li, Fs-ids: A novel few-shot learning based intrusion detection system for scada networks, inICC 2021 - IEEE International Conference on Communications, 2021,pp. 16. Z. Shi, M. Xing, J. Zhang, and B. Hao Wu, Few-shot network intrusiondetection based on model-agnostic meta-learning with l2f method,in 2023 IEEE Wireless Communications and Networking Conference(WCNC), 2023, pp. 16.",
  "H. Xu, H. Xiong, and G.-J. Qi, K-shot contrastive learning of visualfeatures with multiple instance augmentations, 2021": "M. N. Rizve, S. Khan, F. S. Khan, and M. Shah, Exploring com-plementary strengths of invariant and equivariant representations forfew-shot learning, in Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR), June 2021, pp.10 83610 846. B. Xi, J. Li, Y. Li, R. Song, D. Hong, and J. Chanussot, Few-shot learning with class-covariance metric for hyperspectral imageclassification, IEEE Transactions on Image Processing, vol. 31, pp.50795092, 2022.",
  "X. Chen, G. Zhu, and J. Wei, Mmml: Multimanifold metric learningfor few-shot remote-sensing image scene classification, IEEE Trans-actions on Geoscience and Remote Sensing, vol. 61, pp. 114, 2023": "J. Snell, K. Swersky, and R. Zemel, Prototypical networks for few-shot learning, in Proceedings of the 31st International Conference onNeural Information Processing Systems, ser. NIPS17. Red Hook, NY,USA: Curran Associates Inc., 2017, p. 40804090. F. Sung, Y. Yang, L. Zhang, T. Xiang, P. H. S. Torr, andT. M. Hospedales, Learning to compare: Relation network forfew-shot learning, 2018 IEEE/CVF Conference on Computer Visionand Pattern Recognition, pp. 11991208, 2017. [Online]. Available: O. Vinyals, C. Blundell, T. Lillicrap, K. Kavukcuoglu, and D. Wierstra,Matching networks for one shot learning, in Proceedings of the 30thInternational Conference on Neural Information Processing Systems,ser. NIPS16.Red Hook, NY, USA: Curran Associates Inc., 2016, p.36373645. J. Oh, S. Kim, N. Ho, J.-H. Kim, H. Song, and S.-Y. Yun,Understanding cross-domain few-shot learning based on domainsimilarity and few-shot difficulty, in Advances in Neural InformationProcessing Systems, A. H. Oh, A. Agarwal, D. Belgrave, andK. Cho, Eds., 2022. [Online]. Available: L. De Moura and N. Bjrner, Z3: An efficient smt solver, in Toolsand Algorithms for the Construction and Analysis of Systems: 14thInternational Conference, TACAS 2008, Held as Part of the JointEuropean Conferences on Theory and Practice of Software, ETAPS2008, Budapest, Hungary, March 29-April 6, 2008. Proceedings 14.Springer, 2008, pp. 337340.",
  "W. Lalouani and M. Younis, Robust distributed intrusion detectionsystem for edge of things, in 2021 IEEE Global CommunicationsConference (GLOBECOM).IEEE, 2021, pp. 0106": "M. Sarhan, S. Layeghy, and M. Portmann, Evaluating standard featuresets towards increased generalisability and explainability of ml-basednetwork intrusion detection, Big Data Research, vol. 30, p. 100359,2022. E. Caville, W. W. Lo, S. Layeghy, and M. Portmann, Anomal-e:A self-supervised network intrusion detection system based ongraph neural networks, Knowledge-Based Systems, vol. 258, p.110030, 2022. [Online]. Available: X. Guo, B. Zhou, and S. Skiena, Subset node anomaly trackingover large dynamic graphs, in Proceedings of the 28th ACM SIGKDDConference on Knowledge Discovery & Data Mining, ser. KDD 22.Association for Computing Machinery, 2022. [Online]. Available:",
  "R. E. Schapire, Explaining adaboost, Empirical Inference: Festschriftin Honor of Vladimir N. Vapnik, pp. 3752, 2013": "R. S. Fisher, J. H. Cross, J. A. French, N. Higurashi, E. Hirsch,F. E. Jansen, L. Lagae, S. L. Mosh, J. Peltola, E. Roulet Perezet al., Operational classification of seizure types by the internationalleague against epilepsy: Position paper of the ilae commission forclassification and terminology, Epilepsia, vol. 58, no. 4, pp. 522530,2017. S. Kim, J. Lee, N. Lee, W. Kim, S. Choi, and C. Park, Task-equivariantgraph few-shot learning, in Proceedings of the 29th ACM SIGKDDConference on Knowledge Discovery and Data Mining, 2023, pp.11201131.",
  "F. Liu, D. Chen, F. Wang, Z. Li, and F. Xu, Deep learningbased single sample face recognition: a survey, Artificial IntelligenceReview, vol. 56, no. 3, p. 27232748, Aug. 2022. [Online]. Available:": "L. Huang, W. Yu, W. Ma, W. Zhong, Z. Feng, H. Wang, Q. Chen,W. Peng, X. Feng, B. Qin, and T. Liu, A survey on hallucinationin large language models: Principles, taxonomy, challenges, and openquestions, 2023. Chenyang Qiu received his B.Sc. degree in science from Beijing JiaotongUniversity, Beijing, China, in 2020. He is currently pursuing his Ph.D degree atthe National Engineering Research Center for Mobile Network Technologies,Beijing University of Posts and Telecommunications, Beijing. His researchinterests include Wireless Network Intrusion Detection, Semantic Communi-cation, Graph Neural Networks, and AI Robustness. He has published papersin top-tier conferences and journals including KDD, AAAI, and IEEE TCYB.Guoshun Nan (Member, IEEE) is a tenure-track professor at the NationalEngineering Research Center for Mobile Network Technologies, BeijingUniversity of Posts and Telecommunications. He has broad interest in naturallanguage processing, computer vision, machine learning, and wireless com-munications, such as information extraction, model robustness, multimodalretrieval, and next-generation wireless networks. He is a member of theNational Engineering Research Center for Mobile Network Technologies. Hehas published papers in top-tier conferences and journals including ACL,CVPR, EMNLP, SIGIR, IJCAI, CKIM, SIGCOMM, IEEE JSAC, IEEECommunications Magazine, IEEE Network, Computer Networks. He servedas a Reviewer for ACL, EMNLP, AAAI, IJCAI, Neurocomputing, and IEEETransactions on Image Processing.Hongrui Xia is an undergraduate student at the National Engineering Re-search Center for Mobile Network Technologies, Beijing University of Postsand Telecommunications. He specializes in network security and intrusiondetection, aiming to advance his expertise in safeguarding digital systems anddetecting cyber threats. Dedicated to contributing to the field through researchand innovation.Zheng Weng is an undergraduate student at the National Engineering Re-search Center for Mobile Network Technologies, Beijing University of Postsand Telecommunications. He focuses on Graph Neural Networks (GNNs) andmachine learning, exploring innovative methods to enhance data security andnetwork integrity through advanced computational models.Xueting Wang is an undergraduate student at the National EngineeringResearch Center for Mobile Network Technologies, Beijing University ofPosts and Telecommunications. Her current research interests include artificialintelligence security, the analysis and detection of network traffic attacks, andthe use of AI automation to detect and analyze viruses such as Trojans.Meng Shen (Member, IEEE) received the B.Eng degree from ShandongUniversity, Jinan, China in 2009, and the Ph.D degree from TsinghuaUniversity, Beijing, China in 2014, both in computer science. Currently heserves in Beijing Institute of Technology, Beijing, China, as a professor. Hisresearch interests include privacy protection for cloud and IoT, blockchainapplications, and encrypted traffic classification. He received the Best PaperRunner-Up Award at IEEE IPCCC 2014. He is a member of the IEEE.Xiaofeng Tao (Senior Member, IEEE) received the bachelors degree inelectrical engineering from Xian Jiaotong University, Xian, China, in 1993,and the masters and Ph.D. degrees in telecommunication engineering from theBeijing University of Posts and Telecommunications (BUPT), Beijing, China,in 1999 and 2002, respectively. He is currently a Professor at the NationalEngineering Research Center for Mobile Network Technologies, BeijingUniversity of Posts and Telecommunications, a fellow of the Institution ofEngineering and Technology, and the Chair of the IEEE ComSoc BeijingChapter. He has authored or coauthored over 200 articles and three books inwireless communication areas. He focuses on B5G/6G research.Jun Liu (Member, IEEE) received the masters degree from Fudan Universityand the Ph.D. degree from the School of Electrical and Electronic Engineering,Nanyang Technological University. He is currently an Assistant Professor withthe Singapore University of Technology and Design. His research interestsinclude computer vision, machine learning, and artificial intelligence. Hisresearch works are published in many conferences and journals, includingIEEE Transactions on Pattern Analysis and Machine Intelligence, IEEETransactions on Image Processing, NeurIPS, CVPR, ICCV, and ECCV. Heis also an organizer of international workshops. He was the Area Chair ofICML/NeurIPS (20222023), ICLR (20222024), IJCAI 2023, and CVPR2024."
}