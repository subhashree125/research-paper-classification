{
  "Xinchen Zhang, Running Zhao, Zhihan Jiang, Zhicong Sun, Yulong Ding,Edith C.H. Ngai, Shuang-Hua Yang": "The University of Hong Kong Shenzhen Key Laboratory of Safety and Security for NextGeneration of Industrial Internet, Southern University of Science and TechnologyUniversity of Reading The Hong Kong Polytechnic University AbstractThe rapid expansion of the Internet of Things (IoT)has raised increasing concern about targeted cyber attacks.Previous research primarily focused on static Intrusion DetectionSystems (IDSs), which employ offline training to safeguard IoTsystems. However, such static IDSs struggle with real-worldscenarios where IoT system behaviors and attack strategies canundergo rapid evolution, necessitating dynamic and adaptableIDSs. In response to this challenge, we propose AOC-IDS, anovel online IDS that features an autonomous anomaly detectionmodule (ADM) and a labor-free online framework for contin-ual adaptation. In order to enhance data comprehension, theADM employs an Autoencoder (AE) with a tailored ClusterRepelling Contrastive (CRC) loss function to generate distinctiverepresentation from limited or incrementally incoming data inthe online setting. Moreover, to reduce the burden of manuallabeling, our online framework leverages pseudo-labels automat-ically generated from the decision-making process in the ADMto facilitate periodic updates of the ADM. The elimination ofhuman intervention for labeling and decision-making boosts thesystems compatibility and adaptability in the online setting toremain synchronized with dynamic environments. Experimentalvalidation using the NSL-KDD and UNSW-NB15 datasets demon-strates the superior performance and adaptability of AOC-IDS,surpassing the state-of-the-art solutions. The code is released at Termsintrusion detection system, online learning, con-trastive learning, Internet of Things",
  "I. INTRODUCTION": "The exponential growth of the Internet of Things (IoT)has revolutionized multiple sectors, including transportation,healthcare, smart cities, agriculture, and more . How-ever, it also escalates cybersecurity threats. For example, themalware attacks targeted at IoT systems aggravate every year1.Given this, developing Intrusion Detection Systems (IDS) thatcan adapt to evolving or new attacks and efficiently learnfrom enormous data is paramount , . The advances inmachine learning, particularly deep learning, have boosted thisdevelopment .Basically, IDS falls into two categories: signature-baseddetection and anomaly-based detection . While signature-based detection efficiently identifies known threats by com-",
  "Co-corresponding authors: Edith C.H. Ngai (Email: ),Shuang-Hua Yang (Email: )1": "paring data against a library of threat signatures, it strug-gles with unknown threats . Conversely, anomaly-baseddetection systems depend on their comprehension of regularbehavioral patterns, termed as representations or features.They trigger alerts upon identifying deviations from theseestablished patterns, thereby facilitating the detection of novelor zero-day attacks . This approach provides a significantadvantage over signature-based detection, particularly withinan ever-evolving threat landscape. Therefore, we concentrateon anomaly-based systems to handle new and changing threats.In dynamic open-world scenarios, not only new malicioussystem patterns like zero-day attacks can emerge, but alsobenign behavior of the system can evolve over time. Thisevolution could be attributed to environmental changes orshifts in user preferences, both capable of altering normalpatterns. Given the reliance of anomaly-based intrusion de-tection on accurate modeling of normal system patterns, anyshift in the normal-abnormal behavior boundary could impairdetection performance. Therefore, anomaly-based intrusionsystems necessitate continuous adaptation to the evolvingnormal behavior of the system over time. Online learningoffers an effective solution to enhance the systems adaptabilitythrough ongoing monitoring and updating system behaviorprofiles. However, there are still significant research gapsin the application of online learning to anomaly-based IDS,especially for identifying anomalies from streaming data inIoT systems. Most existing learning-based anomaly detectionsystems train a static model offline, lacking dynamism in anever-changing environment. It is important to note that manyexisting works related to online IDS often refer to IDS thatdetects intrusions by performing real-time inferences, in whichits training process remains the same as that of offline IDS withno further model updates .Establishing an effective online learning framework forintrusion detection necessitates prompt adaptation of the IDSto a continuous influx of unlabeled data. This situation givesrise to a number of significant challenges.Primarily, online learning requires the model to establisha normal profile of system patterns from limited or incre-mentally incoming data and be able to adapt to changingdata distributions without extensive retraining. To increase therepresentation learning capability of the model, we employ",
  "arXiv:2402.01807v1 [cs.CR] 2 Feb 2024": "contrastive learning , a method renowned for its abilityto learn robust and informative representations by attractingpositive (similar) pairs and repelling negative (dissimilar)pairs, enabling the anomaly-based IDS to capture commoncharacteristics of benign behaviors effectively and distinguishthese benign representations from malicious ones. Specifically,we propose a novel supervised contrastive loss, named ClusterRepelling Contrastive (CRC) loss. The CRC loss, coupledwith the simultaneous use of both encoder and decoder out-puts from an Autoencoder (AE), significantly enhances therepresentation capability of the detection model with limitedavailable information. As for the post-processing of data repre-sentations, we implement an autonomous statistical decision-making process based on Gaussian distributions for intrusiondetection. Compared to traditional methods, which usuallyrequire manual threshold selection, the proposed decision-making method is more compatible with the online setting.Moreover, online learning also confronts the inherent chal-lenge of effectively utilizing substantial volumes of unlabeleddata. Many existing approaches , employ a straight-forward method of manually labeling new data, which is alabor-intensive process that compromises the practicality ofthe system. To address this issue, we propose the use ofpseudo-labels generated by the IDS itself based on currentknowledge to complete the intrusion detection process andthe dataset expansion autonomously. Leveraging these pseudo-labels facilitates the use of supervised contrastive loss, whichprovides clearer guidance for the learning algorithm thanunsupervised ones. This strategy significantly reduces the laborfor labeling a high volume of unlabeled data and ensuresmodel performance through a supervised contrastive loss.In this work, our contributions are summarized as follows: We present AOC-IDS, an autonomous online IDS, fea-turing a distinct anomaly detection module (ADM) andan innovative online framework enabling continual adap-tation. Our system design delivers a robust solution forintrusion detection in dynamic environments where thesystem behaviors and attack strategies evolve over time. We employ an AE with a custom-designed CRC lossfunction and leverage both encoder and decoder outputsfor superior data comprehension and enhanced repre-sentation capability within the ADM. The utilization ofcontrastive learning benefits the discrimination of repre-sentations for differentiating malicious behavior based onnormal system patterns. In the online learning framework, we utilize an au-tonomous decision-making process without human inter-vention to generate pseudo-labels. These pseudo-labelsalleviate the demand for manual labeling and facilitateautonomous updates, making our ADM highly compati-ble with the online framework. We conduct extensive experiments on network traf-fic datasets, NSL-KDD and UNSW-NB15 datasets, todemonstrate the optimal performance and adaptability ofAOC-IDS. The ablation study reveals the contributions ofindividual components. : System overview of AOC-IDS. In the proposed system,the ADM undergoes adaptation within the online framework.The online framework consists of two steps: pseudo-labelgeneration and system adaptation. The ADM extracts thefeature of an input using an AE and the extracted feature islabeled according to the Gaussian fit result.",
  "II. SYSTEM OVERVIEW": "Developing an online learning-based IDS that can effec-tively adapt to dynamic environments involves two key com-ponents: (i) Anomaly Detection Module: This necessitatesthe establishment of an ADM that is proficient in detectingintrusions, especially for the online setting with limited orincrementally incoming data. (ii) Online Framework: Thiscalls for the effective utilization of unlabeled new data toperpetually update the ADM. gives an overview of AOC-IDS. The ADM extractsthe feature of an input using an AE and the extracted featureis labeled according to the Gaussian fit result. The ADM alsoundergoes adaptation within the online framework. The onlineframework consists of two steps, pseudo-label generation andsystem adaptation, to continually update the ADM.",
  "A. Anomaly Detection Module": "In cybersecurity, the efficacy of an anomaly-based detectionsystem depends on its understanding of normal behavioralpatterns. It is pivotal for the system to generate discrimina-tive representations and discern benign representations frompotential threats for accurate intrusion detection.As depicted in , the ADM thus comprises arepresentation-learning process, responsible for the extractionof salient features from the input and training data, and adecision-making process, which established the normal behav-ioral patterns and separates potential malicious features fromnormal behavioral patterns autonomously.Representation Learning with a Novel Contrastive Loss.We propose a novel AE incorporating supervised contrastive learning to generate more discriminative representations forintrusion detection from both the encoder and decoder, enhanc-ing the differentiation between normal and abnormal patterns.Our AE, while maintaining a similar structure to traditionalAEs, features a modified CRC loss and focuses on extractingsalient intrusion detection features from input vectors via boththe encoder and decoder. The AE is trained to generate similarrepresentations for all normal instances, while distancing theintrusion representations. This method is more straightforwardthan reconstructing normal instances for intrusion detection.Consequently, the proposed approach leads to a more efficientand accurate intrusion detection model.In contrastive learning, an anchor sample is a reference datapoint used for comparison. During training, similar examples(positive samples) are encouraged to have high similarity, anddissimilar examples (negative samples) are encouraged to havelow similarity with the anchor. This process aids the modelin learning discriminative representations for grouping similarsamples together and distancing dissimilar ones.In intrusion detection, the variability of zero-day attacksnecessitates a training focus on normal behavior, which isconsistent, unlike the divergent patterns of attacks. Hence, ourcontrastive learning uses only normal samples as anchors toconstruct positive pairs, treating all abnormalities as negatives.Notations. In the subsequent analysis, the subscripts n anda represent normal and abnormal, while the superscriptsen and de represent the encoder and decoder. For a fixedtraining dataset D inclusive of both normal and abnormal data:",
  "B. Online Framework": "The online framework updates the ADM and dataset contin-ually, preserving the systems adaptability to evolving threats.It has two phases: (i) pseudo-label generation based oninference from the ADM, eliminating manual labeling for au-tonomous updates, and (ii) system adaptation for model fine-tuning and the regeneration of Gaussian distribution parame-ters aligned with the continuously updated training dataset.Initially, a detection model is trained using a small labeleddataset. Once a certain amount of new inputs has been pseudo-labeled, the model is updated using the expanded dataset,including both true (initial) labels and pseudo-labels.Our framework incorporates specific considerations, such asthe introduction of random noise and constraints on the acqui-sition of Gaussian distributions. These factors alleviate poten-tial overfitting due to incorrect judgments, thereby enhancingthe overall robustness of the online learning framework.",
  "= {{x1,...,xln},{y1,...,yln},{x1,...,xla},{y1,...,yla}},": "where X and Y stand for the set of input vectors and theircorresponding labels. The dataset comprises ln ( N) normalinputs and la ( N) abnormal inputs. Each input vector x hasa dimension d ( N), while each label y {0,1}, where 0signifies normal, and 1 signifies abnormal. We denote eachlearned representation of the input in the training dataset asv V. The detection model in our work is denoted as AE,where is the model weight.In this work, we propose the CRC loss function extendedfrom the standard InfoNCE , one of the most popularlosses in contrastive learning. For an anchor sample repre-sentation vn,i from the normal class, the goal is to maximizethe similarity between the positive pair {vn,i,vn, j}, wherei, j {1,2,...,ln}, while minimizing the similarity betweenthe anchor sample vn,i and negative example set {va,k|k {1,2,...,la}}. The CRC loss denoted by L , can then beformulated as:",
  ": Difference between InfoNCE loss and CRC loss inintrusion detection": "where (0,1] is the temperature parameter and the functionh() is a function that measures the similarity between twovectors, detailed in (3).It is worth noting that when selecting the negative samplepairs, we traverse not only all the negative samples corre-sponding to each fixed anchor sample but also all the availableanchors in the normal class. This adjustment enables a dual-category repulsion effect at each stage, unlike the traditionalmethod where only a single anchor repels negative samplesand does not pay attention to the relationship between negativeexamples and other positive samples, demonstrated in .In this work, we use the cosine similarity score to evaluatethe similarity between two vectors, defined as follows:",
  "L final = L en +L de.(4)": "By minimizing the loss function, we can achieve a dualobjective: to simultaneously maximize the similarity amongnormal data representations and minimize the similarity be-tween normal representations and those of intrusions.Autonomous Decision-Making Process. Our ADM incor-porates an autonomous decision-making process, as detailedin . It starts with the learned representations of alltraining data D and the average (mean) representation ofnormal training data Dn.Subsequently, we calculate cosine similarity scores betweenthe average normal representation and all training dataset rep-resentations. Intuitively, the distribution of these scores shouldfollow the combined form of two Gaussian distributions. TheGaussian distribution with a higher mean parameter shouldrepresent the normal distribution because normal represen-tations should have greater similarity to the average normalrepresentations by nature. In contrast, the Gaussian distributionwith a lower mean represents the abnormal distribution.To formalize this intuition, we use Maximum LikelihoodEstimation (MLE) to fit cosine similarity scores into two Gaus-sian distributions, denoted as normal and abnormal. This",
  ": Timeline of the proposed online framework": "label-free optimization reduces overfitting risks on challengingsamples.During inference, after obtaining the representation of eachtest input from AE, we calculate the cosine similarity score be-tween the test representation and the average normal represen-tation. This score is then applied to both normal and abnormalGaussian distributions to derive the associated probabilities.The class of the test data corresponds to the distribution typewith the higher probability.Our detection model independently processes input vectorsvia the encoder and decoder to generate representations. Asa result, the procedure mentioned above applies to both theencoder and decoder. The final decision stems from a votingmechanism that considers the outputs from both of them.The probability of the input correlating with each distributionserves as a confidence measure of the results, with the outcomeexhibiting higher confidence elected as the final decision.",
  "B. Incorporating Online Learning": "In the traditional closed-world scenario, one assumes thattraining data capture every possible instance or situation themodel may encounter post-deployment, which an offline-trained static IDS handles successfully. However, this as-sumption often falls short in real-world applications whereenvironmental conditions and system patterns are dynamic,necessitating continuous adaptations of the detection system.We propose an online learning framework that enhances oursystems adaptability to continuously changing environments.As shown in , our online framework follows a sequencethat includes expanding the training dataset with pseudo-labelsand periodically fine-tuning the ADM based on this expandeddataset. A salient feature of our approach is its independencefrom manual labeling during the online training process,thereby bolstering the systems practicality and efficiency.The online learning framework is presented in Algorithm 1. Initially, the detection model AE with random initializedweight is trained on a small initial labeled training datasetD0 = {X0,Y0} for epoch0 rounds (Algorithm 1 line 2). Sub-sequently, the online training process involves two stages: thepseudo-label generation phase (Algorithm 1 lines 5-9), and thesystem adaptation phase (Algorithm 1 lines 10-13).Pseudo-label Generation. In the pseudo-label generationphase, we assign a pseudo-label to each new input vector xj",
  "end": "passing through the ADM by the current model AE. If theinput is identified as anomalous (i.e., the pseudo-label yj is 1),the system promptly triggers an alarm. During the pseudo-labelgeneration phase, the ADM performs inference to generatepredictions, thereby fulfilling the intrusion detection task.System Adaptation. In the system adaptation phase, eachnew input x j and its corresponding pseudo-label yj are in-corporated to expand the training dataset D = {X,Y}. Afterdetecting m new data entries, we fine-tune the current detectionmodel AE over epoch1 iterations on the updated training setD. It is worth noting that the updated label set Y includes bothtrue labels and pseudo-labels.Nonetheless, the expanded training dataset may includemislabeled data, potentially causing the model to deviate fromthe truth and leading to inferior performance compared to ascenario where no updates were made.Therefore, to resist the adverse effect of false pseudo-labelsduring system updates, our framework incorporates specificstrategies, including constraints on the acquisition of Gaussiandistributions and the introduction of random noise to enhancethe robustness of the online learning framework.More specifically, we recognize the crucial role of the aver- age normal representation in generating distributions. Thus, werestrict the averaging of normal representations to the initialtraining dataset X0, which consists solely of true labels. Thisrestriction (Algorithm 1 line 5) ensures the reliability of theacquired Gaussian distributions. The random noise strategy(Algorithm 1 line 10) effectively mitigates the issue of over-fitting ones own wrong judgments in a self-learning context.It accomplishes this by diversifying the wrong judgments froma singular direction to various divergent directions, therebypreventing the model from continuously reinforcing its ownmistaken interpretations.Furthermore, we designed the ADM with the compatibilityof the online framework in mind. The autonomous decision-making process, which requires minimal label information,endows the system with a high degree of resistance to falselabel information. This is due to the Gaussian fit processmerely focusing on the shape of the distribution, rather thanthe class affiliation of the points within it.Through the implementation of these strategies, we can cre-ate a robust system that consistently delivers high performance,demonstrating resistance to inaccuracies from pseudo-labels.",
  "IV. EXPERIMENTS": "This section presents the experimental setup and results. Wedetail the datasets, experiment settings, and baseline methodsin subsection IV-A. The superior performance of AOC-IDSover the baseline methods in the online setting is demonstratedin subsection IV-B. Additionally, ablation experiments areconducted to illustrate the contribution of sub-componentsin AOC-IDS in subsection IV-C. The experimental resultsreveal that our method outperforms the state-of-the-art (SOTA)techniques and underscores the significant contributions ofeach component in our system to its capacity and adaptability.",
  "A. Dataset Preparation and Experiment Settings": "1) Datasets: To verify the effectiveness of the proposedmethod in intrusion detection, we conduct experiments on twodatasets, NSL-KDD and UNSW-NB15 , which arewidely used in the field of IoT system intrusion detection.NSL-KDD Dataset. A standard benchmark in intrusiondetection, NSL-KDD comprises 125,973 training and 22,544test network traffic samples, with 24 attack types in trainingand 38 in testing. These attacks span four categories: DoS(Denial of Service Attack), U2R (User to Root Attack), R2L(Remote to Local Attack), and Probing Attack. It is notablethat some attack types only exist in the test set rather thanthe training set, which makes the tasks closer to real-worldscenarios, i.e., zero-day attack detection.UNSW-NB15 Dataset. UNSW-NB15 contains a hybrid ofthe real modern norm and the contemporary synthesized attackactivities of the network traffic. To comprehensively representthe diversity of attacks, nine attack types are considered inthe dataset, including Fuzzers, Analysis, Backdoors, DoS,Exploits, Generic, Reconnaissance, Shellcode, and Worms.This dataset is divided into the training set with 175,341samples and the test set with 82,332 samples. 2) Baselines: We compare the proposed method with thefollowing SOTA baseline IDSs , and some otherwidely-used machine learning baselines, including decisiontree classifier (DTC), random forest (RF), support vectormachine (SVM), and XGBoost, in the same online setting. FeCo defines a contrastive loss, which is in theform of InfoNCE, for maximizing the distance betweenbenign and malicious representations while minimizingthe distance among benign representations. The learnedrepresentations are fed into a decision-making processwith a fixed threshold. CIDS is a contrastive learning-based IDS with acontrastive cross-entropy loss which is a combination ofcontrastive loss and classification loss. The labels can bedirectly generated by the detection model.3) Experiment Settings: Our pre-processing approach isstraightforward and avoids complex feature engineering. Itincludes two steps. Firstly, we remove any attribute with thesame value across the entire dataset as it does not contribute tothe task. In the NSL-KDD dataset, we removed one attributewith a constant value, reducing the dimensionality of trainingattributes from 41 to 40. The UNSW-NB15 dataset had nosuch attributes. Therefore, all 42 attributes were retained. Next,we normalize the continuous attributes and apply one-hotencoding to discrete ones. Following these steps, the NSL-KDD dataset ends up with 121 dimensions, while the UNSW-NB15 dataset with 196 dimensions. The data pre-processingprocedures are applied consistently across all comparativemethods to facilitate an equitable performance comparison.The experiments are, by default, conducted in an onlinesetting, a scenario in which the IDS initially has access onlyto a limited number of labeled datasets. The remaining datais gradually fed into the system in a streamlined manner.For both datasets, the ADM initially trains on 20% of theoriginal training datasets and undergoes an update after everyincremental addition of 1.6% of the original training dataset(2000 samples for NSL-KDD, and 2784 samples for theUNSW-NB15 dataset). For the NSL-KDD dataset, epoch0 = 4,epoch1 = 1, and = 20%. For the UNSW-NB15 dataset,epoch0 = 300, epoch1 = 3, and = 5%.The architecture of our AE comprises layer sizes for NSL-KDD and for UNSW-NB15. The training process employs a StochasticGradient Descent (SGD) optimizer with a learning rate of0.001 and a batch size of 128. The temperature in thecontrastive loss function is set to 0.02.The reported results are the average of five consecutiverounds of experimentation, guaranteeing their reliability.",
  "Acc.Pre.Rec.F1Acc.Pre.Rec.F1": "AOC-IDS88.9085.9996.2190.8189.1990.6589.7090.14w/o CRC loss88.7986.8794.6290.5685.8886.6689.4487.43w/o contrasitve loss74.6291.6560.9673.2181.4975.0499.4885.55w/o decoder87.6887.2891.9089.4469.1970.5675.3872.79w/o encoder87.6283.8297.0689.9484.6288.6382.8485.56w/o DC pro.86.0289.8485.0487.3486.5683.1794.7688.59 directly. Subsequent post-processing is then carried out todetermine the predicted label. By breaking down the intrusiondetection task into two distinct, more nuanced parts, thedetection model is able to focus on the representation learningtask resulting in a more powerful representation learningability brought by contrastive learning. This approach leadsto notable performance enhancements compared to systemsthat rely solely on binary cross-entropy loss for classification.2) Encoder & Decoder: We compared the methods ofsolely using the output information from either the encoder,described as w/o decoder, or the decoder, described asw/o encoder, to train the model in ACO-IDS. TABLE IIIsuggests that using information from both the encoder anddecoder outputs enhances performance. This is due to thecomprehensive integration of all available information to learnmore insightful representations from the input data, therebyimproving the models learning capability and facilitating adeeper understanding of the input data.3) Decision Making Process: We compared our adaptive,fully automated decision-making process with a fixed thresh-old method, represented by w/o DC pro. In the ablation studywith a fixed threshold, after obtaining the cosine similarityscore distribution, instead of fitting it into two Gaussiandistributions, we set a threshold as p% lowest normal cosinesimilarity score as in . Note that the threshold of p% hasspecific statistical implications, representing the tolerable falsepositive rate on the test set. Therefore, it is best to select astatistically common value. In this experiment, p is set to 5.TABLE III illustrates that adopting a fixed threshold resultedin a decline in system performance. Consequently, our adaptiveand fully automated decision-making process is advantageous.",
  "DoS459276+074586+4Probe116564+024214+2R2L9956+227546+8U2R524+02004+3": "subdivided into seen and unseen in the training dataset,for instance, DoS seen and DoS unseen, with all unseenattacks considered zero-day for the IDS.We use the recall for each kind of attack to eval-uate the detection rate of each kind of attack, as therecall measures the proportion of attacks that are de-tected. Given the prediction of j-th instance yj and thetrue label ofj-th instance ylabelj, the recall of each at-tack category i {attack seen,attack unseen}, whereattack {DoS,Probe,U2R,R2L} is defined as",
  "j 1(ylabelj= i),(5)": "where yj {0,1} is binary results of normal with label 0and attack with label 1, and 1() is the indicator function,which equals one if the condition in the function is satisfied. demonstrates AOC-IDS surpasses all comparisonmethods in the detection of zero-day attacks across all cate-gories, with a remarkable detection rate of over 91%. This highlevel of performance highlights AOC-IDSs capacity in man-aging zero-day attack challenges in dynamic environments.Despite a few selected methodologies, such as FeCo andSVM, attaining satisfactory detection rates (over 80%) forzero-day attacks in the Probe category, they fall short inmaintaining consistent performance across various attack cat- egories.Certain methodologies, including RF and XGBoost,present less than a 50% recall rate, thereby indicating theirinadequacy for detecting zero-day attacks.Significantly, the performance drop of AOC-IDS betweenknown and unknown attacks is minimal. This contrasts withsome methods which, while effective against known attacks,see a severe decline when facing unknown ones. This consis-tent performance demonstrates the IDSs capacity to accuratelydefine normal behavior patterns by utilizing a limited range ofattack types, showcasing its resilience when faced with theunpredictability of zero-day attacks.",
  "C. Ablation Experiments": "In this section, we conduct ablation experiments to delineatethe efficacy of various components and design strategies inAOC-IDS, including the CRC loss function, the integration ofencoder and decoder outputs, and the decision-making process.The analysis underscores their collective influence on boostingrepresentational learning capabilities and lessening manualintervention, thereby promoting adaptability and compatibilitywith dynamic environments.1) CRC Loss: We compared our custom-designed CRC losswith standard contrastive loss, i.e., InfoNCE loss and cross-entropy loss, denoted by w/o CRC loss and w/o contrastiveloss respectively. In TABLE III, the result shows the CRC lossoutperforms the InfoNCE loss. This verifies the superiority ofthe dual-category repulsion effect produced by the CRC lossbecause it avoids the possible repetitive pulling and pushingof negative sample pairs in the standard InfoNCE. Moreover,TABLE III provides evidence that utilizing contrastive losses,which includes our custom-crafted CRC and the standardInfoNCE, outperforms the use of classification (cross-entropy)loss. This underscores the importance of enhanced representa-tion learning capabilities offered by contrastive loss for intru-sion detection tasks. When cross-entropy loss is employed,the intrusion detection task can be solely handled by theAE, which directly predicts labels for the binary classificationtask (normal or abnormal). Conversely, when applyingcontrastive loss in our experimental setup, the primary role ofAE becomes learning representations, rather than predicting",
  "D. Analysis of Online Learning Performance": "The online setting is specially designed for the dynamic andever-changing environment in the real world. The two selecteddatasets represent two distinct scenarios: NSL-KDD approxi-mates real-world conditions with its dynamic network trafficbehavior and the potential for zero-day attacks, while UNSW-NB15 presents a more idealized scenario with static networktraffic behavior. Online learning is much more important inthe former than in the latter scenario.Hence, we conducted experiments to emphasize the differ-ent importance of online-learning deployment in these twoscenarios. The online training process consists of initial andsubsequent training phases. Performance post-initial trainingrefers to the system being trained solely based on the initiallabeled dataset. As illustrated in TABLE III, our Intrusion TABLE IV: Performance (%) of AOC-IDS: comparisons be-tween complete online training, initial online training, andoffline training. denotes the performance difference relativeto complete online training. The highest metric performanceis bolded.",
  "Offline91.0290.1195.3892.3689.6799.4485.8190.12-2.12-4.12+0.83-1.55-0.48-8.79+3.89+0.02": "Detection System (IDS) exhibits performance improvementsafter completing online training in both the NSL-KDD andUNSW-NB15 datasets, with a greater enhancement observedon the NSL-KDD dataset compared to the UNSW-NB15dataset. This observation validates the compatibility of AOC-IDS in the online setting and implies NSL-KDD, being amore challenging and dynamic dataset, benefits more from theonline setting. As for UNSW-NB15 with a relatively uniformdistribution in the training dataset, the model can achievesatisfactory performance with sufficient training on the limitedtraining dataset, leading to less significant performance im-provement after completing online training. In contrast, NSL-KDD is a more intricate dataset, and randomly selected datasubsets fail to represent the entire dataset. Consequently, inthe online setting, the performance shows greater improvementwhen exposed to all the input traffic in the training dataset onthe NSL-KDD dataset.The performance of offline training corresponds to trainingthe system with complete access to the label information ofthe original training dataset. As illustrated in TABLE III, inthe online setting, there is a slight decrease in performanceon the NSL-KDD dataset compared to offline settings. It isattributed to the limited labeled data in the online setting,making it more challenging. Nevertheless, this slight decreasein model performance under online settings is still consideredacceptable and does not significantly compromise the efficacyof the IDS in the online setting. Regarding the UNSW-NB15dataset, since the partial training dataset effectively representsthe entire training dataset, there is minimal performance vari-ation between online and offline training scenarios.",
  "A. Intrusion Detection": "Intrusion detection refers to the process of identifyingand responding to unauthorized or malicious activities thatpose a threat to system security . The development ofmachine learning, especially deep learning, has significantlyadvanced intrusion detection research, since they are effectiveand efficient in learning complex representations , . Various traditional machine learning methods, such asSVM and random forest , , and classic deep learningarchitectures, such as convolutional neural network (CNN), and recurrent neural network (RNN) have beenapplied to intrusion detection. Ferrag et al. reviewed theworks of intrusion detection systems based on deep learningapproaches and analyzed the performance of different deeplearning models, including RNNs, CNNs, deep AEs, restrictedBoltzmann machines, deep Boltzmann machines, and deepbelief networks.However, intrusion detection still faces several challenges,including adaptability to new system patterns, zero-day at-tacks, and labor-intensive labeling. To address these issues,online learning and contrastive learning have been incorpo-rated into IDS.",
  "B. Online Learning": "Online learning, proposed to address challenges in dynamicenvironments, is a machine learning paradigm that involvesperiodically updating a model as new data becomes available. This approach enables the model to adapt to changingdata distributions and facilitates continuous updates , .As a result, online learning is well-suited for various applica-tions, such as recommendation systems , fraud detection, spam filtering , resource allocation , and otherdomains where adaptive decision-making is crucial.In the context of IoT, the utilization of the online learn-ing paradigm has led to significant achievements due to itsadaptability . Although many online frameworks for IDScan update the models periodically to adapt to dynamic envi-ronments, they require labor-intensive labeling for continuoustraining . To address this issue, Han et al. proposedan online deep-learning framework that only labels the mostinfluential samples to reduce the labeling overhead. Gyamfi etal. developed a novel online network intrusion detectionsystem that can update the model when the environmentuncovers the dynamic attacks. Xu et al. proposed a few-shot meta-learning framework for IDS with only a limitednumber of shots of malicious samples.In this work, we propose an autonomous online-learningframework compatible with inherent streaming data in IoTsystems. This framework facilitates dynamic system updat-ing without the need for laborious manual labeling, therebyaugmenting its capability to manage evolving data streams.",
  "C. Contrastive Learning": "Contrastive learning learns representations by contrastingpositive samples with negative samples . The goal is toenhance the similarity between similar samples and increasethe dissimilarity between dissimilar samples in the learnedrepresentation space . InfoNCE is the most commonlyused loss function in contrastive learning, measuring the sim-ilarity between two views by comparing their representations. Contrastive learning has achieved state-of-the-art resultsin various domains, including computer vision , naturallanguage processing , and mobile computing . Contrastive learning has also been applied to enhance theperformance of intrusion detection systems. For instance,Wang et al. defined a contrastive loss for maximizingthe distance between benign and malicious samples and at thesame time, minimizing the distance among benign samples.In , a contrastive learning scheme was proposed to detectboth known and unknown attacks, expanding the representa-tion capacity of intrusion detection systems and outperformingsimilar models in detecting previously unseen attacks. Yue etal. introduced a contrastive learning-based method fornetwork intrusion detection, which improved accuracy whilereducing false detections caused by intra-class diversity andinter-class similarity. Liu et al. proposed CoLA, a con-trastive learning model that leveraged local information fromnetwork data for anomaly detection in attributed networks.In this study, we design a novel contrastive loss, specificallytailored to intrusion detection tasks. Operating within a binaryclassification paradigm, this function distinguishes betweentwo categories normal and abnormal, and generates adual-category repulsion effect at each step.",
  "VI. CONCLUSION": "In this paper, we introduce AOC-IDS, designed for intrusiondetection in dynamic network environments with evolvingattacks and system behaviors. By integrating an AE equippedwith a tailored CRC loss function, which utilizes the outputsof both the encoder and decoder, AOC-IDS achieves superiordata interpretation and enhanced representational capacity.These elements facilitate the more effective differentiationof malicious activities from standard system patterns. Cru-cially, the online learning framework facilitates autonomouscontinual adaptation of the system with the help of pseudo-labels automated generated from the ADM. The eliminationof manual labeling bolsters the practicality of AOC-IDS. Wesubstantiate the exceptional performance and adaptability ofAOC-IDS through comparative experiments on two datasets:NSL-KDD and UNSW-NB15. Our ablation study providesan insightful analysis of the contributions of each systemcomponent. Further analysis confirms that model updatingindeed enhances overall performance. When compared tooffline learning, our system maintains performance with asignificant reduction in the volume of information required. ThisresearchissupportedinpartbytheNationalNaturalScienceFoundationofChina(GrantNo.92067109,61873119,62211530106),inpartbytheShenzhen Science and Technology Program (Grant No.ZDSYS20210623092007023, GJHZ20210705141808024), inpart by the Educational Commission of Guangdong Province(Grant No. 2019KZDZX1018), and in part by the UGCGeneral Research Fund (Grant No. 17203320, 17209822)from Hong Kong. H. Pourrahmani, A. Yavarinasab, R. Zahedi, A. Gharehghani, M. H.Mohammadi, P. Bastani, and J. Van herle, The applications of internetof things in the automotive industry: A review of the batteries, fuel cells,and engines, Internet of Things, vol. 19, p. 100579, 2022. A. A. Brincat, F. Pacifici, S. Martinaglia, and F. Mazzola, The internetof things for intelligent transportation systems in real smart citiesscenarios, in 2019 IEEE 5th World Forum on Internet of Things (WF-IoT), 2019, pp. 128132.",
  "P.Garca-Teodoro,J.Daz-Verdejo,G.Macia-Fernandez,andE. Vazquez, Anomaly-based network intrusion detection: Techniques,systems and challenges, Computers & Security, vol. 28, no. 1, pp.1828, 2009": "M. A. Ferrag, L. Maglaras, S. Moschoyiannis, and H. Janicke, Deeplearning for cyber security intrusion detection: Approaches, datasets, andcomparative study, Journal of Information Security and Applications,vol. 50, p. 102419, 2020. F. E. Heba, A. Darwish, A. E. Hassanien, and A. Abraham, Principlecomponents analysis and support vector machine based intrusion de-tection system, in 2010 10th International Conference on IntelligentSystems Design and Applications, 2010, pp. 363367. I. Ahmad, M. Basheri, M. J. Iqbal, and A. Rahim, Performancecomparison of support vector machine, random forest, and extremelearning machine for intrusion detection, IEEE Access, vol. 6, pp.33 78933 795, 2018. R. Vinayakumar, K. P. Soman, and P. Poornachandran, Applyingconvolutional neural network for network intrusion detection, in 2017International Conference on Advances in Computing, Communicationsand Informatics (ICACCI), 2017, pp. 12221228.",
  "K. Al Jallad, M. Aljnidi, and M. S. Desouki, Anomaly detectionoptimization using big data and deep learning to reduce false-positive,Journal of Big Data, vol. 7, no. 1, pp. 112, 2020": "W. Wang, C. Liang, Q. Chen, L. Tang, H. Yanikomeroglu, and T. Liu,Distributed online anomaly detection for virtualized network slicingenvironment, IEEE Transactions on Vehicular Technology, vol. 71,no. 11, pp. 12 23512 249, 2022. G. Baldini and I. Amerini, Online distributed denial of service (ddos)intrusion detection based on adaptive sliding window and morphologicalfractal dimension, Computer Networks, vol. 210, p. 108923, 2022. M. A. Teixeira, M. Zolanvari, K. M. Khan, R. Jain, and N. Meskin,Flow-based intrusion detection algorithm for supervisory control anddata acquisition systems: A real-time approach, IET Cyber-PhysicalSystems: Theory & Applications, vol. 6, no. 3, pp. 178191, 2021.",
  "A. van den Oord, Y. Li, and O. Vinyals, Representation learning withcontrastive predictive coding, 2019": "F. Pendlebury, F. Pierazzi, R. Jordaney, J. Kinder, L. Cavallaro et al.,Tesseract: Eliminating experimental bias in malware classificationacross space and time, in Proceedings of the 28th USENIX SecuritySymposium.USENIX Association, 2019, pp. 729746. S. T. Jan, Q. Hao, T. Hu, J. Pu, S. Oswal, G. Wang, and B. Viswanath,Throwing darts in the dark? detecting bots with limited data usingneural data augmentation, in 2020 IEEE symposium on security andprivacy (SP).IEEE, 2020, pp. 11901206. N. Wang, Y. Chen, Y. Hu, W. Lou, and Y. T. Hou, Feco: Boostingintrusion detection capability in iot networks via contrastive learning,in IEEE INFOCOM 2022 - IEEE Conference on Computer Communi-cations, 2022, pp. 14091418.",
  "Y. Tian, C. Sun, B. Poole, D. Krishnan, C. Schmid, and P. Isola, Whatmakes for good views for contrastive learning? Advances in neuralinformation processing systems, vol. 33, pp. 68276839, 2020": "P. Khosla, P. Teterwak, C. Wang, A. Sarna, Y. Tian, P. Isola,A. Maschinot, C. Liu, and D. Krishnan, Supervised contrastive learn-ing, Advances in neural information processing systems, vol. 33, pp.18 66118 673, 2020. D. T. Hoffmann, N. Behrmann, J. Gall, T. Brox, and M. Noroozi,Ranking info noise contrastive estimation: Boosting contrastive learningvia ranked positives, in Proceedings of the AAAI Conference onArtificial Intelligence, vol. 36, no. 1, 2022, pp. 897905.",
  "P. H. Le-Khac, G. Healy, and A. F. Smeaton, Contrastive representationlearning: A framework and review, Ieee Access, vol. 8, pp. 193 907193 934, 2020": "R. Zhou, R. Zhao, and E. C. Ngai, Human activity recognition frommotion and acoustic sensors using contrastive learning, in 2023 IEEEInternational Conference on Acoustics, Speech, and Signal ProcessingWorkshops (ICASSPW), 2023, pp. 14. M. Lopez-Martin, A. Sanchez-Esguevillas, J. I. Arribas, and B. Carro,Contrastive learning over random fourier features for iot networkintrusion detection, IEEE Internet of Things Journal, vol. 10, no. 10,pp. 85058513, 2023. Y. Liu, Z. Li, S. Pan, C. Gong, C. Zhou, and G. Karypis, Anomaly de-tection on attributed networks via contrastive self-supervised learning,IEEE Transactions on Neural Networks and Learning Systems, vol. 33,no. 6, pp. 23782392, 2022."
}