{
  "ABSTRACT": "Job recommender systems are crucial for aligning job opportuni-ties with job-seekers in online job-seeking. However, users tend toadjust their job preferences to secure employment opportunitiescontinually, which limits the performance of job recommendations.The inherent frequency of preference drift poses a challenge topromptly and precisely capture user preferences. To address thisissue, we propose a novel session-based framework, BISTRO, totimely model user preference through fusion learning of semanticand behavioral information. Specifically, BISTRO is composed ofthree stages: 1) coarse-grained semantic clustering, 2) fine-grainedjob preference extraction, and 3) personalized top- job recommen-dation. Initially, BISTRO segments the user interaction sequenceinto sessions and leverages session-based semantic clustering toachieve broad identification of person-job matching. Subsequently,we design a hypergraph wavelet learning method to capture thenuanced job preference drift. To mitigate the effect of noise ininteractions caused by frequent preference drift, we innovativelypropose an adaptive wavelet filtering technique to remove noisyinteraction. Finally, a recurrent neural network is utilized to analyzesession-based interaction for inferring personalized preferences. Ex-tensive experiments on three real-world offline recruitment datasetsdemonstrate the significant performances of our framework. Sig-nificantly, BISTRO also excels in online experiments, affirming itseffectiveness in live recruitment settings. This dual success under-scores the robustness and adaptability of BISTRO.",
  "* Chen Zhu, Xiangyu Zhao, and Hengshu Zhu are the corresponding authors.This work was accomplished by the first author while interning at BOSS Zhipinunder the supervision of the second author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08.",
  "Session-based Recommendation, Interaction Hypergraph, Hyper-graph Wavelet Learning, Job Recommender System": "ACM Reference Format:Xiao Han, Chen Zhu, Xiao Hu, Chuan Qin, Xiangyu Zhao, and Heng-shu Zhu. 2024. Adapting Job Recommendations to User Preference Driftwith Behavioral-Semantic Fusion Learning. In Proceedings of the 30th ACMSIGKDD Conference on Knowledge Discovery and Data Mining (KDD 24),August 2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 12 pages.",
  "KDD 24, August 2529, 2024, Barcelona, SpainXiao Han et al": "performance. To address this difficulty, BISTRO employs a recur-rent neural network to align recommendations with previouslyextracted job preferences precisely. This approach underscores ourdedication to providing timely and relevant job matches, ensuringhigh accuracy in meeting user needs.To refine the analysis of a users personalized features, we con-sider the last jobs with which a user has recently interacted, alongwith their embeddings job , []. A recurrent neural networkis employed to generate the personalized feature :",
  "RELATED WORK2.1Job Recommender System": "In job recommender systems, various studies have been proposedto match job seekers with recruiters. As highlighted by , while traditional recommendersystems are adept at predicting job seekers preferences, a key toaugmenting the systems overall effectiveness lies in addressingthe issue of preference drift. Conventionally, this challenge hasbeen approached through feature engineering in a certain degree,utilizing content data to capture evolving preferences .Efforts have also been made to integrate clusteringinto recommender systems, tackling this problem at the modellevel by grouping similar users or jobs based on minimal user/jobcontents. Although the user and job representations could be en-hanced by these refined features, they heavily rely on the resultsof semantic analysis of fixed content. To overcome these limita-tions, we introduce a behavioral-semantic fusion framework thatmerges content-driven and interaction-based methodologies, offer-ing a more comprehensive and adaptive solution to the challengeof preference drift.",
  "Adapting Job Recommendations to User Preference Drift with Behavioral-Semantic Fusion LearningKDD 24, August 2529, 2024, Barcelona, Spain": "in those two sessions . These hyperedges also tackle the issue ofpreference drift among sessions.To sufficiently filter the noise while capturing the job preferences,we design a spectral-based hypergraph wavelet convolutional neu-ral network with a graph filter in the spectral domain for graphconvolutional operation.The graph convolution of the general graph signal with a filter R is defined as:",
  "PRELIMINARIES": "In this paper, we adopt the BISTRO framework to solve user prefer-ence drift during the job-seeking process in top- job recommen-dations for users. Specifically, as shown in the above statistics, webelieve a user U would continue to refine her/his resume alongwith her/his job preference drift. Thus, we first segment the userinteraction sequence based on the timestamps of resume refine-ment under the assumption that the job preferences of users remainrelatively stable within a given session. Definition 1. Job Preference Drift. It refers to the phenomenonin which users change their job preferences, which could be predomi-nantly observed through whether the user modifies the resume ratherthan modeling the short-term job-seeking behaviors where user inter-ests tend to remain stable.",
  "METHODOLOGY": "In this section, we detail the architecture of the proposed frame-work, BISTRO, illustrated in . The framework comprisesthree primary modules: 1) a coarse-grained semantic clusteringmodule, 2) a fine-grained job preference extraction module, and 3)a personalized top- recommendation module.Initially, the coarse-grained semantic clustering module incor-porates a feature clustering approach with a probabilistic latent semantic analysis method, which facilitates the identification ofbroad user or job categories. The probabilistic latent semantic analy-sis method could efficiently summarize topics of the resume contentand job requirements, and those topics could guide clustering direc-tions. Subsequent to this, the fine-grained job preference extractionmodule constructs a multi-granular interaction hypergraph to dealwith the data drift issue and then designs an adaptive waveletlearning algorithm for noise-robust preference extraction. In thehypergraph, we define two types of hyperedges, reflecting theintra-session and inter-session relationships, to introduce more in-formation to the graph. Moreover, the wavelet filter in hypergraphwavelet learning is designed to detect noise in the spectral domainand further adaptively mitigate the effects of data noise. The finalstage combines a recurrent neural network to discern personalizedjob preferences from short-term sequential interactions to generatetop- job recommendation results.",
  "Coarse-grained Semantic Clustering": "The coarse-grained semantic clustering serves as the foundationalcomponent of our framework, setting the stage for nuanced pref-erence feature extraction. By tackling the challenge of aligningdiverse and dynamic job preferences with suitable opportunities,this module highlights the core motivation behind the intricateprocess of facilitating effective employment matching. It utilizessemantic insights from resumes and job descriptions to broadlymatch job seekers with appropriate vacancies, identifying poten-tial fits based on semantic themes related to job preference andrecruitment requirements.In our model, the conditional probability between the documentcontent and words is captured through a latent embed-ding ( = Linear() or Linear()), representing a class or topic.The model parameters, (|) and (|), allow for the possibil-ity that words may associate with multiple classes and documentsthat may cover various topics. We assume that the distributionof words given a class, (|) is conditionally independent of thedocument, implying (|,) = (|). Thus, the joint probabilityof a document and a word is represented as:",
  "(|) = (,) (|,) (,) (|,) .(5)": "Following training, the \"folding-in\" process applies the estimated (|) to test documents , recalculating (|) while keep-ing (|) constant. Typically, only a few iterations of the EMalgorithm are required for this process.After semantic analysis, we combine the normalized documentand word latent embeddings {1,2, } with other normalizedattributes such as age to achieve clustering by K-Means algo-rithm for the whole data := U or V due to the fact of its highefficiency, as shown in Equation (6).",
  "Fine-grained Job Preference Extraction": "Short-term interactions at a session level always encompass issuesof user preference drift and noisy interactions, with each influencingthe other. To tackle the dual challenges above, the fine-grained jobpreference extraction module utilizes a novel adaptive hypergraphwavelet learning method in a unified approach.Initially, employing a standard graph structure to map user-jobinteractions often results in a proliferation of isolated vertices andedges, adversely impacting the efficacy of graph learning-based jobpreference extraction. In response, this paper introduces a hyper-graph structure, denoted as G = (V, E ), which utilizes twospecialized types of hyperedges to enhance the data with additionalinsights. The hypergraph for each user group encompasses jobgroup nodes, alongside corresponding features (graph signals) .The hyperedge, defined as = link(, , ) E, constitutes a subset of the vertex set V, capturing complex, high-order rela-tionships within the graph. For illustration, consider two sessions:1= {1, 2, 3, 4}, 2= {5, 2, 6, 7, 2, 8}. The introductionof two distinct hyperedge types significantly augments the dataconnectivity within the user-job graph, as depicted in .Session Hyperedges E . The intra-session relationship is demon-strated as one of the critical factors to session-based recommenda-tion . For each user group, we link all jobs in each session toenhance the connectivity of these jobs. As for the job 2 in (a), we connect the session jobs {1, 3, 4} and {5, 6, 7, 8} thatinclude it with a hyperedge, respectively. It reveals the high-ordercorrelation of jobs facilitating the interaction on 2.",
  "where is the layer index, (1) R1 is the input graphsignal, (0):,= R1, 1 is the number of input channels": "and is the number of output channels, (), is a diagonal matrixfilled with learnable parameters.From Equation (9), the Laplacian eigenvectors of the hypergraphneed to be precomputed to realize the mapping of hypergraphfeatures between the vertex and spectral domains. Note that theLaplacian matrix of a hypergraph is defined as follows: L := = 1 , where is the adjacency matrix of thehypergraph, is the node-edge relationship matrix, and are degree matrix of nodes and hyperedges separately. Then, theeigenvectors can be obtained by eigendecomposition methods, asshown in Equation (10). 1 = ,(10)where is a diagonal matrix of Laplacian eigenvalues.In addition, the filter utilized in Equation (9) is usually aset of learnable hyperparameters but has problems such as con-vergence difficulty. Therefore, we utilize the wavelet kernel tofinely define a series of filters that filter in-session noise adap-tively for different user groups. Similar to the hypergraph Fouriertransform, the hypergraph wavelet transform projects the hyper-graph signal from the vertex domain into the spectral domain.Graph wavelet transform employs a set of wavelets as bases, de-fined as = concat(1 ,2 , , ) R, where each wavelet R1 corresponds to a signal on graph diffused away fromnode and is a scaling parameter, which is adapted to spectrumbounds. Mathematically, and 1can be written as",
  "= () T, 1= () T,(11)": "where () = diag[(1), ,()] and () = diag[1(1), ,1()] are scaling matrix.To reduce the computational overhead incurred by the inverseoperation, we choose the heat kernel () := as the waveletmother kernel in this paper, and then 1() = () = ().However, eigen-decomposition is known to have extremely highcomputational overhead. In order to avoid the computational costcaused by solving the eigen-decomposition of the Laplacian matrix,we use Chebyshev polynomials to approximate the convolutionaloperator =1 , where =2",
  "EXPERIMENTS": "In this section, we first describe the datasets used in this paper. Then,we introduce the experimental settings and compare BISTRO withrepresentative baselines. We further present some case studies onjob recommendations (Appendix C.3). The experiments are mainlydesigned to answer the research questions as follows: RQ1: Can our BISTRO recommend suitable jobs for users? RQ2: Does the clustering module effectively accommodate newjobs or users who have just revised their resumes? RQ3: How does the specially designed hypergraph wavelet learn-ing method deal with preference drift and noise issues? RQ4: How do different settings influence the model performance?",
  "Dataset": "The datasets come from the real-world online recruitment marketsof multiple cities (Shenzhen, Shanghai, and Beijing). We utilizethe user-job interaction (browse, click, chat, and so on) logs, userresumes, and job requirements data on this platform from July 1,2023 to January 31, 2024 (215 days in total). To protect the privacyof users and platform operators, all sensitive information related tousers is hashed or removed, and we only keep those data in the in-formation technology industry. The detailed statistical informationof our datasets is summarized in .",
  "Experimental Settings": "BaselinesWe compare BISTRO with baselines from differenttypes of recommendation methods, including conventional meth-ods: BasicMF , ItemKNN , PureSVD , and SLIM ,DAE , MultVAE , EASE ; Graph neural networks-basedmethods: SLRec and SGL , P3a , RP3b , NGCF ,LightGCN , GCCF , NCL , DirectAU , HG-GNN ,A-PGNN , AdaGCL , and MvDGAE ; Sequential recom-mendation methods: STAMP , GRU4Rec , BERT4Rec ,CL4Rec , CoScRec , and TiCoSeRec . More details aboutthese baselines are shown in Appendix C.1. For ablation studies, wecompare the variants of BISTRO to verify the effectiveness of eachcomponent.Evaluation metricsIn this paper, two metrics commonly usedin recommendation algorithms are used as evaluation metrics: hitratio and mean reciprocal rank, and the definitions of these metricsare demonstrated as follows:",
  "Hit Ratio (HR): It measures the proportion of successful recom-mended jobs out of all the recommendations made. Later, we useH@ to denote the value of HR when the model makes top-recommendations": "Mean Reciprocal Rank (MRR): It is a statistical measure thatfocuses explicitly on the rank of the first relevant item in the list ofrecommendations to show the effectiveness of a recommendationmethod, and in this paper we use the symbol M@ to presentthis metric for simplicity. Implementation DetailsWe experiment with a Spark clusterfor preprocessing the data and A800 GPU servers to train and inferthe proposed model. It has three parts: coarse-grained semanticclustering, fine-grained job preference extraction, and personalizedtop- job recommendation. 1) Coarse-grained semantic clustering:we set the ratio of the number of groups to the number of users toabout 1:1000 and the ratio of the number of groups to the numberof job numbers to about 1:500. User professional skills and theirinherent characteristics, such as work experience, are used as userclustering characteristics. Similarly, we extract job requirementsas clustering features for jobs. 2) Fine-grained job preference ex-traction: the sparse matrix is used to represent the structure ofhypergraphs efficiently. In addition, the order of Chebyshev ap-proximation is = 3, the total degree of interpolants is = 50,and the number of hypergraph convolutional layers is = 1. Weset the number of hidden dimensions of this network to = 128.4) Personalized top- job recommendation: the number of hiddendimensions of the recurrent neural network is set to be the sameas the one in hypergraph convolutional layers: rnn = 128. We set = 10 for baseline experiments, and more experimental resultsunder different settings of can be found in Appendix C.2. As foreach dataset, we split the training and validation data at a ratio",
  "Bold indicates the statistically significant improvements(i.e., two-sided t-test with p < 0.05) over the best baseline (underlined).For all metrics: the higher, the better": "We can see that most conventional methods have poor perfor-mance, i.e., BasicMF, ItemKNN, SLIM, DAE, and EASE. SLIM de-ploys only a linear function to model user-job interactions, whichlimits the ability to generalize the model. BasicMF, ItemKNN,DAE, and EASE cannot provide fine-grained modeling for user/jobfeatures. PureSVD and MultVAE offer significant enhancementsin performance over other techniques, yet they require extensivecomputational resources. Despite their advantages, they fall shortof accurately capturing the dynamics of drifted interactions.",
  "MvDGAE0.670.460.790.490.760.530.690.47TiCoSeRec 0.450.230.660.410.730.720.700.78CoScRec0.420.300.430.280.460.320.550.46BISTRO0.82 0.71 1.00 0.96 0.98 1.00 0.97 0.95": "C indicates the rate of having a chat about the recommended jobs,S stands for the rate of onboarding to the recommended jobs.* Please note that all results have been normalized tosafeguard the companys trade secrets.For all metrics: the higher, the better. Compared to GNN-based methods, BISTRO allows for the ex-traction of fine-grained user representations from user resumesand their use in preference analysis. Among these baselines,MvDGAE achieves the best performance. This is because it alsouses noise reduction representation learning based on multiviewgraphs. However, it lacks content modeling of user resumes andjob requirements, resulting in lower results than our framework. Sequential models can effectively learn the relationship amonguser-job interactions over time, but such interactions can easilybe negatively impacted by spontaneous user preference drift,which would be directly reflected in interaction records. Thus, thesequence-only models do not apply to the job recommendationscenario, and their performance is justifiably worse than that ofour framework.Furthermore, we extended our evaluation by deploying ourmodel from the offline experiments to an online recruitment plat-form for a half-week online experiment, as shown in . Inonline experiments, the performance is measured on a daily basis,and we randomly select a unique 1% of active users and push theresults for each model directly at the re-rank stage. It demonstratesour proposed methods superior performance and exceptional ro-bustness compared to other baseline models.",
  "Ablation Study (RQ2, RQ3)": "The influence of clusteringAs mentioned previously, theclustering module can effectively achieve semantic matching ata coarse-grained level. Therefore, we partition the dataset intofour subsets that do not overlap each other to train the model toachieve the following four tasks: 1) existing jobs for existing users,2) existing jobs for users who have just revised resumes, 3) newjobs for existing users, and 4) new jobs for users who have justrevised resumes. The comparison results are shown in .",
  ": Results of model performance in relation to theproportion of noise in data": "Compared to the framework without a clustering module, BISTROis better adapted to semantic matching: neither the HR nor the MRRsuffers from a significant drop, which shows the efficiency of theclustering module.The effect of hyperedgesThe construction of hyperedges inBISTRO can increase the density of the interaction graph, whichcould add more structural information to address the preferencedrift issue. To verify this idea, we use the following formula to com-pute the density of an undirected graph: Density =2| E| |V|(|V|1) .As shown in , the density of the graph is doubled whenwe add all types of hyperedges and the experimental results havealso been improved due to the optimization of the structure in thegraph.",
  "Without hyperedges1.177%0.41090.3375Only session hyperedges2.811%0.49040.4028Only transition hyperedges2.793%0.49270.4046Both types of hyperedges3.581%0.62470.5131": "The validity of hypergraph wavelet filterIn BISTRO, wedesign a novel hypergraph wavelet learning method. In this learningmethod, a wavelet filter is deployed for data denoising as well asfine-grained job preference feature extraction. As shown in ,the curves illustrate the results of three models, which have differentfiltering settings, under different percentages of noise in the data.We can also visualize from it that our method, BISTRO, has thesmoothest decrease in model performance as the proportion ofnoise in the data increases.To vividly show the denoising capability of the proposed hy-pergraph wavelet filter, we randomly select a user who is activein a week, filter the 50 most recent interactions from three jobcategories, and construct an interaction graph. In this graph, eachnode represents a job the user has engaged with, interconnectedby grey dotted lines, while the interaction sequence of the user isdepicted with grey edges. On this basis, we introduce noisy jobs(marked with orange crosses) and their corresponding interactions(denoted by orange edges and dotted lines) to mimic the effect of auser accidentally clicking on unrelated job types. Given that each",
  ": Results of denoising performance": "model generates job preference representations for diverse jobs,we visualize the connections between the user and jobs, as wellas the relationships among jobs themselves, as shown in .We eliminate edges whose cosine similarity between job repre-sentation pairs fell below a uniform threshold and remove linksbetween isolated jobs and the user. Consequently, a graph withmore orange lines indicates lower model performance. Notably, asdata noise levels escalated, the comparative models demonstrateddiminished noise filtering effectiveness relative to our proposedapproach. Specifically, the random walk-based method significantlyunderperformed compared to the spectral GCN method, primarilydue to the ability of spectral graph neural networks to filter outirrelevant interaction features. Furthermore, our approach employsa wavelet kernel to create a set of sub-filters, adeptly denoisingby dynamically selecting appropriate filters for the users evolvingcharacteristics.",
  "Parametric Study (RQ4)": "The size of user (job) groupsThe size of user and job groupsare two hyperparameters that need to be predefined. Therefore, wechoose 500:1, 1000:1, and 2000:1 as the ratios of the total numberof users and the number of user groups , and 100:1, 500:1, 1000:1as the ratios of the total number of jobs and the number of jobgroups for our experiments respectively, as shown in (a)and 6(b). We can easily observe that our model achieves best when =1000:1 and =500:1.",
  ": Results under different session lengths": "The order of Chevbyshev approximationThe order of Chevby-shev approximation greatly impacts the performance of hypergraphwavelet neural networks. To find the best order, we test our modelwith = 1, 2, 3, 4 and 5, and the results are shown in (c).We can see that the performance of the model remains constantwhen is greater than or equal to 3. Notice that as increases,the computational overhead of the model will also increase, so wechoose = 3 as the hyperparameter of our model.The average length of a sessionThe length of the session isanother hyperparameter that affects the performance of the model.In (a), we can see that the average length of each sessionis 19-37 on average, and such short behavioral sequences in jobrecommendations (In job recommendations, the average number ofinteractions for users to find a suitable job is more than 80 times) areeasily interfered with by noisy interactions. Therefore, we furthercompared our proposed framework with the top-2 baselines underdifferent session length, as illustrated in (b). It can be seenthat when the session length is relatively short, noise has a hugenegative impact on the accuracy of all models. However, as thesession length decreases, our framework is more robust than theother two methods and can better resist noise interference.",
  "CONCLUSION": "This study introduces BISTRO, an innovative framework designedto navigate the challenges of job preference drift and the subse-quent data noise. The framework is structured around three mod-ules: a coarse-grained semantic clustering module, a fine-grainedjob preference extraction module, and a personalized top- job rec-ommendation module. Specifically, a hypergraph is constructed todeal with the preference drift issue and a novel hypergraph waveletlearning method is proposed to filter the noise in interactions whenextracting job preferences. The effectiveness and clarity of BISTROare validated through experiments conducted with both offline andonline environments. Looking ahead, we aim to continue refiningBISTRO to enhance its applicability in broader contexts, particularlyin scenarios characterized by anomalous data.",
  "Shuqing Bian, Wayne Xin Zhao, Yang Song, Tao Zhang, and Ji-Rong Wen. 2019.Domain adaptation for person-job fit with transferable deep global match net-work. In Proc. of EMNLP": "John P Boyd. 2001. Chebyshev and Fourier spectral methods. Courier Corporation. Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. SpectralNetworks and Locally Connected Networks on Graphs. In Proc. of ICLR. Jiajun Bu, Shulong Tan, Chun Chen, Can Wang, Hao Wu, Lijun Zhang, andXiaofei He. 2010. Music recommendation by unified hypergraph: combiningsocial media information and music content. In Proc. of ACM MM.",
  "Xia Ning and George Karypis. 2011. Slim: Sparse linear methods for top-nrecommender systems. In Proc. of ICDM": "Yitong Pang, Lingfei Wu, Qi Shen, Yiming Zhang, Zhihua Wei, Fangli Xu, EthanChang, Bo Long, and Jian Pei. 2022. Heterogeneous global graph neural networksfor personalized session-based recommendation. In Proc. of WSDM. Bibek Paudel, Fabian Christoffel, Chris Newell, and Abraham Bernstein. 2016.Updatable, accurate, diverse, and scalable recommendations for interactive appli-cations. ACM Transactions on Interactive Intelligent Systems (TiiS) (2016). Chuan Qin, Le Zhang, Rui Zha, Dazhong Shen, Qi Zhang, Ying Sun, Chen Zhu,Hengshu Zhu, and Hui Xiong. 2023. A comprehensive survey of artificial intelli-gence techniques for talent analytics. arXiv preprint arXiv:2307.03195 (2023).",
  "Xin Xia, Hongzhi Yin, Junliang Yu, Qinyong Wang, Lizhen Cui, and XiangliangZhang. 2021. Self-supervised hypergraph convolutional networks for session-based recommendation. In Proc. of AAAI": "Xu Xie, Fei Sun, Zhaoyang Liu, Shiwen Wu, Jinyang Gao, Jiandong Zhang, BolinDing, and Bin Cui. 2022. Contrastive learning for sequential recommendation. In2022 IEEE 38th international conference on data engineering (ICDE). Tanya V Yadalam, Vaishnavi M Gowda, Vanditha Shiva Kumar, Disha Girish,and M Namratha. 2020. Career recommendation systems using content basedfiltering. In 2020 5th International Conference on Communication and ElectronicsSystems (ICCES). Shuo Yang, Mohammed Korayem, Khalifeh AlJadda, Trey Grainger, and SriraamNatarajan. 2017. Combining content-based and collaborative filtering for job rec-ommendation system: A cost-sensitive Statistical Relational Learning approach.Knowledge-Based Systems (2017).",
  "Yuhao Yang, Chao Huang, Lianghao Xia, and Chenliang Li. 2022. Knowledgegraph contrastive learning for recommendation. In Proc. of SIGIR": "Tiansheng Yao, Xinyang Yi, Derek Zhiyuan Cheng, Felix Yu, Ting Chen, AdityaMenon, Lichan Hong, Ed H Chi, Steve Tjoa, Jieqi Kang, et al. 2021. Self-supervisedlearning for large-scale item recommendations. In Proc. of CIKM. Chi Zhang, Rui Chen, Xiangyu Zhao, Qilong Han, and Li Li. 2023. Denoising andPrompt-Tuning for Multi-Behavior Recommendation. In Proceedings of the ACMWeb Conference 2023, WWW 2023, Austin, TX, USA, 30 April 2023 - 4 May 2023. Mengqi Zhang, Shu Wu, Meng Gao, Xin Jiang, Ke Xu, and Liang Wang. 2020.Personalized graph neural networks with attention mechanism for session-awarerecommendation. IEEE Transactions on Knowledge and Data Engineering (2020).",
  "Jiawei Zheng, Qianli Ma, Hao Gu, and Zhenjing Zheng. 2021. Multi-view denois-ing graph auto-encoders on heterogeneous information networks for cold-startrecommendation. In Proc. of KDD": "Zhi Zheng, Xiao Hu, Zhaopeng Qiu, Yuan Cheng, Shanshan Gao, Yang Song,Hengshu Zhu, and Hui Xiong. 2024. Bilateral Multi-Behavior Modeling for Recip-rocal Recommendation in Online Recruitment. IEEE Transactions on Knowledgeand Data Engineering (2024). Zhi Zheng, Zhaopeng Qiu, Tong Xu, Xian Wu, Xiangyu Zhao, Enhong Chen, andHui Xiong. 2022. CBR: context bias aware recommendation for debiasing usermodeling and click prediction. In Proceedings of the ACM Web Conference 2022.",
  "NotationDescription": "SThe set of session-based interactionsGInteraction graphVGroup-based node-set, V = {1, 2, }EThe hyperedge set, E = {1,2, }UThe user set, U = {1,2, }XGraph features that extracted from user/job contentsThe user resume setThe job requirement set&User/Job groupsLGraph Laplacian matrixThe node-edge relationship matrix of the hypergraph&The degree matrix of nodes and hyperedgesEigen-vectors of graph Laplacian matrixGraph filter with training parameter The ratio of the users (jobs) to user (job) groupsThe order of Chebyshev approximation",
  "BMODEL COMPLEXITY": "Our proposed framework, BISTRO, is efficient. We will analyzeit from two aspects: theoretical [from (3) to ( log)] andapplication (less than 100 per sample) level.Theoretical levelAmong all modules in BISTRO, the graph neural network (GNN)is considered very time-consuming. Actually, graph learning-basedrecommender systems have computational limitations in practice.To address this issue, we cluster users (jobs) based on the semanticinformation in their resumes (requirements) using the K-Meansalgorithm and use a simple RNN to extract the personalized prefer-ence for a person in the user group. The extraction of preferencefeatures based on user (job) groups reduces the computationaloverhead of GNNs. Noting that eigendecomposition in GNNs isresource-intensive, we place it by using the Chebyshev polynomialestimation, and the Chebyshev coefficient in the polynomial can becomputed by Fast Fourier Transform, which reduces the computa-tional complexity from exponential complexity (3) to ( log).Therefore, our algorithm is efficient.Application levelIn practice, the training of all models is performed offline. Forexample, we use spark cluster to calculate the clustering center ofeach group and use HGNN to learn the corresponding representa-tion of groups. For new or updated users and jobs, we assign themto the nearest group based on semantic clustering. Only the RNNmodule operates online, inferring personalized user representationswithin groups. In the online experiment, the 99% Response Time ofBISTRO is less than 100.",
  "The details of these baselines are as follows:": "BasicMF : A model that combines matrix factorization with aMultilayer Perceptron (MLP) for recommendations. ItemKNN : A recommender that utilizes item-based collabo-rative filtering. PureSVD : An approach that applies Singular Value Decompo-sition for recommendation tasks. SLIM : A recommendation method known as the Sparse LinearMethod. DAE : Stands for Collaborative Denoising Auto-Encoder, usedin recommendation systems. MultVAE : A model extending Variational Autoencoders tocollaborative filtering for implicit feedback. EASE : A recommendation technique called EmbarrassinglyShallow Autoencoders for Sparse Data. P3a : A method that uses ordering rules from random walkson a user-item graph. RP3b : A recommender that re-ranks items based on 3-hoprandom walk transition probabilities. NGCF : Employs graph embedding propagation layers togenerate user/item representations. LightGCN : Utilizes neighborhood information in the user-item interaction graph. SLRec : A method using contrastive learning among nodefeatures. SGL : Enhances LightGCN with self-supervised contrastivelearning. GCCF : A multi-layer graph convolutional network for recom-mendation. NCL : Enhances recommendation models with neighborhood-enriched contrastive learning. DirectAU : Focuses on the quality of representation based onalignment and uniformity. HG-GNN : Constructs a heterogeneous graph with both usernodes and item nodes and uses a graph neural network to learn theembedding of nodes as a potential representation of users or items. A-PGNN : Uses GNN to extract session representations forintra-session interactions and uses an attention mechanism to learnfeatures between sessions. AdaGCL : Combines a graph generator and a graph denoisingmodel for contrastive views. MvDGAE : Stands for Multi-view Denoising Graph AutoEn-coders. STAMP : A model based on the attention mechanism to modeluser behavior sequence data. GRU4Rec : Utilizes Gated Recurrent Units for session-basedrecommendations. BERT4Rec : A model for the sequence-based recommendationthat handles long user behavior sequences. CL4Rec : An improved version of BERT4Rec with locality-sensitive hashing for faster item retrieval. CoScRec : It explores an innovative recommendation ap-proach that enhances sequential recommendation systems throughrobust data augmentation and contrastive self-supervised learningtechniques. TiCoSeRec : A method based on CoSeRec, utilizing data aug-mentation algorithms for sequence recommendation improvement.",
  ": A real-life scenario for the job recommendation": "Beyond its effectiveness in performance, BISTRO also boastsconsiderable interpretability. To demonstrate how the frameworkmitigates both the job preference drift and data noise problems,we present a real-life scenario to illustrate the logic behind thesuggestions made by BISTRO, as shown in .In this figure, jobs with IDs ***872 and ***994 are two job posi-tions that are newly posted in the online recruitment system, whileIDs ***265 and ***523 are two job positions that a large number ofusers interact with frequently. Among them, ***872 and ***265, aswell as ***994 and ***523, have similar occupational demand descrip-tions respectively. Also, the user with ID ***175 shared a similar resume with user ID ***479 before ***175 modified the resume, andafter his resume was changed, ***175 had a similar content withuser ***013. Recommendations in this scenario can be divided intothree examples:Example 1 (Recommendation for a dynamically changing user)Consider the user represented by ID ***175, BISTRO addresses thischallenge by deploying content-based analysis. The frameworkutilizes the users social network and a set of resume attributescollected to create a composite feature profile to identify users withsimilar tastes. Subsequently, it recommends a job with ID ***523favored by a like-minded user with ID ***013 to him.Example 2 (Recommendation for a new job)A newly postedjob with ID ***872 lacks any user interaction data, complicating thegeneration of a meaningful representation for it. BISTRO, however,overcomes this by incorporating auxiliary information such as skillrequirements and working experience, and then associated tags tolocate similar content. By leveraging this approach combined withthe users expectations, BISTRO acquires a rich and informativeembedding for the job, enabling it to recommend the job to userswho have shown an interest in comparable jobs.Example 3 (Recommend a new job to a dynamically changing user)Combining both two situations illustrated above, BISTRO deals withthis complex challenge by utilizing a wavelet graph denoising filterand graph representation method. In this way, it can recommend thelatest jobs with similar job content to users with the same real-timeneeds as well as similar user content characteristics."
}