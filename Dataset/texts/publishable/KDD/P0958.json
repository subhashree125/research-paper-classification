{
  "ABSTRACT": "Generative Artificial Intelligence image models have achieved out-standing performance in text-to-image generation and other tasks,such as inpainting that completes images with missing fragments.The performance of inpainting can be accurately measured by tak-ing an image, removing some fragments, performing the inpaintingto restore them, and comparing the results with the original image.Interestingly, inpainting can also be applied recursively, startingfrom an image, removing some parts, applying inpainting to recon-struct the image, and then starting the inpainting process again onthe reconstructed image, and so forth. This process of recursivelyapplying inpainting can lead to an image that is similar or com-pletely different from the original one, depending on the fragmentsthat are removed and the ability of the model to reconstruct them.Intuitively, stability, understood as the capability to recover an im-age that is similar to the original one even after many recursiveinpainting operations, is a desirable feature and can be used asan additional performance metric for inpainting. The concept ofstability is also being studied in the context of recursive trainingof generative AI models with their own data. Recursive inpaintingis an inference-only recursive process whose understanding maycomplement ongoing efforts to study the behavior of generative AImodels under training recursion. In this paper, the impact of recur-sive inpainting is studied for one of the most widely used imagemodels: Stable Diffusion. The results show that recursive inpaint-ing can lead to image collapse, so ending with a nonmeaningfulimage, and that the outcome depends on several factors such as thetype of image, the size of the inpainting masks, and the number ofiterations. Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from -KDD, August 26, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 978-1-4503-XXXX-X/18/06",
  "INTRODUCTION": "Generative Artificial Intelligence (AI) has taken center stage in thelast two years and triggered a new technology revolution. Gen-erative AI models can generate text, audio, images, or video andcan be used in many transformative applications. Among the AItools, Large Language Models (LLMs) such as GPT4 , which cananswer questions, summarize, translate, and paraphrase texts, andtext-to-image generators such as DALL-E , which can create",
  "GenAI-KDD, August 26, 2024, Barcelona, SpainJavier Conde, Miguel Gonzlez, Gonzalo Martnez, Fernando Moral, Elena Merino-Gmez, and Pedro Reviriego": ": Example of recursive inpainting on Diego Velzquez, Portrait of Innocence X, 1650. On the left, the original image isshown. Each subsequent image to the right displays the result after applying two recursive inpainting operations, up to thefinal image after sixteen inpainting operations. : Example of recursive inpainting on Vincent Van Gogh, Lugekone, 1885, On the left, the original image is shown.Each subsequent image to the right displays the result after applying two recursive inpainting operations, up to the final imageafter sixteen inpainting operations. As for the images, to try to avoid bias in the selection, they havebeen selected randomly from a large dataset with more than 81,0000art images of several types and made by different artists3. From thisdataset, 100 images were randomly chosen to create our evaluationset4. The input images are 512x512 pixels. when their original formfactor is not square, blank bands are added on the sides to fit the512x512 pixels format.To generate the masks for inpainting, the images are divided intosquares of a given size, and in each iteration, a square is randomlyselected and used as the mask. The generation of the masks isillustrated in for the case of a 128x128 square and twoiterations. It can be observed that one square is removed in eachiteration. Then, inpainting is run, and the results obtained for thepixels in the mask are used to replace the ones in the initial picture.This modified picture is then used as the input image for the nextiteration. This procedure guarantees that at each iteration, theinpainting only modifies the pixels in the selected mask.To estimate the similarity with the original image across itera-tions, we use the Learned Perceptual Image Path Similarity (LPIPS) metric widely used to assess the quality of inpainting5. In theimplementation used, the features of three neural networks can beused to compute the metric: SqueezeNet , AlexNet , andVGG .To enable a direct comparison of inpainting with different masksizes, our experiments use as the main parameter not the number ofinpainting operations but the number of pixels on which inpaintingis done. For example, for a 256x256 mask, four inpainting opera-tions correspond to changing a number of pixels equal to those inthe original 512x512 images. Instead, for a 128x128 mask, sixteeninpainting operations are needed to change 512x512 pixels6. Using 3 results of our experiments are available, both image and metrics as well as thescripts to run the experiments at implementation used is available in a public repository that the pixels changed in two iterations can be the same as each iterationselects a mask randomly. as a metric the number of pixels that are inpainted relative to theimage size makes comparisons easier across different masks andimage sizes.In the first experiment, we take the 100 random images andperform recursive inpainting for 400% of the pixels with masks of64x64, 128x128, 256x256. To quantify the degradation as inpaintingoperations are done, the LPIPS metric between the original imageand each generation has been computed using the three neuralnetworks (SqueezeNet, AlexNet, and VGG) features. The averagedistances on the 100 images at each step of 50% inpainting are shownin . The bars show the standard deviation observed on thesamples on each of the data points. Several initial observations canbe made from the results:",
  "PRELIMINARIES2.1Inpainting": "One of the functionalities implemented by some modern generativeAI image tools is inpainting , which takes an image with miss-ing fragments and fills in those fragments to complete the image. An example of the use of inpainting is illustrated in .In this case, Stable Diffusion was used, and we started from a com-plete image, applied a mask to remove some parts, and then usedinpainting to complete the image. This enables a comparison be-tween the original image and the result of inpainting. It can be seenthat the tool is able to produce an image that resembles the originalone. Interestingly, the AI model used, Stable Diffusion, changes theface to one that resembles a male which matches theories aboutthe painting being a portrait of one of Leonardo Apprentices 1.Different runs produce results with different types of faces, mostlywoman-like.The performance of inpainting depends on the model, the typeof image, and the sizes and locations of the missing fragments. In general, of the information lost in the image fragments, in-painting can only recover a fraction. A number of metrics can beused to measure the similarity between the original image and thereconstructed one : from classical ones such as the StructuralSimilarity (SSIM) or the multi-scale SSIM (MS-SSIM) basedon the pixel level, to more advanced ones such as the Learned Per-ceptual Image Patch Similarity (LPIPS) or the Paired/UnpairedInception Discriminative Score (P/U-IDS) , which use AI modelsto capture human-like perceptual aspects.",
  "Recursiveness in Generative AI": "The massive use of generative AI to generate text and images iscreating a loop in which AI-generated content is uploaded to theInternet and then scrapped to train newer AI models . This canlead to a performance degradation of AI models or even to theircollapse when they are trained with data produced by themselves. This has triggered interest in understanding under which condi-tions these generative AI models are stable when trained recursivelywith data produced by the AI models ,. This depends on sev-eral factors, including the model, the amount of AI-generated dataused for each retraining, and whether the loop includes a singleor several AI models. The study of this loop is important as it mayimpact both future AI models but also the nature of future contentthat will dominate the Internet. In all these studies, recursivenessinvolves training newer AI models with data generated from otherAI models, however in some cases recursiveness can occur whenusing the same AI model for inference only. This, to the best of ourknowledge, has not been studied.",
  "RECURSIVE INPAINTING (RIP)": "An interesting observation is that a different recursive loop forAI image models can be created when using inpainting. This isillustrated in ; we start from an image and then apply a maskto remove some parts of it and use inpainting to complete them. Atthis point, we have a second image that the AI image model haspartly created. Then, we repeat the process using a different mask to",
  "How Stable is Stable Diffusion under Recursive InPainting (RIP)?GenAI-KDD, August 26, 2024, Barcelona, Spain": ": Example of the use of inpainting on Leonardo Da Vinci, Mona Lisa, 1503, (left) original image, (center) image afterapplying a mask, (right) image after using inpainting to complete the missing fragment. obtain a second image that, in this case, is created from AI generatedcontent. The process continues, and we recursively apply inpaintingon images that have already been inpainted. In the process, as weremove and reconstruct parts of the images, information will belost, but will this lead to images that are completely different fromthe original? images that are simpler and less complex? or will theinpainting be stable and lead to images that are only variations ofthe original image? As in the case of recursiveness when trainingmodels with their own data, it is of interest to understand wheninpainting is stable or when it collapses under recursion.",
  ": Illustration of the Recursive InPainting (RIP) pro-cess": "An example of recursive inpainting is shown in . The topleft plot corresponds to the original image, in this case, a portrait ofPope Innocent X by Velzquez. The other images correspond to theresults after applying inpainting two, four, six,..., up to sixteen timeson one-fourth of the image. It can be seen that as the iterationsprogress, the image starts to depart from the original, and significantchanges are introduced. However, even after the sixteen iterations,the final image still resembles the original one. Instead, when thesame process is done for a sketch by Vincent van Gogh, as shownin the lady in the original image no longer appears in thelast image, which is completely different from the initial one.The impact of recursive inpainting depends on many factors,such as the AI model, the type of image used, or the masks ap-plied at each iteration. Intuitively, more complex images or masksthat remove larger parts of the image will be more likely to leadto collapse. In the following section, the findings of an extensiveempirical study of recursive inpainting with Stable Diffusion arepresented as a first step towards understanding the key factors thatdetermine the impact of recursive inpainting.",
  "(1) The AI model.(2) The input images.(3) The masks applied at each step.(4) The number of iterations": "In our experiments, Stable Diffusion , a latent text-to-imagediffusion model ,, has been used because it is an open modeland one of the most widely used AI image models. In particular, aversion of Stable Diffusion 2 fine-tuned for inpainting was used2.This model employs a mask-generation technique where themasked regions, along with the latent VAE representations of themasked image, serve as additional conditioning for the inpaintingprocess. The model parameters were set to the default values. Notext prompt was used to guide the inpainting to make the modelfocus on reconstructing the missing parts from the remaining visualelements with no text guidance.",
  "(5) The standard deviation is significant which suggests thatdifferent behaviors will be observed for different images": "To better understand the variability of the distances for eachimage, scatter plots of the LPIPS distances of the 100 images for eachof the neural networks are shown in . It can be observedthat there is significant variability across images but the trendsare similar to the ones observed in the mean: distance is largerwith more inpainting and with larger masks. Comparing the threenetworks (SqueezeNet, AlexNet, and VGG), the last one, VGG isthe one with fewer outliers. VGG is also the most complex networkand thus should be expected to better capture the features of the",
  ": Mean LPIPS across the 100 images versus the inpainting done for AlexNet (left), SqueezeNet (middle) and VGG (right)for different mask sizes (64x64, 128x128, 256x256)": "images . Therefore, in the following, we only report results forVGG although all the metrics are available in the repository alongwith the images.Another factor that can impact the degradation is the image usedas the starting point for the process. To analyze this, LPIPS distanceplots were generated for each image and analyzed manually. A fewillustrative examples are shown in . In the first one (left),the distance tends to stabilize as recursive inpainting progresses.In the second, there is a large difference in the distances with masksize and finally, in the last one, the distances are similar for allmask sizes. The image sequences for the three images are shownin Figures 10,11,12.In the first image even when using a small mask, see a, we observe that the image gradually becomes blurred andloses quality as the recursive inpainting progresses. However, itstill manages to maintain the overall style of the original image.With a medium-sized mask, b, the initial iterations showa similar trend, but as the blurring errors accumulate, the imageeventually degenerates completely in the final iterations. Whenusing a large mask, c, the style of the image is quickly lost,resulting in a completely different image by the end of the process.Therefore, it seems that the stabilization of the error can be at leastpartially attributed to the collapse of the process producing imagesunrelated to the original one.For the second image, the results in show the impactof the mask size, when it is small, a, the inpainting focuses on reconstructing the texture of the image as there are no objects.Instead, for the largest mask size c, the inpainting startsadding new objects which leads to more and more objects endingwith a collage. Instead in the third image, the results in are similar for all mask sizes and only towards the end differencescan be observed for the largest mask size in c. In this case,removing a large part of the image does not cause the insertion ofnew objects, leading to a different behavior. In summary, the typeand features of the initial image seem to be an important factor forthe outcome of recursive inpainting.As the parts removed are randomly chosen, it is of interest to seewhether the degradation is similar on different runs. To understandthe variability of the degradation with the run, 10 images have beenselected from the set of 100, and each has been run 10 times. TheLPIPS metrics across runs for three different images are shown in when using the VGG network which again tends to havethe lowest deviations. It can be observed that the variations arelarger for larger masks which is expected as the larger the mask,the fewer the iterations to reach a given percentage of inpaintingwhich causes more variability. The variations are also reduced asthe percentage of inpainting increases showing again, that thelarger the number of inpainting operations the lower the variability.This means that recursive inpainting seems to converge in termsof LPIPS distance as the process advances.Finally, looking at the results in qualitative terms from an aes-thetic perspective, the results raise several important concerns,",
  ": Examples: Distance stabilizes (left), Large distance and variation with mask size (middle), similar distance with masksize (right)": "independent of the quantitative analysis of the metrics. It is sur-prising when the AI, instead of fixing the missing parts, createsnew things that dont fit in the painting. This likely happens whensmall bits left over from the erased sections make the AI assume anobject was there, even if it wasnt. This shows the AI doesnt trulyrecognize the painting it is dealing, with which raises doubts aboutthe entire result. Moreover, the AI seems to not know the rules formaking things look realistic in terms of perspective. It twists anglesin odd ways at times. The worst cases happen when the AI cantcomprehend how faces are rotated and tries to reconstruct themhaphazardly, just to make it resemble a head or a human compo-nent. In some images, the AI attempts to reconstruct a sort of colorpalette in the best situations, particularly when the alterations areminimal. However, in other cases, it simply uses arbitrary colors orelements to try to resemble the original image which results in apixelated appearance.",
  "LIMITATIONS AND DISCUSSION": "The evaluation conducted is just an initial step to understand theeffects of recursive inpainting. Additional experiments with differ-ent configurations of Stable Diffusion and also with other AI imagemodels are needed to evaluate the impact of each of the parametersand also of the model. The same reasoning applies to the input im-ages, a larger number of images, possibly with different features interms of the objects represented and their shapes and sizes should be evaluated as in our experiments we have focused on paintings.In addition to these extensions of the empirical evaluation, theo-retical models that can explain the impact of recursive inpaintinghave also yet to be developed. Another area for study would beto compare the results of AI to those produced by humans whenpresented with the same problem. However, doing experimentswith humans would require a significant effort and also depend ontheir painting capabilities. To apply recursive inpainting, severalpersons, one per iteration would be needed to make sure that theyhave not seen the original or previous images in the series whichmakes the procedure rather complicated. In summary, as discussedbefore, this paper is just the first step in the analysis of recursiveinpainting that is primarily intended to present the problem andmotivate further work.Even with the limitations discussed, the results presented showhow recursive inpainting can lead to images that are completelydifferent from the original ones. This is similar to the model col-lapse observed when training generative AI models with their owndata for which techniques to avoid collapse are being proposed. Analyzing the similarities and differences between recursiveinpainting and recursive training loops is another avenue for futureresearch. Exploring modifications to the AI models to avoid thecollapse of recursive inpainting is also of interest and could lead tobetter image-generation AI models. More broadly, understanding",
  "CONCLUSION AND FUTURE WORK": "In this paper, the effect of recursive inpainting on AI image modelshas been presented and studied empirically. The results show thatrecursiveness can lead to the degradation and, eventually, the col-lapse of the image. This is similar to what has been observed in therecursive training of generative AI models, which is attracting sig-nificant interest from the community. Therefore, this paper opensanother area in the research of the impact of the recursive use ofgenerative AI, in this case only in the inference phase, that cancomplement existing research efforts and lead to further insightson the causes of collapse. This can, in turn, lead to improvementsin the AI models to mitigate the impact of recursiveness.The analysis of recursive inpainting presented in this paper isjust the first step. Additional AI models, images, and model con-figurations should be tested to better understand the impacts of recursive inpainting. Beyond empirical results, it is also of interestto develop theoretical models that can explain the impacts of recur-sive inpainting. Exploring the links between recursive training andrecursive inpainting is also an interesting area for future research. This work was supported by the FUN4DATE (PID2022-136684OB-C22) and ENTRUDIT (TED2021-130118B-I00 projects funded by theSpanish Agencia Estatal de Investigacin (AEI) and by the ChipsAct Joint Undertaking project SMARTY (Grant no. 101140087). Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Floren-cia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, ShyamalAnadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774(2023).",
  "Pedro Reviriego Fernando Moral-Andrs, Elena Merino-Gmez and FabrizioLombardi. 2023. Can Artificial Intelligence Reconstruct Ancient Mosaics? Studiesin Conservation 0, 0 (2023), 114": "Matthias Gerstgrasser, Rylan Schaeffer, Apratim Dey, Rafael Rafailov, HenrySleight, John Hughes, Tomasz Korbak, Rajashree Agrawal, Dhruv Pai, AndreyGromov, et al. 2024. Is Model Collapse Inevitable? Breaking the Curse of Recursionby Accumulating Real and Synthetic Data. arXiv preprint arXiv:2404.01413 (2024). Zishan Guo, Renren Jin, Chuang Liu, Yufei Huang, Dan Shi, Linhao Yu, Yan Liu,Jiaxuan Li, Bojian Xiong, Deyi Xiong, et al. 2023. Evaluating large languagemodels: A comprehensive survey. arXiv preprint arXiv:2310.19736 (2023). Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, andSepp Hochreiter. 2017. GANs Trained by a Two Time-Scale Update Rule Convergeto a Local Nash Equilibrium. In Advances in Neural Information Processing Systems,I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan,and R. Garnett (Eds.), Vol. 30. Curran Associates, Inc. Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid Ashraf, William JDally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level accuracy with 50xfewer parameters and< 0.5 MB model size. arXiv preprint arXiv:1602.07360 (2016).",
  "Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. 2012. Imagenet classifi-cation with deep convolutional neural networks. Advances in neural informationprocessing systems 25 (2012)": "Tuomas Kynknniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and TimoAila. 2019. Improved precision and recall metric for assessing generative models.Advances in Neural Information Processing Systems 32 (2019). Andreas Lugmayr, Martin Danelljan, Andres Romero, Fisher Yu, Radu Timofte,and Luc Van Gool. 2022. Repaint: Inpainting using denoising diffusion proba-bilistic models. In Proceedings of the IEEE/CVF conference on computer vision andpattern recognition. 1146111471.",
  "Matteo Marchi, Stefano Soatto, Pratik Chaudhari, and Paulo Tabuada. 2024.Heat Death of Generative Models in Closed-Loop Learning. arXiv preprintarXiv:2404.02325 (2024)": "Gonzalo Martnez, Lauren Watson, Pedro Reviriego, Jos Alberto Hernndez,Marc Juarez, and Rik Sarkar. 2023. Towards understanding the interplay ofgenerative artificial intelligence and the Internet. In International Workshop onEpistemic Uncertainty in Artificial Intelligence. Springer, 5973. Muhammad Ferjad Naeem, Seong Joon Oh, Youngjung Uh, Yunjey Choi, andJaejun Yoo. 2020. Reliable fidelity and diversity metrics for generative models. InInternational Conference on Machine Learning. PMLR, 71767185.",
  "Weize Quan, Jiaxi Chen, Yanli Liu, Dong-Ming Yan, and Peter Wonka. 2024. DeepLearning-Based Image and Video Inpainting: A Survey. International Journal ofComputer Vision (2024), 134": "Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, AlecRadford, Mark Chen, and Ilya Sutskever. 2021. Zero-shot text-to-image generation.In International conference on machine learning. Pmlr, 88218831. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjrnOmmer. 2022. High-resolution image synthesis with latent diffusion models. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition.1068410695. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjrnOmmer. 2022. High-resolution image synthesis with latent diffusion models. InProceedings of the IEEE/CVF conference on computer vision and pattern recognition.1068410695. Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli.2015. Deep unsupervised learning using nonequilibrium thermodynamics. InInternational conference on machine learning. PMLR, 22562265. Aarohi Srivastava, Abhinav Rastogi, Abhishek Rao, Abu Awal Md Shoeb,Abubakar Abid, Adam Fisch, Adam R Brown, Adam Santoro, Aditya Gupta,Adri Garriga-Alonso, et al. 2022. Beyond the imitation game: Quantifying andextrapolating the capabilities of language models. arXiv preprint arXiv:2206.04615(2022). Roman Suvorov, Elizaveta Logacheva, Anton Mashikhin, Anastasia Remizova,Arsenii Ashukha, Aleksei Silvestrov, Naejin Kong, Harshith Goka, KiwoongPark, and Victor Lempitsky. 2022. Resolution-robust Large Mask In paintingwith Fourier Convolutions. In 2022 Ieee Winter Conference On Applications Of",
  "Computer Vision (Wacv 2022). IEEE COMPUTER SOC, 31723182": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-AnneLachaux, Timothe Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, et al. 2023. Llama: Open and efficient foundation language models. arXivpreprint arXiv:2302.13971 (2023). Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. 2004. Imagequality assessment: from error visibility to structural similarity. IEEE transactionson image processing 13, 4 (2004), 600612. Zhou Wang, Eero P Simoncelli, and Alan C Bovik. 2003. Multiscale structural sim-ilarity for image quality assessment. In The Thrity-Seventh Asilomar Conferenceon Signals, Systems & Computers, 2003, Vol. 2. Ieee, 13981402. Shiyuan Yang, Xiaodong Chen, and Jing Liao. 2023. Uni-paint: A unified frame-work for multimodal image inpainting with pretrained diffusion model. In Pro-ceedings of the 31st ACM International Conference on Multimedia. 31903199. Wei Yu, Kuiyuan Yang, Yalong Bai, Tianjun Xiao, Hongxun Yao, and Yong Rui.2016. Visualizing and comparing AlexNet and VGG using deconvolutional layers.In Proceedings of the 33 rd International Conference on Machine Learning. Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, and Oliver Wang.2018. The unreasonable effectiveness of deep features as a perceptual metric.In Proceedings of the IEEE conference on computer vision and pattern recognition.586595. Shengyu Zhao, Jonathan Cui, Yilun Sheng, Yue Dong, Xiao Liang, Eric I Chang,and Yan Xu. 2021. Large scale image completion via co-modulated generativeadversarial networks. arXiv preprint arXiv:2103.10428 (2021)."
}