{
  "ABSTRACT": "Spurious correlations are brittle associations between certain at-tributes of inputs and target variables, such as the correlation be-tween an image background and an object class. Deep image classi-fiers often leverage them for predictions, leading to poor general-ization on the data where the correlations do not hold. Mitigatingthe impact of spurious correlations is crucial towards robust modelgeneralization, but it often requires annotations of the spuriouscorrelations in data a strong assumption in practice. In this paper,we propose a novel learning framework based on meta-learning,termed SPUME SPUriousness-aware MEta-learning, to train animage classifier to be robust to spurious correlations. We designthe framework to iteratively detect and mitigate the spurious cor-relations that the classifier excessively relies on for predictions.To achieve this, we first propose to utilize a pre-trained vision-language model to extract text-format attributes from images. Theseattributes enable us to curate data with various class-attribute cor-relations, and we formulate a novel metric to measure the degreeof these correlations spuriousness. Then, to mitigate the relianceon spurious correlations, we propose a meta-learning strategy inwhich the support (training) sets and query (test) sets in tasksare curated with different spurious correlations that have highdegrees of spuriousness. By meta-training the classifier on thesespuriousness-aware meta-learning tasks, our classifier can learnto be invariant to the spurious correlations. We demonstrate thatour method is robust to spurious correlations without knowingthem a priori and achieves the best on five benchmark datasetswith different robustness measures.",
  "ACM Reference Format:Guangtao Zheng, Wenqian Ye, and Aidong Zhang. 2024. Spuriousness-Aware Meta-Learning for Learning Robust Classifiers. In Proceedings of the": "Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08",
  "INTRODUCTION": "Spurious correlations are prevalent in real-world datasets. They arebrittle associations between certain input attributes and the corre-sponding target variables. For example, the class cow is correlatedwith grassland when most training images show a cow on a grass-land, but the correlation breaks when a cow is at a beach . Thegrassland feature is spurious as it does not always correlate withthe label cow and is not truly predictive for all cow images. Deepimage classifiers often use spurious correlations as their predictionshortcuts , such as inferring an image as representing a cow byfocusing on the grassland background of the image. Although thisshortcut learning strategy can achieve high overall performancewhen the majority of samples have spurious correlations, it gener-alizes poorly on samples where spurious correlations do not hold.Thus, mitigating the reliance on spurious correlations is crucial forobtaining robust image classifiers.Existing approaches require annotations of spurious correlationsor group labels, which separate data into multiple groups witheach containing samples of the same class and sharing the sameattribute. For example, a group label (cow, grass field) represents allcow images with grass fields as the background. The group labelsare used to formulate new optimization objectives or used formodel selection and/or model fine-tuning . However,knowing the group labels in data requires expert knowledge andcostly human annotations, which cannot scale to large datasets.Completely removing the requirement for group labels while learn-ing robust classifiers is also a challenging task since we have noknowledge about what spurious correlations we need to mitigate.In this paper, we propose a novel learning framework to trainan image classifier to be robust to spurious correlations withoutthe need of group labels. We design our framework to iterativelydetect and mitigate the spurious correlations that the classifierheavily relies on for predictions. To achieve this, we first proposean automatic spurious attribute detection method empowered by apre-trained vision-language model (VLM). The VLM enables us todetect text-format attributes which represent many similar pixel-level features and are interpretable to humans. These attributestogether with class labels can formulate various class-attributecorrelations which we may find to be spurious in data, and thesecorrelations can cover many potential scenarios where an imageclassifier fails to generalize because of its reliance on one or multipleof these spurious correlations. Therefore, to train a robust classifieragainst spurious correlations in general without the guidance of",
  "KDD 24, August 2529, 2024, Barcelona, SpainGuangtao Zheng, Wenqian Ye, & Aidong Zhang": "training, and its time complexity grows linearly with the amountof data it uses. The total training cost is (( +)), where isthe number of training epochs, and are the time cost of meta-learning a classifier and obtaining spuriousness scores per epoch,respectively, with , since the latter only requires for-ward passes through the classifier. Moreover, using a metric-basedmeta-learning technique (Eq. (6)) leads to being comparable totraining a standard classifier. Therefore, our method does not incursignificant training cost compared with the ERM training.Model Selection. We divide the validation data Dval into groupsbased on the detected attributes A and calculate the average accu-racy over these groups as follows,",
  "RELATED WORK": "Detecting Spurious Attributes. Spurious attributes spuriouslycorrelate with class labels in data and tend to be exploited forpredictions, posing a great risk to the robustness of deep neuralclassifiers. Detecting spurious attributes typically requires domainknowledge and human annotations . For example,researchers found that object backgrounds and image tex-ture are spurious and can bias the predictions of deep learningmodels. Recently, model explanation methods are used todetect spurious attributes. Neurons in the penultimate layer of a robust model assisted with limited human supervision are also uti-lized for spurious attribute detection . Pre-specifying a setof candidate spurious attributes for spurious attribute detection isalso explored . Our method of spurious attribute detection iscompletely unsupervised. We exploit the prior knowledge in pre-trained VLMs and extract spurious attributes in interpretable textformat without any human supervisions.Mitigating Spurious Correlations. Spurious correlations tend tobias a models predictions. There is a growing number of works onmitigating the impact of spurious correlations. Methods that aim tobalance data distributions or to perform distributionallyrobust optimization require knowing group labels which pro-vide information about the spurious correlations in data. Recentworks aim to infer group labels to relax this requirement, suchas identifying misclassified samples , clustering hidden repre-sentations , invariant learning , or training a group labelestimator using a small set of data with group labels . Kirichenkoet al. uses group-balanced validation data to retrain the lastlayer of a model. All these methods still require group labels for thevalidation data for model selection, which is a strong assumptionin practice. A recent work uses masked data with interpretationtechniques to mitigate the impact of spurious correlations withoutthe need of group labels. Our method automatically detects spuri-ous correlations and uses them to construct spuriousness-awarelearning tasks and to do model selection. Another line of works isto use data augmentation, such as mixup or selectiveaugmentation , to mitigate spurious bias in model training. Ourmethod is orthogonal to these approaches as we focus on learningrobust classifiers with existing data.Meta-learning. Meta-learning is a bi-level learningparadigm and is popular in few-shot learning . Itaims to learn from one set of data and to generalize on another setof data. It has been found that the meta-learning can learn high-quality representations , achieving good generalization acrossdifferent tasks. Utilizing the novel idea of meta-learning, in thispaper, we transform the problem of spurious correlation mitigationinto a novel meta-learning problem to facilitate learning featurerepresentations robust to spurious correlations.",
  "PROBLEM FORMULATION": "Consider a training dataset Dtr = {(,)}=1 with X, Y, where X denotes the input space containing all possi-ble inputs, Y denotes the set of classes. In real-world scenarios,a sample in Dtr typically has spurious attributes and these at-tributes have spurious correlations with the label . We describethe two important concepts below. Spurious attributes: A spurious attribute A describes somecommon patterns in the input space X and spuriously correlateswith some label Y, where A denotes all possible spuriousattributes. In other words, can be in samples of multiple classesor only in some samples of a class, and therefore is not essential toany of the classes. For example, the land background\" attribute canexist in images of waterbird and landbird classes , and landbackground\" is non-essential to either of the classes. Spurious correlations: A spurious correlation, denoted as ,,describes the brittle association between the spurious attribute",
  "model": ": Overview of SPUME. (a) Detect attributes from training data and measure their spuriousness in three steps. \\green\"denotes without the attribute green\". (b) Construct spuriousness-aware meta-learning tasks guided by the spuriousness scoresof the detected attributes. (c) Meta-train a robust feature extractor using the constructed tasks. and the label . The spurious correlation , does not alwayshold in the sense that can be associated with multiple s or can correlate with other attributes in some samples. Knowing allthe spurious correlations in Dtr, we can divide Dtr into multipledata groups Dtr, G, where = (,) denotes the group labelfor samples with the label and having the spurious attribute ,and G = Y A denotes the set of all group labels.Given a deep neural classifier with parameters , we train itwith empirical risk minimization (ERM) on the training set Dtr andobtain the optimized classifier as follows:",
  "= arg minE(,)Dtr( (),),(1)": "where (, ) is the cross-entropy loss function.The problem occurs when data groups {Dtr| G, Dtr Dtr}in Dtr are imbalanced in sizes or the inductive bias of the classifier favors particular data groups. For example, a majority group Dtrwith the group label = (,) in Dtr, which has significantly moresamples than other groups, may bias the optimization in Eq. (1)towards favoring the data in Dtr having the spurious correlation,, i.e.,",
  "arg minE(,)Dtr( (),),(2)": "with |Dtr| |Dtr |, where , G and , and | | denotes thesize of a set. As a result, the classifier , instead of utilizing the corefeatures in samples to predict, may superficially learn the mappingfrom to , which is non-robust when the correlation between and breaks. More specifically, since is a spurious attribute, theremay exist , in samples from class with . Then, it isvery likely that will wrongly predict these samples as insteadof . For example, when learns to use water backgrounds ()to predict waterbirds (), it fails to recognize landbirds () withwater backgrounds. Similarly, when the inductive bias in favors certain spurious correlations, the classifier will encounter the samegeneralization problem.Spurious correlations pose a great challenge to the robustnessof machine learning models. To address this, typically, all or partialgroup labels of the training data is required for various purposes,such as formulating the group robustness objective , reweight-ing the training data, or selecting models . However, acquiringgroup labels for a dataset typically involves human-guided annota-tions, which is costly and not scalable, especially when the datasetis large. In the following, without the need of group labels, wepropose a novel spuriousness-aware meta-learning framework totrain a classifier to be robust to spurious correlations.",
  "SPURIOUSNESS-AWARE META-LEARNING": "We give the overview of our framework in , where we firstdetect spurious attributes with a pre-trained VLM ((a) and.1). To effectively use the detected spurious attributes forspurious correlation mitigation, we propose a novel meta-learningstrategy and provide details on how to construct spuriousness-aware meta-training tasks ((b) and .2) and meta-learnrobust representations ((c) and .3).",
  "Automatic Spurious Attribute Detection": "To automatically detect spurious attributes in a target dataset with-out human-guided annotations, we propose to exploit the priorknowledge in a pre-trained VLM. Our method detects spuriousattributes in text format and consists of the following three steps. Step 1: Generate Text Descriptions. We generate a text descriptionfor each image using a pre-trained VLM , which is capable ofgenerating text descriptions of images at scale. Moreover, since themodel is trained on massive data and is not specifically fine-tunedon the target dataset, it can discover general objects and patterns.",
  "For example, in (a), besides the class object vase, the VLMalso detects the vases color green and a background object tablewith its material wooden": "Step 2: Extract Informative Words as Attributes. We extract in-formative words from the text descriptions of images as attributes.We select nouns, which describe objects, and adjectives, which de-scribe certain properties of objects, as the informative words. Forexample, we extract green, vase, top, wooden, and table from thedescription in (a). We instantiate the attribute extractor with an automatic procedure (.2) to extract these infor-mative words from the text descriptions obtained in the first step.Then, these extracted words are added to the attribute set A as thepossible spurious attributes.Remark. VLMs can detect general objects and patterns. However,due to the inductive bias learned during pre-training, VLMs maygenerate text descriptions for some images that are not alignedwith human understandings, such as describing a red-and-greenbackground as a Christmas tree\". Although Christmas tree\" is notself-explanatory in this case, it is still a valid and useful attribute,representing samples having similar red-and-green backgrounds.This also highlights the benefit of using VLMs: they can detectpatterns that are not easily perceived by humans. A limitation ofsuch a VLM-based detection approach is that VLMs may struggle ondescribing images from domain-specific tasks where, for example,slight changes in orientation of objects or variations in geographiesare important for robust predictions. Nevertheless, our proposedspurious attribute detection approach is not restricted to a specificVLM, and it can be improved if more capable VLMs are available. Step 3: Measure Spuriousness. To know whether a detected at-tribute A is spurious, we need to consider it in the correlationwith a class label , since among all the correlations between theattributes in A and class labels, some of them may be vacuous they do not exist in the training data (e.g., only exists in imagesof the class with ), and some of them are not spurious (e.g.,the attribute is detected exclusively in all the images of the class). Moreover, we are interested in identifying spurious correlationsthat are likely to be exploited by a classifier for predictions as thesecorrelations directly affect the robustness of the classifier.To unify the above cases, we propose a metric to quantify thelikelihood of the correlation , being spurious and used by aclassifier, i.e., spuriousness of the correlation. The metric considers, , the training data Dtr, and the classifier , and maps themto a finite value, which we call spuriousness score. We defines asfollows. Definition 1 (Spuriousness Metric). Given a class label Y, anattribute A, and a classifier trained on D with , thespuriousness metric for , is a mapping : Y A D , where D denotes a set of sample-label pairs, denotes theset of all possible , and denotes the output value rangeof , with being the lowest and being the highest. When thedata group size |D (,) | = 0 or |D (, ) | = 0, where denotes allattributes in A other than , the mapping outputs .",
  "Given the training set D, |D (,)| = 0 and |D (, )| = 0 cor-respond to that , does not exist in D and that , exists": "exclusively in samples of class , respectively. For both cases, thespuriousness of , should be the smallest.Then, we specifically design based on the performance of theclassifier . The motivation is that the classifier will gener-alize poorly on samples of the class without the attribute if excessively relies on for predicting the label . Therefore, asdemonstrated in (a), the spuriousness will be higher if hasa larger performance discrepancy on images with and without and be lower when the performance discrepancy is smaller. Weformally define our spuriousness metric for , as follows,",
  "D (,) D denotes the subset of all training data from the": "class with the attribute , D (, ) D denotes the subset ofall training data from the class without the attribute , (; )denotes the classification accuracy of on a given set of samples,and abs() denotes taking the absolute value. The division in Eq. (3)aims to produce larger values than the simple difference betweenthe two accuracies, making different correlations more distinctive.Moreover, using log() avoids encountering extreme values fromthe division, and tanh(abs()) bounds the score in the range from0 to 1. Other designs of are possible, and we have shown in ourexperiments that our method proposed in the following is robustto different choices of spuriousness metrics. Discussion. With the detected attributes and our spuriousnessmetric, we can identify spurious correlations that are likely tobe used for predictions by a classifier and thus pose a potentialrisk to the robustness of the classifier. To improve the robustnessto spurious correlations, we need to mitigate the classifiers re-liance on those spurious correlations. Since there are multiple spu-rious correlations, mitigating all of them at once is a challengingtask. To address this, we formulate the problem in a novel meta-learning setting, where we construct meta-learningtasks with each task containing some potentially harmful spuriouscorrelations. Now, our goal is to learn a good classifier that performswell across all these tasks with various spurious correlations.In the following, we first introduce how to construct meta-learning tasks with the identified spurious correlations. Then, wegive the details of using the constructed tasks for meta-learning.",
  "Spuriousness-Aware Task Construction": "To mitigate spurious correlations via meta-learning, we first cre-ate meta-learning tasks which will be used in meta-training. Ameta-learning task typically consists of a support (training) set Sproviding training samples for learning novel concepts and a query(test) set Q containing test samples for the evaluation of the learn-ing outcome. We use the two sets to simulate spurious correlationsin meta-learning tasks so that these spurious correlations can beeffectively mitigated via meta-learning.As illustrated in (b), for each class with = 1, . . . , ,we first sample two attributes and from A based on theirspuriousness scores, where . Specifically, we normalize the",
  "Spuriousness-Aware Meta-Learning for Learning Robust ClassifiersKDD 24, August 2529, 2024, Barcelona, Spain": "scores as probabilities, and an attribute with a higher spuriousnessscore will be more likely to be selected than another attribute witha lower spuriousness score. In this way, we target the spuriouscorrelations that pose a high risk to the robustness of the classifier.Then, the two sampled attributes formulate two spurious cor-relations with , i.e., , and ,, based on which, we get two data groups, D (, )trand D(, )tr, from the training setDtr. These two groups of data together represent a shift in thecorrelation between the two spurious attributes and the class label.If the classifier learns to rely on the spurious correlation in onegroup of data for predictions, then it will fail on the other groupof data with a different spurious correlation. Thus, crafting such ashift facilitates learning a robust classifier.Next, for efficient training, we randomly sample data pointsper class from the two data groups to construct the non-overlappingsupport set S and the query set Q, i.e.,",
  "where D (, )tr= D (, )trD(, )trand D(, )tr= D(, )tr": "D (, )trare sets of elements unique to D (, )trand D(, )tr,respectively. Taking the above set difference ensures that the twospurious correlations wont appear in the same set since somesamples may have both the attributes and .After constructing the two sets for each class, we obtain theconstructed task T = {S, Q} with S = =1S and Q = =1Q. If is large, we can randomly select a subset of classes to constructT. The constructed task T demonstrates to the classifier that thespurious correlations in T are highly risky for it, and that theclassifier should be invariant to them in order to perform well onthis task. Importantly, the construction of meta-learning tasks alsoensures that biases in VLMs wont be passed down to the classifieras the construction process effectively decorrelates biased attributesfrom VLMs with prediction targets.",
  "Meta-Learning Robust Representations": "To train a robust classifier using the constructed tasks, we modify so that it fits in with the meta-learning paradigm. Specifically,we discard the last linear classification layer of and keep itsfeature extractor 1 : X R, where 1 and is the numberof dimensions in the feature extractors outputs. Thus, learning arobust classifier is equivalent to learning robust representations.As illustrated in (c), for the th task, we use the repre-sentations of the samples in the support set S provided by 1 togenerate (learn) a centroid-based classifier with class-centroidsW = {w1, . . . , w } calculated as follows",
  "T (1) =E(,)Q log(|,1, S).(8)": "A high loss indicates that the classifier, and in turn the featureextractor 1, rely on the spurious correlations in the support setand cannot generalize well on the query set.Learning Objective. We minimize the loss in (8) over tasks con-structed with various spurious correlations to find a feature extrac-tor 1 that is robust to multiple spurious correlations, i.e.,",
  "= arg min1ET (Dtr,A,,1)T (1),(9)": "where (Dtr, A,,1) denotes all possible meta-learning tasks con-structed from Dtr based on the detected attributes A, the spurious-ness metric , and the feature extractor 1.To solve (9), we adopt an iterative optimization procedure. Wefirst fix 1 and construct a set of meta-training tasks based on A, 1,and . Then, we update 1 using the constructed tasks. The abovesteps are iterated until some stop criterion is met. We name ourmethod as SPUriousness-aware MEta-Learning (SPUME) and givethe training details in Algorithm 1.Complexity Analysis. VLMs do not incur training cost becausethey are only used for data preparation. Extracting attributes (Line1, Algorithm 1) is a onetime offline process, and empirically, itstime cost scales linearly with the dataset size. Spuriousness mea-surement (Line 4, Algorithm 1) is performed periodically during",
  "EXPERIMENT5.1Datasets": "We tested our method on five image classification datasets withvarious types of spurious correlations, which are introduced below.Detailed dataset statistics are give in in Appendix.Waterbirds contains waterbird and landbird classes. It is asynthetic dataset generated by combining images of the two kindsof birds from the CUB dataset with water and land backgroundsfrom the Places dataset , producing (landbird, land), (landbird,water), (waterbird, land), and (waterbird, water) groups.CelebA is a large-scale image dataset of celebrity faces. It con-tains images showing two hair colors, non-blond and blond, whichare spuriously correlated with gender. There are four groups inthe CelebA dataset: (non-blond, female), (non-blond, male), (blond,female), and (blond, male).ImageNet-9 is a subset of ImageNet and contains ninesuper-classes. It is known to have correlations between objectclasses and image textures. We followed the setting in and to prepare training and validation data.ImageNet-A is a dataset of real-world images, adversariallycurated to test the limits of classifiers such as ResNet-50. Whilethese images are from standard ImageNet classes , they areoften misclassified in multiple models. We used this dataset to testthe robustness of a classifier after training it on ImageNet-9.NICO is designed for out-of-distribution image classification,simulating real-world scenarios where testing distributions differfrom training ones. It labels images with both main concepts (e.g.,cat) and contexts (e.g., at home). We used the Animal super-classin NICO and followed the setting in for data preparation.",
  ": Statistics of the attributes detected from the Water-birds, CelebA, NICO, and ImageNet-9 datasets": "transformer as the encoder and the language model GPT-2 as the decoder. BLIP has a multimodal mixture of encoder-decoder architecture. After generating text descriptions, we usedSpacy ( to extract nouns and adjectives from thedescriptions automatically. We additionally filtered out words withfrequencies less than 10 to remove potential annotation noise and toensure that we have enough samples to construct a meta-learningtask with selected spurious attributes. We give the statistics of thedetected spurious attributes in the four datasets (ImageNet-A isnot included as it is only used for testing) in . BLIP detectsmore attributes than ViT-GPT2 overall but less attributes for eachimage. Based on the two VLMs, our method has two variations,namely SPUME-BLIP and SPUME-ViT-GPT2. In the followingexperiments, we report the results of both methods. Training Settings. We set = 10 for sampling each class ofimages for both the support and query sets of a task. Followingexisting settings , we used ResNet-50 as the feature ex-tractor for the experiments on the Waterbirds and CelebA datasets,and used ResNet-18 on the ImageNet-9 and NICO datasets. Allmodels were initialized with weights pre-trained on ImageNet. Weused a stochastic gradient descent (SDG) optimizer with a mo-mentum of 0.9 and a weight decay of 104 during meta-training.We trained a model for 100 epochs and used the cosine anneal-ing scheduler to control the decay of learning rate. Without anygroup labels, our method used the pseudo-unbiased accuracy onthe validation set defined in Eq. (10) for model selection, whileother methods used the average validation accuracy. We repeatedeach experiment three times and calculated the averaged resultswith standard deviations. We provide additional training details inAppendix. All experiments were conducted on NVIDIA A100 GPUs.We provide an open-source implementation of our method SPUMEat Baselines. We compare our methods with state-of-the-art meth-ods on mitigating spurious correlations and provide descriptions ofthe baseline methods in Appendix. For fair comparison, the samefeature extractor was used for methods compared on each dataset.Group labels were not used for model training and selection forall the compared methods. Note that we did not include VLMs asbaselines, as they were exclusively used for extracting attributesfrom training data in our method. Moreover, directly using VLMsrequires a completely different design, e.g., designing proper inputprompts for classification.",
  ": A meta-learning task with = 5 constructed fromthe Waterbirds dataset. Images in the support set differ sig-nificantly from images in the query set in terms of theirbackgrounds": "Evaluation Metrics. To evaluate the robustness to spurious cor-relations on the Waterbirds and CelebA datasets, which providegroup labels, we adopted the widely accepted robustness metric,worst-group accuracy, that gives the lower-bound performanceof a classifier on the test set with various dataset biases. We alsocalculated the accuracy gap between the standard average accu-racy and the worst-group accuracy as a measure of a classifiersreliance on spurious correlations. A high worst-group accuracywith a low accuracy gap indicates that the classifier is robust tospurious correlations and can fairly predict samples from differ-ent groups. We adopted average accuracy for the evaluationson the NICO, ImageNet-9, and ImageNet-A datasets as the thesedatasets are specifically constructed to evaluate the robustness todistributional shifts.",
  "Visualization of a Spuriousness-Aware Task": "We show a spuriousness-aware meta-learning task constructedfrom the Waterbirds dataset with = 5 in . For images in thesame class, their backgrounds differ significantly in the support andquery sets. Specifically, the landbird images selected based on theattribute horse\" in the support set have land backgrounds, whilethe same-class images selected based on the attribute ocean\" inthe query set mainly have water backgrounds. Similarly, the queryimages of waterbird selected based on the attribute group\" havebackgrounds filled with a group of people, while the correspondingsupport images selected based on the attribute grass field\" havegrass backgrounds without irrelevant objects.The constructed task creates a challenging learning scenario forclassifiers that rely on spurious correlations for predictions. Forexample, a classifier that learns to use the land backgrounds topredict landbird from the support set will fail to predict landbirdimages with water backgrounds in the query set. Optimizing a clas-sifiers performance on these spuriousness-aware tasks facilitatesthe classifier to learn to be invariant to spurious correlations.",
  "400 6000200 400 6000200 400 6000200 400 600": ": Spuriousness scores for all the class-attribute cor-relations before and after applying SPUME-BLIP to a classi-fier. The horizontal axes represent the indexes of detectedattributes or class-attribute correlations, and the verticalaxes represent the spuriousness scores. (a)-(d) Spuriousnessscores on the Waterbirds dataset with landbird and water-bird classes. (e)-(h) Spuriousness scores on the CelebA datasetwith non-blond and blond classes.",
  "SPUME Mitigates Reliance on SpuriousCorrelations": "We calculated the spuriousness scores for all the detected class-attribute correlations before and after applying SPUME-BLIP to aclassifier with the ResNet-50 backbone initialized with ImageNetpre-trained weights. We sorted the scores in the before\" scenariosand kept the order in the corresponding after\" scenarios. From (a), (c), (e), and (g), we observe that the initial classifiers exhibithigh reliance on the detected class-attribute correlations whichhave high spuriousness scores. After applying SPUME-BLIP to theclassifiers on the Waterbirds dataset, we observe from (b) and(d) that the reliance on most of class-attribute correlations are miti-gated and these correlations all have low spuriousness scores. Onthe CelebA dataset, which has more class-attribute correlations thanthe Waterbirds dataset, it becomes more challenging to mitigate thereliance on all these correlations. As observed from (f) and(h), some correlations, which have low spuriousness scores initially,become highly spurious. Nevertheless, SPUME-BLIP can still miti-gate the reliance on most of the class-attribute correlations havinghigh spuriousness scores. Moreover, since spuriousness scores arenot directly incorporated into our optimization objective in (9), thedecrease in spuriousness scores demonstrates the effectiveness ofour spuriousness-aware meta-learning strategy in mitigating thereliance on spurious correlations.",
  "Quantitative Evaluation": "We compared our methods with prior methods on mitigating spuri-ous correlations on the five datasets. On each of the datasets, weshow the reported results of these methods when they are availableand give the details of these methods in Appendix.For experiments on the Waterbirds and CelebA datasets, weaimed to simulate a more realistic learning scenario and thus didnot provide group labels during model training, even though the",
  ": Comparison of worst-group accuracy (%) and accu-racy gap (%) on the CelebA dataset. All methods do not haveaccess to ground-truth group labels": "two datasets provide group labels. During testing, we used thegroup labels to formulate the worst-group accuracy and calculatedthe accuracy gap as the standard average accuracy minus the worst-group accuracy. The two metrics measure a classifiers robustnessto specific spurious correlations specified by the group labels, andour goal is to train the classifier to be robust to these spuriouscorrelations without knowing them.Our methods, SPUME-ViT-GPT2 and SPUME-BLIP achieve thebest worst-group accuracy and the best accuracy gap on the Wa-terbirds and CelebA datasets (Tables 2 and 3), suggesting that ourtrained classifiers have strong and balanced prediction capabilityacross different data groups. Note that the spurious attribute detec-tion process proposed in .1 could introduce biases presentin VLMs into the detected spurious attributes. More specifically,biases in different VLMs result in different sets of attributes. Conse-quently, SPUME simulates different sets of spurious correlationsduring meta-training. However, this wouldnt be a significant con-cern. Since our spurious attribute detection process can detect manydistinctive attributes with well-established VLMs, SPUME can miti-gate many potential spurious correlations. Thus, biases in VLMswont significantly affect the effectiveness of our framework. Wedemonstrate this by showing that SPUME with two well-establishedVLMs are effective and have comparable performance across dif-ferent datasets (Tables 2 and 3). Moreover, SPUME-BLIP performs",
  ": Comparison of average accuracy (%) and accuracygap (%) on the ImageNet-9 and ImageNet-A datasets": "much better than SPUME-ViT-GPT2 on the CelebA dataset whereBLIP detects approximately twice as many attributes as ViT-GPT2does (), suggesting that detecting more attributes benefitsSPUME in training more robust classifiers.The NICO dataset provides object-context correlations and aimsto evaluate the out-of-distribution generalization capability of aclassifier by testing it in new contexts. We did not use the providedcorrelations during training and calculated the standard average ac-curacy on the test set with new object-context correlations. SPUME-ViT-GPT2 and SPUME-BLIP outperform previous methods withhigher average accuracies ().For the experiments on the ImageNet-9 which does not provideinformation on spurious correlations, we trained and tested ourmethods on the ImageNet-9 dataset. We also tested our methods onthe ImageNet-A dataset which contains images representing variousfailure prediction modes in an ImageNet pre-trained classifier. Theaccuracy gap is calculated as the average validation accuracy on theImageNet-9 dataset minus the average accuracy on the ImageNet-A dataset. Our methods achieve the best on ImageNet-A whilewell balancing between different prediction modes with the lowestaccuracy gaps ().",
  "Ablation Study": "Spuriousness-Aware Task Construction. To evaluate the effective-ness of using VLMs to guide the construction of meta-learningtasks, we compared SPUME with SPUME-Random which uses ran-domly constructed tasks during training. We also included theclassical ERM model and the ERM-Cosine model that uses cosinedistance for predictions to compare with the meta-learning basedapproaches. We observe from that switching to the cosine-distance-based classifier increases the robustness to spurious cor-relations. Moreover, SPUME-Random outperforms ERM by 12.3%in the worst-group accuracy and improves the accuracy gap by13.3%, demonstrating that meta-learning is a promising approachto improve the robustness to spurious correlations. Additionally,using spuriousness-aware meta-learning tasks constructed withthe VLMs (BLIP and ViT-GPT2) can further improve robustness tospurious correlations. Specifically, SPUME-BLIP achieves 7.0% and4.4% increments over SPUME-Random in the worst-group accuracyand accuracy gap, respectively, and SPUME-ViT-GPT2 achieves7.2% and 3.6% increments in the two metrics.",
  "Different Designs of the Spuriousness Metric. We have given ourdesign of spuriousness metric in Eq. (3). Here, we explore other pos-sible design choices shown in , where = (D (,); )": "(D (, ); ), = (D (,); )/ (D (, ); ), (; ) is the accu-racy measure used in Eq. (3), and Constant\" represents that weassign the same score for all the detected attributes. Our methodSPUME-BLIP works well with different spuriousness metrics andstill outperforms the baselines we compared in . Moreover,our method works well with non-negative spuriousness metrics asSPUME with tanh(abs(log())) or abs() performs better than withthe other two metrics. Scaling Parameter of the Centroid-Based Classifier. We analyzedhow the scaling parameter of the centroid-based classifier (Eq. (7))affects the performance of SPUME. shows the worst-groupaccuracies and accuracy gaps of SPUME-BLIP with different son the Waterbirds dataset. A very large or small , e.g., = 100 or = 1, harms to robustness of the trained classifiers. In practice, weset to be in the range from 5 to 50.",
  ": Worst-group accuracy and accuracy gap compar-isons between SPUME-BLIP with different s on Waterbirds": "outputs of VLMs. To show this, we added an additional layer afterthe backbone to predict detected attributes for each image, actingas a regularization. We then fine-tuned the whole model on theWaterbirds and CelebA datasets, respectively. The worst-groupaccuracies on the two datasets are 71.7% and 47.2%, respectively,which are close to ERM trained models. Therefore, the attributesthemselves do not provide useful regularization on the robustnessof the classifier. Moreover, directly using VLMs for predictionsrequires a completely different inference pipeline and is not aseffective as our proposed SPUME. Details are provided in Appendix.",
  "CONCLUSION": "We proposed a novel framework to train a classifier to be robustagainst spurious correlations in settings where spurious correla-tions are not known or specified. We first adopted a pre-trained VLMto automatically extract text-format attributes from a target dataset.Then, we quantified the spuriousness of the correlations betweendetected attributes and class labels using a spuriousness metric.To effectively mitigate multiple detected spurious correlations, weadopted a meta-learning strategy which iteratively meta-trains aclassifier on multiple meta-learning tasks constructed to representvarious class-attribute correlations with high spuriousness values.Our framework, SPUME, mitigates many highly spurious corre-lations in training samples and performs the best under differentrobustness measures on five benchmark datasets. In the future, weaim to explore more capable VLMs and combine other approaches,e.g., customized data augmentations, for mitigating a models re-liance on a wider range of spurious correlations.",
  "Abubakar Abid, Mert Yuksekgonul, and James Zou. 2022. Meaningfully debuggingmodel mistakes using conceptual counterfactual explanations. In InternationalConference on Machine Learning. PMLR, 6688": "Saeid Asgari, Aliasghar Khani, Fereshte Khani, Ali Gholami, Linh Tran, AliMahdavi Amiri, and Ghassan Hamarneh. 2022. Masktune: Mitigating spuriouscorrelations by forcing to explore. Advances in Neural Information ProcessingSystems 35 (2022), 2328423296. Hyojin Bahng, Sanghyuk Chun, Sangdoo Yun, Jaegul Choo, and Seong JoonOh. 2020. Learning de-biased representations with biased representations. InInternational Conference on Machine Learning. PMLR, 528539. Haoyue Bai, Rui Sun, Lanqing Hong, Fengwei Zhou, Nanyang Ye, Han-Jia Ye,S-H Gary Chan, and Zhenguo Li. 2021. Decaug: Out-of-distribution general-ization via decomposed feature representation and semantic augmentation. InProceedings of the AAAI Conference on Artificial Intelligence, Vol. 35. 67056713.",
  "Elliot Creager, Jrn-Henrik Jacobsen, and Richard Zemel. 2021. Environmentinference for invariant learning. In International Conference on Machine Learning.PMLR, 21892200": "Yin Cui, Menglin Jia, Tsung-Yi Lin, Yang Song, and Serge Belongie. 2019. Class-balanced loss based on effective number of samples. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition. 92689277. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Im-ageNet: A large-scale hierarchical image database. In 2009 IEEE Conference onComputer Vision and Pattern Recognition. 248255. Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xi-aohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, GeorgHeigold, Sylvain Gelly, et al. 2020. An Image is Worth 16x16 Words: Trans-formers for Image Recognition at Scale. In International Conference on LearningRepresentations.",
  "Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-agnostic meta-learning for fast adaptation of deep networks. In International Conference onMachine Learning, Vol. 70. 11261135": "Robert Geirhos, Jrn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel,Wieland Brendel, Matthias Bethge, and Felix A Wichmann. 2020. Shortcut learn-ing in deep neural networks. Nature Machine Intelligence 2, 11 (2020), 665673. Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge, Felix A.Wichmann, and Wieland Brendel. 2019. ImageNet-trained CNNs are biasedtowards texture; increasing shape bias improves accuracy and robustness.. InInternational Conference on Learning Representations. Zongbo Han, Zhipeng Liang, Fan Yang, Liu Liu, Lanqing Li, Yatao Bian, PeilinZhao, Bingzhe Wu, Changqing Zhang, and Jianhua Yao. 2022. Umix: Improvingimportance weighting for subpopulation shift via uncertainty-aware mixup.Advances in Neural Information Processing Systems 35 (2022), 3770437718.",
  "Yue He, Zheyan Shen, and Peng Cui. 2021. Towards non-iid image classification:A dataset and baselines. Pattern Recognition 110 (2021), 107383": "Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, and Dawn Song.2021. Natural adversarial examples. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition. 1526215271. Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras, Logan Engstrom, BrandonTran, and Aleksander Madry. 2019. Adversarial examples are not bugs, they arefeatures. Advances in Neural Information Processing Systems 32 (2019). Pavel Izmailov, Polina Kirichenko, Nate Gruver, and Andrew G Wilson. 2022. Onfeature learning in the presence of spurious correlations. Advances in NeuralInformation Processing Systems 35 (2022), 3851638532.",
  "Daniel Levy, Yair Carmon, John C Duchi, and Aaron Sidford. 2020. Large-scalemethods for distributionally robust optimization. Advances in Neural InformationProcessing Systems 33 (2020), 88478860": "Junnan Li, Dongxu Li, Caiming Xiong, and Steven Hoi. 2022. Blip: Bootstrappinglanguage-image pre-training for unified vision-language understanding andgeneration. In International Conference on Machine Learning. PMLR, 1288812900. Evan Z Liu, Behzad Haghgoo, Annie S Chen, Aditi Raghunathan, Pang Wei Koh,Shiori Sagawa, Percy Liang, and Chelsea Finn. 2021. Just train twice: Improvinggroup robustness without training group information. In International Conferenceon Machine Learning. PMLR, 67816792.",
  "Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. 2015. Deep learningface attributes in the wild. In Proceedings of the IEEE International Conference onComputer Vision. 37303738": "Junhyun Nam, Hyuntak Cha, Sungsoo Ahn, Jaeho Lee, and Jinwoo Shin. 2020.Learning from failure: De-biasing classifier from biased classifier. Advances inNeural Information Processing Systems 33 (2020), 2067320684. Junhyun Nam, Jaehyung Kim, Jaeho Lee, and Jinwoo Shin. 2022. Spread SpuriousAttribute: Improving Worst-group Accuracy with Spurious Attribute Estimation.In International Conference on Learning Representations.",
  "Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever,et al. 2019. Language models are unsupervised multitask learners. OpenAI blog1, 8 (2019), 9": "Aniruddh Raghu, Maithra Raghu, Samy Bengio, and Oriol Vinyals. 2020. RapidLearning or Feature Reuse? Towards Understanding the Effectiveness of MAML.In International Conference on Learning Representations. Andrei A. Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals, Razvan Pascanu,Simon Osindero, and Raia Hadsell. 2019. Meta-Learning with Latent EmbeddingOptimization. In International Conference on Learning Representations.",
  "Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical Networksfor Few-shot Learning. In Advances in Neural Information Processing Systems.40774087": "F. Sung, Y. Yang, L. Zhang, T. Xiang, P. H. S. Torr, and T. M. Hospedales. 2018.Learning to Compare: Relation Network for Few-Shot Learning. In IEEE/CVFConference on Computer Vision and Pattern Recognition. 11991208. Rishabh Tiwari and Pradeep Shenoy. 2023. Overcoming Simplicity Bias in DeepNetworks using a Feature Sieve. In International Conference on Machine Learning(Proceedings of Machine Learning Research, Vol. 202), Andreas Krause, EmmaBrunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and JonathanScarlett (Eds.). PMLR, 3433034343.",
  "Shirley Wu, Mert Yuksekgonul, Linjun Zhang, and James Zou. 2023. Discoverand Cure: Concept-aware Mitigation of Spurious Correlation. arXiv preprintarXiv:2305.00650 (2023)": "Kai Yuanqing Xiao, Logan Engstrom, Andrew Ilyas, and Aleksander Madry.2021. Noise or Signal: The Role of Image Backgrounds in Object Recognition. InInternational Conference on Learning Representations. Huaxiu Yao, Yu Wang, Sai Li, Linjun Zhang, Weixin Liang, James Zou, and ChelseaFinn. 2022. Improving out-of-distribution robustness via selective augmentation.In International Conference on Machine Learning. PMLR, 2540725437. Han-Jia Ye, Hexiang Hu, De-Chuan Zhan, and Fei Sha. 2020. Few-Shot Learningvia Embedding Adaptation with Set-to-Set Functions. In IEEE/CVF Conference onComputer Vision and Pattern Recognition. 88088817.",
  "Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. 2018.mixup: Beyond Empirical Risk Minimization. In International Conference on Learn-ing Representations": "Jiawei Zhang, Yang Wang, Piero Molino, Lezhi Li, and David S Ebert. 2018. Man-ifold: A model-agnostic framework for interpretation and diagnosis of machinelearning models. IEEE Transactions on Visualization and Computer Graphics 25, 1(2018), 364373. Michael Zhang, Nimit S Sohoni, Hongyang R Zhang, Chelsea Finn, and Christo-pher Re. 2022. Correct-N-Contrast: a Contrastive Approach for Improving Robust-ness to Spurious Correlations. In International Conference on Machine Learning(Proceedings of Machine Learning Research, Vol. 162), Kamalika Chaudhuri, Ste-fanie Jegelka, Le Song, Csaba Szepesvari, Gang Niu, and Sivan Sabato (Eds.).PMLR, 2648426516. Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba.2017. Places: A 10 million image database for scene recognition. IEEE Transactionson Pattern Analysis and Machine Intelligence 40, 6 (2017), 14521464.",
  "AAPPENDIXA.1Datasets": "depicts detailed statistics for all datasets. For Waterbirdsand CelebA datasets, we give the number of training, validation,and test images in each group specified by classes and attributes.For example, the group label (landbird, land) in the Waterbirdsdataset has 3498 training images which are all landbird and haveland backgrounds. NICO provides context labels as spurious at-tributes. ImageNet-9 and ImageNet-A datasets do not have cleargroup partitions specified by the class and attribute associations.",
  ": Classes and their associated contexts in the NICOdatasets. Contexts not shown in the table are used in thetraining set": "NICO is a real-world dataset for out-of-distribution robust-ness. We used its Animal subset containing 10 object classes and 33context labels. Following the setting in , we split the datasetinto training, validation, and test sets with each set having uniquecontexts. gives the allocation of the contexts for the 10classes.The ImageNet-9 dataset is a subset of ImageNet. It has 9super-classes, i.e., Dog, Cat, Frog, Turtle, Bird, Primate, Fish, Crab,Insect, which are obtained by merging similar classes from Ima-geNet. ImageNet-A contains real-world images that are challengingto the image classifiers trained on standard ImageNet. We extractimages of the 9 super-classes from the ImageNet-A dataset and usethese images as the test data.",
  "A.3Baselines": "We briefly summarize and describe the baselines which are com-pared in the experiments:Group DRO proposes to train the models on the worst-caseloss over a set of predefined groups.ReBias proposes a novel framework to train a de-biased rep-resentation by encouraging it to be different from a set of biasedrepresentations.REx proposes a min-max algorithm to optimize for the worstlinear combination of risks on different environments.",
  ": Hyperparameter settings and model selection criteria for SPUME training on the Waterbirds, CelebA, NICO, andImageNet-9 datasets. denotes pseudo unbiased validation accuracy": "LfF proposes a failure-based debiasing scheme by training apair of neural networks: the first network to be biased by repeatedlyamplifying its prejudice\" and debias the training of the secondnetwork by focusing on samples that counter the first network.CVaR DRO is an algorithm for distributionally robust opti-mization of convex losses with conditional value at risk (CVaR) and2 divergence uncertainty sets.JTT proposes a simple two-stage approach that first trains astandard ERM model and then trains a second model by upweight-ing the training examples misclassified by the first model.DFR retrains the last linear layer on a small held-out datasetwith balanced groups of data.CaaM learns causal features that are robust in any confound-ing context and self-annotates the confounders in an unsupervisedfashion.LWBC / SSL+ERM employs a committee of classifiers as anauxiliary module that identifies bias-conflicting data and assignslarge weights to them when training the main classifier. SSL+ERMis another approach proposed in this paper that uses self-supervisedrepresentation as the frozen backbone of the committee and themain classifier.MaskTune employs an interpretation-based masking strat-egy that mitigates over-reliance on spurious features. It forces thetrained model to explore new features during a single epoch fine-tuning by masking previously discovered features.DivDis is a simple two-stage framework for identifying andresolving ambiguity in data. It first learns a diverse set of hypothesesand then disambiguates them by selecting one of the discoveredfunctions using additional information (e.g. target labels).JiGen jointly classifies objects and solves unsupervised jigsawtasks.Mixup trains a neural network on convex combinations ofpairs of examples and their labels to alleviate memorization andsensitivity to adversarial examples in deep neural networks.CNBB is a non-independent and identically distributed (Non-I.I.D) learning method that is based on batch balancing inspired bycausal inference.DecAug proposes a semantic augmentation and feature decom-position approach to disentangle context features from category-related features.SIFER automatically identifies and suppresses easily-computablespurious features in lower layers of the network and allows the",
  "( ())( (),)(11)": "where () = W1 () + b, and (, ) is a binary entropyloss. We trained the whole model on the Waterbirds and CelebAdatasets, respectively. If the attributes contain information effectivein improving a classifiers robustness to spurious correlations, wewill observe improved performance after training. However, theworst-group accuracies on the Waterbirds and CelebA datasets are71.7% and 47.2%, respectively, which are only slightly better thanthose of ERM and fall far behind the results of SPUME. Therefore,the detected attributes from the VLM alone do not contain infor-mation effective for improving a classifiers robustness to spuriouscorrelations. Directly Using VLMs for Predictions. Although the goal of thispaper is to learn a classic and resource-light classifier that is robustto spurious correlations, we explored the scenario when BLIP isdirectly used for prediction with modifications on the inference par-adigm. Specifically, we used text embeddings of the sentences withthe template a photo of class_label\" (a person with hair_colorhair\" for CelebA) from BLIP as the classifier weights and calcu-lated the cosine similarity between an image embedding and theseweights in the shared embedding space of BLIP. We predicted thelabel such that its corresponding sentence has the highest similar-ity to the image embedding. The worst group accuracies on theWaterbirds and CelebA datasets are 1.17% and 29.71% respectively.The average accuracies on the NICO, ImageNet-9, and ImageNet-Adatasets are 14.30%, 13.43%, and 9.20%, respectively. Directly usingthe VLM without carefully tuning the inference pipeline performsmuch worse than our proposed method. In contrast, our proposedmethod SPUME exploits the attributes provided by VLMs in a novelway for significant improvement in the robustness of a classifier tospurious correlations."
}