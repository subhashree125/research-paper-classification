{
  "Kurt TutschkuDepartment of Computer ScienceBlekinge Institute of TechnologyKarlskrona,": "AbstractSynthetic data generation faces significant chal-lenges in accurately replicating real data, particularly withtabular data, where achieving high fidelity and utility is crit-ical. While numerous methods have been developed, the mosteffective approach for creating high-quality synthetic data fornetwork traffic security remains to be seen. This study conductsa comprehensive comparative analysis of non-AI, conventionalAI, and generative AI techniques for synthetic tabular datageneration using two widely recognized cybersecurity datasets:NSL-KDD and CICIDS-2017. Particular emphasis was placed onprominent GAN models for tabular data generation, includingCTGAN, CopulaGAN, GANBLR++, and CastGAN. The resultsindicate that GAN-based methods, particularly CTGAN andCopulaGAN, outperform non-AI and conventional AI approachesin terms of fidelity and utility. To the best of our knowledge, thisresearch contributes to the field by offering the first compar-ative evaluation of these methods specifically for cybersecuritynetwork traffic data, filling a critical gap in the literature. Italso introduces mutual information for feature selection, furtherenhancing the quality of the generated synthetic data. Thesefindings provide valuable guidance for researchers seeking themost suitable synthetic data generation method in cybersecurityapplications.Index TermsGenerative Adversarial Networks (GANs), Syn-thetic tabular Data, Cybersecurity, NSL-KDD, CICIDS, Mutualinformation, Feature selection",
  "I. INTRODUCTION": "In the rapidly evolving field of cybersecurity, IDS playsa crucial role in identifying and mitigating threats withinnetwork environments. These systems rely heavily on high-quality data to detect patterns indicative of malicious activity. However, acquiring real-world cybersecurity data posessignificant challenges, primarily due to privacy concerns andtime constraints . Researchers have turned to synthetic datageneration as a viable alternative to address this. Syntheticdata, when adequately generated, can mimic the characteristicsof real-world data while avoiding the associated ethical andlegal issues, making it a valuable resource for training andevaluating IDS .Despite the growing interest in synthetic data generation,producing synthetic datasets that maintain the utility, fidelity,and data integrity required for practical cybersecurity applica-tions remains a significant challenge . Utility refers to theability of synthetic data to support the same analytical tasksas real data . At the same time, fidelity ensures that the synthetic data accurately reflects the statistical properties ofthe original data . Data integrity, on the other hand, focuseson the accuracy and reliability of data, ensuring that it remainsunaltered and consistent , . Follow these criteria to avoidsynthetic data that is either unrealistic or similar to real data,rendering it less valuable or risky.GANs have shown great potential for generating synthetictabular data for cybersecurity purposes. Various GAN ar-chitectures like VanillaGAN , WGAN , and WGAN-GP , as well as models specifically designed for tabulardata generation such as CTGAN , CopulaGAN ,and GANBLR , have been successfully used to createsynthetic IDS data . However, the effectiveness of GANsfor generating tabular data specific to cybersecurity, such asnetwork flow data used in IDS, has yet to be thoroughlybenchmarked against other tabular synthetic data generationmethods: Artificial intelligence (AI) based and non-AI based.",
  "A. Synthetic data for cybersecurity": "1) Data privacy: Sharing real-world cybersecurity datainvolves a risk of sharing sensitive information, whichhinders collaboration and research . Thus, the syn-thetic data resolves this issue, and valuable data can beshared without compromising privacy . 2) Data scarcity: The real-world cyber security data isoften imbalanced, with normal traffic making up ahigher percentage than attacks or malicious traffic. Thiscauses a problem of data scarcity. Synthetic data in thisscenario can help balance both instances and improvecyber security tasks, such as efficient, unbiased intrusiondetection . 3) Diversity of scenarios: Cybersecurity threats are be-coming more dynamic and diverse, but real cybersecu-rity datasets often need more diversity . In this sce-nario, synthetic data helps simulate various uncommonattacks and allows for more comprehensive testing ofcybersecurity tools . 4) Enhancing AI models: When training cyber securitymodels such as Intrusion detection systems (IDS), alarge, high-quality dataset is essential for effective de-tection. Therefore, synthetic data plays a crucial role in",
  "B. Synthetic data challenges in cybersecurity": "1) Data realism: One of the primary challenges in gen-erating synthetic data is ensuring its realism comparedto real-world data . The effectiveness of AI modelstrained on synthetic data depends on how accurately thedata represents real cyber threats and network conditions. Many generative models are still in the process ofachieving data realism by increasing their fidelity andutility to mimic actual trends . 2) Lack of variability: Some generative models are ex-plicitly designed to generate a diverse set of networkinstances and cyber threats. However, if synthetic datais not generated with sufficient variability, it may misscapturing the full spectrum of possible attack vectors incybersecurity , . For instance, the WassersteinGAN has solved the problem faced by the vanillaGAN of mode collapse, thus ensuring that the generatedoutcome is not limited to a few instances . 3) Class imbalance: Cybersecurity often suffers from classimbalance, where regular traffic is much larger thancyberattacks . Synthetic data generation methodsaddress this problem by balancing malicious and benigntraffic and attacks within the cybersecurity dataset formore robust intrusion detection . 4) Privacy concerns: Synthetic data attempts to concealconfidential information from real-world sensitive datato address privacy and security concerns . However,it is not entirely free from these challenges. Ensuringthat sensitive information cannot be traced back fromthe synthetic data is crucial and remains a concern. 5) Standardization: More standardization is needed forgenerating, validating, and integrating synthetic data intocybersecurity practices. This makes it challenging toensure the reliability and consistency of the syntheticdatasets across different cybersecurity applications ,. 6) Perfomace evaluation: For evaluating synthetic data,it is crucial to note that achieving a high similarityscore does not guarantee its real-world applicability.Similarly, obtaining high accuracy in synthetic cyber-security datasets for any ML/DL model does not ensurecompatibility with real-world datasets , .",
  "C. Motivation": "This research addresses critical challenges in strengtheningIDS defenses amidst a rapidly escalating cyber threat land-scape. IDS are vital for securing networks by detecting andmitigating intrusions, but a lack of high-quality, real-worlddata for training and refinement hampers their effectiveness.Obtaining such data is challenging due to privacy concerns,ethical issues, and evolving network behaviors. Synthetic datageneration using techniques like GANs offers a promising so-lution by creating realistic, high-fidelity data that mimics net- work activities without violating privacy or legal constraints.This research is crucial to improving IDS capabilities, enablingthem to adapt to modern cyber adversaries sophisticated tac-tics. This study aims to enhance IDS robustness and reliabilityby benchmarking different synthetic data generation methods,contributing to more secure cybersecurity frameworks.This research fills a gap in cybersecurity by offering acomprehensive comparison of synthetic data generation meth-ods for enhancing IDS. While synthetic datas potential hasbeen recognized, there is limited clarity on which meth-odstraditional, AI-based, or GAN-basedprovide the high-est fidelity and utility for IDS. Existing literature has exploredvarious techniques but lacks a focused comparison of theireffectiveness in generating network traffic data for IDS. Thisstudy bridges the gap by systematically evaluating differentsynthetic data generation techniques, guiding the developmentof more effective IDS and contributing to more robust, moreadaptable cybersecurity defenses.",
  "E. Contribution": "The contributions of this work are summarized below:1) ComprehensiveComparisonofSyntheticDataGeneration Methods: This research uniquely com-pares three prominent synthetic data generation meth-odsstatistical, classical AI, and generative AIoncybersecurity network traffic datasets (NSLKDD, CI-CIDS17). This provides the first direct comparison ofthese methods in the cybersecurity field. 2) Filling the Knowledge Gap in Cybersecurity Data:The study addresses a gap in the literature by identify-ing the most suitable synthetic data generation methodspecifically for network traffic datasets, offering clarityin an area where no previous comparative study exists. 3) Practical Guidance for Researchers: By evaluatingthe performance of these methods, this research offers aclear recommendation on the best approach for generat-ing synthetic cybersecurity data, enabling researchers to",
  "A. Synthetic Tabular Data Generation Methods": "Synthetic data is an artificially produced dataset that mimicsthe statistical features of real-world data without disclosing anysensitive information . This data type spans various forms,such as tabular data, images, and text.Tabular data, organized in a table format with rows andcolumns, is widely used for ML and DL modeling. It isalso crucial for cybersecurity applications due to its structurednature. It is ideal for representing logs, transaction records,and other important information for detecting and mitigatingsecurity threats . For example, cybersecurity datasets oftencontain tabular data in IDS, fraud detection, and anomalydetection, enabling precise analysis and decision-making ,. Additionally, tabular datas clear and organized formatallows for effectively applying ML and DL algorithms toenhance security measures .The significance of synthetic data in cybersecurity stemsfrom the challenges associated with accessing high-quality,real-world data in this field. Privacy concerns, regulatorylimits, and the sensitive nature of cybersecurity informationoften restrict the availability of data . By facilitatingthe generation of realistic datasets free of genuine, sensitive",
  "Synthetic data finds multiple applications in cybersecurity,improving different facets of security management and threatresponse:": "1) Intrusion Detection Systems (IDS): By supplying var-ied and representative datasets encompassing a rangeof attack patterns and behaviors, synthetic data aids inthe training and testing of IDS, enhancing their detec-tion accuracy and resilience . Research has shownthat employing synthetic data techniques on datasetslike UNSW-NB15 and CICIDS-17 has significantly im-proved the performance of deep learning models usedin IDS . 2) Anomaly Detection: Synthetic data plays a role in sim-ulating typical and atypical behaviors within networks,thereby facilitating the training of systems to detectdeviations indicative of potential security incidents .Synthetic data has been used to preserve privacy anddetect anomalies in the KDD dataset. Its effectiveness,measured in supervised, semi-supervised, and unsuper-vised anomaly detection, showed an accuracy of 99.69%,similar to models trained on original data . 3) Security Training and Simulation: The value of syn-thetic data extends to crafting realistic scenarios forsecurity training exercises and simulations. This enablessecurity teams to hone their responses to varied cyberthreats without compromising real data . A deepConvolutional Generative Adversarial Network (DC-GAN) model was used to generate synthetic cyberattackdata and realistic attack simulations to train deep learn-ing models for better detection. The model with thosesimulated attacks achieved an accuracy of 99.69% onthe KDD dataset and 97.93% on the CICIDS-17 dataset.In discussing the significance and uses of synthetic tabulardata in cybersecurity, we will focus on the methods used togenerate such data effectively. The later sections will delveinto the specifics and their architecture. They will also providean experimental analysis of the prominent standard (non-AI)and AI-based methods for creating synthetic tabular data forcybersecurity IDS.",
  "C. Metrics for Evaluation": "1) Fidelity: Fidelity measures how well the synthetic datareplicates the statistical properties of the original real-world data . Therefore, the single most significantmetric for evaluating synthetic tabular data generally in-volves assessing the datas underlying distribution .This approach is based on the definition of data synthesisto capture the probability distribution function of the original data, thereby creating synthetic data that mir-rors these characteristics . However, the evaluationprocess can be subjective, based on the data produc-tions objective. As a result, researchers employ variousmethods to assess synthetic tabular data, considering itsstructure markedly differs from that of images.Unlike synthetic tabular data, the validation of syntheticimage-based output is often visual. If the model yieldsrealistic images, its deemed successful. Images com-prise spatial information, shape, texture, objects, andcolor . Nonetheless, synthetic data is confined toimages and encompasses tabular data , character-ized by its complexity, multiple interconnected features,hidden patterns, and context-dependent information .Hence, evaluating synthetic tabular data demands a morestructured approach. 2) Utility: Utility measures the usefulness of syntheticdata for the same tasks or analyses as the originaldata . To evaluate the quality of the synthetic data,key performance metrics such as accuracy, F1 score,precision, and recall were compared between modelstrained and tested on real data versus those involvingsynthetic data , , . Specifically, the followingscenarios were used to rank performance:TRTR (Train and Test on Real Data): Baseline per-formance using real data. TSTR (Train on Synthetic,Test on Real): Measures how well models trained onsynthetic data generalize to real data. TRTS (Train onReal, Test on Synthetic): Assesses the consistency ofsynthetic data in replicating real data behavior. TSTS(Train and Test on Synthetic Data): Evaluates syntheticdatas internal consistency and utility within a self-contained model , . By comparing these fourscenarios, the utility of the synthetic data can be ranked,providing insight into how well it replicates the practicaluse of real data . 3) Universal metrices: Recent research has examined syn-thetic tabular data via diverse statistical and ML methods. Nevertheless, these approaches could be moreprecise regarding suitable evaluation measures. Hence,theres been a move to define universal metrics toboost universality and interpretability. One such met-ric is TabSynDex, offering a score between 0 and 1to gauge the synthetic datas closeness to real data. However, this metric still needs to improve inselecting the proper evaluation measures. For example,there needs confirmation that TabSynDexs five maincomponents adequately represent the synthetic datascompleteness or facilitate more accessible validationof generated tabular data. A recent SCH Yang et al.proposal introduces a structured evaluation methodologyfocused on comparing the distributions of synthetic andreal data . This study is pivotal as it aligns withgenerative AIs core principle: replicating the probabilitydistribution of the original dataset. Therefore, by considering the recent research in the domain,this study employs prominent evaluation metrics such asfidelity (statistical similarity), utility, and class balance in itsevaluation section.",
  "A. Standard Methods (non-AI)": "1) Random Oversampling (ROS) is a widely used tech-nique to address class imbalance, a common issue indatasets, especially in domains like cybersecurity wherecertain types of data, such as network intrusions, are rarecompared to normal traffic. ROS works by duplicatingsamples from the minority class to balance the class dis-tribution, thereby preventing ML models from becomingbiased toward the majority class . This technique isparticularly relevant when the non-complex small datasetlacks sufficient examples of minority classes.In synthetic tabular data generation, ROS is often em-ployed to artificially increase the number of minorityclass samples, helping models better learn the charac-teristics of these rare events. However, its applicationin cybersecurity data, which often involves complexrelationships between variables, may be limited if usedalone, as it does not generate new, diverse data points.The basic procedure of ROS is straightforward:",
  "b) DuplicateSamples: Randomly select samplesfrom the minority class and duplicate them untilthe class distribution is balanced": "c) Augmented Dataset: The result is a dataset witha balanced class distribution, where the minorityclass is equally represented as the majority classThis process does not alter the duplicated samples,meaning the new data points are exact copies of theoriginal samples. 2) SyntheticMinorityOversamplingTechnique(SMOTE)isanadvancedover-samplingmethoddesignedtoaddressthelimitationsofROSbygeneratingsyntheticexamplesratherthanmerelyduplicating existing ones. Introduced by Chawla et al.in 2002, SMOTE aims to balance the class distributionin datasets by creating new instances of the minorityclass, which helps improve the performance of MLmodels,particularlyinscenarioswheretheclassimbalance is significant . Unlike traditional over-sampling methods, SMOTE synthesizes new samples byinterpolating between existing minority class samples,leading to more generalized decision boundaries forclassifiers .SMOTE is particularly useful in domains such as cyber-security, where the occurrence of attacks (minority class)is much rarer than normal behavior (majority class). Thetechnique is well-suited for situations where the minority",
  "a) Minority Class: For each minority class instance,there is a need to select k-nearest neighbors, e.g.,k = 5": "b) Synthetic Samples: One of the k-nearest neighborsis randomly chosen to generate a synthetic datapoint. The synthetic data point is created by inter-polating between the feature vector of the originaldata point and that of the selected neighbor. Thisinterpolation involves calculating the differencebetween the feature vector of the selected neighborand the original data point. Then, this differenceis multiplied by a random number between 0 and1, and the resulting value is added to the featurevector of the original data point.",
  "tions within the minority class, thereby mitigatingthe risk of overfitting and improving the modelsability to generalize": "3) Adaptive Synthetic Sampling (ADASYN) is an over-sampling method similar to ROS and SMOTE. However,it introduces a more adaptive approach to generatingsynthetic data. It was introduced by He et al. in 2008 andfocuses on the harder-to-learn examples from the minor-ity class. ADASYN improves on SMOTE by adaptingthe sampling procedure based on the learning difficultyof each minority class sample. Data points that areharder to classify receive more synthetic neighbors; therest receive fewer neighbors. .ADASYN is particularly useful in domains such ascybersecurity, where the rarity of specific attack types(minority class) can cause models to perform poorly. By adaptively generating synthetic samples basedon the distribution of the minority class, ADASYN helpsmodels learn the decision boundary more effectively,leading to better generalization and improved detectionof minority class instances .",
  "ADASYN operates through the following steps:": "a) IdentifyDifficultMinorityClass: ADASYNcomputes the local density of each minority classby analyzing how many of its nearest neighbors be-long to the majority class. Data points surroundedby majority-class neighbors are considered harderto classify. b) Weight Assignment: Weights are assigned to eachminority instance/data point based on difficultylevel. Harder-to-classify points receive a higherweight, implying that more synthetic samples willbe generated. c) Synthetic Samples: For each minority instance,ADASYN interpolates between the instances andone of its nearest minority class neighbors. Syn-thetic samples are created along the line connectingthe two instances.",
  "d) Data Balancing: ADASYN adds the generatedsamples to the original ones, focusing on the prob-lematic region to reduce the class imbalance andimprove the model training and learning": "4) Cluster Centroids is an under-sampling technique de-signed to address class imbalance by reducing the num-ber of majority class instances. Unlike traditional under-sampling methods, which randomly remove majorityclass samples, Cluster Centroids utilizes a clusteringalgorithm to identify representative centroids within themajority class. The technique was popularized to pre-serve the majority classs distribution and structure whilereducing its size, thereby balancing the dataset withoutlosing critical information , . This approach isbeneficial in scenarios where the majority class is sub-stantial, and random under-sampling could significantlylose valuable data.The concept of cluster centroids is applicable in variousdomains, including cybersecurity. In highly imbalanceddatasets, where normal traffic significantly outweighs theattack data, cluster centroids help by grouping similarattack (minority class) samples into clusters and gener-ating synthetic data points at the centroid of each cluster.This helps represent the attack patterns more effectivelyand exposes ML models to diverse attacks for robustanomaly detection .Cluster Centroids operates through the following steps:",
  "d) Balanced Dataset: Synthetic data is added to theoriginal data to balance class distributions, improv-ing the AI models ability to learn from minorityclasses for higher efficiency": "5) Gaussian Mixture Model (GMM) is a probabilisticmodel used to represent the presence of sub-populationswithin an overall population without requiring that aninstance belong exclusively to a single sub-population.GMMs are particularly useful for modeling data thatexhibit multiple underlying distributions, assuming thatall data points are generated from a mixture of severalGaussian distributions with unknown parameters .Each Gaussian component within a GMM represents acluster characterized by its mean, variance, and mixingcoefficient.In the context of synthetic tabular data generation,GMMs approximate the data distribution, making themhighly applicable for generating new samples that pre-serve the statistical properties of the original dataset.This is especially useful in cybersecurity, where mod-eling the intricate patterns of network traffic or attackvectors requires flexible and accurate representation ofcomplex, multimodal distributions . GMMs providea robust method for capturing these patterns, allowingfor generating synthetic data that closely mimic real-world scenarios .GMM operates through the following steps: a) Fitting GMM: GMM fits the original data byassuming it comes from the mixture of multipleGaussian distributions. It estimates these Gaus-sian components parameters (mean, covariance,and weights) using the Expectation-Maximization(EM) algorithm. b) Estimate Gaussian Parameters: The model as-signs data points to different Gaussian componentsbased on their likelihood and calculates the mean(center), covariance (spread), and mixture weight(probability and skewness) for each Gaussian dis-tribution. c) Sampling: After training the model, synthetic datais generated by randomly selecting a Gaussiancomponent (based on its weight) and then sam-pling a point from the selected Gaussian using itsparametric values. d) Data Generation: Repeating the sampling processmultiple times generates synthetic data that mimicsthe structure and underlying distribution of theoriginal data. Thus, the generated data points fromall components are combined to form the finalsynthetic dataset. .",
  ". Bayesian Network illustrating some key feature dependencies in the NSL-KDD dataset": "conditional dependencies via a directed acyclic graph(DAG).BayesianNetworksareparticularlyeffective for modeling complex relationships in datawhere uncertainty and causality play critical roles ,. In figure 2, this BN illustrates that target is acentral feature, influenced by several other variables,includingservice_http,service_private,flag_SF, logged_in, and flad_S0. This suggeststhat target plays a crucial role in determining thesystems behavior, as it is obvious by its binary data typeof normal or attack. The BN also shows key conditionaldependencies, such as flag_SF being dependenton logged_in and service_domain_u, whiledst_host_serror_rateinfluencesflad_S0.Somefeatures,likeservice_privateandservice_http, directly impact target but donot further influence other variables. Overall, thisnetwork emphasizes the significant joint dependenciesbetween these system features, highlighting target asa critical node and capturing the complex relationshipsbetween the various network-related parameters.In synthetic data generation, BNs generate data thatpreserves the inherent dependencies and conditionalprobabilities observed in the original dataset. This isparticularly valuable in cybersecurity, where understand-ing the intricate dependencies between various networkevents, user behaviors, or attack patterns is essentialfor generating realistic synthetic datasets. By capturingthese relationships, BNs allow for the generation ofsynthetic data that not only mimics the distribution ofthe original data but also maintains the underlying causal",
  "structures, making it highly applicable for scenariosrequiring interpretable and robust synthetic data .The process of generating synthetic data using BayesianNetworks involves the following steps :": "a) Structure Learning: The first step is to determinethe structure of the Bayesian Network, which in-volves identifying the dependencies between vari-ables. This can be done using expert knowledge oralgorithms that learn the structure from data, suchas hill climbing or score-based methods . Eachnode in the network corresponds to a variable, anddirected edges between nodes represent conditionaldependencies. b) Parameter Learning: After defining the struc-ture, the next step is to estimate the conditionalprobability distributions (CPDs) for each variablein the network, given its parent node. This jointprobability information is learned from the originaldataset. c) Sampling: After learning the structure and pa-rameters (CPDs), synthetic data is generated bysampling from the Bayesian network. First, theroot node is sampled from its marginal distribution,and then the child nodes are sampled based ontheir conditional probabilities. This process contin-ues throughout the network until all variables aresampled.",
  "the dataset. This process ensures that the generateddata depicts the dependencies learned from theoriginal dataset": "2) Tabular Variational Autoencoder (TVAE) is a genera-tive model designed to handle the complexities of tabulardata, often including a mix of continuous and categoricalvariables. TVAE has the base idea of autoencodersthat consists of two parts: an encoder network thatlearns to compress high-dimensional data into a low-dimensional, latent spacial representation (the code) anda decoder network that decompresses the compressedrepresentation into the original domain as depicted in . Thus, it extends the traditional VariationalAutoencoder (VAE) framework by adapting it to thespecific needs of tabular data, ensuring that the gener-ated synthetic data accurately reflects the structure anddistribution of the original dataset .Mathematical process of TVAE for Synthetic data gen-eration: a) Encoder-Decoder Architecture: TVAE uses anencoder-decoderstructurewheretheencoderq(z|x) maps the input data x to a latent space z,and the decoder p(x|z) reconstructs the data fromthis latent representation. The encoder outputs theparameters of a Gaussian distribution in the latentspace:",
  "Where N(z; (x), (x)2I) represents a multi-variate normal (Gaussian) distribution where thelatent variable z is assumed to follow a Gaus-sian distribution with mean (x) and covariance": "matrix (x)2I. The two parameters, (x) and(x), are functions of the input x and are learnedby the encoder network. More precisely, (x)is the mean vector of the Gaussian distribution,parameterized by the input x. This vector rep-resents the expected value of the latent variablez for a given input x, determining the centerof the distribution, and (x)2 is the varianceof the latent variable z, also parameterized bythe input x. This variance determines how muchthe latent variable z can deviate from its mean(x), controlling the spread of the distribution.Specifically, (x)2 is the element-wise square ofthe standard deviation (x). Plus, I is the identitymatrix used to represent that the latent variablesare assumed to be independent, meaning there isno covariance between different latent dimensions.The use of I ensures that the covariance matrix isdiagonal, implying that each latent variable has itsindependent variance, controlled by (x)2.",
  "DKL(q(z|x)||p(z))(2)": "Here, L(, ; x) is the objective function (ELBO)to maximize during the training of TVAE. Itmeasures how well the model reconstructs dataand regularizes the latent space, and log p(x|z)represents the reconstruction loss, ensuring that thegenerated data x resembles the input data x. DKL is the Kullback-Leibler divergence that regularizesthe latent space to follow a prior distribution p(z),typically a standard normal distribution N(0, I).Plus, Eq(z|x)[log p(x|z)] is the expected log-likelihood term, representing the reconstructionloss. It ensures that the generated data x resemblesthe input data x. c) Latent Variable Modeling: The latent space z issampled from the Gaussian distribution parameter-ized by (x) and (x). This latent space effec-tively captures the dependencies and distribution ofthe original data. d) Data Generation: To generate synthetic data, sam-ples are drawn from the latent space z, and thesesamples are passed through the decoder p(x|z) toproduce synthetic data points x. The decoder en-sures that the synthetic data preserves the statisticalcharacteristics of the original tabular dataset. e) Categorical and Continuous Data Handling:TVAE incorporates specific mechanisms to handlethe peculiarities of tabular data. Standard Gaussiandistributions are used for continuous variables,while TVAE often employs a Gumbel-Softmax dis-tribution for categorical variables to allow gradient-based optimization. 3) Diffusion Models, particularly Denoising DiffusionProbabilistic Models (DDPM), have emerged as a pow-erful class of generative models , . Originallydeveloped for continuous data types such as images,these models have been adapted to handle the com-plexities of tabular data, which often includes a mixof categorical and numerical variables. The applicationof diffusion models to tabular data is exemplified bythe Tabular Diffusion Model (TabDDPM), which hasshown state-of-the-art performance in generating high-quality synthetic tabular data .Mathematical process of diffusion models for tabulardata generation: a) Forward and Reverse Diffusion Processes: Thediffusion model begins with a forward processthat gradually adds Gaussian noise to the data.Given a data point x0, the forward process gen-erates a sequence of increasingly noisy versionsx1, x2, . . . , xT , where each step adds a smallamount of noise ():",
  "txt1, tI)(3)": "Here, t is a variance schedule that controls theamount of noise added at each step t. The term1 t represents the decay factor, which ensuresthat the noise doesnt overwhelm the signal, and Iis the identity matrix indicating that the noise isisotropic.The reverse process aims to generate synthetic databy denoising a sample starting from pure noise.",
  "p(xt1|xt) = N(xt1; (xt, t), 2I)(4)": "Here, (xt, t) is the predicted mean and 2 is thepredicted variance at time step t, both parameter-ized by the neural network . The network param-eters are optimized to minimize the Kullback-Leibler divergence between the forward and re-verse processes, effectively learning to denoise thedata step by step. b) Loss Function: The training objective for diffusionmodels in tabular data is typically the variationallower bound (VLB), which can be simplified to themean-squared error (MSE) between the predictednoise and the actual noise:",
  "L() = Et,x0, (xt, t)2(5)": "Here, (xt, t) is the predicted noise by the modelat time step t, where xt represents the noisy dataand is parameterized by the neural network .The term represents the noise added to the dataduring the forward process. The model minimizesthe difference between and (xt, t), effectivelylearning to reverse the noise and reconstruct thedata.The expectation Et,x0, denotes the averaging overall time steps t, initial data x0, and noise samples applied during the forward process. c) Handling Categorical and Numerical Features:Diffusion models for tabular data, such as TabD-DPM, extend the basic framework to handle mixeddata types. Categorical variables are typically pro-cessed using multinomial diffusion, where the datais represented as one-hot encoded vectors, andthe noise is added in a way that respects theunconditional nature of the data:",
  "q(xt|xt1) = Cat(xt; (1 t)xt1 + t/K) (6)": "Here, Cat(xt; ) represents the categorical distri-bution, which ensures that the synthetic data ad-heres to the unconditional nature of the variable.The term t is the variance schedule controllingthe amount of noise added, while K representsthe number of categories. (1 t)xt1 + t/Kmaintains the correct distribution of categories byadjusting the probability mass of each category atevery time step t.Numerical variables are handled using standardGaussian diffusion processes. The model learns todenoise both categorical and numerical features ina unified framework, ensuring that the generatedsynthetic data maintains the relationships and dis-tributions of the original data.",
  ". Diffusion Model Flow": "d) Synthetic Data Generation: After training, themodel can generate synthetic tabular data by sam-pling from the learned distribution. The reverseprocess generates a sequence of less noisy samplesfrom a sample of pure noise until the final syntheticdata point is produced. This approach allows themodel to create realistic tabular data that capturesindividual feature distributions and the dependen-cies between features. 4) Generative Adversarial Networks (GAN)a) Conditional Tabular GAN (CTGAN): CTGAN is agenerative model designed explicitly for tabular data, whichis often characterized by the presence of mixed data types,including both categorical and continuous variables . CT-GAN extends the traditional GAN framework () byincorporating techniques that are well-suited for the uniquechallenges of tabular data generation, such as handling im-balanced datasets and preserving the relationships betweenvariables , .Mathematical process of CTGAN for synthetic data gener-ation: 1) Generator and Discriminator Networks: CTGAN usesa generator network G(z, c) that takes as input a noisevector z sampled from a standard normal distributionand a conditional vector c that encodes the categoricalfeatures. The generator produces synthetic data samplesthat mimic the real data distribution. The discrimina-tor network D(x, c) is then tasked with distinguishingbetween real data samples x and synthetic samples gen-erated by G(z, c) while also considering the conditionalvector c.",
  "where x is the original continuous variable, xsample isa value randomly sampled from the distribution of x,and (xmode) is the empirical standard deviation of xwithin its mode": "3) Conditional Vector Construction: CTGAN utilizes aconditional vector c to guide the generation process,particularly for categorical variables. This vector isone-hot encoded, allowing the generator to focus onproducing samples that match the specific conditionsdefined by c. The conditional vector is also integratedinto the discriminators training process, helping it betterdifferentiate between natural and synthetic data based onthe specified conditions. 4) Training Objective: The training process of CTGANfollows the standard GAN framework, where the genera-tor and discriminator are trained in a min-max game. Thegenerator aims to minimize the following loss functionto fool the discriminator, while the discriminator tries tomaximize its ability to distinguish real from syntheticdata:",
  ". Original GAN structure by Goodfellow": "Where G represents the generator, D represents thediscriminator, x is a data sample drawn from the realdata distribution pdata, z is a random noise vector drawnfrom the prior distribution pz, c denotes any additionalconditional information, G(z, c) does the generator gen-erate the synthetic data, and D(x, c) and D(G(z, c), c)are the discriminators outputs for real and syntheticdata, respectively. 5) Data Sampling and Imbalance Handling: CTGANemploys a training-by-sampling technique to addressclass imbalance in tabular data. The data points are sam-pled during training to ensure underrepresented classesare adequately represented in the training batches. Thisapproach mitigates the impact of imbalanced datasets onthe quality of the generated data.b) Copula GAN: CopulaGAN is a generative model thatcombines the strengths of copula-based statistical models withthe flexibility of GANs to generate synthetic tabular data .Copulas are mathematical tools that describe the dependencestructure between random variables, enabling the modeling ofcomplex dependencies separately from the marginal distribu-tions . By integrating copulas into the GAN framework,Copula GAN effectively captures the intricate dependencies intabular data, making it particularly suitable for scenarios wherepreserving the relationships between variables is crucial .The mathematical process of Copula-GAN for syntheticdata generation: 1) Marginal Distribution Estimation: The first step inCopula GAN involves estimating the marginal distribu-tions of each variable in the tabular dataset. This canbe achieved using kernel density estimation for contin-uous variables or empirical distributions for categoricalvariables. The goal is to transform the original data intoa uniform distribution on the interval using thecumulative distribution function (CDF) of each variable:",
  "C(u1, . . . , ud) = P(U1 u1, . . . , Ud ud)(10)": "where C denotes the copula function, u1, . . . , ud arethe values of the copula-transformed variables, andU1, . . . , Ud are the random variables corresponding tothese transformed values. The expression P(U1u1, . . . , Ud ud) represents the joint probability thatU1 is less than or equal to u1, U2 is less than or equalto u2, and so on up to Ud and ud.The copula function separates the dependency structurefrom the marginal distributions, which is advantageousfor generating synthetic data that preserves the originaldatas relationships. 3) Generator and Discriminator Networks: In CopulaGAN, the generator G(z) takes a noise vector z andgenerates samples in the copula space, aiming to mimicthe dependency structure captured by the copula func-tion. The discriminator D(u) evaluates whether a givensample from the copula space is real or generated,guiding the generator to produce more realistic samples:",
  "xi = F 1i(ui)for i = 1, . . . , d(12)": "Where xi represents the i-th component of the syntheticdata in the original data space, ui is the i-th elementin the sample in the copula space, and F 1idenotes theinverse of the marginal CDF of the i-th variable. Thisinverse transformation ensures that the generated datapoints follow the original marginal distributions whilemaintaining the dependencies modeled by the copula.c) Naive Bayes and Logistic Regression GAN (GAN-BLR++: GANBLR++ is an advanced generative model de-signed to address the limitations of traditional GANs in gen-erating synthetic tabular data, mainly where complex depen-dencies and mixed data types (categorical and numerical) areinvolved. Unlike its predecessor, GANBLR, which primarilyfocused on modeling categorical data using restricted BayesianNetworks, GANBLR++ introduces significant enhancementsthat allow it to generate both categorical and numerical datawith greater accuracy , . This model integrates unre-stricted Bayesian Networks and introduces a Dirichlet MixtureModel (DMM) for numerical data generation, enabling it tocapture the full range of dependencies in real-world tabulardatasets . GANBLR++ is particularly useful in domainswhere the integrity of the generated data is critical, such ascybersecurity, which offers a robust solution that balancesflexibility, accuracy, and computational efficiency.The mathematical process of GANBLR++ for synthetic datageneration: 1) Incorporation of Unrestricted Bayesian Networks:GANBLR++ leverages unrestricted Bayesian Networksto model complex dependencies between variables. Thenetwork structure is learned through a scoring functionthat optimizes the log-likelihood of the data while in-cluding a regularization term to avoid overfitting. Thisallows the model to represent more intricate relation-ships between variables than the restricted networks usedin GANBLR.",
  "Score(G : Ddata) = LL(G : Ddata) |G|(13)": "where Score(G : Ddata) is the score of the networkstructure G given the data Ddata, LL(G : Ddata)denotes the log-likelihood of the data under the networkG, is the regularization parameter, and |G| representsthe complexity of the network G. The regularizationterm |G| helps prevent overfitting by penalizing morecomplex network structures. 2) Dirichlet Mixture Model for Numerical Data: Tohandle numerical data effectively, GANBLR++ uses aDirichlet Mixture Model (DMM). The DMM identifiesmodes within the numerical data distribution and sam-ples from these modes during data generation, ensuringthat the generated values accurately reflect the underly-ing distribution of the original data.",
  "xi N(c, c)(14)": "where xi is the i-th sample from the numerical data,N(c, c) denotes a Gaussian distribution with mean cand standard deviation c for a particular mode c. Theparameters c and c represent the mean and standarddeviation of the Gaussian distribution associated withthe mode c. 3) Mode-Specific Sampling: GANBLR++ further refinesthe generation of numerical data through mode-specificsampling, which ensures that the generated data pointsnot only match the distributional characteristics of theoriginal data but also maintain the necessary granularity.",
  "c c + 1(15)": "where xi is the i-th sample from the numerical data,N(c, c) denotes a Gaussian distribution with mean cand standard deviation c for a particular mode c, and cis a mode-specific threshold parameter. The constraintc <xic c c + 1 ensures that xi falls within aspecific range relative to the mode c, maintaining thegranularity of the distribution.d) Cascaded Tabular GAN (CasTGAN): CasTGAN is anovel framework designed for generating realistic tabular data. Traditional GAN models often struggle with capturingthe complex dependencies between features in tabular datasets,leading to synthetic data that fails to preserve the validity andinterdependencies present in the original data . CasTGANaddresses this limitation by employing a cascaded architecturewhere each generator in the sequence is responsible forsynthesizing a single feature of the dataset. This architectureallows the model to better capture the intricate relationshipsbetween features, ensuring that the generated data is not onlystatistically similar to the real data but also semantically valid.The primary motivation behind CasTGAN is to enhance thegeneration of high-quality synthetic tabular data, which iscrucial in scenarios where data privacy is a concern and realdata cannot be freely shared or used.The mathematical framework of CasTGAN can be brokendown into the following steps: 1) Cascaded Generators: The model is composed ofmultiple generators G1, G2, . . . , GM, each responsiblefor generating one feature of the dataset. Each generatorGi receives inputs from a noise vector z and the outputsof the previous generator Gi1. 2) Auxiliary Learners: For each generator Gi, there is anauxiliary learner ALi that computes a loss specific tothe feature generated by Gi. The auxiliary loss guidesthe generator toward producing more accurate and validfeature values.",
  "GP Expx(xD(x)2 1)2(16)": "where G represents the cascade of generators, D isthe discriminator, x is a sample from the real data dis-tribution pdata, z is a sample from the prior distributionpz, G(z) is the generated sample from the cascade ofgenerators, x is a sample from the data distribution usedfor the gradient penalty px, xD(x) is the gradient ofthe discriminator concerning x, xD(x)2 denotes theL2 norm of this gradient, and GP is the gradient penaltycoefficient. The term (xD(x)2 1)2 enforces theLipschitz constraint on the discriminator.",
  "IV. MUTUAL INFORMATIAON": "Mutual Information (MI) measures the mutual dependencebetween two random variables (linear or non-linear), initiallyintroduced by Shannon in his foundational work on infor-mation theory . It quantifies the amount of informationgained about one random variable through the observation ofanother . Unlike the correlation coefficient, limited to real-valued random variables and linear relationships, MI is moregeneral, capturing both linear and non-linear dependencies. The concept of MI is closely related to entropy, afundamental notion in information theory that measures theexpected amount of information in a random variable .MI can be understood as the expected value of the pointwisemutual information (PMI), reflecting how much the jointdistribution of two variables deviates from the product of theirmarginal distributions .",
  "A. Comparison with Other Methods": "The rationale for selecting MI over other methods liesin its comprehensive mathematical framework. Initially, thisstudy considered two general approaches for choosing the bestfeatures based on their dependence on the target feature andtheir relationships. Correlation was the first and most obviouschoice, mathematically defined as the Pearson correlation coefficient (equ: ??). However, correlation only accounts forlinear relationships . In real-world scenarios, non-linearrelationships often need to be identified and quantified to selectthe optimal set of features.",
  "XY(17)": "where Cov(X, Y ) is the covariance between variables Xand Y , and X and Y are the standard deviations of X andY , respectively. While correlation is effective for capturinglinear relationships, it does not account for the non-linearrelationships that often exist in real-world data, limiting itseffectiveness for feature selection.The second option was a tree-based AI technique, knownfor its robustness and ability to identify essential featuresrigorously . However, tree-based methods suffer from theblack box problem, offering little interpretability regardingwhy certain features are selected.While approaches like Information Gain (IG) have beenused for feature selection, as demonstrated by one study, Information Gain only measures the relationship be-tween individual features and the target variable, overlookinginterdependencies between features . Mathematically, itmeasures the reduction in entropy when a feature X is usedto predict the target variable Y .",
  "IG(Y, X) = H(Y ) H(Y |X)(18)": "where H(Y ) is the entropy of the target variable Y , andH(Y |X) is the conditional entropy of Y given X. AlthoughInformation Gain quantifies the relationship between individ-ual features and the target variable, it ignores interdependen-cies among the features.In contrast, MI captures the relationship between featuresand the target and the dependencies among the featuresthemselves, providing a more holistic evaluation . MIis defined as:",
  "MI(X, Y ) = H(X) + H(Y ) H(X, Y )(19)": "where H(X) and H(Y ) are the entropies of variables Xand Y , and H(X, Y ) is their joint entropy. By capturing non-linear dependencies and interactions among features, MI offersa more comprehensive framework for feature selection.Compared to other AI-based feature selection methods,such as recursive feature elimination or embedded methodsbased on decision trees , MI has the upper hand bybeing model-agnostic. Many AI-based techniques are tied tospecific algorithms or models, which may introduce biases orlimit generalizability across different datasets or classifiers.MI, however, evaluates feature importance based on statisticaldependencies independent of any specific model, making ita versatile and unbiased approach . This allows MI toprovide a more robust selection process, especially in scenarioswhere feature relationships are complex and nonlinear, acommon occurrence in cybersecurity network data.",
  "B. Application of Mutual Information in this Study": "In this study, MI is crucial for measuring the datasetsdependency between different features (variables). It helpsunderstand the strength of relationships between variables,which is essential for modeling and analysis. For example,mutual information was used to quantify the relation betweeneach feature xi and the target y and between each feature toidentify interdependencies within the features. This step wascrucial to filter down the essential features that explain thetarget variables and to cluster the features exhibiting similarbehavior.The mutual information score of every feature was deter-mined concerning the target, and the top 25% of the featureswere selected based on the mutual information weights (TableIII & Table IV). This way, the computation was less intensive,the information was high, and the results were more inter-pretable.",
  "V. EVALUATION METRICS": "The evaluation metrics utilized in this study align with thoseused in previous studies, as outlined in section II of thispaper. The following section details how these metrics wereemployed in this study and how each metric was measured toassess the experimental results. 1) Statistical Similarity (Fidelity) refers to the necessityfor synthetic data to resemble the underlying statisticalproperties of real data closely . This metrics coremathematical definition is that each variables probabil-ity distribution in the synthetic dataset should closelymatch that of the corresponding variable in the realdataset . However, beyond replicating the individualbehavior of each variable, it is equally important to ex-amine the interdependencies and relationships betweenvariables. To evaluate these relationships, we comparethe correlations among variables in both datasets .Another crucial aspect is the preservation of the datastructure. For instance, if a variable is binary in thereal data, it must remain binary in the synthetic data toensure logical consistency. Similarly, suppose a variableis defined to have values greater than or equal to zero(such as packet size in network traffic data). In thatcase, the corresponding variable in the synthetic datashould also respect this constraint. Failing to maintainthese structural properties can lead to synthetic data that,while statistically similar on a superficial level, fails tocapture the logical and contextual nuances necessary foraccurate downstream analyses and applications . Inthis study, the following metrics were used to measurethe statistical similarity (fidelity), as shown in Tables Vto X: a) DataBoundaries(DB): This metriccheckswhether the synthetic data adheres to the originaldatas logical minimum and maximum values. Forexample, a binary column should contain onlybinary values, ensuring no out-of-bound entries. b) Correlation (Corr): This is assessed by examiningthe correlation heatmap of all variables absolutevalues of the correlation coefficients. It evaluatesthe strength and direction of relationships in bothreal and synthetic datasets.",
  "c) Probability Distribution (PD): This compares theunderlying probability distribution of each variablebetween the real and synthetic datasets, ensuringthat their statistical properties are aligned": "2) Performance (utility/accuracy) is a widely used metricto evaluate the utility of synthetic data, particularly inthe context of ML and DL models . This metriccompares how models trained on synthetic data performrelative to those trained on real data . The mostcommon approach is to contrast TRTR (train and test onreal data) with TSTR (train on synthetic data and teston real data). By assessing the models accuracy, F1score, precision, and recall, researchers can determinethe efficacy of the synthetic data. Suppose the modelsperformance metrics in the TSTR scenario are compa-rable to or exceed those in the TRTR scenario. In thatcase, the synthetic data is considered a viable alternativeto the real data .Moreover, a well-performing TSTR indicates that thesynthetic data captures the essential patterns and re-lationships within the real data, making it suitablefor model development, validation, and deployment inprivacy-sensitive environments. However, its crucial tonote that synthetic datas utility is not solely dependenton performance metrics; it also relies on the datasability to generalize across different models and tasks,which should be considered in comprehensive evalua-tions .Thus, in this study, the accuracy of TRTR was comparedwith TSTR for measuring ML utility, as reported inTables V to X. 3) Class Balance (CB) is a critical metric for evaluatingthe quality of synthetic tabular data, particularly in clas-sification tasks. Class balance refers to the distributionof instances across different classes in the dataset .Maintaining a balanced class distribution in real-worlddatasets is essential for training robust ML models,as imbalanced courses can lead to biased models thatperform poorly on underrepresented classes .Ensuring that the class distribution closely mirrors thereal data is essential when assessing synthetic data. Thisinvolves not only comparing the overall proportions ofeach class but also examining the stability of theseproportions across different subsets of the data. Somemethods and tools for generating synthetic data inher-ently include mechanisms to evaluate and maintain classbalance, ensuring that the synthetic dataset accuratelyreflects the class distribution of the real dataset. Supposea synthetic data generation method does not inherentlyaddress class balance. In that case, it may require ad- ditional post-processing to adjust class distributions andavoid introducing bias into the model training process.Thus, the CB results mentioned in Tables V to X repre-sent how much difference exists between the NORMALand ATTACK cases. If the classes in the synthetic dataare the same, there is zero difference; otherwise, thedifference is detailed in the results table later in thispaper.",
  "B. Software Setup": "The software environment for the experiments was basedon Microsoft Windows 11 Pro. The primary programminglanguage used was Python 3.12.4, which provides a stableand versatile platform for implementing various data scienceand ML techniques. Essential libraries and frameworks includeNumPy for numerical operations, Pandas for data manipula-tion, Seaborn and matplotlib for data visualization, and sci-kit-learn for ML utilities. The experiments also leveraged PyTorchfor deep learning tasks. For handling class imbalance, theimbalanced-learn library (learn) was employed. The librariesare crucial for the GAN models, including SDV (SyntheticData Vault) for tabular data generation, as they support modelslike CTGAN, TVAE, and CopulaGAN. Due to the lack of pre-existing packages, their official GitHub repositories were alsoutilized for specialized GAN models such as GANBLR andCASTGAN. PGMPy and SciPy were also used for probabilis-tic graphical models and scientific computations.",
  "C. Datasets & Pre-processing": "1) NSL-KDD dataset, a refined version of the originalKDD Cup 1999 dataset, is widely used in cybersecurityto evaluate IDS . It addresses some critical issuespresent in its predecessor, such as redundant records andimbalanced distribution, thereby providing a more accu-rate and reliable benchmark for performance evaluation.For this study, the training portion of the NSL-KDDdataset, originally consisting of 125,973 instances and42 columns (41 features and 1 (binary) target), was used.The preprocessing of the NSL-KDD dataset involvedseveral essential steps to prepare it for synthetic datageneration and evaluation. Initially, categorical columnswere encoded to transform non-numeric data into asuitable format for ML algorithms. This encoding pro-cess ensured that all categorical variables were con-verted into numerical values, facilitating the subsequentanalysis. Following the encoding, feature extraction was performed to identify the most significant features usingMutual Information. This process selected the featurestop 25% (Q1) based on the mutual information weights.This step resulted in a reduced feature set of 26 encodedfeatures (Table I), which were the most important (basedon the information weights; Table III) for accuratelyrepresenting the data. This refined feature set was thenused in the data generation phase, ensuring that thesynthetic data closely mirrored the critical characteristicsof the original dataset. 2) CICIDS-17 dataset, part of the Canadian Institute forCybersecuritys intrusion detection dataset collection, iswidely employed for evaluating cybersecurity systems. It provides a comprehensive network traffic data setwith diverse attack types and normal traffic, offering arobust benchmark for performance assessment. CICIDS-17 has one week of captured network traffic data in eightcomma-separated files (CSV). These files are generatedbased on the attack types. There are 2,830,743 instancesof all eight files and 79 columns (78 numerical featuresand one binary target).Preprocessing of the CICIDS-17 dataset involved severalvital steps to ready it for synthetic data generation andevaluation. First, all the files were individually tested fornull values and duplicated columns. In this process, itwas found that there were some infinity values in thedata. Thus, all the null values, infinity, and duplicatedcolumn Fwd Header Length were removed. Secondly,all the cleaned data files were concatenated into a singleCSV file for further feature selection. Lastly, mutualinformation was performed to select the variables top25% (Q1) based on the mutual information weights. Thisstep resulted in a reduced feature set of 21 features (Ta-ble II), which were determined to be the most important(based on the information weights; IV) for accuratelyrepresenting the data. This reduced feature set wasthen employed in the synthetic data generation phase,ensuring that the synthetic data accurately reflected theessential characteristics of the original dataset.",
  "VII. EXPERIMENTAL RESULTS AND DISCUSSION": "Given the surge in interest in generating synthetic tabulardata, the GAN framework has emerged as a seminal approach,attracting substantial research attention. Consequently, thispaper delves deeply into evaluating current high-performingGAN models, leveraging recent advancements in this domain.A meticulous analysis of four leading models is presented inSection III, elucidating their methodologies and performancemetrics.",
  "service domain u0.048430": "data, making it less suitable for cybersecurity applications. Bydefinition, ROS does not generate novel data points; it is justrandom sampling. SMOTE and Cluster Centroid, by enhancingML utility, present better alternatives for applications whereboth statistical fidelity and predictive accuracy are critical.Both SMOTE and cluster centroids create novel data pointsby interpolation and average representation, respectively ,. GMMs performance highlights its strength in capturingfeature correlations and creating novel data points using the",
  "fundamental definition of samples from fitted distributions.Still, its lower utility score suggests it may not be ideal for allapplications ,": "2) AI Methods: Bayesian Networks struggle with largerdatasets, particularly with multi-class features, indicates aneed for better handling such data structures in AI mod-els. The potential reason for this struggle comes from theprobabilistic graphical model. This graph tries to representdependency between variables, and in the case of the CIC-IDS large dataset, it fails to create discretization because oflow representation learning (memory) , . Diffusionmodels require further refinement to improve their statisticalsimilarity and utility because they are, in general, designed for",
  "Accuracy = Machine Learning Utility on TRTR vs TSTR, TRTR = Train and Test on Real Data, TSTR = Train on Synthetic and Test on Real Data": "high-dimensional data with spatial relationships (e.g., images),making it challenging to capture the non-spatial, relationalstructure of tabular data . The success of TVAE andCTGAN emphasizes the growing importance of generativeAI models in synthetic data generation. However, their lackof inherent class imbalance solutions suggests that additionaltechniques may be required to address this issue comprehen-sively. TVAE and CTGAN excel in generating high-quality syn-thetic tabular data due to their specialized architectures andloss functions. TVAE uses a probabilistic latent space to modelcomplex dependencies, handling continuous and categoricalfeatures with different probability distributions . Its KLdivergence-based loss regularizes the model, ensuring diverseyet realistic data generation . CTGAN, on the other hand,uses a conditional generator to capture feature relationshipsand a specific loss function that optimizes for mode-specificnormalization, preserving the distributions of both majorityand minority categories . The combination of thesetailored architectures and well-designed loss functions enablesboth models to generate synthetic data that closely mirrorsthe statistical properties of the original dataset, making them",
  "highly effective for tabular data generation": "3) Prominent GANs: The superior performance of CTGANand Copula-GAN reinforces their suitability for generatingsynthetic tabular data that retains statistical integrity andpractical utility. CopulaGAN excels in generating synthetictabular data because it uses copulas to model the dependenciesbetween variables and their marginal distributions separately. This allows it to capture complex relationships betweenfeatures more accurately than standard GANs. By decouplingthe modeling of individual feature distributions from their jointdependency structure, CopulaGAN ensures that the syntheticdata maintains the statistical properties of the original dataset,making it highly effective for tabular data . CastGANsinnovative architecture of each generator and auxiliary learnerfor each variable shows promise, though its limitations withbinary features suggest areas for future improvement .The effectiveness of GANBLR++ demonstrates the value ofintegrating Bayesian principles into GAN frameworks, provid-ing a robust foundation for capturing complex probabilisticrelationships in the data for both numerical and categoricaldatasets .",
  ") Benchmarking the boundary of attack and normal": "traffic: This research applies generative AI techniquesto analyze the distinction between normal and abnormalnetwork traffic rigorously. Through this exploration,we aim to enhance our comprehension of thresholddynamics, significantly contributing to developing moreresilient IDS. 3) Fidelity vs Privacy: Enhancing the fidelity and utilityof synthetic data often poses privacy risks. Thus, it isimperative to identify an optimized balance between fi-delity and privacy, particularly concerning cybersecuritydatasets. This endeavor requires careful consideration",
  "to safeguard individual privacy while maintaining thedatas utility for cybersecurity purposes": "4) Data dynamic features: Develop and refine featureselection methods targeting data dynamic features innetwork flows. These techniques should adapt to evolv-ing network environments, identifying the most relevantfeatures for real-time IDS. 5) Adaptive IDS: Design IDS that dynamically adjusts tochanges in network traffic patterns. This would involvereal-time analysis and feature selection to detect newthreats emerging as the network evolves. 6) Loss functions: Conduct a comparative analysis ofvarious generative AI loss functions tailored to thestudys specific context. This will help identify whichloss functions are most effective in optimizing the ap-plications model performance, providing insights intotheir strengths and limitations in different scenarios. 7) Correlation vs. Dependency: To examine the deeperrelationships between variables by exploring logical andconditional dependencies, going beyond the surface-level insights provided by simple correlation measures.This will allow a more critical understanding of howvariables interact, particularly in complex datasets wherecorrelations may not fully capture the underlying depen-dencies.",
  "IX. CONCLUSION": "Our comparative study systematically explores the effec-tiveness of synthetic tabular data generation techniques withincybersecurity network traffic, covering both daily and ma-licious traffic scenarios. Through a detailed evaluation ofseveral synthetic data generation methods across two signif-icant datasets, we have revealed critical insights into theirperformances and the inherent trade-offs they entail. SMOTEand Cluster Centroids demonstrated substantial data simi-larity and class balance but suffer from the drawback ofproducing redundant, non-novel values. Conversely, CTGANand TVAE outperformed the other methods, although theydo not inherently ensure balanced class distribution. Cast-GAN emerges as a strong contender by maintaining internalfeature dependencies, offering a more balanced approach.The insights from this study provide essential guidance forselecting synthetic data generation techniques based on spe-cific cybersecurity requirements. This research significantly impacts the field by highlighting the strengths and limita-tions of each method, offering a clear framework for op-timizing synthetic data generation in cybersecurity applica-tions. The source code of this experiment is available at our Analysis.git.",
  "S. Bourou, A. El Saer, T.-H. Velivassaki, A. Voulkidis, and T. Zahari-adis, A review of tabular data synthesis using gans on an ids dataset,Information, vol. 12, no. 09, p. 375, 2021": "D. Ganji and C. Chakraborttii, Towards data generation to alleviateprivacy concerns for cybersecurity applications, in 2023 IEEE 47thAnnual Computers, Software, and Applications Conference (COMP-SAC), pp. 14471452, IEEE, 2023. A. Kotal, A. Piplai, S. S. L. Chukkapalli, and A. Joshi, Privetab:Secure and privacy-preserving sharing of tabular data, in Proceedingsof the 2022 ACM on International Workshop on Security and PrivacyAnalytics, pp. 3545, 2022.",
  "C. Yinka-Banjo and O.-A. Ugot, A review of generative adversarialnetworks and its application in cybersecurity, Artificial IntelligenceReview, vol. 53, pp. 17211736, 2020": "A. Dunmore, J. Jang-Jaccard, F. Sabrina, and J. Kwak, A comprehen-sive survey of generative adversarial networks (gans) in cybersecurityintrusion detection, IEEE Access, vol. 11, pp. 7607176094, 2023. R. Mohammad, F. Saeed, A. A. Almazroi, F. S. Alsubaei, and A. A.Almazroi, Enhancing intrusion detection systems using a deep learn-ing and data augmentation approach, Systems, vol. 12, no. 3, p. 79,2024. A. Kothare, S. Chaube, Y. Moharir, G. Bajodia, and S. Dongre,Syngen: synthetic data generation, in 2021 International Conferenceon Computational Intelligence and Computing Applications (ICCICA),pp. 14, IEEE, 2021. R. Mayer, M. Hittmeir, and A. Ekelhart, Privacy-preserving anomalydetection using synthetic data, in Data and Applications Security andPrivacy XXXIV: 34th Annual IFIP WG 11.3 Conference, DBSec 2020,Regensburg, Germany, June 2526, 2020, Proceedings 34, pp. 195207, Springer, 2020. K. El Emam, L. Mosquera, and J. Bass, Evaluating identity disclosurerisk in fully synthetic health data: model development and validation,Journal of medical Internet research, vol. 22, no. 11, p. e23139, 2020.",
  "V. Bindschaedler and R. Shokri, Synthesizing plausible privacy-preserving location traces, in 2016 IEEE Symposium on Security andPrivacy (SP), pp. 546563, IEEE, 2016": "N. Peppes, T. Alexakis, K. Demestichas, and E. Adamopoulou, Acomparison study of generative artificial network architectures formalicious cyber-attack data generation, Applied Sciences, vol. 13,no. 12, p. 7106, 2023. A. Ceccarelli and T. Zoppi, Intrusion detection without attack knowl-edge: generating out-of-distribution tabular data, in 2023 IEEE 34thInternational Symposium on Software Reliability Engineering (ISSRE),pp. 125136, IEEE, 2023.",
  "N. Peppes, T. Alexakis, E. Adamopoulou, and K. Demestichas, Theeffectiveness of zero-day attacks data samples generated via gans ondeep learning classifiers, Sensors, vol. 23, no. 2, p. 900, 2023": "A. Hu, R. Xie, Z. Lu, A. Hu, and M. Xue, Tablegan-mca: Evaluatingmembership collisions of gan-synthesized tabular data releasing, inProceedings of the 2021 ACM SIGSAC Conference on Computer andCommunications Security, pp. 20962112, 2021. E. Lomurno, A. Archetti, L. Cazzella, S. Samele, L. Di Perna, andM. Matteucci, Sgde: Secure generative data exchange for cross-silo federated learning, in Proceedings of the 2022 5th InternationalConference on Artificial Intelligence and Pattern Recognition, pp. 205214, 2022. Z. Zhao, R. Birke, and L. Y. Chen, Fct-gan: Enhancing global corre-lation of table synthesis via fourier transform, in Proceedings of the32nd ACM International Conference on Information and KnowledgeManagement, pp. 44504454, 2023. A. J. Rodriguez-Almeida, H. Fabelo, S. Ortega, A. Deniz, F. J. Balea-Fernandez, E. Quevedo, C. Soguero-Ruiz, A. M. Wagner, and G. M.Callico, Synthetic patient data generation and evaluation in diseaseprediction using small and imbalanced datasets, IEEE Journal ofBiomedical and Health Informatics, 2022. R. Rai and S. Sural, Tool/dataset paper: Realistic abac data generationusing conditional tabular gan, in Proceedings of the Thirteenth ACMConference on Data and Application Security and Privacy, pp. 273278, 2023.",
  "L. Lusa et al., Evaluation of smote for high-dimensional class-imbalanced microarray data, in 2012 11th international conferenceon machine learning and applications, vol. 2, pp. 8994, IEEE, 2012": "J. Sun, J. Lang, H. Fujita, and H. Li, Imbalanced enterprise creditevaluation with dte-sbd: Decision tree ensemble based on smote andbagging with differentiated sampling rates, Information Sciences,vol. 425, pp. 7691, 2018. J. Sun, H. Li, H. Fujita, B. Fu, and W. Ai, Class-imbalanced dynamicfinancial distress prediction based on adaboost-svm ensemble combinedwith smote and time weighting, Information Fusion, vol. 54, pp. 128144, 2020. H. He, Y. Bai, E. A. Garcia, and S. Li, Adasyn: Adaptive syntheticsampling approach for imbalanced learning, in 2008 IEEE interna-tional joint conference on neural networks (IEEE world congress oncomputational intelligence), pp. 13221328, Ieee, 2008. A. S. Hussein, T. Li, D. M. Abd Ali, K. Bashir, and C. W. Yohannese,A modified adaptive synthetic sampling method for learning imbal-anced datasets, in Developments of Artificial Intelligence Technologiesin Computation and Robotics: Proceedings of the 14th InternationalFLINS Conference (FLINS 2020), pp. 7683, World Scientific, 2020. A. S. A. AL-Ghamdi, M. Ragab, M. F. S. Sabir, A. Elhassanein,and A. A. Gouda, Optimized artificial neural network techniquesto improve cybersecurity of higher education institution., Computers,Materials & Continua, vol. 72, no. 2, 2022.",
  "J. C. Rodriguez, Measuring financial contagion: A copula approach,Journal of empirical finance, vol. 14, no. 3, pp. 401423, 2007": "A. H. Z. Nik, M. A. Riegler, P. Halvorsen, and A. M. Storas,Generation of synthetic tabular healthcare data using generative adver-sarial networks, in International Conference on Multimedia Modeling,pp. 434446, Springer, 2023. Y. Zhang, N. Zaidi, J. Zhou, and G. Li, Ganblr++: incorporatingcapacity to generate numeric attributes and leveraging unrestrictedbayesian networks, in Proceedings of the 2022 SIAM InternationalConference on Data Mining (SDM), pp. 298306, SIAM, 2022. N. Bouguila and D. Ziou, High-dimensional unsupervised selectionand estimation of a finite generalized dirichlet mixture model based onminimum message length, IEEE transactions on pattern analysis andmachine intelligence, vol. 29, no. 10, pp. 17161731, 2007.",
  "D. Stiawan, M. Y. B. Idris, A. M. Bamhdi, R. Budiarto, et al., Cicids-2017 dataset feature analysis with information gain for anomalydetection, IEEE Access, vol. 8, pp. 132911132921, 2020": "R. Mahto, S. U. Ahmed, R. u. Rahman, R. M. Aziz, P. Roy, S. Mallik,A. Li, and M. A. Shah, A novel and innovative cancer classificationframework through a consecutive utilization of hybrid feature selec-tion, BMC bioinformatics, vol. 24, no. 1, p. 479, 2023. X. Zhang, X.-M. Zhao, K. He, L. Lu, Y. Cao, J. Liu, J.-K. Hao, Z.-P. Liu, and L. Chen, Inferring gene regulatory networks from geneexpression data by path consistency algorithm based on conditionalmutual information, Bioinformatics, vol. 28, no. 1, pp. 98104, 2012.",
  "A. Kiran and S. S. Kumar, A methodology and an empirical analysisto determine the most suitable synthetic data generator, IEEE Access,2024": "J. Xu, L. Wei, W. Wu, A. Wang, Y. Zhang, and F. Zhou, Privacy-preserving data integrity verification by using lightweight streamingauthenticated data structures for healthcare cyberphysical system,Future Generation Computer Systems, vol. 108, pp. 12871296, 2020. A. F. Karr, C. N. Kohnen, A. Oganian, J. P. Reiter, and A. P. Sanil,A framework for evaluating the utility of data altered to protectconfidentiality, The American Statistician, vol. 60, no. 3, pp. 224232, 2006. M. Pereira, M. Kshirsagar, S. Mukherjee, R. Dodhia, J. Lavista Ferres,and R. de Sousa, Assessment of differentially private synthetic datafor utility and fairness in end-to-end machine learning pipelines fortabular data, Plos one, vol. 19, no. 2, p. e0297271, 2024. J. Snoke, G. M. Raab, B. Nowok, C. Dibben, and A. Slavkovic,General and specific utility measures for synthetic data, Journal ofthe Royal Statistical Society Series A: Statistics in Society, vol. 181,no. 3, pp. 663688, 2018. P. Tholke, Y.-J. Mantilla-Ramos, H. Abdelhedi, C. Maschke, A. De-hgan, Y. Harel, A. Kemtur, L. M. Berrada, M. Sahraoui, T. Young,et al., Class imbalance should not throw you off balance: Choosingthe right classifiers and performance metrics for brain decoding withimbalanced data, NeuroImage, vol. 277, p. 120253, 2023.",
  "E. R. Fernandes and A. C. de Carvalho, Evolutionary inversion of classdistribution in overlapping areas for multi-class imbalanced learning,Information Sciences, vol. 494, pp. 141154, 2019": "T. Lee, K. B. Lee, and C. O. Kim, Performance of machine learningalgorithms for class-imbalanced process fault detection problems,IEEE Transactions on Semiconductor Manufacturing, vol. 29, no. 4,pp. 436445, 2016. M. Tavallaee, E. Bagheri, W. Lu, and A. A. Ghorbani, A detailedanalysis of the kdd cup 99 data set, in 2009 IEEE symposium oncomputational intelligence for security and defense applications, pp. 16, Ieee, 2009.",
  "Q. Zhu, J. Su, W. Bi, X. Liu, X. Ma, X. Li, and D. Wu, A batchnormalized inference network keeps the kl vanishing away, arXivpreprint arXiv:2004.12585, 2020": "B. A. Alabsi, M. Anbar, and S. D. A. Rihan, Conditional tabulargenerative adversarial based intrusion detection system for detectingddos and dos attacks on the internet of things networks, Sensors,vol. 23, no. 12, p. 5644, 2023. M. Hernadez, G. Epelde, A. Alberdi, R. Cilla, and D. Rankin, Syn-thetic tabular data evaluation in the health domain covering resem-blance, utility, and privacy dimensions, Methods of information inmedicine, vol. 62, no. S 01, pp. e19e38, 2023."
}