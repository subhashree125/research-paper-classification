{
  "ABSTRACT": "Recently, personalized federated learning (pFL) has attracted in-creasing attention in privacy protection, collaborative learning,and tackling statistical heterogeneity among clients, e.g., hospitals,mobile smartphones, etc. Most existing pFL methods focus on ex-ploiting the global information and personalized information inthe client-level model parameters while neglecting that data is thesource of these two kinds of information. To address this, we pro-pose the Federated Conditional Policy (FedCP) method, whichgenerates a conditional policy for each sample to separate the globalinformation and personalized information in its features and thenprocesses them by a global head and a personalized head, respec-tively. FedCP is more fine-grained to consider personalization in asample-specific manner than existing pFL methods. Extensive exper-iments in computer vision and natural language processing domainsshow that FedCP outperforms eleven state-of-the-art methods by upto 6.69%. Furthermore, FedCP maintains its superiority when someclients accidentally drop out, which frequently happens in mobilesettings. Our code is public at",
  "Federated Learning; Statistical Heterogeneity; Personalization; Con-ditional Computing; Feature Separation": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 23, August 610, 2023, Long Beach, CA, USA 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0103-0/23/08...$15.00 ACM Reference Format:Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, RuhuiMa, and Haibing Guan. 2023. FedCP: Separating Feature Information forPersonalized Federated Learning via Conditional Policy. In Proceedings ofthe 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining(KDD 23), August 610, 2023, Long Beach, CA, USA. ACM, New York, NY,USA, 13 pages.",
  "INTRODUCTION": "Nowadays, many web-based services, such as personalized recom-mendations , benefit from artificial intelligence (AI) andthe huge volume of data generated locally on various clients ,e.g., hospitals, mobile smartphones, internet of things, etc. At thesame time, legislation endeavors on data privacy protection con-tinue to increase, e.g., General Data Protection Regulation (GDPR)of Europe and California Consumer Privacy Act (CCPA) .Due to privacy concerns and regulations, centralized AI faces sig-nificant challenges . On the other hand, because of the datasparsity problem, it is hard to learn a reasonable model for a giventask independently on each client .Federated learning (FL) is proposed as a collaborative learningparadigm to utilize local data on the participatingclients for the global model training without sharing the privatedata of clients. As one of the famous FL methods, FedAvg conductsfour steps in each communication iteration: (1) The server sendsthe old global model parameters to the selected clients. (2) Eachselected client initializes the local model with the received globalparameters and trains the local model on local data. (3) The selectedclients upload the updated local model parameters to the server. (4)The server generates new global model parameters by aggregatingthe received client model parameters. However, in practice, thedata on the client is typically not independent and identically dis-tributed (non-IID) as well as unbalanced . With thisstatistical heterogeneity challenge , the single global modelin traditional FL methods, such as FedAvg, can hardly fit the localdata well on each client and achieve good performance .",
  "KDD 23, August 610, 2023, Long Beach, CA, USAJianqing Zhang et al": "To meet the personalized demand of each client and address thechallenge of statistical heterogeneity in FL, personalized federatedlearning (pFL) comes along that focuses on learning personalizedmodels rather than a single global model . Most existingpFL methods consider the global model as a container that storesthe global information and enriches the personalized models withthe parameters in the global model. However, they only focus onclient-level model parameters, i.e., the global/personalized model toexploit the global/personalized information. Specifically, the meta-learning-based methods (such as Per-FedAvg ) only fine-tuneglobal model parameters to fit local data, and the regularization-based methods (such as pFedMe , FedAMP , and Ditto )only regularize model parameters during local training. Althoughpersonalized-head-based methods (such as FedPer, FedRep ,and FedRoD ) explicitly split a backbone into a global part (fea-ture extractor) and a personalized part (head), they still focus onexploiting global and personalized information in model parame-ters rather than the source of information: data. As the model istrained on data, the global/personalized information in modelparameters is derived from client data. In other words, theheterogeneous data on clients contains both global and personal-ized information. As shown in , widely-used colors, e.g.,blue, and rarely-used colors, e.g., purple and pink, contain globalinformation and personalized information in images, respectively.",
  ": An example for FedCP. /: extracted feature vector,CPN /: Conditional Policy Network, : frozen globalhead, / : personalized head. Best viewed in color": "To exploit the global and personalized information in the dataseparately, we propose a Federated Conditional Policy (FedCP)method based on conditional computing techniques . Sincethe dimension of raw input data is much larger than the feature vec-tor extracted by the feature extractor, we focus on the feature vectorfor efficiency. As the proportion of the global and personalized infor-mation in the features differ among samples and clients, we proposean auxiliary Conditional Policy Network (CPN) to generate thesample-specific policy for feature information separation. Then,we process the global feature information and personalized featureinformation by a global head and a personalized head in differentroutes, respectively, as shown in . We store the personal-ized information in the personalized head and reserve the globalinformation by freezing the global head without locally training it.Through end-to-end learning, CPN automatically learns to generatethe sample-specific policy. We visualize six cases in .1 toshow the effectiveness of the feature information separation ability.To evaluate FedCP, we conduct extensive experiments on variousdatasets in two widely-used scenarios , i.e., the pathological",
  "settings and the practical settings. FedCP outperforms eleven state-of-the-art (SOTA) methods in both scenarios, and we analyze thereasons in .1. In summary, our key contributions are:": "To the best of our knowledge, we are the first to considerpersonalization on the sample-specific feature information inFL. It is more fine-grained than using the client-level modelparameters in most existing FL methods. We propose a novel FedCP that generates a sample-specificpolicy to separate the global information and personalizedinformation in features on each client. It processes these twokinds of feature information through a frozen global headand a personalized head on each client, respectively. We conduct extensive experiments in computer vision (CV)and natural language processing (NLP) domains to show theeffectiveness of FedCP. Besides, FedCP keeps its superiorperformance even when some clients accidentally drop out.",
  "RELATED WORK2.1Personalized Federated Learning": "To collaboratively learn models among clients on their local privatedata while protecting privacy, traditional FL methods, such as Fe-dAvg and FedProx , come along. Based on FedAvg, FedProximproves the stability of the FL process through a regularizationterm. However, in practice, statistical heterogeneity widely existsin the FL setting, so it is hard to learn a single global model that fitswell with the local data in each client .Recently, pFL has attracted increasing attention for its abilityto tackle statistical heterogeneity in FL . Among meta-learning-based methods, Per-FedAvg learns an initial sharedmodel as the global model that satisfies the learning trend foreach client. Among regularization-based methods, pFedMe learns an additional personalized model locally for each client withMoreau envelopes. In addition to learning only one global model forall clients, FedAMP generates one server model for one clientthrough the attention-inducing function to find similar clients. InDitto , each client learns its personalized model locally with aproximal term to fetch global information from global model pa-rameters. Among personalized-head-based methods, FedPerand FedRep learn a global feature extractor and a client-specifichead. The former locally trains the head with the feature extractor,while the latter locally fine-tunes the head until convergence beforetraining the feature extractor in each iteration. To bridge traditionalFL and pFL, FedRoD explicitly learns two prediction tasks witha global feature extractor and two heads. It uses the balanced soft-max (BSM) loss for the global prediction task and processesthe personalized task by the personalized head. Among other pFLmethods, FedFomo calculates the client-specific weights foraggregation on each client using the personalized models fromother clients. FedPHP locally aggregates the global model andthe old personalized model using a moving average to keep the his-torical personalized information. It also transfers the informationin the global feature extractor through the widely-used maximummean discrepancy (MMD) loss . These above pFL methodsonly focus on exploiting global and personalized information ofmodel parameters but do not dig deep into data.",
  "(b) Upload and download streams in FedCP": ": (a) The conditional policy separates information from into and in the red rhomboid. Except for thefeature vectors and vector , a standard rectangle and a rounded rectangle represent a layer and a module, respectively. Therounded rectangle with the dashed border is in Eq. (6). (gray border) is not a part of the personalized model, wheredata only flows forward during training. Data flows in all the lines during training, but it only flows in the solid lines duringinference. (b) For clarity, we separately show the upload and download streams for the feature extractors, the heads, and theCPNs. Still, we upload or download them as a union between the server and each client in practice. Best viewed in color.",
  "Conditional Computing": "Conditional computing is a technique that introduces dynamic char-acteristics into models according to task-dependent conditionalinputs . Formally, given a conditional input (e.g., im-age/text, model parameter vector, or other auxiliary information)and an auxiliary module (;), a signal can be generated by = (;) and used to interfere with models, such as dynamicrouting and feature adaptation.To activate specific parts in a model and process the data indifferent routes for each input sample, many approaches generatesample-specific policies for route selection. Conditioned on theinput image, ConvNet-AIG can decide which layers are neededduring inference using Gumbel Softmax . With a policy network,SpotTune makes decisions for each image to select whichblocks in a pre-trained residual network to fine-tune.Instead of focusing on dynamic model topology, some methodspropose adapting the learned features. In the few-shot learning field,TADAM adapts the features through an affine transformationconditioned by the extracted task representation. In the video objectdetection field, TMA proposes a learnable affine transformationconditioned by video frames for feature adaptation.The above methods use conditional computing techniques butare designed for centralized AI scenarios and specific tasks. Com-bining the ideas of dynamic routing and feature adaptation, wedevise the CPN module in our FedCP to separate global feature in-formation and personalized feature information then process themin different routes for pFL scenarios and various tasks.",
  "In statistically heterogeneous pFL settings, non-IID and unbal-anced data exist on clients, who train their personalized mod-els 1, . . . , in a collaborative manner. clients own private": "datasets D1, . . . , D , respectively, which are sampled from dis-tinct distributions without overlapping.Similar to FedPer, FedRep , and FedRoD , we split thebackbone into a feature extractor : R R, that maps inputsamples to feature space and a head : R R, which mapsfrom low-dimensional feature space to a label space. FollowingFedRep, we consider the last fully connected (FC) layer in eachgiven backbone as the head. , , and are the dimension ofthe input space, feature space, and label space, respectively. isdetermined by the given backbone and typically .Different from FedPer, FedRep and FedRoD, on client , we havea global feature extractor (parameterized by ), a global head(parameterized by ), a personalized feature extractor (parame-terized by ), a personalized head (parameterized by ), anda CPN (parameterized by ). Specifically, for the feature extrac-tors, we initialize by overwriting it with corresponding globalparameters in each iteration, and then locally learn the per-sonalized feature extractor. The feature generated by the changingpersonalized feature extractor may not fit the frozen global headduring local learning. Thus, we freeze the global feature extractorafter receiving and align the features outputted by the personalizedfeature extractor to the ones generated by the global feature extrac-tor through the MMD loss, as shown in (a). For the globalhead, we freeze it after it has been initialized by to preserveglobal information. In short, at the start of each iteration, we over-write by new then freeze and . As shown by thenon-transparent module in (a), the personalized model usedfor inference (parameterized by ) consists of the personalizedfeature extractor, the global head, the personalized head, and theCPN, i.e., := { ,,, }. The frozen global featureextractor is only used for local learning and is not part of the per-sonalized model. We omit iteration notation, sample index notation,and biases for simplicity. Given the local loss F (described later),",
  "= (; ), (,) D.(2)": "Due to statistical heterogeneity, R contains global and per-sonalized feature information. To separately exploit these two kindsof information, we propose FedCP that learns sample-specific sep-aration in an end-to-end manner, as shown in . 3.2.1Separating feature information. Guided by the global infor-mation in the frozen global head and the personalized informationin the personalized head, the CPN (the core of FedCP) can learnto generate the sample-specific policy and separate the global andpersonalized information in automatically.Specifically, we devise CPN as the concatenation of an FC layerand a layer-normalization layer followed by the ReLU activationfunction , as shown in (a). On client , we generate thesample-specific policy by",
  "{, } := CPN(C; ),(3)": "where R, R, + = 1, [], and C R is thesample-specific input for CPN. We describe the details of the inputC and the output {, } as follows.C is generated to achieve the sample-specific characteristic andintroduce personalized (client-specific) information. We can directlyobtain the sample-specific vector , so we only introduce howto obtain the client-specific information here. Based on FedRepand FedRoD, the parameters in the personalized head, i.e., ,naturally contain client-specific information. However, is amatrix, not a vector. Thus, we generate by reducing the dimensionof. Recall that a head is an FC layer in FedCP, i.e., R,so the th column of corresponds to th feature in . Weobtain := =1 , where is the th row in and R.In this way, we obtain a client-specific vector with the same shapeand feature-wise semantics as . Then we combine sample-specific and the client-specific via C := (/|| ||2) , where || ||2is the 2-norm of and is the Hadamard product. We obtain before local learning in each iteration and regard it as a constantduring training. During inference, we reuse the latest .We separate information by multiplying the policy {, } and to obtain the global feature information and personalized fea-ture information . There are connections among features ,so we output {, } with real numbers instead of Boolean values,i.e., (0, 1) and (0, 1). Inspired by the Gumbel-Max trickfor policy generating , we generate the policy with the help ofthe intermediates and a softmax operation through the follow-ing two steps. Firstly, CPN generates the intermediates R2,where = {,1,,2}, [], ,1 and ,2 are scalars without",
  "Privacy Analysis": "According to (b) and Algorithm 1, our proposed FedCPshares the parameters of one feature extractor, one head, and oneCPN. As for the head part, we upload on each client afteraggregating and by Eq. (6). This process can be viewedas adding noise (global parameters ) to , thus protectingprivacy during the uploading and downloading. Besides, the sample-specific characteristic further improves the privacy-preserving abil-ity of FedCP. On the one hand, since C is dynamically generatedwithout sharing with the server, it is hard to recover the sample-specific policy with the CPN or through model inversion attacks .On the other hand, without the sample-specific policy, the connec-tion between the feature extractor and the head is broken, increas-ing the difficulty of attacks based on shared model parameters. Weevaluate the privacy-preserving ability of FedCP in Appendix B.",
  "EXPERIMENTAL SETUP": "We evaluate FedCP on various image/text classification tasks. Forthe image classification tasks, we use four famous datasets, includ-ing MNIST , Cifar10 , Cifar100 and Tiny-ImageNet (100K images with 200 classes) using a famous 4-layer CNN . To evaluate FedCP on a larger backbone model than the4-layer CNN, we also use ResNet-18 on Tiny-ImageNet. Weset the local learning rate = 0.005 for the 4-layer CNN and =0.1 for ResNet-18. For the text classification tasks, we use the AGNews dataset with the fastText and set = 0.1 for fastTextwith other settings being the same as image classification tasks.We simulate the heterogeneous settings in two widely-usedscenarios, i.e., the pathological setting and practical set-ting . For the pathological setting, we sample 2/2/10 classes on MNIST/Cifar10/Cifar100 from a total of 10/10/100 classes foreach client with disjoint data. Specifically, similar to FedAvg ,we separate clients into groups that own unbalanced data with thesame labels. Following MOON , we create the practical settingthrough the Dirichlet distribution, denoted as (). Specifically,we sample , () and allocate a , proportion of the sam-ples of class to client . We set = 0.1 for the default practicalsetting . Then, we split the data on each client into a trainingdataset (75%) and a test dataset (25%).Following FedAvg, we set the local batch size to 10 and thenumber of local learning epochs to 1. We run all tasks up to 2000iterations until all methods converge empirically. Based on pFedMe,FedFomo, and FedRoD, we set the total number of clients to 20and the client joining ratio = 1 by default. Following pFedMe,we report the test accuracy of the best global model for traditionalFL methods and the average test accuracy of the best personalizedmodels for pFL methods. We run all the experiments five timesand report the mean and standard deviation. Besides, we run allexperiments on a machine with two Intel Xeon Gold 6140 CPUs(36 cores), 128G memory, eight NVIDIA 2080 Ti GPUs, and CentOS7.8. For more results and details, please refer to the Appendix.",
  "Samples": "Generic_head Case 0 Personalized_head Case 1 Case 2 Case 3 Case 4 Case 5 : The first row shows six samples from Tiny-ImageNet. The second and third rows respectively show theGrad-CAM visualizations of the learned personalized modelwith only the global head or the personalized head activated.Highlighted areas are the parts the model pays attention to.",
  "ABLATION STUDY5.1Feature Information Visualization": "To visualize the separated global and personalized feature infor-mation when using ResNet-18, we adopt the Grad-CAM onthe learned personalized model when only the global head or thepersonalized head is activated. Six cases from Tiny-ImageNet areshown in .According to , with only the global head activated, thepersonalized model focuses on relatively global information, suchas trees (Case 0 and Case 4), grasses (Case 1), or sky (Case 2 andCase 5) in the background. When we only activate the personalizedhead, the personalized model focuses on the relatively personalizedinformation, such as foreground (Case 2 and Case 5) or objects(Case 0, Case 1, and Case 4). As for Case 3, the rarely-used pinkcolor is more personalized than the widely-used blue color.",
  "Effectiveness of CPN input": "To show the effectiveness of each part of the CPN input, we removethem one by one and obtain the variants: without client-specificvector (w.o. cs), without sample-specific vector (w.o. ss), withoutclient-specific and sample-specific vector (w.o. cs & ss). For w.o. cs& ss, we regard the randomly initialized frozen vector as the CPNinput, which has the same shape as the sample-specific vector.In , removing either the client-specific vector or thesample-specific vector causes an accuracy decrease. However, w.o.cs performs better than w.o. ss, so the sample-specific vector is moresignificant than the client-specific one. According to and, removing these two kinds of information and using therandom vector, w.o. cs & ss still achieves higher accuracy than allthe baselines because CPN module can still learn to separate featureinformation through the end-to-end training.",
  "Effectiveness of FedCP modules": "To show the effectiveness of each module in FedCP, we removethem one by one and obtain the variants: without the frozen globalfeature extractor and the MMD loss (without GFM for short, i.e.,w.o. GFM), without CPN (w.o. CPN), without CPN and GFM (w.o.CPN & GFM), without CPN and the frozen global head (w.o. CPN &GH), without CPN, GFM, and the frozen global head (w.o. CPN &GFM & GH, similar to FedPer), as shown in . It is invalid tokeep CPN while removing the frozen global head since they are aunion for our feature separating goal.In , without the GFM to align the features, the accuracyof w.o. GFM decreases by 1.31% compared to FedCP, but it still out-performs other baselines (see ). Without CPN, the accuracyof w.o. CPN decreases by 3.01%, so CPN is more critical than theGFM when the frozen global head exists. Removing both the CPNand the GFM (w.o. CPN & GFM) degenerates further than removingone of them, which means that these two modules can facilitateeach other. The CPN and the frozen global head are the key mod-ules in FedCP. Without them, the performance of w.o. CPN & GHdegenerates significantly, with a 8.74% drop compared to FedCP.Furthermore, w.o. CPN & GFM & GH (removing all the modules)performs better than w.o. CPN & GH. It means simply adding theGFM to w.o. CPN & GFM & GH causes performance degeneration.",
  "EVALUATION AND ANALYSIS6.1Main Experiments": "Due to the limited space, we use the TINY and TINY* to repre-sent using the 4-layer CNN on Tiny-ImageNet and using ResNet-18on Tiny-ImageNet, respectively. shows that FedCP out-performs all the baselines when using either the 4-layer CNN orthe ResNet-18, especially on relatively challenging tasks. In the de-fault practical setting on Cifar100, FedCP exceeds the best baseline(Ditto) by 6.69%. Our CPN only introduces an additional 0.527M(million) parameters on each client, which is 9.25% and 4.67% ofthe parameters in the 4-layer CNN (5.695M) and the ResNet-18(11.279M), respectively. In the following, we analyze why FedCPoutperforms all the baselines.In , FedAvg and FedProx perform poorly, as the globalmodel cannot fit the local data well on all the clients. They directlyfeed features to the global head, regardless of the personalizedinformation in the features. In contrast, FedCP separates and feedsthe global information and the personalized information in thefeatures to the global head and the personalized head, respectively.Per-FedAvg performs poorly among pFL methods, as the aggre-gated learning trend can hardly meet the trend of each personalizedmodel. In contrast, FedCP considers personalization in a sample-specific manner conditioned by the client-specific vector, whichmeets the demand of each client, thus performing better.pFedMe and FedAMP utilize regularization terms to extract in-formation from the local model and the client-specific server model,respectively. However, excessively concentrating on personaliza-tion is not beneficial to the collaborative goal of FL. Since Dittoextracts global information from the global model, it performs betterthan pFedMe and FedAMP. Like Ditto, FedCP also takes advantageof global information for each client.FedPer and FedRep only share the feature extractor withoutsharing heads. They ignore some global information in the headpart, so they perform worse than FedCP. FedRoD bridges the goalof traditional FL and pFL by learning two heads with two objectives.However, these two goals are competing , so FedRoD performsworse than FedRep, which also learns a personalized head but onlyfocuses on the goal of pFL. Like FedRep, FedCP only focuses on thepFL goal, thus performing the best.",
  "Computing and Communication Overhead": "Here, we focus on the training phase. We report the total time andthe number of iterations required for each method to convergeand calculate the average time consumption in each iteration, asshown in . Ditto and pFedMe cost more time in each iter-ation than most methods since the additional personalized modeltraining takes much extra time. Compared to most baselines, e.g.,Per-FedAvg, pFedMe, Ditto, FedRep, and FedPHP, FedCP costs lesstraining time in each iteration. In FedCP, the parameters in the CPNmodule only require an additional 4.67% communication overheadper iteration when using ResNet-18 compared to FedAvg.",
  "Different Heterogeneity Degrees": "In addition to , we conduct experiments on the settings withdifferent degrees of heterogeneity on Tiny-ImageNet and AG Newsby varying . The smaller the is, the more heterogeneous thesetting is. We show the accuracy in , where FedCP still out-performs the baselines. Most pFL methods achieve higher accuracythan traditional FL methods in the more heterogeneous setting. Inthe setting with a larger , most of them cannot achieve higheraccuracy than FedAvg on Tiny-ImageNet. In contrast, the meth-ods that utilize global information during local learning (FedPHP,FedRoD, and FedCP) maintain excellent performance. FedRoD per-forms worse than FedRep, as the latter focuses only on the goalof pFL. pFedMe and FedAMP perform poorly among pFL methods.Their accuracy is lower than traditional FL methods when = 1.",
  "Scalability with Different Client Amounts": "Following MOON , we conduct another six experiments (i.e., = 10, = 30, = 50, = 100, = 200, and = 500) to studythe scalability of FedCP and keep other settings unchanged. Per-FedAvg requires more data than other methods, as meta-learningrequires at least two batches of data, which is invalid on someclients in our unbalanced settings when 200. Since the totaldata amount is constant on Cifar100, the local data amount (onaverage) decreases as the client amount increases. With both and local data amount changing, it is unreasonable to compare theresults among different in . Some pFL methods, includingPer-FedAvg and pFedMe, achieve relatively poor performance in thesetting with = 10, where few clients (e.g., hospitals) participate inFL, and each of them possesses a large data repository. When =500 (e.g., mobile smartphones), each client only has 90 samples fortraining on average, which is not enough for the weight calculationin FedFomo, so it performs worse than FedAvg. FedAMP diverges asit is hard to find similar clients when they have little data. Accordingto , FedCP still outperforms all the baselines.To simulate a real-world scenario where more clients meansmore total data amount in FL, we consider the setting Cifar100( = 0.1, = 1, and = 50) used above as the base setting and",
  "FedCP50.930.3454.310.2555.430.21": "randomly sample 10 and 30 clients from existing 50 clients to formthe Cifar100 ( = 0.1, = 1, and = 10|50) and Cifar100 ( = 0.1, =1, and = 30|50) settings, respectively. When we increase the clientamount, the accuracy increases as more data are utilized to trainthe globally shared modules, which facilitates information transferamong clients. The superior performance of FedCP in showsits scalability in this real-world scenario.",
  "Large Local Epochs": "Large local epochs can reduce total communication iterations butincrease computing overhead per iteration for most of the methodsin FL . With larger local epochs, FedCP can still maintain itssuperiority as shown in . Most of the methods performworse with larger local epochs since more local training aggravatesthe discrepancy among client models, which is adverse to serveraggregation. For example, the accuracy of FedRoD drops by 2.16%when the number of local epochs increases from 5 to 40.",
  "FedCP: Separating Feature Information for Personalized Federated Learning via Conditional PolicyKDD 23, August 610, 2023, Long Beach, CA, USA": "Honglei Zhang, Fangyuan Luo, Jun Wu, Xiangnan He, and Yidong Li. 2023.LightFR: Lightweight federated recommendation with privacy-preserving matrixfactorization. ACM Transactions on Information Systems (2023), 128. Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, andHaibing Guan. 2023. FedALA: Adaptive Local Aggregation for PersonalizedFederated Learning. In AAAI Conference on Artificial Intelligence (AAAI).",
  "= 0.0156.560.3556.710.3256.310.3954.480.109.730.02 = 0.141.670.1742.750.0343.490.0442.830.078.140.06 = 0.524.950.1526.550.2327.660.1626.950.274.540.04": "From , the accuracy first increases and then decreases as increases, which is similar among three settings with differentdegrees of heterogeneity. By assigning a proper value to , thepersonalized feature extractor can learn the information from thelocal data while guiding the output features to fit the frozen globalhead. When the value of is overlarge (e.g., = 50), the personalizedfeature extractor can hardly learn from the local data. Instead, ittends to output similarly to the frozen global feature extractor. Topay more attention to the local data in a more heterogeneous setting(e.g., = 0.01), FedCP requires a relatively smaller , as the globalinformation plays a less critical role in this situation.",
  "POLICY STUDY": "We show the policy change for the training samples and the gener-ated policies for all the test samples during inference in .For clarity, we collect all the sample-specific on each client andaverage them to obtain . Then we further average the elementsin to generate one scalar, which is called personalization identi-fication ratio (PIR): PIR := 1",
  "(b) distribution of test samples on all clients": ": Visualizations for PIR and distribution on Tiny-ImageNet in the default practical setting. Blue color andorange color represent the figures for the 4-layer CNN andResNet-18, respectively. We draw PIR change curves for train-ing samples. Best viewed in color. When using diverse backbones with different feature extractionabilities, the policies vary in both PIR change and distribution.As shown in (a), on client #0, PIR increases from the initialvalue of 0.50 to around 0.58 in the first 20 iterations and remainsalmost unchanged using the 4-layer CNN. However, when usingResNet-18, PIR decreases first and then increases rapidly to around0.61, which means that the features extracted by the feature extrac-tor in ResNet-18 contain more global feature information in earlyiterations, and our CPN can automatically capture this dynamiccharacteristic during all FL iterations. In (b), the valuerange of varies among clients, as they contain diverse samples.For example, the range on client #10 is the largest among clients.Although the policies are different for the samples, the mean valuesof are similar among clients when using one specific backbone,as shown in (b). The values of are all larger than 0.5during inference, which means the learned features contain morepersonalized feature information than global feature informationon clients in these scenarios.",
  "CONCLUSION": "We propose a Federated Conditional Policy (FedCP) method thatgenerates a policy for each sample to separate its features into theglobal feature information and the personalized feature information,then processes them by the global head and the personalized head,respectively. FedCP outperforms eleven SOTA methods by up to6.69% under various settings with excellent privacy-preservingability. Besides, FedCP also maintains excellent performance whensome clients accidentally drop out. This work was supported in part by the Shanghai Key Labora-tory of Scalable Computing and Systems, National Key R&D Pro-gram of China (2022YFB4402102), Internet of Things special sub-ject program, China Institute of IoT (Wuxi), Wuxi IoT InnovationPromotion Center (2022SP-T13-C), Industry-university-researchCooperation Funding Project from the Eighth Research Institutein China Aerospace Science and Technology Corporation (Shang-hai) (USCAST2022-17), and Intel Corporation (UFunding 12679).The work of H. Wang was supported in part by the NSF grantCRII-OAC-2153502. Ruhui Ma is the corresponding author.",
  "Lydia de la Torre. 2018. A guide to the california consumer privacy act of 2018.Available at SSRN 3275571 (2018)": "Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. 2020. Personalized Fed-erated Learning with Theoretical Guarantees: A Model-Agnostic Meta-LearningApproach. In International Conference on Advances in Neural Information Process-ing Systems (NeurIPS). Jonas Geiping, Hartmut Bauermeister, Hannah Drge, and Michael Moeller. 2020.Inverting gradients-how easy is it to break privacy in federated learning?. InInternational Conference on Advances in Neural Information Processing Systems(NeurIPS). Arthur Gretton, Karsten Borgwardt, Malte Rasch, Bernhard Schlkopf, and AlexSmola. 2006. A Kernel Method for the Two-Sample-Problem. In InternationalConference on Advances in Neural Information Processing Systems (NeurIPS). Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing, andRogerio Feris. 2019. Spottune: Transfer Learning through Adaptive Fine-Tuning.In IEEE Conference on Computer Vision and Pattern Recognition (CVPR).",
  "Eric Jang, Shixiang Gu, and Ben Poole. 2016. Categorical Reparameterizationwith Gumbel-Softmax. arXiv preprint arXiv:1611.01144 (2016)": "Armand Joulin, Edouard Grave, Piotr Bojanowski, and Tomas Mikolov. 2017. Bagof Tricks for Efficient Text Classification. In Conference of the European Chapterof the Association for Computational Linguistics (EACL). Peter Kairouz, H Brendan McMahan, Brendan Avent, Aurlien Bellet, MehdiBennis, Arjun Nitin Bhagoji, Kallista Bonawitz, Zachary Charles, Graham Cor-mode, Rachel Cummings, et al. 2019. Advances and Open Problems in FederatedLearning. arXiv preprint arXiv:1912.04977 (2019).",
  "Lanlan Liu and Jia Deng. 2018. Dynamic Deep Neural Networks: OptimizingAccuracy-Efficiency Trade-Offs by Selective Execution. In AAAI Conference onArtificial Intelligence (AAAI)": "Mi Luo, Fei Chen, Dapeng Hu, Yifan Zhang, Jian Liang, and Jiashi Feng. 2021. Nofear of heterogeneity: Classifier calibration for federated learning with non-iiddata. In International Conference on Advances in Neural Information ProcessingSystems (NeurIPS). Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, andBlaise Aguera y Arcas. 2017. Communication-Efficient Learning of Deep Net-works from Decentralized Data. In International Conference on Artificial Intelli-gence and Statistics (AISTATS). Kevin P Murphy. 2012. Machine learning: a probabilistic perspective. MIT press. Dinh C Nguyen, Ming Ding, Pubudu N Pathirana, Aruna Seneviratne, Jun Li, andH Vincent Poor. 2021. Federated learning for internet of things: A comprehensivesurvey. IEEE Communications Surveys & Tutorials 23, 3 (2021), 16221658. Boris Oreshkin, Pau Rodrguez Lpez, and Alexandre Lacoste. 2018. Tadam: TaskDependent Adaptive Metric for Improved Few-Shot Learning. In InternationalConference on Advances in Neural Information Processing Systems (NeurIPS).",
  "Protection Regulation. 2016. Regulation (EU) 2016/679 of the European Parliamentand of the Council. Regulation (eu) 679 (2016), 2016": "Jiawei Ren, Cunjun Yu, Xiao Ma, Haiyu Zhao, Shuai Yi, et al. 2020. BalancedMeta-softmax for Long-tailed Visual Recognition. International Conference onAdvances in Neural Information Processing Systems (NeurIPS). Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedan-tam, Devi Parikh, and Dhruv Batra. 2017. Grad-cam: Visual Explanations fromDeep Networks via Gradient-based Localization. In IEEE International Conferenceon Computer Vision (ICCV).",
  "{1, . . . , } = arg min G(F1, . . . , F ),(9)": "where F, [] is the local loss and G(F1, . . . , F ) = =1 F.During the training phase, the value of G is the training loss ofFedCP. To study the convergence of FedCP, we denote the losscalculated with the trained personalized models after local learningas and the loss calculated with the initialized personalizedmodels before local learning as . Except for the loss val-ues, we also evaluate the corresponding test accuracy, calculatedby averaging the accuracy of all the personalized models on thecorresponding local test datasets of clients.To empirically analyze the convergence of FedCP, we draw thetraining loss curves and test accuracy curves for our FedCP whenusing ResNet-18, as shown in . On Tiny-ImageNet in thedefault practical setting, becomes close to after 74iterations, and both of them reach the minimum value meanwhile.In other words, FedCP converges after training around 74 iterations.With the training loss decreasing, the test accuracy increases. Boththe loss curve and the accuracy curve fluctuate before iteration56 when using ResNet-18 due to the policy update, as shown in in the main body of this paper.",
  "Here, following a traditional FL method FedCG , we consider asemi-honest scenario where the server follows the FL protocol but": "may recover original data from a victim client with its model up-dates via Deep Leakage from Gradients (DLG) attack . Amongthe baselines in our paper, there are two categories in terms of in-formation transmission between the server and clients. Methods inCategory 1 share the parameters in the entire backbone model, suchas FedAvg, FedProx, Per-FedAvg, pFedMe, Ditto, FedRoD, FedFomo,and FedPHP. Methods in Category 2 only share the parameters inthe feature extractor, such as FedPer and FedRep. Without loss ofgenerality, we select the most famous methods in each category asthe representative baselines: FedAvg for Category 1 and FedPer forCategory 2. Also following FedCG, we provide the experimental re-sults in to evaluate the privacy-preserving ability of FedCPwith representative baselines in Peak Signal-to-Noise Ratio (PSNR).The lower value of PSNR shows better privacy-preserving ability.The results in show the superiority of FedCP.",
  "CCONDITIONAL POLICY NETWORK DESIGN": "By default, our CPN consists of a fully connected (FC) layer and a layer-normalization layer (LN for short) followed by theReLU activation function . Here, we investigate how differentdesigns affect the effectiveness of CPNs by varying the numberof FC layers, the normalization layer, and the activation function,as shown in . Since the intermediate outputs R2 have two groups, we set the number of groups to two for the group-normalization (GN for short). We only change the consideredcomponent based on FedCP. The accuracy results with an underlineare higher than the accuracy of FedCP.",
  "ResNet-1844.1844.5044.3644.1143.7043.2543.4944.69": "The results in show that we can further improve FedCPby using other architectures for the CPN. Adding more FC layersto process its input improves the test accuracy for ResNet-18 butcauses a slight decrease for the 4-layer CNN. The additional pa-rameters introduced for FedCP with 1 FC, 2 FC, 3 FC, and 4 FC are0.527M (million), 0.790M, 1.052M, and 1.315M, respectively. How-ever, the additional computing cost in each iteration introducedby additional FC layers is not worth the little accuracy increase.As for the normalization layer, replacing the LN with the batch-normalization (BN) improves 0.64% test accuracy for the 4-layerCNN. However, it decreases around 0.48% accuracy for ResNet-18,which also contains BN layers. Similar to LN that normalizes entire, GN respectively normalizes ,1 and ,2. However, the test ac-curacy for both the 4-layer CNN and ResNet-18 decreases with the"
}