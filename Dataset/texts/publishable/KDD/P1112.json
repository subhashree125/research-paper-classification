{
  "ABSTRACT": "Contemporary recommendation systems are designed to meetusers needs by delivering tailored lists of items that align withtheir specific demands or interests. In a multi-stage recommenda-tion system, reranking plays a crucial role by modeling the intra-listcorrelations among items. The key challenge of reranking lies in theexploration of optimal sequences within the combinatorial spaceof permutations. Recent research proposes a generator-evaluatorlearning paradigm, where the generator generates multiple feasiblesequences and the evaluator picks out the best sequence based onthe estimated listwise score. The generator is of vital importance,and generative models are well-suited for the generator function.Current generative models employ an autoregressive strategy forsequence generation. However, deploying autoregressive modelsin real-time industrial systems is challenging. Firstly, the generatorcan only generate the target items one by one and hence suffersfrom slow inference. Secondly, the discrepancy between trainingand inference brings an error accumulation. Lastly, the left-to-rightgeneration overlooks information from succeeding items, leadingto suboptimal performance.To address these issues, we propose a Non-AutoRegressive gen-erative model for reranking Recommendation (NAR4Rec) designedto enhance efficiency and effectiveness. To tackle challenges suchas sparse training samples and dynamic candidates, we introduce amatching model. Considering the diverse nature of user feedback,we employ a sequence-level unlikelihood training objective to dif-ferentiate feasible sequences from unfeasible ones. Additionally, toovercome the lack of dependency modeling in non-autoregressivemodels regarding target items, we introduce contrastive decod-ing to capture correlations among these items. Extensive offlineexperiments validate the superior performance of NAR4Rec overstate-of-the-art reranking methods. Online A/B tests reveal that",
  "Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain. 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "INTRODUCTION": "Recommendation systems offer users personalized item lists tai-lored to their interests. Various approaches have been proposed tocapture user interests, focusing on feature interactions,user preference modeling, and so on. However, most ex-isting methods treat individual items separately, neglecting theirmutual influence and leading to suboptimal results. Acknowledg-ing that user interactions with one item may correlate with othersin the recommendation list, reranking is introduced to con-sider contextual information and generate an optimal sequence ofrecommendation items.The main challenge in reranking is exploring optimal sequenceswithin the vast space of permutations. Reranking methods aretypically categorized into on-stage and two-stage approaches. One-stage methods take candidates as input, estimating refinedscores for each item within the permutation, and rerank them greed-ily based on these scores. However, one-stage methods encounteran inherent contradiction: the reranking operation inherentlyalters the permutation, introducing different mutual influences be-tween items compared to the initial arrangement. Consequently, therefined score conditioned on the initial permutation is consideredimplausible.To tackle this challenge, two-stage methods utilize a generator-evaluator framework. Here, the generator creates multiple feasible",
  "KDD 24, August 2529, 2024, Barcelona, Spain.Yuxin Ren et al": "target sequence. This makes them well-suited for the reranking task,particularly considering the vast space of possible permutations.While autoregressive models have proven effective, deployingthem in industrial recommendation systems is challenging. Firstly,their sequential decoding process leads to slow inference, intro-ducing latency that hinders real-time application. Secondly, thesemodels, trained to predict based on ground truth, face a discrepancyduring inference when they receive their own generated outputsas input. This misalignment may lead to compounded errors, asinaccuracies generated in earlier timesteps accumulate over time,resulting in inconsistent or divergent sequences that deviate fromthe true distribution of the target sequence. Thirdly, autoregressivemodels rely on a left-to-right causal attention mechanism, limitingthe expressive power of hidden representations, as each item en-codes information solely from preceding items. This constraintimpedes optimal representation learning, resulting in suboptimalperformance.",
  "RELATED WORK2.1Reranking in Recommendation Systems": "In contrast to earlier phases like matching and ranking, whichtypically learn a user-specific itemwise scoring function, the coreof reranking in recommendation systems lies in modeling correla-tions within the exposed list. Reranking, building uponcandidate items from the ranking stage, selects a subset and de-termines their order to ensure exposing the most suitable itemsto the users. Existing research on reranking can be systematicallyclassified into two principal categories: one-stage, andtwo-stage methods.One-stage methods treat reranking as a retrieval task, recom-mending the top k items based on scores from a ranking model.These methods refine the initial list distribution using list-wiseinformation, optimizing overall recommendation quality. Subse-quently, the candidates are reranked by the refined itemwise scorein a greedy manner. The distinction lies in the network architec-tures for capturing list-wise information, such as GRU in DLCM,and transformer in PRM. However, user feedback for the ex-posed list is influenced not just by item interest but also by ar-rangements and surrounding context. The rerankingoperation modifies permutations, thereby introducing influencesdistinct from the initial permutation. Moreover, one-stage meth-ods, which exclusively model the initial permutation, fall short ofcapturing alternative permutations. Consequently, those methodsstruggle to maximize overall user feedback.Two-stage methods embrace a generator-evaluatorframework. In this framework, the generator initiates the processby generating multiple feasible sequences, and subsequently, theevaluator selects the optimal sequence based on the estimated list-wise score. This framework allows for a comprehensive explorationof various feasible sequences, and an informed selection of themost optimal one based on listwise considerations. The role of thegenerator is particularly crucial for generating sequences. Com-mon approaches for generators can be categorized into heuristicmethods, such as beam search or item swapping,and generative models . Generative models are moresuitable than heuristic methods for reranking given the vast permu-tation space. These generative models typically adopt a step-greedystrategy which autoregressively decides the display results of eachposition. However, the high computational complexity of onlineinferences limits their application in real-time recommendationsystems.To address the challenges linked with autoregressive generationmodels, our work investigates the viability of non-autoregressivegenerative models within the generator-evaluator framework. Non-autoregressive generative models generate the target sequence onceto alleviate computational complexity.",
  "Non-autoregressive Generative Models for Reranking RecommendationKDD 24, August 2529, 2024, Barcelona, Spain": ": Comparison between autoregressive model (left) and non-autoregressive model (right). Auto-regressive modelsgenerate items sequentially while non-autoregressive models generate all items simultaneously. Then it has since gained increased attention in nature language pro-cessing, e.g. text summarization, text error correction.Specifically, efforts have been focused on tackling the absence of tar-get information in non-autoregressive models. Strategies include en-hancing the training corpus to mitigate target-side dependencies and refining training approaches to alleviate learningdifficulties.Although non-autoregressive generation has been explored intext, those conventional techniques are not directly applicable torecommendation systems. We tackle the challenges encounteredin recommendation systems to improve the convergence and per-formance of non-autoregressive models and make the first attemptto integrate non-autoregressive models into reranking within real-time recommender systems.",
  "PRELIMINARY3.1Reranking problem Formulation": "For each user within the set , a request encompasses a set of userprofile features(such as user ID, gender, age), the recent interactionhistory, and candidates items denoted as = {1,2, ,},where is the number of candidates. Given candidates , the goalof reranking is to propose an item sequence = {1,2, ,}that elicits the most favorable feedback for user , where is thesequence length and is the recommended list of the rerankingmodel. We denote the reranking models as F (,,) where thecorresponding parameter is . In real-time recommendation sys-tems, reranking acts as the last stage to deliver the ultimate list ofrecommended items. Typically, significantly exceeds , with being less than 10 and ranging from several tens to hundreds.In a multi-interaction scenario, users may exhibit distinct typesof interaction (e.g., clicks, likes, comments) for each item exposure.Formally, we define the set of user interactions as , and ,,represents users response to item concerning interaction .Given , each item has a multi-interaction response e, =[e,,1, . . . , e,,||]. For all items ,the overall user response is:",
  "The overall utility is quantified as the summation of individual itemutilities, denoted as R(,) = =1 R(,). The utility associatedwith each item may correspond to a specific interaction type ,": "such as clicks, watch time, or likes. In such cases, the item utilityis expressed as R(,) = ,,. Alternatively, the item utilitycan be represented as the weighted sum of diverse interactionsR(,) = ,,, where denotes the weight for eachinteraction.The reranking objective is to maximum the overall utility R(,)for a given user : R(,).(2) Reranking introduces a permutation space with exponential size,represented as O( ), where represents the number of candi-dates and represents the number of items to be selected andordered. Each permutation represents a potential arrangement ofitems, and users provide unique feedback for each permutation.However, in practical scenarios, users typically encounter only onepermutation. Thus, the main challenge in reranking lies in effi-ciently and effectively determining the optimal permutation giventhe vast solution space yet extremely sparse real user feedback astraining samples.",
  "=1( |0:1,1:;),(3)": "where the special tokens 0 (e.g., <bos>) and +1 (e.g., <eos>)denote the beginning and end of target sequences. Importantly, thelength of the generated sequence is predetermined and fixed, unlikevariable lengths in text.Factorizing the sequence generation output distribution autore-gressively leads to a maximum likelihood training with a cross-entropy loss at each timestep:",
  "=1log( |1:;).(6)": "Despite the removal of the autoregressive structure, the models re-tain an explicit likelihood function. The training of models employsseparate cross-entropy losses for each output distribution. Cru-cially, these distributions can be computed simultaneously duringinference, which significantly differs from the sequential process ofautoregressive models. This non-autoregressive approach reducesinference latency, thereby enhancing the efficiency of recommen-dation systems in real-world applications.",
  "APPROACH": "In this section, we present a detailed introduction of NAR4Rec. Wewill first discuss our non-autoregressive model structure, whichestimates the probability by a matching model in section 4.1. Then,we delve into unlikelihood training, a method aimed at discerningfeedback within the recommended sequence in section 4.2. Finally,we propose contrastive decoding to model the dependency in targetsequence in section 4.3. The sequence evaluator in our generator-evaluator framework is introduced in section 4.4.",
  "Matching model": "Non-autoregressive models encounter challenges in training con-vergence due to two main reasons. Firstly, the sparse nature oftraining sequences presents learning difficulties. Unlike text se-quences that often share linguistic structures, recommended listsin training samples seldom have the same exposures, posing chal-lenges for effective learning from limited data. Secondly, during the reranking stage, identical index for candidates may denote differ-ent items, leading to a variable vocabulary as the candidates to beranked vary across samples.Conventional models may struggle to handle such variationsefficiently. To tackle these challenges, we introduce two key compo-nents to our models: a candidates encoder for effectively encodingrepresentations of candidates and a position encoder to captureposition-specific information within the target sequence. Initially,we randomly initialize an embedding for each position in the targetsequences. Notably, we share these position embeddings acrosstraining data to enhance learning on sparse data. Subsequently, weintegrate bidirectional self-attention and cross-attention modulesto acquire representations for each position, leveraging informationfrom the candidates.Additionally, to address the challenge posed by the dynamicvocabulary arising from variations in candidates across samples,we employ a matching mechanism. Specifically, we match each can-didate with each position in the target sequence, thereby yieldingprobabilities for each candidate at every position. In the following,we elaborate on the structure of NAR4Rec.Given a user and candidates = {1,2, ,}, the hiddenrepresentation of is x R . We stack x together into matrixX R . Additionally, we randomly initialize an embedding vec-tor for each position as . Also, we stack into T R .To align the embedding dimension of X with that of T, we projectthem into same hidden dimension by a linear projection layer.Then X R and T R. Consequently, X is represented asX R and T as T R.Candidates Encoder. The candidates encoder adopts the stan-dard Transformer architecture by stacking Transformer lay-ers. In each layer, the architecture mainly consists of two blocks, aself-attention block and a feed-forward network. An input X forself-attention block is linearly transformed into query (Q), key(K) and value (V) as follows:",
  ": Architectural Overview of the Generator and Evaluator Models. The evaluator evaluates multiple sequences generatedby the generator and estimates listwise score to select the optimal sequence": "block between the self-attention block and the feed-forward net-work in each Transformer layer. As can be seen in , in eachlayer, the cross-attention block receives the hidden representationfrom the self-attention blocks of both encoders and processes themvia cross-attention operation. Specifically, the hidden representa-tion from the candidates encoder and position encoder are denotedas X and T, respectively. Similar to the self-attention block, weinitially apply linear projection to them:",
  "Q = TWQ, K = XWK, V = XWV.(11)": "Then, we applies the formula in eq. (9) to Q, K, and V to get theoutput hidden representation. The cross-attention is introduced tocapture the correlation between candidates and target sequence.Probability Matrix. To compute the probability matrix, we per-form a matrix multiplication on the output hidden representationfrom the candidates encoder (denoted as {x1, x2, ..., xn}) and posi-tion encoder (denoted as {t1, t2, ..., tm}). Subsequently, we apply acolumn-wise softmax function to normalize the scores. Formally,the probability score of placing the -th candidate item to the -thposition is calculated as:",
  "Unlikelihood Training": "The discrepancy between text and item sequences hinders the directapplication of generative models from text to item recommendation.This disparity arises from the unique characteristics of user inter-actions in recommendation scenarios. Unlike the structured natureof natural language text, the feedback within recommendation se-quences is diverse due to the varied nature of user interactions.While text sequences typically follow conventional language struc-tures to convey information or construct a coherent narrative, userfeedback in recommendation sequences is characterized by diverseactions such as clicks or likes, reflecting a diverse and nuancedfeedback.Consequently, the difference in objectives between maximumlikelihood training(as in eq. (5)) and reranking (as in eq. (2)) posesa significant challenge. Although maximum likelihood trainingeffectively captures patterns in text sequences, its applicability di-minishes in recommendation scenarios where user preferences aredynamic and subjective. The essence of high-quality recommen-dations lies not just in sequence patterns from training data but,more crucially, in the user utility of the recommended list. Userinteractions with recommended items are subjective and context-driven, adding complexity to aligning the training objective withthe desired model behavior. To address this challenge, we proposeunlikelihood training, guiding the model to assign lower probabili-ties to undesired generations. This adjustment aligns the trainingprocess with the intricate feedback patterns.Unlikelihood training reduces the models probability of gen-erating a negative sequence. Given candidates and a negative",
  "=1 log(1 ),(14)": "The loss decreases as decreases.Unlike text generation, where messages are clear and content-focused, managing attributes like topic, style, and sentiment in theoutput text is straightforward. However, recommendationsequences involve user feedback with implicit signals. For instance,a lack of interaction with a recommended item may suggest disin-terest. This highlights the models need to understand both explicitand implicit cues in user feedback. Effective control over genera-tion in recommendation sequences becomes crucial to tailor theoutput based on user preferences and behaviors, thus enhancingthe personalized recommendations. Specifically, we classify a itemsequence as positive or negative based on the overall utility definedin section 3.1, and the corresponding loss is as follows:",
  "Lul(,) =": "=1=1 log(1 )if R(,) < =1=1 log( )if R(,) (15)where is the threshold for positive and negative sequences.In summary, beyond the primary goal of learning positive se-quence patterns through sequence likelihood, unlikelihood train-ing introduces an additional objective to reduce the likelihood ofgenerating sequences with low utilities, effectively training rec-ommendation models to discern feedback within recommendationsequences.",
  "Contrastive Decoding": "Compared with autoregressive generation, the non-autoregressiveapproach significantly enhances computation efficiency and makesit feasible to deploy in real-time recommendation systems. However,non-autoregressive generation introduce the conditional indepen-dence assumption: each target items distribution () dependsonly on the candidates . This deviation from autoregressive mod-els poses challenges in capturing the inherently multimodal natureof the distribution of valid target sequences. Take machine trans-lation for example, when translating the phrase \"thank you\" intoGerman could result in multiple valid translations such as \"VielenDank\" and \"Danke\". However, non-autoregressive models may gen-erate unplausible translations like \"Danke Dank\". The conditionalindependence assumption in eq. (5) restricts the models ability toeffectively grasp the multimodal distribution in target sequences.Essentially, the assumption of conditional independence limitsthe models ability to navigate a vast solution space and identify themost suitable permutation from numerous valid options for a givenset of candidates. This limitation is especially evident in recommen-dation where the number of reasonable target sequences far ex-ceeds those encountered in text. Consequently, non-autoregressiveframeworks grapple with the challenge of mitigating the impact ofconditional independence to improve their capacity for generatingdiverse and contextually appropriate target sequences. To tacklethis, we propose contrastive decoding to model the co-occurrencerelationship between items and thereby improve the target depen-dency. Contrastive decoding incorporates a diversity prior that regu-lates the sequence decoding procedure. This is grounded in theintuition that an effective recommended list needs to be composedof a wide variety of items. In fact, contrastive decoding leveragesa similarity score function as a regulator when decoding, captur-ing the interdependence between various positions in the targetsequence.Formally, given the preceding context <, at time step , theselection of the output follows",
  "x xj .(17)": "Specifically, the similarity penalty is defined as the maximum simi-larity between the representation of and all items in<. NAR4Recutilizes the dot product item embedding and position embeddingto compute the probability matrix. Higher embedding similaritybetween items often means similar probability in a certain position.We introduce such penalty to introduce intra-list correlation.Also, to encourage the language model to learn discriminativeand isotropic item representations, we incorporate a contrastiveobjective into the training of the language model. Specifically, givena sequence , the Litem and Lposition are defined as:",
  "Sequence Evaluator": "The sequence evaluator model is designed to estimate the overallutility of a given sequence, as illustrated in fig. 2. The generatedsequence from the generator is first encoded using a self-attentionand a feed-forward layer to capture contextual information. Thehidden representation then passes through the linear projectionlayer to predict the score for a specific target. The overall utility iscalculated as the weighted sum of itemwise scores. Ultimately, thesequence with the highest overall utility is chosen for delivery tothe users.",
  "EXPERIMENTS": "In this section, we conduct extensive offline experiments and on-line A/B tests to demonstrate the effectiveness of NAR4Rec. Wefirst describe our experiment setup and baselines in section 5.1.For offline experiments in section 5.2, we compare NAR4Rec withexisting baselines on both performance and training and inferencetime. Then we alternate the hyper-parameter to analyse the hyper-parameter sensitivity of NAR4Rec. To further show the effective-ness of NAR4Rec in real-time recommendation system, we conductonline A/B tests to ablate our proposed methods in section 5.3.",
  "Avito53,562,2691,324,10323,562,269Meituan230,525,5313,201,92298,525,531": "Dataset: To evaluate reranking recommendation, we expectthat each sample of the dataset is an exposed sequence to usersrather than a manually constructed sequence. For public dataset,we choose Avito dataset. For industrial dataset, we use real-worlddata collected from Kuaishou short-video platform. The detailedintroduction is given in table 1. Avito2: The Avito dataset is a publicly available collection ofuser search logs from avito.ru. The dataset comprises over 53million lists with 1.3 million users and 36 million ads. Eachsample corresponds to a search page with multiple ads. Theuser search logs from first 21 days are used as training setand the search logs from the last 7 days are used as test set.The sequence length in Avito is 5. Kuaishou: The Kuaishou dataset is derived from Kuaishou,a widely used short-video application with a user base ofover 300 million daily active users. Each sample in the datasetrepresents an actual user request log, which contains userinformation(e.g. user id, age, gender), candidates items anduser interaction to exposed items. The dataset consists of atotal of 82,230,788 users, 26,835,337 items, and 1,811,625,438requests. Each request contains 6 items in the exposed itemsequence and 60 candidates from ranking.",
  "PIER: PIER applies hashing algorithm to slect top-kcandidates from the full permutation based on user inter-ests. Then the generator and evaluator are jointly trained togenerate better permutations": "Metrics As there is not common sequence generation metricsfor recommendation, we follow previous work and evaluatethese models using three commonly adopted metrics: AUC, LogLoss,and NDCG on Avito dataset. For Avito dataset, where and areequal(5), the task is to predict the itemwise click-through rate givena listwise input. For Kuaishou dataset, where and are 60 and6 respectively, we employ Recall@6, Recall@10, and LogLoss asevaluation metrics. The task for Kuaishou dataset is to predictwhether an item is chosen to be one of the exposed 6 items.Hyperparameters For Avito dataset, the learning rate is 10-3,the optimizer is Adam and the batch size is 1024. For Kuaishoudataset, the learning rate and optimizer is the same as Avito, butthe batch size is 256. 5.2.1Performance comparison. Here we show the results of ourproposed method NAR4Rec. As can be seen in in table 2 and ta-ble 3, NAR4Rec outperforms 5 baslines including recent strongreranking methods. PRM outperforms DNN and DCNby effectively capturing the mutual influence between items. Ad-ditionally, Edge-rerank surpass DNN and DCN with an adativebeam search with previous item information. PIER demonstratessuperiority over other baselines by the interaction per category.Notably, our proposed method exhibits the highest improvementwith a significant increase of 0.0125 in the AUC metric compared toother baseline models. table 3 shows the results of our offline experi-ments on Kuaishou. The evaluation metrics used in this experimentinclude Recall@6, Recall@10, and Loss. Our method achieves su-perior results on all metrics compared to other baseline models aswell.",
  "DNN66.47%86.65%0.6764DCN68.22%87.95%0.6809PRM73.17%92.25%0.5328Edge-rerank73.63 %92.90%0.5252PIER73.50%92.44%0.5361NAR4Rec74.86%93.16%0.5199": "5.2.2Training and Inference Time comparison. Given that NAR4Recis closely related to autoregressive models, we conduct a compari-son with autoregressive models Seq2Slate. We compare the trainingand inference time on the Avito dataset between Seq2slate andNAR4Rec. We also give training and inference time for genera-tors in other baselines in table 4. Since Seq2slate utilizes recurrentneural networks as its backbone network, both training and in-ference processes adopt an autoregressive manner. The inferencespeedup of NAR4Rec over Seq2slate is almost the same as train-ing. NAR4Rec only requires 58 minutes to complete the trainingwhile Seq2Slate requires 283 minutes. Such a significant reductionin training time (i.e. approximately 5 speedup) highlights thecomputational efficiency of NAR4Rec. The autoregressive modelrepresented by Seq2Slate generates target sequences item by item,while our Non-autoregressive NAR4Rec generates all items at once.So when generating a sequence of length 5, NAR4Rec shows ap-proximately 5 speedup. 5.2.3Hyper-parameter Analysis of NAR4Rec. We further analyzethe hyper-parameter sensitivity on NAR4Rec. Here, we conduct aseries of experiments on NAR4Rec and PIER. As shown in fig. 3,we demonstrate that our experimental results exhibit insensitivityto variations in the learning rate, batch size, and epoch.Then, we analyze the impact of weight and margin in con-trastive loss and the impact of penalty parameter in contrastivedecoding. shows the results of our experiments. We change while fixing =0.5, and change while fixing =0.01 in con-trastive loss. When changing in contrastive decoding, we set=0.5 and =0.01 as the default parameters. : The training and inference time comparison betweenNAR4Rec and baseline methods on the Avito dataset. Allexperiments are conducted on Tesla T4 16G GPU and thebatch size is set to 1024. The training and inference time iscalculated by averaging the result over 100 steps.",
  "Text sequence generation often is evaluated by human labeling. Inrecommendation, we resort to online A/B experiments to obtainthe feedback from users to demonstrate our effectiveness": "5.3.1Experiments setup. In online A/B experiments, we evenlydivide the traffic of the entire app into ten buckets. The online base-line is Edge-rerank, with 20% of the traffic assigned to NAR4Rec,while the remaining traffic is assigned to Edge-rerank. 5.3.2Experimental Results. The experiments have been launchedon the system for ten days, and the result is listed in table 5.NAR4Rec outperforms Edge-rerank by a large margin. NAR4Recshows users watch more(i.e a higher Views) videos, spend moretime on each video(i.e. more Long Views and Complete Views) anda more positive user feedback(i.e. a improvement on like, follows)over .",
  "+1.161%+1.71%+1.15%+1.82%+2.45%": ": Online experiments results. All values are the rela-tive improvements of NAR4Rec. For the online A/B test inKuaishou, the improvements of over 0.5% in positive interac-tions(like, follow) and 0.2% in views are very significant. 5.3.3Ablation Study on Unlikelihood Training. To show the effec-tiveness of unlikelihood training, we compare vanilla training on allexposed sequences with unlikelihood training. Unlikelihood showsmore Views and a longer Watch Time.",
  "CONCLUSION": "In this paper, we provide an overview of the current formulationand challenges associated with reranking in recommendation sys-tems. Although non-autoregressive generation has been exploredin natural language processing, conventional techniques are notdirectly applicable to recommendation systems. We tackle the chal-lenges in recommendations to improve the convergence and perfor-mance of non-autoregressive models and make the first attempt tointegrate non-autoregressive models into reranking in real-time rec-ommender systems. Extensive online and offline A/B experimentshave demonstrated the effectiveness and efficiency of NAR4Recas a versatile framework for generating sequences with enhancedutility. Moving forward, our future work will focus on refining the",
  "modeling of sequence utility to further enhance the capabilities ofNAR4Rec": "Qingyao Ai, Keping Bi, Jiafeng Guo, and W Bruce Croft. 2018. Learning a deeplistwise context model for ranking refinement. In The 41st international ACMSIGIR conference on research & development in information retrieval. 135144. Abhijeet Awasthi, Sunita Sarawagi, Rasna Goyal, Sabyasachi Ghosh, and VihariPiratla. 2019. Parallel Iterative Edit Models for Local Sequence Transduction. InProceedings of the 2019 Conference on Empirical Methods in Natural Language Pro-cessing and the 9th International Joint Conference on Natural Language Processing(EMNLP-IJCNLP). 42604270. Irwan Bello, Sayali Kulkarni, Sagar Jain, Craig Boutilier, Ed Chi, Elad Eban,Xiyang Luo, Alan Mackey, and Ofer Meshi. 2018. Seq2Slate: Re-ranking and slateoptimization with RNNs. arXiv preprint arXiv:1810.02019 (2018). Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton,and Greg Hullender. 2005. Learning to rank using gradient descent. In Proceedingsof the 22nd international conference on Machine learning. 8996. Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra,Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al.2016. Wide & deep learning for recommender systems. In Proceedings of the 1stworkshop on deep learning for recommender systems. 710.",
  "Yufei Feng, Binbin Hu, Yu Gong, Fei Sun, Qingwen Liu, and Wenwu Ou. 2021.GRN: Generative Rerank Network for Context-wise Recommendation. arXivpreprint arXiv:2104.00860 (2021)": "Marjan Ghazvininejad, Omer Levy, Yinhan Liu, and Luke Zettlemoyer. 2019.Mask-Predict: Parallel Decoding of Conditional Masked Language Models. InProceedings of the 2019 Conference on Empirical Methods in Natural Language Pro-cessing and the 9th International Joint Conference on Natural Language Processing(EMNLP-IJCNLP). 61126121. Xudong Gong, Qinlin Feng, Yuan Zhang, Jiangling Qin, Weijie Ding, Biao Li, PengJiang, and Kun Gai. 2022. Real-time Short Video Recommendation on MobileDevices. In Proceedings of the 31st ACM International Conference on Information& Knowledge Management. 31033112.",
  "Thorsten Joachims, Laura Granka, Bing Pan, Helene Hembrooke, and Geri Gay.2017. Accurately interpreting clickthrough data as implicit feedback. In AcmSigir Forum, Vol. 51. Acm New York, NY, USA, 411": "Yichong Leng, Xu Tan, Rui Wang, Linchen Zhu, Jin Xu, Wenjie Liu, LinquanLiu, Xiang-Yang Li, Tao Qin, Edward Lin, et al. 2021. FastCorrect 2: Fast ErrorCorrection on Multiple Candidates for Automatic Speech Recognition. In Findingsof the Association for Computational Linguistics: EMNLP 2021. 43284337. Yichong Leng, Xu Tan, Linchen Zhu, Jin Xu, Renqian Luo, Linquan Liu, TaoQin, Xiangyang Li, Edward Lin, and Tie-Yan Liu. 2021. Fastcorrect: Fast errorcorrection with edit alignment for automatic speech recognition. Advances inNeural Information Processing Systems 34 (2021), 2170821719. Margaret Li, Stephen Roller, Ilia Kulikov, Sean Welleck, Y-Lan Boureau,Kyunghyun Cho, and Jason Weston. 2020. Dont Say That! Making InconsistentDialogue Unlikely with Unlikelihood Training. In Proceedings of the 58th AnnualMeeting of the Association for Computational Linguistics. 47154728. Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, andGuangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature in-teractions for recommender systems. In Proceedings of the 24th ACM SIGKDDinternational conference on knowledge discovery & data mining. 17541763.",
  "Tie-Yan Liu et al. 2009. Learning to rank for information retrieval. Foundationsand Trends in Information Retrieval 3, 3 (2009), 225331": "Lori Lorigo, Maya Haridasan, Hrnn Brynjarsdttir, Ling Xia, Thorsten Joachims,Geri Gay, Laura Granka, Fabio Pellacini, and Bing Pan. 2008. Eye tracking andonline search: Lessons learned and challenges ahead. Journal of the AmericanSociety for Information Science and Technology 59, 7 (2008), 10411052. Lori Lorigo, Bing Pan, Helene Hembrooke, Thorsten Joachims, Laura Granka,and Geri Gay. 2006. The influence of task and gender on search and evaluationbehavior using Google. Information processing & management 42, 4 (2006), 11231131. Liang Pang, Jun Xu, Qingyao Ai, Yanyan Lan, Xueqi Cheng, and Jirong Wen.2020. Setrank: Learning a permutation-invariant ranking model for informationretrieval. In Proceedings of the 43rd international ACM SIGIR conference on researchand development in information retrieval. 499508.",
  "for recommendation. In Proceedings of the 13th ACM conference on recommendersystems. 311": "Xiaowen Shi, Fan Yang, Ze Wang, Xiaoxu Wu, Muzhi Guan, Guogang Liao, WangYongkang, Xingxing Wang, and Dong Wang. 2023. PIER: Permutation-LevelInterest-Based End-to-End Re-ranking Framework in E-commerce. In Proceedingsof the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining.48234831. Mitchell Stern, William Chan, Jamie Kiros, and Jakob Uszkoreit. 2019. Insertiontransformer: Flexible sequence generation via insertion operations. In Interna-tional Conference on Machine Learning. PMLR, 59765985. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang.2019. BERT4Rec: Sequential recommendation with bidirectional encoder rep-resentations from transformer. In Proceedings of the 28th ACM internationalconference on information and knowledge management. 14411450. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,Aidan N Gomez, ukasz Kaiser, and Illia Polosukhin. 2017. Attention is allyou need. Advances in neural information processing systems 30 (2017).",
  "Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross networkfor ad click predictions. In Proceedings of the ADKDD17. 17": "Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun Cho, andJason Weston. 2019. Neural Text Generation With Unlikelihood Training. InInternational Conference on Learning Representations. Yunjia Xi, Weiwen Liu, Xinyi Dai, Ruiming Tang, Weinan Zhang, Qing Liu, Xi-uqiang He, and Yong Yu. 2021. Context-aware reranking with utility maximizationfor recommendation. arXiv preprint arXiv:2110.09059 (2021).",
  "Chunting Zhou, Jiatao Gu, and Graham Neubig. 2019. Understanding Knowl-edge Distillation in Non-autoregressive Machine Translation. In InternationalConference on Learning Representations": "Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, XiaoqiangZhu, and Kun Gai. 2019. Deep interest evolution network for click-through rateprediction. In Proceedings of the AAAI conference on artificial intelligence, Vol. 33.59415948. Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, YanghuiYan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-throughrate prediction. In Proceedings of the 24th ACM SIGKDD international conferenceon knowledge discovery & data mining. 10591068."
}