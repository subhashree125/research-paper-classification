{
  "Abstract": "The rapid proliferation of Industrial Internet of Things (IIoT) systems ne-cessitates advanced, interpretable, and scalable intrusion detection systems(IDS) to combat emerging cyber threats. Traditional IDS face challengessuch as high computational demands, limited explainability, and inflexi-bility against evolving attack patterns. To address these limitations, thisstudy introduces the Lightweight Explainable Network Security framework(LENS-XAI), which combines robust intrusion detection with enhanced in-terpretability and scalability. LENS-XAI integrates knowledge distillation,variational autoencoder models, and attribution-based explainability tech-niques to achieve high detection accuracy and transparency in decision-making. By leveraging a training set comprising 10% of the available data,the framework optimizes computational efficiency without sacrificing perfor-mance. Experimental evaluation on four benchmark datasetsEdge-IIoTset,UKM-IDS20, CTU-13, and NSL-KDDdemonstrates the frameworks supe-rior performance, achieving detection accuracies of 95.34%, 99.92%, 98.42%,and 99.34%, respectively. Additionally, the framework excels in reducing falsepositives and adapting to complex attack scenarios, outperforming existingstate-of-the-art methods. Key strengths of LENS-XAI include its lightweightdesign, suitable for resource-constrained environments, and its scalabilityacross diverse IIoT and cybersecurity contexts. Moreover, the explainability",
  ". Introduction": "In the ever-expanding digital landscape, the rapid proliferation of in-terconnected devices has led to a corresponding rise in sophisticated cyberthreats, challenging the efficacy of traditional network security measures .Intrusion Detection Systems (IDS) have emerged as critical components insafeguarding networks by identifying and mitigating anomalous activities .However, the increasing complexity of cyberattacks necessitates the adoptionof advanced methodologies that can keep pace with evolving threats whilemaintaining interpretability and scalability . Recent studies highlights theadoption of advanced methodologies, including the integration of deep learn-ing (DL) techniques with artifical intelligence (AI) for enhanced intrusion de-tection , federated incremental learning for Internet of Things (IoT) se-curity monitoring , and blockchain-enhanced decision-making frameworks. Furthermore, intelligent systems tailored for specialized environmentslike unmanned aerial vehicles highlight the potential of interpretable IDS inaddressing domain-specific challenges .Despite this progress, a significant challenge persists: the black-box na-ture of these models undermines their adoption in critical applications whereexplainability and transparency are paramount. Addressing this gap, Ex-plainable AI (XAI) has gained prominence, enabling researchers and prac-titioners to understand and trust IDS based on machine learning (ML) /DL . Incorporating XAI frameworks into IDS improves both opera-tional transparency and decision-making reliability.For example, modelssuch as DeepRoughNetID have demonstrated robust anomaly detectioncapabilities by combining feature engineering with interpretable algorithms.Similarly, the integration of XAI into IoT-based intrusion detection systems,as illustrated by TwinSec-IDS , highlights the potential of explainable frameworks in addressing security challenges in complex environments. Theseadvancements underline the necessity of pairing state-of-the-art ML/DL tech-niques with XAI to foster adoption and trust in IDS solutions.The contemporary cybersecurity ecosystem also demands lightweight mod-els that can operate efficiently in resource-constrained settings such as IoTand edge computing environments. For example, the Zero-Trust Marine Cy-berdefense framework exemplifies the integration of lightweight architec-tures with explainable mechanisms, showcasing their effectiveness in spe-cialized domains. This approach aligns with industry trends that prioritizethe dual objectives of computational efficiency and interpretability. Amongthe cutting-edge methodologies in IDS development, knowledge distillationand variational autoencoders (VAEs) have emerged as transformative tech-niques. Knowledge distillation facilitates the transfer of insights from com-plex, high-capacity models to compact, efficient ones, ensuring that resource-efficient systems do not compromise on performance . Meanwhile, VAEshave proven instrumental in learning latent representations of data, allow-ing anomaly detection by analyzing deviations from normal patterns .Leveraging these methodologies within an XAI framework can redefine theparadigms of network security.Despite these advances, a critical gap persists in the current literature. Al-though existing approaches address aspects of either scalability, interpretabil-ity, or computational efficiency, comprehensive solutions that holistically in-tegrate these factors remain scarce. In particular, studies such as PANACEA and XAIEnsembleTL-IoV emphasize specific facets of IDS but fail toprovide an integrated framework applicable in diverse real-world scenarios,particularly in resource-constrained environments. Furthermore, the absenceof robust explanations for model predictions often hinders the deploymentof these systems in critical applications where trust and accountability areparamount. In the evolving landscape of autonomous vehicles, ensuring ro-bust in-vehicle network security is paramount.In this study, we introduce LENS-XAI, an advanced framework that re-defines lightweight and explainable network security by combining knowledgedistillation with VAEs. The LENS-XAI approach is tailored for resource-constrained environments, such as IoT and edge computing, emphasizingscalability and interpretability. Its well-designed architecture enables highdetection accuracy, robust anomaly detection, and actionable insights intodecision-making processes. This framework seeks to balance performance andtransparency, offering an effective solution for intrusion detection in modern",
  "Enhanced Explainability: LENS-XAI incorporates variable attribu-tion-based XAI mechanisms mechanisms to provide detailed insights,fostering greater trust and clarity in its operations": "Optimized for Resource-Constrained Environments: Its scal-able and lightweight architecture is designed to adapt seamlessly toIoT and edge computing scenarios without sacrificing detection perfor-mance. Robust Validation: Extensive experiments on benchmark datasets,including NSL-KDD, CTU-13, UKM20 and EDGEIIoTset, demonstratethe frameworks efficacy and reliability in diverse real-world applica-tions. The remainder of this paper is organized as follows. Section II reviews relatedworks in ML/DL-based IDS and XAI integration. Section III outlines themethodology, detailing the proposed model architecture and its components.Section IV presents experimental results, highlighting performance metricsand comparative analyses. Finally, Section V & VI conclude with insightsand future directions for advancing IDS research.",
  ". Literature survey": "IDSs have been widely researched to address the increasing sophisticationof cyberattacks. This section reviews recent advances in IDS methodologieswith an emphasis on using XAI and lightweight architectures to enhanceinterpretability and efficiency. 2.1. Explainable Deep Learning Approaches for IDSDL models have dramatically transformed IDS by providing enhancedaccuracy and adaptability in identifying malicious activities. However, theirinherent black-box nature raises significant concerns about trust and in-terpretability. To address these issues, Sindiramutty et al. proposed a Bi-LSTM-based framework integrated with explainable mechanisms, includ-ing enhanced krill herd optimization, which provides valuable insights intoits decision-making process. This framework has proven effective in indus-trial cyber-physical systems, emphasizing the need for models that balanceinterpretability with high performance. Similarly, Nalini et al. introducedDeepRoughNetID, a model designed to enhance anomaly detection capabil-ities by combining robust feature engineering with interpretable algorithms.While achieving high detection rates, DeepRoughNetID highlights the impor-tance of evaluating its effectiveness in resource-constrained environments, adomain where its applicability remains underexplored. Al-Essa et al. extended this line of research by developing PANACEA, a neural modelensemble utilizing knowledge distillation to enhance both efficiency and ex-plainability. While PANACEA demonstrates its potential through accuratedetection rates, its reliance on specific datasets limits its generalizabilityacross diverse network environments. Alotaibi et al. applied XAI to webphishing classification in IoT and cyber-physical systems, achieving strong re-sults but requiring further validation across diverse IoT architectures. Zhaoet al. also addressed these challenges by proposing a lightweight IDSframework based on knowledge distillation and deep metric learning. How-ever, their approach fell short in addressing the few-shot learning problem,leaving room for further optimization. 2.2. Lightweight and Scalable ModelsAs IoT devices and edge computing architectures continue to proliferate,IDS models must adapt to operate effectively in resource-constrained settings.Lightweight and scalable frameworks have become essential in addressingthese demands. Nkoro et al. proposed the Zero-Trust Marine Cyberde-fense framework, which integrates lightweight architectures with explainablemechanisms to ensure robust cybersecurity in IoT-based maritime networks.This approach exemplifies the effectiveness of models designed for specializedenvironments, emphasizing computational efficiency without compromisinginterpretability. Ullah et al. presented IDS-INT, a transformer-based in-trusion detection model that employs transfer learning to handle unbalancednetwork traffic. While its advanced architecture achieves high detection accu-racy, the models scalability across different network configurations remainsa critical area for further validation.Chen et al. explored federated learning for IDS, incorporating dif-ferentially private knowledge distillation to preserve data privacy while en- hancing classification accuracy. Their framework balanced privacy and util-ity, but required optimization for heterogeneous IoT architectures.Simi-larly, Kumar et al. developed a blockchain-enabled IDS integrated withXAI for enhanced decision-making transparency in industrial systems. Whilepromising, their approach demands further evaluation in dynamic industrialcontexts. In parallel, Fatema et al. introduced a federated learning frame-work combined with XAI techniques to enhance the security and efficiency ofIDS in IoT ecosystems. Their work highlights the growing need for collabo-rative and distributed approaches that ensure scalability and trustworthinessin real-world applications. 2.3. Advanced Anomaly Detection TechniquesModern anomaly detection methods emphasize the need to capture com-plex data patterns and deviations effectively, particularly in dynamic networkenvironments. Gaspar et al. explored the integration of SHAP (SHapleyAdditive exPlanations) and LIME (Local Interpretable Model-Agnostic Ex-planations) techniques in intrusion detection systems based on Multi-LayerPerceptron models.By combining local and global interpretability, theirapproach not only improves detection accuracy but also enhances the trans-parency of model predictions, fostering trust among users. Bacevicius et al. investigated hybrid approaches to handle unbalanced intrusion detec-tion datasets, demonstrating improved classification accuracy in multi-classscenarios. Roy et al. proposed an explainable deep neural framework tai-lored for industrial settings, enabling trustworthy and transparent anomalydetection processes. In addition, Ahmed et al. developed a hybrid en-semble IDS model incorporating bagging, boosting, and SHAP to achievehigh accuracy. These methodologies underline the importance of combininginterpretability with advanced learning mechanisms to address the complex-ities of modern cyber threats. 2.4. Knowledge Distillation & VAEsKnowledge distillation and VAEs have emerged as powerful tools forbuilding efficient and interpretable IDS frameworks. By transferring knowl-edge from high-capacity models to lightweight counterparts, knowledge dis-tillation ensures that computationally efficient systems maintain high detec-tion accuracy. Sindiramutty et al. effectively combined these techniquesto design an anomaly detection model capable of balancing efficiency and explainability in industrial applications. Similarly, Moustafa et al. in-tegrated VAEs with federated learning and XAI frameworks to develop arobust intrusion detection solution for IoT networks. Javeed et al. fur-ther demonstrated the utility of these approaches in specialized domains,designing an interpretable IDS tailored for unmanned aerial vehicles.Building on prior advancements, our earlier study by Yagiz et al. in-troduced the KD-XVAE system, integrating a Knowledge Distillation frame-work with VAEs. This model achieved exceptional performance, with perfectrecall, precision, and F1 scores, while maintaining a lightweight computa-tional design. By employing XAI techniques such as SHAP, the KD-XVAEsystem enabled interpretability by highlighting key latent features criticalfor decision-making. These studies highlight the transformative potential ofintegrating knowledge distillation and VAEs into XAI-based intrusion detec-tion systems, paving the way for innovative solutions that meet the demandsof modern network security. 2.5. Research GapThe reviewed works highlight several research gaps in IDS development.Bacevicius et al. and Le et al. emphasized the challenges associatedwith raw and unbalanced intrusion detection datasets, particularly in multi-class classification problems. Moustafa et al. and Kostopoulos et al. explored the use of XAI to address the interpretability issues of IDS models.Furthermore, Shtayat et al. and Sivamohan et al. demonstratedthe potential of integrating ensemble learning and DL techniques for robustintrusion detection but noted limitations in scalability across diverse IoTenvironments. The computational challenges and lack of interpretability inintrusion detection frameworks were also highlighted in works by Hattak et al. and Arisdakessian et al. . Additionally, the need for enhanced attackclassification and explanations in dynamic IoT environments was underlinedby Gaspar et al. and Kumar et al. . .In response to these gaps, our proposed LENS-XAI framework inte-grates knowledge distillation and VAEs within a lightweight architecture,tailored for resource-constrained IoT and edge computing environments. Em-phasizing scalability, interpretability, and efficiency, it employs variableattribution-based XAI mechanisms to provide transparent insights intodecision-making processes.By validating its performance across diversedatasets and scenarios, this framework advances the state-of-the-art in IDS. 2.6. Problem Statement and MotivationExisting IDS frameworks face significant challenges in scalability, dataset-specific performance, and adaptability to dynamic environments. Many mod-els rely on static feature selection techniques and heuristic-driven metrics,which limit their ability to identify critical relationships among features,particularly in the context of imbalanced datasets. Additionally, the compu-tational overhead of existing solutions restricts their real-time applicability,especially in resource-constrained environments like IoT and edge comput-ing. The limited scenario-based evaluations and reliance on specific datasetsfurther constrain the generalizability of these models, leaving critical gapsin their ability to address diverse real-world applications.Moreover, theabsence of dynamic threat adaptation mechanisms undermines the effective-ness of IDS frameworks in handling evolving cyber threats. These challengesnecessitate the development of robust, scalable, and generalizable IDS solu-tions capable of operating efficiently in resource-constrained environments.By addressing these limitations, it becomes possible to enhance the overallefficiency, adaptability, and reliability of IDS frameworks, ensuring improvedsecurity across diverse and dynamic network scenarios.",
  ". Methodology": "3.1. Framework OverviewThe proposed workflow begins with input datasets, which undergo pre-processing to remove inconsistencies, transform categorical attributes, andnormalize numerical features. The processed data is fed into a VAE, cap-turing latent representations critical for anomaly detection. To enhance ef-ficiency, Knowledge Distillation transfers the learned representations from arobust teacher model to a lightweight student model, optimizing computa-tional performance for resource-constrained environments. Finally, a variableattribution-based explainability method provides transparent insights intothe decision-making process, enhancing trust and usability in the detectionframework.",
  "(1)": "where and are the mean and standard deviation of the feature, respec-tively. This standardization ensures that the features have a mean of 0 and astandard deviation of 1, facilitating balanced gradient updates during modeltraining. 3.3. Representation Learning with Variational AutoencodersFollowing preprocessing, we employ VAEs to model the underlying datadistribution and derive expressive latent representations that facilitate anomalydetection.",
  "balances the trade-off between reconstruction fidelity and latent-space regularization": "3.3.3. Latent Representation for Anomaly DetectionWe use the encoders learned representations to identify anomalous sam-ples in subsequent classification or threshold-based detection steps.Intu-itively, examples that yield high reconstruction error or have low likelihoodunder the learned latent distribution are flagged as potential intrusions. 3.4. Knowledge Distillation for Model OptimizationVAEs combined with high-capacity classification models can be compu-tationally demanding. To alleviate inference costs without sacrificing perfor-mance, we employ Knowledge Distillation , transferring the knowledgefrom a powerful teacher model to a more compact student model.",
  "Here, T() denotes the temperature-scaled softmax operator": "3.5. Variable Attribution-Based ExplainabilitySecurity analysts require interpretable results to validate and trust IDSoutcomes. To meet this need, we incorporate a variable attribution-basedexplainability approach, as detailed in Algorithm 1, which quantifies thecontributions of individual features in anomaly predictions . This al-gorithm computes feature attributions by decomposing the model predictionfor a given test instance into baseline and individual feature contributions,ensuring the property of local accuracy.Specifically, the algorithm itera-tively calculates the marginal contribution of each feature by comparing the expected model prediction conditioned on subsets of features. The processguarantees that the sum of all contributions aligns with the models out-put, providing a transparent and interpretable breakdown of the prediction.",
  "The difference isolates the marginal contribution of the j-th variable": "3.5.2. Generalization to Subsets of FeaturesTo handle more general cases, let J = {j1, j2, . . . , jK} be a subset ofK p indices from {1, 2, . . . , p}, and let L = {l1, l2, . . . , lM} be anothersubset of M p K indices, such that J L = . Define the conditionaldifference for L | J as :",
  ". Performance evaluation": "We begin by assessing the intrusion detection performance of the proposedLENS-XAI framework, comparing it against baseline methods as outlined in.3. Furthermore, .5 provides a comprehensive evaluationof the frameworks explainability, benchmarked against state-of-the-art tech-niques. 4.1. Experimental Setup and Evaluation MetricsThe proposed framework is implemented in Python, incorporating mod-ern libraries such as TensorFlow and PyTorch for model development andleveraging variable attribution methods for explainability. The preprocessingpipeline is designed to ensure data consistency by addressing missing values,encoding categorical variables, and normalizing numerical features. Explain-ability is achieved through an attribution-based approach that highlights thecontribution of individual features to the models predictions, enabling in-terpretable anomaly detection. The experimental settings use a batch sizeof 64 across all datasets. Training epochs are set to 200 for UKM-IDS20,500 for Edge-IIoTset, and 100 for NSL-KDD, with a consistent learning rateof 0.001, ensuring robust latent representations. Knowledge distillation isconducted with a temperature parameter T = 2 and a weighting coefficient = 0.5. The system configuration, tailored to support the integration ofXAI principles, is summarized in .The key evaluation metrics used in this study are defined as follows:",
  "Memory Usage: The memory footprint of the model during inferencewas evaluated to determine the hardware requirements for real-timedeployment": "4.2. Dataset DescriptionsThe proposed LENS-XAI framework is assessed using four benchmarkdatasets: Edge-IIoTset, UKM20, CTU-13, and NSL-KDD. These datasetswere carefully chosen for their distinctive features and their relevance to intrusion detection in IIoT and Vehicular Network (IVN) environments. Ta-ble 2, detailed in Appendix I, summarizes the key characteristics of thesedatasets, highlighting their relevance for evaluating the proposed intrusiondetection framework.",
  "DoS,Probe,R2L,U2R41features;148,517 samples": "Edge-IIoTset Dataset. The Edge-IIoTset dataset is designed for cyber-security research in IoT and edge computing environments. It features bothbenign and malicious network traffic, annotated with detailed labels, times-tamps, and traffic characteristics. The dataset spans multiple protocols andincludes diverse attack types such as Denial of Service (DoS), data exfil-tration, and command injection. This comprehensive coverage makes Edge-IIoTset an invaluable resource for testing intrusion detection systems in com-plex and realistic network scenarios. shows the various classes of",
  ": Class distribution of Edge-IIoTset dataset": "UKM20 Dataset. The UKM-IDS20 dataset is tailored for intrusion detec-tion in vehicular networks, offering traffic data from Controller Area Network(CAN) buses. It encompasses both normal and attack scenarios, includingmessage injection and spoofing attacks. Key features, such as CAN IDs, datalength codes (DLC), and payload data, enable robust anomaly detection andthe evaluation of IDS solutions specific to IVN environments. showsthe class distribution of the UKM20. The dataset is publicly accessible at2. CTU-13 Dataset. The CTU-13 dataset is a widely recognized benchmarkfor botnet traffic analysis. While not specific to IVNs, it contains a mix ofnormal and botnet-infected traffic with detailed flow-based features. Thedataset is well-suited for evaluating generalized IDS models that can beadapted for IVN use cases. The CTU-13 dataset is publicly available at3.This dataset consists of the following traffic types and their respective counts:",
  "Attack Traffic: 38,898 instances": "NSL-KDD Dataset. The NSL-KDD dataset is a refined version of theKDD Cup 1999 dataset, addressing redundancy and imbalance issues. Itprovides labeled network traffic with 43 features, including protocol type,service, flag, and attack labels. The dataset includes separate training (KD-DTrain+) and testing (KDDTest+) subsets, facilitating model developmentand validation in diverse cybersecurity contexts. illustrates the dis-tribution of classes within the NSL-KDD. This dataset is publicly availableat4. 4.3. Performance Evaluation of the Introduced LENS-XAI Method4.3.1. Analysis on Edge-IIoTset Dataset provides a comprehensive comparison of the proposed LENS-XAIframework with state-of-the-art intrusion detection systems on the Edge-IIoTset dataset, evaluating multi-class classification tasks.",
  "Multi-class Classification Results": "Accuracy: The LENSXAI Student achieved the highest accuracy of99.34%, surpassing all competing models, including RNN-IDS (81.29%) and MCNN-DFS (81.44%) . The Teacher model also demon-strated remarkable accuracy at 98.66%, showcasing the efficacy of theknowledge transfer process. Precision and Recall: With a precision of 98.47% and recall of98.49%, the Student model outperformed traditional approaches likeNaive Bayes (76.1% precision) and Random Forest (75.9% recall) .The Teacher model closely followed, achieving precision and recall val-ues of 98.64% and 98.67%, respectively.",
  "LENS-XAI Student95.3195.7495.3195.36": "accuracy (99.64%100.00%). For Backdoor, the models perform strongly(97.89%98.49%), while in rare attacks like SQL Injection, the Teacheroutperforms the Student (34.21% vs. 19.13%). Both models achieve perfectdetection (100.00%) for Normal traffic, showcasing reliability. The Teacherdemonstrates better handling of rare scenarios, solidifying its robustness forIoT intrusion detection. Confusion Matrix Analysis. illustrates the confusion matricesfor the LENS-XAI framework, showcasing the performance of the Teacherand Student models on the Edge IIoT dataset for multiclass classification.The Teacher model achieves high accuracy across frequent attacks such asDDoS ICMP and DDoS UDP, with minimal misclassifications. For in-stance, only 1 instance of DDoS ICMP was misclassified as another type,demonstrating robust detection capabilities.Similarly, the Student model exhibits strong performance, closely approx-imating the Teachers accuracy. Notably, it correctly classifies 61,156 DDoSICMP instances and 109,559 DDoS UDP instances.While both mod-els perform exceptionally well for frequent attack types, rare attack typeslike SQL Injection and Uploading exhibit slightly higher misclassificationrates. These results affirm the scalability and reliability of the LENS-XAIframework in detecting a wide range of attack types within IoT environments.",
  "UDP Data Flood (Student)100.0099.41100.0099.71": "Frequent Attacks: Both models excel in detecting common attackssuch as BeEF HTTP Exploits, Metasploit Exploits, and Normaltraffic, achieving perfect or near-perfect accuracy (99.95%100.00%).The Teacher and Student models are equally capable in these scenarios,demonstrating high reliability for frequent attack detection. Rare Attacks: For less frequent attacks like ARP Poisoning andMass HTTP Requests, the Student model slightly outperforms theTeacher model in accuracy (99.77% vs. 95.72% for ARP Poisoning).This reflects the effectiveness of knowledge distillation in the LENS-XAI framework, enabling the Student model to closely replicate theTeacher models performance. Confusion Matrix Analysis. presents the confusion matricesfor the LENS-XAI framework, illustrating the performance of the Teacherand Student models on the UKM-IDS20 dataset for multiclass classificationtasks.The Teacher model demonstrates high accuracy across all classes,with minimal misclassifications.For example, all 444 instances of ARPPoisoning are correctly classified, while only 7 Normal instances are mis-classified. Similarly, frequent attack types such as BeEF HTTP Exploits, Mass HTTP Requests, and Metasploit Exploits achieve near-perfectdetection, highlighting the models robustness.The Student model closely approximates the Teachers performance, withslightly higher misclassifications in certain categories. For instance, it cor-rectly classifies 434 out of 445 BeEF HTTP Exploits instances, while11 instances are misclassified. Despite these minor differences, the Studentmodel maintains strong overall performance, correctly identifying 8,008 Nor-mal instances and 525 TCP Flood instances.",
  ": Confusion matrices of the LENS-XAI framework on the UKM IDS20 dataset:(Left) Teacher and (Right) Student models, showcasing effective differentiation betweeneight classes": "4.3.3. Analysis on CTU-13 Dataset presents a comparative analysis of the proposed LENS-XAI frame-work against state-of-the-art ML models on the CTU-13 dataset. The resultsunderline the robustness and effectiveness of the proposed framework in in-trusion detection. Accuracy: The LENSXAI Teacher achieved an exceptional accuracyof 98.42%, outperforming models like SVM-RBF (85.03%) and k-NN(93.00%) . The LENSXAI Student also delivered a strong perfor-mance with an accuracy of 98.12%, demonstrating the efficiency ofthe knowledge distillation process. Recall: Both LENSXAI Teacher and Student achieved outstandingrecall scores of 98.42% and 98.12%, respectively, ensuring high detec-tion rates for malicious activities. These results outperform traditionalmethods such as NB (76.00%) and LR (86.00%) .",
  "bot-DL : Demonstrated competitive accuracy (96.60%) butlacks the explainability critical for trust and transparency in in-trusion detection systems, a key advantage of LENS-XAI": "k-NN and SVM-RBF : Fell short in both accuracy andscalability, with lower accuracy scores of 93.00% and 85.03%, re-spectively, underlining the efficacy of the advanced techniques in-tegrated into LENS-XAI. presents the confusion matrices of the LENS-XAI framework forboth the Teacher and Student models on the CTU-13 dataset, illustratingtheir capabilities in distinguishing between normal and anomaly classes. TheTeacher model demonstrates robust performance, misclassifying only 566normal instances as anomalies and 541 anomalies as normal, ensuring highclassification accuracy. Similarly, the Student model achieves strong results,with only 1,355 normal instances and 333 anomaly instances misclassified.These results underline the effectiveness of the LENS-XAI framework in accu-rately classifying network traffic while maintaining minimal misclassificationrates.",
  "R2L (Teacher)89.1578.9889.1583.76R2L (Student)85.4677.6185.4781.35": "closely followed with slight increases in misclassifications. Both models per-formed well on Normal traffic, maintaining accuracies above 98%. However,rare attacks like U2R remain challenging due to class imbalance, with theTeacher achieving 37.14% accuracy compared to 23.80% for the Student.In general, the LENS-XAI framework ensures high classification performanceand scalability, with minimal misclassifications for major attack types. Confusion Matrix Analysis. illustrates the confusion matricesfor the LENS-XAI framework, highlighting the performance of the Teacherand Student models on the NSL-KDD dataset for multiclass classification.The Teacher model demonstrates exceptional accuracy with minimal misclas-sifications, such as 121 DoS and 237 Normal instances. The Student modelclosely mirrors the Teachers performance, correctly classifying 47,783 DoSand 68,934 Normal instances, showcasing its efficiency and robustness inknowledge distillation. 4.4. Model Complexity and Inference Time4.4.1. Multi-Class Classification Analysis provides a detailed comparison of the Student and Teacher mod-els in terms of the number of parameters and inference time per batch formulti-class classification across three benchmark datasets: UKM20, Edge-IIoTset, and NSL-KDD.",
  ": Confusion matrices of the LENS-XAI framework on the NSL-KDD dataset:(Left) Teacher and (Right) Student models, showcasing effective differentiation betweenfive classes": "For instance, the Teacher model has 13,065 parameters for UKM20,while the Student model only requires 4,489 parameters, representinga notable reduction in computational complexity. Similarly, for Edge-IIoTset, the parameter count is 22,415 for the Teacher model, comparedto 9,167 for the Student model. Inference Time: Despite its reduced parameter count, the Studentmodel demonstrates competitive inference times. For example, the in-ference time per batch for UKM20 is 11.92 ms for the Student modelversus 13.41 ms for the Teacher model. The Edge-IIoTset dataset showsa similar trend, with the Student model achieving an inference time of29.77 ms, compared to 34.22 ms for the Teacher model.",
  "parameters. For Edge-IIoTset, the parameter count is 4,225 for theStudent model and 12,545 for the Teacher model": "Inference Time: The Student model achieves superior inference timesin binary classification tasks. For example, the inference time per batchfor CTU-13 is 5 ms for the Student model, compared to 7 ms for theTeacher model. For Edge-IIoTset, the Student model achieves an in-ference time of 26.77 ms, whereas the Teacher model records 30.25 ms.",
  "These results highlight the computational efficiency of the Student model,making it a suitable choice for resource-constrained environments without asubstantial sacrifice in performance": "4.5. Variable Attribution-Based Explainability AnalysisTo uncover the inner workings of the LENS-XAI model and ensure trans-parency, we implemented a variable attribution-based explainability approach,detailed in Algorithm 1. This method dissects model predictions by quanti-fying the contributions of individual features and latent variables, guarantee-ing local accuracy. By applying this approach to datasets such as CTU-13,UKM20, NSL-KDD, and Edge-IIoTset, we gained critical insights into the factors driving model decisions. The results, presented in the subsequentsub-sections, showcase its effectiveness in binary classification for the CTU-13 dataset and both binary and multi-class tasks for the UKM20 dataset.This analysis not only highlights key predictive features but also validatesthe methods utility in enhancing transparency and trust for intrusion detec-tion systems across diverse classification scenarios. 4.5.1. Binary Classification Results on CTU-13 Dataset compares the explainability outcomes of the Teacher and Studentmodels for detecting anomalies in the CTU-13 dataset under binary classi-fication.Both models demonstrate strong predictive capability, yet theyprioritize different latent dimensions and corresponding original features intheir decision-making processes. Explainability Insights from the Teacher Model. A detailed break-down analysis of the Teacher model () indicates a final predictedvalue of approximately 0.999984 for the sample under examination.Theinitial intercept (0.419964) serves as the baseline probability before featurecontributions are considered. Several latent dimensionsmapped to featuressuch as Flow Duration and Fwd IAT Totprovide positive contribu-tions, gradually elevating the prediction closer to 1.0. Notably, latent dimen-sion 15 (Flow IAT Mean) and 1 (Tot Fwd Pkts) offer significant booststo the prediction, underlining their critical role in detecting malicious traffic.Conversely, certain dimensions (e.g., mapped to Bwd IAT Max) exhibitnegative or minimal contributions, reflecting how the model discounts thesefactors for this particular instance.By linking each latent dimension to the most influential original feature,security analysts gain insight into why the Teacher model flags a flow asanomalous.For instance, high values in Fwd IAT Tot or Flow IATMean suggest irregular timing patterns, consistent with potential maliciousbehaviors. This transparent mapping helps validate the models decisionsand facilitates targeted countermeasures. Explainability Insights from the Student Model. The Student model,while aiming to reproduce the Teachers performance at lower computationalcost, reveals a slightly different attribution pattern. Its mean predicted prob-ability (0.425) is comparable to the Teachers (0.42), indicating that it haslearned a similarly discriminative latent space. Through the same break-down procedure, the Student model also emphasizes a core set of latent",
  "Mapped FeatureContributionCumulative Prediction": "Intercept+0.4199640.419964Flow IAT Mean+0.2559640.675928Tot Fwd Pkts+0.1221590.798087Flow Duration+0.0183760.816463Fwd Pkt Len Max+0.0340820.850545Flow IAT Std+0.0022650.852810TotLen Fwd Pkts+0.0220640.874874TotLen Bwd Pkts-0.0034030.871471Bwd IAT Tot-0.0288230.842647Fwd IAT Tot+0.0110630.853711Flow Byts/s-0.0674720.786239Flow Pkts/s+0.0509350.837174Bwd Header Len+0.0288900.866064Fwd Header Len+0.0441600.910225Bwd Pkt Len Std+0.0097720.919996Fwd Pkt Len Std-0.0075740.912422Fwd IAT Mean+0.0144290.926851Tot Bwd Pkts-0.0633840.863467Flow IAT Max-0.0099150.853552Bwd Pkt Len Mean+0.0508420.904394Fwd Header Len-0.0052070.899187Flow Duration-0.0046800.894508Flow Byts/s+0.0165310.911038Flow Pkts/s-0.0048260.906212Bwd IAT Mean-0.0801310.826081Fwd IAT Std+0.1158190.941900Flow Byts/s+0.0048550.946755Fwd Pkt Len Std+0.0085060.955260Flow Duration+0.0088060.964066Bwd Header Len-0.0002040.963862Flow IAT Std+0.0126790.976540Bwd Pkt Len Mean+0.0118680.988408Bwd IAT Tot+0.0115760.999984",
  "dimensions mapped to features like Flow Duration, Bwd IAT Std, andFwd IAT Mean; however, it often distributes its attributions more broadly": "For instance, Flow IAT Std can exhibit substantial positive contributions,hinting that variability in packet timing is a decisive indicator for intrusiondetection. In certain cases, negative attributions (e.g., mapped to Fwd IATMax) signal how the Student model can down-weight specific timing-relatedvariables that the Teacher model might consider more crucial. Despite thesenuanced differences, the Student model maintains high accuracy on the CTU-13 dataset. This consistency of essential featurescoupled with some redis-tribution of attributionsdemonstrates effective knowledge transfer. More-over, by retaining interpretability, the Student model remains transparentregarding its learned decision boundaries, further ensuring trustworthinessin operational environments.",
  ": Variable attribution-based explainability results for the CTU-13 dataset, high-lighting key feature contributions for (Left) Teacher and (Right) Student models": "4.5.2. Binary Classification Results on UKM20 Dataset illustrates the explainability outcomes of the Teacher and Stu-dent models for binary classification of anomalies in the UKM20 dataset.Both models exhibit robust predictive performance, with distinct patternsof feature emphasis and latent dimension prioritization, highlighting theirunique strategies for identifying and leveraging critical factors in decision-making. Explainability Insights from the Teacher Model. The Teacher modelachieved a final predicted value of approximately 0.9990, with an initial base-line probability (intercept) of 0.689. Key features such as Source Bytes,",
  "Flow Duration added +0.0794, suggesting irregular timing patterns,which are crucial for identifying anomalies": "Conversely, features like Backward Packet Timing Variability hadminimal or negative contributions (0.0020), demonstrating the Teachermodels ability to down-weight less influential factors.This selective fea-ture attribution enhances the models precision in flagging anomalies. Bymapping each latent dimension to influential features, security analysts canbetter understand the models rationale. Explainability Insights from the Student Model. The Student model,designed to replicate the Teachers performance with lower computationaldemands, produced a final predicted value of 0.999971. While the Studentmodel prioritized many of the same key features as the Teacher model, itexhibited a broader attribution pattern. For example:",
  "Backward Packet Timing Variability, which contributed min-imally or negatively (0.0002), showing its lower importance for thistask": "These contributions highlight the Teacher models ability to identify andfocus on critical features, ensuring precision in multi-class predictions. Bymapping latent dimensions to influential features, the model offers trans-parency and interpretability for multi-class classification, enabling analyststo validate its predictions effectively. Explainability Insights from the Student Model. The Student model,designed to replicate the Teachers performance with reduced computationalcomplexity, produced a final predicted value of 0.956. While prioritizing sev-eral key features similar to the Teacher model, the Student model distributedits attributions more broadly. Key insights include:",
  ". Discussion": "The increasing prevalence of interconnected systems and the concurrentrise in cyber threats highlight the critical need for advanced IDS that pri-oritize accuracy, explainability, and scalability. The proposed LENS-XAIframework addresses these challenges by integrating VAEs, knowledge distil-lation, and variable attribution-based explainability mechanisms into a cohe-sive and lightweight architecture. This study provides compelling evidence,",
  "through extensive evaluations (see ), of the frameworks potential tosafeguard resource-constrained environments such as IoT and edge comput-ing systems": "5.1. Key Findings and ImplicationsSuperior Detection Performance Across Datasets. The LENS-XAIframework demonstrated superior performance across benchmark datasets,consistently achieving high detection accuracy. As detailed in .3 and, the framework achieved an accuracy of 95.34% on the Edge-IIoTsetdataset with the Teacher model and 95.31% with the Student model. Onthe UKM20 dataset, it achieved near-perfect accuracies of 99.92% (Teacher)and 99.80% (Student) as highlighted in . Similarly, for the CTU-13dataset, the framework outperformed other models, achieving 98.42% accu-racy (Teacher) and 98.12% (Student), as shown in . For the NSL-KDDdataset, multi-class classification accuracies of 98.66% (Teacher) and 99.34%(Student) were observed, outperforming other state-of-the-art methods (Ta-ble 8).These results affirm the robustness of the LENS-XAI framework in de-tecting a wide range of cyber threats, including frequent and rare attacktypes. The frameworks ability to maintain low false-positive rates, as evi-dent from confusion matrices in Figures 4 - 7, ensures its practical utility inreal-world scenarios. Enhanced Explainability and Interpretability. The integration of vari-able attribution methods provides a granular understanding of the frame-works decision-making process, as discussed in .5. The Teachermodel identified critical features such as Source Bytes and Flow Dura-tion, with significant contributions to anomaly detection (Tables 12 and 13).Visualization results in Figures 8 and 9 highlight the importance of temporalpatterns in detecting anomalies.The Student model effectively replicated the Teacher models interpretabil-ity, albeit with broader feature attribution patterns. This balance betweenexplainability and computational efficiency makes LENS-XAI suitable forresource-constrained environments, such as IoT and edge devices. Lightweight Design and Scalability. The knowledge distillation approachenabled the Student model to achieve comparable detection performance tothe Teacher model while significantly reducing resource consumption, as de-tailed in . This scalability ensures that LENS-XAI can be deployed in environments with limited computational resources. For instance, TheStudent model achieved up to a 44% reduction in computational overhead(average reduction of 23.47%) while maintaining detection rates above 95%across dataset. Practical Utility in Real-World Applications. The comprehensive eval-uation of LENS-XAI highlights its practicality for real-world deployment.The frameworks ability to balance high performance, scalability, and inter-pretability makes it a valuable tool for cybersecurity. Furthermore, explain-ability analyses presented in Figures 8 and 9 reinforce stakeholder trust byoffering transparent decision-making processes. 5.2. Comparison with Existing MethodsThe LENS-XAI framework advances beyond traditional IDS by com-bining high accuracy, lightweight architecture, and enhanced interpretabil-ity. As demonstrated in Tables 7 and 8, it consistently outperformed modelssuch as RNN, CNN, and Random Forest in terms of accuracy and explain-ability.The use of knowledge distillation further enhances its suitabilityfor resource-constrained environments, setting it apart from black-box ap-proaches like bot-DL and FFS-HTTP, which lack interpretability ().These comparisons underline the versatility and robustness of LENS-XAI asa state-of-the-art IDS, capable of addressing the diverse challenges of moderncybersecurity.",
  ". LimitationsDespite the promising results, this study acknowledges certain limitationsthat require further investigation:": "Dependence on Labeled Data: The reliance on labeled datasetsrestricts the frameworks applicability in scenarios where annotateddata is scarce. Future research could explore unsupervised or semi-supervised learning techniques to mitigate this limitation. Explainability vs.Computational Overhead: While the inclu-sion of explainability mechanisms strengthens transparency, it may in-troduce additional computational costs. Optimizing these mechanismsfor real-time applications is an important avenue for future work. Evaluation on Dynamic Threat Profiles: Expanding the evalua-tion to datasets with evolving and dynamic threat landscapes ()is crucial to ensure the frameworks robustness against emerging cyberthreats.",
  ". Conclusion": "This research introduces a novel intrusion detection framework, LENS-XAI, which integrates lightweight design principles with enhanced inter-pretability and scalability, utilizing a training set comprising 10% of the avail-able data to optimize model efficiency without compromising performance.The framework employs variable attribution methods to provide transparentinsights into its decision-making process while maintaining superior perfor-mance across multiple benchmark datasets.Initial preprocessing ensuresdata consistency, followed by effective feature extraction and dimensionalityreduction to optimize model performance. The Teacher-Student architectureof LENS-XAI achieves a robust balance between high detection accuracyand computational efficiency. Notably, the framework recorded accuracies of95.34%, 99.92%, 98.42%, and 99.34% on the Edge-IIoTset, UKM20, CTU-13,and NSL-KDD datasets, respectively, outperforming state-of-the-art models.The analysis highlights that LENS-XAI not only excels in detecting fre-quent and complex attack types but also addresses challenges such as classimbalance and overfitting, improving generalization to unseen test cases.Furthermore, its scalability and explainability make it an ideal candidatefor real-world deployment in resource-constrained environments like IoT andedge computing systems. The framework reduces computational overheadand time complexity, enhancing its practical utility for safeguarding inter-connected systems.Future work could focus on addressing limitations indetecting rare attack types and exploring ensemble AI systems to furtherimprove intrusion detection in distributed and evolving threat environments.By advancing these areas, LENS-XAI aims to strengthen its role as a next-generation cybersecurity solution.",
  "Mentioned in the manuscript": "I. Alrashdi, K. M. Sallam, M. A. Alrowaily, O. Alruwaili, B. Arain,Fidwatch: Federated incremental distillation for continuous monitoringof iot security threats, Ad Hoc Networks 165 (2024) 103637. doi:10.1016/j.adhoc.2024.103637. F. Ullah, S. Ullah, G. Srivastava, J. C.-W. Lin, Ids-int: Intrusion de-tection system using transformer-based transfer learning for imbalancednetwork traffic, Digital Communications and Networks 10 (1) (2024)190204. doi:10.1016/j.dcan.2023.03.008. E. C. Nkoro, J. N. Njoku, C. I. Nwakanma, J.-M. Lee, D.-S. Kim, Zero-trust marine cyberdefense for iot-based communications: An explainableapproach, Electronics (Switzerland) 13 (2) (2024) 276. doi:10.3390/electronics13020276. K. Fatema, M. Anannya, S. K. Dey, C. Su, R. Mazumder, Securingnetworks: A deep learning approach with explainable ai (xai) and fed-erated learning for intrusion detection, in: Lecture Notes in ComputerScience (including subseries Lecture Notes in Artificial Intelligence andLecture Notes in Bioinformatics), Vol. 15215 LNCS, 2025, pp. 260275.doi:10.1007/978-981-97-8540-7_16. R. Kumar, A. Aljuhani, D. Javeed, P. Kumar, S. Islam, A. K. M. N.Islam, Blockchain and explainable ai for enhanced decision making incyber threat detection, Software - Practice and Experience 54 (8) (2024)13371360. doi:10.1002/spe.3319. D. Javeed, T. Gao, P. Kumar, S. Shoukat, I. Ahmad, R. Kumar, Anintelligent and interpretable intrusion detection system for unmannedaerial vehicles, in: IEEE International Conference on Communications,2024, pp. 19511956. doi:10.1109/ICC51166.2024.10622703.",
  "D. Gaspar, P. Silva, C. Silva, Explainable ai for intrusion detectionsystems: Lime and shap applicability on multi-layer perceptron, IEEEAccess 12 (2024) 3016430175. doi:10.1109/ACCESS.2024.3368377": "M. Nalini, B. Yamini, P. Sinthia, S. Praveena Rachel Kamala, Deep-roughnetid: A robust framework for network anomaly intrusion detec-tion with high detection rates, IETE Journal of Research 70 (9) (2024)71377148. doi:10.1080/03772063.2024.2350932. S. Krishnaveni, S. Sivamohan, B. Jothi, T. M. Chen, M. Sathiya-narayanan, Twinsec-ids: An enhanced intrusion detection system insdn-digital-twin-based industrial cyber-physical systems, Concurrencyand Computation: Practice and Experience (2024). doi:10.1002/cpe.8334. A. Alzubi, O. Darwish, A. Albashayreh, Y. Tashtoush, Cyberattackevent logs classification using deep learning with semantic feature anal-ysis, Computers and Security 150 (2025) 104222. doi:10.1016/j.cose.2024.104222. T. Walczyna, D. Jankowski, Z. Piotrowski, Enhancing anomaly de-tection through latent space manipulation in autoencoders: A com-parative analysis, Applied Sciences 15 (1) (2024) 286. doi:10.3390/app15010286.",
  "tack detection in the internet of vehicles, Results in Engineering 24(2024) 103171. doi:10.1016/j.rineng.2024.103171": "S. R. Sindiramutty, C. E. Tan, S. P. Lau, R. Thangaveloo, A. H. Gharib,Explainable ai for cybersecurity, Advances in Explainable AI Applica-tions for Smart Cities (2024) 3197.doi:10.4018/978-1-6684-6361-1.ch002. S. R. Alotaibi, H. K. Alkahtani, M. Aljebreen, A. Alshuhail, M. K.Saeed, S. A. Ebad, W. S. Almukadi, M. Alotaibi, Explainable artificialintelligence in web phishing classification on secure iot with cloud-basedcyber-physical systems, Alexandria Engineering Journal 110 (2025) 490505. doi:10.1016/j.aej.2024.09.115. R. Zhao, Y. Chen, Y. Wang, Y. Shi, Z. Xue, An efficient and lightweightapproach for intrusion detection based on knowledge distillation, in:Proceedings of the IEEE International Conference on Communications,2021, pp. 18. doi:10.1109/ICC42927.2021.9500574. Y. Chen, S. Al-Rubaye, A. Tsourdos, L. Baker, C. Gillingham,Differentially-private federated intrusion detection via knowledge dis-tillation in third-party iot systems of smart airports, IEEE Interna-tional Conference on Communications 2023-May (2023) 603608. doi:10.1109/ICC45041.2023.10279722. M. Bacevicius, A. Paulauskaite-Taraseviciene, Machine learning algo-rithms for raw and unbalanced intrusion detection data in a multi-classclassification problem, Applied Sciences (Switzerland) 13 (2023) 7328.doi:10.3390/app13127328. S. Roy, J. Li, V. Pandey, Y. Bai, An explainable deep neural frame-work for trustworthy network intrusion detection, in: Proceedings ofthe 2022 10th IEEE International Conference on Mobile Cloud Com-puting, Services, and Engineering (MobileCloud), 2022, pp. 2530.doi:10.1109/MobileCloud55333.2022.00011. U. Ahmed, Z. Jiangbin, A. Almogren, S. Khan, M. T. Sadiq, A. Al-tameem, A. U. Rehman, Explainable ai-based innovative hybrid ensem-ble model for intrusion detection, Journal of Cloud Computing 13 (1)(2024) 150. doi:10.1186/s13677-024-00712-x. N. Moustafa, N. Koroniotis, M. Keshk, A. Y. Zomaya, Z. Tari, Explain-able intrusion detection for cyber defences in the internet of things: Op-portunities and solutions, IEEE Communications Surveys and Tutorials25 (3) (2023) 17751807. doi:10.1109/COMST.2023.3280465. M. A. Yagiz, P. MohajerAnsari, M. D. Pese, P. Goktas, Transform-ing in-vehicle network intrusion detection: Vae-based knowledge dis-tillation meets explainable ai, in: Proceedings of the Sixth Workshopon CPS&IoT Security and Privacy, ACM, 2024, pp. 93103.doi:10.1145/3690134.3694819. T.-T.-H. Le, R. W. Wardhani, D. S. C. Putranto, U. Jo, H. Kim, To-ward enhanced attack detection and explanation in intrusion detectionsystem-based iot environment data, IEEE Access 11 (2023) 131661131676. doi:10.1109/ACCESS.2023.3336678. N. Kostopoulos, D. Kalogeras, D. Pantazatos, M. Grammatikou,V. Maglaris, Shap interpretations of tree and neural network dns clas-sifiers for analyzing dga family characteristics, IEEE Access 11 (2023)6114461160. doi:10.1109/ACCESS.2023.3286313. M. M. Shtayat, M. K. Hasan, R. Sulaiman, S. Islam, A. U. R. Khan,An explainable ensemble deep learning approach for intrusion detectionin industrial internet of things, IEEE Access 11 (2023) 115047115061.doi:10.1109/ACCESS.2023.3323573. S. Sivamohan, S. Sridhar, S. Krishnaveni, Tea-ekho-ids: An intrusiondetection system for industrial cps with trustworthy explainable ai andenhanced krill herd optimization, Peer-to-Peer Networking and Appli-cations 16 (4) (2023) 19932021. doi:10.1007/s12083-023-01507-8. A. Hattak, G. Iadarola, F. Martinelli, F. Mercaldo, A. Santone, Amethod for robust and explainable image-based network traffic clas-sification with deep learning, in:Proceedings of the InternationalConference on Security and Cryptography, 2023, pp. 385393.doi:10.5220/0012083200003555. S. Arisdakessian, O. A. Wahab, A. Mourad, H. Otrok, M. Guizani, Asurvey on iot intrusion detection: Federated learning, game theory, so-cial psychology, and explainable ai as future directions, IEEE Internet",
  "K. Yang, J. Wang, M. Li, An improved intrusion detection method foriiot using attention mechanisms, bigru, and inception-cnn, Scientific Re-ports 14 (1) (2024) 19339. doi:10.1038/s41598-024-70094-2": "W. N. H. Ibrahim, S. Anuar, A. Selamat, O. Krejcar, R. G. Crespo,E. Herrera-Viedma, H. Fujita, Multilayer framework for botnet detec-tion using machine learning algorithms, IEEE Access: Practical Inno-vations, Open Solutions 9 (2021) 4875348768. doi:10.1109/ACCESS.2021.3060778. A. Sharma, H. Babbar, Detecting cyber threats in real-time: A super-vised learning perspective on the ctu-13 dataset, in: 2024 5th Inter-national Conference for Emerging Technology (INCET), 2024, pp. 15.doi:10.1109/INCET61516.2024.10593100. I. Letteri, G. Della Penna, P. Caianiello, Feature selection strategies forhttp botnet traffic detection, in: 2019 IEEE European Symposium onSecurity and Privacy Workshops (EuroS&PW), IEEE, 2019, pp. 202210. doi:10.1109/EuroSPW.2019.00029.",
  "A. Pektas, T. Acarman, Botnet detection based on network flow sum-mary and deep learning, International Journal of Network Management28 (6) (Nov. 2018). doi:10.1002/nem.2039": "S. Taheri, M. Salem, J. S. Yuan, Leveraging image representation of net-work traffic data and transfer learning in botnet detection, Big Data andCognitive Computing 2 (4) (2018) 116. doi:10.3390/bdcc2040037.URL M. Al-Qatf, Y. Lasheng, M. Al-Habib, K. Al-Sabahi, Deep learningapproach combining sparse autoencoder with svm for network intrusiondetection, IEEE Access 6 (2018) 5284352856. doi:10.1109/ACCESS.2018.2869577. B. Ingre, A. Yadav, Performance analysis of nsl-kdd dataset using ann,in: 2015 International Conference on Signal Processing and Commu-nication Engineering Systems, IEEE, 2015, pp. 9296. doi:10.1109/SPACES.2015.7058223. A. Javaid, Q. Niyaz, W. Sun, M. Alam, A deep learning approach for net-work intrusion detection system, in: Proceedings of the 9th EAI Inter-national Conference on Bio-inspired Information and CommunicationsTechnologies, 2016, pp. 2126. doi:10.4108/eai.3-12-2015.2262516. R. Vinayakumar, M. Alazab, K. P. Soman, P. Poornachandran, A. Al-Nemrat, S. Venkatraman, Deep learning approach for intelligent in-trusion detection system, IEEE Access 7 (2019) 4152541550.doi:10.1109/ACCESS.2019.2895334."
}