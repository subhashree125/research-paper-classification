{
  "ABSTRACT": "Brain graphs, which model the structural and functional relation-ships between brain regions, are crucial in neuroscientific and clin-ical applications involving graph classification. However, densebrain graphs pose computational challenges including high run-time and memory usage and limited interpretability. In this paper,we investigate effective designs in Graph Neural Networks (GNNs)to sparsify brain graphs by eliminating noisy edges. While priorworks remove noisy edges based on explainability or task-irrelevantproperties, their effectiveness in enhancing performance with spar-sified graphs is not guaranteed. Moreover, existing approaches oftenoverlook collective edge removal across multiple graphs. To address these issues, we introduce an iterative frameworkto analyze different sparsification models. Our findings are as fol-lows: (i) methods prioritizing interpretability may not be suitablefor graph sparsification as they can degrade GNNs performancein graph classification tasks; (ii) simultaneously learning edge se-lection with GNN training is more beneficial than post-training;(iii) a shared edge selection across graphs outperforms separateselection for each graph; and (iv) task-relevant gradient informationaids in edge selection. Based on these insights, we propose a newmodel, Interpretable Graph Sparsification (IGS), which enhancesgraph classification performance by up to 5.1% with 55.0% feweredges. The retained edges identified by IGS provide neuroscientificinterpretations and are supported by well-established literature.",
  "ACM Reference Format:Gaotang Li, Marlena Duda, Xiang Zhang, Danai Koutra, and Yujun Yan.2023. Interpretable Sparsification of Brain Graphs: Better Practices and": "Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 23, August 610, 2023, Long Beach, CA, USA 2023 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0103-0/23/08. Effective Designs for Graph Neural Networks. In Proceedings of the 29thACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD23), August 610, 2023, Long Beach, CA, USA. ACM, New York, NY, USA,12 pages.",
  "INTRODUCTION": "Understanding how brain function emerges from the communica-tion between neural elements remains a challenge in modern neu-roscience . Over the years, researchers have used brain graphs toencode the correlations of brain activities and uncover interestingconnectivity patterns between brain regions. They find that thetopological properties of brain graphs are useful in predicting vari-ous phenotypes and understanding brain activities ,which account for the wide usage of brain graphs in neuroscientificresearch . Adopting the graph representations (oftentermed \"connectomes\"), many neuroscientific problems can be castas graph problems. In this paper, we focus on end-to-end braingraph classification tasks since many brain graph classificationtasks have meaningful real-life clinical significance, such as provid-ing a non-invasive neuroimaging biomarker for the identificationof certain psychiatric/neurological disorders at an early stage (e.g.autism, Alzheimers disease) .Despite the benefits of modeling brain data as graphs, even well-preprocessed brain graphs pose serious challenges. A functionalMRI-based (fMRI) brain graph, which is usually computed as pair-wise correlations of fMRI time-series data, is fully connected. Theresulting dense graph causes two unavoidable problems. First, itinhibits the use of efficient sparse operations, which leads to largetime and memory consumption when the graphs are large .Second, the dense graph suffers from fMRI-related noise, makingit extremely hard to train a model that learns useful generaliza-tion rules and provides good interpretability . To this end, it iscrucial to make brain graphs more sparse and less noisy. The com-mon practice in neuroscience is to remove the \"weak\" edges, whoseweights are below the predefined threshold . However, directthresholding requires a wide search for the proper threshold ,and the sparsified graphs may lack useful edges and preserve sig-nificant noise. To illustrate it, in , we show the performanceon the original graphs and sparsified graphs obtained using directthresholding in a classification task. It can be seen that direct thresh-olding may drop important edges and/or keep unimportant edges,which leads to a decrease in performance.",
  "Original52.73.7755.43.51Direct thresholding52.05.5154.83.19": "Prior work related to graph sparsification generally falls intotwo categories. The first line of work learns the relative importanceof the edges, which can be used to remove unimportant edges inthe graph sparsification process. These works usually focus oninterpretability explicitly, oftentimes referred to as explainablegraph neural networks (explainable GNNs) . The core ideaembraced by this community is to identify small subgraphs that aremost accountable for model predictions. The relevance of the edgesto the final predictions is encoded into an edge importance mask, amatrix that reveals the relative importance of the edges and can beused to sparsify the graphs. These works show good interpretabilityunder various measures . However, it remains unclear whetherbetter interpretability indicates better performance. The other lineof work tackles unsupervised graph sparsification , withoutemploying any label information. Some methods reduce the numberof edges by approximating pairwise distances , cuts , oreigenvalues . These task-irrelevant methods may discard usefultask-specific edges for predictions. Fewer works are task-relevant,primarily focusing on node classification . Consequently,these works produce different edge importance masks for eachgraph. However, in graph classification, individual masks can leadto significantly longer training time and susceptibility to noise.Conversely, a joint mask emerges as the preferred choice, offeringrobustness against noise and greater interpretability. This work. To assess the quality of the sparsified graphs obtainedfrom interpretable models in the graph classification task, we pro-pose to evaluate the effectiveness of the sparsification algorithmsunder an iterative framework. At each iteration, the sparsificationalgorithms decide which edges to remove and feed the sparsifiedgraphs to the next iteration. We measure the effectiveness of a spar-sification algorithm by computing the accuracy of the downstreamgraph classification task at each iteration. An effective sparsificationalgorithm should acquire the ability to identify and remove noisyedges, resulting in a performance boost in the graph classificationtask after several iterations (.2).We utilize this iterative framework to evaluate two commonpractices used in graph sparsification and graph explainability: (1)obtaining the edge importance mask from a trained model and (2)learning an edge importance mask for each graph individually .For instance, GNNExplainer learns a separate edge importancemask for each graph after the model is trained. Through our empir-ical analysis, we find that these practices are not helpful in graphsparsification, as the sparsified graphs may lead to lower classifica-tion accuracy. In contrast, we identify three key strategies that canimprove the performance. Specifically, we find that (S1) learning ajoint edge importance mask (S2) simultaneously with the train-ing of the model helps improve the performance over the iterations, as it passes task-relevant information through back-propagation.Another strategy to incorporate the task-relevant information isto (S3) initialize the mask with the gradient information from theimmediate previous iteration. This strategy is inspired by the ev-idence in the computer vision domain that gradient informationmay encode data and task-relevant information and may contributeto the explainability of the model .Based on the identified strategies, we propose a new Interpretablemodel for brain Graph Sparsification, IGS. We evaluate our IGSmodel on real-world brain graphs under the iterative frameworkand find that it can benefit from iterative sparsification. IGS achievesup to 5.1% improvement on graph classification tasks with graphs of55.0% fewer edges than the original compared to strong baselines.Our main contributions are summarized as follows: General framework. We propose a general iterative frame-work to analyze the effectiveness of different graph sparsi-fication models. We find that edge importance masks gen-erated from interpretable models may not be suitable forgraph sparsification because they may not improve the per-formance of graph classification tasks. New insights. We find that two practices commonly used ingraph sparsification and graph explainability are not helpfulunder the iterative framework. Instead, we find that learninga joint edge importance mask along with the training ofthe model improves the classification performance duringiterative graph sparsification. Furthermore, incorporatinggradient information in mask learning also boosts the per-formance in iterative sparsification.",
  "In this section, we introduce key notations, provide a brief back-ground on GNNs, and formally define the problem that we investi-gate": "Notations. We consider a set of graphs G. Each graph (V, E) G in this set has nodes, and the corresponding node set and edgeset are denoted as V and E, respectively. The graphs share the sameset of nodes. The set of neighboring nodes of node is denoted asN. We focus on the setting where the input graphs are weighted,and we represent the weighted adjacency matrix of each inputgraph as A R. The node features in are representedby a matrix X R, where its -th row X [, :] represents thefeatures of the -th node, and refers to the dimensionality ofthe node features. For conciseness, we use X()to represent thenode representations/output at the -th layer of a GNN. Given ouremphasis on graph classification problems, we denote the numberof classes as , the set of labels as Y, and associate each graph with a corresponding label Y.",
  "Sparsifying": "Input GraphsOne Input Graph InstanceSparsified Graph : General iterative framework of sparsification. This framework progressively eliminates noisy edges from input braingraphs by learning an edge importance mask for each/all graph(s). The edge importance mask(s) can be generated from awell-trained GNN model or trained simultaneously with a GNN model. Important edges are depicted in orange, while noisyedges are shown in grey. Dashed lines with purple crosses represent the removed edges in the sparsified graphs.",
  "input graph . These gradients are obtained through backpropa-gation and are referred to as the gradient map": "Supervised Graph Classifcation. Given a set of graphs{1,2, , } and their labels {1,2, , } for training, weaim to learn a function : G Y, such that the loss E(L(, )) isminimized, where E denotes expectation, L denotes a loss function,and = () denotes the predicted label of . GNNs for Graph Classification. An -layer GNN model often follows the message-passing framework, whichconsists of three components : (1) neighborhood propagationand aggregation: m()= AGGREGATE(X()[, :], N); (2) combi-nation: X(+1)[, :] = COMBINE(X()[, :], m() ), where AGGREGATE andCOMBINE are learnable functions; (3) global pooling. x = Pooling(X(L) }), where the Pooling function operates on all node repre-sentations, including options like Global_mean, Global_max orother complex pooling functions . The loss is given by =1 GtrainCrossEntropy (Softmax(x ), ), where Gtrain rep-resents the set of training graphs and = |Gtrain|. Though ourframework does not rely on specific GNNs, we illustrate the effec-tiveness of our framework using the GCN model proposed in .The performance of GNN models heavily depends on the qualityof the input graphs. Messages propagated through noisy edges cansignificantly affect the quality of the learned representations .Inspired by this observation, we focus on the following problem: Problem: Interpretable, Task-relevant Graph Sparsification.Given a set of input graphs G = {1,2, , } and the corre-sponding labels Y = {1,2, , }, we seek to learn a set of graph-specific edge importance masks {M1, M2, , M } {0, 1},OR a joint edge importance mask M {0, 1} shared by allgraphs, which can be used to remove the noisy edges and retain themost task-relevant ones. This should lead to enhanced classifica-tion performance on sparsified graphs. Edge masks that effectivelyidentify task-relevant edges are considered to be interpretable.",
  "PROPOSED METHOD: IGS": "In this section, we introduce our proposed iterative framework forevaluating various sparsification methods. Furthermore, we intro-duce IGS, a novel and interpretable graph sparsification approachthat incorporates three key strategies: (S1) joint mask learning, (S2)simultaneous learning with the GNN model, and (S3) utilizationof gradient information. We provide detailed explanations of thesestrategies in the following subsections.",
  "Iterative Framework": "illustrates the general iterative framework. At a high level,given a sparsification method, our framework iteratively removesunimportant edges based on the edge importance masks generatedby the method at each iteration. In detail, the method can generateeither a separate edge importance mask M for each input graph or a joint edge importance mask M shared by all input graphs G ={1,2, }. These edge importance masks indicate the relevanceof edges to the tasks labels. In our setting, we also allow trainingthe masks simultaneously with the model. Ideal edge masks arebinary, where zeros represent unimportant edges to be removed. Inreality, many models (e.g. GNNs ) learn soft edge importancemasks with values between . In each iteration, our frameworkremoves either the edges with zero values in the masks (if binary)or a fixed percentage of edges with the lowest importance scoresin the masks. We present the framework of iterative sparsificationin Algorithm 1, where G denotes the set of sparsified graphs atiteration , and denotes the -th graph in the set G. Though existing works have proposed different ways todefine the \"importance\" of an edge and thus they generate differentsparse graphs, we believe that a direct and effective way to evaluatethese methods is to track the performance of these sparsified graphsunder this iterative framework. The trend of the performance re-veals the relevance of the remaining edges to the predicted labels.",
  "ABCDE": "A0.70.40.20.3 0.8 B0.40.60.30.9 0.4 C0.20.30.40.1 0.9 D0.30.90.10.3 0.7 E0.80.40.90.7 0.6 D A C B E D A C B E D A C B E D A C B E D A C B E D A C B E D A C B E D A C B E D A C B E D A C B E D A C B E D A C B E",
  "Removed Edge": "Thickness - Value of Edge Weight : Training process of IGS. At iteration , IGS takes a set of input graphs and initializes its joint edge importance maskusing the joint gradient map from the previous iteration. It trains the GNN model and the edge importance mask together,followed by sparsifying all input graphs using the obtained mask. Normal training is then conducted on the sparsified graphs.The gradient information is later extracted by computing a joint gradient map. Finally, IGS feeds the sparsified graphs to thenext iteration and uses the joint gradient map to initialize the subsequent joint edge importance mask. IGS is model-agnosticand can be seamlessly integrated with existing GNN models. as shown in . Each entry in M represents if the correspond-ing edge in the original input graph should be kept (value 1) ornot (value 0). Directly learning the discrete edge mask is hard asit cannot generate gradients to propagate back. Thus, at each it-eration, we learn a soft version of M, where each entry is within and reflects the relative importance of each edge. Consider-ing the symmetric nature of the adjacency matrix for undirectedbrain graphs, we require the learned edge importance mask to besymmetric. We design the soft edge importance mask as ( + ), where is a matrix to be learned and is the Sigmoid function. Agood initialization of can boost the performance and acceleratethe training speed. Thus, we initialize this matrix with the gradientmap (.2.2) from the previous iteration (Step 5 in ).Furthermore, following , we regularize the training of by re-quiring ( +) to be sparse. Thus we apply a 1 regularization on( + ). In summary, we have the following training objective:",
  "OUTPUT: G with smallest": "where denotes the Hadamard product; L is the Cross-Entropyloss; is the regularization coefficient. We optimize the joint maskacross all training samples in a batch-training fashion to achieveour objective of learning a shared mask. Subsequently, we convertthis soft mask into an indicator matrix by assigning zero values tothe lowest percentage of elements:",
  "The indicator matrix M can then be used to sparsify the inputgraph through an element-wise multiplication, e.g. = M": "3.2.2Joint Gradient Information (S3). Inspired from the evidencein the computer vision domain that gradient information may en-code data and task-relevant information and may contribute tothe explainability of the model , we utilize the gradientinformation, i.e., gradient maps to initialize and guide the learningof the edge importance mask. Step 4 in illustrates the general idea of generating a jointgradient map by combining gradient information from each traininggraph. Each training graph has gradient maps (), =1, 2, ,, each corresponding to the output in class ().Instead of using the saliency maps , which consider only thegradient maps from the predicted class, we leverage all the gradientmaps as they provide meaningful knowledge. For 1, . . . , Gtrain, we compute the unified mask of class j as the sum of theabsolute values of each gradient map, represented as",
  "EMPIRICAL ANALYSIS": "In this section, we aim to answer the following research ques-tions using our iterative framework: (Q1) Is learning a joint edgeimportance mask better than learning a separate mask for eachgraph? (Q2) Does simultaneous training of the edge importancemask with the model yield better performance than training themask separately from the trained model? (Q3) Does the gradientinformation help with graph sparsification? (Q4) Is our method IGSinterpretable?",
  "Setup": "4.1.1Dataset. We use the WU-Minn Human Connectome Project(HCP) 1200 Subjects Data Release as our benchmark dataset toevaluate our method and baselines . The pre-processed braingraphs can be obtained from ConnectomeDB . These braingraphs are derived from the resting-state functional magnetic reso-nance imaging (rs-fMRI) of 812 subjects, where no explicit task isbeing performed. Predictions using rs-fMRI are generally harderthan task-based fMRI . The obtained brain graphs are fully con-nected, and the edge weights are computed from the correlationof the rs-fMRI time series between each pair of brain regions .The parcellation of the brain is completed using Group-ICA with100 components , which results in 100 brain re-gions comprising the nodes of our brain graphs. Additionally, a setof cognitive assessments were performed on each subject, whichwe utilized as cognitive labels in our prediction tasks. Specifically,",
  "we utilize the scores from the following cognitive domains as ourlabels, which incorporate age adjustment :": "PicVocab (Picture Vocabulary) assesses language/vocabularycomprehension. The respondent is presented with an audiorecording of a word and four photographic images on thecomputer screen and is asked to select the picture that mostclosely matches the words meaning. ReadEng(OralReadingRecognition)assesseslan-guage/reading decoding. The participant is asked to readand pronounce letters and words as accurately as possible.The test administrator scores them as right or wrong. PicSeq (Picture Sequence Memory) assesses the Open ofepisodic memory. It involves recalling an increasinglylengthy series of illustrated objects and activities presentedin a particular order on the computer screen.",
  "ListSort (List Sorting) assesses working memory and requiresthe participant to sequence different visually- and orally-presented stimuli": "CardSort (Dimensional Change Card Sort) assesses the cog-nitive flexibility. Participants are asked to match a series ofbivalent test pictures (e.g., yellow balls and blue trucks) tothe target pictures, according to color or shape. Scoring isbased on a combination of accuracy and reaction time. Flanker (Flanker Task) measures a participants attention andinhibitory control. The test requires the participant to focuson a given stimulus while inhibiting attention to stimuliflanking it. Scoring is based on a combination of accuracyand reaction time. More details can be found in ConnectomeDB . These scores arecontinuous. In order to use them for graph classification, we assignthe subjects achieving scores in the top third to the first class andthe ones in the bottom third to the second class.",
  "Baselines. We outline the baselines used in our experiments": "Grad-Indi . This method obtains the edge importance maskfor each individual graph from a trained GNN model. In contrastto the gradient information (Strategy S3) proposed in .2.2,a gradient map of each sample is generated for the predicted class: T = () () . Later, the edge importance maskM for is generated based on Equation (2). Grad-Joint. We adapt Grad-Indi to incorporate our proposedstrategies (S1+S3) and learn an edge importance mask shared byall graphs from a trained GNN model. Specifically, we leverage themethod described in .2.2 that generates the joint gradientmap to obtain the joint importance mask. Grad-Trained. We further modify Grad-Indi to train the jointedge mask concurrently with the GNN training (S2). We also use thejoint gradient map (.2.2) to initialize the edge importancemask (Strategies S1+S2+S3). The main differences of Grad-Trainedfrom IGS are that: (1) it does not require symmetry of the edge mask;(2) it does not require edge mask sparsity (without1 regularization).",
  "edge important mask for all graphs (Strategy S1)": "GNNExplainer-Trained. Adapted from , this method simul-taneously trains a joint edge important mask and the GNN model(Strategies S1+S2). Compared with IGS, this method does not usegradient information. BrainNNExplainer . This method (also known as IBGNN)trains a joint edge important mask for all graphs after the GNN istrained. It is slightly different from GNNExplainer-Joint in termsof objective functions. We follow the original setup in . BrainGNN . This method does not explicitly perform thegraph sparsification task, but uses node pooling to identify impor-tant subgraphs. It learns to preserve important nodes and all theconnections between them. We follow the original setup in . 4.1.3Training Setup. To fairly evaluate different methods underthe iterative framework, we adopt the same GNN architecture ,hyper-parameter settings, and training framework. We set the num-ber of convolutional layers to four, the dimension of the hiddenlayers to 256, the dropout rate to 0.5, the batch size to 16, the opti-mizer to Adam, the learning rate to 0.001, and the regularizationcoefficient to 0.0001. Note that though we use the GNN from ,IGS is model-agnostic, and we provide the results of other back-bone GNNs in . For each prediction task, we shuffle thedata and take four different data splits. The train/val/test split is0.7/0.15/0.15. To reduce the influence of imbalances, we manuallyensure each split has equal labels. In each iteration, we adopt earlystopping and set the patience to 100 epochs. We stop trainingif we cannot observe a decrease in validation loss in the latest 100epochs. We fix the removing ratio % to be 5% per iteration. In theiterative sparsification, we run a total of 55 iterations and use thevalidation loss of the sparsified graphs as the criterion to selectthe best iteration (Step 3 in ). We present the average andstandard deviation of test accuracies over four splits, using themodel obtained from the best iteration. The code is available at",
  "(Q1-Q3) Graph Classification under theIterative Framework": "In , we present the results of IGS with the eight baselinesmentioned in section 4.1.2. The first row represents the predictiontask we study; the second row represents the performance averagedacross four different splits using the original graph; and the restof the rows denote the performance of other baselines. Notably,for better comparison across different baselines, the last columnshows the average rank of each method. Below we present ourobservations from :First, learning a joint mask contributes to a better performancethan learning a mask for each graph separately. We can start bycomparing the performance between GNNExplainer-Joint andGNNExplainer-Indi as well as Grad-Joint and Grad-Indi. Theperformance disparity between the methods in each pair is notableand consistent across all prediction tasks. Notably, Grad-Joint(rank: 4.33) outperforms Grad-Indi (rank: 7.67) by a considerablemargin, while GNNExplainer-Joint (rank: 4.67) ranks significantly",
  "Interpretable Sparsification of Brain Graphs:Better Practices and Effective Designs for Graph Neural NetworksKDD 23, August 610, 2023, Long Beach, CA, USA": "Key take-aways. Overall, in addition to the IGS models superiorclassification performance, our results suggest that the iterativepruning of the IGS edge masks during training does indeed re-tain important and neurologically meaningful edges while remov-ing noisy connections. While it has been shown in the literaturethat resting-state connectivity can be used to predict task perfor-mance , the ability of the IGS model to sparsify the restingstate brain graph to clearly task-relevant edges for prediction oftask performance further underscores the interpretability of theresultant edge masks.",
  "GCN (Original Graphs)52.73.7755.43.5151.92.1852.12.5556.66.5048.915.83-": "Grad-Indi53.41.6553.79.4849.33.7148.76.9446.94.6550.72.767.67Grad-Joint57.83.3458.23.0850.16.1748.95.1052.45.0251.53.944.33Grad-Trained55.55.2960.01.3649.54.1250.22.2056.37.6651.64.033.83GNNExplainer-Indi49.73.8655.34.0648.93.2944.83.7652.13.8647.31.588.33GNNExplainer-Joint56.47.9455.87.3352.02.8450.13.0153.58.3250.35.814.67GNNExplainer-Trained56.83.1059.22.9651.43.5151.22.0156.04.7150.92.013.17BrainNNExplainer57.03.7755.75.7650.31.4749.84.4752.43.6350.93.954.83BrainGNN53.03.2547.53.0050.73.1350.93.1350.11.1249.06.226.67IGS57.83.1060.12.7853.04.6651.82.1257.05.4952.11.971.00 higher than GNNExplainer-Indi (rank: 8.33). Using a joint maskinstead of individual masks can provide up to 6.7% boost in accuracy,validating our intuition in section 3.2.2 that a joint mask is morerobust to sample-wise noise.Second, training the mask and the GNN model simultaneouslyyields better results than obtaining the mask from the trainedmodel. We can see this by comparing the performance betweenthe Trained and the Joint variants of Grad and GNNExplainer.Changing from post-training to joint-training can provide up to3.4% performance improvements, as demonstrated in the ReadEngtask by the two variants of GNNExplainer. Even though in sometasks the post-training approach may outperform the trained ap-proach (e.g. Grad-Joint and Grad-Trained in the PicVocab task),the trained approach has a higher average rank than the post-training approach (e.g. 3.83 vs. 4.33 for Grad and 3.17 vs. 4.67 forGNNExplainer). In addition, the better performance of IGS overBrainNNExplainer also demonstrates the effectiveness of obtain-ing the edge mask during training rather than after training.Third, incorporating gradient information helps improve clas-sification performance. We can see this by first comparingthe performance of Grad-Joint and Grad-Trained against theoriginal graphs. The use of gradient information can provideup to 5.1% higher accuracy, though the improvement dependson the task. Furthermore, since the main difference betweenGNNExplainer-Trained and IGS lies in the use of gradient infor-mation, the consistent superior performance of IGS strengthensthis conclusion.Fourth, we compare the performance of the baselines against theperformance of the original graphs (second row). Grad-Indi and GNNExplainer-Indi are implementations that faithfullyfollow their original formulation or are provided directly by theauthors. These two approaches fail to achieve any performanceimprovements through iterative sparsification, with the exceptionof Grad-Indi in the task of PicVocab and ReadEng. This raises thequestion of whether these existing instance-level approaches canidentify the most meaningful edges in noisy graphs. These methodsmay be vulnerable to severe sample-wise noise. On the contrary,with our suggested modifications, the joint and trained versions can remove the noise and provide up to 5.1% performance boostcompared to the base GCN method applied to the original graphs.However, the improvement is dataset-dependent. For instance,GNNExplainer-Trained provides decent performance boosts inPicVocab, ReadEng, and Flanker, but degrades in PicSeq, ListSort,and CardSort.Finally, our proposed approach, IGS, achieves the best perfor-mance across all prediction tasks, demonstrated by its highest rankamong all methods. Compared with the performance on the origi-nal graphs, IGS can provide consistent performance boost acrossall prediction tasks, with the exception of ListSort, which is a chal-lenging task that no baseline surpasses the original performance.Furthermore, using the sparsified graph identified by IGS generallyresults in less variance in accuracy and leads to better stability whencompared to the original graphs, with the exception on the PicSeqtask. In addition, the superior performance of IGS over BrainGNNdemonstrates the effectiveness of using edge importance masks asopposed to node pooling. Graph Sparsity. In , we present the final average sparsity ofthe graphs obtained by IGS over four data splits. We observe thatwith significantly fewer edges retained, IGS can still achieve up to5.1% performance boost. : Final sparsity of the sparsified brain graphs identifiedby IGS averaged over different splits. The initial sparsity is50% by thresholding. IGS can remove more than half of theedges while achieving up to 5.1% performance boost.",
  "KDD 23, August 610, 2023, Long Beach, CA, USAGaotang Li, Marlena Duda, Xiang Zhang, Danai Koutra, & Yujun Yan": "AD CO DF DA FP LA SO V1 V2 ADCO DFDA FP LASO V1V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 ADCO DFDA FP LASO V1V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 ADCO DFDA FP LASO V1V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 AD CO DF DA FP LA SO V1 V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 AD CO DF DA FP LA SO V1 V2 0.00 0.05 0.10 0.15 0.20 0.25 0.30 AD CO DF DA FP LA SO V1 V2 AD CO DF DA FP LA SO V1 V2 0.00 0.01 0.02 0.03 0.04 0.05 0.06 0.07 : Weighted brain network edge masks at both node (top row) and subnetwork level (bottom row - computed as theaverage of corresponding edges) for PicVocab task. Early, middle, and final phases of training are depicted from left to right,and high-importance subnetworks are highlighted in red. We find that IGS gradually removes noisy edges and its final edgeimportance mask can provide high-quality interpretations. Highlighted (Orange) label names represent the regions that aremeaningful in this task. Brain network labels and abbreviations: Auditory (AD), Cingulo-Opercular (CO), Dorsal Attention(DA), Default (DF), Frontoparietal (FP), Language (LA), Somatomotor (SO), Visual 1 (V1), Visual 2 (V2). largest overlap between regions identified in the Cole-Anticevicparcellation . We then obtained the edge masks from the best-performing iteration of each prediction task and assessed thehighest-weighted edges in each mask. Results. Since our IGS model performed best in the language-relatedprediction tasks, ReadEng and PicVocab, we focus our interpretabil-ity analysis on this domain. There is ample evidence in the neu-roscience literature that supports the existence of an intrinsic lan-guage network that is perceptible during resting state ;thus, it is unsurprising that our rs-fMRI based brain networks arepredictive of language task performance. It has also been well es-tablished for over a century that the language centers (includingBrocas area, Wernickes area, the angular gyrus, etc.) are character-istically left-lateralized in the brain . In both ReadEng andPicVocab, the majority of the highest weighted edges retained inthe masks involved brain regions localized to the left hemisphere,falling in line with the expectations for a language task. PicVocab. Figures 3 and 4 depict the progression of the edge masksat both the node and subnetwork level over the training iterationstowards optimal edge mask in both the ReadEng and PicVocab tasks.Evaluating the edge masks at the subnetwork level offers valuableinsights into which functional connections are most important forthe prediction of each task. The PicVocab edge mask homed inon functional connections involving the Cingulo-Opercular (CO)network, specifically between CO and the Dorsal Attention (DA), Visual1 (V1), Visual2 (V2) and Frontoparietal (FP) networks. The COnetwork has been shown to be implicated in word recognition ,and its synchrony with other brain networks identified here mayrepresent the stream of neural processing related to the PicVocabtask, in which subjects respond to an auditory stimulus of a wordand are prompted to choose the image that best represents theword. Connectivity between the Auditory (AD) and V2 networks isalso evident in the PicVocab edge mask, suggesting the upstreamintegration of auditory and visual stimuli involved in the PicVocabtask are also predictive of task performance. ReadEng. The IGS model also found edge mask connections be-tween the V1 network and the CO, Language (LA) and DA networks,as well as CO-LA and CO-AD connections, to be most predictive ofReadEng performance. This task involves the subject reading aloudwords presented on a screen. From our results, it follows that theability of Vis1 to integrate with networks responsible for languageprocessing (LA and CO) and attention (DA), as well as the capacityfor functional synchrony between the language-related networks(CO-LA), would be predictive of overall ReadEng performance. Theimportance of the additional CO-AD connectivity identified by ourmodel also suggests that the ability of the CO language networkto integrate with auditory centers may be involved in the neuralprocesses responsible for the proper pronunciation of the wordsgiven by visual cues.",
  "Graph Explainability": "Our work is related to explainable GNNs given that we identifyimportant edges/subgraphs that account for the model predictions.Some explainable GNNs are perturbation-based, where the goalis to investigate the relation between output and input variations.GNNExplainer learns a soft mask for the nodes and edges,which explains the predictions of a well-trained GNN model. Sub-graphX explains its predictions by efficiently exploring differ-ent subgraphs with a Monte Carlo tree search. Another approachfor explainable GNNs is surrogate-based; the methods in this cat-egory generally construct a simple and interpretable surrogatemodel to approximate the output of the original model in certainneighborhoods . For instance, GraphLime considers theN-hop neighboring nodes of the target node and then trains anonlinear surrogate model to fit the local neighborhood predic-tions; RelEx first uses a GNN to fit the BFS-generated datasetsand then generates soft masks to explain the predictions; PGM-Explainer generates local datasets based on the influence ofrandomly perturbing the node features, shrinks the size of thedatasets via the Grow-Shrink algorithm, and employs a Bayesiannetwork to fit the datasets. In general, most of these methods focuson the node classification task and make explanations for a singlegraph, which is not applicable to our setting. Others only applyto simple graphs, which cannot handle signed and weighted braingraphs . Additionally, most methods generate explanationsafter a GNN is trained. Though some methods achieve decent re-sults in explainability-related metrics (e.g. fidelity scores ), itremains unclear whether their explanations can necessarily removenoise and retain the important part of the original graph, whichimproves the classification accuracy.",
  "Graph Sparsification": "Compared to the explainable GNN methods, graph sparsifica-tion methods explicitly aim to sparsify graphs. Most of the ex-isting methods are unsupervised . Conventional methods re-duce the size of the graph through approximating pairwise dis-tances , preserving various kinds of graph cuts , node de-gree distributions , and using some graph-spectrum basedapproachse . These methods aim at preserving the struc-tural information of the original input graph without using the labelinformation, and they assume that the input graph is unweighted.Relatively fewer supervised works have been proposed. For exam-ple, NeuralSparse builds a parametrized network to learn a k-neighbor subgraph by limiting each node to have at most edges.On top of NeuralSparse, PTDNet removes the k-neighbor as-sumption, and instead, it employs a low-rank constraint on thelearned subgraph to discourage edges connecting multiple com-munities. Graph Condensation proposes to parameterize thecondensed graph structure as a function of condensed node fea-tures and optimizes a gradient-matching training objective. Despitethe new insights offered by these methods, most of them focusexclusively on node classification, and their training objectives arebuilt on top of that. A work that shares similarity to our proposedmethod, IGS, is BrainNNExplainer (also known as IBGNN). It isinspired by GNNExplainer and obtains the joint edge mask in apost-training fashion. On the other hand, our proposed method, IGS,trains a joint edge mask along with the backbone model and incor-porates gradient information in an iterative manner. Another lineof work leverages node pooling to identify important subgraphs,and learns to preserve important nodes and all the connections be-tween them. One representative work is BrainGNN . However,the connections between preserved nodes are not necessarily allinformative, and some may contain noise.",
  "Saliency Maps": "Saliency maps are first proposed to explain the deep convolutionalneural network models in image classification tasks . Specif-ically, the method proposes to use the gradients backpropagatedfrom the predicted class as the explanations. Recently, introducesthe concept of saliency maps to graph neural networks, employingsquared gradients to explain the underlying model. Additionally, suggests using graph saliency to identify regions of interest(ROIs). In general, the gradients backpropagated from the outputlogits can serve as the importance indicators for model predictions.In this work, inspired by the line of saliency-related works, weleverage the gradient information to guide our model.",
  "CONCLUSIONS": "In this paper, we studied neural-network-based graph sparsifica-tion for brain graphs. By introducing an iterative sparsificationframework, we identified several effective strategies for GNNs tofilter out noisy edges and improve the graph classification perfor-mance. We combined these strategies into a new interpretable graphclassification model, IGS, which improves the graph classificationperformance by up to 5.1% with 55% fewer edges than the originalgraphs. The retained edges identified by IGS provide neuroscientificinterpretations and are supported by well-established literature.",
  "ACKNOWLEDGEMENTS": "We thank the anonymous reviewers for their constructive feedback. Thismaterial is based upon work supported by the National Science Foundationunder IIS 2212143, CAREER Grant No. IIS 1845491, a Precision Health In-vestigator Award at the University of Michigan, and AWS Cloud Credits forResearch. Data were provided [in part] by the Human Connectome Project,WU-Minn Consortium (PIs: D. Van Essen and K. Ugurbil; 1U54MH091657)funded by the 16 NIH Institutes and Centers that support the NIH Blue-print for Neuroscience Research; and by the McDonnell Center for SystemsNeuroscience at Washington University. Any opinions, findings, and con-clusions or recommendations expressed in this material are those of the",
  "Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, andBeen Kim. 2018. Sanity checks for saliency maps. Advances in neural informationprocessing systems 31 (2018)": "Bijaya Adhikari, Yao Zhang, Sorour E Amiri, Aditya Bharadwaj, and B AdityaPrakash. 2017. Propagation-based temporal network summarization. IEEE Trans-actions on Knowledge and Data Engineering 30, 4 (2017), 729742. Ahmed Alqaraawi, Martin Schuessler, Philipp Wei, Enrico Costanza, and NadiaBerthouze. 2020. Evaluating saliency map explanations for convolutional neuralnetworks: a user study. In Proceedings of the 25th International Conference onIntelligent User Interfaces. 275285. Salim Arslan, Sofia Ira Ktena, Ben Glocker, and Daniel Rueckert. 2018. Graphsaliency maps through spectral convolutional networks: Application to sex clas-sification with brain connectivity. In Graphs in Biomedical Image Analysis andIntegrating Medical Imaging and Non-Imaging Modalities: Second InternationalWorkshop, GRAIL 2018 and First International Workshop, Beyond MIC 2018, Held inConjunction with MICCAI 2018, Granada, Spain, September 20, 2018, Proceedings 2.Springer, 313.",
  "Christian F Beckmann and Stephen M Smith. 2004. Probabilistic independentcomponent analysis for functional magnetic resonance imaging. IEEE transactionson medical imaging 23, 2 (2004), 137152": "Ccile Bordier, Carlo Nicolini, and Angelo Bifone. 2017. Graph analysis andmodularity of brain functional connectivity networks: searching for the optimalthreshold. Frontiers in neuroscience 11 (2017), 441. Paulo Branco, Daniela Seixas, and Sao L Castro. 2020. Mapping language withresting-state functional magnetic resonance imaging: A study on the functionalprofile of the language network. Human Brain Mapping 41, 2 (2020), 545560.",
  "Moo K Chung. 2018. Statistical challenges of big brain network data. Statistics &probability letters 136 (2018), 7882": "Hejie Cui, Wei Dai, Yanqiao Zhu, Xiaoxiao Li, Lifang He, and Carl Yang. 2021.Brainnnexplainer: An interpretable graph neural network framework for brainnetwork based disease analysis. arXiv preprint arXiv:2107.05097 (2021). Talya Eden, Shweta Jain, Ali Pinar, Dana Ron, and C Seshadhri. 2018. Provableand practical approximations for the degree distribution using sublinear graphsamples. In Proceedings of the 2018 World Wide Web Conference. 449458. Bruce Fischl. 2012. FreeSurfer. Neuroimage 62, 2 (2012), 774781. Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George EDahl. 2017. Neural message passing for quantum chemistry. ICML (2017). Matthew F Glasser, Timothy S Coalson, Emma C Robinson, Carl D Hacker, JohnHarwell, Essa Yacoub, Kamil Ugurbil, Jesper Andersson, Christian F Beckmann,Mark Jenkinson, et al. 2016. A multi-modal parcellation of human cerebral cortex.Nature 536, 7615 (2016), 171178. Matthew F Glasser, Stamatios N Sotiropoulos, J Anthony Wilson, Timothy SCoalson, Bruce Fischl, Jesper L Andersson, Junqian Xu, Saad Jbabdi, MatthewWebster, Jonathan R Polimeni, et al. 2013. The minimal preprocessing pipelinesfor the Human Connectome Project. Neuroimage 80 (2013), 105124.",
  "Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representationlearning on large graphs. Advances in neural information processing systems 30(2017)": "Christopher J Honey, Olaf Sporns, Leila Cammoun, Xavier Gigandet, Jean-Philippe Thiran, Reto Meuli, and Patric Hagmann. 2009. Predicting humanresting-state functional connectivity from structural connectivity. Proceedings ofthe National Academy of Sciences 106, 6 (2009), 20352040. Seunghoon Hong, Tackgeun You, Suha Kwak, and Bohyung Han. 2015. Onlinetracking by learning discriminative saliency map with convolutional neuralnetwork. In International conference on machine learning. PMLR, 597606.",
  "Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, and Been Kim. 2019. Abenchmark for interpretability methods in deep neural networks. Advances inneural information processing systems 32 (2019)": "Qiang Huang, Makoto Yamada, Yuan Tian, Dinesh Singh, and Yi Chang. 2022.Graphlime: Local interpretable model explanations for graph neural networks.IEEE Transactions on Knowledge and Data Engineering (2022). Jie Lisa Ji, Marjolein Spronk, Kaustubh Kulkarni, Grega Repov, Alan Anticevic,and Michael W Cole. 2019. Mapping the human brains cortical-subcorticalfunctional network organization. Neuroimage 185 (2019), 3557.",
  "Yike Liu, Tara Safavi, Abhilash Dighe, and Danai Koutra. 2018. Graph summa-rization methods and applications: A survey. ACM computing surveys (CSUR) 51,3 (2018), 134": "Dongsheng Luo, Wei Cheng, Wenchao Yu, Bo Zong, Jingchao Ni, Haifeng Chen,and Xiang Zhang. 2021. Learning to drop: Robust graph neural network viatopological denoising. In Proceedings of the 14th ACM international conference onweb search and data mining. 779787. Han Lv, Zhenchang Wang, Elizabeth Tong, Leanne M Williams, Greg Zaharchuk,Michael Zeineh, Andrea N Goldstein-Piekarski, Tali M Ball, Chengde Liao, andMax Wintermark. 2018. Resting-state functional MRI: everything that nonexpertshave always wanted to know. American Journal of Neuroradiology 39, 8 (2018),13901399. Daniel S Marcus, John Harwell, Timothy Olsen, Michael Hodge, Matthew FGlasser, Fred Prior, Mark Jenkinson, Timothy Laumann, Sandra W Curtiss, andDavid C Van Essen. 2011. Informatics and data mining tools and strategies forthe human connectome project. Frontiers in neuroinformatics 5 (2011), 4. Maarten Mennes, Clare Kelly, Xi-Nian Zuo, Adriana Di Martino, Bharat B Biswal,F Xavier Castellanos, and Michael P Milham. 2010. Inter-individual differencesin resting-state functional connectivity predict task-induced BOLD activity. Neu-roimage 50, 4 (2010), 16901701. Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan EricLenssen, Gaurav Rattan, and Martin Grohe. 2019. Weisfeiler and leman go neural:Higher-order graph neural networks. In Proceedings of the AAAI conference onartificial intelligence, Vol. 33. 46024609.",
  "David Peleg and Alejandro A Schffer. 1989. Graph spanners. Journal of graphtheory 13, 1 (1989), 99116": "Phillip E Pope, Soheil Kolouri, Mohammad Rostami, Charles E Martin, and HeikoHoffmann. 2019. Explainability methods for graph convolutional neural net-works. In Proceedings of the IEEE/CVF conference on computer vision and patternrecognition. 1077210781. Jonathan D Power, Alexander L Cohen, Steven M Nelson, Gagan S Wig,Kelly Anne Barnes, Jessica A Church, Alecia C Vogel, Timothy O Laumann,Fran M Miezin, Bradley L Schlaggar, et al. 2011. Functional network organizationof the human brain. Neuron 72, 4 (2011), 665678.",
  "Dardo Tomasi and Nora D Volkow. 2012. Resting functional connectivity oflanguage networks: characterization and reproducibility. Molecular psychiatry17, 8 (2012), 841854": "Kenneth I Vaden, Stefanie E Kuchinsky, Stephanie L Cute, Jayne B Ahlstrom,Judy R Dubno, and Mark A Eckert. 2013. The cingulo-opercular network providesword-recognition benefit. Journal of Neuroscience 33, 48 (2013), 1897918986. David C Van Essen, Kamil Ugurbil, Edward Auerbach, Deanna Barch, Timothy EJBehrens, Richard Bucholz, Acer Chang, Liyong Chen, Maurizio Corbetta, San-dra W Curtiss, et al. 2012. The Human Connectome Project: a data acquisitionperspective. Neuroimage 62, 4 (2012), 22222231.",
  "Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerfulare graph neural networks? arXiv preprint arXiv:1810.00826 (2018)": "Yujun Yan, Milad Hashemi, Kevin Swersky, Yaoqing Yang, and Danai Koutra.2021. Two Sides of the Same Coin: Heterophily and Oversmoothing in GraphConvolutional Neural Networks. arXiv preprint arXiv:2102.06462 (2021). Yujun Yan, Jiong Zhu, Marlena Duda, Eric Solarz, Chandra Sripada, and DanaiKoutra. 2019. Groupinn: Grouping-based interpretable neural network for clas-sification of limited, noisy brain data. In Proceedings of the 25th ACM SIGKDDinternational conference on knowledge discovery & data mining. 772782. Fengyu Yang and Chenyan Ma. 2022. Sparse and Complete Latent Organizationfor Geospatial Semantic Segmentation. 2022 IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR) (2022), 17991808. Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec.2019. Gnnexplainer: Generating explanations for graph neural networks. Ad-vances in neural information processing systems 32 (2019). Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and JureLeskovec. 2018. Hierarchical graph representation learning with differentiablepooling. Advances in neural information processing systems 31 (2018).",
  "AIGS WITH OTHER BACKBONE GNNS": "In , we present the results of IGS evaluated on different GNNbackbones (noted by - IGS) and compare it against the originalperformance (noted by Original Graphs). Specifically, we considerthree additional GNN models: GraphSAGE , GraphConv ,and GIN . The experimental and hyperparameter settings followthose in .1. Compared with the performance of the orig-inal graphs, the sparsified graphs obtained from IGS consistentlycontribute to performance gains across all GNN backbones andprediction tasks. It provides an average of 4.72% increase in the testaccuracies for GraphSage, an average of 1.92% increase in the testaccuracies for GraphConv, and an average of 1.45% increase in thetest accuracies for GIN. This demonstrates that the improvementsachieved by IGS are model-agnostic.",
  "BADDITIONAL STUDIES ONINTERPRETABILITY": "In , we provide the interpretability analysis for the ReadEngtask, following the same setting as . The ReadEng taskinvolves the subjects reading aloud words presented on a screen. Ascan be seen in , the IGS model effectively identifies the sig-nificance of interactions between the visual (Vis1) network and theCingulo-Opercular (CO), Language (LA), and Dorsal Attention (DA)networks for this prediction task. Furthermore, it elucidates thatthe functional synchrony between the language-related networks(CO-LA, CO-AD) is accountable for this task.",
  "GIN (Original Graphs)55.85.4256.46.9449.93.5352.62.8455.03.0048.53.83GIN - IGS59.35.8356.75.5451.03.2854.15.7055.06.4750.84.80": "AD CO DF DA FP LA SO V1 V2 ADCO DFDA FP LASO V1V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 ADCO DFDA FP LASO V1V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 ADCO DFDA FP LASO V1V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 AD CO DF DA FP LA SO V1 V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 AD CO DF DA FP LA SO V1 V2 0.0 0.1 0.2 0.3 0.4 0.5 AD CO DF DA FP LA SO V1 V2 AD CO DF DA FP LA SO V1 V2 0.00 0.05 0.10 0.15 0.20 0.25 0.30"
}