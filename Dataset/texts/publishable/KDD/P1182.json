{
  "Abstract": "Query autocomplete (QAC) also known as ty-peahead, suggests list of complete queries asuser types prefix in the search box. It is oneof the key features of modern search enginesspecially in e-commerce. One of the goals oftypeahead is to suggest relevant queries to userswhich are seasonally important. In this paperwe propose a neural network based natural lan-guage processing (NLP) algorithm to incorpo-rate seasonality as a signal and present end toend evaluation of the QAC ranking model. In-corporating seasonality into autocomplete rank-ing model can improve autocomplete relevanceand business metric.",
  "Introduction": "Query autocomplete (QAC) is a common featurein most modern search engines. It refers to thetask of suggesting complete queries given the pre-fix consisting of limited number of characters (Caiet al., 2016). Goal of QAC is to help users for-mulate their query or predict users intent. Stud-ies have shown that it can significantly reduce thenumber of characters typed, thus reducing physicaland cognitive overload (Shokouhi and Radinsky,2012; Zhang et al., 2015). An autocomplete sys-tem typically consists of two steps: Matching andRanking: Matching refers to the task of generat-ing candidates using some form of string matchingor retrieval techniques using data structures suchas prefix trees. In the second step (Ranking) thematched suggestions are ordered according to theirexpected likelihood (Shokouhi, 2013).The focus of this paper is Ranking step, specifi-cally, generation of the seasonality scores for eachquery such that it can be generated offline and incor-porated in the autocomplete ranking model. Sea-sonality plays an important role in e-commercesearch. Likelihood of users searching for seasonal queries in that particular season is higher than thenon-seasonal queries. For example, in winter, usersare more likely to search for winter related querieslike winter gloves or winter hats than generic ver-sion of gloves or hats. Therefore it makes senseto rank them higher during winter season. Sinceseasonal queries is mostly searched during specificpart of the year they do not have very high aggre-gate popularity score. So, the common practice ofranking queries by their aggregate popularity scorecan overshadow this temporal factor.In this paper, we define the querys seasonalityscore based on query volume similar to the ideamentioned in (Yang et al., 2021) and propose asimple feed forward neural network architectureto predict score given the query and month. Themodel learns relationship between query tokensand the time period specified in the training dataand can predict seasonality scores for new queries.This score can be generated for all the queries re-gardless of whether it is head, torso or tail and canbe computed offline. It can then be integrated inthe QAC ranking model to reflect seasonality in thesuggested queries and their ranking. We also showthe improvement in relevance and business metricsusing offline evaluation and online experiments.",
  "(1)": "where f(q) denotes the number of times the queryq appears in the search log Q and C(p) is a set ofquery completions that start with the prefix p. Un-der the MPC model, the candidates are ranked bytheir past popularity and the scores do not changeas long as the same query log Q is used. It isassumed here that the current query popularity dis-tribution will remain the same as that previouslyobserved.Time sensitive QAC approaches have been stud-ied in (Shokouhi and Radinsky, 2012; Whiting andJose, 2014; Strizhevskaya et al., 2012). Shokouhiand Radinsky (2012) analyzed why it is hard forMostPopularCompletion (MPC) based approachto handle queries whose popularity may changeover a period of time. To account for such tempo-ral behavior, they propose a time sensitive QACranking model. Here the default aggregate can-didate scores are replaced with forecasted valuescomputed by time-series models based on queryhistory. In (Whiting and Jose, 2014), the authoruses predicted popularity based on short-range timeperiod regression models to rank the suggestions.In addition, Jiang et al. (2017) proposed a hybridQAC model combining periodicity with burst trendto predict future popularity of queries. They useDiscrete Fourier Transform to find the periodic be-havior of each querys popularity. Cai et al. (2014)proposed a hybrid QAC model which considers pre-dicted query popularity and user-specific context.The predicted query popularity is defined basedon long-term time series analysis plus recent trendbased on regression model.Seasonality in queries has been studied before. Shokouhi (2011) used time series decompositiontechniques to identify seasonal queries in the con-text of web search. Vlachos et al. (2004) built timeseries for each query and phrase in the query logsand detected significant periodicities and burst insequences. A recent work on seasonal relevance inecommerce by Yang et al. (2021) leverages deeplearning based language modeling task to learn andassign seasonal relevance scores to items. Thesescores are used as signals in search ranking.In this paper, our work focuses on time-sensitiveauto-completion in QAC ranking. The primary dif-ference between prior work and our work is that we use a neural network model to assign seasonal-ity score to queries. Benefit of the deep learningbased NLP approach is that it can learn from largeamount of queries present in the search logs andlearn to model the relationship between query to-kens and time of the year (month in our case). Thisenables the feasibility to predict the seasonalityfor unseen or rare queries with limited historicaldata. E-commerce search logs typically follow longtail distribution, and such characteristics make lan-guage model based deep learning techniques moredesirable since the queries in QAC will have com-prehensive coverage for the seasonality score.Application of deep learning in the context ofQAC has been studied before such as (Park andChiba, 2017; Yuan and Kuang, 2021). However, thedirection of work is orthogonal to ours. Park andChiba (2017) proposed a neural language model togenerate a queries for unseen or rare prefixes, andYuan and Kuang (2021) proposed deep pairwiselearning to rank model that employs contextual andbehavioral features to rank the queries by minimiz-ing pairwise loss.",
  "Seasonality": "We conduct our study for the queries in our searchlogs. Queries tend to show seasonality patterns,which is demonstrated by the peak and off-peaktraffic during different periods of the year. Forexample, in November and December queries re-lated to Thanksgiving and Christmas have highertraffic. In auto-complete, our goal is to assign ahigher weight to these queries according to theirseasonalities.",
  ",(2)": "where tqm denotes the traffic of query q in monthm, and tm is the overall traffic of the month.An advantage of the above equation is that, itenforces the value to be between 0 and 1 for eachquery - month pair. This allows us to compare sea-sonality component of each query independently, regardless of the aggregate popularity of the query.Also, normalizing query volume in the given monthtqm by total query volume in that month tm takescare to a certain extent of changing consumershopping pattern overall or external circumstancesacross different time period in the year. indicates the trend that is captured bythe above Eq. (2) in the year for sample querieswinter hats and fathers day gift.",
  "Modeling seasonality": "Seasonality for a given query q in the month mcan be estimated from data through Vqm . How-ever, it has couple of limitations. First, it can onlybe computed for queries which have traffic infor-mation available. Second, it can be noisy due tofactors like the query being tail/torso, sparse data,and other external scenarios.To take care of cold start and reduce noise dueto the above mentioned issues, we build a neuralnetwork to model the seasonality values based onthe query text q, month m and Vqm which is definedin the previous section. q and m is the input to theneural network and Vqm is the target value. Themodel can be represented by a function f() : (q,m) Sqm, and f() is learnt by minimizing themean square error",
  "Training Dataset Generation": "We use search query logs to create the trainingdataset. It is a log of every single query the searchplatform has seen in the past. Firstly, we computemonthly query volume for each query tqm and filterout queries that have query volume below certainthreshold say K. Then we aggregate monthly queryvolume of all search queries tm. Finally, using theEq. (2) we compute Vqm. This is normalized andscaled to a value between 0 to 1 using monthlyand yearly search traffic. After the thresholdingand some random sampling, our training datasetconsist of about 337,000 distinct queries.",
  "B 100D0.002186B 300D0.0024142B 300D0.00215": "dimensional pre-trained Glove embedding (Pen-nington et al., 2014). This layer is set as trainable.We use dropout ratio of 0.2 in between the lay-ers to reduce overfitting, it was obtained via hyperparameter tuning. The layers in between use reluas non-linear activation function. Finally, the out-put layer is a single neuron with linear activationfunction. The intuition behind the architecture isto capture relevancy of the given query and monthfor building a regression model which can predictVqm. To select number of layers, dropout and thedimensions of Glove embedding, we performed hy-per parameter tuning and used mean square erroras the evaluation metric. We were able to obtainoptimal mean square error using the configurationof the architecture as described above.Adam optimizer and mean square error lossfunction are used for training the model.In table 1, we show the loss metric for 100 and300 dimensional Glove embedding pretrained with6B and 42B tokens (Pennington et al., 2014). Wereport the numbers for configuration of the dropoutparameters for which we obtained the best mse loss.The neural network model can be further im-proved by potentially introducing attention layer.Another way to model seasonality is to build a se-quence to sequence deep learning model and have itpredict twelve numbers for a given query which cor-respond to seasonality values for the twelve monthsin a year. We leave the evaluation of these methodsas future work. Note that the objective of this paperis to define seasonality and evaluate if integratingit with the auto-complete ranking model improvesthe overall ranking performance.",
  "System Implementation for QAC rankingmodel": "Our auto complete system consists of two compo-nents: L1 and L2 ranker (a re-ranking model). L1ranker is linear time series model trained on a his-torical search log. It is trained to predict a linearcombination of number of add-to-carts, clicks andimpressions a given query would receive in upcom-ing weeks. This runs offline in a batch manner andhelps us select initial corpus of queries which weindex into our auto-complete platform. L2 rankeris a runtime re-rank model: a function of the offlinescore generated by L1 ranker and the user sessionlevel feature. It performs re-ranking and showstop ten suggestion to users. This function couldbe a simple linear model or a more sophisticatedfunction estimated through deep learning models.In L2 ranker we incorporate the seasonality valuepredicted by the deep learning model as a signal.The L1 ranker already captures seasonality andtime sensitivity to a certain extent. By integrat-ing the seasonality signal into the re-rank modelL2, we are interested to observe the additional im-provements to the ranking. We obtained the weightfor the seasonality signal in the L2 ranker by fine-tuning it on evaluation datasets. For offline andonline evaluation, the control group is the QACmodel where L2 ranker does not have seasonalitysignal and the test group is the QAC model whereL2 ranker includes the seasonality signal. shows ranking of QAC suggestions forthe prefix \"memo\" a week before the memorialday in the US. We can see suggestions related tothe memorial day event is ranked higher in testcompared to the control goup. It is to be notedthat extra suggestions relevant to the event showup because we re-rank top N suggestions obtainedfrom L1 ranker to display top K to the user, whereN > K.",
  "Offline evaluation": "The offline evaluation system uses queries fromhistorical search logs to query the auto-completesystem and records the suggestions for each charac-ter of a given query. From the search logs we knowthe ground truth query i.e. final query user hadsubmitted. Thus we can compute reciprocal rankfor each search request. We use this technique tocompute mean reciprocal rank (MRR) from about400,000 prefixes generated from randomly sampled50,000 search queries for four platforms: desktop,",
  "Conclusion and Future Work": "In this work, we introduced a method to makeauto-complete suggestions seasonally relevant us-ing deep learning based NLP algorithm to predictseasonality for a given query and month. The pre-dicted score is integrated as a feature in the auto-complete learning-to-rank model. We also presentend-to-end evaluation of auto-complete rankingmodel and measure the gains in mean reciprocalrank (MRR).As future work, we intend to explore follow-ing areas: First, generation of seasonality scoreat a more granular level such as biweekly, weeklyintervals or include day of the week as signal inthe ranking model. Second, making use of trans-former based architecture to model the seasonalityof queries. Third, study the interaction of seasonal-ity and query category, and include seasonality atthe category level in the learning-to-rank model.",
  "Danyang Jiang, Honghui Chen, and Fei Cai. 2017. Ex-ploiting querys temporal patterns for query auto-completion. Mathematical problems in engineering,2017": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean. 2013. Distributed representa-tions of words and phrases and their compositionality.Advances in neural information processing systems,26. Dae Hoon Park and Rikio Chiba. 2017. A neural lan-guage model for query auto-completion. In Proceed-ings of the 40th International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval, pages 11891192. Jeffrey Pennington, Richard Socher, and Christopher DManning. 2014. Glove: Global vectors for word rep-resentation. In Proceedings of the 2014 conferenceon empirical methods in natural language processing(EMNLP), pages 15321543. Milad Shokouhi. 2011. Detecting seasonal queries bytime-series analysis. In Proceedings of the 34th in-ternational ACM SIGIR conference on Research anddevelopment in Information Retrieval, pages 11711172.",
  "Milad Shokouhi. 2013. Learning to personalize queryauto-completion. In Proceedings of the 36th inter-national ACM SIGIR conference on Research anddevelopment in information retrieval, pages 103112": "Milad Shokouhi and Kira Radinsky. 2012.Time-sensitive query auto-completion. In Proceedings ofthe 35th international ACM SIGIR conference onResearch and development in information retrieval,pages 601610. Alisa Strizhevskaya, Alexey Baytin, Irina Galinskaya,and Pavel Serdyukov. 2012. Actualization of querysuggestions using query logs. In Proceedings of the21st International Conference on World Wide Web,pages 611612. Michail Vlachos,Christopher Meek,ZografoulaVagena, and Dimitrios Gunopulos. 2004. Identify-ing similarities, periodicities and bursts for onlinesearch queries. In Proceedings of the 2004 ACMSIGMOD international conference on Managementof data, pages 131142."
}