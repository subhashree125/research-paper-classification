{
  "ABSTRACT": "Time series modeling is crucial for many applications, however,it faces challenges such as complex spatio-temporal dependenciesand distribution shifts in learning from historical context to predicttask-specific outcomes. To address these challenges, we proposea novel approach using an agentic Retrieval-Augmented Gener-ation (RAG) framework for time series analysis. The frameworkleverages a hierarchical, multi-agent architecture where the mas-ter agent orchestrates specialized sub-agents and delegates theend-user request to the relevant sub-agent. The sub-agents utilizesmaller, pre-trained language models (SLMs) customized for specifictime series tasks through fine-tuning using instruction tuning anddirect preference optimization, and retrieve relevant prompts froma shared repository of prompt pools containing distilled knowledgeabout historical patterns and trends to improve predictions on newdata. Our proposed modular, multi-agent RAG approach offers flex-ibility and achieves state-of-the-art performance across major timeseries tasks by tackling complex challenges more effectively thantask-specific customized methods across benchmark datasets.KEYWORDS",
  "Time Series Analysis, Retrieval Augmented Generation": "1INTRODUCTIONTime series modeling underpins a vast spectrum of real-world ap-plications, including demand planning , anomaly detection ,inventory management , energy load forecasting , weathermodeling , and many others. However, it is not without its chal-lenges. High dimensionality, non-linearity, sparsity, and distribu-tion shifts all pose significant hurdles. Successfully navigating thesechallenges in time series analysis applications necessitates both con-siderable domain knowledge and the design of neural network archi-tectures tailored to address task-specific goals, leading to better per-formance. In contrast to task-specific approaches, which employ dif-ferent architecture designs for time series analysis, foundational pre-trained large language models (LLMs), such as OpenAIs GPT-4 and Googles Gemini , with their strong generalization andlogical reasoning capabilities, have shown remarkable versatilityacross a broad spectrum of natural language processing (NLP) tasks,requiring minimal fine-tuning or only a few demonstrationsfor adaptation to niche tasks. Open-source, small-scale pretrainedlanguage models (SLMs), such as Google Gemma () and MetaLLaMA (), offer cost-effective domain customization throughParameter Efficient Fine-Tuning (PEFT) () techniques us-ing task-specific labeled datasets. Additionally, these smaller mod-els can be further aligned with human preferences using DirectPreference Optimization (DPO) , a fine-tuning technique thatutilizes paired preference data, such as datasets of preferred anddispreferred responses. However, SLMs may lack the reasoningand generalization capabilities of large-scale proprietary language models. The potential of foundational SLMs designed for univer-sal time series applications (a single-model-fits-all approach), suchas diverse time series tasks like classification, anomaly detection,forecasting, imputation, and others, remains largely unexploredbut holds great promise. This approach contrasts sharply withthe traditional approach of using customized, task-specific meth-ods () for time series modeling for various applications.Adapting SLMs designed for NLP tasks for time series modeling tocapture trends and patterns within the complex data, though uncon-ventional, offers a clear possibility for providing unique insights.However, this is a challenging task as SLMs are trained primarily ontext corpora, which operates on discrete tokens, while time seriesdata is inherently continuous. Furthermore, SLMs may lack theinherent ability to detect and interpret time series patterns andtrends like seasonality, cyclicity, or outliers, due to the absence ofrelated pretraining knowledge. Moreover, current LMs designedfor time series analysis () rely on a fixed-length windowof past observations to generate predictions, which may be inade-quate for capturing complex patterns and trends present in timeseries data, thus hindering accurate modeling. Smaller window sizesmay capture local patterns but miss broader trends, while largerwindow sizes can capture more context but may overlook finerdetails. In recent times, Retrieval-Augmented Generation (RAG)or Retrieval-Augmented Language Modeling (RALM)combines pre-trained language models with information retrievalfrom external knowledge bases to augment text generation capabil-ities for open-ended question-answering(ODQA) tasks or forimproved language modeling for text summarization, completionwith improved accuracy. While regular RAG methods augment gen-eration with retrieved knowledge for ODQA tasks, Agentic RAGstake this further by being instruction-following agents that cantackle complex goals through multi-step reasoning and iterativerefinement cycles using repeated retrievals over a knowledge baseto ensure the final response aligns with the end user request. In thiswork, we propose an Agentic RAG framework for time series anal-ysis to improve task-specific outcomes by addressing challengeslike distributional shifts, fixed window limitations in time seriesdata. illustrates the framework. Our Agentic RAG frame-work presents a hierarchical, multi-agent architecture composed ofa master (top-level) agent and specialized sub-agents customizedfor specific time series tasks. The top-level agent acting as theorchestrator analyzes the incoming user request, determines itsnature and complexity, and then routes (or delegates) it to the cor-responding task-specific sub-agent to produce the desired output.Similarly to how regular RAG frameworks retrieve relevant infor-mation from external knowledge bases like documents, databases,or access the real world through APIs, this Agentic RAG frameworkleverages distinct prompt pools as internal knowledge bases foreach sub-agent focused on specific time series tasks. As specialized",
  "30th, ACM KDD August 25 - 29, 2024, 2024, Barcelona, SpainChidaksh Ravuru, Sagar Srinivas Sakhinana, and Venkataramana Runkana": "attention) allows SLMs to process unseen long-range dependen-cies, enabling SLMs to naturally handle extended text and maintainperformance. It outperforms fine-tuning methods on multiple NLPbenchmarks, demonstrating a significant step forward for SLMs inmanaging long text sequences. Nevertheless, fine-tuning general-purpose SLMs on task-specific data and objectives can still providesignificant performance gains and allow for customization and adap-tation to the unique challenges and requirements of different timeseries analysis tasks. Instruction-tuning of SLMs captures complextask-specific spatio-temporal dependencies and improves predic-tion accuracy. We perform instruction-tuning of SLMs with an im-proved context length (32K tokens) using parameter-efficientfine-tuning (PEFT) techniques on their associated specific tasks(e.g., forecasting, imputation) using the corresponding time-seriesdatasets. This approach could significantly enhance the effective-ness of SLMs in processing extensive time-series data. We leverageDirect Preference Optimization (DPO; ), which involves ran-domly masking 50 % of the data and performing binary classificationtask to predict the corresponding correct task-specific outcomes.This is done to steer the predictions of the SLMs toward morereliable outcomes in the specific context of time series analysis,favoring preferred responses over dispreferred responses.4EXPERIMENTSDatasets: We evaluate the proposed Agentic-RAG frameworkon four tasks: forecasting, classification, anomaly detection, andimputation. To comprehensively evaluate the framework perfor-mance against several baselines, we conducted experiments usingboth univariate and multivariate benchmark datasets across mul-tiple time series tasks. The variants include Agentic-RAG withSelfExtend-Gemma-2B-instruct, Gemma-7B-instruct, and Llama3-8B-instruct. We utilized several real-world traffic-related datasets(PeMSD3, PeMSD4, PeMSD7, PeMSD7(M), PeMSD8) obtained fromthe Caltrans Performance Measurement System (PeMS) for fore-casting, classification, and imputation. To ensure consistency withprior research, these datasets are preprocessed by aggregating30-second data points into 5-minute averages. Additionally, publiclyavailable traffic prediction datasets (METR-LA, PEMS-BAY) are utilized, with data aggregated into 5-minute intervals, resultingin 288 observations per day. provides comprehensive detailsregarding the spatiotemporal multivariate datasets. For anomaly de-tection, we evaluate the proposed Agentic-RAG framework on pub-licly available multivariate datasets, conducting a comprehensivebenchmark comparison against baseline methods. providesan overview of the datasets used in this study. SWaT and WADI1 arereal-world datasets on water treatment facilities and distributionnetworks, respectively. SMAP and MSL are expert annotated open-source datasets of telemetry data sourced from NASA. TheTennessee Eastman Process (TEP)2 dataset is a simulated industrialbenchmark designed for process monitoring and control, compris-ing 20 distinct fault types. The HAI3 dataset comprises time-seriesdata from an industrial testbed for detecting adversarial attacks onindustrial control systems, involving steam-turbine power genera-tion and pumped-storage hydropower generation processes, with",
  "AgentCls": ": The figure illustrates the proposed agentic RAGframework, designed to handle diverse time series analysistasks. The framework employs a hierarchical, multi-agentarchitecture. A master agent receives end-user questions androutes them to appropriate specialized sub-agents based onthe specific time series task (e.g., forecasting, imputation,classification, anomaly detection). The sub-agents utilize pre-trained SLMs fine-tuned on task-specific datasets using tech-niques like instruction tuning and direct preference opti-mization to capture spatio-temporal dependencies withinand across the time series datasets. Each sub-agent main-tains its own prompt pool as key-value pairs, which storesrelevant historical knowledge related to specific trends andpatterns within its respective specialized domain. This al-lows the sub-agents to leverage related past experiences forimproved task-specific predictions on new, similar data, andis then relayed back to the user through the master agent. In summary, the master agent orchestrates sub-agents, selectsthe most appropriate sub-agent, and allocates the task to the special-ized sub-agent. The sub-agent retrieves relevant information froma shared knowledge base of prompt pools and generates an out-put based on the retrieved information. The differentiable promptpools for each sub-agent, acting as specialized dynamic knowledgerepositories, provide the necessary historical context and under-standing to effectively analyze new input data for their designatedtasks. The master agent gathers responses from the chosen sub-agent and synthesize these responses to produce a comprehensiveanswer for the end-user query. The hierarchical, multi-agent archi-tecture for time series analysis offers key advantages. It enablesmodularity, flexibility, and accuracy by allowing specialized sub-agents to focus on specific tasks, be updated independently, andbe dynamically allocated by the meta-agent to generate compre-hensive results. Extensive empirical studies demonstrate that theAgentic-RAG framework achieves performance on par with, oreven surpassing, state-of-the-art methods across multiple time se-ries analysis tasks for both univariate and multivariate datasets. Themulti-agent approach tackles the diverse and complex challenges oftime series analysis, unlike a single, universal agent that attemptsto be a jack-of-all-trades for all time series tasks.2PROBLEM FORMULATIONConsider a time series dataset characterized by univariate time se-ries, with sequential data collected over timestamps, representedas a data matrix X R . Each row in this matrix represents aunivariate time series, and each column corresponds to data col-lected at a specific timestamp. To refer to data from a specific timeseries or timestamp, we use subscripts and superscripts, respec-tively. For instance, = X,: denotes the data from the -th timeseries, and = X:, denotes the data at timestamp .2.1ForecastingWe utilize a sliding window of size , to construct time seriessubsequences = +1: R , which have been observedover previous -steps prior to current time step to predict aboutthe future values for the next -steps, +1 = +1:+ R .2.2Missing Data ImputationWe utilize a binary mask matrix M {0, 1} , where , = 0indicates that the value , is missing, and , = 1 indicates thatthe value is observed in the data matrix X R . Missing data canfollow random or block patterns across the univariatetime series and timestamps. We utilize observed values Xobs =XM to estimate the missing values Xmiss = X (1M). denoteselement-wise multiplication. We utilize a sliding window of size over the observed samples Xobs, to construct subsequences obs =+1:obs R , which have been observed over previous -stepsprior to the current time step . These observed samples are used topredict the missing values for the next -steps, +1miss = +1:+missR by leveraging spatio-temporal dependencies within the data.2.3Anomaly DetectionAssuming the time series dataset exhibits normal behavior duringthe initial train timestamps, any pattern deviating from the normalbehavior in subsequent timestamps > train is anomalous. Dataobserved after train is considered the test dataset. We use a slidingwindow to construct samples from previous time steps R",
  "+1(1)": "where denotes the number of time points in the movingaverage calculation. T denotes the time points in the validationset. We set the anomaly detection threshold(Th) as the movingaveraged maximum anomaly value for time + 1, +1 over thevalidation data. During inference, time points with an anomalyscore above the threshold were flagged as anomalies.2.4ClassificationWe perform unsupervised -means clustering, identifying () op-timal clusters or regimes and assigning cluster labels C R toeach time point in the data matrix X R . Then, a slidingwindow approach is employed to predict the cluster labels for thenext steps +1 = +1:+ R based on the observed sample = +1: R over the previous time steps.3PROPOSED METHOD The proposed framework offers a novel approach to time series anal-ysis by leveraging a hierarchical, multi-agent architecture. It com-prises a master agent that coordinates specialized sub-agents, eachdedicated to a specific time series task such as forecasting, anomalydetection, or imputation. These sub-agents employ pre-trained lan-guage models and utilize prompt pools as internal knowledge bases,storing key-value pairs representing historical patterns and trends.By retrieving relevant prompts from these pools, the sub-agents canaugment their predictions with contextual knowledge about relatedpast patterns, enabling them to adapt to diverse trends within com-plex time series data. The frameworks modular design, combinedwith the strengths of individual sub-agents, allows for improvedperformance across various time series analysis tasks, surpassingthe limitations of traditional fixed-window methods.3.1Dynamic Prompting MechansimCurrent time series methods typically utilize past data within apredefined window length to understand historical trends and pre-dict task-specific outcomes. However, this approach may not beoptimal because there is no universally ideal window length forall time series data. A larger window length might obscure short-range dependencies, while a smaller window length might fail tocapture long-range dependencies . Existing methods fail to capturethe full complexity of diverse trends and patterns within the com-plex data required for accurate time series modeling. Adjusting thewindow length in real-world scenarios can be challenging and com-putationally expensive. Achieving this goal is an ambitious task,given the current state of research in this field. To address the chal-lenges of non-stationarity and distributional shifts in real-worlddata, we utilize a differentiable dynamic prompting mechanism.This mechanism allows traditional time series methods to access related past knowledge by retrieving the same group of promptsfrom the prompt pool for effective adaptive learning on new, similarinput data. The dynamic prompting approach utilizes a shared poolof prompts stored as key-value pairs. For time series applications,each prompt is represented by a key vector encoding the essentialglobal characteristics associated with that prompt. The correspond-ing value matrix contains specific knowledge related to those trendsor patterns, such as seasonality, cyclicality, irregularities, and othereffects. The key vector acts as an identifier or query vector to re-trieve relevant prompts from the pool based on similarity to theinput new data, providing a form of conditioning or context abouthistorical patterns to enhance the predictions. This allows the timeseries methods to effectively leverage encoded knowledge frompast experiences, enhancing their predictions by recognizing andapplying learned patterns from the shared prompt pool to the newinput data. The pool of prompts P contains a set of distinctkey-value pairs as follows:P = (1, 1), (2, 2), . . . , (, )Here, is the total number of prompts in the pool, R is the key vector of the -th prompt, and R is the corre-sponding prompt value matrix with length and dimensionality. In order to retrieve the most relevant prompts for a given inputtime series = +1: R, we first linearly project it into -dimensional embeddings R. We then utilize a score-matchingfunction to measure the similarity between the input and eachprompt key: , =",
  "| |||": "where computes the cosine similarity between the input em-bedding and the prompt key k. The top- prompts with thehighest similarity scores are selected, where 1 . LetJ = 1, 2, . . . , be the set of indices corresponding to the top-most relevant prompts retrieved from the pool P for the giveninput time series . The selected prompts, along with the originalinput, are concatenated to form the input embedding as follows:",
  "=1; . . . ; ;": "where s R(+1). We linearly project s to -dimensionalrepresentation as follows:s = swhere R(+1) is a learnable weight matrix. In sum-mary, it aims to improve time series modeling efficiency on thetask-specific performance by allowing the framework to recognizeand apply learned patterns across non-stationarity datasets withdistributional shifts via the shared prompt representation pool.3.2Fine-Tuning/Preference Optimization SLMs Current pretrained SLMs, such as Googles Gemma and MetasLlama-3 models, are designed with a context length of 8K tokens.However, they struggle to process long input sequences that ex-ceed their pretraining context window. This is because the limitedlength of the context window during pretraining restricts their ef-fectiveness during inference when dealing with longer texts. SLMswith an improved context length can better capture long-termspatio-temporal dependencies and complex patterns that unfoldover extended periods, which is essential for accurate predictionsand understanding seasonal or cyclic trends. We build upon recentwork to improve how SLMs handle long sequences without fine-tuning. A two-tiered attention mechanism (grouped and neighbor",
  ": Statistical summary of benchmark datasets. is thelength of subsequences or historical window length": "Evaluation Metrics: For forecasting and imputation tasks, theperformance of the proposed framework is evaluated using MAE,RMSE, and MAPE metrics on the original scale of the time seriesdata. For classification tasks, we use accuracy. For anomaly detec-tion, we utilize the standard evaluation metrics of precision (P in%), recall (R in %), and F1-score (F1 in %). We utilize a multi-metricapproach for a fair and rigorous comparison with baseline models.To do this, we compute the confusion matrix: true positive (TP) forcorrectly detected anomalies, false negative (FN) for undetectedanomalies, true negative (TN) for correctly identified normal points,and false positive (FP) for normal points mistakenly identified asanomalies. Precision (TP/(FP + TP)) represents the proportion ofcorrectly detected anomalies among all identified anomalies, whilerecall (TP / (FN + TP)) represents the proportion of all true anom-alies that were correctly detected. The F1-score is calculated as theharmonic mean of precision and recall. The threshold for identify-ing anomalies is set to the highest anomaly score(refer to .3) from the validation dataset. For the SWaT and WADI datasets,which contain contiguous anomaly segments, we adopt the pointadjustment strategy to flag the entire subsequence as ananomaly if the model predicts one. On the Tennessee Eastmandataset, we utilize the Fault Detection Rate (FDR, in %), defined asthe ratio of the number of faults detected to the total number offaults that occur, to evaluate the effectiveness of our framework.Experimental Settings: To reduce memory footprint and com-putational complexity, we segment the time series datasets using asliding window technique with a predefined historical window sizeto obtain time series subsequences (smaller, overlapping sequencesof a fixed length). We performed instruction-tuning(fine-tuning)of the small-scale language models, such as SelfExtend-InstructLLaMA 3-8B, Gemma-2B, and Gemma-7B models using the PEFTtechnique such as QLoRA, on their specific associated timeseries tasks using corresponding datasets. We set the followinghyperparameters: a batch size of 16, a sequence length of 32K, alearning rate of 1e-5, training for 15 epochs, 500 warmup steps, aweight decay of 0.01, and a gradient accumulation of 2 steps. Weused the AdamW optimizer and a linear scheduler to adjust thelearning rate during training. We utilized a 4-bit quantization forQLoRA. The QLoRA hyperparameters include the low-rank() of",
  "Best performance in bold. Second-best with underlines(except Agentic-RAG framework Variants)": "16, an of 32, and a dropout of 0.05 to ensure efficient parameterupdates. We performed preference tuning on the SLMs using DirectPreference Optimization(DPO) along with QLoRA, minimizingthe binary cross-entropy (BCE) loss with the following hyperpa-rameters: a learning rate of 5.0e-7 with a cosine scheduler and agradient accumulation of 2 steps. was set to 0.2 to better alignSLMs with the desired preferences. We conducted training for 3epochs using the AdamW optimizer, with a batch size of 8 for boththe training and evaluation phases. These hyperparameters werechosen to balance the trade-off between SLMs performance onthe specific time series task and computational resources. Opti-mal hyperparameter values are highly task-specific and dependon the dataset and language model architecture. Extensive experi-mentation are crucial to find the best configurations. We discussthe hyperparameter optimization results in appendix. To ensureefficient and consistent framework training, we preprocess time-series data by standardizing each variable (zero mean, unit variance)and calculate evalution metric on the original scale. We leverageNVIDIA GPUs and PyTorch for accelerated training, enabling theuse of small-scale models and datasets. For robust evaluation, weconduct multiple independent runs and report ensemble averages.5RESULTSTables 3-4 present a performance comparison of the Agentic-RAGframework variants with baseline methods on seven benchmark datasets (PeMSD3, PeMSD4, PeMSD7, PeMSD7M, PeMSD8, METR-LA, and PEMS-BAY) on the forecasting task. We report experimentalresults from a previous study for a fair and rigorous compari-son. Tables 5-6 show the performance of Agentic-RAG frameworkvariants on time-series anomaly detection on benchmark datasets.We present experimental results of baseline methods from earlierstudies . Our proposed framework outperforms base-line methods across the benchmark datasets, showing significantimprovements on the forecasting and anomaly detection tasks. Wepresent experimental results on missing data imputation and classi-fication tasks in the appendix. Experimental results on univariatedatasets across all time series tasks are discussed in the appendix.6CONCLUSIONIn this work, we propose an Agentic RAG framework to address thechallenges of distribution shifts, and fixed-length subsequences intime series analysis. The framework overcomes these challenges byleveraging a hierarchical, multi-agent architecture with specializedsub-agents for various time series tasks. Each sub-agent utilizes aprompt pool as its internal knowledge base to store historical pat-terns and trends. The sub-agent retrieves relevant prompts and uti-lizes the corresponding knowledge to improve predictions on new,unseen data. This modular design with task-specific sub-agentsand knowledge augmentation outperforms traditional methods inhandling complex time series analysis tasks.",
  "AI@Meta. 2024. Llama 3 Model Card. (2024)": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shot learners. Advances in NeuralInformation Processing Systems 33 (2020), 18771901. Defu Cao, Furong Jia, Sercan O Arik, Tomas Pfister, Yixiang Zheng, Wen Ye,and Yan Liu. 2024. TEMPO: Prompt-based Generative Pre-trained Transformerfor Time Series Forecasting. In The Twelfth International Conference on LearningRepresentations.",
  "Wei Cao, Dong Wang, Jian Li, Hao Zhou, Lei Li, and Yitan Li. 2018.Brits:Bidirectional recurrent imputation for time series. Advances in neural informationprocessing systems 31 (2018)": "Chao Chen, Karl Petty, Alexander Skabardonis, Pravin Varaiya, and ZhanfengJia. 2001. Freeway performance measurement system: mining loop detector data.Transportation Research Record 1748, 1 (2001), 96102. Zekai Chen, Dingshuo Chen, Xiao Zhang, Zixuan Yuan, and Xiuzhen Cheng.2021. Learning graph structures with transformer for multivariate time seriesanomaly detection in iot. IEEE Internet of Things Journal (2021). Jeongwhan Choi, Hwangyong Choi, Jeehyun Hwang, and Noseong Park. 2022.Graph neural controlled differential equations for traffic forecasting. In Proceed-ings of the AAAI Conference on Artificial Intelligence, Vol. 36. 63676374. Paul F Christiano, Jan Leike, Tom Brown, Miljan Martic, Shane Legg, and DarioAmodei. 2017. Deep reinforcement learning from human preferences. Advancesin neural information processing systems 30 (2017).",
  "Zeyu Han, Chao Gao, Jinyang Liu, Sai Qian Zhang, et al. 2024. Parameter-efficient fine-tuning for large models: A comprehensive survey. arXiv preprintarXiv:2403.14608 (2024)": "Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, SheanWang, Lu Wang, and Weizhu Chen. 2021. Lora: Low-rank adaptation of largelanguage models. arXiv preprint arXiv:2106.09685 (2021). Kyle Hundman, Valentino Constantinou, Christopher Laporte, Ian Colwell, andTom Soderstrom. 2018. Detecting spacecraft anomalies using lstms and nonpara-metric dynamic thresholding. In Proceedings of the 24th ACM SIGKDD interna-tional conference on knowledge discovery & data mining. 387395. Hongye Jin, Xiaotian Han, Jingfeng Yang, Zhimeng Jiang, Zirui Liu, Chia-YuanChang, Huiyuan Chen, and Xia Hu. 2024. Llm maybe longlm: Self-extend llmcontext window without tuning. arXiv preprint arXiv:2401.01325 (2024). Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y Zhang, Xiaoming Shi,Pin-Yu Chen, Yuxuan Liang, Yuan-Fang Li, Shirui Pan, et al. 2023. Time-llm:Time series forecasting by reprogramming large language models. arXiv preprintarXiv:2310.01728 (2023).",
  "Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion ConvolutionalRecurrent Neural Network: Data-Driven Traffic Forecasting. In ICLR": "Xi Victoria Lin, Xilun Chen, Mingda Chen, Weijia Shi, Maria Lomeli, Rich James,Pedro Rodriguez, Jacob Kahn, Gergely Szilvasy, Mike Lewis, et al. 2023. Ra-dit:Retrieval-augmented dual instruction tuning. arXiv preprint arXiv:2310.01352(2023). Hengbo Liu, Ziqing Ma, Linxiao Yang, Tian Zhou, Rui Xia, Yi Wang, QingsongWen, and Liang Sun. 2023. SADI: A Self-Adaptive Decomposed InterpretableFramework for Electric Load Forecasting Under Extreme Events. In IEEE Interna-tional Conference on Acoustics, Speech and Signal Processing.",
  "Ivan Marisca, Cesare Alippi, and Filippo Maria Bianchi. 2024. Graph-basedForecasting with Missing Data through Spatiotemporal Downsampling. arXivpreprint arXiv:2402.10634 (2024)": "Ivan Marisca, Andrea Cini, and Cesare Alippi. 2022. Learning to reconstructmissing data from spatiotemporal graphs with sparse observations. Advances inNeural Information Processing Systems 35 (2022), 3206932082. Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. 2023.A Time Series is Worth 64 Words: Long-term Forecasting with Transformers.In The Eleventh International Conference on Learning Representations. OpenAI. 2023. GPT-4 Technical Report. arXiv:2303.08774 [cs.CL] Boris N Oreshkin, Dmitri Carpov, Nicolas Chapados, and Yoshua Bengio. 2020. N-BEATS: Neural basis expansion analysis for interpretable time series forecasting.In International Conference on Learning Representations. Jaideep Pathak, Shashank Subramanian, Peter Harrington, Sanjeev Raja, AsheshChattopadhyay, Morteza Mardani, Thorsten Kurth, David Hall, Zongyi Li,Kamyar Azizzadenesheli, et al. 2022. Fourcastnet: A global data-driven high-resolution weather model using adaptive fourier neural operators. arXiv preprintarXiv:2202.11214 (2022). Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, StefanoErmon, and Chelsea Finn. 2024. Direct preference optimization: Your languagemodel is secretly a reward model. Advances in Neural Information ProcessingSystems 36 (2024). Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, KevinLeyton-Brown, and Yoav Shoham. 2023. In-context retrieval-augmented languagemodels. Transactions of the Association for Computational Linguistics 11 (2023),13161331. Machel Reid, Nikolay Savinov, Denis Teplyashin, Dmitry Lepikhin, TimothyLillicrap, Jean-baptiste Alayrac, Radu Soricut, Angeliki Lazaridou, Orhan Firat,Julian Schrittwieser, et al. 2024. Gemini 1.5: Unlocking multimodal understandingacross millions of tokens of context. arXiv preprint arXiv:2403.05530 (2024).",
  "Lifeng Shen, Zhuocong Li, and James Kwok. 2020. Timeseries anomaly detectionusing temporal hierarchical one-class network. Advances in Neural InformationProcessing Systems 33 (2020), 1301613026": "Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, MikeLewis, Luke Zettlemoyer, and Wen-tau Yih. 2023. Replug: Retrieval-augmentedblack-box language models. arXiv preprint arXiv:2301.12652 (2023). Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Tharindu Kalu-arachchi, Rajib Rana, and Suranga Nanayakkara. 2023. Improving the domainadaptation of retrieval augmented generation (RAG) models for open domainquestion answering. Transactions of the Association for Computational Linguistics11 (2023), 117. Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-BaptisteAlayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth,et al. 2023. Gemini: a family of highly capable multimodal models. arXiv preprintarXiv:2312.11805 (2023). Gemma Team, Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupati-raju, Shreya Pathak, Laurent Sifre, Morgane Rivire, Mihir Sanjay Kale, JulietteLove, et al. 2024. Gemma: Open models based on gemini research and technology.arXiv preprint arXiv:2403.08295 (2024). Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-AnneLachaux, Timothe Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, et al. 2023. Llama: Open and efficient foundation language models. arXivpreprint arXiv:2302.13971 (2023). Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and MingshengLong. 2023. TimesNet: Temporal 2D-Variation Modeling for General Time SeriesAnalysis. In The Eleventh International Conference on Learning Representations.",
  "Weiqi Zhang, Chen Zhang, and Fugee Tsung. 2022. GRELEN: Multivariate TimeSeries Anomaly Detection from the Perspective of Graph Relational Learning..In IJCAI. 23902397": "Yunhao Zhang and Junchi Yan. 2022. Crossformer: Transformer utilizing cross-dimension dependency for multivariate time series forecasting. In The eleventhinternational conference on learning representations. Hang Zhao, Yujing Wang, Juanyong Duan, Congrui Huang, Defu Cao, YunhaiTong, Bixiong Xu, Jing Bai, Jie Tong, and Qi Zhang. 2020. Multivariate time-series anomaly detection via graph attention network. In 2020 IEEE InternationalConference on Data Mining (ICDM). IEEE, 841850.",
  "A.1Missing Data Imputation": "Time series imputation is a critical step in time series analysis. It ad-dresses a common issue in this field: missing values within datasets.These missing values can arise from sensor failures, data transmis-sion errors, or incomplete records. By imputing these gaps, timeseries imputation ensures the quality and reliability of subsequentanalyses. The Agentic-RAG framework achieves this by handlingseasonality, trends and capturing the inherent spatio-temporal de-pendencies within the data. Ultimately, imputation improves dataquality, enabling more accurate analysis, modeling, and decision-making. In essence, it plays a vital role by maintaining data in-tegrity and enabling reliable analysis. To evaluate the Agentic-RAGframeworks ability to handle missing data, we simulated two typesof missingness patterns: point missing and block missing.These patterns represent varying degrees of data availability. Toachieve this, we introduced synthetic missingness into time seriesdatasets following these patterns. For point missing, individualvalues were randomly omitted with a probability threshold (), con-trolling the overall percentage of missing data. The block missingpattern involves removing contiguous, multi-period, multi-timeseries segments. This is done by randomly selecting start and endtimes, as well as start and end time series, to define uniform blockswith an average length of (). All data points within each block arethen omitted. Furthermore, two block missing patterns are consid-ered: temporal and spatial. For temporal block missing, contiguousmulti-period segments are removed from a given time series. This isdone by randomly selecting start and end times, creating stretchesof unavailable temporal data. For spatial block missing, contiguousblocks are removed across multiple related time series at specifictime points. This involves randomly selecting the start and endtime series, resulting in missing spatial data at the chosen timepoints. Both patterns show varying levels of missing informationin the time series data. In summary, point missing refers to spo-radic gaps in the data, while block missing involves the absence ofentire contiguous multi-period and multi-series segments. Blockmissing can further be categorized into two types: temporal blockmissing, where contiguous segments are removed within a singletime series, and spatial block missing, where contiguous blocks areremoved across multiple related time series, mimicking realisticscenarios of faulty data collection. In the context of time series impu-tation, in-sample\" and out-of-sample\" imputation refer to distinctevaluation settings. In-sample imputation involves the imputationmethod reconstructing missing values within a given fixed inputsequence, , using all available observed data within that sequence.Out-of-sample imputation involves training the imputation methodusing the fixed sequence to impute missing points in a futuresequence, +1. In this work, we utilize out-of-sample settings, asthis approach mimics real-world scenarios and rigorously assessesthe Agentic-RAG frameworks robustness and generalizability byevaluating its ability to handle new, unseen data. The simulateddatasets with missing values were then used to evaluate the missingdata handling capabilities of the proposed Agentic-RAG framework.We split multiple benchmark datasets in chronological order with a ratio of 7:1:2 for the METR-LA and PEMS-BAY datasets and aratio of 6:2:2 for the other datasets into training, validation, andtest sets. We evaluated the Agentic-RAG frameworks performanceon simulated data using multiple imputation metrics (e.g., RMSE,MAE, and MAPE). This analysis helps us understand how well theframework handles time series data with missing values, particu-larly how its performance changes as the percentage of missingdata increases. We establish the Agentic-RAG framework, trainedon complete data (no missing values), as a strong performancebenchmark. This benchmark allows us to evaluate the frameworkseffectiveness in imputing missing data under different conditionsof data incompleteness. Tables 7 and 8 present the imputation re-sults on standard benchmark datasets with different missingnesspatterns, while the framework performs slightly worse than thebaseline for minimal missing data. Its accuracy degrades more sig-nificantly as the data becomes more incomplete, regardless of thespecific missingness pattern. Our proposed Agentic-RAG frame-work demonstrates robustness to missing data by focusing on theavailable observations for imputing missing values, thereby avoid-ing the introduction of potentially inaccurate estimates that couldobscure the underlying trends and patterns within the time seriesdata. Additionally, the Agentic-RAG framework effectively capturesthe complex non-linear intra- and inter-time series dependenciesand this leads to more reliable imputation. The experiments showthat our framework can learn the spatiotemporal dependenciesfrom partially observed data with various missingness patterns,resulting in lower imputation errors.",
  "A.2Time Series Classification": "Time series classification is a crucial task with applications acrossvarious domains. In time series analysis, regimes, or clusters rep-resent distinct behavioral modes, operating conditions, or statesof the system underlying the data. Identifying and characterizingthese regimes is crucial for understanding the complex patterns anddynamics within the data. This allows for more accurate modeling,forecasting, and decision-making in applications where time seriesanalysis is essential. The emergence of different regimes or clusterscan stem from changes in the data generation process, external con-ditions, or the inherent non-stationarity and multivariate natureof the time series. This reflects the rich information content andcomplexity often encountered in real-world time series data. Toevaluate the proposed Agentic-RAG frameworks ability to handletime series classification tasks, an unsupervised clustering approachwas employed for data labeling. We first applied k-means clusteringto the original time series datasets, determining the optimal num-ber of clusters (k) using established techniques such as the elbowmethod or silhouette analysis. The optimal clusters were treatedas class labels, representing distinct regimes within the time series,and each time series was assigned the corresponding cluster label,creating a labeled classification dataset. We adopted a time-baseddivision strategy to split multiple benchmark datasets into training,validation, and testing sets. The METR-LA and PEMS-BAY datasetswere split at a 7:1:2 ratio, while other datasets used a 6:2:2 split.We evaluated the frameworks performance on the held-out testset using standard classification metrics: accuracy, precision, recall.This methodology allowed us to assess the frameworks ability tolearn the underlying patterns and relationships associated with",
  "BUNIVARIATE DATASETS": "We conducted several experiments to evaluate the proposed Agentic-RAG framework variants: SelfExtend-Agentic-RAG with Gemma-2B, SelfExtend-Agentic-RAG with Gemma-7B, and SelfExtend-Agentic-RAG with Llama-8B, on the univariate datasets for mul-tiple time series analysis tasks such as forecasting and imputation.B.1Forecasting and Imputation The ETT (Electricity Transformer) datasets, ETTh1, ETTh2,ETTm1, and ETTm2, are popular benchmarks used for evaluat-ing and benchmarking univariate time series forecasting methods.They provide a challenging benchmark due to the presence of com-plex patterns, such as trends, seasonality, and irregularities, whichare commonly found in real-world time series data. ETTh1 and ETTh2 are two hourly time series datasets containing observationsof electricity transformers from two different locations. ETTm1 andETTm2 are two monthly time series datasets containing observa-tions of electricity transformers from two different locations. Inthis work, we utilize the ETT datasets to evaluate the Agentic-RAG framework for both forecasting and missing data imputationtasks. The shows the performance of various methodson the multi-horizon forecasting task using a lookback windowof size 512. It presents mean squared error (MSE) and mean ab-solute error (MAE) for nine models (GPT4TS, PatchTST,TimesNet, FEDFormer, LightTS, N-BEATS, Agentic-RAG w/Gemma-2B, Agentic-RAG w/Gemma-7B, and Agentic-RAGw/Llama-8B) across four datasets (ETTh1, ETTh2, ETTm1, ETTm2)at different time horizons (96, 192, 336, 720). This allows for acomprehensive analysis of forecasting accuracy and robustness ofAgentic-RAG framework across varying prediction lengths. The per-formance of various methods for imputing missing data (point andblock missing) and their effectiveness in out-of-sample imputationsettings are compared in Tables 12 and 13. The evaluated methods",
  "MLP83.01%81.52%82.02%84.52%83.01%83.51%86.01%85.01%85.53%": ": The table presents a comparative evaluation of the Agentic-RAG framework variants performance on three benchmarkdatasets: PeMSD7(M), PeMSD8, and PEMS-BAY, across various metrics for time series classification. include GPT4TS, PatchTST, TimesNet, FEDFormer,LightTS, N-BEATS, Agentic-RAG with Gemma-2B, Agentic-RAG with Gemma-7B, and Agentic-RAG with Llama-8B. The eval-uation employs a 512-step historical window for imputing 96-step-ahead (short-term prediction) and 720-step-ahead (long-term pre-diction) missing values in future data. The tables show results forfour datasets (ETTh1, ETTh2, ETTm1, ETTm2) under three missingdata scenarios: 0% missing (no missing data), 20% point missing, and20% block missing. The proposed Agentic-RAG framework variantsdemonstrate strong performance on the benchmark datasets forboth forecasting and imputation tasks, with lower errors.",
  "CENVIRONMENTAL IMPACT": "Our Agentic-RAG framework training process, involving multi-ple variants running for extended periods, increases our energyconsumption and carbon footprint. Accurate quantification of thecarbon footprint of deep learning experiments is essential for pro-moting sustainable practices in artificial intelligence research anddevelopment. A crucial aspect of this endeavor is estimating the en-ergy consumption and associated greenhouse gas emissions duringthe computationally intensive training processes. This is calculatedby determining the Total Graphics Power (TGP), which representsthe maximum power draw of the GPU, including the GPU chip itselfand other components like memory and additional circuitry. Forexample, the NVIDIA P100 GPU has a TGP of 300 watts, while theNVIDIA T4 GPU has a TGP of 70 watts. By multiplying the TGP bythe training time, we can estimate the energy consumption, whichis then converted to carbon emissions using a region-specific car-bon intensity factor. This factor accounts for the energy mix (coal,natural gas, renewables, etc.) used to generate electricity in the geo-graphic area where the computations are performed. Considering a725-GPU hours training experiment and using an estimated carbonintensity factor of 0.0007 metric tons CO2e per kWh for the year2024 (for more information on the carbon intensity of electricity,you can visit CO2 Intensity - Our World in Data), the calculatedcarbon footprint would be 152.25 kg CO2e for the NVIDIA P100 GPU and 35.525 kg CO2e for the NVIDIA T4 GPU. Note: kg CO2estands for kilograms of carbon dioxide equivalent. The averageperson in the United States emits approximately 43.8 kg of carbondioxide equivalent (CO2e) per day. Given the emissions of 152.25kg CO2e for the NVIDIA P100 GPU and 35.525 kg CO2e for theNVIDIA T4 GPU, it would take a single persons emissions ap-proximately 3.5 days to match the emissions of the P100 GPU andapproximately 0.8 days (or 19 hours) to match the emissions of theT4 GPU. While the calculated carbon footprint provides valuableinsight, the actual energy consumption and resulting emissionsmay vary due to factors like GPU utilization and regional energysources. Nonetheless, quantifying the carbon footprint is a crucialstep towards understanding and mitigating the environmental im-pact of deep learning research, paving the way for more sustainableand responsible practices in artificial intelligence.",
  "DHYPERPARAMETER OPTIMIZATION": "Hyperparameter optimization involves training the Agentic-RAGframework variants multiple times with different hyperparametersettings. This can be computationally expensive, especially for com-plex pre-trained language models or large datasets. We optimizedthe hyperparameters for the best-performing Agentic-RAG w/Llama-8Bvariant. For simplicity and in the interest of time, we have utilizedthe same settings for evaluating the performance of Agentic-RAGwith w/Gemma-2B and w/Gemma-7B variants for both multi-variate and univariate datasets across all tasks. In our experiments,we optimized the training process for supervised fine-tuning usinga batch size from {16, 32, 64}, learning rate from {15, 55, 14}.The training was conducted over epochs in the range of {10, 15, 20}with a warmup step count from {500, 1000, 1500} and a weightdecay for regularization from {0.01, 0.05, 0.1}. We used gradient ac-cumulation steps for stabilized training convergence from {2, 4, 8}and employed the AdamW optimizer. To manage memory andcomputational efficiency, we applied 4-bit quantization for QLoRA,with hyperparameters including a low-rank () from {16, 32, 64},an () from {32, 64, 128}, and a dropout from {0.05, 0.1, 0.2}. For",
  "Agentic Retrieval-Augmented Generation for Time Series Analysis30th, ACM KDD August 25 - 29, 2024, 2024, Barcelona, Spain": "preference tuning, the hyperparameter () was set in the rangeof {0.2, 0.4, 0.6} and learning rate from {5.0 7, 1.0 6, 5.0 6}.The optimal hyperparameters for training were chosen to achievea balance between performance and computational efficiency. Theoptimal hyperparameters for supervised fine-tuning were a batchsize of 16 and a learning rate of 1e-5, trained over 15 epochs with500 warmup steps and a weight decay of 0.01, utilizing the AdamWoptimizer. Gradient accumulation steps were set to 2. QLoRA quan-tization was applied with 4-bit precision, and its specific hyperpa-rameters included a low-rank () of 16, an alpha () of 32, and adropout rate of 0.05. Preference optimization was performed witha learning rate of 5.0e-7 over 3 epochs and a beta value of 0.2.",
  "We evaluated the frameworks performance with and with-out DPO and assessed how aligning SLMs with preferredoutcomes impacts the accuracy and reliability of predic-tions": "Our study investigates the impact of different components on theoverall performance of the framework, SelfExtend-Agentic-RAGW/Llama 3 - 8B\", in time series forecasting, anomaly detection, andclassification tasks across various benchmark datasets. We system-atically disable each component (dynamic prompting mechanism(DPM), sub-agent specialization (SAS), instruction-tuning (IT), or di-rect preference optimization (DPO)) and compare the results to thefull framework. Tables 14 and 15 detail the forecasting performance,highlighting that the original framework consistently achieves thelowest error rates in MAE, RMSE, and MAPE across different hori-zons and datasets. This indicates the crucial role of each componentin improving forecasting accuracy. focuses on anomaly de-tection tasks, showing the original frameworks superior precision,recall, and F1-score compared to its ablated variants. The origi-nal framework consistently achieves higher metrics scores acrossanomaly benchmark datasets such as SWaT, WADI, SMAP, MSL,and HAI. The significant performance drop observed in the ablatedvariants underscores the importance of the integrated components,demonstrating their synergistic contribution to enhancing anomaly detection capabilities. For classification tasks, the original frame-work excels, as demonstrated in Tables 17 and 18, achieving thehighest accuracy, precision, and recall across datasets like PeMSD3,PeMSD4, PeMSD7, METR-LA, PeMSD7(M), PeMSD8, and PEMS-BAY. The superior performance in classification tasks, coupled withthe significant drop observed in ablated variants, highlights thecritical role each component plays in the original frameworks suc-cess. This comprehensive analysis underscores the importance ofintegrating all components to maximize performance across fore-casting, anomaly detection, and classification tasks. The synergisticcontribution of the dynamic prompting mechanism, sub-agent spe-cialization, instruction-tuning, and direct preference optimization isevident in the consistent superiority of the Agentic-RAG frameworkcompared to its ablated variants."
}