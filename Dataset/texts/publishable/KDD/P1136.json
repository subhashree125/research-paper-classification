{
  "ABSTRACT": "The advent of large language models (LLMs) has ushered in a newparadigm of search engines that use generative models to gatherand summarize information to answer user queries. This emergingtechnology, which we formalize under the unified framework ofgenerative engines (GEs), can generate accurate and personalizedresponses, rapidly replacing traditional search engines like Googleand Bing. Generative Engines typically satisfy queries by synthe-sizing information from multiple sources and summarizing themusing LLMs. While this shift significantly improves user utilityand generative search engine traffic, it poses a huge challenge forthe third stakeholder website and content creators. Given theblack-box and fast-moving nature of generative engines, contentcreators have little to no control over when and how their contentis displayed. With generative engines here to stay, we must ensurethe creator economy is not disadvantaged. To address this, we in-troduce Generative Engine Optimization (GEO), the first novelparadigm to aid content creators in improving their content visi-bility in generative engine responses through a flexible black-boxoptimization framework for optimizing and defining visibility met-rics. We facilitate systematic evaluation by introducing GEO-bench,a large-scale benchmark of diverse user queries across multiple do-mains, along with relevant web sources to answer these queries.Through rigorous evaluation, we demonstrate that GEO can boostvisibility by up to 40% in generative engine responses. Moreover,we show the efficacy of these strategies varies across domains, un-derscoring the need for domain-specific optimization methods. Ourwork opens a new frontier in information discovery systems, withprofound implications for both developers of generative enginesand content creators.1",
  "Equal Contribution1Code and Data available at": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "INTRODUCTION": "The invention of traditional search engines three decades ago revo-lutionized information access and dissemination globally . Whilethey were powerful and ushered in a host of applications like aca-demic research and e-commerce, they were limited to providinga list of relevant websites for user queries. However, the recentsuccess of large language models has paved the way forbetter systems like BingChat, Googles SGE, and perplexity.ai thatcombine conventional search engines with generative models. Wedub these systems generative engines (GE) because they search forinformation and generate multi-modal responses by using multiplesources. Technically, generative engines () retrieve relevantdocuments from a database (like the internet) and use large neuralmodels to generate a response grounded on the sources, ensuringattribution and a way for the user to verify the information.The usefulness of generative engines for developers and usersis evident users access information faster and more accurately,while developers craft precise and personalized responses, improv-ing user satisfaction and revenue. However, generative enginesdisadvantage the third stakeholder website and content creators.Generative Engines, in contrast to traditional search engines, re-move the need to navigate to websites by directly providing aprecise and comprehensive response, potentially reducing organictraffic to websites and impacting their visibility . With millionsof small businesses and individuals relying on online traffic andvisibility for their livelihood, generative engines will significantlydisrupt the creator economy. Further, the black-box and propri-etary nature of generative engines makes it difficult for content",
  "KDD 24, August 2529, 2024, Barcelona, SpainPranjal Aggarwal et al": ": Ranking and Visibility Metrics are straightforward in traditional search engines, which list website sources in rankedorder with verbatim content. However, Generative Engines generate rich, structured responses, often embedding citationsin a single block interleaved with each other. This makes ranking and visibility nuanced and multi-faceted. Further, unlikesearch engines, where significant research has been conducted on improving visibility, optimizing visibility in generativeengine responses remains unclear. To address these challenges, our black-box optimization framework proposes a series ofwell-designed impression metrics that creators can use to gauge and optimize their websites performance and also allows thecreator to define their impression metrics. However, since Word Count is not impacted by the ranking ofthe citations (whether it appears first, for example), we propose aposition-adjusted count that reduces the weight by an exponentiallydecaying function of the citation position:",
  "FORMULATION & METHODOLOGY2.1Formulation of Generative Engines": "Despite the deployment of numerous generative engines to millionsof users, there is currently no standard framework. We provide a for-mulation that accommodates various modular components in theirdesign. We describe a generative engine, which includes severalbackend generative models and a search engine for source retrieval.A Generative Engine (GE) takes a user query and returns a nat-ural language response , where represents personalized userinformation. The GE can be represented as a function:",
  ":= (, ) (1)": "Generative Engines comprise two crucial components: a.) A setof generative models = {1,2...}, each serving a specific pur-pose like query reformulation or summarization, and b.) A searchengine that returns a set of sources = {1,2...} given aquery . We present a representative workflow in , which,at the time of writing, closely resembles the design of BingChat. Thisworkflow breaks down the input query into a set of simpler queriesthat are easier to consume for the search engine. Given a query, aquery re-formulating generative model, 1 = , generates a setof queries 1 = {1,2...}, which are then passed to the searchengine to retrieve a set of ranked sources = {1,2, ...,}. Thesets of sources are passed to a summarizing model 2 = ,which generates a summary for each source in , resulting inthe summary set ( = {1,2, ...,}). The summaryset is passed to a response-generating model 3 = , whichgenerates a cumulative response backed by sources . In this work,we focus on single-turn Generative Engines, but the formulationcan be extended to multi-turn Conversational Generative Engines(Appendix A).The response is typically a structured text with embeddedcitations. Citations are important given the tendency of LLMs tohallucinate information . Specifically, consider a response composed of sentences {1,2...}. Each sentence may be backedby a set of citations that are part of the retrieved set of documents . An ideal generative engine should ensure all statementsin the response are supported by relevant citations (high citationrecall), and all citations accurately support the statements theyre",
  "Generative Engine Optimization": "The advent of search engines led to search engine optimization(SEO), a process to help website creators optimize their content toimprove search engine rankings. Higher rankings correlate withincreased visibility and website traffic. However, traditional SEOmethods are not directly applicable to Generative Engines. This isbecause, unlike traditional search engines, the generative modelin generative engines is not limited to keyword matching, andthe use of language models in ingesting source documents andresponse generation results in a more nuanced understanding oftext documents and user query. With generative engines rapidlyemerging as the primary information delivery paradigm and SEOis not directly applicable; new techniques are needed. To this end,we propose Generative Engine Optimization, a new paradigmwhere content creators aim to increase their visibility (or impres-sion) in generative engine responses. We define the visibility of awebsite (also referred to as a citation) in a cited response by thefunction (,), which the website creator wants to maximize.From the generative engines perspective, the goal is to maximizethe visibility of citations most relevant to the user query, i.e., maxi-mize ((,), (,,)), where (,,) measures therelevance of citation to the query in the context of response and is determined by the exact algorithmic design of generativeengine and is a black-box function to end-users. Further, both thefunctions and are subjective and not well-defined yet forgenerative engines, and we define them next. 2.2.1Impressions for Generative Engines. In SEO, a websites im-pression (or visibility) is determined by its average ranking overa range of queries. However, generative engines output naturenecessitates different impression metrics. Unlike search engines,Generative Engines combine information from multiple sourcesin a single response. Factors such as length, uniqueness, and pre-sentation of the cited website determine the true visibility of acitation. Thus, as illustrated in , while a simple rankingon the response page serves as an effective metric for impressionand visibility in conventional search engines, such metrics are notapplicable to generative engine responses.In response to this challenge, we propose a suite of impressionmetrics designed with three key principles in mind: 1.) The metricsshould hold relevance for creators, 2.) They should be explainable,and 3.) They should be easily comprehensible by a broad spectrumof content creators. The first of these metrics, the Word Countmetric, is the normalized word count of sentences related to acitation. Mathematically, this is defined as:",
  "||(2)": "Here is the set of sentences citing , is the set of sentencesin the response, and || is the number of words in sentence . Incases where a sentence is cited by multiple sources, we share theword count equally with all the citations. Intuitively, a higher wordcount correlates with the source playing a more important part inthe answer, and thus, the user gets higher exposure to that source.",
  "||(3)": "Intuitively, sentences that appear first in the response are morelikely to be read, and the exponent term in definition giveshigher weightage to such citations. Thus, a website cited at thetop may have a higher impression despite having a lower wordcount than a website cited in the middle or end of the response.Further, the choice of exponentially decaying function is motivatedby several studies showing click-through rates follow a power-lawas a function of ranking in search engines . While the aboveimpression metrics are objective and well-grounded, they ignorethe subjective aspects of the impact of citations on the users at-tention. To address this, we propose the \"Subjective Impression\"metric, which incorporates facets such as the relevance of the citedmaterial to the user query, influence of the citation, uniqueness ofthe material presented by a citation, subjective position, subjectivecount, probability of clicking the citation, and diversity in the ma-terial presented. We use G-Eval , the current state-of-the-artfor evaluation with LLMs, to measure each of these sub-metrics. 2.2.2Generative Engine Optimization methods for website. Toimprove impression metrics, content creators must make changesto their website content. We present several generative engine-agnostic strategies, referred to as Generative Engine Optimiza-tion methods (GEO). Mathematically, every GEO method is a func-tion : , where is the initial web content, and is the modified content after applying the GEO method. The modifi-cations can range from simple stylistic alterations to incorporatingnew content in a structured format. A well-designed GEO is equiv-alent to a black-box optimization method that, without knowingthe exact algorithmic design of generative engines, can increasethe websites visibility and implement textual modifications to independent of the exact queries.For our experiments, we apply Generative Engine Optimiza-tion methods on website content using a large language model,prompted to perform specific stylistic and content changes to thewebsite. In particular, based on the GEO method defining a spe-cific set of desired characteristics, the source content is modifiedaccordingly. We propose and evaluate several such methods:1: Authoritative: Modifies text style of the source content to bemore persuasive and authoritative, 2. Statistics Addition: Modifiescontent to include quantitative statistics instead of qualitative dis-cussion, wherever possible, 3. Keyword Stuffing: Modifies contentto include more keywords from the query, as expected in classi-cal SEO optimization. 4. Cite Sources & 5. Quotation Addition:Adds relevant citations and quotations from credible sources re-spectively, 6.) 6. Easy-to-Understand: Simplifies the language ofwebsite, while 7. Fluency Optimization improves the fluency ofwebsite text. 8. Unique Words & 9. Technical Terms: involvesadding unique and technical terms respectively wherever possible,These methods cover diverse general strategies that websiteowners can implement quickly and use regardless of the websitecontent. Further, except for methods 3, 4, and 5, the remainingmethods enhance the presentation of existing content to increaseits persuasiveness or appeal to the generative engine, without re-quiring extra content. On the other hand, methods 3,4 and 5 may",
  "EXPERIMENTAL SETUP3.1Evaluated Generative Engine": "In accordance with previous works , we use a 2-step setup forGenerative Engine design. The first step involves fetching relevantsources for input query, followed by a second step where an LLMgenerates a response based on the fetched sources. Similar to pre-vous works, we do not use summarization and provide the wholeresponse for each source. Due to context length limitations and qua-dratic scaling cost based on the context size of transformer models,only the top 5 sources are fetched from the Google search enginefor every query. The setup closely mimics the workflow used inprevious works and the general design adopted by commercial GEssuch as you.com and perplexity.ai. The answer is then generatedby the gpt3.5-turbo model using the same prompt as priorwork . We sample 5 different responses at temperature=0.7, toreduce statistical deviations.Further in Section C.1, we evaluate the same Generative EngineOptimization methods on Perplexity.ai, which is a commerciallydeployed generative engine, highlighting the generalizability of ourproposed Generative Engine Optimization methods.",
  "Benchmark : GEO-bench": "Since there is currently no publicly available dataset containingGenerative Engine related queries, we curate GEO-bench, a bench-mark consisting of 10K queries from multiple sources, repurposedfor generative engines, along with synthetically generated queries.The benchmark includes queries from nine different sources, eachfurther categorized based on their target domain, difficulty, queryintent, and other dimensions. Datasets: 1. MS Macro, 2. ORCAS-1, and 3. Natural Ques-tions: These datasets contain real anonymized user queriesfrom Bing and Google Search Engines. These three collectivelyrepresent the common set of datasets that are used in search en-gine related research. However, Generative Engines will be posedwith far more difficult and specific queries with the intent of syn-thesizing answers from multiple sources instead of searching forthem. To this end, we repurpose several other publicly availabledatasets: 4. AllSouls: This dataset contains essay questions from\"All Souls College, Oxford University.\" The queries in this datasetrequire Generative Engines to perform appropriate reasoning toaggregate information from multiple sources. 5. LIMA: con-tains challenging questions requiring Generative Engines to notonly aggregate information but also perform suitable reasoningto answer the question (e.g., writing a short poem, python code.).6. Davinci-Debtate contains debate questions generated fortesting Generative Engines. 7. Perplexity.ai Discover2: Thesequeries are sourced from Perplexity.ais Discover section, which is an updated list of trending queries on the platform. 8. ELI-53: Thisdataset contains questions from the ELI5 subreddit, where users askcomplex questions and expect answers in simple, laymans terms.9. GPT-4 Generated Queries: To supplement diversity in querydistribution, we prompt GPT-4 to generate queries rangingfrom various domains (e.g., science, history) and based on queryintent (e.g., navigational, transactional) and based on difficulty andscope of generated response (e.g., open-ended, fact-based). . Our benchmark comprises 10K queries divided into 8K, 1K, and1K for train, validation, and test splits, respectively. We preservethe real-world query distribution, with our benchmark containing80% informational queries and 10% each for transactional and navi-gational queries. Each query is augmented with the cleaned textcontent of the top 5 search results from the Google search engine. Tags. Optimizing website content often requires targeted changesbased on the tasks domain. Additionally, a user of GenerativeEngine Optimization may need to identify an appropriate methodfor only a subset of queries, considering multiple factors such asdomain, user intent, and query nature. To facilitate this, we tag eachquery with one of seven different categories. For tagging, we em-ploy the GPT-4 model and manually verify high recall and precisionon the test split.Overall, GEO-bench consists of queries from 25 diverse domainssuch as Arts, Health, and Games; it features a range of query diffi-culties from simple to multi-faceted; includes 9 different types ofqueries such as informational and transactional; and encompasses7 different categorizations. Owing to its specially designed highdiversity, the size of the benchmark, and its real-world nature, GEO-bench is a comprehensive benchmark for evaluating GenerativeEngines and serves as a standard testbed for assessing them forvarious purposes in this and future works. We provide more detailsabout GEO-bench in Appendix B.2.",
  "Evaluation Metrics": "We utilize the impression metrics as defined in .2.1. Specif-ically, we employ two impression metrics: 1. Position-AdjustedWord Count, which combines word count and position count.To analyze the effect of individual components, we also reportscores on the two sub-metrics separately. 2. Subjective Impres-sion, which is a subjective metric encompassing seven differentaspects: 1) relevance of the cited sentence to the user query, 2) in-fluence of the citation, assessing the extent to which the generatedresponse relies on the citation, 3) uniqueness of the material pre-sented by a citation, 4) subjective position, gauging the prominenceof the positioning of source from the users viewpoint, 5) subjec-tive count, measuring the amount of content presented from the",
  "High-Performing Generative Engine Optimization methods": "Authoritative25.625.725.928.930.931.231.731.526.929.530.6Fluency Optimization25.826.226.028.929.429.830.630.129.629.630.0Cite Sources26.626.926.819.820.719.518.920.018.518.919.0Quotation Addition28.828.729.131.431.931.932.331.431.730.932.1Statistics Addition25.826.626.231.633.434.033.734.033.333.133.9 : Performance improvement of GEO methods on GEO-bench with Perplexity.ai as generative engine. Compared to thebaselines simple methods such as Keyword Stuffing traditionally used in SEO often perform worse. However, our proposedmethods such as Statistics Addition and Quotation Addition show strong performance improvements across the board. Thebest performing methods improve upon baseline by 22% on Position-Adjusted Word Count and 37% on Subjective Impression.",
  "RESULTS": "We evaluate various Generative Engine Optimization methodsdesigned to optimize website content for better visibility in Gener-ative Engine responses, compared against a baseline with no opti-mization. Our evaluation used GEO-bench, a diverse benchmarkof user queries from multiple domains and settings. Performancewas measured using two metrics: Position-Adjusted Word Count andSubjective Impression. The former considers word count and citationposition in the GEs response, while the latter computes multiplesubjective factors, giving an overall impression score. details the absolute impression metrics of different meth-ods on multiple metrics. The results reveal that our GEO methodsconsistently outperform the baseline across all metrics on GEO-bench. This shows the robustness of these methods to varyingqueries, yielding significant improvements despite query diver-sity. Specifically, our top-performing methods, Cite Sources, Quota-tion Addition, and Statistics Addition, achieved a relative improve-ment of 30-40% on the Position-Adjusted Word Count metric and15-30% on the Subjective Impression metric. These methods, involv-ing adding relevant statistics (Statistics Addition), incorporatingcredible quotes (Quotation Addition), and including citations fromreliable sources (Cite Sources) in the website content, require mini-mal changes but significantly improve visibility in GE responses,enhancing both the credibility and richness of the content.Interestingly, stylistic changes such as improving fluency andreadability of the source text (Fluency Optimization and Easy-to-Understand) also resulted in a significant visibility boost of 15-30%.This suggests that Generative Engines value not only content butalso information presentation.",
  ": Top Performing categories for each of the GEO meth-ods. Website-owners can choose relevant GEO strategy basedon their target domain": "Further, given generative models are often designed to followinstructions, one would expect a more persuasive and authoritativetone in website content to boost visibility. However, we find nosignificant improvement, demonstrating that Generative Enginesare already somewhat robust to such changes. This highlights theneed for website owners to focus on improving content presentationand credibility.Finally, we evaluate keyword stuffing, i.e., adding more relevantkeywords to website content. While widely used for Search EngineOptimization, we find such methods offer little to no improvementon generative engines responses. This underscores the need forwebsite owners to rethink optimization strategies for generativeengines, as techniques effective in search engines may not translateto success in this new paradigm.",
  "ANALYSIS5.1Domain-Specific Generative EngineOptimizations": "In , we presented the improvements achieved by GEOacross the entirety of the GEO-bench benchmark. However, inreal-world SEO scenarios, domain-specific optimizations are oftenapplied. With this in mind, and considering that we provide cat-egories for every query in GEO-bench, we delve deeper into theperformance of various GEO methods across these categories. provides a detailed breakdown of the categories whereour GEO methods have proven to be most effective. A careful anal-ysis of these results reveals several intriguing observations. For in-stance, Authoritative significantly improves performance in debate-style questions and queries related to the historical domain. Thisaligns with our intuition, as a more persuasive form of writing islikely to hold more value in debates.Similarly, the addition of citations through Cite Sources is par-ticularly beneficial for factual questions, likely because citationsprovide a source of verification for the facts presented, thereby en-hancing the credibility of the response. The effectiveness of differentGEO methods varies across domains. For example, as shown in row5 of , domains such as Law & Government and questiontypes like Opinion benefit significantly from the addition of rele-vant statistics in the website content, as implemented by StatisticsAddition. This suggests that data-driven evidence can enhance thevisibility of a website in particular contexts. The method QuotationAddition is most effective in the People & Society, Explanation,and History domains. This could be because these domains often fluency statistics citation quotes fluency statistics citation quotes 22.4%35.8%34.4%33.0% 35.8%27.0%30.3%35.4% 34.4%30.3%19.1%20.1% 33.0%35.4%20.1%30.3% 31.4% 32.1% 26.0% 29.7%",
  "Improvement": ": Relative Improvement on using combination ofGEO strategies. Using Fluency Optimization and StatisticsAddition in conjunction results in maximum performance.The rightmost column shows using Fluency Optimizationwith other strategies is most beneficial. involve personal narratives or historical events, where direct quotescan add authenticity and depth to the content. Overall, our anal-ysis suggests that website owners should strive towards makingdomain-specific targeted adjustments to their websites for highervisibility.",
  "Optimization of Multiple Websites": "In the evolving landscape of Generative Engines, GEO methods areexpected to become widely adopted, leading to a scenario whereall source contents are optimized using GEO. To understand theimplications, we conducted an evaluation of GEO methods by opti-mizing all source contents simultaneously, with results presentedin . A key observation is the differential impact of GEOon websites based on their Search Engine Results Pages (SERP)ranking. Notably, lower-ranked websites, which typically strugglefor visibility, benefit significantly more from GEO. This is becausetraditional search engines rely on multiple factors, such as the num-ber of backlinks and domain presence, which are challenging forsmall creators to achieve. However, since Generative Engines utilize",
  "Authoritative89.1%": ": Representative examples of GEO methods optimizing source website. Additions are marked in green and Deletions inred. Without adding any substantial new information, GEO methods significantly increase the visibility of the source content. generative models conditioned on website content, factors suchas backlink building should not disadvantage small creators. Thisis evident from the relative improvements in visibility shown in. For example, the Cite Sources method led to a substantial115.1% increase in visibility for websites ranked fifth in SERP, whileon average, the visibility of the top-ranked website decreased by30.3%.This finding highlights GEOs potential as a tool to democra-tize the digital space. Many lower-ranked websites are created bysmall content creators or independent businesses, who traditionallystruggle to compete with larger corporations in top search engineresults. The advent of Generative Engines might initially seem dis-advantageous to these smaller entities. However, the applicationof GEO methods presents an opportunity for these content cre-ators to significantly improve their visibility in Generative Engineresponses. By enhancing their content with GEO, they can reacha wider audience, leveling the playing field and allowing them tocompete more effectively with larger corporations.",
  "Combination of GEO Strategies": "While individual GEO strategies show significant improvementsacross various domains, in practice, website owners are expectedto employ multiple strategies in conjunction. To study the perfor-mance improvements achieved by combining GEO strategies, weconsider all pairs of combinations of the top 4 performing GEOmethods, namely Cite Sources, Fluency Optimization, StatisticsAddition, and Quotation Addition. displays the heatmapof relative improvement in the Position-Adjusted Word Count visi-bility metric achieved by combining different GEO strategies. Theanalysis demonstrates that the combination of Generative En-gine Optimization methods can enhance performance, with thebest combination (Fluency Optimization and Statistics Addition)outperforming any single GEO strategy by more than 5.5%4. Fur-thermore, Cite Sources significantly boosts performance when used",
  "Qualitative Analysis": "We present a qualitative analysis of GEO methods in , con-taining representative examples where GEO methods boost sourcevisibility with minimal changes. Each method optimizes a sourcethrough suitable text additions and deletions. In the first example,we see that simply adding the source of a statement can significantlyboost visibility in the final answer, requiring minimal effort fromthe content creator. The second example demonstrates that addingrelevant statistics wherever possible ensures increased source vis-ibility in the final Generative Engine response. Finally, the thirdrow suggests that merely emphasizing parts of the text and using apersuasive text style can also lead to improvements in visibility.",
  "GEO: Generative Engine OptimizationKDD 24, August 2529, 2024, Barcelona, Spain": "in . Similar to our generative engine, Quotation Additionperforms best in Position-Adjusted Word Count with a 22% im-provement over the baseline. Methods that performed well in ourgenerative engine such as Cite Sources, Statistics Addition showimprovements of up to 9% and 37% on the two metrics. Our obser-vations, such as the ineffectiveness of traditional SEO methods likeKeyword Stuffing, are further highlighted, as it performs 10% worsethan the baseline. The results are significant for three reasons: 1)they underscore the importance of developing different Genera-tive Engine Optimization methods to benefit content creators, 2)they highlight the generalizability of our proposed GEO methodson different generative engines, 3) they demonstrate that contentcreators can use our easy-to-implement proposed GEO methodsdirectly, thus having a high real-world impact. We refer readers toAppendix C.1 for more details.",
  "RELATED WORK": "Evidence-based Answer Generation: Previous works have usedseveral techniques for answer generation backed by sources. Nakanoet al. trained GPT-3 to navigate web environments to generatesource-backed answers. Similarly, other methods fetchsources via search engines for answer generation. Our work unifiesthese approaches and provides a common benchmark for improvingthese systems in the future. In a recent working draft, Kumar andLakkaraju showed that strategic text sequences can manipulateLLM recommendations to enhance product visibility in generativeengines. While their approach focuses on increasing product visibil-ity through adversarial text, our method introduces non-adversarialstrategies to optimize any website content for improved visibilityin generative engine search results. Retrieval-Augmented Language Models: Several recent workshave tackled the issues of limited memory of language modelsby fetching relevant sources from a knowledge base to complete atask . However, Generative Engine needs to generate ananswer and provide attributions throughout the answer. Further,Generative Engine is not limited to a single text modality regardingboth input and output. Additionally, the framework of GenerativeEngine is not limited to fetching relevant sources but instead com-prises multiple tasks such as query reformulation, source selection,and making decisions on how and when to perform them. Search Engine Optimization: In nearly the past 25 years, extensiveresearch has optimized web content for search engines .These methods fall into On-Page SEO, improving content and userexperience, and Off-Page SEO, boosting website authority throughlink building. In contrast, GEO deals with a more complex envi-ronment involving multi-modality, conversational settings. SinceGEO is optimized against a generative model not limited to simplekeyword matching, traditional SEO strategies will not apply toGenerative Engine settings, highlighting the need for GEO.",
  "In this work, we formulate search engines augmented with genera-tive models that we dub generative engines. We propose Genera-tive Engine Optimization (GEO) to empower content creators": "to optimize their content under generative engines. We define im-pression metrics for generative engines and propose and releaseGEO-bench: a benchmark encompassing diverse user queries frommultiple domains and settings, along with relevant sources neededto answer those queries. We propose several ways to optimize con-tent for generative engines and demonstrate that these methods canboost source visibility by up to 40% in generative engine responses.Among other findings, we show that including citations, quotationsfrom relevant sources, and statistics can significantly boost sourcevisibility. Further, we discover a dependence of GEO methods ef-fectiveness on the query domain and the potential of combiningmultiple GEO strategies in conjunction. We show promising resultson a commercially deployed generative engine with millions ofactive users, showcasing the real-world impact of our work. In sum-mary, our work is the first to formalize the important and timelyGEO paradigm, releasing algorithms and infrastructure (bench-marks, datasets, and metrics) to facilitate rapid progress in genera-tive engines by the community. This serves as a first step towardsunderstanding the impact of generative engines on the digital spaceand the role of GEO in this new paradigm of search engines.",
  "LIMITATIONS": "While we rigorously test our proposed methods on two generativeengines, including a publicly available one, methods may need toadapt over time as GEs evolve, mirroring the evolution of SEO.Additionally, despite our efforts to ensure the queries in our GEO-bench closely resemble real-world queries, the nature of queriescan change over time, necessitating continuous updates. Further,owing to the black-box nature of search engine algorithms, wedidnt evaluate how GEO methods affect search rankings. However,we note that changes made by GEO methods are targeted changesin textual content, bearing some resemblance with SEO methods,while not affecting other metadata such as domain name, backlinks,etc, and thus, they are less likely to affect search engine rankings.Further, as larger context lengths in language models become eco-nomical, it is expected that future generative models will be able toingest more sources, thus reducing the impact of search rankings.Lastly, while every query in our proposed GEO-bench is tagged andmanually inspected, there may be discrepancies due to subjectiveinterpretations or errors in labeling.",
  "ACKNOWLEDGEMENTS": "This material is based upon work supported by the National ScienceFoundation under Grant No. 2107048. Any opinions, findings, andconclusions or recommendations expressed in this material arethose of the author(s) and do not necessarily reflect the views ofthe National Science Foundation. Daria Alexander, Wojciech Kusa, and Arjen P. de Vries. 2022. ORCAS-I: QueriesAnnotated with Intent using Weak Supervision. Proceedings of the 45th Inter-national ACM SIGIR Conference on Research and Development in InformationRetrieval (2022).",
  "Sergey Brin and Lawrence Page. 1998.The Anatomy of a Large-Scale Hy-pertextual Web Search Engine. Comput. Networks 30 (1998), 107117": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter,Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, BenjaminChess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, IlyaSutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners.In Advances in Neural Information Processing Systems, H. Larochelle, M. Ran-zato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.), Vol. 33. Curran Associates,Inc., 18771901. Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Fernando Campos, andJimmy J. Lin. 2021. MS MARCO: Benchmarking Ranking Models in the Large-DataRegime. Proceedings of the 44th International ACM SIGIR Conference on Researchand Development in Information Retrieval (2021).",
  "R.Anil Kumar, Zaiduddin Shaik, and Mohammed Furqan. 2019. A Survey onSearch Engine Optimization Techniques. International Journal of P2P NetworkTrends and Technology (2019)": "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins,Ankur P. Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob De-vlin, Kenton Lee, Kristina Toutanova, Llion Jones, Matthew Kelcey, Ming-WeiChang, Andrew M. Dai, Jakob Uszkoreit, Quoc V. Le, and Slav Petrov. 2019.Natural Questions: A Benchmark for Question Answering Research. Transac-tions of the Association for Computational Linguistics 7 (2019), 453466.",
  "G. D. Maayan. 2023.How Google SGE will impact your traffic and 3 SGE recovery case studies.Search Engine Land(5 Sep2023)": "Jacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song,Martin Chadwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham,Geoffrey Irving, and Nathan McAleese. 2022. Teaching language models tosupport answers with verified quotes. ArXiv abs/2203.11147 (2022). Grgoire Mialon, Roberto Dess, Maria Lomeli, Christoforos Nalmpantis, Ra-makanth Pasunuru, Roberta Raileanu, Baptiste Rozire, Timo Schick, JaneDwivedi-Yu, Asli Celikyilmaz, Edouard Grave, Yann LeCun, and Thomas Scialom.2023. Augmented Language Models: a Survey. ArXiv abs/2302.07842 (2023). Reiichiro Nakano, Jacob Hilton, S. Arun Balaji, Jeff Wu, Ouyang Long, ChristinaKim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, XuJiang, Karl Cobbe, Tyna Eloundou, Gretchen Krueger, Kevin Button, MatthewKnight, Benjamin Chess, and John Schulman. 2021. WebGPT: Browser-assistedquestion-answering with human feedback. ArXiv abs/2112.09332 (2021). OpenAI. 2022. Introducing ChatGPT. OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, IlgeAkkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, SamAltman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Bal-com, Paul Baltescu, Haiming Bao, Mohammad Bavarian, Jeff Belgum, Irwan Bello,Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff,Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brit-tany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, FotisChantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, BenChess, Chester Cho, Casey Chu, Hyung Won Chung, Dave Cummings, JeremiahCurrier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, DamienDeville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet,Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simn PosadaFishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian Gibson,Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gor-don, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, Shixiang ShaneGu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton,Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele,Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, ShantanuJain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, DennyJin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, ukasz Kaiser, AliKamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kil-patrick, Jong Wook Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirchner,Jamie Kiros, Matt Knight, Daniel Kokotajlo, ukasz Kondraciuk, Andrew Kon-drich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, MichaelLampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak MingLi, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez, RyanLowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov,Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew,Scott Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, DavidMedina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, PamelaMishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati,Oleg Murk, David Mly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, ArvindNeelakantan, Richard Ngo, Hyeonwoo Noh, Long Ouyang, Cullen OKeefe, JakubPachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascan-dolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng,Adam Perelman, Filipe de Avila Belbute Peres, Michael Petrov, Henrique Pondede Oliveira Pinto, Michael, Pokorny, Michelle Pokrass, Vitchyr H. Pong, TollyPowell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford,Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach,Carl Ross, Bob Rotsted, Henri Roussez, Nick Ryder, Mario Saltarelli, Ted Sanders,Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schul-man, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker,Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, KatarinaSlama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Felipe Pet-roski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine B.Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle,Nick Turley, Jerry Tworek, Juan Felipe Cern Uribe, Andrea Vallone, Arun Vi-jayvergiya, Chelsea Voss, Carroll Wainwright, Justin Jay Wang, Alvin Wang,Ben Wang, Jonathan Ward, Jason Wei, CJ Weinmann, Akila Welihinda, PeterWelinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter,Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, MichaelWu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech Zaremba,Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng,Juntang Zhuang, William Zhuk, and Barret Zoph. 2024. GPT-4 Technical Report.arXiv:2303.08774 [cs.CL] A. Shahzad, Deden Witarsyah Jacob, Nazri M. Nawi, Hairulnizam Bin Mahdin,and Marheni Eka Saputri. 2020. The new trend for search engine optimization,tools and techniques. Indonesian Journal of Electrical Engineering and ComputerScience 18 (2020), 1568. Kurt Shuster, Jing Xu, Mojtaba Komeili, Da Ju, Eric Michael Smith, StephenRoller, Megan Ung, Moya Chen, Kushal Arora, Joshua Lane, Morteza Behrooz,W.K.F. Ngan, Spencer Poff, Naman Goyal, Arthur Szlam, Y-Lan Boureau, MelanieKambadur, and Jason Weston. 2022. BlenderBot 3: a deployed conversationalagent that continually learns to responsibly engage. ArXiv abs/2208.03188 (2022). Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kul-shreshtha, Heng-Tze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, YaGuangLi, Hongrae Lee, Huaixiu Steven Zheng, Amin Ghafouri, Marcelo Menegali,Yanping Huang, Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao Chen,Yuanzhong Xu, Zhifeng Chen, Adam Roberts, Maarten Bosma, Vincent Zhao,Yanqi Zhou, Chung-Ching Chang, Igor Krivokon, Will Rusch, Marc Pickett,Pranesh Srinivasan, Laichee Man, Kathleen Meier-Hellstern, Meredith RingelMorris, Tulsee Doshi, Renelito Delos Santos, Toju Duke, Johnny Soraker, BenZevenbergen, Vinodkumar Prabhakaran, Mark Diaz, Ben Hutchinson, Kristen Ol-son, Alejandra Molina, Erin Hoffman-John, Josh Lee, Lora Aroyo, Ravi Rajakumar,Alena Butryna, Matthew Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Cohen,Rachel Bernstein, Ray Kurzweil, Blaise Aguera-Arcas, Claire Cui, Marian Croak,Ed Chi, and Quoc Le. 2022. LaMDA: Language Models for Dialog Applications.arXiv:2201.08239 [cs.CL] Chunting Zhou, Pengfei Liu, Puxin Xu, Srini Iyer, Jiao Sun, Yuning Mao, XuezheMa, Avia Efrat, Ping Yu, L. Yu, Susan Zhang, Gargi Ghosh, Mike Lewis, LukeZettlemoyer, and Omer Levy. 2023. LIMA: Less Is More for Alignment. ArXivabs/2305.11206 (2023).",
  "using _only_ the provided summarized web search results": "The answer should be correct, high-quality, and written byan expert using an unbiased and journalistic tone. The user's language of choice such as English, Francais, Espamol,Deutsch, or should be used. The answer should beinformative, interesting, and engaging. The answer's logicand reasoning should be rigorous and defensible. Everysentence in the answer should be _immediately followed_ byan in-line citation to the search result(s). The citedsearch result(s) should fully support _all_ the information",
  "ACONVERSATIONAL GENERATIVE ENGINE": "In .1, we discussed a single-turn Generative Enginethatoutputs a single response given the user query. However, one of thestrengths of upcoming Generative Engines will be their ability toengage in an active back-and-forth conversation with the user. Theconversation allows users to provide clarifications to their queriesor Generative Engine response and ask follow-ups. Specifically,in equation 1, instead of the input being a single query , it ismodeled as a conversation history = (,) pairs. The response+1 is then defined as:",
  ":= (, ) +1(5)": "where is the turn number.Further, to engage the user in a conversation, a separate LLM, or , may generate suggested follow-up queries basedon , , and +1. The suggested follow-up queries are typicallydesigned to maximize the likelihood of user engagement. Thisnot only benefits Generative Engine providers by increasing userinteraction but also benefits website owners by enhancing theirvisibility. Furthermore, these follow-up queries can help users bygetting more detailed information.",
  "B.2Benchmark": "GEO-bench contains queries from nine datasets. Representativequeries from each of the datasets are shown in . Further, wetag each of the queries based on a pool of 7 different categories. Fortagging, we use the GPT-4 model and manually confirm high recalland precision in tagging. However, owing to such an automatedsystem, the tags can be noisy and should not be considered carefully.Details about each of these queries are presented here:",
  "Statistics Addition25.8(1.2)26.0(0.8)25.5(1.2)23.1(1.4)26.1(0.9)23.6(0.9)24.5(1.2)22.4(1.2)26.1(1.2)23.8(1.2)24.8(1.1)": ": Absolute impression metrics of GEO methods on GEO-bench. Compared to baselines, simple methods like KeywordStuffing traditionally used in SEO dont perform well. However, our proposed methods such as Statistics Addition and QuotationAddition show strong performance improvements across all metrics. The best methods improve upon baseline by 41% and 28%on Position-Adjusted Word Count and Subjective Impression respectively.",
  "C.1GEO in the Wild : Experiments withDeployed Generative Engine": "We also evaluate our proposed Generative Engine Optimizationmethods on real-world deployed Generative Engine: Perplexity.ai.Since perplexity.ai does not allow the user to specify source URLs,we instead provide source text as file uploads to perplexity.ai whileensuring all answers are generated only using the file sources pro-vided. We evaluate all our methods on a subset of 200 samples ofour test set. Results using Perplexity.ai are shown in ."
}