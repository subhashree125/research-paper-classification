{
  "Abstract": "The objective of privacy-preserving synthetic graph publishing is tosafeguard individuals privacy while retaining the utility of originaldata. Most existing methods focus on graph neural networks underdifferential privacy (DP), and yet two fundamental problems in gen-erating synthetic graphs remain open. First, the current researchoften encounters high sensitivity due to the intricate relationshipsbetween nodes in a graph. Second, DP is usually achieved throughadvanced composition mechanisms that tend to converge prema-turely when working with a small privacy budget. In this paper,inspired by the simplicity, effectiveness, and ease of analysis ofPageRank, we design PrivDPR, a novel privacy-preserving deepPageRank for graph synthesis. In particular, we achieve DP byadding noise to the gradient for a specific weight during learning.Utilizing weight normalization as a bridge, we theoretically revealthat increasing the number of layers in PrivDPR can effectivelymitigate the high sensitivity and privacy budget splitting. Throughformal privacy analysis, we prove that the synthetic graph gener-ated by PrivDPR satisfies node-level DP. Experiments on real-worldgraph datasets show that PrivDPR preserves high data utility acrossmultiple graph structural properties.",
  "Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 25, August 37, 2025, Toronto, ON, Canada 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-1245-6/25/08",
  "Introduction": "Numerous real-world applications, such as social networks ,email networks , and voting networks , are empowered bygraphs and graph analysis . For instance, Facebook leveragessocial network analysis to offer friend recommendations based onthe connections between different users . While the benefitsare indisputable, direct publication of graph data potentially resultsin individual privacy being exposed by different types of privacyattacks . Hence, it is crucial to sanitize graph data before makingit publicly available.Differential privacy (DP) is an extensively studied statisticalprivacy model thanks to its rigorous mathematical privacy frame-work. DP can be applied to graph data in two common ways :edge-level DP and node-level DP. Edge-level DP considers twographs as neighbors if they differ by a single edge, while node-levelDP considers two graphs as neighbors if they differ by the edgesconnected to a single node. Satisfying node-level DP can be chal-lenging as varying one node could result in the removal of 1edges in the worst case, where denotes the number of nodes.With the development of differentially private deep learning ,most existing methods focus on generating syn-thetic graph data by privatizing deep graph generation models. Theadvanced composition mechanisms, such as moments accountant(MA) , are employed to address excessive splitting of privacybudget during optimization, ensuring that the focus remains on mit-igating high sensitivity in graph data. For example, Yang et al. propose two solutions, namely differentially private GAN (DPG-GAN) and differentially private VAE (DPGVAE), which address highsensitivity by enhancing MA. However, they only achieve weakedge-level DP. Recently, a number of methods focus onGraph Neural Networks (GNNs) under node-level RDP, which of-ten mitigate high sensitivity by bounded-degree strategies. Despitetheir success, these methods achieve DP based on advanced compo-sition mechanisms and tend to converge prematurely, particularlywhen the privacy budget is small. This issue results in decreasedperformance in terms of both privacy and utility.Over the past two decades, PageRank has been widely usedin graph mining and learning to evaluate node rankings, thanks",
  "KDD 25, August 37, 2025, Toronto, ON, CanadaSen Zhang, Haibo Hu, Qingqing Ye, and Jianliang Xu": "In the deep learning with DP framework, described in the al-gorithm from Line 7 to Line 9, there is a potential issue of pre-mature termination when working with a limited overall privacybudget, such as 0.5. This occurs because the privacy loss metric,, converges rapidly towards the desired privacy level .As a result, the algorithm may stop prematurely before achievingthe desired level of privacy. This premature termination poses achallenge for existing deep learning models that utilize this frame-work. To mitigate this issue and improve the utility of the trainedmodels, it is often necessary to set a relatively large value for theprivacy budget parameter, . However, this approach introduces atrade-off between privacy and utility since a larger privacy budgetcarries a higher risk to data privacy.",
  "Differential Privacy": "DP is the prevailing concept of privacy for algorithms on statisticaldatabases. Informally, DP limits the change in output distributionof a mechanism when there is a slight change in its input. In graphdata, the concept of neighboring databases is established using twograph datasets, denoted as and . These datasets are consideredneighbors if their dissimilarity is limited to at most one edge ornode.",
  "SymbolDescription": ",Differential privacy parameters, Original and synthetic graphs,Any two neighboring graph datasets ,In-degree and out-degree of node AA randomized algorithm , Set of nodes and edges of Number of nodes in x, yLowercase letters denote vectorsX, YBold capital letters denote matricesx2, X22-norm and Spectral normDimension of low-dimensional vectorsDamping factor of PageRank model",
  "input graphs and that are neighbors (differ by at most one edgeor node), and for all possible (A), we have P[A() ] exp() P[A() ] +": "The concept of the neighboring dataset , is categorizedinto two types. Specifically, if can be derived by replacing asingle data instance in , it is termed bounded DP . If can beobtained by adding or removing a data sample from , it is termedunbounded DP . The parameter is referred to as the privacybudget, which is utilized to tune the trade-off between privacy andutility in the algorithm. A smaller value of indicates a higher levelof privacy protection. The parameter is informally considered asa failure probability and is typically selected to be very small.Suppose that a function maps a graph to a -dimensionaloutput in R. To create a differentially private mechanism from ,it is common practice to inject random noise into the output of .The magnitude of this noise is determined by the sensitivity of ,defined as follows.",
  "PageRank": "The Internet and social networks can be seen as vast graph struc-tures. PageRank is a well-known algorithm used for analyzingthe links in a graph, making it a representative method for graphlink analysis. It operates as an unsupervised learning approach ongraph data. The core concept of PageRank involves establishing arandom walk model on a directed graph, which can be viewed as afirst-order Markov chain. This model describes the behavior of awalker randomly visiting each node along the directed edges of thegraph. By meeting certain conditions, the probability of visitingeach node during an infinitely long random walk converges to astationary distribution. At this point, the stationary probabilityassigned to each node represents its PageRank value, indicating itssignificance. PageRank is defined recursively, and its calculationis typically performed using an iterative algorithm. The formaldefinition of PageRank is as follows: Lemma 2.4. Consider a graph . The PageRank score of a node ,denoted as , represents the probability of reaching node throughrandom walks. The value of can be calculated by summing up theranking scores of its direct predecessors , weighted by the reciprocalof their out-degree . Mathematically, we have:",
  "Problem Definition and Existing Solutions3.1Problem Definition": "In this paper, we consider a directed and unweighted graph =(, ), where represents the set of nodes and represents theset of edges. An undirected graph is a special case of the graphthat we have defined and is included in our problem definition. Ourprimary objective is to address the following problem: given a graph, how can we generate a synthetic graph that possesses similargraph properties as the original graph , while ensuring node-levelDP. Definition 3 (Graph Synthesis under Bounded DP1). A graphsynthesis model L satisfies (,)-node-level DP if two neighboringgraphs and , which differ in only a node and its correspondingedges, satisfy the following condition for all possible (L ):",
  "Existing Solutions": "Existing solutions for graph generation include two tracks: differen-tially private shallow graph models and differentially private deepgraph learning models. As our focus is on the latter one, we willdefer the introduction of private shallow models to . Intraditional differentially private deep learning , the advancedcomposition mechanisms (i.e., MA) are employed to address exces-sive splitting of privacy budget during optimization. DP optimizersfor non-graph data typically update on the summed gradient withGaussian noise:",
  "clipping function defined as(g ()) = g () /max1, g( ) 2": ", is the clipping threshold, and is the batch size. In graph learning,individual examples no longer compute their gradients indepen-dently because changing a single node or edge in the graph mayaffect all gradient values. To address this issue, three types of solu-tions have been proposed: Private GAN model. DPGGAN is a differentially privateGAN for graph synthesis. It improves the sensitivity by enhanc-ing the MA. DPGGAN proves that the noised clipped gradient gapplied as above guarantees that the learned graph generationmodel to be edge-level DP, with a different condition from thatin Theorem 2.1 due to the nature of graph generation.",
  "Private VAE model. DPGVAE is a differentially private VAEdesigned for graph synthesis. It achieves the same level of pri-vacy as DPGGAN under the same conditions": "Private GNN model. The features of one node can influence thegradients of other nodes in the network. The sensitivity for=1 (g ()) may reach under node-level DP. Severalsolutions have been proposed. The classic andadvanced approach is GAP , which uses aggregation pertur-bation to achieve RDP and introduces a new GNN architecturetailored for private learning over graphs, resulting in improvedtrade-offs between privacy and accuracy.Limitations. Despite the usefulness of these approaches, twolimitations in generating synthetic graphs have yet to be solved: 1)DPGGAN and DPGVAE only achieve weak edge-level DP, and 2) MAand RDP typically require a sufficient privacy budget to estimatethe privacy guarantee. Thus, these private models mentioned abovetend to converge prematurely with a small privacy budget. Weexplain the second issue in detail using Algorithm 1.",
  "Our Proposal: PrivDPR": "To tackle the limitations outlined in the previous section, we pro-pose a node-level differentially private deep PageRank for graphsynthesis, inspired by the simplicity, effectiveness, and ease of anal-ysis of PageRank in .2. First, we provide an overview of theapproach. Next, we describe how we construct the deep PageRankand achieve gradient perturbation. Finally, we present the completetraining algorithm.",
  "Deep PageRank. We design a deep PageRank that serves as thefoundation for analyzing the correlation between the numberof layers, high sensitivity, and privacy budget splitting. (see.2)": "Gradient Perturbation. We achieve private deep PageRankby gradient perturbation. Instead of directly reducing high sen-sitivity, we first reveal theoretically that we can preset a desiredsmall sensitivity and achieve it by slightly increasing the num-ber of layers. We then show that the theorem can be extendedto resist privacy budget splitting. (see .3) Graph Reconstruction. We reconstruct the graph by exam-ining the co-occurrence counts of nodes using the acquiredrepresentations during optimization. This process entails creat-ing a transition count matrix, and deriving an edge probability",
  "where (; ) is a fully connected neural network in the followingform: (; ) = +1 (W+1 (W (1 (W1 (. . .1 (VW1) . . .))))) .(4)": "shows the detailed architecture of deep PageRank (i.e.,Eq. (3)), in which graph data is fed into the neural network througha virtual one-hot encoding of nodes as V. The set of learning pa-rameters is denoted as = {V, W1, , W, W+1}, with V indimensions of , W1 in dimensions of , W in dimensionsof , and W+1 in dimensions of 1. The activation functionemployed in each layer is denoted as . For simplicity, the biasterms of each layer are omitted.However, in the backpropagation of deep PageRank, applyingstochastic gradient descent (SGD) to update L becomes infeasible,since the squared loss term in Eq. (3) involves a summation overall nodes pointing to node , denoted as . This means thateach squared loss term aggregates information from multiple linkspointing to the same node , which contradicts the standard SGDassumption (i.e., (,) ) and is thus non-decomposable. Toaddress this challenge, we alternatively establish an upper boundfor L .",
  "where the sensitivity of (, ) L(,;)": "V, denoted asS, can reach up to , as modifying one node could potentiallyimpact all gradients in Eq. (6).As shown in , we design an optimizable matrix V as theinput to the neural network (; ). Since our goal is to privatizeV for graph synthesis, we only need to add noise to the gradient ofV, rather than to the gradients of all the weights. Inspired by this,we explore the use of weight normalization in (; ), which en-ables us to naturally bound the gradient of V and further reveal therelationships among the models parameters. Using weight normal-",
  "The following is a real example showing the calculation toachieve a preset sensitivity": "Example 4.5. Citeseer is a popular citation network with3,327 nodes and 4,732 edges, which is used as the input data. Recall (; ) with V R , W R , and W+1 R1. Using = 3, 327, = 0.85, we have 10, 464. Then, with = =128, S = 5, = 128, = 5, we determine that 7 using Eq. (12). 4.3.2How to Resist Privacy Budget Splitting? Given the totalprivacy parameters and , and the total number of iterations for model optimization, the sequential composition propertyof DP in Theorem 2.2 requires dividing both and . Insteadof using advanced composition mechanisms, we evenly divideprivacy parameters and . In particular, we calculate using",
  "Model Optimization": "The pseudo-code of PrivDPR are presented in Algorithm 2. We firstgenerate a batch set by random walk. Next, we input these sam-ples into the node embedding matrix V using a one-hot encodedvector with a length of . The resulting low-dimensional vectorsare then fed into a neural network. To constrain the gradient withrespect to V, we normalize each weight W using weight normal-ization, and then update W. Subsequently, we introduce Gaussiannoise to the sum of the gradients for V, and then update V. Aftereach parameter update, we count transitions in score matrix S. Af-ter finishing training, we transform S into edge probabilitymatrix A.",
  "Theorem 5.1. The synthetic graphs generated by PrivDPR satisfies(,)-node-level DP": "Proof. In Algorithm 2, for each weight parameter that needsoptimization, the total number of iterations = / isfixed a priori, and the desired privacy cost, say , is split across theiterations: = 1+ + . In this work, the privacy budget is evenlysplit across iterations, so 1 = = =",
  "PrivDPR: Synthetic Graph Publishing with Deep PageRank under Differential PrivacyKDD 25, August 37, 2025, Toronto, ON, Canada": "/. Random walk generation has a complexity of ()per batch. The complexity of weight normalization and private up-dates is (2). The score matrix has a complexity of ( 2). Con-sidering the refined considerations above, the overall time complex-ity can be expressed as ( (/( + 2) + 2)).This implies that the time complexity is linear with respect to thenumber of nodes in the graph, so our method is scalable and canbe applied to large-scale graphs.",
  "How does the privacy budget impact on the performance ofPrivDPR? (see .2)": "How scalable is PrivDPR in the context of link prediction andnode classification tasks? (see .3)Datasets. We run experiments on the five real-world datasets,Cora2, Citeseer , p2p3, Chicago4, and Amazon5. Cora is a cita-tion network of academic papers with 2,708 nodes, 7 classes, and5,429 edges. Citeseer is a similar citation network with 3,327 nodes,6 classes, and 4,732 edges. p2p is a sequence of snapshots fromthe Gnutella P2P network, consisting of 6,301 nodes and 20,777edges. Chicago is a directed transportation network of the Chicagoarea with 12,982 nodes and 39,018 edges. Amazon is a co-purchasenetwork with 410,236 nodes and 3,356,824 edges, representing prod-uct connections based on co-purchases. Since we focus on simplegraphs in this work, all datasets are pre-processed to remove self-loops.Baselines. We compare our PrivDPR 6 with four other baselines:GAP , DPGGAN , DPGVAE , and DPR (No DP). GAPrepresents the current state-of-the-art differentially private GNNmodel, designed to produce private node embeddings. For a faircomparison, we configure GAP to generate synthetic graphs usingthe same generation method as PrivDPR. For a fair comparison, weconfigure GAP to generate synthetic graphs using the same generationmethod as PrivDPR. In this study, we simulate a scenario in which thegraphs contain only structural information, whereas GAP dependson node features. To guarantee a fair evaluation, similar to priorresearch , we employ randomly generated features as inputs forGAP. Given that random features do not infringe on privacy, weeliminate the noise perturbation on features in GAP. DPR (No DP)serves as the non-private version of PrivDPR.Parameter Settings. In PrivDPR, we vary the privacy budget from {0.1, 0.2, 0.4, 0.8, 1.6, 3.2} while keeping the privacy parameter fixed at 105. The learning rate is set to = 1 103, which isconsistent with the settings used in DPGGAN and DPGVAE. Welimit the maximum number of training epochs to = 5. Theembedding dimension is chosen as = 128. Note that we do notspecifically show the effect of as its setting is commonly usedin various network embedding methods . The",
  "code is available at": "delay factor is set to = 0.85. The batch size is = 16. Also, weuse = 2 random walks with a length of = 16. Thesevalues are one-fifth of the recommended values in DeepWalk .In .1, we investigate the impact of adjusting the weightnormalization parameter on PrivDPR, while considering the valueof S as 5, which is determined based on DPGGAN. Note that we donot modify the number of layers in PrivDPR, since it is calculateddynamically based on using Eq. (13). Also, in .1, we assessthe influence of varying the dimension of the hidden layer weight on PrivDPR. To ensure consistency with the original papers, weemploy the official GitHub implementations for GAP, DPGGAN,and DPGVAE. We replicate the experimental setup described inthose papers to maintain consistency and comparability.Graph Utility Metrics. To evaluate the similarity between and, we use eight graph topological metrics: triangle count (TC),wedge count (WC), claw count (CC), relative edge distributionentropy (REDE), characteristic path length (CPL), Diameter, size ofthe largest connected component (LCC), and degree distribution.We evaluate the accuracy of PrivDPR in the aforementionedgraph metrics patterns over all datasets against the baselines. The ac-curacy of each method A on graph is measured by the mean rela-",
  "A ()": ",where A () denotes the true query result in input graph , andA () denotes the differentially private query result in . Eachresult reported is averaged over five repeated runs, that is |A| = 5.A lower MRE indicates a lower error and thus a higher data utility.The degree distribution is measured with Kolmogorov-Smirnov(KS) , which quantifies the maximum distance betweenthe two-degree distributions. Let and denote the cumula-tive distribution functions estimated from the sorted degree se-quences of the original and synthetic graphs, respectively. Then = max | () ()|. The smaller this statistic value, thecloser (more similar) the degree distributions between the syntheticand original graphs. For KS, we also report the average performanceover five independent runs.",
  "Impact of Parameters": "Parameter . In this experiment, we investigate the impact of theparameter on the performance of PrivDPR, focusing on graph met-rics such as TC, REDE, CPL, and KS. For the datasets Cora, Citeseer,p2p, and Chicago, we consider different values of , namely, 2, 4, 6, 8.As shown in , we analyze the standard deviation (SD) ofthe MRE and values for PrivDPR across various . Remark-ably, we consistently observe that the SD remains consistently notmore than 3.5122 02 across all datasets. This result highlightsthe robustness of PrivDPR against variations in . Based on thesefindings, we have made the decision to set as a constant value of8 in subsequent experiments.Parameter . In this experiment, we investigate the impact of theweight dimension parameter on the performance of PrivDPR interms of various graph metrics, including TC, REDE, CPL, and .Specifically, we consider different values of, namely, 64, 128, 256, 512for datasets Cora, Citeseer, p2p, and Chicago. As illustrated in Ta-ble 3, we observe that the SD of the MRE and values forPrivDPR with different is consistently not more than 5.8030 02across all datasets. This finding indicates that PrivDPR exhibits",
  "Impact of Privacy Budget on GraphStatistics Preservation": "The privacy budget is a critical parameter in the context of DP,as it determines the level of privacy provided by the algorithm.We conduct experiments to evaluate the impact of on the per-formance of each private algorithm. Specifically, we present theresults on Cora in . The results on Citeseer, p2p and Chicagodatasets can be found in Appendix E. From these figures, PrivDPR consistently outperforms both DPGGAN and DPGVAE with weakedge-level DP guarantees. The reasons why the results of DPGGANand DPGVAE are poor are twofold: 1) they use the MA mechanismand tend to converge prematurely under small ; and 2) they use athreshold-based method for reconstructing synthetic graphs, whichpotentially generates numerous disconnected subgraphs withinthe synthesized graph. Moreover, it is worth noting that in mostcases, PrivDPR achieves comparable results to DPR (No DP) andsurpasses GAP, even with a small privacy budget of = 0.1. Thisphenomenon can be attributed to two factors. First, our designeddeep PageRank effectively captures the structural properties of theinput graph. Second, the theorem presented in .3 addresseschallenges such as high sensitivity and excessive splitting on theprivacy budget, further enhancing the performance of PrivDPR.",
  "Link Prediction and Node Classification": "For the link prediction task, the existing links in each dataset arerandomly divided into a training set (80%) and a test set (20%). Toevaluate the performance of link prediction, we randomly select anequal number of node pairs without connected edges as negativetest links for the test set. Additionally, for the training set, we samplethe same number of node pairs without edges to construct negativetraining data. We measure performance using the area under theROC curve (AUC). The AUC results and analysis for all methods arepresented in Tables 4 and 5, with = 0.1 and = 3.2, in Appendix F.In summary, PrivDPR consistently achieves the highest AUC amongall privacy-preserving algorithms and maintains high stability.For the node classification task, we randomly sample 90% ofthe nodes as training data and randomly sample 10% of the nodesoutside the training set as test data. We follow the procedure of and evaluate our embeddings using Micro-F1 score. We report theresults in in Appendix G, with = 0.1 and = 3.2. To sum-marize, PrivDPR outperforms other privacy methods across variousdatasets in terms of Micro-F1 and SD. This indicates PrivDPR is anoutstanding off-the-shelf method for different graph downstreamtasks.",
  "Private Shallow Graph Generation Models": "Several research efforts have been dedicated to achieving differ-entially private publication for social graph data. One approach isto generate representative synthetic graphs using the Kroneckergraph model, as explored by Mir and Wright . They estimatethe model parameters from the input graph under DP. Anotherapproach is the Pygmalion model proposed by Sala et al., whichutilizes the dK-series of the input graph to capture the distributionof observed degree pairs on edges . This model has been com-bined with smooth sensitivity to construct synthetic graphs .",
  ": Privacy budget on Cora": "Xiao et al. encode the graph structure through private edge count-ing queries under the hierarchical random graph model and reportimproved results compared to the dK-series approach . Chenet al. employ the exponential mechanism to sample an adjacencymatrix after clustering the input graph . Proserpio et al. suggestdown-weighting the edges of a graph non-uniformly to mitigatehigh global sensitivity arising from very high degree nodes. Theydemonstrate this approach, combined with MCMC-based sampling,for generating private synthetic graphs . Gao and Li proposea private scheme to preserve both the adjacency matrix and per-sistent homology, specifically targeting the persistence structuresin the form of holes . These methods, along with subsequentresearch on private graph release , typically guaranteeweak edge-level DP.",
  "Private Deep Graph Generation Models": "With the rapid development of deep learning, numerous advanceddeep graph generation models have emerged in recent times. Thesemodels employ various powerful neural networks in a learn-to-generate manner . For instance, NetGAN convertsgraphs into biased random walks, learns to generate walks us-ing GAN, and then constructs graphs from the generated walks.GraphRNN , on the other hand, treats graph generation as asequence of node and edge additions, and models it using a heuris-tic breadth-first search scheme and hierarchical RNN. These deeplearning models can generate graphs with richer properties andflexible structures learned from real-world networks. However,existing research on deep graph generation has not thoroughlyexamined the potential privacy threats associated with trainingand generating graphs using powerful models. A recent relatedsolution proposed by Yang et al. introduces DPGGAN and DPG-VAE models for graph synthesis . They improve MA , which is an effective strategy for computing privacy loss after multiplequeries, but only achieves weak edge-level DP. Recent researchendeavors have been dedicated to the advancementof node-level differentially private GNNs. These efforts aim to ad-dress the issue of high sensitivity, but achieving an optimal balancebetween privacy and utility remains a significant challenge. This isprimarily because they often employ advanced composition mecha-nisms to manage privacy budget splitting and yet tend to convergeprematurely when working with a small privacy budget.",
  "Conclusion": "This paper focuses on synthetic graph generation under DP. Theunderlying highlights lie in the following two aspects. First, wedesign a novel privacy-preserving deep PageRank for graph syn-thesis, called PrivDPR, which achieves DP by adding noise to thegradient for a specific weight during learning. Second, we theoret-ically show that increasing the number of layers can effectivelyovercome the challenges associated with high sensitivity and pri-vacy budget splitting. Through privacy analysis, we prove that thegenerated synthetic graph satisfies (,)-node-level DP. Extensiveexperiments on real-world graph datasets show that our solutionsubstantially outperforms state-of-the-art competitors. Our futurefocus is on developing more graph generation techniques for nodeembeddings to enhance the utility of synthetic graphs. This work was supported by the National Natural Science Founda-tion of China (Grant No: 62372122, 92270123 and 62072390), andthe Research Grants Council, Hong Kong SAR, China (Grant No:15224124, 25207224, C2004-21GF and C2003-23Y). We also thankDr. Nan Fu and Dr. Lihe Hou for helpful discussions.",
  "Rui Chen, Benjamin C Fung, Philip S Yu, and Bipin C Desai. 2014. Correlatednetwork data publication via differential privacy. The VLDB Journal 23, 4 (2014),653676": "Ameya Daigavane, Gagan Madan, Aditya Sinha, Abhradeep Guha Thakurta,Gaurav Aggarwal, and Prateek Jain. 2021. Node-level differentially private graphneural networks. arXiv preprint arXiv:2111.15521 (2021). Lun Du, Xu Chen, Fei Gao, Qiang Fu, Kunqing Xie, Shi Han, and Dongmei Zhang.2022. Understanding and improvement of adversarial training for networkembedding from an optimization perspective. In ACM International Conferenceon Web Search and Data Mining. 230240.",
  "Marek Eli, Michael Kapralov, Janardhan Kulkarni, and Yin Tat Lee. 2020. Dif-ferentially private release of synthetic graphs. In Annual ACM-SIAM Symposiumon Discrete Algorithms. 560578": "Alessandro Epasto, Vahab Mirrokni, Bryan Perozzi, Anton Tsitsulin, and PeilinZhong. 2022. Differentially private graph learning via sensitivity-bounded per-sonalized pagerank. In International Conference Neural Information ProcessingSystems. 2261722627. Jie Fu, Qingqing Ye, Haibo Hu, Zhili Chen, Lulu Wang, Kuncan Wang, and XunRan. 2024. DPSUR: Accelerating differentially private stochastic gradient descentusing selective update and release. In Proceedings of the VLDB Endowment. 12001213.",
  "Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, andTina Eliassi-Rad. 2008. Collective classification in network data. AI Magazine 29,3 (2008), 93106": "Dushyant Sharma, Rishabh Shukla, Anil Kumar Giri, and Sumit Kumar. 2019. Abrief review on search engine optimization. In International Conference on CloudComputing, Data Science and Engineering. 687692. Haipei Sun, Xiaokui Xiao, Issa Khalil, Yin Yang, Zhan Qin, Hui Wang, and Ting Yu.2019. Analyzing subgraph statistics from extended local views with decentralizeddifferential privacy. In ACM SIGSAC Conference on Computer and CommunicationsSecurity. 703717.",
  "Qian Xiao, Rui Chen, and Kian-Lee Tan. 2014. Differentially private networkdata release via structural inference. In ACM SIGKDD Conference on KnowledgeDiscovery and Data Mining. 911920": "Carl Yang, Haonan Wang, Ke Zhang, Liang Chen, and Lichao Sun. 2021. Se-cure deep graph generation with link differential privacy. In International JointConference on Artificial Intelligence. 32713278. Qingqing Ye, Haibo Hu, Kai Huang, Man Ho Au, and Qiao Xue. 2023. StatefulSwitch: Optimized time series release with local differential privacy. In IEEEINFOCOM Conference on Computer Communications. 110. Qingqing Ye, Haibo Hu, Ninghui Li, Xiaofeng Meng, Huadi Zheng, and HaotianYan. 2021. Beyond Value Perturbation: Local differential privacy in the temporalsetting. In IEEE INFOCOM Conference on Computer Communications. 110.",
  "Qingqing Ye, Haibo Hu, Xiaofeng Meng, and Huadi Zheng. 2019. PrivKV: Key-value data collection with local differential privacy. In IEEE Symposium on Securityand Privacy. 317331": "Qingqing Ye, Haibo Hu, Xiaofeng Meng, Huadi Zheng, Kai Huang, ChengfangFang, and Jie Shi. 2021. PrivKVM*: Revisiting key-value statistics estimation withlocal differential privacy. IEEE Transactions on Dependable and Secure Computing20, 1 (2021), 1735. Jiaxuan You, Rex Ying, Xiang Ren, William Hamilton, and Jure Leskovec. 2018.GraphRNN: Generating realistic graphs with deep auto-regressive models. InInternational Conference on Machine Learning. 57085717. Quan Yuan, Zhikun Zhang, Linkang Du, Min Chen, Peng Cheng, and MingyangSun. 2023. PrivGraph: Differentially private graph data publication by exploitingcommunity information. In USENIX Security Symposium. 32413258.",
  "AGraph Synthesis": "In what follows, we describe the specific details of generating graphsas discussed in previous works . Once training is complete,we employ the node embeddings to create a score matrix S thatrecords transition counts. Since we intend to analyze this syntheticgraph, we convert the raw counts matrix S into a binary adjacencymatrix. Initially, S is symmetrized by setting = = max(,).However, since we have no explicit control over the starting nodeof the random walks generated by , high-degree nodes are likelyto be overrepresented. Consequently, a simple strategy such asthresholding or selecting the top- entries for binarization mayexclude low-degree nodes and create isolated nodes. To addressthis concern, we ensure that every node has at least one edgeby sampling a neighbor with a probability of = . If anedge has already been sampled, we repeat this procedure. To ensurethe graph is undirected, we include (,) for every edge (, ). Wecontinue sampling edges without replacement, using the probability = , for each edge (, ), until we reach the desired numberof edges (e.g., determined by applying the Sigmoid function withthe threshold value 0.5 to the score matrix). Additionally, to ensurethe graph is undirected, we include (,) for every edge (, ).",
  "CProof of Lemma 4.3": "Proof. The Lipschitz constant of a function and the norm of itsgradient are two sides of the same coin. We define Lip as thesmallest value such that (x) (x)/x x for anyx, x, with the norm being the 2-norm. We can use the inequality1 2Lip 1Lip 2Lip to observe the following bound on",
  "=1W 2 ,": "where the step (i) holds since the Sigmoid function is used, andthe step (ii) holds because weight normalization is implementedthrough spectral normalization. The Sigmoid function can be sub-stituted with other activation functions, such as ReLU and leakyReLU, while the inequalities above still hold.According to Lip, it is possible to show that (;)",
  "FLink Prediction": "A higher value of AUC indicates better utility. From Tables 4 and5, PrivDPR consistently shows the highest AUC scores across alldatasets. This indicates that it is the most effective algorithm forlink prediction while maintaining node-level privacy. DPGGANand DPGVAE, which both offer edge-level privacy, exhibit similarperformance levels with = 0.1 and = 3.2. GAP has the lowestAUC scores compared to the other algorithms, indicating that it isthe least effective for link prediction at both = 0.1 and = 3.2.In the context of SD, a smaller value reflects greater stability inthe algorithm. PrivDPR exhibits the lowest SD across all datasetsunder = 0.1, and also demonstrates the lowest SD for the Cora",
  "GNode Classification": "A higher Micro-F1 score indicates better utility. PrivDPR achievesthe highest average Micro-F1 scores on the Cora and Citeseerdatasets under both = 0.1 and = 3.2. This indicates PrivDPR isan effective algorithm for privacy-preserving node classification.DPGVAE follows with slightly poor Micro-F1 scores but showsstable performance. GAP scores slightly lower than PrivDPR andDPGVAE, and yet performs well especially with larger privacybudgets ( = 3.2). DPGGAN obtains the lowest Micro-F1 scores,particularly struggling with smaller privacy budgets ( = 0.1). Interms of SD, under = 0.1, it is observed that PrivDPR achievesthe most stable result on Cora, while GAP achieves the most sta-ble result on Citeseer. Additionally, both DPGVAE and PrivDPRdemonstrate relatively stable performance across both datasets. Un-der = 3.2, GAP achieves the most stable result on Cora, whileDPGVAE achieves the most stable result on Citeseer. Nevertheless,DPGGAN displays relatively stable performance across both Coraand Citeseer datasets."
}