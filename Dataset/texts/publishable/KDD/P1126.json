{
  "ABSTRACT": "Time series domain adaptation stands as a pivotal and intricatechallenge with diverse applications, including but not limited tohuman activity recognition, sleep stage classification, and machinefault diagnosis. Despite the numerous domain adaptation tech-niques proposed to tackle this complex problem, they primarilyfocus on domain adaptation from a single source domain. Yet, it ismore crucial to investigate domain adaptation from multiple do-mains due to the potential for greater improvements. To addressthis, three important challenges need to be overcome: 1). The lackof exploration to utilize domain-specific information for domainadaptation, 2). The difficulty to learn domain-specific informationthat changes over time, and 3). The difficulty to evaluate learneddomain-specific information. In order to tackle these challengessimultaneously, in this paper, we introduce PrOmpt-based domaiNDiscrimination (POND), the first framework to utilize prompts fortime series domain adaptation. Specifically, to address Challenge1, we extend the idea of prompt tuning to time series analysis andlearn prompts to capture common and domain-specific informationfrom all source domains. To handle Challenge 2, we introduce a con-ditional module for each source domain to generate prompts fromtime series input data. For Challenge 3, we propose two criteria toselect good prompts, which are used to choose the most suitablesource domain for domain adaptation. The efficacy and robustnessof our proposed POND model are extensively validated throughexperiments across 50 scenarios encompassing four datasets. Ex-perimental results demonstrate that our proposed POND modeloutperforms all state-of-the-art comparison methods by up to 66%on the F1-score.",
  "INTRODUCTION": "Due to the prevalence of time series sensor data, time series analysishas found applications in various real-world scenarios, includinghuman activity recognition , sleep stage classification , andmachine fault diagnosis . In these applications, timeseries data are measured under different subjects, operating con-ditions, or sensor configurations (i.e., domains). In other words,time series analysis should be conducted across different domains.Unfortunately, the labels of time series data are difficult to collectdue to the expensive costs of the labeling process . To mitigatelabeling costs, researchers aim to leverage labeled data from somedomains (i.e., source domains) to infer labels for unlabeled datain other domains (i.e., target domains) , which is defined as atime series domain adaptation problem. For example, the goal ofthe transponder fault diagnosis problem is to detect the workingstatuses of transponders (i.e., normal or abnormal) based on fiber-optic signals. In this problem, the model is trained under certainworking modes (e.g., single mode) using labeled time series data,and then this trained model is applied to other working modes (e.g.,multimode).However, the time series domain adaptation problem is highlychallenging due to complex dynamic time series patterns, distri-bution shift (i.e., different distributions of inputs among differentdomains), and possible label shift (i.e., different distributions oflabels among different domains) . These challenges havebeen extensively investigated by researchers, leading to the pro-posal of various methods to address the domain gap, such as kernelmatching , context information alignment , and temporal-spectral fusion . Most existing methods, however, primarilyfocus on domain adaptation from a single source domain. Yet, itis more crucial to investigate it from multiple sources. This is be-cause the more source domains are utilized, the greater potentialimprovements it can achieve. For instance, the collection of labeled",
  "KDD 24, August 2529, 2024, Barcelona, SpainJunxiang Wang et al": "indicates which source domain is most similar to the target do-main. To address this, a natural solution is to directly learn domain-specific information from the labeled time series pair ( ( ), ( )).This motivates us to utilize prompt tuning to learn domain-specificinformation, which was first introduced by the NLP communityand demonstrated impressive success in many NLP tasks .Compared with other domain adaptation techniques, prompt tun-ing has three advantages: firstly, prompts are adjusted via gradi-ents by labeled data from multiple source domains, which offerdomain-specific information; secondly, prompt tuning leveragessmall amounts of labeled data effectively for adaptation, which issuitable for the target domain with limited labeled data ; thirdly,prompts can be utilized as a heuristic to select the most similarsource domain to the target domain for adaptation.The prompt, which is extended from NLP to time series, is de-fined as a learnable vector that prepends to the time series input tolearn domain-specific information by the labeled pair ( ( ), ( )).",
  "RELATED WORK": "Previous research related to this study can be categorized into twomain areas: time series domain adaptation and Large LanguageModels (LLMs) for time series.Time Series Domain Adaptation: Works in this domain canbe classified into Unsupervised Domain Adaptation (UDA) and su-pervised methods.UDA is a common approach, particularly beneficial as it doesnot rely on labels in the target domain. For example, Liu and Xueintroduced the Adversarial Spectral Kernel Matching (AdvSKM) ap-proach, employing a specialized hybrid spectral kernel network toredefine the Maximum Mean Discrepancy (MMD) metric . Laiet al. aligned context information between different time series do-mains using a Markov decision process formulation and employeddeep reinforcement learning for anomaly detection . He et al.addressed feature and label shifts between the source and targetdomains using temporal and frequency features . Other notable",
  "POND: Multi-Source Time Series Domain Adaptation with Information-Aware Prompt TuningKDD 24, August 2529, 2024, Barcelona, Spain": "approaches include autoregressive models , sparse associativestructure alignment , variational methods , contrastivelearning , and temporal-spectral fusion .In addition to UDA, other methods transfer time series knowl-edge in a supervised manner. For instance, Jin et al. proposed anattention-based shared module to learn common latent features,incorporating a domain discriminator retaining domain-specificfeatures across multiple domains . Wilson et al. leveraged target-domain label distributions to enhance model performance withbenefits from multi-source time series data . However, to ourknowledge, all existing time series domain adaptation methods ne-glect domain-specific information such as unique temporal patterns,which could potentially be utilized for better domain adaptation.LLMs for Time Series: Large Language Models (LLMs) haveshown excellent performance in various Natural Language Pro-cessing (NLP) tasks such as natural language inference, questionanswering, and named entity recognition . Recent research hasextended LLMs to address time series problems, generally fallinginto two classes: prompt tuning and fine-tuning.In prompt tuning methods, pretrained LLMs use prompts (i.e.,a sequence of tokens prepended to the time series input) to learnspecific downstream tasks. For example, Xue and Salim proposedPromptCast, a novel approach that transforms numerical inputand output into prompts and frames the time series forecastingtask in a sentence-to-sentence manner . Cao et al. presentedthe TEMPO framework, which decomposed complex interactionsbetween trend, seasonal, and residual components, introducingselection-based prompts to facilitate distribution adaptation in non-stationary time series . Jin et al. proposed the TIME-LLM frame-work, reprogramming the input time series with text prototypesbefore feeding it into a frozen LLM to align the two modalities,with Prompt-as-Prefix (PaP) introduced to enrich the input con-text and guide the transformation of the reprogrammed input .LLMTime highlighted the efficacy of LLMs as zero-shot learnersby encoding numbers into texts as prompts and sampling possibleextrapolations as prompt completions . Sun et al. proposed theTEST model, training an encoder to embed time series tokens withcontrastive learning and aligning text prototypes with time series,utilizing prompts to adapt LLMs to different time series tasks .In contrast, fine-tuning is the other type of method to adaptLLMs to time series, adjusting some components while keepingothers frozen. For example, Zhou et al. presented the OFA frame-work, where only the embedding and normalization layers of LLMswere fine-tuned, while self-attention and feed-forward layers re-mained frozen . Chang et al. proposed the Llm4ts framework,fine-tuning in two stages: first, supervised fine-tuning to orientthe LLM towards time series data, followed by task-specific down-stream fine-tuning . For more information, please refer to therecent survey paper by Jin et al. . While these methods transferknowledge from LLMs to the time series domain, they do not ad-dress the time series domain adaptation problem, where knowledgefrom the source time series domain, rather than text, is transferredto the target domain.",
  "spectively. Here, ( ), ( ) R, where is the number of": "channels and is the sequence length. The labels ( ), ( ) ={1,2, , }, where ( = 1, , ||) represents a label class,and the number of classes is ||. ( ) = { ( )} and ( ) = { ( )}are the label sets for the source domain and the target domain, respectively. Sets ( ) = { ( )} and ( ) = { ( )} representthe input sets for the source domain and the target domain ,respectively. We assume that the labeled time series of all sourcedomains ( = 1, , ) are abundant, but the labeled time seriesare limited in the target domain . Then the multi-source timeseries domain adaptation problem is formulated as follows:Problem Formulation: Given the time series input sets ( )",
  ": ( ) ( )": "Our problem formulation is very flexible: the time series inputcan be either univariate (i.e., = 1) or multivariate (i.e., > 1);the time series domain adaptation can be from a single source (i.e., = 1) or multiple sources (i.e., > 1); the classification problemcan be either binary (i.e., = 2) or multi-class (i.e., > 2).",
  "The Flexible Prompt Generator": "The goal of this section is to explore methods for learning infor-mation that changes over time from different source domains fordomain adaptation (i.e., tackling Challenges 1 and 2). Most existingpapers propose various strategies to extract domain-invariant rep-resentations from all source domains by making different domainsindistinguishable . However, this idea may discarddomain-specific information from multiple source domains, which",
  "( ) = + ( )": "where R is a common prompt to learn the common char-acteristics of all source domains, which can also be directly appliedto the target domain , and ( ) R is a prompt to learndomain-specific information (i.e., information unique to the sourcedomain ), which will be utilized to select the most similar sourcedomain to the target domain .While the domain-specific prompt ( ) is potentially effec-tive to learn domain-specific information about the source domain (i.e., address Challenge 1), it cannot directly address Challenge2. This is because ( ) is time-independent and has little free-dom to capture time-dependent domain-specific information (e.g.,distribution shifts of fiber-optic signals). To tackle this, instead ofusing a fixed prompt, we learn such domain-specific information byprompts generated from the time series input. This is because thetime series input usually contains rich time-dependent information(e.g., time series distributions and trends). Specifically, we introducea conditional module ( ), parameterized by a neural network, togenerate instance-level prompts based on time series instances:",
  "Two Important Criteria for Good Prompts": "In the previous section, we extended prompt tuning to captureinformation on specific time series domains. While prompts areeasy to recognize in computer vision and natural language fields,the learned prompts of time series data are not recognizable tohumans, making it hard, if not impossible, to evaluate whetherprompts are good enough to learn information for time series data.For example, a hard prompt consists of natural language that clearlydescribes the task at hand, explicitly asks the model for some resultor action, and makes it easy to understand why the prompt elicitedsuch behavior from the model . In contrast, the learned promptsof specific time series domains are visualized as extra time segments,which are difficult to understand by humans. Moreover, there is alack of exploration on what constitutes a good prompt that capturesdomain-specific information without human-engineering priors.From our perspective, ideal prompts to capture domain-specificinformation should maintain high fidelity and high distinction, asillustrated in : high fidelity suggests large overlaps betweenthe learned domain-specific prompts and label information (i.e.,large + in ), and high distinction implies small overlapsamong domain-specific prompts of different source domains (i.e.,small in ). They are introduced in details as follows:High Fidelity. One important criterion for the prompt generator( ) is fidelity (i.e., the generated prompt ( )preserves thedomain-specific information of the source domain ). Motivatedby the theory of information bottleneck , high fidelity is definedas the large mutual information between ( )and ( ), whichshould be maximized:",
  "pared to the time series input ( ), i.e., ( ( )) ( ( ))": "Detailed proofs are provided in Section A.1 in the Appendix.These properties demonstrate that minimizing Equation (2) ensuresthat the generated prompts will not decrease fidelity and may addnew information to the time series input.High Distinction. In addition to high fidelity, it is essentialthat the generated domain-specific prompt ( ) distinguishesthe unique information of the source domain from other sourcedomains. This unique information not only aids in understandingthe differences between multiple time series source domains but alsoprovides valuable insights for selecting suitable sources for domainadaptation. To achieve this, from the perspective of informationtheory, we define the objective to maintain high distinction asminimizing the mutual information of domain-specific promptsbetween different source domains, which should be minimized asfollows:",
  "( (1 ), (2 )),(3)": "where (1 ) and (2 ) represent the domain-specific promptsof any two source domains 1 and 2. Equation (3) is computa-tionally infeasible to minimize directly, but it can be achieved byminimizing the leave-one-out upper bound . Other mutualinformation upper bounds, such as the contrastive log-ratio bound, can also conveniently be incorporated into our framework.Therefore, the objective to encourage high distinction is formulated",
  "catenation of the overall prompt + ( )and the time series": "input ( ). Two tuning parameters 1, 2 > 0 control the trade-offamong the training loss, the fidelity loss, and the discriminationloss.To optimize Equation (5), we need to enumerate all source do-mains, which may be inefficient and unscalable . To addressthis, we propose a simple yet effective learning algorithm based onthe classic Reptile meta-learning framework , which randomlypicks a source domain each time and conducts standard steps ofgradient descent without the need for calculating second deriva-tives. The learning process is outlined in Algorithm 1. Specifically,Line 3 updates the prompt generator ( ), and Lines 4-5 update thecommon prompt through extrapolation. Here, the local learningrate performs the gradient descent step, and the global learningrate performs the extrapolation step.",
  "In this section, we discuss the model architecture and implementa-tion, the theoretical aspects of our proposed POND model, and itscomparison with previous papers": "4.4.1Model Architecture and Implementation. For the model ar-chitecture of our proposed POND model, we employ the popularMixture of Expert (MoE) technique to enhance performance :each expert makes an independent prediction, and the router is re-sponsible for learning probability distributions over all predictions.The overall output of our POND model is a linear combination ofall predictions.For the architecture of a single expert, the time series input isfed into a patching layer (i.e., splitting a timeseries input intosubseries-level patches ), a projection layer, a position embed-ding layer, a transformer layer, and a linear head sequentially.The model implementation is illustrated in the following steps: (1) Model Pretraining: All experts of our POND model arepretrained by combining some labeled data from all sourcedomains (e.g. 60%), and the router, which aggregates outputsfrom all experts to make final predictions, is pretrained usingthe same labeled data. (2) Prompt Tuning: Given the pretrained POND model, otherlabeled time series data from all source domains (e.g. 40%)are utilized to learn the common prompt and the promptgenerator ( ) by Equation (5) (i.e., Algorithm 1), and theprompt generator of the target domain ( ) is optimized byEquation (6).",
  "(3) Prompt Adaptation: The most similar source domain isselected by Equation (7), whose prompt generator will beused in the target domain for prediction": "4.4.2Theoretical Analysis. We demonstrate the commonality anddifferences of our proposed POND model compared with tradi-tional prompt-tuning from the theoretical perspective. Specifically,we prove that our proposed POND model shares the universal ap-proximation with prompt tuning, and then we illustrate that ourproposed POND model overcomes the limitation of prompt tun-ing. Without loss of generality, we assume that only one expertmodel is available, and is removed (i.e., ( )= ( ) ( ( );) =",
  "defined as (F1, F2) = (F1() F2())1 . Then Theorem1 states that our proposed POND model can approximate any timeseries classifier, which are trained from specific source domains": "Theorem 1 (Universality of our POND Model). Let 1 < and > 0, and F ( ) : || is a time series classifer,which is trained from source domain and is L-Lipschitz, there exista prompt length and a POND model such that for any F ( ),we can find a domain-specific prompt generator ( ) : R from source domain with ( ([ +( ) (), ]), F ( )) < for all ( = 1, 2, ). Not only our proposed POND model shares the universality, italso overcomes the limitations of prompt tuning. The followingtheorem states that while prompt tuning may not be flexible enoughto learn some labeled time series pairs, our proposed POND modelcan overcome this limitation.",
  "[X2, X0], (2)1) from two source domains 1 and 2, respectively,": "where (1)1 (1)2. For some proposed POND model :(a).[The limitation of prompt tuning]There exists no prompt suchthat ([, ( )1]) = ( )1( = 1, 2).(b).[Our POND Model handles this limitation] There exist the commonprompt and the prompt generators ( ) ( = 1, 2) such that ([ + ( ) ( ( )1), ( )1]) = ( )1( = 1, 2).",
  "EXPERIMENTS": "In this section, we employ four benchmark datasets to evaluateour proposed POND model in comparison with six state-of-the-art methods. All experiments were conducted on a Linux serverequipped with an Intel(R) Xeon(R) Silver 4214 CPU and an NVIDIAGPU running version 510. More experiments are included in thesupplementary materials 1 due to space limitations.",
  "Experimental Settings": "Benchmark Dataset: We evaluated the performance of all methodson four benchmark datasets, HAR, WISDM, HHAR and SSC .The statistics of all benchmark datasets are shown in , whichare introduced as follows:1. HAR : The Human Activity Recognition (HAR) datasetincorporates data collected from three sensorsaccelerometer, gy-roscope, and body sensorsdeployed on 30 subjects (i.e., domains)engaged in six distinct activities.2. WISDM : The WIreless Sensor Data Mining (WISDM)dataset, using accelerometer sensors, involves 36 subjects partic-ipating in activities similar to the HAR dataset, with additionalchallenges due to class distribution imbalances among differentsubjects.3. HHAR : The Heterogeneity Human Activity Recognition(HHAR) dataset was collected from 9 subjects using sensor readingsfrom smartphones and smartwatches.4. SSC : The Sleep Stage Classification (SSC) problem aimsto categorize electroencephalography (EEG) signals into five stages.We utilize the Sleep-EDF dataset , including EEG recordingsfrom 20 healthy subjects.Comparison Methods: We compared our proposed PONDmethod with six state-of-the-art time series domain adaptationapproaches: Raincoat , CoDATs , Deep Coral , MMDA, DIRT-T and DSAN . All comparison methods areintroduced as follows:1. Raincoat : it is an unsupervised domain adaptation methodaddressing both feature and label shifts.2. CoDATs : it is the first method to handle multi-sourcedomain adaptation through adversarial training with weak super-vision.3. Deep Coral : it minimizes domain shift by aligning second-order statistics of source and target distributions.",
  "Linkofsupplementarymaterials:": "4. MMDA : it integrates Maximum Mean Discrepancy (MMD)and CORrelation ALignment (CORAL) along with conditional en-tropy minimization to address domain shift.5. DIRT-T : it utilizes adversarial training, conditional en-tropy, and a teacher model to align source and target domains.6. DSAN : it minimizes the discrepancy between source andtarget domains via a Local Maximum Mean Discrepancy (LMMD)that aligns relevant subdomain distributions.Metrics: Two performance metrics were employed: Macro-F1score and Accuracy. Macro-F1 is the unweighted mean of per-classF1 scores, treating all classes equally. Accuracy is the ratio of accu-rately predicted samples to all samples.Hyperparameter Settings: We adapted the setting of super-vised domain adaptation, where ten samples in the target domainwere used for domain transfer. All source-target scenarios wereselected randomly to ensure the fairness of the performance eval-uation. Single-source domain adaptation methods (e.g. Raincoat)were trained by combining all source domains. For the trainingset of all time series source domains, 60% was used for pretrainingour POND model, 20% for prompt tuning, and 20% for validationsets. The batch size was set to 16. The number of global steps ,global learning rate and the local learning rate were set to 50,0.01 and 0.001, respectively. The number of experts was set to three.The prompt generator is a two-layer Multi-Layer Perceptron (MLP)with Tanh activation. For the transformer model, the numbers ofencoder layers, decoder layers, and heads in the multi-head atten-tion were set to 2, 1, and 4, respectively. The dimensions of themulti-head attention and the feed-forward layer were set to 16and 128, respectively. The hyperparameters 1 and 2 were chosenbased on performance on the validation set. 1 and 2, along withother hyperparameters such as the number of epochs, are providedin . All methods were averaged by ten times.",
  "Experimental Results": "Performance Evaluation: We conducted a comprehensive per-formance evaluation to test all methods across approximately 50scenarios on four datasets. displays the F1-score and accu-racy of all methods on these datasets. Our proposed POND methodconsistently outperforms others across all four datasets. Specifi-cally, on the HAR dataset, the F1-score of POND is approximately0.9, only 2% lower than the top-performing comparison method,Raincoat. The F1-score gaps on the HHAR, and SSC datasets are 5%and 4.4%, respectively. The largest gap is observed in the WISDMdataset, where the F1-score and accuracy of POND hover around0.6 and 0.7, while all comparison methods score below 0.35 and 0.6,respectively. Considering the inherent difficulty of training on theWISDM dataset due to class imbalance, this highlights the effective-ness of our proposed POND, especially on challenging datasets.Among the comparison methods, Raincoat emerges as the bestoverall. In terms of F1-score, Raincoat outperforms MMDA by 5%",
  ": The F1-score and accuracy of all methods on fourbenchmark datasets: the proposed POND outperforms com-parison methods consistently": "on the HAR dataset and shows an 8% superiority over CoDATson the HHAR dataset. For accuracy, Raincoat performs 7% bet-ter than DIRT on the HHAR dataset and surpasses Deep Coralby 3% on the SSC dataset. CoDATs and Deep Coral also demon-strate competitive performance, achieving around 55% accuracy onthe WISDM dataset, while DSAN lags behind at 45%. On the otherhand, MMDA, DIRT, and DSAN exhibit varying performance acrossdatasets. For instance, DSAN performs comparably to Raincoat onthe SSC dataset but ranks the lowest on the WISDM dataset. presents the performance of all methods across variousscenarios in four datasets, including the upper bound achieved bytraining and testing on the target domain. The reported valuesinclude means and standard deviations from ten implementations,with the best results highlighted in bold. The complete performanceevaluation is available in the supplementary materials 1. Overall,our proposed POND model consistently outperforms all methods,aligning with the observations in . Notably, POND exhibitssuperior performance on the challenging WISDM dataset, as indi-cated by . For instance, POND outperforms all comparisonmethods by at least 23% when transferring from domains 0-17 todomain 18. While POND excels overall, there are instances wherecomparison methods outperform it. For example, Deep Coral per-forms better than POND by 2% when transferring domains 1-15 todomain 28 on the HAR dataset, and MMDA marginally outperformsPOND when transferring domains 1-15 to domain 21 on the HARdataset.In addition to superior performance, our proposed POND modeldemonstrates greater stability compared to all comparison meth-ods, as indicated by lower standard deviations. For instance, thestandard deviation of POND is 0.006 when transferring domains0-9 to domain 17 on the SSC dataset, while the standard deviationsof all comparison methods range between 0.024 and 0.118, being atleast 3 times larger than that of POND. Importantly, POND achievesresults close to the upper bound in many scenarios, such as \"HAR1-15 16\", \"SSC 0-9 18\", and \"HHAR 0-6 7\".Ablation Study: Next, we demonstrate the ablation study ofthe proposed POND method, whose goal is to identify whether allcomponents of our proposed POND model contribute to the perfor-mance. Specifically, we explore the necessity of the MoE technique,common prompt, and prompt generator. The challenging WISDM",
  ": The F1-score and accuracy of the proposed PONDmodel with different source domains: the performance growswith the increase of source domains. (The HHAR dataset hasless than 10 domains.)": "dataset was utilized to test the performance. illustrates theperformance of different scenarios, all of which were averaged by10 times. The first two rows show the performance with the com-mon prompt, and the prompt generator available only, respectively.The fourth to sixth rows demonstrate the performance without theMoE, common prompt, and prompt generator, respectively, andthe last row shows the performance of the complete POND model.Overall, our proposed POND model performs best when the MoE,common prompt, and prompt generator are all available, whichsuggests that all components are necessary for the outstandingperformance of our proposed POND model. For example, in the sce-nario of 18-23 6, the best performance without any componentonly achieves a performance no more than 0.58, whereas that ofthe complete POND model is 5% better. The gap is widened to 7%for the scenario 0-17 25.Sensitivity Analysis: In this section, we explore how sourcedomains influence performance on the target domain. illus-trates the relationship between performance metrics (F1-score andaccuracy) and the number of source domains, averaged over 10 im-plementations. Generally, our proposed POND model demonstratesimproved performance with an increasing number of source do-mains. For instance, POND achieves 50% accuracy with two sourcedomains for training, but this figure rises by 30% when an additional8 source domains are included. Similarly, the F1-score of PONDincreases by 20% when the number of source domains changesfrom 2 to 6. However, some exceptions exist. For example, thereis a notable 25% drop in F1-score when increasing the number ofsource domains from 6 to 7 on the WISDM dataset. Another in-stance involves a 5% performance drop when increasing the sourcedomains from 4 to 5 on the SSC dataset.Visualization of Discrimination Loss: Finally, we presenta visualization of the discrimination loss for pairwise sourcedomains. illustrates the exponents of discrimination lossesfor all pairs of source domains across four datasets. Both the X-axisand Y-axis represent the indexes of source domains. Darker colorsindicate smaller discrimination losses, reflecting better domain dis-crimination. The diagonals are left blank. Overall, our proposedPOND model effectively discriminates most source domains, asevidenced by the predominance of dark squares. For instance, do-mains 3-5 and domains 6-7 exhibit clear discrimination with lossesbelow 0.05. Similar effective discrimination is observed for domainpairs 6 and 0 on the WISDM dataset, domain pairs 1 and 5 on theHHAR dataset, and domains 5-7 and 0 in the SSC dataset. However,",
  ": The visualization of the exponent of discriminationloss: most pairs of source domains are well discriminated": "discrimination losses for some domain pairs are larger than others.For instance, on the HAR dataset, the discrimination loss betweendomains 0 and 6 is the largest, approximately 0.30, but still withinan acceptable range. Its worth noting that domain discriminationmay not adhere to the transitive property. For example, domains3 and 9, as well as domains 4 and 9, are well-discriminated, butdomains 3 and 4 are relatively poor-discriminated.",
  "CONCLUSION": "Time series domain adaptation is an important problem with wide-ranging applications. Existing techniques primarily address single-source domain adaptation, yet exploring adaptation from multipledomains holds promise for greater improvements. In this paper, weintroduce POND, the first framework to utilize prompts for timeseries domain adaptation. We extend prompt tuning to time seriesanalysis to capture common and domain-specific information fromall source domains, introduce conditional modules for prompt gener-ation, and propose criteria for selecting effective prompts. Throughextensive experiments across 50 scenarios on four datasets, wedemonstrate the efficacy and robustness of POND, outperformingall state-of-the-art methods by up to 66% on the F1-score.",
  "Bai, G., Ling, C., and Zhao, L. Temporal domain generalization with drift-awaredynamic neural networks. In The Eleventh International Conference on LearningRepresentations (2022)": "Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P.,Neelakantan, A., Shyam, P., Sastry, G., Askell, A., et al. Language modelsare few-shot learners. Advances in neural information processing systems 33 (2020),18771901. Cai, R., Chen, J., Li, Z., Chen, W., Zhang, K., Ye, J., Li, Z., Yang, X., and Zhang,Z. Time series domain adaptation via sparse associative structure alignment.In Proceedings of the AAAI Conference on Artificial Intelligence (2021), vol. 35,pp. 68596867.",
  "Gruver, N., Finzi, M., Qiu, S., and Wilson, A. G. Large language models arezero-shot time series forecasters. arXiv preprint arXiv:2310.07820 (2023)": "He, H., Queen, O., Koker, T., Cuevas, C., Tsiligkaridis, T., and Zitnik, M.Domain adaptation for time series under feature and label shifts. In Proceedings ofthe 40th International Conference on Machine Learning (2329 Jul 2023), A. Krause,E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, and J. Scarlett, Eds., vol. 202 ofProceedings of Machine Learning Research, PMLR, pp. 1274612774. Jin, M., Wang, S., Ma, L., Chu, Z., Zhang, J. Y., Shi, X., Chen, P.-Y., Liang, Y., Li,Y.-F., Pan, S., et al. Time-llm: Time series forecasting by reprogramming largelanguage models. arXiv preprint arXiv:2310.01728 (2023). Jin, M., Wen, Q., Liang, Y., Zhang, C., Xue, S., Wang, X., Zhang, J., Wang, Y.,Chen, H., Li, X., Pan, S., Tseng, V. S., Zheng, Y., Chen, L., and Xiong, H. Largemodels for time series and spatio-temporal data: A survey and outlook. arXivpreprint arXiv:2310.10196 (2023).",
  "Kwapisz, J. R., Weiss, G. M., and Moore, S. A. Activity recognition using cellphone accelerometers. ACM SigKDD Explorations Newsletter 12, 2 (2011), 7482": "Lai, K.-H., Wang, L., Chen, H., Zhou, K., Wang, F., Yang, H., and Hu, X. Context-aware domain adaptation for time series anomaly detection. In Proceedings ofthe 2023 SIAM International Conference on Data Mining (SDM) (2023), SIAM,pp. 676684. Lessmeier, C., Kimotho, J. K., Zimmer, D., and Sextro, W. Condition monitoringof bearing damage in electromechanical drive systems by using motor currentsignals of electric motors: A benchmark data set for data-driven classification. InPHM Society European Conference (2016), vol. 3.",
  "Lester, B., Al-Rfou, R., and Constant, N. The power of scale for parameter-efficient prompt tuning. arXiv preprint arXiv:2104.08691 (2021)": "Li, Y., Chen, Z., Zha, D., Du, M., Ni, J., Zhang, D., Chen, H., and Hu, X. Towardslearning disentangled representations for time series. In Proceedings of the28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (2022),pp. 32703278. Ling, C., Zhao, X., Lu, J., Deng, C., Zheng, C., Wang, J., Chowdhury, T., Li,Y., Cui, H., Zhao, T., et al. Domain specialization as the key to make largelanguage models disruptive: A comprehensive survey. arXiv preprint arXiv 2305(2023).",
  "Shu, R., Bui, H., Narui, H., and Ermon, S. A dirt-t approach to unsuperviseddomain adaptation. In International Conference on Learning Representations (2018)": "Stisen, A., Blunck, H., Bhattacharya, S., Prentow, T. S., Kjrgaard, M. B.,Dey, A., Sonne, T., and Jensen, M. M. Smart devices are different: Assessing andmitigatingmobile sensing heterogeneities for activity recognition. In Proceedingsof the 13th ACM conference on embedded networked sensor systems (2015), pp. 127140. Sun, B., and Saenko, K. Deep coral: Correlation alignment for deep domain adap-tation. In Computer VisionECCV 2016 Workshops: Amsterdam, The Netherlands,October 8-10 and 15-16, 2016, Proceedings, Part III 14 (2016), Springer, pp. 443450.",
  "Tishby, N., Pereira, F. C., and Bialek, W. The information bottleneck method.arXiv preprint physics/0004057 (2000)": "Wang, D., Chen, Z., Fu, Y., Liu, Y., and Chen, H. Incremental causal graphlearning for online root cause analysis. In Proceedings of the 29th ACM SIGKDDConference on Knowledge Discovery and Data Mining (2023), pp. 22692278. Wang, D., Chen, Z., Ni, J., Tong, L., Wang, Z., Fu, Y., and Chen, H. Inter-dependent causal networks for root cause localization. In Proceedings of the29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (2023),pp. 50515060.",
  "Wang, Y., Chauhan, J., Wang, W., and Hsieh, C.-J. Universality and limitationsof prompt tuning. In Proceedings of Advances in Neural Information ProcessingSystems 36 (NeurIPS 2023) (2023)": "Wilson, G., Doppa, J. R., and Cook, D. J. Multi-source deep domain adaptationwith weak supervision for time-series sensor data. In Proceedings of the 26th ACMSIGKDD international conference on knowledge discovery & data mining (2020),pp. 17681778. Wu, Z., Wang, S., Gu, J., Hou, R., Dong, Y., Vydiswaran, V. V., and Ma, H. Idpg:An instance-dependent prompt generation method. In Proceedings of the 2022Conference of the North American Chapter of the Association for ComputationalLinguistics: Human Language Technologies (2022), pp. 55075521.",
  "Ying, Z., Bourgeois, D., You, J., Zitnik, M., and Leskovec, J. Gnnexplainer: Gen-erating explanations for graph neural networks. Advances in neural informationprocessing systems 32 (2019)": "Yue, Z., Wang, Y., Duan, J., Yang, T., Huang, C., Tong, Y., and Xu, B. Ts2vec:Towards universal representation of time series. In Proceedings of the AAAIConference on Artificial Intelligence (2022), vol. 36, pp. 89808987. Zhao, M., Yue, S., Katabi, D., Jaakkola, T. S., and Bianchi, M. T. Learning sleepstages from radio signals: A conditional adversarial architecture. In InternationalConference on Machine Learning (2017), PMLR, pp. 41004109.",
  "A.2Proofs of Theorems 1 and 2": "To prove Theorems 1 and 2, we follow the similar procedure of. To make proofs self-contained, we first mathematically for-mulate our simplified POND model . Without loss of generality,we assume that has only one expert transformer network, and itconsists of an attention layer and an MLP layer. The attention layerand the transformer layer are defined as follows :",
  "where () is the ReLU activation function": "Theorem 1 (Universality of our POND Model). Let 1 < and > 0, and F ( ) : || is a time series classifer,which is trained from source domain and is L-Lipschitz, there exista prompt length and a POND model such that for any F ( ),we can find a domain-specific prompt generator ( ) : R from source domain with ( ([ +( ) (), ]), F ( )) < for all ( = 1, 2, ). Proof. Let the common prompt = 0, the prompt generator( ) be constant ( ), and be a transformer with two heads ofsize one and four hidden units, then this theorem can be directlyderived from Theorem 1 in .",
  "(1)1 ( (2)1, (2)1) + (2)1in Theorem 2, and W, W, W,and W are full rank": "Assumption 2 (Assumption on the MLP Layer). ( )1( = 1, 2) inTheorem 2 are in the range set of . Moreover, the number ofchannels 2+(( 1( (1)1)X1)( 1( (2)1)X2))in Theorem 2. Here (S) measures the dimension of the subspacespanned by vectors in a set S and 1(y) = {x : (x) = y}."
}