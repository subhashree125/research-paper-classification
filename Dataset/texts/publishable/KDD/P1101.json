{
  "Dynamic Environment Responsive Online Meta-Learningwith Fairness Awareness": "CHEN ZHAO, Baylor University, USAFENG MI, The University of Texas at Dallas, USAXINTAO WU, University of Arkansas, USAKAI JIANG, The University of Texas at Dallas, USALATIFUR KHAN, The University of Texas at Dallas, USAFENG CHEN, The University of Texas at Dallas, USA The fairness-aware online learning framework has emerged as a potent tool within the context of continuouslifelong learning. In this scenario, the learners objective is to progressively acquire new tasks as they arriveover time, while also guaranteeing statistical parity among various protected sub-populations, such as raceand gender, when it comes to the newly introduced tasks. A significant limitation of current approaches lies intheir heavy reliance on the i.i.d (independent and identically distributed) assumption concerning data, leadingto a static regret analysis of the framework. Nevertheless, its crucial to note that achieving low static regretdoes not necessarily translate to strong performance in dynamic environments characterized by tasks sampledfrom diverse distributions. In this paper, to tackle the fairness-aware online learning challenge in evolvingsettings, we introduce a unique regret measure, FairSAR, by incorporating long-term fairness constraintsinto a strongly adapted loss regret framework. Moreover, to determine an optimal model parameter at eachtime step, we introduce an innovative adaptive fairness-aware online meta-learning algorithm, referred to asFairSAOML. This algorithm possesses the ability to adjust to dynamic environments by effectively managingbias control and model accuracy. The problem is framed as a bi-level convex-concave optimization, consideringboth the models primal and dual parameters, which pertain to its accuracy and fairness attributes, respectively.Theoretical analysis yields sub-linear upper bounds for both loss regret and the cumulative violation offairness constraints. Our experimental evaluation on various real-world datasets in dynamic environmentsdemonstrates that our proposed FairSAOML algorithm consistently outperforms alternative approaches rootedin the most advanced prior online learning methods.",
  "Additional Key Words and Phrases: Fairness, Online meta-learning, Changing environments, Adaption": "ACM Reference Format:Chen Zhao, Feng Mi, Xintao Wu, Kai Jiang, Latifur Khan, and Feng Chen. 2024. Dynamic EnvironmentResponsive Online Meta-Learning with Fairness Awareness. ACM Trans. Knowl. Discov. Data. 1, 1, Article 1(January 2024), 23 pages. Authors addresses: Chen Zhao, , Baylor University, One Bear Place #97356, Waco, Texas, USA, 76798-7356; Feng Mi, , The University of Texas at Dallas, 800 W. Campbell Road, Richardson, Texas, USA,75080-3021; Xintao Wu, , University of Arkansas, 4183 Bell Engineering Center, Fayetteville, Arkansas,USA, 72701; Kai Jiang, , The University of Texas at Dallas, 800 W. Campbell Road, Richardson, Texas,USA, 75080-3021; Latifur Khan, , The University of Texas at Dallas, 800 W. Campbell Road, Richardson,Texas, USA, 75080-3021; Feng Chen, , The University of Texas at Dallas, 800 W. Campbell Road,Richardson, Texas, USA, 75080-3021. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without feeprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and thefull citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored.Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requiresprior specific permission and/or a fee. Request permissions from . 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.1556-4681/2024/1-ART1 $15.00",
  ":2Zhao, et al": "1INTRODUCTIONIn the real world, data that includes biases are often collected incrementally over time, and theunderlying distribution assumptions can undergo significant changes at critical junctures. A casein point is a recent report by the New York Times , which highlights that systematic algorithmsexhibited increased discriminatory tendencies towards African Americans in the context of bankloans during the COVID-19 pandemic compared to the pre-pandemic era. These algorithms areconstructed from a series of sequentially gathered data streams, where decision-making exhibitsbias towards the protected racial population at each step. This situation underscores two key issues:(1) Online algorithms typically neglect the crucial aspect of fairness in learning, where fairness isdefined as the equality of predictive performance across different sub-populations, ensuring thata models predictions remain statistically independent of protected characteristics (e.g., race). (2)Machine learning models heavily rely on the i.i.d assumption, which becomes untenable when theenvironment undergoes changes, as exemplified by shifts occurring before and after the pandemic.To effectively manage bias over time, particularly in the context of ensuring fairness across variousprotected sub-populations, fairness-aware online algorithms are designed to address supervisedlearning problems where fairness is a prominent concern. These algorithms aim to sequentiallytrain predictive models that remain unbiased. In particular, the objective of these algorithms istwofold: first, to ensure that the static loss regret, which measures the cumulative loss of the learneragainst the best-fixed action in hindsight, and second, to limit the violation of various fairnessprinciples, both exhibit sub-linear growth in the total number of time steps . Its worth notingthat while these approaches achieve cutting-edge theoretical guarantees, its important to recognizethat the metric of static regret holds significance primarily in stable or stationary environments.Low static regret, however, doesnt necessarily translate to excellent performance in changingenvironments because time-invariant benchmarks may perform poorly under such circumstances.To overcome the challenge posed by changing environments in online learning, two distinctnotions of regret have garnered attention: strongly adaptive regret and dynamic regret .These concepts offer differing perspectives on handling changes over time. Dynamic regret takesa global approach, addressing changes in environments by comparing the cumulative loss of thelearner against a sequence of comparators. Importantly, it allows these comparators to evolveover time, reflecting the dynamic nature of the learning process. Conversely, strongly adaptiveregret adopts a more localized viewpoint, giving greater consideration to short time intervals. Thistype of regret can be seen as the maximum regret statistic across all intervals . While somerecent works have made strides in achieving sub-linear loss regret in online learningwithin changing environments, they often overlook the crucial aspect of learning with fairness.This neglect of fairness, which is a fundamental characteristic of human intelligence, remains asignificant limitation in these approaches.In this paper, we present a new challenge, namely fairness-aware online meta-learning inchanging environments. In this scenario, a series of data batches or tasks are collected sequentiallyover time, with the environments associated with these tasks potentially undergoing variations.Our primary objectives in this research are twofold: Firstly, we aim to extend the applicability ofpredictive learning accuracy and model fairness to novel and evolving environments. Secondly, weendeavor to minimize both loss regret and the cumulative violation of fairness constraints, ensuringthat they exhibit sublinear growth over time.To achieve these goals, we introduce a novel online learning algorithm named fair stronglyadaptive online meta-learner (FairSAOML). This algorithm updates model parameters through atwo-level approach: online fair interval-level learning and meta-level learning. These two levels",
  "Dynamic Environment Responsive Online Meta-Learning with Fairness Awareness1:3": "of problems interact with two sets of parameters: primal parameters , which pertain to modelaccuracy, and dual parameters , which govern fairness considerations. To provide more details, wedraw inspiration from the concept of learning with expert advice , and we carefully design threealternative sets of intervals. At each time step [], a subset of intervals is chosen to activateseveral experts, with each active expert running an interval-specific algorithm. An expert takesa meta-solution pair (1, 1) from the previous time as input and generates an interval-levelsolution (,, ,) for the specific interval . A meta-algorithm combines the weighted contributionsof all experts to form a solution pair (, ) at time , which is then utilized to make predictionsfor the subsequent time step. This approach allows us to address the challenges of fairness-awareonline meta-learning in changing environments effectively.The main contributions of this paper are summarized: In this paper, we propose a novel framework addressing the problem of fairness-aware onlinemeta-learning in changing environments. We start with the introduction of a novel adaptivefairness-aware regret FairSAR. A novel algorithm FairSAOML is further proposed to find agood decision sequentially. At each time, the problem is formulated as a constrained bi-levelconvex-concave optimization with respect to a primal-dual parameter pair.",
  "O( log)1/4for violation of fairness constraints": "We validate the performance of our approach with state-of-the-art techniques on real-worlddatasets. Our results demonstrate that FairSAOML can effectively adapt both accuracy andfairness in changing environments, and it shows substantial improvements over the bestprior works. This paper is organized as follows. In , some related works are introduced. provides notations and some backgrounds of this paper. In , we detail the proposedmethodology. In , we discuss the theoretically grounded analysis for the learning approach.Empirical settings and results on real-world benchmarks compared with cutting-edge techniquesare given in and . Finally, this paper is concluded in .",
  "RELATED WORK": "Changing environments in online learning. Since the pioneering work in online learning,numerous subsequent researches have been developed under the assumption of a stationaryenvironment with static regret. Low static regret, however, cannot imply a good performancein a changing environment due to time-invariant comparators. To address this limitation, tworegret metrics, dynamic regret and adaptive regret , is devised to measure the learnersperformance in changing environments. To bound the general dynamic regret, the path-length ofcomparators is introduced and further developed. Unlike dynamic regret, adaptive regrethandles changing environments from a local perspective by focusing on comparators in shortintervals. To reduce the time complexity of adaptive regret-based online algorithms, geometriccovering intervals and data streaming techniques are developed. Although existingmethods achieve state-of-the-art performance, a major drawback is that they immerse in minimizingobjective functions but ignore the model fairness of prediction.Fairness-aware online learning problems assume individuals arrive one at a time and thegoal of such algorithms is to train predictive models free from biases. From the perspective of",
  ":4Zhao, et al": "optimization, group fairness notions are normally considered as constraints added to learningobjectives. However, when the constraints are complex, the computational burden of the projectiononto constraints may be too high. Several closely related works, including FairFML , FairGLC, FairAOGD , aims to improve the theoretic guarantees by relaxing the output througha simpler closed-form projection. However, these methods are not ideal for continual lifelonglearning with changing task distributions, as they assume that all samples come from the samedata distribution.Online meta-learning addresses the issue of learning with fast adaptation, where a meta-learnerlearns knowledge transfer from history tasks onto new coming ones. FTML can be consideredas an application of MAML in the setting of online learning. FairFML extends FTML bycontrolling bias in an online working paradigm with task-specific adaptation. Unfortunately, noneof such techniques are devised to adapt to changing environments.Although a recent work tackles the problem of fairness-aware online learning for changingenvironments, it heavily depends on the assumption that the number of times is known in advanceand unchanged. The number of learning processes is hence fixed. Besides, due to the setting ofintervals in this work, the learning efficiency at the beginning times is low.In this paper, to bridge the above-mentioned areas, we study the problem of fairness-awareonline meta-learning to deal with changing task environments. In particular, at each time, modelparameters are determined by the proposed novel algorithm FairSAOML. This algorithm refersto ideas of dynamic programming and expert tracking techniques. Inspired by fairness-awareonline learning and meta-learning, a bi-level adaptation strategy is used to accommodate changingenvironments and learn models with accuracy and fairness.",
  "PRELIMINARIES": "3.1NotationsAn index set of a sequence of tasks is defined as [] = {1, 2, ..., } and = {, + 1, , }.Vectors are denoted by lowercase boldface letters. Scalars are denoted by lowercase italic letters.Some important notations are listed in . 3.2Constraints for Group FairnessIn general, group fairness criteria used for evaluating and designing machine learning modelsfocus on the relationships between the protected attribute and the system output . Theproblem of group unfairness prevention can be seen as a constrained optimization problem. Forsimplicity, we consider one binary protected attribute (e.g. gender) in this work. However, our ideascan be easily extended to many protected attributes with multiple levels.Let Z = X Y be the data space, where X = E S. Here E R is an input space, S = {1, 1}is a protected space, and Y = {1, 1} is an output space for binary classification. Given a task(batch) of samples {e,,}=1 (E Y S) where is the number of datapoints, a fine-grainedmeasurement to ensure fairness in class label prediction is to design fair classifiers by controllingthe notions of fairness between protected subgroups, such as demographic parity and equality ofopportunity . Definition 1 (Notions of Fairness ). A classifier : R R is fair when itspredictions are independent of the protected attribute s = {}=1. To get rid of the indicator functionand relax the exact values, a linear approximated form of the difference between protected subgroupsis defined ,",
  "NotationsDescriptions": "Total number of learning tasksIndices of tasksLength of time intervals in generalD , D , DSupport/Validation/Query set of data D, Meta-level primal/dual parameters at round ,, ,Interval-level primal/dual parameters for an expert at round ()Loss function at round ()Fairness functionTotal number of fairness notionsIndices of fairness notionsG()Base learnerUExpert setA, SActive/Sleeping expert set at round IAGC interval setCTarget set of intervals at round BRelaxed primal domainBProjection operation onto domain B1,2Learning rates,Expert weight of at round Augmented constant where | | is the absolute function and > 0 is the fairness relaxation determined by empirical analysis.1 is an empirical estimate of 1. 1 is the proportion of samples in group = 1 and correspondingly1 1 is the proportion of samples in group = 1. Notice that, in Definition 1, when 1 = P(e,,)Z( = 1), the fairness notion () is defined asthe difference of demographic parity (DDP). Similarly, when 1 = P(e,,)Z( = 1, = 1), () isdefined as the difference of equality of opportunity (DEO) . Therefore, parameters in thedomain of a task is feasible if it satisfies the fairness constraint () 0. 3.3Fairness-Aware Online LearningThe protocol of fairness-aware online convex optimization can be viewed as a repeated gamebetween a learner and an adversary, where the learner is faced with tasks {D}=1 one after another.At each round [],",
  "Step 3: The learner incurs an instantaneous loss (, D) and fairness notions (, D), []": "Step 4: Advance to + 1.The goal of fairness-aware online learning is to (1) minimize the loss regret over therounds, which is to compare to the cumulative loss of the best-fixed model in hindsight and (2)ensure the total violation of fair constraints sublinearly increase in . The loss regret is typicallyreferred to as static regret since the comparator is time-invariant. To control bias and ensure group",
  "(2)": "where the summation of fair constraints is defined as long-term constraints in . The big Onotation in the constraint is to bound the total violation of fairness sublinear in . The maindrawback of using the metric of static regret is that it is only meaningful for stationary environments,and low static regret cannot imply a good performance in changing environments since the time-invariant comparator in Eq.(2) may behave badly .",
  "Settings and Problem Formulation": "To address the limitation of changing environments in online learning, adaptive regret (AR) based on is defined as the maximum static regret over any contiguous intervals. However, AR does notrespect short intervals well. To this end, strongly adaptive regret (SAR) is proposed to improveAR, which emphasizes the dependence on lengths of intervals, and it takes the form that",
  "= (, D)(3)": "where indicates the length of time interval. In SAR, the learner is competing with changingcomparators, as varies with over [, + 1].In this paper, we consider the online meta-learning setting similar in , but tasks aresampled from heterogeneous distributions. Instead of static regret, we define a novel regret FairSARin Eq.(4). Let {}=1 be the sequence of model parameters generated in the Step 1 of the learningprotocol (see .3). The goal of our problem is to minimize FairSAR under the long-term fairconstraints:",
  "(4)": "where (0, 1). D , D D are the support and validation set. G () is the base learner whichcorresponds to one or multiple gradient steps . Different from traditional online learning settings,the long-term constraint violation () : B R R is satisfied. To facilitate our analysis, is originally chosen from its domain = { R : (, D) 0, []}. A projectionoperator is hence typically applied to the updated variables to make them feasible .To lower the computational complexity and accelerate the online processing speed, we relax thedomain to B, where B = K with K being the unit 2 ball centered at the origin, and = max{ > 0 : = || 1 2||2, 1, 2 }.In the protocol stated in .3, the key step (Step 1) is to find a good parameter ateach time . In the following subsections, we first introduce three types of intervals where eachinterval combines a list of tasks (.2); then, for each interval, a learning process (an expert)",
  "Dynamic Environment Responsive Online Meta-Learning with Fairness Awareness1:7": ". An illustration of adapting to changing environments using dynamic intervals (DI). (Left) At time1 [], a number of intervals {1, , 1} are selected from the interval set I . (Right) At time 2 > 1, adifferent interval set are selected. Assume that the environment changes at 1, to adapt to the change quickly,larger weights are given to the outputs through interval-level experts, where such outputs are not based onintervals prior to 1.",
  "Intervals": "In Eq.(4), FairSAR evaluates the learners performance on each time interval, and it is the maximumregret over any contiguous intervals. This subsection introduces three alternative interval setsto adapt to changing environments: dynamic intervals (DI) and two geometric covering-basedintervals (AGC and DGC). Each interval in an interval set refers to a range of time indices associatedwith a collection of data batches, as data batches arrive one after another over time. Inspired bylearning with expert advice , each interval is built upon a learning process, defined as an expert,and each expert updates model parameters via G and outputs interval-level parameters with respectto a specific interval. Details of the interval-level learning are given in .3.1.",
  "C= {| = , I, []}(6)": "Cdynamically selects a subset of intervals from I. An example is illustrated in . Attime 1, the target set C1 selects 1 intervals where C1= {, , , }. Similarly,when at time 2 where 2 > 1, C2 = {, , , , , }.To adapt to changing environments, at each time, a number of experts are initiated based onintervals selected in the target set. At time 2, each expert corresponding to an interval C2 ,where = , , takes the parameter 21 as well as its corresponding dataset {D}2=",
  "# total experts |U | at time log2 log2 + 1# active experts |A | at time log2 log2 + 1# sleeping experts |S | at time 0< log2 < log2 + 1ComplexityO()O(log)O(log)": ". (Upper) A graphical illustration of AGC intervals (base=2) with = 18. The interval set I consistsof 4 subsets {I0, I1, I2, I3} and each contains different numbers of intervals with fixed length. Intervalscovered by shadow is an example of target subset C5when = 5. (Lower) An illustration of DGC intervals(base=2) with is unknown in advance. The interval subsets {I0, I1, } increase as increases. Similar tothe setting of AGC intervals, when = 5, the target set C5only includes one interval 50. as input. Each expert independently gives an interval-level solution 2, on . A good 2 istherefore achieved at time 2 by further combining the decisions {2, }2=1 through weightedaverage. More details are stated in .3.The key idea of constructing dynamic intervals is that at time 2, some of the outputs {2, }2=1+1on intervals {1+1, , 2} are not based on any data prior to time 1 where 1 < 2, so that if theenvironment changes at 1, those outputs may be given a larger weight by the meta-algorithm,allowing it to adapt more quickly to the change.A main drawback with the construction of dynamic intervals, however, is a factor of increasein the time complexity. The number of intervals and learning processes increases linearly in time.To avoid this, we reduce the complexity to O(log) by restarting algorithms on a designed set ofgeometric covering intervals, i.e., AGC and DGC intervals in .2.2 and 4.2.3, respectively.",
  "[log2 1]{0}Iwhere, I = {| = [( 1) 2 + 1, min {, 2}], N}": "(7)An example with = 18 is given in to illustrate the composition of AGC intervals. Withselecting 2 as the log base in Eq.(7), intervals are hence decomposed into log182 = 4 subsets (i.e.,I0, I1, I2, and I3) with fixed lengths of 20 = 1, 21 = 2, 22 = 4, and 23 = 8. Notice that the log baseequals 2 is not required, but a larger base number leads to fewer interval subsets. AGC intervalscan be considered a special case of a more general set of intervals, and they efficiently reduce thetime complexity to O(log).Similar to DI, a target set C I including a set of intervals starting from are selectedfrom I at each time:",
  "As shown in , given = 18 and when = 5, the target set C5contains three intervals,, and , where each initiates at = 5 with interval lengths 1, 2, and 4, respectively": "4.2.3Dynamic Geometric Covering (DGC) Intervals. Although the setting of AGC intervals effi-ciently reduces the complexity, one limitation is that the total number of times needs to be knownand fixed in advance. However, this assumption does not always hold. This leads to the number ofinterval sets (i.e. log2 ) being unchanged in AGC, as {0, , log2 1}.To tackle this limitation, we alternatively propose another type of interval set, namely dynamicgeometric covering (DGC) intervals, I.",
  "{0,1,2, }Iwhere, I = {| = [ 2, ( + 1) 2 1], N}(9)": "illustrates the difference between the settings of DGC and AGC intervals. Since the totalnumber of times is unknown in advance, the number of interval sets, log2 + 1, in DGC increasesas becomes larger. For each interval set I, its first interval 1 I initializes at the 2-th time,and each interval I holds the same length of 2. Furthermore, the setting of the target setC I at time is the same as the one in AGC, referring to Eq.(8). As indicated in , in contrast to AGC, in DGC, an additional interval set I4 is initialized at time = 16 with aninterval length of 24 = 16. Similarly, when = 5, the target set C5includes the interval only, as there is one interval in I that starts at time 5.A brief comparison between different interval settings introduced in this section is listed in . 4.3Learning Experts4.3.1The Interval-level Learning within An Expert. As we mentioned at the beginning of .2, each interval is built upon a learning process, defined as an expert. At time , an expert isa learning algorithm G : R (a.k.a., a base learner, such as one or multiple gradientsteps ) within an interval that inputs parameters 1 and outputs interval-level parameters ,specific to the interval . The interval-level parameter update for an expert on interval at time is defined",
  ":10Zhao, et al": ". An overview of FairSAOML with AGC or DGC intervals to determine model parameter pair at eachround. A target set (shadowed) of intervals is initially selected and is later used to activate correspondingexperts. Each active expert runs through a base learner for the interval-level parameter-pair adaption, and itsweight is updated. The meta-level parameter pair is finally attained through the meta-learner by combiningthe weighted actions of all experts.",
  "for AGC intervals, |U| = log2. The number of experts is unchanged at different times,resulting from being known in advance and fixed": "for DGC intervals, |U| = log2 + 1. The number of experts slowly increases as needed,without known in advance.Furthermore, to adapt to changing environments efficiently, all experts are dynamically par-titioned into active and sleeping (or inactive) experts at each time , denoted A U andS = U\\A, respectively. As indicated in .2, a target set C, for all types of intervals I,I, and I, is subsetted from the interval set. Active experts are experts corresponding tointervals in the target sets, wherein active experts update model parameters at interval-level usingEq.(10). For sleeping experts, as no corresponding intervals are selected in the target set at time ,their interval-level model parameters are not updated and remain at the last update. Similarly, thenumber of active/sleeping experts varies by applying different types of interval sets, where at time",
  "for dynamic intervals, all experts are active experts A= {}=1 and the number ofsleeping experts is zero, S=": "for AGC and DGC intervals, the number of active experts is the cardinality of the selectedtarget set. As the example shown in , when = 5, active experts are A5={0, 1, 2} and A5= {0}, and sleeping experts are S5= {3} and S5= {1, 2}(experts 3 and 4 are not initialized until = 8 and = 16, respectively). 4.4Learning Dynamically for Bi-Level AdaptationRecall that in the protocol of fairness-aware online learning (.3), the main goal for thelearner is to sequentially decide on the model parameter that performs well on the loss sequence",
  "Dynamic Environment Responsive Online Meta-Learning with Fairness Awareness1:11": "and the long-term fair constraints. Crucially, inspired by , we consider a setting where at eachround the learner can perform a number of expert-specific updates at an interval level in theactive set A.As specified in Eq.(4), model parameters at each round are determined by formulating problemswith a nested bi-level adaptation process: interval-level and meta-level. Each level corresponds to asub-learner, i.e. base and meta learner, respectively, described in . The problem of learninga meta-level parameter is embedded with the optimization problem of finding interval-levelparameters , in Eq.(10). For experts in the sleeping set S, the base learner is not applied. Themeta-level problem takes the form in Eq.(11).",
  "S, (,, D,) 0(11)": "where , 0 is the expert weight of at . D, D, is the query set where D, D, = ., is the interval-level model parameter for an sleeping expert S where the round index < represents the last time this expert was activated.In the following section, we introduce our proposed algorithm FairSAOML. In stead of optimizingprimal parameters only, it efficiently deals with the bi-level optimization problem of Eq.(10)(11) byapproximating a sequence of pairs of primal-dual meta parameters {(, )}=1 where the pairrespectively responds for adjusting accuracy and fairness level.",
  "An Efficient Algorithm: FairSAOML": "To find a good model parameter pair (, ) at each time, an efficient working flow is proposed inAlgorithm 1. Inspired by dynamic programming and expert-tracking techniques, experts ateach time are recursively divided into active and sleeping ones. Model parameters in active expertsare locally updated, but those in sleeping experts are directly inherited from the previous time.Specifically, at the beginning of , a target set containing intervals is used to activate a subsetof experts in U. For each active expert in A, an interval-level algorithm takes the meta-levelsolution (1, 1) and outputs an expert-specific solution pair (,, ,). Finally, through themeta-learner, we combine the weighted solutions of all experts and move to the next time.We explain the main steps in Algorithm 1 below. In Step 4, when a new task arrives at time , abatch of data D is randomly sampled from D for validation purposes, and the performance on 1achieved is recorded. A target set of intervals C is selected from I in Step 5. For each interval C(Step 6-8), the corresponding expert , is activated, according to a specific ActivateExpertsprocedure on the choice of interval sets indicated in the subroutines of FairSAOML in Algorithm 2.We present three distinct expert activation procedures in Algorithm 2. For each active expert,we set adaptive stepsizes , = /(",
  "+ 2 1 and = max{": "+ , max{|| ||2, P}},where is the non-protected features lied in the interval and is its feature dimension. P is aset which includes all past intervals until time . Specifically in DI and DGC, at some time , newexperts are initiated. We set the constants , and , to zeros that are further used to changethe corresponding expert weight to adapt to changing environments.In Steps 9-11 of Algorithm 1, for all experts in U, a following weight , is estimated:",
  "Here, a weight function is defined as (,) = 1": "2( + 1, + 1) ( 1, 1), where(,) = exp([]2+/3) and []+ = max(0,) and (0, 0) = 1. In Steps 12-21, our FairSAOMLresponds to the bi-level adaptation stated in Eq.(10) and (11). Specifically, to solve the interval-levelproblem in Eq.(10), for each active expert in A, we consider following Lagrangian function",
  "=11, (1, D,)(13)": "where the interval-level parameter pair for an active expert are initialized with the meta-levelparameter (1, 1) . For optimization with simplicity, cumulative constraints in Eq.(10) areapproximated with the summarized regularization. Interval-level parameters are updated througha base learner G (). One example for the learner is updating with one gradient step usingthe pre-determined adaptive stepsize ,. Notice that for multiple gradient steps, , and ,interplay each other for updating.",
  "+(16)": "where B is the projection operation to the relaxed domain B that is introduced in .1.This approximates the true desired projection with a simpler closed form. Finally, in Steps 22-25, weupdate each experts and values, determining the expert weight for the next time. The intuitionof weight update is to re-adjust the difference between the meta-solution and the interval-levelsolution given by the expert.",
  "ANALYSIS": "To analyze, we first make the following assumptions as in . Examples where these assump-tions hold include logistic regression and 2 regression over a bounded domain. As for constraints,a family of fairness notions, such as DDP stated in Definition 1, are applicable as discussed in .For simplicity, in this section we omit D used in (), and (), . Assumption 1 (Convex domain). The convex set is non-empty, closed, bounded, and it isdescribed by convex functions as = { : () 0, []}. The relaxed domain B (where B) contains the origin 0 and its diameter is bounded by .",
  "Assumption 3 (Strongly convexity). Suppose (), and (), have strong convexity, thatis, 1, 2 B, || ( 1) ( 2)|| || 1 2||, || ( 1) ( 2)|| || 1 2||": "Under the above assumptions, we first state the key Theorem 1 that the proposed FairSAOMLenjoys a sub-linear guarantee for both regret and long-term fairness constraints in the long run forAlgorithm 1. Theorem 1. Set = arg min +1= (G ()) where [, + 1] []. Under Assumptions1, 2 and 3, the regret FairSAR proposed in Eq.(4) of FairSAOML in Algorithm 1 satisfies the bounds inEq.(17) for all three interval settings that stated in .2.",
  "Under Assumptions 1, 2 and 3, we target Eq.(15) and have": "Lemma 1 (Theorem 1 in ). Suppose and : R+ R satisfy Assumptions 1, 2 and 3.The interval-level update and the augmented Lagrangian function L (, ) are defined in Eq.(14)(12)and Eq.(15). Then, the function L (, ) is convex-concave with respect to the arguments and ,respectively. Furthermore, as for L (, ), if stepsize , for each active expert is selected as ,",
  "Therefore, as for FairSAR proposed in Eq.(4), we complete the proof": "Discussion for Upper Bounds. Under aforementioned assumptions and provable convexity ofEq.(18) in (see Lemma 1), the proposed FairSAOML in Algorithm 1 achieves sub-linear boundsin FairSAR for both loss regret and violation of fairness constraints. Although such bounds arecomparable with the strongly adapted loss regret in (see ) in terms of online learningin changing environment paradigms, we bound loss regret and cumulative fairness constraintssimultaneously. On the other hand, in terms of fairness-aware online learning, our proposed methodoutperforms by giving a tighter bound of fair constraint violations.Complexity. The computational complexity of FairSAOML in Algorithm 1 at each time []is O( |U |) where is the number of meta-level iterations and |U | is the total numberof experts that needs to be maintained at , and the complexity of each expert is O(1).",
  "EXPERIMENTAL SETTINGS": "6.1DatasetsWe use the following publicly available datasets. (1) New York Stop-and-Frisk (NYSF) is aprominent dataset of a real-world application on policing in New York City from 2009 to 2010.It documents whether a pedestrian who was stopped on suspicion of weapon possession wouldin fact possess a weapon. As this data had a pronounced racial bias on African Americans, foreach frisked record, we consider race as the binary protected attribute, that is black and non-black.Besides, this dataset consists of records collected in five different sub-districts, Manhattan (M),Brooklyn (B), Queens (Q), Bronx (R), and Staten (S). Since there are large performance disparitiesacross districts and race groups, each district is viewed as an independent domain. To adapt theonline learning setting, data in each domain is further split into 32 tasks and each task correspondsto ten days of a month with 111 non-protected features. According to DDP values in Definition1, the fairness levels from low to high are Bronx (0.74), Queens (0.68), Staten (0.65), Manhattan",
  "Dynamic Environment Responsive Online Meta-Learning with Fairness Awareness1:17": "(0.53) and Brooklyn (0.44). The larger DDP values indicate a lower fairness level. We hence considertwo settings for domain adaptation where each setting contains 96 tasks in total: (i) fairness levelfrom high to low: Brooklyn to Manhattan to Staten (BMS); and (ii) fairness level from low tohigh: Bronx to Queens then Staten (RQS). (2) MovieLens1 contains 100k ratings by 943 userson 1682 movies, and each rating is given a binary label (recommending\" if rating greater than3, not recommending\" otherwise). We consider gender as the protected attribute. To generatedynamic environments, following , we construct a larger dataset by combining three copies ofthe original data and flipping the original values of non-protected attributes by multiplying -1 forthe middle copy. Therefore, each copy is considered as a data domain. Furthermore, each data copyis split into 30 tasks by timestamps, and there are 90 tasks in total. 6.2Evaluation MetricsTwo popular evaluation metrics are introduced that each allows quantifying the extent of biastaking into account the protected attribute. Demographic Parity (DP) and Equalized Odds (EO) can be formalized as",
  "Competing Methods": "We compare the performance of our algorithm FairSAOML on various interval settings (hyphenatedby DI, AGC, and DGC) with six baseline methods. These baselines are chosen from three perspec-tives: online meta-learning (MaskFTML, FairFML), online fairness learning (FairFML, FairAOGD,FairGLC), and online learning in changing environments (AOD, CBCE). MaskFTML : the original FTML finds a sequence of meta parameters by simply applyingMAML at each round. To focus on fairness learning, this approach is applied to modifieddatasets by simply removing protected attributes. FairFML controls bias in an online working paradigm and aims to attain zero-shotgeneralization with task-specific adaptation. Different from our FairSAOML, FairFML focuseson a static environment and assumes tasks sampled from an unchangeable distribution.",
  "Settings": "As discussed in , the performance of our proposed method has been well justified theoreti-cally for machine learning models whose objectives are strongly convex and smooth. However, inmachine learning and fairness studies, due to the nonlinearity of neural networks, many problemshave a non-convex landscape where theoretical analysis is challenging. Nevertheless, algorithmsoriginally developed for convex optimization problems like gradient descent have shown promisingresults in practical non-convex settings . Taking inspiration from these successes, we describepractical instantiations for the proposed online algorithm and empirically evaluate the performancein .For each task, we set the number of fairness constraints to one, i.e. = 1. For the rest, wefollow the same settings as used in online meta-learning . In particular, we meta-train with asupport size of 400 for each class and 800 for a query set, whereas 90% (hundreds of datapoints) oftask samples for evaluation. Besides, for the NYSF dataset, we choose the base of 2, and the totalnumber of experts is 96 for DI, 6 for AGC, and 7 for DGC. Similarly, we choose the base of 3 forthe MovieLens dataset; hence, the number of experts is 90 for DI, 4 for AGC, and 5 for DGC. Allthe baseline models used to compare with our proposed approach share the same neural networkarchitecture and parameter settings. All the experiments are repeated ten times with the samesettings, and the mean and standard deviation results are reported.",
  "Implementation Details and Hyperparameter Tuning": "Our neural network trained follows the same architecture used in , which contains two hiddenlayers of size 40 with ReLU activation functions. In the training process of the MovieLens (NYSF)data, each gradient is computed using a batch size of 200 (800) examples where each binary classcontains 100 (400) examples. For each dataset, we tune the folowing hyperparameters: (1) the initialdual meta parameter 0 is chosen from {0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000};(2) the interval-level gradient steps are chosen from 1 to 10; (3) the number of iterations are chosen from {20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100}; (4) learning rates1 and 2 for updating meta-level parameters in Eq.(16) and (15) are chosen from {0.0001, 0.0005,0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000}; (5) the positive constant used in theaugmented term are chosen from {10, 25, 50, 75, 100}.",
  "Overall Performance": "The consolidated results, depicted in , provide a comprehensive evaluation of the effective-ness and efficiency of the proposed method, utilizing three evaluation metrics: fairness (DP andEO) and model precision (accuracy).In all the curves presented for various methods, higher values indicate better performance acrossall plots. The shaded regions in the figures represent standard errors. The results demonstratethat our proposed FairSAOML with all interval settings effectively mitigates bias as the learnerencounters more tasks, eventually satisfying the \"80%-rule\" fairness condition , where DP and EOexceed 0.8 in the latter stages. Furthermore, FairSAOML consistently outperforms most alternativeapproaches in terms of achieving the best model precision, as indicated by the high accuracy scores.Regarding learning efficiency, our FairSAOML with the DI setting takes the most running time. Incontrast, FairSAOML with AGC and DGC settings exhibit the shortest running times when comparedto the baseline methods shown in the bar charts of . This observation can be attributed toseveral factors: (1) the number of experts at each time in AGC and DGC significantly decreasescompared to the one in DI; (2) only active experts, but not sleeping ones, make contributions for",
  ". Performance of ablation studies on the New York Stop-and-Frisk BMS dataset. (a-c) FairSAOML-AGC, (d-f) FairSAOML-DGC": "7.2Adaptability to Changing EnvironmentsThe primary objective of our experimental design is to assess the adaptability of FairSAOMLconcerning fairness and model accuracy as the environment transitions from one to another. Tofacilitate a clearer visualization of these changing environments, we have manually inserted verticaldotted lines in , distinguishing the different environments at specific task indices. Ourexperimental findings reveal that, while FairSAOML may not initially outperform other baselinemethods in the first environment, it excels in adapting to changing conditions. As a result, itsperformance consistently improves in terms of both model fairness and predictive accuracy as theenvironment evolves.In .2.2, we introduced experts as crucial components in FairSAOML, where the modelparameter pair (, ) at time is determined by aggregating weighted expert advice. illustrates the evolution of expert weights in FairSAOML-AGC and FairSAOML-DGC. We did nottrack the weight changes of experts in FairSAOML-DI due to its larger number of experts (96 inNYSF and 90 in MovieLens). Our observations are as follows: (1) Experts associated with longerintervals receive larger weights, and these weights continue to increase as the learner encountersmore tasks; (2) Conversely, experts linked to shorter intervals receive smaller weights and becomeless influential over time. These findings align with expectations, as assigning heavier weights toexperts with longer intervals empowers our FairSAOML to effectively adapt to the volatility inmodel performance induced by changing environments.Among the baseline methods, MaskFTML demonstrates superior accuracy performance in thefirst environment, as evidenced in (c, g, k). However, it falls short when it comes to achievingmodel fairness, suggesting that merely attempting to obscure the protected attribute from decision-makers is insufficient to improve prediction fairness. On the other hand, FairFML, FairAOGD, andFairGLC exhibit an ability to mitigate bias in the first environment. Still, they struggle to adapt bothfairness and predictive accuracy when the environment undergoes changes. In contrast, AOD andCBCE, originally designed for online learning in dynamic environments, prioritize learning accuracybut do not effectively address model fairness when environmental shifts occur. Furthermore, the",
  "Ablation Studies": "We conducted ablation studies on the NYSF (BMS) dataset to assess the contributions of twopivotal components within FairSAOML: expert weights , and the base learner, as described in.3.1.To elaborate, meta-level parameters are computed at each time by aggregating expert decisionsbased on their respective weights. By removing expert weights, all experts contribute equally to thedecision-making process. Furthermore, within active experts, base learners, as defined in Eq.(10),are employed to update model parameters at an interval level. Without base learners, all activeexperts share the same model parameters inherited from the previous time and are consequentlyassigned equal weight. The key insights from the results presented in are as follows: (1)Expert weights play a significant role in FairSAOML, indicating their importance in achievingeffective bias control and predictive accuracy; (2) The inclusion of base learners serves to enhancemodel performance concerning bias control and predictive accuracy. These findings emphasizethe critical contributions of expert weights and base learners to the overall effectiveness of theFairSAOML algorithm.",
  "Sensitive Analysis on Different Bases in AGC and DGC": "Sensitive analyses conducted on the MovieLens dataset, as depicted in , involve the subsettingof intervals using different bases selected from the set {2, 3, 4, 5}. According to Eq.(7) and Eq.(9), theconfiguration with the smallest base value (i.e., 2) results in the highest number of experts (6 forAGC and 7 for DGC). Consequently, the largest expert in this setting carries the longest intervals(32 for AGC and 64 for DGC).Our observations regarding model fairness reveal that settings with smaller bases exhibit slightlybetter performance than those with larger bases in the first environment. However, the oppositetrend is observed in the last environment. This occurs for two main reasons: (1) In the firstenvironment, the largest experts carry more information in the smaller base setting than in thelarger base setting; (2) In the last environment, the largest experts in smaller base settings becomeless pure and incorporate data from different environments, leading to a deterioration in fairness.These findings underscore the sensitivity of the FairSAOML algorithm to the choice of base valueand its impact on model fairness, particularly in different environmental contexts.",
  ":22Zhao, et al": "8CONCLUSIONTo address the challenges of fairness-aware online learning in changing environments, wheredata tasks are sampled from diverse distributions one after another, we introduce a novel regretmeasure called FairSAR. FairSAR extends strongly adaptive regret by incorporating long-termfairness constraints. In technical terms, we start by proposing three alternative sets of intervals. Ateach time step, we dynamically select a target set consisting of multiple intervals from these sets.Next, we introduce a novel learning algorithm, named FairSAOML, to sequentially determine modelparameters. In this algorithm, we dynamically activate a subset of experts based on the intervals inthe target set and update their parameters at an interval level. The meta-level model parameters arethen obtained by combining the weighted contributions of all experts. Detailed theoretical analysisand accompanying proofs provide justification for the efficiency and effectiveness of our proposedalgorithm. We demonstrate upper bounds for loss regret and the violation of fairness constraints.Empirical studies conducted on real-world datasets demonstrate that our method outperformsstate-of-the-art online learning techniques in terms of both model accuracy and fairness. ACKNOWLEDGMENTSThis work is supported by the Baylor University Startup funds, the National Science Foundationunder grant numbers 2147375 and 1750911, and the National Center for Transportation Cyber-security and Resiliency (TraCR) headquartered in Clemson, South Carolina, USA. Any opinions,findings, conclusions, and recommendations expressed in this material are those of the author(s)and do not necessarily reflect the views of TraCR, and the U.S. Government assumes no liability forthe contents or use thereof.",
  "Chelsea Finn, Pieter Abbeel, and Sergey Levine. 2017. Model-Agnostic Meta-Learning for Fast Adaptation of DeepNetworks. ICML (2017)": "Chelsea Finn, Aravind Rajeswaran, Sham Kakade, and Sergey Levine. 2019. Online Meta-Learning. ICML (2019). Andrs Gyorgy, Tams Linder, and Gbor Lugosi. 2012. Efficient tracking of large classes of experts. IEEE Transactionson Information Theory (2012). Moritz Hardt, Eric Price, and Nathan Srebro. 2016. Equality of opportunity in supervised learning. NeurIPS (2016). Elad Hazan and Edgar Minasyan. 2020. Faster Projection-free Online Learning. In Proceedings of Thirty Third Conferenceon Learning Theory.",
  "Kwang-Sung Jun, Francesco Orabona, Stephen Wright, and Rebecca Willett. 2017. Improved Strongly Adaptive OnlineLearning using Coin Betting. In AISTATS": "Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, Akshay Balsubramani, WeihuaHu, Michihiro Yasunaga, Richard Lanas Phillips, Irena Gao, Tony Lee, Etienne David, Ian Stavness, Wei Guo, BertonEarnshaw, Imran Haque, Sara M Beery, Jure Leskovec, Anshul Kundaje, Emma Pierson, Sergey Levine, Chelsea Finn,and Percy Liang. 2021. WILDS: A Benchmark of in-the-Wild Distribution Shifts. In ICML. Michael Lohaus, Michael Perrot, and Ulrike Von Luxburg. 2020. Too Relaxed to Be Fair. In ICML. Haipeng Luo and Robert E Schapire. 2015. Achieving all with no parameters: Adanormalhedge. In Conference onLearning Theory. PMLR, 12861304.",
  "Yuanyu Wan, Bo Xue, and Lijun Zhang. 2021. Projection-free Online Learning in Dynamic Environments. AAAI(2021)": "Zhuoyi Wang, Yuqiao Chen, Chen Zhao, Yu Lin, Xujiang Zhao, Hemeng Tao, Yigong Wang, and Latifur Khan. 2021.CLEAR: Contrastive-Prototype Learning with Drift Estimation for Resource Constrained Stream Mining. In WWW. Yongkai Wu, Lu Zhang, and Xintao Wu. 2019. On Convexity and Bounds of Fairness-aware Classification. WWW. Jiahao Xie, Zebang Shen, Chao Zhang, Boyu Wang, and Hui Qian. 2020. Efficient projection-free online methods withstochastic recursive gradient. In AAAI. Jianjun Yuan and Andrew Lamperski. 2018. Online convex optimization for cumulative constraints. NeurIPS (2018). Lijun Zhang, Shiyin Lu, and Tianbao Yang. 2020. Minimizing Dynamic Regret and Adaptive Regret Simultaneously.AISTATS (2020).",
  "Lijun Zhang, Shiyin Lu, and Zhi-Hua Zhou. 2018. Adaptive Online Learning in Dynamic Environments, In InternationalConference on Neural Information Processing Systems. NeurIPS 2018": "Chen Zhao. 2021. Fairness-Aware Multi-Task and Meta Learning. Ph. D. Dissertation. Chen Zhao and Feng Chen. 2019. Rank-Based Multi-task Learning For Fair Regression. IEEE International Conferenceon Data Mining (ICDM) (2019). Chen Zhao and Feng Chen. 2020. Unfairness Discovery and Prevention For Few-Shot Regression. ICKG (2020). Chen Zhao, Feng Chen, and Bhavani Thuraisingham. 2021. Fairness-Aware Online Meta-learning. ACM SIGKDD(2021). Chen Zhao, Feng Mi, Xintao Wu, Kai Jiang, Latifur Khan, and Feng Chen. 2022. Adaptive fairness-aware onlinemeta-learning for changing environments. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discoveryand Data Mining. 25652575."
}