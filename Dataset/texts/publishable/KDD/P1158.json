{
  "Renlang Huang, Minglei Zhao, Jiming Chen, and Liang Li": "Abstract Sparse keypoint matching based on distinct 3Dfeature representations can improve the efficiency and robust-ness of point cloud registration. Existing learning-based 3Ddescriptors and keypoint detectors are either independent orloosely coupled, so they cannot fully adapt to each other. In thiswork, we propose a tightly coupled keypoint detector and de-scriptor (TCKDD) based on a multi-task fully convolutional net-work with a probabilistic detection loss. In particular, this self-supervised detection loss fully adapts the keypoint detector toany jointly learned descriptors and benefits the self-supervisedlearning of descriptors. Extensive experiments on both indoorand outdoor datasets show that our TCKDD achieves state-of-the-art performance in point cloud registration. Furthermore,we design a keypoint detector and descriptors-assisted LiDARodometry and mapping framework (KDD-LOAM), whose real-time odometry relies on keypoint descriptor matching-basedRANSAC. The sparse keypoints are further used for efficientscan-to-map registration and mapping. Experiments on KITTIdataset demonstrate that KDD-LOAM significantly surpassesLOAM and shows competitive performance in odometry.",
  "I. INTRODUCTION": "Point cloud registration is crucial for many robotic and3D vision applications, such as simultaneous localization andmapping (SLAM) and 3D reconstruction . Althoughthe classic iterative closest point (ICP) algorithm canprecisely estimate the transformation, it requires an initialguess close to the ground truth and inefficient iterations toestablish correct correspondences. In contrast, sparse featurematching directly establishes reliable correspondences be-tween keypoints with similar descriptors, achieving efficientand robust point cloud registration.Even though a few hand-crafted 3D keypoint detectors , and descriptors have been proposed over theyears, the performance of 3D-3D point association remainsunsatisfactory. In contrast, the learning-based descriptor isregarded as a promising approach , which maps thelow-level geometric representations to a discriminative fea-ture space. These descriptors are always learned in a self-supervised manner by maximizing the similarity betweencorresponding point features and minimizing the similaritybetween other point pairs. However, as it is difficult to defineand label keypoints, these descriptors usually overlook key-point detection and randomly sample points for descriptionand matching, thus suffering from several drawbacks. First,inefficient oversampling is required to ensure a sufficientnumber of correspondences. Second, these poorly localizedsampled points will result in inaccurate pose estimation.Third, non-salient points with indiscriminative descriptors",
  "The authors are with the College of Control Science and Engineering,Zhejiang University, Hangzhou, 310027, P. R. China": ".The feature maps colored in saliency uncertainty built by our KDD-LOAM on KITTI sequence 07. Sharp corners and edges, distinguishablebuildings, pillars, and vehicles are detected as salient regions (red), whileflat surfaces, chaotic vegetation, and unstably scanned regions far from thesensor are detected as non-salient regions (blue). It is noteworthy that planarsurfaces (most from roads) have been fitted as sparse surfels. degrade the inlier ratio. Similarly, existing keypoint detectorstrained independently cannot fully adapt to descriptors.To this end, we design a tightly coupled joint keypointdetector and descriptor, i.e., TCKDD. Inspired by KPConv, we propose a fully convolutional neural network forkeypoint detection and description, which utilizes a KPConv-based encoder-decoder backbone for 3D feature embedding.In addition, it densely predicts both a descriptor and thesaliency uncertainty via two independent point-wise MLPheads for each point. The descriptors are learned througha quadruplet hardest contrastive loss in a self-supervisedmanner. To fully exert the potential of descriptors, we quanti-tatively define a matchability index fully based on descriptorsand design a novel probabilistic detection loss based onmaximum likelihood estimation. With this loss, the detectionhead can estimate the point-wise matchability robustly forkeypoint selection and make the network concentrate on thelearning of descriptors in salient regions.As a deep front-end, TCKDD can densely predict globaland local context-aware descriptors and detect keypointswith higher matchability. A series of experiments show thatTCKDD achieves state-of-the-art performance on both theindoor RGB-D camera dataset 3DMatch and the outdoorLiDAR dataset KITTI for point cloud registration. Withthis powerful front-end, we utilize RANSAC as the middle-end to establish sparse correspondences based on the de-scriptors and minimize the point-to-point metric at the back-end. This pipeline can be operated in real-time for the reg-istration between consecutive scans. Consequently, we candesign a keypoint detector and descriptors assisted LiDARodometry and mapping framework, i.e., KDD-LOAM, with",
  "arXiv:2309.15394v1 [cs.CV] 27 Sep 2023": "this keypoint descriptor matching-based registration pipelineas the LiDAR odometry module. We propose to constructa voxel hash map consisting of only salient regions and fitthe planar patches into sparse surfels, enabling a memory-efficient representation and fast nearest neighbor search.Then the keypoints from the current scan will be alignedto the map based on both point-to-point and point-to-planemetrics for more accurate localization. Experiments on theKITTI dataset demonstrate that the TCKDD-based odometryoutperforms LOAM which leverages the planar pointsand edge points for odometry by a large margin. Withoutloop closure detection and pose graph optimization, KDD-LOAM achieves competitive performance in odometry whilemaintaining real-time performance. is a demonstrationof our keypoint detection and mapping results. The maincontributions of this work are summarized as follows:",
  "II. RELATED WORK": "Feature matching is a prominent approach in point cloudregistration, efficiently establishing reliable sparse correspon-dences based on descriptors. Early methods use local hand-crafted descriptors based on either histograms , or sig-natures . Recent focus has shifted to learning-based 3D de-scriptors. For instance, 3DMatch and PerfectMatch employ 3D CNNs to learn local volumetric descriptors,converting patches into truncated distance function (TDF) orsmoothed density value (SDV) representations. PPFNet uses PointNet for global context-aware patch descrip-tors, while FCGF designs a sparse 3D convolutionalencoder-decoder network. SpinNet proposes a spatialpoint Transformer, converting point clouds as cylindrical vol-umes for transformation-invariant features. Recent methodslike learn point cloud interactions to enhance the inlierratio, including coarse-to-fine registration approaches , that achieve end-to-end correspondence learning.Unlike the exploration of learning-based 3D descriptors,most 3D keypoint detectors are hand-crafted and target pointswith unique curvatures or significant geometric variationsin the principal direction as keypoints. However, theystruggle with real-world scans that are noisy, sparse, and non-uniform. Hence, researchers explore learning-based detectorsfor more reliable results. USIP trains a feature proposalnetwork via a probabilistic chamfer loss to predict 3D key-points with high repeatability. To adapt the keypoint detectorto the descriptors, some researchers propose to jointly learnthe 3D keypoint detector and descriptors. 3DFeat-Net designs a weakly supervised patch-wise network minimizinga saliency-weighted feature alignment triplet loss. However, it does not explicitly prioritize keypoint detection perfor-mance. D3Feat densely predicts descriptors with a fullyconvolutional encoder-decoder and obtains saliency scoresfrom descriptors using a self-supervised detection loss.LiDAR odometry estimation involves real-time point cloudregistration typically based on ICP or NDT. Nearly all mod-ern SLAM systems are designed on top of odometry. Zhanget al. propose LOAM that extracts and aligns planar andedge points to a sparse voxel grid-based feature map. LeGO-LOAM segments the point cloud to remove unstableparts and adds ground constraints to improve accuracy.Additionally, F-LOAM employs a faster non-iterativedistortion compensation method to reduce the computationalcost. However, these methods rely on hand-crafted featureextraction, which is only suitable for small pose derivationsand requires multiple iterations for reliable correspondences. III. METHODOLOGYIn this work, we design a tightly coupled keypoint detectorand descriptor for 3D point cloud registration, i.e., TCKDD.The principles of tight coupling are three-fold: 1) the detectorand the descriptor share a common feature extractor; 2) thedetector fully matches the matchability of the descriptors; 3)the detector and the descriptor can enhance each other viaa probabilistic detection loss. We further integrate TCKDDinto a real-time LiDAR odometry and mapping system. A. Network ArchitectureWe treat the joint learning of 3D keypoint detection anddescription as a multi-task learning paradigm and followits fundamental neural network style, i.e., plugging severalseparated task-specific prediction heads into a shared featureextraction backbone. Inspired by KPConv , we proposea fully convolutional network for 3D keypoint detectionand description. KPConv directly operates on irregular pointsets by interpolating point features to uniformly distributedkernel points for regular convolution, i.e., linear mapping,and summation of kernel responses.Utilizing the normalized KPConv, TCKDD can constructa fully convolutional network that directly consumes pointsets, as depicted in . The backbone can extract multi-scale 3D features at different encoder layers consisting of astack of residual bottleneck blocks. The locality of KPConvenables strided convolution for downsampling. The decodercan recover the resolution via nearest upsampling and ag-gregate the multi-scale 3D features via skip connections and11 convolution (unary blocks). Different from the originalKPFCNN , we replace the batch normalization withgroup normalization , which is robust w.r.t. batch size andgroup-wise features. Finally, TCKDD densely predicts bothpoint-wise descriptors and saliency uncertainty based on theshared 3D features from the backbone via two independentall-MLP heads, i.e., 1 1 convolutional blocks. B. Quadruplet Contrastive Loss for Descriptor LearningMetric learning is widely used to train descriptors. Essen-tially it maps low-level geometric representations to a high-dimensional feature space, where descriptors of correctly",
  ".The network architecture of TCKDD for jointly learning of 3Dkeypoint detection and description": "associated point pairs are close, while those of other pairsdiffer by at least a margin. The correspondence set C oftwo partially overlapped point clouds P, Q is a set of themutually nearest points (pi, qj) satisfying pi qj2 Rp.The negative point set Ni of a point pi P is a set of pointsqk Q satisfying piqk2 Rn(Rn Rp). Denote di, djas the descriptors of pi P, qj Q, then the self-superviseddescriptor loss can be designed as a hardest quadrupletcontrastive loss according to metric learning strategies:",
  "C. Self-supervised Probabilistic Detection Loss": "The principle of joint learning of 3D keypoint detectionand description is to fully adapt the detector and the de-scriptors to each other. Therefore, we treat the detectionhead of TCKDD as a saliency scoring network based on thematchability of descriptors. According to (1), we can directlydesign a metric named matchability index to characterize thematchability of a given descriptor di quantitatively:",
  "+, (2)": "where dj is the descriptor of the correctly associated pointof pi in point cloud Q. This matchability index is actuallythe hardest triplet loss of a single descriptor in metric learn-ing, which describes the distinctness of a descriptor in thefeature space. Particularly, we use the hardest negative pairsfor negative mining so that the matchability index directlymodels the decision margin of descriptor matching and opti-mizes the decision boundary during metric learning. A lowermatchability index mi indicates greater matchability of thedescriptor di, i.e., the 3D point pi is more salient. Therefore,all we need is to learn a matchability index estimator asa keypoint detector. We propose to learn a probabilistic model rather than a regressive model for matchability indexestimation since the descriptor is predicted from a specificpoint cloud sampled from the surfaces of a dense 3D scenein a specific perspective, and so as the descriptors of theassociated points. Ideally, metric learning would constructa fully discriminative feature space where the matchabilityindex of each descriptor is zero. Hence, we choose anexponential distribution to model the matchability index miwith a parameter i, or namely saliency uncertainty:",
  ".(4)": "Theoretically, the first derivative of the log-likelihood indi-cates that the global optimality conditions for detector learn-ing are i = mi, making the probabilistic detection loss ef-fective for training the detection head as a robust matchabilityestimator. Remarkably, this loss is also a weighted form ofthe hardest contrastive loss, with the descriptor losses of key-points having higher weights than those of non-salient points.When the detector meets global optimality, this detection lossturns out to be a logarithmic contrastive loss, prioritizingthe descriptors of keypoints. This approach enhances thematchability of keypoints, mitigating the negative effects ofmining geometric features in non-salient areas like planarsurfaces and disorganized regions. Hence, this probabilisticdetection loss can not only train a keypoint detector as arobust matchability estimator that fully accommodates thejointly learned descriptors but also promote the learning ofkeypoint descriptors via weighted metric learning.",
  "D. Keypoint Detector and Descriptors Assisted LOAM": "As illustrated in , we integrate TCKDD into aLiDAR odometry and mapping system, i.e., KDD-LOAM,consisting of the following key components.Scan deskewing and scan-to-scan registration. Similarto , we first utilize the most generally applicable con-stant velocity model for scan deskewing, which requires noextra sensors involving time synchronization. As a powerfulfront-end of point cloud registration, TCKDD can denselypredict global and local context-aware descriptors and detectkeypoints by sorting the saliency uncertainty. We leverageRANSAC to establish sparse correspondences based on thedescriptors and minimize the sum of point-to-point distancesbetween inlier correspondences based on SVD. This pipelineachieves real-time scan-to-scan registration to provide a solidinitial guess for incremental ego-motion estimation. .The system overview of KDD-LOAM. We leverage the constantvelocity model for scan deskewing and predict the point-wise descriptorsand saliency uncertainty through TCKDD. Based on a reliable relativepose guess from RANSAC-based scan-to-scan registration, KDD-LOAMachieves accurate odometry by aligning the deskewed and subsampled scanwith a high-resolution yet memory-efficient local map. Keypoint subsampling and mapping. With a reliable rel-ative pose guess from scan-to-scan registration, we refine theego-pose estimate by aligning the deskewed and subsampledscan with the accumulated local map. Unlike methods suchas that create sparse feature maps of edge points orsurface points with noisy directions or normals, we proposea voxel grid map capturing detailed geometry akin to surfacereconstruction. We keep it simple, approximating complex3D surfaces in any topology with ample scan points. Utilizinga voxel hash map with voxel size v v v that stores upto Nmax points per voxel, we achieve efficient insertion,indexing, deletion, and nearest neighbor search compared to3D arrays or KD-trees . Instead of high-resolutionpanoptic mapping , KDD-LOAM accumulates a voxelhash map for only salient regions with low saliency uncer-tainty. For better surface representation, we fit voxels withNmax points to planes via least square regression. Voxelsmeeting error criteria of regression are replaced with surfelsrepresented by the point closest to their center, their normalvector, and radius v. Our approach, in contrast to , adaptsvoxel grids for adaptive 3D salient region reconstruction,combining dense points and sparse surfels for a memory-efficient representation applicable to global mapping.Inspired by CT-ICP , we adopt a two-stage voxelgrid-based subsampling for sequential map update and ego-pose estimation. In the first stage, we use voxel size v( (0, 1]) to downsample by reserving an original scanpoint per voxel to prevent discretization errors. After scan-to-map registration, these subsampled points are transformedusing the global pose estimate and added to the voxel hashmap. In the second stage, we propose a saliency-aware voxelgrid subsampling using voxel size v ( ) to selectkeypoints for faster scan-to-map registration. Non-salientpoints are discarded, while salient regions accommodatemore points per voxel for accurate point cloud registration.Robust scan-to-map registration. We use scan-to-mapregistration for more accurate odometry as it proves morereliable and robust than scan-to-scan registration , .Our scan-to-map registration builds on the classic ICP algo-rithm, which typically establishes correspondences between two point clouds via nearest neighbor search. With a reliablescan-to-scan relative pose guess grounded in geometricallyconsistent correspondences, it is more likely to avoid sub-optimal convergence and reduce ICP iterations. However,ICP requires a hand-crafted maximum distance threshold foroutlier rejection, which depends on the expected initial error.To this end, we treat scan-to-map registration as compen-sation for scan-to-scan pose estimation, determining the max-imum distance threshold by assessing deviations from thescan-to-scan pose estimate over time. Denote this deviationas T SE(3), the upper bound of the point deviation is",
  ",(5)": "where r is the maximum range of LiDAR scans, R SO(3) and t R3 refer to the rotation and translationcomponents of T, respectively. Inspired by KISS-ICP ,we adopt a Gaussian distribution over (T) and compute itsstandard deviation t to robustly set the maximum distancethreshold of ICP as the three-sigma bound t = 3t.Given a point from the current scan during data associa-tion, we first search the nearest point and the nearest surfelseparately in the voxel hash map based on point-to-pointdistances. Next, we evaluate the point-to-point distance fromthe nearest point and the point-to-plane distance from thenearest surfel to determine its correspondence. Finally, themaximum distance threshold t determines whether to acceptthis correspondence as an inlier. This process establishes a setof point-to-point and point-to-plane correspondences for eachICP iteration. A robust ego-pose (i.e., rotation R SO(3)and translation t R3) is estimated by minimizing the sumof point-to-point residuals and point-to-plane residuals:",
  "t/3 + e(Rp + t, q)2 ,(6)": "where is the Geman-McClure kernel with a strong outlierrejection property. The optimal pose can be estimated via theGauss-Newton method. The Jacobian can be derived by ap-plying the left perturbation model with = [T T ]T R6, se(3). For a point-to-point residual e = Rp +t q22, the Jacobian of e = Rp + t q w.r.t. is",
  "A. Indoor Scenes: 3DMatch Benchmark": "3DMatch is a widely used 3D reconstruction benchmarkincluding 62 indoor scenes collected by RGB-D cameras.We use the training data preprocessed by and evaluateour TCKDD against both hand-crafted and learning-baseddescriptors on the official test set including scan pairs with> 30% overlap using two metrics: feature matching recall(FMR) and registration recall (RR) .TCKDD is evaluated with different numbers of key-points in Table I, compared with state-of-the-art learning-based descriptors PerfectMatch , FCGF , D3Feat ,SpinNet , Predator , YOHO and coarse-to-fineregistration methods CoFiNet , GeoTransformer .For TCKDD, we compare random sampling (rand) withthree saliency-based keypoint selection strategies: proba-bilistic sampling (prob), non-maximum suppression (NMS),and probabilistic NMS (NMS-prob). In terms of FMR,TCKDD without keypoints consistently outperforms all 3Ddescriptors and performs on par with GeoTransformer. Whensampled points are fewer than 1000, TCKDD with keypointsachieves higher FMR, showing more stable performanceagainst existing descriptors. In terms of RR, TCKDD withprobabilistic keypoints outperforms all the descriptors andCoFiNet consistently by 239%. With over 250 sampledpoints, our probabilistic keypoints even surpass GeoTrans-former notably. Furthermore, the effectiveness and robustnessof our keypoints are validated through consistent RR im-provement, especially with fewer than 1000 sampled points.We demonstrate the robustness of TCKDD (prob) byvarying the inlier distance threshold 1 and the inlier ratiothreshold 2 in FMR. As shown in , we report theperformance of hand-crafted descriptors SpinImages ,",
  "ModelRTE (cm)RRE ()RR (%)": "3DFeat-Net 25.90.2596.0FCGF 9.50.3096.6D3Feat 7.20.3099.8SpinNet 9.90.4799.1Predator 6.80.2799.8CoFiNet 8.20.4199.8GeoTransformer (RANSAC)7.40.2799.8GeoTransformer (LGR) 6.80.2499.8TCKDD (ours, prob)6.80.27100.0 SHOT , FPFH and ealier learning-based descriptorsCGF , 3DMatch , PPFNet , PPF-FoldNet .TCKDD consistently outperforms other methods with 1 5cm and significantly surpasses them across all inlier ratiothresholds. Under a stricter condition 2 = 0.2, TCKDDmaintains a high FMR of 89.3%, while SpinNet, D3Feat,and FCGF drop to 85.7%, 75.8%, and 67.4%, respectively,which highlights that TCKDD is more robust to maintainhigher inlier ratio in challenging scenarios.",
  "B. Outdoor Scenes: KITTI Benchmark": "For the KITTI dataset, we use sequences 0 to 5 fortraining, 6 to 7 for validation, and 8 to 10 for testing. Werefine the GPS localization results via ICP as groundtruth. Additionally, only point cloud pairs at least 10maway from each other are selected. Following , we usethree metrics for evaluation: relative translation error (RTE),relative rotation error (RRE) and registration recall (RR).In Table II, TCKDD is compared with the state-of-the-art descriptors 3DFeat-Net , FCGF , D3Feat ,SpinNet , Predator and coarse-to-fine registra-tion methods CoFiNet , GeoTransformer . TCKDDachieves state-of-the-art RTE and the highest registrationrecall of 100%, which demonstrates the effectiveness androbustness. Within TCKDD, we compare random sampling(rand) with two saliency-based keypoint selection strategies:sorting (sort) and probabilistic sampling (prob). As shownin Table III, TCKDD maintains 100% of RR even with only1000 randomly sampled points, indicating the robustness ofits descriptors in establishing sparse yet reliable correspon-",
  "scan-to-scanscan-to-mapscan-to-scanscan-to-map": "004.13 / 1.720.81 / 0.312.28 / 0.980.67 / 0.26013.46 / 0.952.01 / 0.522.89 / 0.802.19 / 0.48027.47 / 2.554.66 / 1.462.03 / 0.910.99 / 0.35034.35 / 2.080.92 / 0.472.03 / 1.400.90 / 0.44041.65 / 0.810.72 / 0.360.67 / 0.490.62 / 0.29054.06 / 1.660.51 / 0.241.96 / 1.000.45 / 0.22061.11 / 0.510.59 / 0.272.01 / 1.270.59 / 0.27072.84 / 1.800.44 / 0.241.80 / 1.360.43 / 0.22095.75 / 1.880.70 / 0.303.05 / 1.280.62 / 0.23103.60 / 1.760.98 / 0.383.26 / 1.380.84 / 0.34 dences. The sorted keypoints notably reduce RTE comparedto random sampling, especially with fewer sampled pointsfor registration, thus underscoring TCKDDs ability to detectkeypoints with high matchability and repeatability.",
  "C. Evaluation of LiDAR Odometry and Mapping Systems": "In this subsection, we design experiments to demonstratethat 1) TCKDD effectively improves odometry accuracyagainst its baseline A-LOAM; 2) KDD-LOAM significantlyreduces cumulative error in scan-to-scan registration andoutperforms classic LiDAR odometry or SLAM systems;3) KDD-LOAM achieves more memory-efficient mappingwhile maintaining performance comparable to KISS-ICP. Allthe algorithms are evaluated with the mean relative pose error(RPE) over trajectories of 100 to 800m (relative translationerror in % / relative rotational error in /100m) . Se-quence 08 is excluded from evaluation due to significanterrors in its ground-truth localization results.We first demonstrate the effectiveness of TCKDD byreplacing the scan-to-scan registration step of A-LOAM withTCKDD-based RANSAC. As shown in Table IV, TCKDD-based scan-to-scan registration significantly outperforms A-LOAM based on hand-crafted keypoints, providing a muchmore reliable and accurate pose guess for the subsequentscan-to-map registration. Furthermore, we integrate TCKDD-based scan-to-scan registration with the subsequent mappingstep of A-LOAM. Apart from sequence 01 collected froma featureless environment, TCKDD-aided A-LOAM outper-forms A-LOAM by a large margin, especially in sequences00, 02, and 10 with 0.14%, 3.67% and 0.14% improvementsof average RTEs, respectively. These results indicate thatTCKDD-based odometry outperforms hand-crafted featuresand effectively complements existing mapping approaches.Finally, we evaluate KDD-LOAM against state-of-the-artLiDAR odometry methods on the KITTI dataset , includ-ing LOAM , F-LOAM , SuMa , SuMa++ ,",
  "SeqLOAMF-LOAMSuMaSuMa++KISS-ICPKDD-LOAM": "000.78 / -0.92 / 0.430.77 / 0.320.65 / 0.220.52 / 0.190.52 / 0.18011.43 / -2.80 / 0.6011.15 / 0.761.63 / 0.470.65 / 0.140.76 / 0.14020.92 / -1.56 / 0.522.93 / 0.933.54 / 0.140.53 / 0.150.51 / 0.14030.86 / -1.09 / 0.661.25 / 0.610.67 / 0.470.66 / 0.160.67 / 0.16040.71 / -1.43 / 0.520.86 / 0.270.34 / 0.270.35 / 0.130.37 / 0.07050.57 / -0.79 / 0.360.56 / 0.320.40 / 0.190.32 / 0.140.26 / 0.12060.65 / -0.72 / 0.390.64 / 0.510.47 / 0.270.26 / 0.080.26 / 0.08070.63 / -0.54 / 0.390.47 / 0.370.39 / 0.280.32 / 0.160.31 / 0.15090.77 / -1.28 / 0.550.79 / 0.410.58 / 0.200.48 / 0.130.50 / 0.12100.79 / -1.77 / 0.580.99 / 0.440.67 / 0.300.60 / 0.200.53 / 0.17",
  "KISS-ICP4685.63936.65038.94785.93836.84456.8KDD-LOAM4065.53091.24434.43881.83101.73714.9": "and KISS-ICP . As shown in Table V, KDD-LOAM con-sistently outperforms classic odometry systems, LOAM, F-LOAM, and SLAM systems SuMa, SuMa++ across nearly allthe scenes. This underscores the effectiveness and robustnessof KDD-LOAM. Compared with KISS-ICP using a similarvoxel hash map and an ICP-based scan-to-map registrationstep with adaptive thresholds, KDD-LOAM achieves lowerRREs in all sequences while performing on par with KISS-ICP in RTEs, showcasing its potential to achieve lower globallocalization drifts. The average RPEs are reported as Avg,while Avg stands for the results without the featurelesssequence 01. Except for sequence 01, KDD-LOAM evenachieves a lower average RPE than KISS-ICP with a morememory-efficient map representation. We compare the aver-age memory usage for local maps of some long sequencesin Table VI, which indicates that KDD-LOAM consumes16.6% less memory for local mapping than KISS-ICP.",
  "V. CONCLUSIONS": "This paper presents a tightly coupled 3D keypoint detectorand descriptor for point cloud registration along with akeypoint detector and descriptor assisted LiDAR odometryand mapping system. We exploit the multi-task learningparadigm with a carefully designed probabilistic detectionloss to learn a fully convolutional 3D descriptor and akeypoint detector fully adapted to it. Our odometry andmapping system achieves robust registration and memory-efficient mapping based on dense keypoints and sparsesurfels. The evaluation results indicate that our keypointdetector and descriptor are robust to different range-sensingtechnologies and achieve state-of-the-art registration recall.The experiments on the KITTI benchmark demonstrate thatour real-time and memory-efficient KDD-LOAM performson par with state-of-the-art LiDAR odometry systems. Infuture work, we intend to investigate keypoint descriptor-based loop closure detection and pose graph optimization toextend our KDD-LOAM to a full SLAM system.",
  "S. Salti, F. Tombari, and L. Di Stefano, Shot: Unique signatures ofhistograms for surface and texture description, Computer Vision andImage Understanding, vol. 125, pp. 251264, 2014": "X. Bai, Z. Luo, L. Zhou, H. Fu, L. Quan, and C.-L. Tai, D3feat:Joint learning of dense detection and description of 3d local features,in Proceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pp. 63596367, 2020. H. Thomas, C. R. Qi, J.-E. Deschaud, B. Marcotegui, F. Goulette, andL. J. Guibas, Kpconv: Flexible and deformable convolution for pointclouds, in Proceedings of the IEEE/CVF International Conference onComputer Vision, pp. 64116420, 2019.",
  "J. Zhang and S. Singh, Loam: Lidar odometry and mapping in real-time., in Robotics: Science and systems, 2014": "Z. Gojcic, C. Zhou, J. D. Wegner, and A. Wieser, The perfect match:3d point cloud matching with smoothed densities, in Proceedings ofthe IEEE/CVF Conference on Computer Vision and Pattern Recogni-tion, pp. 55455554, 2019. H. Deng, T. Birdal, and S. Ilic, Ppfnet: Global context aware localfeatures for robust 3d point matching, in Proceedings of the IEEEConference on Computer Vision and Pattern Recognition, pp. 195205, 2018. C. R. Qi, H. Su, K. Mo, and L. J. Guibas, Pointnet: Deep learningon point sets for 3d classification and segmentation, in Proceedingsof the IEEE Conference on Computer Vision and Pattern Recognition,pp. 652660, 2017.",
  "C. Choy, J. Park, and V. Koltun, Fully convolutional geometricfeatures, in Proceedings of the IEEE/CVF International Conferenceon Computer Vision, pp. 89588966, 2019": "S. Ao, Q. Hu, B. Yang, A. Markham, and Y. Guo, Spinnet: Learninga general surface descriptor for 3d point cloud registration, inProceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pp. 1175311762, 2021. S. Huang, Z. Gojcic, M. Usvyatsov, A. Wieser, and K. Schindler,Predator: Registration of 3d point clouds with low overlap, inProceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pp. 42674276, 2021. H. Yu, F. Li, M. Saleh, B. Busam, and S. Ilic, Cofinet: Reliablecoarse-to-fine correspondences for robust point cloud registration, Ad-vances in Neural Information Processing Systems, vol. 34, pp. 2387223884, 2021. Z. Qin, H. Yu, C. Wang, Y. Guo, Y. Peng, S. Ilic, D. Hu, andK. Xu, Geotransformer: Fast and robust point cloud registration withgeometric transformer, IEEE Transactions on Pattern Analysis andMachine Intelligence, 2023.",
  "Y. Wu and K. He, Group normalization, in Proceedings of theEuropean Conference on Computer Vision (ECCV), pp. 319, 2018": "I. Vizzo, T. Guadagnino, B. Mersch, L. Wiesmann, J. Behley, andC. Stachniss, Kiss-icp: In defense of point-to-point icpsimple, ac-curate, and robust registration if done the right way, IEEE Roboticsand Automation Letters, vol. 8, no. 2, pp. 10291036, 2023. P. Dellenbach, J.-E. Deschaud, B. Jacquet, and F. Goulette, Ct-icp:Real-time elastic lidar odometry with loop closure, in IEEE Inter-national Conference on Robotics and Automation (ICRA), pp. 55805586, IEEE, 2022. H. Wang, Y. Liu, Z. Dong, and W. Wang, You only hypothesizeonce: Point cloud registration with rotation-equivariant descriptors, inProceedings of the 30th ACM International Conference on Multimedia,pp. 16301641, 2022."
}