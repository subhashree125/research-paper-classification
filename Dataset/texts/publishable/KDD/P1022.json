{
  "Abstract": "Distributed databases are fundamental infrastructures of todayslarge-scale software systems such as cloud systems. Detectinganomalies in distributed databases is essential for maintaining soft-ware availability. Existing approaches, predominantly developedusing Loghuba comprehensive collection of log datasets fromvarious systemslack datasets specifically tailored to distributeddatabases, which exhibit unique anomalies. Additionally, theres anotable absence of datasets encompassing multi-anomaly, multi-node logs. Consequently, models built upon these datasets, primar-ily designed for standalone systems, are inadequate for distributeddatabases, and the prevalent method of deeming an entire clusteranomalous based on irregularities in a single node leads to a highfalse-positive rate. This paper addresses the unique anomalies andmultivariate nature of logs in distributed databases. We exposethe first open-sourced, comprehensive dataset with multivariatelogs from distributed databases. Utilizing this dataset, we conductan extensive study to identify multiple database anomalies and toassess the effectiveness of state-of-the-art anomaly detection usingmultivariate log data. Our findings reveal that relying solely onlogs from a single node is insufficient for accurate anomaly detec-tion on distributed database. Leveraging these insights, we proposeMultiLog, an innovative multivariate log-based anomaly detec-tion approach tailored for distributed databases. Our experiments,based on this novel dataset, demonstrate MultiLogs superiority,outperforming existing state-of-the-art methods by approximately12%.",
  "*Corresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain. 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "Introduction": "The distributed databases, such as Google Spanner, AlibabaOceanBase, PingCAP TiDB, and Apache IoTDB havebeen widely used in cloud systems and is becoming a fundamen-tal infrastructure to support the requirement for extremely highvolume of data storage.However, existing distributed databases suffer from frequentanomalies such as system failure, performance degradation, etc,and these anomalies often cause huge financial losses. For instance,Alibaba Cloud suffers from Intermittent Slow Queries (iSQs),which result in billions of dollars in losses annually. Amazon alsoreports that every 0.1s of loading delay caused by database anom-alies would cause an extra 1% financial loss. As a result, detectingthe anomalies of distributed databases and mitigating the affectionsof system anomalies are notoriously essential.As system logs meticulously track the states and significantevents of actively running processes, they serve as a rich source foranomaly detection. Consequently, log-based anomaly detection hasemerged as an effective method for ensuring software availabilityand has garnered extensive research attention. Most existing log-based anomaly detection models primarily utilize datasets fromLoghub, a comprehensive compilation of log datasets from adiverse range of systems. Among the most commonly utilized aresystems such as standalone systems (e.g., BGL, Thunderbird,HPC), distributed computing frameworks (like Hadoop,Spark), and distributed file systems (e.g., HDFS, Zookeeper.Leveraging Loghub, a variety of log-based anomaly detectionmodels have been developed, broadly classified into two cate-gories: supervised models and unsupervisedmodels. Supervised models, such asRobustLog, necessitate labeled data comprising both normaland abnormal instances to construct their predictive frameworks.",
  "KDD 24, August 2529, 2024, Barcelona, Spain.Lingzhe Zhang et al": "In contrast, unsupervised models detect deviations relying solelyon standard data. They are primarily split into deep neural network-based and graph-based models.Although these anomaly detection methods have demonstratedpromising outcomes based on Loghub, they still face the fol-lowing practical challenges when applied to distributed databases: Lack of Log Anomaly Datasets Collected from Dis-tributed Databases: Notably absent in Loghub are datasetsspecifically collected for distributed databases. This omis-sion highlights a significant gap in the design, implemen-tation, and testing of state-of-the-art models tailored fordistributed databases. These databases are characterized byunique anomalies and features, necessitating the utlization ofinformation from multiple dimensions, and many anomaliescannot be detected within the current node alone. Absence of Datasets with Multi-Anomaly, Multi-NodeLogs: The majority of these datasets do not disclose thevariety of anomaly types injected, often suggesting a lim-ited scope of anomaly types. Even in datasets where thetypes are specified, like Hadoop, the range is limited(e.g., Machine down, Network disconnection, Disk full), lack-ing comprehensiveness. Additionally, these datasetstypically comprise logs from single sources either fromstandalone systems or single node of distributed systems,failing to capture the multi-node, interconnected nature ofdistributed databases. Model Limitations for Distributed Databases: Existingapproaches are tailored for standalone systems, which donot align with the complexities of distributed databases. Inthese databases, to ensure data consistency, cluster nodes arecategorized into Leaders and Followers, meaning differentnodes can exhibit distinct information. Current methods,when used in distributed databases for what is termed ascluster anomaly detection, generally label the entire clusteras anomalous if any single node exhibits abnormal behavior.This approach can lead to a high rate of false positives, asit doesnt adequately consider the intricacies of distributedsystems. Recognizing this gap, we first construct a comprehensive datasetspecifically designed for anomaly detection in distributed databases.Sourced from Apache IoTDB, this dataset comprises 900 mil-lion records and spans 216 GB, making it the first dataset of thisscale and specificity. We inject 11 types of anomalies, coveringall categories reported in state-of-the-art research on distributeddatabases. It includes a wide range of anomalies, fromresource-related issues to datatbase software faults. Moreover, toenable effective multivariate log-based anomaly detection, we metic-ulously collected logs from various nodes.We subsequently carry out an empirical study using this datasetto explore the characteristics of anomalies in distributed databases.Our study focuses on the performance of state-of-art anomaly de-tection models in identifying a spectrum of database anomalies,particularly in scenarios where logs from multiple database nodesare utilized. The findings of our study revealed a notable short-fall in these models they are unable to reach peak performancewhen faced with database anomalies, and exhibit a high rate of false positives in detecting anomalies from multiple node logs. This inad-equacy stems from the fact that different nodes within a databasecan present unique insights into anomalies, with certain anomaliesbeing detectable only through the analysis of logs from multiplenodes.Building upon these insights, we introduce MultiLog, a multi-variate log-based anomaly detection method for distributed data-base. In detail, we initially gather sequential, quantitative, and se-mantic information from the logs of each individual node within thedatabase cluster. Subsequently, these results are processed throughStandalone Estimation, where we utilize LSTM enhanced with self-attention to encode the data into a probability sequence, facilitatinganomaly detection for each node. Finally, we introduce a ClusterClassifier that incorporates an AutoEncoder with a meta-classifierto standardize the probabilities across all nodes and identify thepresence of any anomalies within the entire cluster.Our experiments demonstrate that MultiLog significantly sur-passes current state-of-the-art methods. The evaluation resultsindicate that MultiLog excels in multi-node classification, achiev-ing a remarkable improvement of approximately 12% over existingmethods. Furthermore, in the realm of anomaly detection withinstandalone database nodes, MultiLog notably boosts classificationperformance, recording an impressive enhancement of over 16%.To summarize, our key contributions are as follows:",
  "We construct and open the first dataset for multivariate log-based anomaly detection on distributed databases, totaling216 GB in size and comprising a total of 900 million records": "We conduct a comprehensive study on database logs based onthis dataset. Our study highlights that existing models facechallenges in achieving optimal performance with randomlyinjected database anomalies. Notably, they exhibit a highrate of false positives when identifying anomalies acrossdistributed database nodes. Inspired by the findings, we propose a multivariate log-basedanomaly detection method for distributed database namedMultiLog. This approach utilizes Standalone Estimation toencode sequential, quantitative, and semantic informationfrom the logs of individual nodes, leveraging LSTM with self-attention for this purpose. Subsequently, MultiLog employsa Cluster Classifier, which integrates an AutoEncoder witha meta-classifier, to effectively classify anomalies within thedatabase cluster. The effectiveness of MultiLog is confirmed based on ouropen dataset. Experiments show that MultiLog outperformsstate-of-art methods in multi-nodes classification by approx-imately 12% and improves classification effectiveness in stan-dalone database nodes by over 16%.",
  ": Application of Existing Models in a DistributedContext (Single-Point Classification)": "of a print statement in the source code, which appears in logs withvarying parameter values across different executions. By using a setof invariant keywords and parameters (with parameters indicatedby a placeholder \"*\"), an event can encapsulate multiple log entries.An event sequence is a sequence of log events, each correspondingone-to-one with log entries in a log sequence.We summarize the overall process of log-based anomaly detec-tion in three steps: log parsing, log grouping, and model training.Log parsing extracts log events from system logs, and log group-ing transforms the log sequence into an event sequence. Modeltraining focuses on capturing the characteristics of event sequencesand constructing models for automated recognition. In this pa-per, we apply Drain3 for log parsing, a tool implemented byLogparser. For log grouping, we adopt a time-window basedapproach. Additionally, our study utilizes three state-of-the-artmodels: RobustLog, LogAnomaly, and PLELog.",
  "Application of Anomaly Detection Modelsin a Distributed Context": "When implementing the aforementioned log-based anomaly detec-tion models in a distributed context, the prevailing approach is toassume the entire system is experiencing an anomaly if any singlenode within the cluster exhibits abnormal behavior.As illustrated in , consider a distributed cluster with nodes (1,2,..., 1, ). At each time window, a log-based anomaly detection model is applied to each to predict whether the system is normal or anomalous, denotedas 0, 1. The label for the entire distributed cluster is thendetermined as =1. This implies that if any is anomalous withina given time window, the overall prediction for the cluster isclassified as anomalous; otherwise, it is considered normal.",
  "Construction of Dataset": "In this section, we describe the construction of dataset. We conductexperiments using Apache IoTDB v1.2.2 in a docker environ-ment. Each docker cluster consists of one config node and one datanode, with a configuration of 4 Intel(R) Xeon(R) Platinum 8260CPUs at 2.40GHz, 16GB of DIMM RAM, 1.1TB NVMe disk, andrunning on openjdk11.For the generation of the data, we employ 4 write clients bydefault to insert data to four randomly selected nodes with eachclient assigned 100 threads for parallel insertion.Furthermore, to inject anomalies into the cluster we mainly uti-lize Chaos Mesh. It is an open-source cloud-native chaosengineering platform that provides a wide range of fault injectiontypes, allowing users to simulate various types of anomalies thatmay occur in the real world. However, it is only suitable for sim-ulating anomalies in docker environments. For anomalies relatedto workload and internal bugs, we employ dynamic read / writeworkload adjustment and database configuration modification ap-proaches to inject.",
  "Database Anomalies": "We conduct an analysis of the definitions and classifications ofanomalies in system and database work and discover that databaseanomalies can be classified into two categories: (1) anomalies caused by the system and (2) anomaliesgenerated by the database itself.As outlined in , we categorize 6 types of system-inducedanomalies and 5 types of database-specific anomalies. Among these,Resource-Intensive Compaction (No.10) isthe most prevalent background task in LSM-based databases. Itsimpact on system CPU and memory resources varies based onconfiguration and can lead to write stall issues. Overly FrequentDisk Flushes (No.11) is a fault present in various types of databases.It pertains to the interaction between memory and disk in thedatabase, significantly affecting the frequency of disk file creationand overall database performance.",
  ": Architecture of Anomaly Injection": "The main architecture of anomaly injection is demonstrated in. During the experiment, the database initially operatesnormally for a set period. Subsequently, various types of anomaliesare injected into the database. Before each injection, the currenttimestamp is recorded. The anomalies are then introduced andsustained for a specified duration. After the injection, the current",
  "No.AnomalyCause TypeDescription": "1CPU SaturationSystemThe CPU computing resources exhaust.2IO SaturationSystemThe I/O bandwidth is heavily occupied.3Memory SaturationSystemInsufficient memory resources.4Network Bandwidth LimitedSystemThe network bandwidth between nodes is limited.5Network Partition AriseSystemNetwork partition occurs between nodes.6Machine DownSystemOne server goes down when the applications are running.7Accompanying Slow QueryDatabaseExcessive query load.8Export OperationsDatabaseBacking up data to external source.9Import OperationsDatabaseImporting data from external source.10Resource-Intensive CompactionDatabaseCompaction tasks consume a substantial amount of system resources.11Overly Frequent Disk FlushesDatabaseThe low interval of flush operations leads to frequent disk writes. timestamp is recorded again. The database is then allowed to resumenormal operation for a certain period before the next anomaly isintroduced. This process is repeated, with each cycle injecting adifferent type of anomaly, thus maintaining the database clusterin a cyclic state of normal - abnormal - normal - - abnormal -normal.In the aforementioned architecture, the key component is theanomaly injector, which is responsible for injecting anomalies intothe database. In the implementation, anomalies No. 1 to No. 6 uti-lize Chaos Mesh, anomalies No. 7 to No. 9 are accomplished byadjusting the read / write workload, and anomalies No. 10 to No.11 are implemented through hot modifications to the database con-figuration.",
  ": Sequential Data": "As depicted in , the predominant form of informationis sequential data, specifically, the sequence of log entries. Rawlogs undergo an initial parsing process into event templates, corre-sponding to each print statement in the code. This transformationsimplifies the initially complex logs, rendering them as structuredsequential information. Following this, a fixed-size window is ap-plied to convert the obtained sequential information into organizedwindows, resulting in the final sequential data. This type of informa-tion proves particularly valuable in the detection of anomalies suchas No.8 and No.9 export and import operations, as these operationsoften generate logs resembling Currently [*] data.",
  ": Quantitative Data": "The next aspect is quantitative information, as depicted in, which pertains to the frequency of each type of log entrywithin a window. Derived from the sequential data, this involvescounting the occurrences of different event templates within a fixed-size window. This statistical approach is valuable for detectinganomalies such as No.11 Overly Frequent Disk Flushes, which arecharacterized by an excessive number of disk flush logs.",
  ": Semantic Data": "The last aspect is semantic information, as depicted in ,which involves logs with inherent semantic content. Similar to theprevious categories, this type of information is also derived from thesequential data. It transforms each event template into a semanticvector using sentence embedding methods. Then, the sequentialdata set in converted to a vector data set within a fixed-size window.This enrichment supplements the sequential data with meaningfulsemantic information. It proves valuable for leveraging internaldatabase states in anomaly detection. For example, the presence ofterms like error or too high can serve as significant indicators.",
  "Detecting Anomaly from Multiple NodeLogs": "We further analyze how individual nodes in a database clusterperceive anomalies when one is injected into a specific node.Firstly, we find that the node directly affected by the anom-aly faces challenges in detecting its own issue. As shown in, when inject anomaly (No.8 Export Operation) into 1,PLELog results with a Precision of 39.68%, Recall of 99.01%, andF1-Score of 56.66% and RobustLog results with a Precision of 55.81%,Recall of 71.29%, and F1-Score of 62.61%. However, other nodes areable to detect this anomaly, with 6 achieving an F1-Score of90.73% in PLELog and 99.00% in RobustLog. This situation arisesbecause, although export-related anomalies generate explicit logsin the affected node, the patterns and frequency of these logs arerelatively low, yet they significantly impact system performance.This leads to issues in information exchange with other nodes,making it possible to detect the anomaly from nodes other thanthe affected one. These experiments highlight the fact that relying",
  "%38.20%49.64%291.55%73.03%81.25%375.71%59.55%66.67%485.07%64.04%73.08%582.35%15.73%26.42%687.88%32.58%47.54%Cluster65.57%89.89%75.83%": "Therefore, when conducting cluster anomaly detection, its cru-cial to utilize information from each node, which means employingSingle-Point Classification is essential. To illustrate the significanceof this approach, we conduct an experiment involving the randominjection of anomaly No.8 into all nodes. We find that the individ-ual assessments of all nodes are not very effective. As shownin , when anomaly No.8 is randomly injected. However, theuse of Single-Point Classification enables us to achieve relativelybetter results for the entire cluster, although these results still fallshort of the standards required for production environments indatabases.Furthermore, we assess the overall state of the cluster for anom-alies using the labels predicted by multiple nodes and employing the",
  "%97.62%59.85%280.58%98.81%88.77%393.33%100.00%96.55%498.65%86.90%92.41%594.94%89.29%92.02%696.34%94.05%95.18%Cluster41.58%100.00%58.74%": "aforementioned Single-Point Classification method. We presentsa detailed analysis of the evaluation results for each node and thecluster during the injection of anomaly No.7 (Accompanying SlowQuery) into node 1. As shown in , it is noticeablethat while the F1-Scores for anomaly detection at each individualnode are generally high (mostly above 90%), the effectivenessdrastically decreases when Single-Point Classification is ap-plied. This is evident in both RobustLog (with a 76.71% F1-Score)and LogAnomaly (with a 58.74% F1-Score), where a significant in-crease in false positives is observed (Reflected in 100% Recall andlower Precision). However, the application of Single-Point Classifi-cation is essential, especially for anomalies such as No.8, where itis challenging to determine which node provides the correct label. Summary. In the context of cluster anomaly detection, relyingsolely on logs from a single node may result in missing manysignificant anomalies. However, using only Single-Point Classi-fication to synthesize judgments from various nodes can lead toa high false positive rate.",
  "MultiLog: A Multivariate Log-Based AnomalyDetection Method For Distributed Database": "Our empirical study reveals that state-of-the-art models fail toachieve optimal detection results when faced with the injection ofmultiple anomalies. It also indicates that certain anomalies cannotbe accurately classified by relying solely on logs from a singlenode, underscoring the need for a multivariate log approach inaddressing cluster anomaly detection. However, both state-of-the-art models combined with Single-Point Classification method fallshort in obtaining sufficiently accurate detection outcomes.Therefore, in this section, we introduce MultiLog, a multivari-ate log-based anomaly detection method specifically designed fordistributed databases. depicts the MultiLog framework. Un-like Single-Point Classification, which directly uses the predicted labels from multiple nodes to determine the clusters anomaly la-bel, MultiLog first employs Standalone Estimation to parse, embed,reduce dimensions, and compress logs from multiple nodes. Thisprocess ensures that, in each Time Window, each node outputs avariable-length probability list. Following this, the Cluster Classifierintegrates these probability lists from each node to conclusivelydetermine whether the current cluster is anomalous or normal.",
  "Standalone Estimation": "MultiLog transforms raw log sequences into three types of infor-mation: sequential, quantitative, and semantic, with the aim ofpreserving a comprehensive range of log data for later cluster classi-fication. To capture long-term temporal dependencies and enhancecrucial information, we further integrate self-attention. Summar-ily, Standalone Estimation encompasses five stages: log parsing &grouping, sequential embedding, quantitative embedding, semanticembedding, and information enhancement. 5.1.1Log Parsing & Grouping. As discussed in .1, rawlog messages are unstructured and include variable log parameters,presenting challenges to automated analysis. Thus, aligning withlog-based anomaly detection practices, MultiLog employs log pars-ing to extract structured log events from these messages, therebyenabling more efficient analysis. Specifically, MultiLog utilizes thestate-of-the-art Drain method for log parsing, which has beenproven highly effective and efficient in existing studies. Afterlog parsing, the entirety of raw log messages in the current timewindow can be represented as = (1,2, ...,). Subsequently, forthe convenience of further processing, we employ the fixed win-dow method to further segment into a series of fixed-lengthsequences , each of length . 5.1.2Log Embedding. After log grouping, each batch of raw logmessages is parsed into log events, forming natural sequentialpatterns. The entirety of raw log messages can be representedas = ((1),(2), ...,( )), where each event is representedas . On this basis, we obtain quantitative patterns. To capturethis aspect, we further perform the following transformation: Foreach group of log sequence , we compute the count vector as = ( (1), (2), ..., (), where () represents the fre-quency of in the event vector sequence . Beyond sequentialand quantitative patterns, an event sequence can also encapsulatesemantic patterns. To extract the semantic information from logevents, MultiLog treats each log event as a sentence in natural lan-guage. In detail, we can compute the semantic embedding of as = (((1)), ((2)), ..., (( ))), where (( )) representsthe semantic embedding of log event ( ). More detailed formuladetails are illustrated in Appendix A. 5.1.3Information Enhancement. For each pattern previously ana-lyzed, we employ an LSTM with self-attention to amplify key infor-mation. Each embedding output , , and serves as the inputfor an LSTM. The LSTMs output is denoted as = [1,2, ...,],where represents the hidden state at log event , and is thesize of the window. The self-attention mechanism, applied to this se-quence of hidden states, is calculated as Equation 1, with the scoringfunction defined as (,) = , and as a learnableweight matrix.The context vector , a weighted sum of the hidden",
  "Cluster Classifier": "After acquiring the probabilities calculated by the Standalone Es-timation from the database logs of each node, MultiLog employsthe Cluster Classifier to predict the likelihood of the cluster beinganomalous or normal. To standardize the length of the probabilitiesoutput by each node, an AutoEncoder is applied. Subsequently, Mul-tiLog utilizes a meta-classifier to concatenate these standardizedprobabilities and predict the final outcome for the cluster in thecurrent time window. In summary, the Cluster Classifier consistsof two key steps: AutoEncoder for probability standardization andMeta-Classification for final cluster analysis. 5.2.1AutoEncoder. Given that different nodes generate varyingamounts of log data within the same time window, as previouslydescribed, we group logs based on a fixed length of and assigna probability {0, 1} indicating the likelihood of anomaly foreach group. Consequently, for a database with nodes, it can beinferred that in each time window, the probability list for node is = [1, 2, ..., ], where represents the final outputfor each group as mentioned earlier, and denotes the number ofgroups.",
  "= ()(2b)": "Subsequently, for the node outputs {1, 2, ..., }, MultiLogfirstly apply the encoder function , which truncates or padsthe input probability list to a fixed length , and then maps itto a latent representation of a fixed size . This process is for-mulated in Equation 2a and involves three linear layers with ReLUactivation functions. The decoder function then endeavors toreconstruct the original input from , as outlined in Equation 2b,with the reconstructed probability list denoted as . To align theprobability lists of each node, we utilize MSELoss to minimize thediscrepancy between and , thereby achieving a standardized,dense representation for each nodes probability list. 5.2.2Meta-Classification. After standardizing probabilities withthe AutoEncoder, MultiLog employs Meta-Classification for thefinal assessment of the clusters anomaly status. The latent rep-resentations from each nodes standardized probability list, de-noted as {1,2, ..., }, are concatenated to form a single vectoras Equation 3a. This concatenated vector is then fed into the meta-classifier. The meta-classifier, denoted as , is a neural networkcomprising one hidden layer and an output layer, the latter using asoftmax activation function. The prediction of the overall anomalystatus of the cluster is then formulated as in Equation 3b. Thisprocess determines whether the cluster is classified as \"anomalous\"or \"normal\", based on the collective information from all nodes.",
  "Compared Approaches": "Regarding the existing log-based anomaly detection approaches, weadopt PLELog, RobustLog and LogAnomaly. In partic-ular, we use the their public implementations and determinetheir parameters by first reproducing the results in their correspond-ing studies.To conduct a more comprehensive comparison of MultiLog withthese works, we additionally implement two additional methodsfor integrating logs from different nodes, beyond the Single-PointClassification approach.Vote-Based Classification: This method employs a voting sys-tem among nodes to make decisions, a concept often utilized indistributed consensus algorithms. It involves aggregating the de-cisions from individual nodes, where each nodes prediction label( {0, 1}) is considered a \"vote\". The final decision is determinedbased on the majority of votes, signifying that if =1 > 2 in acluster with nodes, it is identified as anomalous; otherwise, it isconsidered normal.Best-Node Classification: This approach designates the nodewith the best overall performance as the deciding factor for clusteranomaly detection. While this method may not be feasible in real-time operation, it serves as a theoretical benchmark representingthe optimal solution in certain scenarios. Essentially, it assumesthat one node, due to its superior performance or accuracy in anom-aly detection, can be the sole determinant of the clusters state,thus providing insight into the best possible outcomes under idealconditions.",
  "Evaluation Results": "We first conduct cluster anomaly detection based on state-of-artmodels: PLELog, RobustLog, and LogAnomaly, employing theSingle-Point Classification, Vote-Based Classification, and Best-Node Classification methods as previously described, and comparethem with our proposed MultiLog on our dataset.As shown in , it is observable that for the Multi2Singledataset, RobustLog achieves the best result with Vote-Based Clas-sification (F1-Score of 98.16%), closely approaching the Best-NodeClassification, which is impractical in real-world use, yet still fellshort of MultiLog, which reaches 99.75% on this dataset, surpassingthe performance on PLELog, RobustLog, and LogAnomaly usingBest-Node Classification. Furthermore, for the Multi2Multi dataset,the effectiveness of MultiLog far exceeds the best results of these",
  "MultiLog99.88%99.75%99.82%": "three state-of-the-art models (LogAnomaly with Single-Point Clas-sification), by approximately 11.5%. This indicates that MultiLog,through the combination of Standalone Estimation and ClusterClassifier, can effectively perform anomaly detection in complex,multi-node scenarios with multiple anomalies. Moreover, even insimpler scenarios with a single type of anomaly (Single2Single,Single2Multi), MultiLog also achieved better results than the state-of-the-art models, with nearly 99% F1-Score, surpassing the perfor-mance of the infeasible Best-Node Classification in state-of-the-artmodels. This demonstrates that MultiLog is highly effective evenfor single-anomaly scenarios.To delve deeper into the specifics under the Multi2Single andMulti2Multi datasets, we further conduct a detailed comparisonbetween the state-of-the-art models (using Single-Point Classifica-tion, as this approach is commonly adopted in practical scenarios)and MultiLog. As depicted in , it is apparent that the superi-ority of MultiLog stems from its remarkably low false positive rate.Whether its PLELog, RobustLog, or LogAnomaly, their Recall ratesare nearly 100%, indicating their ability to almost always detect allanomalies. However, their Precision varies (ranging from 24.18% forRobustLog to 72.23% for LogAnomaly in the Multi2Multi dataset),whereas MultiLogs Precision is also close to 100%. In summary,MultiLog surpasses these state-of-the-art models chiefly due toits substantially lower rate of false positives, which, in practicalproduction environments, can greatly reduce the workload of DBA(database administrator).To validate the effectiveness and stability of MultiLog, we con-duct additional ablation experiments (Appendix B).",
  "Limitations": "Though our approach can significantly enhance anomaly detectionperformance with multivariate logs, there still exist several notablelimitations. Firstly, our method is supervised. However, it can beadapted to unsupervised scenarios by integrating the Cluster Clas-sifier with unsupervised models such as clustering. Secondly, dueto increased network transmission and computational overhead,our approach operates less efficiently than state-of-the-art methods.In scenarios with very few instances of certain anomaly types, itmay be relatively impractical. Thirdly, while our dataset includes adiverse range of injected anomalies compared to other datasets, itstill deviates from real-world scenarios.",
  "Related Work7.1Log-Based Anomaly Detection andDiagnosis": "Log analysis for fault detection and localization is a well-establishedresearch area. These method-ologies typically involve extracting templates and key informationfrom logs, followed by constructing models for anomaly detectionand classification. There are mainly two types of models in thisdomain: graph-based and deep-learning models.Graph-based models leverage log events parsed from log filesto create a graph-based representation. They detect conflicts andanomalies by comparing event sequences against this graph. Forinstance, LogFlash utilizes a real-time streaming process forlog transitions, enhancing the speed of anomaly detection anddiagnosis. HiLog performs an empirical study on four anti-patterns that challenge the assumptions underlying anomaly de-tection and diagnosis models, proposing a human-in-the-loop ap-proach to integrate human expertise into log-based anomaly detec-tion. LogKG introduces a Failure-Oriented Log Representation(FOLR) method to extract failure-related patterns, using the OPTICSclustering method for anomaly diagnosis.Deep-learning models, conversely, use various neural networksto model sequences of log events. LogRobust applies TermFrequency-Inverse Document Frequency (TF-IDF) and word vector-ization to convert log events into semantic vectors, thus improvingthe accuracy of anomaly detection. UniParser employs a tokenencoder and a context encoder to learn patterns from log tokensand their adjacent contexts.",
  "Anomaly Detection and Diagnosis forDatabase": "Several anomaly detection and diagnosis approaches have beendeveloped for databases, particularly through the useof metrics data. FluxInfer builds a weighted undirected depen-dency graph to illustrate the dependency relationships of anoma-lous monitoring data and employs a weighted PageRank algorithmfor diagnosing online database anomalies. iSQUAD adopts theBayesian Case Model to diagnose anomalies of intermittent slowqueries (iSQs) in cloud databases, based on Key Performance In-dicators (KPI) data. OpenGauss, an autonomous databasesystem, implements an LSTM-based auto-encoder with an attentionlayer for system-level anomaly diagnosis, also leveraging features in metrics data. Sentinel constructs a fine-grained model of datasystem behavior through debug logs to assist DBAs in diagnosinganomalies.To the best of our knowledge, we are the first to construct adataset specifically designed for log-based anomaly detection indatabases. Distinct from prior research, our focus is on leveragingdatabase logs instead of metric data. Additionally, our approachemphasizes the utilization of logs from distributed nodes, setting itapart from related work that concentrates on addressing anomalydetection issues in standalone nodes.",
  "Conclusions": "In this paper, we study the problem of multivariate log-based anom-aly detection in distributed databases. Initially, we conduct a com-prehensive study to evaluate state-of-the-art anomaly detectionmodels specific to distributed databases. This study reveals thatthese models experience a decline in classification effectivenesswhen dealing with multiple database anomalies and exhibit a highfalse positive rate when using multivariate logs. Based on the study,we introduce MultiLog, a multivariate log-based anomaly detec-tion approach for distributed database. MultiLog adeptly leveragesmultivariate logs from all nodes within the distributed databasecluster, significantly enhancing the efficacy of anomaly detection.For evaluation, we release the first open-sourced comprehensivedataset featuring multivariate logs from distributed databases. Ourexperimental evaluations based on this dataset demonstrate theeffectiveness of MultiLog.In future work, our research will concentrate on incorporatingmore characteristics of distributed databases for anomaly detection.Additionally, we will further explore anomaly diagnosis and rootcause analysis for distributed databases based on log data.",
  "This work was supported by the National Key R&D Research Fundof China (2021YFF0704202)": "Anton Babenko, Leonardo Mariani, and Fabrizio Pastore. 2009. AVA: automatedinterpretation of dynamically detected anomalies. In Proceedings of the eighteenthinternational symposium on Software testing and analysis. 237248. Adam Bjrnberg. 2021. Cloud native chaos engineering for IoT systems. Peter Bodik, Moises Goldszmidt, Armando Fox, Dawn B Woodard, and HansAndersen. 2010. Fingerprinting the datacenter: automated classification of perfor-mance crises. In Proceedings of the 5th European conference on Computer systems.111124. Michael Alan Chang, Bredan Tschaen, Theophilus Benson, and Laurent Vanbever.2015. Chaos monkey: Increasing sdn reliability through systematic networkdestruction. In Proceedings of the 2015 ACM Conference on Special Interest Groupon Data Communication. 371372.",
  "Mike Chen, Alice X Zheng, Jim Lloyd, Michael I Jordan, and Eric Brewer. 2004.Failure diagnosis using decision trees. In International Conference on AutonomicComputing, 2004. Proceedings. IEEE, 3643": "Pengfei Chen, Yong Qi, Pengfei Zheng, and Di Hou. 2014. Causeinfer: Auto-matic and distributed performance diagnosis with hierarchical causality graph inlarge distributed systems. In IEEE INFOCOM 2014-IEEE Conference on ComputerCommunications. IEEE, 18871895. Rui Chen, Shenglin Zhang, Dongwen Li, Yuzhe Zhang, Fangrui Guo, WeibinMeng, Dan Pei, Yuzhi Zhang, Xu Chen, and Yuqing Liu. 2020. Logtransfer: Cross-system log anomaly detection for software systems with transfer learning. In 2020IEEE 31st International Symposium on Software Reliability Engineering (ISSRE).IEEE, 3747.",
  "Peter Hochschild, et al. 2013. Spanner: Googles globally distributed database.ACM Transactions on Computer Systems (TOCS) 31, 3 (2013), 122": "donglee afar. 2023. logdeep. Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. 2017. Deeplog: Anomalydetection and diagnosis from system logs through deep learning. In Proceedingsof the 2017 ACM SIGSAC conference on computer and communications security.12851298. Chiming Duan, Tong Jia, Ying Li, and Gang Huang. 2023. AcLog: An Approachto Detecting Anomalies from System Logs with Active Learning. In Proceedingsof the 27th IEEE International Conference on Web Services. 10211030. Ilenia Fronza, Alberto Sillitti, Giancarlo Succi, Mikko Terho, and Jelena Vlasenko.2013. Failure prediction based on log files using random indexing and supportvector machines. Journal of Systems and Software 86, 1 (2013), 211.",
  "Haixuan Guo, Shuhan Yuan, and Xintao Wu. 2021. Logbert: Log anomaly detec-tion via bert. In 2021 international joint conference on neural networks (IJCNN).IEEE, 18": "Xiao Han and Shuhan Yuan. 2021. Unsupervised cross-system log anomalydetection via domain adaptation. In Proceedings of the 30th ACM InternationalConference on Information & Knowledge Management. 30683072. Pinjia He, Jieming Zhu, Shilin He, Jian Li, and Michael R Lyu. 2016. An evaluationstudy on log parsing and its use in log mining. In 2016 46th annual IEEE/IFIPinternational conference on dependable systems and networks (DSN). IEEE, 654661.",
  "Yintong Huo, Yichen Li, Yuxin Su, Pinjia He, Zifan Xie, and Michael R Lyu. 2023.AutoLog: A Log Sequence Synthesis Framework for Anomaly Detection. arXivpreprint arXiv:2308.09324 (2023)": "Vimalkumar Jeyakumar, Omid Madani, Ali Parandeh, Ashutosh Kulshreshtha,Weifei Zeng, and Navindra Yadav. 2019. ExplainIt!A declarative root-causeanalysis engine for time series data. In Proceedings of the 2019 InternationalConference on Management of Data. 333348. Tong Jia, Ying Li, Yong Yang, Gang Huang, and Zhonghai Wu. 2022. AugmentingLog-based Anomaly Detection Models to Reduce False Anomalies with HumanFeedback. In Proceedings of the 28th ACM SIGKDD Conference on KnowledgeDiscovery and Data Mining. 30813089. Tong Jia, Yifan Wu, Chuanjia Hou, and Ying Li. 2021. LogFlash: Real-time stream-ing anomaly detection and diagnosis from system logs for large-scale softwaresystems. In 2021 IEEE 32nd International Symposium on Software Reliability Engi-neering (ISSRE). IEEE, 8090. Tong Jia, Lin Yang, Pengfei Chen, Ying Li, Fanjing Meng, and Jingmin Xu. 2017.Logsed: Anomaly diagnosis through mining time-weighted control flow graphin logs. In 2017 IEEE 10th International Conference on Cloud Computing (CLOUD).IEEE, 447455.",
  "Pinjia He Jinyang Liu Michael R. Lyu Jieming Zhu, Shilin He. 2023. Loghub: Alarge collection of system log datasets towards automated log analytics. (2023)": "Yuyuan Kang, Xiangdong Huang, Shaoxu Song, Lingzhe Zhang, Jialin Qiao, ChenWang, Jianmin Wang, and Julian Feinauer. 2022. Separation or not: On handingout-of-order time-series data in leveled lsm-tree. In 2022 IEEE 38th InternationalConference on Data Engineering (ICDE). IEEE, 33403352. Jinhan Kim, Valeriy Savchenko, Kihyuck Shin, Konstantin Sorokin, HyunseokJeon, Georgiy Pankratenko, Sergey Markov, and Chul-Joo Kim. 2020. Automaticabnormal log detection by analyzing log history for providing debugging in-sight. In Proceedings of the ACM/IEEE 42nd International Conference on SoftwareEngineering: Software Engineering in Practice. 7180.",
  "Yinglung Liang, Yanyong Zhang, Hui Xiong, and Ramendra Sahoo. 2007. Failureprediction in ibm bluegene/l event logs. In Seventh IEEE International Conferenceon Data Mining (ICDM 2007). IEEE, 583588": "Qingwei Lin, Hongyu Zhang, Jian-Guang Lou, Yu Zhang, and Xuewei Chen. 2016.Log clustering based problem identification for online service systems. In Pro-ceedings of the 38th International Conference on Software Engineering Companion.102111. Dewei Liu, Chuan He, Xin Peng, Fan Lin, Chenxi Zhang, Shengfang Gong, ZiangLi, Jiayu Ou, and Zheshun Wu. 2021. Microhecl: High-efficient root cause local-ization in large-scale microservice systems. In 2021 IEEE/ACM 43rd InternationalConference on Software Engineering: Software Engineering in Practice (ICSE-SEIP).IEEE, 338347. Ping Liu, Yu Chen, Xiaohui Nie, Jing Zhu, Shenglin Zhang, Kaixin Sui, MingZhang, and Dan Pei. 2019. Fluxrank: A widely-deployable framework to auto-matically localizing root cause machines for software service failure mitigation.In 2019 IEEE 30th International Symposium on Software Reliability Engineering(ISSRE). IEEE, 3546. Ping Liu, Shenglin Zhang, Yongqian Sun, Yuan Meng, Jiahai Yang, and DanPei. 2020. Fluxinfer: Automatic diagnosis of performance anomaly for onlinedatabase system. In 2020 IEEE 39th International Performance Computing andCommunications Conference (IPCCC). IEEE, 18. Yudong Liu, Xu Zhang, Shilin He, Hongyu Zhang, Liqun Li, Yu Kang, Yong Xu,Minghua Ma, Qingwei Lin, Yingnong Dang, et al. 2022. Uniparser: A unified logparser for heterogeneous log data. In Proceedings of the ACM Web Conference2022. 18931901. Siyang Lu, Xiang Wei, Yandong Li, and Liqiang Wang. 2018. Detecting anomalyin big data system logs using convolutional neural network. In 2018 IEEE 16th IntlConf on Dependable, Autonomic and Secure Computing, 16th Intl Conf on PervasiveIntelligence and Computing, 4th Intl Conf on Big Data Intelligence and Computingand Cyber Science and Technology Congress (DASC/PiCom/DataCom/CyberSciTech).IEEE, 151158. Minghua Ma, Zheng Yin, Shenglin Zhang, Sheng Wang, Christopher Zheng, Xin-hao Jiang, Hanwen Hu, Cheng Luo, Yilin Li, Nengjun Qiu, et al. 2020. Diagnosingroot causes of intermittent slow queries in cloud databases. Proceedings of theVLDB Endowment 13, 8 (2020), 11761189. Adetokunbo AO Makanju, A Nur Zincir-Heywood, and Evangelos E Milios. 2009.Clustering event logs using iterative partitioning. In Proceedings of the 15thACM SIGKDD international conference on Knowledge discovery and data mining.12551264. Weibin Meng, Ying Liu, Yichen Zhu, Shenglin Zhang, Dan Pei, Yuqing Liu, YihaoChen, Ruizhi Zhang, Shimin Tao, Pei Sun, et al. 2019. Loganomaly: Unsuperviseddetection of sequential and quantitative anomalies in unstructured logs.. In IJCAI,Vol. 19. 47394745.",
  "Subhadeep Sarkar, Dimitris Staratzis, Ziehen Zhu, and Manos Athanassoulis.2021. Constructing and analyzing the LSM compaction design space. Proceedingsof the VLDB Endowment 14, 11 (2021)": "Yicheng Sui, Yuzhe Zhang, Jianjun Sun, Ting Xu, Shenglin Zhang, ZhengdanLi, Yongqian Sun, Fangrui Guo, Junyu Shen, Yuzhi Zhang, et al. 2023. LogKG:Log Failure Diagnosis through Knowledge Graph. IEEE Transactions on ServicesComputing (2023). Chen Wang, Xiangdong Huang, Jialin Qiao, Tian Jiang, Lei Rui, Jinrui Zhang,Rong Kang, Julian Feinauer, Kevin A McGrail, Peng Wang, et al. 2020. Apacheiotdb: time-series database for internet of things. Proceedings of the VLDB En-dowment 13, 12 (2020), 29012904. Li Wu, Johan Tordsson, Jasmin Bogatinovski, Erik Elmroth, and Odej Kao. 2021.Microdiag: Fine-grained performance diagnosis for microservice systems. In 2021IEEE/ACM International Workshop on Cloud Intelligence (CloudIntelligence). IEEE,3136. Wei Xu, Ling Huang, Armando Fox, David Patterson, and Michael I Jordan. 2009.Detecting large-scale system problems by mining console logs. In Proceedings ofthe ACM SIGOPS 22nd symposium on Operating systems principles. 117132. Lin Yang, Junjie Chen, Zan Wang, Weijing Wang, Jiajun Jiang, Xuyuan Dong,and Wenbin Zhang. 2021. Semi-supervised log-based anomaly detection viaprobabilistic label estimation. In 2021 IEEE/ACM 43rd International Conference onSoftware Engineering (ICSE). IEEE, 14481460.",
  "Multivariate Log-based Anomaly Detection for Distributed DatabaseKDD 24, August 2529, 2024, Barcelona, Spain": "Zhenkun Yang, Chuanhui Yang, Fusheng Han, Mingqiang Zhuang, Bing Yang,Zhifeng Yang, Xiaojun Cheng, Yuzhong Zhao, Wenhui Shi, Huafeng Xi, et al.2022. OceanBase: a 707 million tpmC distributed relational database system.Proceedings of the VLDB Endowment 15, 12 (2022), 33853397. Kun Yin, Meng Yan, Ling Xu, Zhou Xu, Zhao Li, Dan Yang, and Xiaohong Zhang.2020. Improving log-based anomaly detection with component-aware analysis.In 2020 IEEE International Conference on Software Maintenance and Evolution(ICSME). IEEE, 667671. Dong Young Yoon, Ning Niu, and Barzan Mozafari. 2016. Dbsherlock: A per-formance diagnostic tool for transactional databases. In Proceedings of the 2016International Conference on Management of Data. 15991614. Lingzhe ZHANG, Xiangdong HUANG, Jialin QIAO, Wangminhao GOU, andJianmin WANG. 2021. Two-stage file compaction framework by log-structuredmerge-tree for time series data. Journal of Computer Applications 41, 3 (2021),618. Lingzhe Zhang, Yuqing Zhu, Yanzhe An, Yuan Zi, and Jianmin Wang. 2024. Theoptimization problem of system load balancing and its solution for industrialInternet-of-Things data management. SCIENTIA SINICA Informationis (2024).",
  "Tianzhu Zhang, Han Qiu, Gabriele Castellano, Myriana Rifai, Chung Shue Chen,and Fabio Pianese. 2023. System Log Parsing: A Survey. IEEE Transactions onKnowledge and Data Engineering (2023)": "Xu Zhang, Yong Xu, Qingwei Lin, Bo Qiao, Hongyu Zhang, Yingnong Dang,Chunyu Xie, Xinsheng Yang, Qian Cheng, Ze Li, et al. 2019. Robust log-basedanomaly detection on unstable log data. In Proceedings of the 2019 27th ACMJoint Meeting on European Software Engineering Conference and Symposium onthe Foundations of Software Engineering. 807817. Xuanhe Zhou, Lianyuan Jin, Ji Sun, Xinyang Zhao, Xiang Yu, Jianhua Feng, ShifuLi, Tianqing Wang, Kun Li, and Luyang Liu. 2021. Dbmind: A self-driving platformin opengauss. Proceedings of the VLDB Endowment 14, 12 (2021), 27432746. Xiang Zhou, Xin Peng, Tao Xie, Jun Sun, Chao Ji, Wenhai Li, and Dan Ding. 2018.Fault analysis and debugging of microservice systems: Industrial survey, bench-mark system, and empirical study. IEEE Transactions on Software Engineering 47,2 (2018), 243260. Jieming Zhu, Shilin He, Jinyang Liu, Pinjia He, Qi Xie, Zibin Zheng, and Michael RLyu. 2019. Tools and benchmarks for automated log parsing. In 2019 IEEE/ACM41st International Conference on Software Engineering: Software Engineering inPractice (ICSE-SEIP). IEEE, 121130.",
  "ALog EmbeddingA.1Sequential Embedding": "After log grouping, each batch of raw log messages is parsed into logevents, forming natural sequential patterns. Specifically, each eventis represented as a distinct vector , and the entire collection ofunique event vectors is denoted as = {1,2, ...,}. Consequently,the event vector sequence is transformed as Equation 4, where constitutes the sequential embedding of this particular group oflog message sequences.",
  "A.2Quantitative Embedding": "Beyond sequential patterns, an event sequence also exhibits quan-titative patterns. Typically, normal program execution follows cer-tain invariants, with specific quantitative relationships consistentlymaintained in logs under various inputs and workloads. For in-stance, each file opened during a process is eventually closed. Assuch, the number of logs indicating \"create a memtable\" shouldmatch those showing \"flush a memtable to file\" under normal condi-tions. These quantitative relationships within logs are indicative ofstandard program execution behaviors. Anomalies can be identifiedwhen new logs disrupt these invariants. To capture this aspect, weanalyze the quantitative pattern of logs as follows: For each groupof log sequence , we compute the count vector as Equation 5,where () represents the frequency of in the event vectorsequence (1,2, ...,), and .",
  "A.3Semantic Embedding": "Beyond sequential and quantitative patterns, an event sequencecan also encapsulate semantic patterns. To extract the semanticinformation from log events, MultiLog treats each log event asa sentence in natural language. Given that log events are formu-lated by developers to record system statuses, most tokens in theseevents are English words with intrinsic semantics. However, logevents also contain non-character tokens (like delimiters, opera-tors, punctuation marks, and number digits) and composite tokensresulting from word concatenations (such as \"NullPointerExcep-tion\") due to programming conventions. In alignment with existingresearch, MultiLog initially preprocesses log events by elim-inating non-character tokens and stop words, and decomposingcomposite tokens into individual words using Camel Case splitting.Following this, MultiLog utilizes pre-trained word vectors based onthe Common Crawl Corpus with the FastText algorithm, whichis adept at capturing the inherent relationships among words innatural language. This means each word in a processed log event istransformed into a -dimensional vector (denoted as ) using thepre-trained word2vec model, where is set to 300 in FastText wordvectors.",
  "#)(6b)": "After transforming each word to a -dimension vector via Fast-Text word embedding, MultiLog further transforms a log event intoa semantic vector by aggregating all the word vectors within it. Forthis aggregation, MultiLog adopts TF-IDF, taking into accountthe significance of each word. Term Frequency (TF) measures howfrequently a word assesses the frequency of a word in a log event,calculated as Equation 6a, where # represents the count of inthe log event and # represents the total word count in the logevent. Inverse Document Frequency (IDF) evaluates the commonal-ity or rarity of iacross all log events, computed as Equation 6b,where # is the total number of log events, and # is the numberof log events containing . The weight of a word (denoted as ) isdetermined by . Ultimately, the semantic vector (denotes ) of a log event is derived by summing up all word vectors in thelog event, weighted by their TF-IDF values, as = 1",
  "BEffectiveness of Cluster Classifier": "Although the effectiveness of MultiLog is a combined result of theStandalone Estimation and Cluster Classifier, the latter plays a cru-cial role in utilizing information from multiple nodes. Therefore,to further analyze its impact, we conduct comparative validationexperiments on both the Multi2Single and Multi2Multi datasets.For the probability lists resulting from Standalone Estimation, weemploy both the Single-Based Classification and Vote-Based Classi-fication to judge whether the cluster is anomalous or normal. PrecisionRecallF1-score0 Score (%) 90.72 99.7795.03100 26.76 42.22 99.8899.6299.75 Single-PointVote-BasedCluster (ours)",
  ": Results with(out) Cluster Classifier": "As depicted in , when employing Vote-Based Classifica-tion, a consistently high Precision (always 100%) is maintained,but the Recall is low (26.76% for Multi2Single and 39.31% forMulti2Multi), indicating that many anomalies are missed. In con-trast, using Single-Point Classification balances Precision and Recallto some extent, significantly improving the F1-Score to approxi-mately 95% on both datasets, surpassing the results achieved bystate-of-the-art methods mentioned previously. However, with theimplementation of the Cluster Classifier, the F1-Score exceeds 99%on both datasets, demonstrating the Cluster Classifiers superiorability to utilize information from multiple nodes effectively."
}