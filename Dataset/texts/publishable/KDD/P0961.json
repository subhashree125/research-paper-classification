{
  "ABSTRACT": "Continuous-Time Dynamic Graph (CTDG) precisely models evolv-ing real-world relationships, drawing heightened interest in dy-namic graph learning across academia and industry. However, ex-isting CTDG models encounter challenges stemming from noise andlimited historical data. Graph Data Augmentation (GDA) emergesas a critical solution, yet current approaches primarily focus onstatic graphs and struggle to effectively address the dynamics inher-ent in CTDGs. Moreover, these methods often demand substantialdomain expertise for parameter tuning and lack theoretical guaran-tees for augmentation efficacy. To address these issues, we proposeConda, a novel latent diffusion-based GDA method tailored for CT-DGs. Conda features a sandwich-like architecture, incorporating aVariational Auto-Encoder (VAE) and a conditional diffusion model,aimed at generating enhanced historical neighbor embeddings fortarget nodes. Unlike conventional diffusion models trained on en-tire graphs via pre-training, Conda requires historical neighborsequence embeddings of target nodes for training, thus facilitatingmore targeted augmentation. We integrate Conda into the CTDGmodel and adopt an alternating training strategy to optimize perfor-mance. Extensive experimentation across six widely used real-worlddatasets showcases the consistent performance improvement ofour approach, particularly in scenarios with limited historical data.",
  "Corresponding Author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from 24, August 2529, 2024, Barcelona, Spain. 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 979-8-4007-0490-1/24/08",
  "INTRODUCTION": "Continuous-Time Dynamic Graphs (CTDGs), with every edge (event)having a timestamp to denote its occurrence time, are prevalentin real-world applications such as social networks , physicalsystems and e-commerce . Recently, CTDG models have gained increasing attention due totheir significant representation capacity by directly learning therepresentation of the continuously occurring events in CTDGs. De-spite the rapid advancements in CTDG models, they encounter twoprimary challenges. Firstly, the \"observed\" CTDG often falls shortof accurately representing the true underlying process it intendsto model, mainly due to various factors such as measurement in-accuracies, thresholding errors, or human mistakes . Secondly,most CTDG methods typically rely on extensive historical data foreffective training . However, in many applications, obtainingsuch data is impractical, particularly in scenarios with a cold start.For instance, a nascent trading platform may only possess a fewdays worth of user-asset interactions, rendering existing CTDGmodels trained on such limited data inadequate and resulting insub-optimal performance.Graph Data Augmentation (GDA) has emerged as a promisingsolution, with existing methods falling into two main categories :structure-oriented and feature-oriented methods. Structure-orientedmethods, such as , typically involve adjusting graph con-nectivity by adding or removing edges or nodes. On the other hand,feature-oriented methods, exemplified by works from , directly modify or create raw features of nodes or edges ingraphs.",
  "KDD 24, August 2529, 2024, Barcelona, Spain.Yuxing Tian, Aiwen Jiang, Qi Huang, Jian Guo, & Yiyan Qi": "Tanya Y. Berger-Wolf and Jared Saia. 2006. A Framework for Analysis of DynamicSocial Networks. In Proceedings of the 12th ACM SIGKDD International Conferenceon Knowledge Discovery and Data Mining (Philadelphia, PA, USA) (KDD 06).Association for Computing Machinery, New York, NY, USA, 523528. Xiaofu Chang, Xuqin Liu, Jianfeng Wen, Shuang Li, Yanming Fang, Le Song, andYuan Qi. 2020. Continuous-time dynamic graph learning via neural interactionprocesses. In Proceedings of the 29th ACM International Conference on Information& Knowledge Management. 145154. Nan Chen, Zemin Liu, Bryan Hooi, Bingsheng He, Rizal Fathony, Jun Hu, andJia Chen. 2024. Consistency Training with Learnable Data Augmentation forGraph Anomaly Detection with Limited Supervision. In The Twelfth InternationalConference on Learning Representations.",
  "PRELIMINARIES2.1Continuous-Time Dynamic Graph": "A CTDG can be represented as a chronological sequence of inter-actions between specific node pairs: = {(0, 0,0), . . . , (, ,)},where denotes the timestamp and the timestamps are orderedas (0 0 1 ... ). , denote the node IDs of the interaction at timestamp , is the entire node set. Eachnode is associated with node feature , and each interaction(, ,) has edge feature , , where and denote thedimensions of the node and link feature respectively.",
  "Diffusion Model": "The diffusion model encompasses both forward and reverse pro-cesses.Forward process. In general, given an input data point 0 drawnfrom the distribution (0), the forward process involves graduallyintroducing Gaussian noise to 0, generating a sequence of increas-ingly noisy variables 1, 2, . . . , in a Markov chain. The finalnoisy output, , follows a Gaussian distribution N (0, ) and car-ries no discernible information about the original data point. Specif-ically, the transition from one point to the next is determined bya conditional probability (|1) = N (; 1 1, ),where (0, 1) controls the scale of noise added at step .Reverse process. The reverse process reverses the effects of theforward process by learning to eliminate the added noise and triesto gradually reconstruct the original data 0 via sampling from by learning a neural network .Inference. Once trained, the diffusion model can produce new databy sampling a point from the final distribution N (0, ) andthen iteratively denoising it using the aforementioned model 1 0 to obtain a sample from the data distribution.",
  "METHODOLOGY": "Existing structure-oriented GDA methods like MeTA augment theCTDGs by modifying the initial interactions through edge addi-tion/deletion and time perturbation. However, these methods in-troduce coarse-grained augmentations and substantially alter theoriginal transition patterns within CTDGs. Conversely, simply in-troducing noise to either the raw or hidden feature space often lackstheoretical bound. In this section, we introduce a novel fine-grainedGDA model based on a conditional diffusion model and establishrobust theoretical guarantees.",
  "Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph ModelKDD 24, August 2529, 2024, Barcelona, Spain": "From the results, we can observe that with the ratio of train setdecreasing, the performance of each baseline also decreases. Specif-ically, when the training data is relatively sufficient, all baselinesachieve great performance. However, when training data is morelimited, the performance of most baselines drops significantly (e.g.JODIE on Wiki_0.1, all baselines on Reddit_0.1, MOOC_0.1 andSocialEvo_0.1). The possible reason is that the paradigm of CTDGmodels is to use historical data to obtain target node embeddings.When historical data is limited, the quality of the obtained embed-dings cannot be guaranteed. In addition, the data distribution of thetesting set could be diverse from the training set. This would lead tothe model overfitting the historical data and cannot be generalizedto future data. By using Conda, the models performance improves.It is achieved by utilizing the conditional diffusion model to gener-ate augmented historical neighbor embeddings of the target nodeduring the training of the CTDG model. In Conda, the mechanismof partial noise addition and conditional inputs ensures that thenewly generated embeddings are not random. Instead, they closelyresemble the embeddings of recently interacted neighbors. Con-sequently, this guarantees high-quality embeddings of the nodeshistorical neighbors following augmentation.In addition, we also compare Conda with three GDA methodsto show the superiority of our GDA method. Overall, we find thatConda can consistently outperform competing GDA methods. Fur-thermore, the variance in the results indicates that Conda providesstable improvements in model performance, unlike other GDAmethods that rely on random augmentations and thus yield erraticresults. This stability is particularly evident in the setting with moresparse training data (e.g. 0.1 train set ratio). By analyzing the experi-ments on datasets with a 0.3 train set ratio, its obvious that all GDAmethods can improve baselines performance on most datasets tosome extent, but the improvement on UCI_0.3 is relatively minorcompared to SocialEvo_0.3. The reason may be that SocialEvo hasa smaller sparsity and longer interaction sequences than UCI. Thisphenomenon suggests that training the CTDG model indeed re-quires sufficient historical interaction data. Moreover, we noticethat MeTA improves baselines performance than DropEdge andDropNode. This might be because MeTA considers the time pertur-bation, which is crucial for dynamic graph learning. Additionally,unlike Dropedge and DropNode, which essentially remove edges,MeTA maintains or even increases the number of interaction datasamples before and after augmentation by simultaneously addingand removing edges. However, due to the combination of multipleaugmentation strategies, the results of MeTA also introduce a largervariance, indicating that it is hard to control.Next, we analyze the results of the experiment on datasets with a0.1 train set ratio. clearly shows that, apart from our method,which still achieves stable performance improvements, the otherthree methods frequently resulted in outcomes even worse thanthe original baseline. The main reason is that at such a low ratioof train sets, the datasets become extremely sparse. At this level,employing random perturbations like edge deletion further reducesthe already insufficient data samples and risks removing essentialinteraction. However, our method maintains stable performancegains by controlling the diffused sequence length. Even thoughthe dataset becomes sparser and the historical neighbors of nodesdecrease, by simultaneously reducing the length of the diffused",
  "For brevity, we omit the subscript node and superscript timestamp in for unless necessary to avoid ambiguity": "where a hyper-parameter controls the noise scales, andtwo hyper-parameters min < max (0, 1) indicating the upperand lower bounds of the added noises.Reverse Process with Conditional Denoising. The reverseprocess is used to reconstruct the original 0 by denoising . Withthe partial nosing strategy adopted in the forward process, we cannaturally employ the part without noise as the conditional inputwhen denoising.Starting from , the reverse process is parameterized by thedenoising transition step:",
  "Optimization and Alternating Training": "In this section, we first present the optimization objective for theConda and the CTDG model, respectively. Then we introduce thetraining and inference process of CTDG model with conda.Although our ultimate goal is to learn a CTDG model , butwe also have to learn the parameters of the VAE encoder (|),the conditional diffusion model log (0) and the VAE decoder (| 0) for providing positive augmentation to the CTDG model.CTDG model. For training the CTDG model , the Loss func-tion L depends on the downstream task. For example, if thedownstream task is link prediction, then the loss function is binarycross-entropy.",
  "E (|)log (|)": "(8)where the first term measures the reconstruction likelihood of thedecoder from variational distribution, the second term measureshow similar the learned variational distribution is to a prior beliefheld over latent variables. Maximizing the ELBO is thus equivalentto maximizing its first term and minimizing its second term. Sincethe KL divergence term of the ELBO can be computed analytically,and the reconstruction term can be approximated using a MonteCarlo estimate:",
  "=2||x0 (x,) ||2(16)": "Optimization of Conda.In conclusion, we combine and minimize the loss of the condi-tional diffusion model and VAE via L(0;) + L (;,)to optimize Conda, where the hyper-parameter ensures the twoterms in the same magnitude.Alternating training. Unlike the common diffusion models thatare trained for the direct generation of raw graph data throughpre-training, Conda requires the historical neighbor sequence em-beddings of nodes obtained through the CTDG encoder beforeperforming the diffusion process. Therefore, we utilize alternativetraining method to alternatively train the CTDG model and Conda.Here we briefly describe the training process. Initially, the CTDGmodel is trained by minimizing the L for rounds. Thenwe insert Conda into the intermediate layer of the CTDG model andtrain the ,, according to L(0;) + L (;,) withthe frozen for rounds. Next, we train the CTDG model again for rounds with the ,, frozen. At this point, Condais in the inference phase, used to generate augmented historicalneighbor embeddings via the reverse process. The above processwill be repeated several times.",
  "Baselines. Since Conda is agnostic to model structure, toevaluate the performance of our GDA method, we conduct experi-ments on several state-of-the-art CTDG models, including JODIE ,": "DyRep , TGAT , TGN , TCL , GraphMixer , DyG-Former . We also combine our method with other data aug-mentation methods: DropEdge , DropNode , and MeTA .Detailed descriptions of these baselines and GDA methods can befound in Appendix A.2 and Appendix A.3, respectively. 4.1.3Evaluation and hyper-parameter settings. We evaluateConda on the task of link prediction. As for the evaluation met-rics, we follow the previous works , employing AveragePrecision (AP) and Area Under the Receiver Operating Character-istic Curve (A-R) as the evaluation metrics. We perform the gradsearch to find the best settings of some critical hyper-parameters.We vary the learning rates of all baselines in {14, 13}, thedropout rate of dropout layer in {0.0, 0.1, 0.2, 0.3, 0.4, 0.5}, the num-ber of sampled neighbors and the diffusion length",
  "}, respectively. The": "number of diffusion steps is fixed at 50, respectively. Besides, thenoise scale is tuned in {15, 14, 13, 12}. Regarding GDAmethods used for comparison, we vary the drop rate for Dropedgeand Dropnode in {0.1, 0.2, 0.3, 0.4, 0.5}. As for MeTA, we controlthe magnitude of the three DA strategies with a unified , vary in{0.1, 0.2, 0.3}, and follow the setting in its paper. More details arelisted in the Appendix.The configurations of the baselines align with those specifiedin their respective papers. The model that achieves the highestperformance on the validation set is selected for testing. We conductfive runs of each method with different seeds and report the average",
  "Performance Comparison and Discussion": "In this section, in order to verify the effectiveness of Conda, weintegrate it into each baseline across six datasets with differentratios of the train set for the link prediction task. As shown in and , mean and standard deviations of five runs arereported, and the best results are highlighted in bold font. Theexperiment results clearly demonstrate that Conda improves theperformance of all the baselines with respect to all datasets withdifferent ratios of train sets.",
  "Ablation analysis": "We conduct an ablation study to assess the contributions of theVAE and diffusion components within the Conda module. Theresults, summarized in , compare the baseline GraphMixer,add Conda without VAE (+Conda w/o VAE), add Conda withoutdiffusion (+Conda w/o diffusion), and add the full Conda module(+Conda).It is obvious that the full Conda module achieves the highest APscores on all datasets, and consistently outperforms all variants,indicating the importance of both VAE and diffusion components.Removing the diffusion component results in a performance drop,particularly on WIKI_0.1 (from 94.61 to 93.87), highlighting the dif-fusions role in generating effective latent representation. Similarly,removing the VAE component also decreases AP scores, especiallyon MOOC_0.1 (from 75.24 to 74.77). In conclusion, the combinationof the VAE and diffusion model results in superior performance, asshown by consistently higher AP scores compared to the ablatedvariants. This synergy is crucial for optimal model performance.In addition to the ablation study of the Conda module, we alsoexplore different training approaches to further understand theirimpact on model performance. As shown in , we conductexperiments on GraphMixer+Conda with two different trainingapproaches: end-to-end training (E2E) and alternative training (AT).The results indicate that the E2E training approach results in asignificant performance decline across all datasets. For example,on the MOOC_0.1 and MOOC_0.3, the AP drops from 75.24.61(AT) to 73.62 (E2E) and from 80.01 (AT) to 78.53 E2E), respectively.This decline can be attributed to conflicting objectives between theConda module and the CTDG model. The Conda module aims togenerate embeddings similar to the original data, while the CTDGmodel seeks to learn from diverse augmented data close to realityto enhance performance. When integrated into end-to-end training,these conflicting goals prevent the model from optimally achiev-ing both objectives, leading to suboptimal or even diminishingperformance.",
  "Sensitivity of Hyper-Parameters": "In this section, we conduct experiments to investigate the Sensitiv-ity of two important hyper-parameters in our proposed method:diffused sequence length and noise scale .We conducted experiments with DyGFormer on Reddit, MOOC,and SocialEvo datasets, as DyGFormer tends to yield better resultsfrom longer historical neighbor sequences on these datasets, whichcan effectively show the effect on the model performance of usingvarying diffused lengths across the historical neighbor sequence.We also provide the optimal configurations of the number ofsampled neighbors and diffused sequence length of differentbaselines on different datasets in Appendix A.4. Specifically, we firstset , the number of sampled historical neighbors by DyGFormer",
  ", the model performance is slightly worse than at": "8but still outperforms the baseline. This phenomenon indicates thatConda can consistently generate positive augmentation when itcontrols the length of diffused sequence embedding to be relativelyshort.For the noise scale, we conduct experiments on GraphMixer+Condawith Reddit_0.3, MOOC_0.3, and SocialEvo_0.3 . As illustrated in, we can observe that, as the noise scale increases, the per-formance first rises compared to training without noise ( = 0),verifying the effectiveness of denoising training. However, enlarg-ing noise scales degrades the performance due to corrupting thepattern of interaction sequence. Hence, we also should carefullychoose a relatively small noise scale (e.g. 14).",
  "RELATED WORK5.1Graph Data Augmentation": "There is a growing interest among researchers in graph data aug-mentation (GDA) methods since they offer an attractive solution indenoising and generally augmenting graph data. GDA methods canbe categorized into structure-oriented and feature-oriented meth-ods by the data modality that they aim to manipulate. Structure-oriented GDA methods often modify the graph structure via addingor removing edges and nodes. Zhao et al. and Gasteiger et al. modify the graph structure and used the modified graph fortraining/inference, Feng et al. , Rong et al. randomly dropedges/nodes from the observed training graph. Wang et al. utilizes a node-centric strategy to crop a subgraph from the origi-nal graph while maintaining its connectivity. However, these GDAmethods are usually used in static graphs or DTDG and can not bedirectly applied to CTDG due to the lack of consideration of time,Although Wang et al. introduces MeTA for CTDG model, whichaugments CTDG combining three structure-oriented GDA methodsincluding perturbing time, removing edges, and adding edges withperturbed time. However, it is limited to apply on CTDG modelswith memory modules because it needs to incorporate amulti-level memory module to process augmented graphs of vary-ing magnitudes at different levels. Furthermore, It is widely noticedthat the effectiveness structure-oriented GDA methods requires agreat of specific domain knowledge, necessitating the selection ofdiverse augmentation strategy combinations tailored to differentgraph datasets.Feature-oriented methods directly modify or create raw fea-tures. Hou et al. uses Attribute Masking that randomly masknode features, Kong et al. augments node features with gradient-based adversarial perturbations. Its worth noting that structure-oriented and feature-oriented augmentation are also sometimescombined in some GDA methods. For example, You et al. sum-marizes four types of graph augmentations to learn the invariantrepresentation across different augmented view. Wang et al. changes both the node feature and the graph structure for different nodes individually and separately, to coordinate DA for differentnodes. However, most of these methods require original features fornodes or edges. Meanwhile, Most CTDG datasets are attribute-freegraphs. Additionally, there are only a few structure-oriented andfeature-oriented GDA methods that offer rigorous proofs or theoret-ical bounds (e.g., Evidence Lower Bound). Most rely predominantlyon empirical intuition or constraints from contrastive learning toachieve positive augmentation.",
  "Generative Models": "Generative models are powerful tools for learning datadistribution. Recently, researchers have proposed several interest-ing generative models for graph data generation. Variational graphauto-encoder (VGAE) exploits the latent variables to learn in-terpretable representations for undirected graphs. Salha et al. make use of a simple linear model to replace the GCN encoder inVGAE and reduce the complexity of encoding schemes. Xu et al. propose a generative GCN model to learn node representationsfor growing graphs. ConDgen exploits the GCN encoder to han-dle the invariant permutation for conditional structure generation.Besides, diffusion-based generative models are shown to be power-ful in generating high-quality graphs . DiGress ,one of the most advanced graph generative models, employs a dis-crete diffusion process to progressively add discrete noise to graphsby either adding or removing edges and altering node categories.However, these diffusion models rely on continuous Gaussian noiseand do not align well with graph structure. In addition, they arelimited to generating small graphs and can not scale up to largegraphs. Contrary to these approaches mainly focusing on structuregeneration, pretrains a VAE for node feature generation, whichcan serve as a DA method for the downstream backbone models.However, VAE often uses over-simplified prior and decoder, whichsuffers from the trade-off between tractability and representationability.",
  "CONCLUSION": "In this paper, we propose Conda, a novel GDA method designedto integrate seamlessly into any CTDG model. Conda utilizes alatent conditional diffusion model to enhance the embeddings ofnodes historical neighbor sequences during the training phase ofCTDG models. Unlike structure-oriented and feature-oriented GDAmethods, Conda operates within the latent space rather than theinput space, thereby enabling more subtle modeling of transition indynamic graphs. More importantly, Conda employs a conditionaldiffusion model to generate high-quality historical neighbor em-beddings with solid theoretical foundations. Extensive experimentsconducted on various baseline models using real-world datasetsdemonstrate the efficacy of our method Conda. In the future, weaim to extend our method to CTDG with edge deletions.",
  "Kaize Ding, Zhe Xu, Hanghang Tong, and Huan Liu. 2022. Data Augmentationfor Deep Graph Learning: A Survey. SIGKDD Explor. Newsl. 24, 2 (dec 2022),6177": "Wenzheng Feng, Jie Zhang, Yuxiao Dong, Yu Han, Huanbo Luan, Qian Xu, QiangYang, Evgeny Kharlamov, and Jie Tang. 2020. Graph random neural networksfor semi-supervised learning on graphs. In Proceedings of the 34th InternationalConference on Neural Information Processing Systems (Vancouver, BC, Canada)(NIPS20). Curran Associates Inc., Red Hook, NY, USA, Article 1853, 12 pages.",
  "Johannes Gasteiger, Stefan Weienberger, and Stephan Gnnemann. 2019. Diffu-sion improves graph learning. Curran Associates Inc., Red Hook, NY, USA": "Ian J Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. Generative adversarialnetworks. In Advances in Neural Information Processing Systems. Derek Greene, Dnal Doyle, and Pdraig Cunningham. 2010. Tracking theEvolution of Communities in Dynamic Social Networks. In 2010 InternationalConference on Advances in Social Networks Analysis and Mining. 176183.",
  "Rakshit S. Trivedi, Mehrdad Farajtabar, Prasenjeet Biswal, and Hongyuan Zha.2019. DyRep: Learning Representations over Dynamic Graphs. In InternationalConference on Learning Representations": "Vikas Verma, Meng Qu, Kenji Kawaguchi, Alex Lamb, Yoshua Bengio, JuhoKannala, and Jian Tang. 2021. Graphmix: Improved training of gnns for semi-supervised learning. In Proceedings of the AAAI conference on artificial intelligence,Vol. 35. 1002410032. Clement Vignac, Igor Krawczuk, Antoine Siraudin, Bohan Wang, Volkan Cevher,and Pascal Frossard. 2023. DiGress: Discrete Denoising diffusion for graphgeneration. In The Eleventh International Conference on Learning Representations. Lu Wang, Xiaofu Chang, Shuang Li, Yunfei Chu, Hui Li, Wei Zhang, XiaofengHe, Le Song, Jingren Zhou, and Hongxia Yang. 2021. Tcl: Transformer-baseddynamic graph modelling via contrastive learning. arXiv:2105.07944 (2021).",
  "Yiwei Wang, Wei Wang, Yuxuan Liang, Yujun Cai, Juncheng Liu, and Bryan Hooi.2020. NodeAug: Semi-Supervised Node Classification with Data Augmentation.207217": "Da Xu, Chuanwei Ruan, Kamiya Motwani, Evren Korpeoglu, Sushant Kumar,and Kannan Achan. 2019. Generative graph convolutional network for growinggraphs. In International Conference on Acoustics, Speech and Signal Processing. Carl Yang, Peiye Zhuang, Wenhan Shi, Alan Luu, and Pan Li. 2019. ConditionalStructure Generation through Graph Variational Generative Adversarial Nets..In Advances in Neural Information Processing Systems. Yuning You, Tianlong Chen, Yang Shen, and Zhangyang Wang. 2021. Graph Con-trastive Learning Automated. In Proceedings of the 38th International Conferenceon Machine Learning (Proceedings of Machine Learning Research, Vol. 139), MarinaMeila and Tong Zhang (Eds.). PMLR, 1212112132.",
  "Le Yu, Leilei Sun, Bowen Du, and Weifeng Lv. 2023. Towards Better DynamicGraph Learning: New Architecture and Unified Library. arXiv:2303.13047 (2023)": "Han Yue, Chunhui Zhang, Chuxu Zhang, and Hongfu Liu. 2022. Label-invariantAugmentation for Semi-Supervised Graph Classification. In Advances in NeuralInformation Processing Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave,K. Cho, and A. Oh (Eds.), Vol. 35. Curran Associates, Inc., 2935029361. Shilei Zhang, Toyotaro Suzumura, and Li Zhang. 2021. DynGraphTrans: DynamicGraph Embedding via Modified Universal Transformer Networks for FinancialTransaction Data. In 2021 IEEE International Conference on Smart Data Services(SMDS). 184191.",
  "A.2Detail Descriptions of baselines": "JODIE is a RNN-based method. Denote () as the embeddingof node at timestamp , , as the link feature between , at timestamp , and as the timestamp that node latestinteract with other nodes. When an interaction between node , happens at timestamp , JODIE updates the node embeddingusing RNN by () = ( (),(),,, ). Then,the embedding of node at timestamp 0 is computed as (0) =(1 + (0 )) (). TGAT is a self-attention-based method that could capture spa-tial and temporal information simultaneously. TGAT first con-catenates the raw feature with a trainable time encoding(), i.e., () = [||()] and () = ( + ). Then, self-attention is applied to produce node representation (0) =( (0),()| 0 ()), where 0 () denotes the neigh-bors of node at time 0 and denotes the timestamp of the",
  "latest interaction of node . Finally, the prediction on any nodepair at time 0 is computed by ([ (0)||(0)])": "TGN is a mixture of RNN- and self-attention based method. TGNutilizes a memory module to store and update the (memory) state () of node . The state of node is expected to represents history in a compressed format. Given the memory updateras mem, when an link () connecting node is observed,node s state is updated as () = ( ( ),( )||()).where ( ) is the memory state of node just before time. || is the concatenation operator, and node is s neighborconnected by ,(). The implementation of is a recurrentneural network (RNN), and node s embedding is computed byaggregating information from its L-hop temporal neighborhoodusing self-attention. DyRep is an RNN-based method that updates node states uponeach interaction. It also includes a temporal-attentive aggregationmodule to consider the temporally evolving structural informa-tion in dynamic graphs. TCL is a contrastive learning-based method. It first generateseach nodes interaction sequence by performing a breadth-firstsearch algorithm on the temporal dependency interaction sub-graph. Then, it presents a graph transformer that considers bothgraph topology and temporal information to learn node repre-sentations. It also incorporates a cross-attention operation formodeling the inter-dependencies of two interaction nodes. GraphMixer is a simple MLP-based architecture. It uses a fixedtime encoding function that performs rather than the trainableversion and incorporates it into a link encoder based on MLP-Mixer to learn from temporal links. A node encoder with neighbormean-pooing is employed to summarize node features. DyGFormer is a self attetion-based method. Specifically, fornode , DyGFormer just retrieves the features of involved neigh-bors and links based on the given features to represent their en-codings. DyGFormer is equipped with a neighbor co-occurrenceencoding scheme, which encodes the appearing frequencies ofeach neighbor in the sequences of the source node and destina-tion node, and can explicitly explore the correlations betweentwo nodes. Instead of learning at the interaction level, DyG-Former splits each source/destination nodes sequence into mul-tiple patches and then feeds them to the transformer."
}