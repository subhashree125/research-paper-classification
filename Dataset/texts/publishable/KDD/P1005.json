{
  "Abstract": "Traditional regression and prediction tasks often only provide deterministic pointestimates. To estimate the distribution or uncertainty of the response variable,traditional methods either assume that the posterior distribution of samples followsa Gaussian process or require thousands of forward passes for sample generation.We propose a novel approach called DistPred for regression and forecasting tasks,which overcomes the limitations of existing methods while remaining simpleand powerful. Specifically, we transform proper scoring rules that measure thediscrepancy between the predicted distribution and the target distribution into adifferentiable discrete form and use it as a loss function to train the model end-to-end. This allows the model to sample numerous samples in a single forwardpass to estimate the potential distribution of the response variable. We havecompared our method with several existing approaches on multiple datasets andachieved state-of-the-art performance. Additionally, our method significantlyimproves computational efficiency. For example, compared to state-of-the-artmodels, DistPred has a 180x faster inference speed. Experimental results can bereproduced through this Repository.",
  "Introduction": "Traditional deterministic point estimates are no longer sufficient to meet the needs of AI safety anduncertainty quantification. For example, we may want to obtain confidence intervals for predictedpoints to make important decisions, such as deciding whether to travel based on weather forecasts orhow to invest based on stock predictions. Moreover, this is particularly important in high-security AIapplication areas such as autonomous driving, risk estimation, and decision-making. In this paper, we consider the underlying distribution behind predicting the response variable becauseit reflects the confidence intervals at all levels. For example, based on this distribution, we cancalculate confidence intervals, coverage rate, and uncertainty quantification at any level, as shown in. Currently, predicting the distribution of the response variable poses a challenge because at aspecific moment, the response variable can only take on a single deterministic value. This point canbe viewed as a representative sample from its underlying distribution, but it fails to represent theoverall state of the underlying distribution.",
  "% CI": ": DistPred can provide K predicted values y of the response variable y given the predictorvariable x in a single forward process, denoted as E( Y|x), where Y represents a maximum likelihoodsample of y. Based on this sampling, the probability mass function (PMF) P(y|x), cumulativedistribution function (CDF) F(y|x), and confidence curve CC(y|x) for the response variable y canbe computed, thereby yielding comprehensive statistical insights into y. For instance, this includesconfidence intervals (CI) at any desired level, as well as p-values. Currently, several methods are employed to predict the underlying distribution of the response vari-able in regression and forecasting tasks. The most straightforward approach is to assume that theresponse variable follows a prior distribution and represents a specific statistic from that distribution.Specifically, several methods (Bishop, 1994; Greene, 2003; Salinas et al., 2020; He et al., 2020)transform distribution prediction and uncertainty quantification into predicting statistical variablessuch as mean and variance by assuming that the response variable follows a known continuous distri-bution. For instance, mixture density networks (Bishop, 1994) superimpose a specific distribution,typically Gaussian, weighted by designated parameters to fit the prior distribution. Heteroscedasticityregression (Greene, 2003) quantifies uncertainty by modeling the variability of residuals as a functionof independent variables. These methods only predict statistical variables, which reduces the infer-ence cost, but strong assumptions often fail to capture the true data distribution, resulting in inferiorperformance. Conformal prediction offers an alternative approach for distribution prediction (Vovk et al., 2017,2018; Romano et al., 2019; Xu and Xie, 2021, 2023). The authors defined the random predictionsystem in (Vovk et al., 2017, 2018) and proposed a nonparametric prediction distribution method basedon conformal assumptions. The authors integrated conformal prediction with quantile regressionin (Romano et al., 2019; Xu and Xie, 2021, 2023) to construct prediction intervals for the responsevariable by training multiple bootstrap estimators. However, the application of conformal predictionto distribution prediction can be constrained by its reliance on the exchangeability assumptionof residuals and the challenges in managing temporal dependencies (autocorrelation), potentiallyresulting in less reliable prediction intervals in non-i.i.d. data settings. Uncertainty quantification is a method that indirectly reflects the potential distribution of the responsevariable, which can be classified into two primary categories: epistemic uncertainty and aleatoricuncertainty Der Kiureghian and Ditlevsen (2009). Epistemic uncertainty refers to the uncertaintywithin the model itself. In contrast, aleatoric uncertainty pertains to the inherent randomness in theobservations. Quantitative analysis involves generating numerous samples (e.g., using MCMC) byperturbing the explanatory variables or models, thereby approximating the underlying distribution. Forinstance, bayesian neural networks (BNNs) (Blundell et al., 2015; Immer et al., 2021; Daxberger et al.,2021) simulate this uncertainty by assuming that their parameters follow a predefined distribution,thereby capturing the models uncertainty given the data. Similarly, ensemble-based methods havebeen proposed to combine multiple deep models with random outputs to capture prediction uncertainty.MC Dropout (Gal and Ghahramani, 2016) shows that enabling dropout during each testing processyields results akin to model ensembling. Additionally, models based on GANs and diffusion havebeen introduced for conditional density estimation and prediction uncertainty quantification (Zhouet al., 2021b; Liu et al., 2021; Han et al., 2022). These models utilize noise during the generation ordiffusion process to obtain different predicted values for estimating the uncertainty of the responsevariable. The common characteristic of these methods mentioned above is the requirement of K forward passesto sample K representative samples. For example, Bayesian framework-based methods require Klearnable parameter samples to be inferred in order to obtain K representative samples; ensemble methods require K models to jointly infer; MC Dropout requires K forward passes with randomdropout activations; generative models require K forward or diffusion processes. However, theexcessive forward passes result in significant computational overhead and slow speed, a drawbackthat becomes increasingly apparent for AI applications with high real-time requirements. To address this issue, we propose a novel method called DistPred, which is a distribution-freeprobabilistic inference method for regression and forecasting tasks. DistPred is a simple and powerfulmethod that can estimate the distribution of the response variable in a single forward pass. Specifically,we contemplate employing all predictive quantiles to specify the potential cumulative density function(CDF) of the predictor variable, and we show that the full quantiles prediction can be translatedinto calculating the minimum expected score of the response variable and the predictive ensemblevariables. Based on this, we transform proper scoring rules that measure the discrepancy betweenthe predicted distribution and the target distribution into a differentiable discrete form and use it asa loss function to train the model end-to-end. This allows the model to sample numerous samplesin a single forward pass to estimate the potential distribution of the response variable. DistPredis orthogonal to other methods, enabling its combination with alternative approaches to enhanceestimation performance. Further, we show that DistPred can provide comprehensive statisticalinsights into the response variable, including confidence intervals at any desired level, p-values, andother statistical information, as shown in . Experimental results show that DistPred outperformsexisting methods in terms of both accuracy and computational efficiency. Specifically, DistPred has a180x faster inference speed than state-of-the-art models.",
  "Method": "Assume that the dataset D = {xi,yi}Ni=1 consists of N sample-label pairs. The subscript i willbe omitted if it does not cause ambiguity in the context. Our objective is to utilize a machinelearning model M with parameters to predict the underlying distribution P(y|x) from D, aiming toacquire comprehensive statistical insights such as obtaining confidence intervals (CI) and quantifyinguncertainty at any desired level.",
  ". We have only a deterministic target point, without access to its distribution information,which limits our ability to guide the models learning process": "To address the aforementioned issues, we contemplate employing full predictive quantilesq1, q2, , qK at levels 1,2, ,K, (K ), to specify the potential CDF F(y) of the responsevariable y. This is because if we know the cumulative distribution function of a random variable, wecan find any quantile byq = inf{y R : F(y) }.(1)",
  "S( q1, , qK;P) =S( q1, , qK;y)dP(y).(3)": "The function S in Eq. 3 satisfies the scoring rule, which offers a concise measure for assessingprobabilistic forecasts by assigning numerical scores according to the forecast distribution andpredicted outcomes (Gneiting and Raftery, 2007; Jordan et al., 2017). Specifically, let denotethe set of possible values of the quantity of interest, and let P denote a convex class of probabilitydistributions on , the scoring rule is a function",
  "S : P R{}(4)": "that assigns numerical values to pairs of forecasts P P and observations y . We identifyprobabilistic forecasts P with the associated CDF F or PDF f, and consider scoring rules to benegatively oriented, where a lower score signifies a more accurate forecast. A proper scoring rule isoptimized when the forecast aligns with the true distribution of the observation, i.e., if",
  "S(F(y),I{y y})dy(7)": "is proper. Here, we establish a relationship between the full quantiles of the response variable and itsCDF. However, the CDF here is in continuous form and cannot be directly observed. Therefore, weneed to convert it into a discrete form, as the number of quantiles K is always finite in practice. It isworth noting that Eq. 7 corresponds to the continuous ranked probability score (CRPS) in which S isthe quadratic or Brier score, defined as",
  ": DistPreds architec-ture.A model M with pa-rameters takes one inputvariable x and outputs an en-semble of K response variabley1, , yK": "Based on the analysis provided above, it is evident that predictingthe full quantiles is equivalent to minimizing Eq. 9 w.r.t E( Y|y).Hence, as illustrated in the architecture depicted in , we candevelop a model M with parameters that infers an ensemble ofpredictive variables Y = {y1, , yK} in a forward pass and utilizeEq. 10 to train it end-to-end. This allows the model to samplenumerous samples in a single forward pass to estimate the empiricalCDF F by the predictive ensemble variables",
  "Kj=1|yk yj|.(11)": "Its worth noting that Eq. 11 is a differentiable discrete form w.r.tY and Y that strictly satisfies proper scoring rules. However, im-plementations of Eq. 11 exhibit inefficiency due to their storagecomplexity of O(K2). This can be enhanced by using algebraicallyequivalent representations based on the generalized quantile function(Laio and Tamea, 2007) and the sorted predictive ensemble variablesyk,",
  "Kk=1yk(k 1).(13)": "Actually, according to the definition of L-Moments, we can prove that the last term of Eq. 11 can bedecomposed into the 1-th and 0-st order L-moments of Eq. 13, i.e., Eq. 13 is an unbiased estimateof Eq. 11 when it has a finite first L-moment. To conserve memory, we suggest utilizing Eq. 13,which has a storage complexity of O(K), as the loss function, since predicting ensemble variables inlong-term forecasting tasks may lead to out-of-memory issues on GPUs.",
  "Incorporate Alternative Methodologies": "DistPred is orthogonal to other methods, enabling its combination with alternative approaches toenhance estimation performance. Here, with a focus on computational efficiency and memoryconservation, we opt to integrate MC Dropout with DistPred, thereby denoting the amalgamation asDistPred+MCD. In our experiments, we observed that using DistPred+MCD can further enhanceuncertainty quantification performance, albeit with a marginal increase in computational effort.",
  "PICP and QICE Metrics": "The metric utilized in BNNs to assess uncertainty estimates, namely the negative log-likelihood(NLL), is computed based on Gaussian prior. This assumption implies that they consider both theconditional distribution p(y|x = x) for all x are Gaussian. However, this assumption is very difficultto verify for real-world datasets. We follow (Han et al., 2022) and use the following two metrics,both of which are designed to empirically evaluate the degree of similarity between learned and trueconditional distributions:",
  "Nn=1I{yn q/2}I{yn q1/2},(14)": "where q/2 and q1/2 represent the low and high percentiles, respectively, that we have selectedfor the predicted y outputs given the same x input. This metric evaluates the proportion of accurateobservations that lie within the percentile range of the generated y samples corresponding to each xinput. Within this study, we opt for the 2.5th and 97.5th percentiles, signifying that an optimal PICPvalue for the model should ideally reach 95%. However, a caveat of the PICP metric becomes apparent in the measurement of distribution differences.Drawing from this reasoning, Han et al. (2022) introduces a novel empirical metric called QICE. Thismetric can be perceived as an enhanced version of PICP, offering finer granularity and addressing theissue of uncovered quantile ranges. To calculate QICE, the initial step involves generating an adequatenumber of samples for each y value. These samples are then divided into M bins of approximatelyequal sizes. Subsequently, the quantile values are determined at each boundary within these bins. Thedefinition of QICE entails computing the mean absolute error (MAE) between the proportion of truedata encompassed by each quantile interval and the optimal proportion, which is 1/M for all intervals:",
  "Toy Examples": "To demonstrate the effectiveness of DistPred, we initially conducted experiments on 8 toy examplesas done in (Han et al., 2022). These examples are specifically crafted with distinct statisticalcharacteristics in their data generating functions: some have a uni-modal symmetric distribution fortheir error term (linear regression, quadratic regression, sinusoidal regression), while others exhibitheteroscedasticity (log-log linear regression, log-log cubic regression) or multi-modality (inversesinusoidal regression, 8 Gaussians, full circle). The research demonstrates that a trained DistPred model has the capability to produce samples thatclosely resemble the true response variable for novel covariates. Additionally, it can quantitativelymatch the true distribution based on certain summary statistics. The study visualizes scatter plotscomparing real and generated data for all eight tasks in . In cases where the tasks involveunimodal conditional distributions, the interest region fills the region between the 2.5th and 97.5thpercentiles of the generated y values. We note that within every task, the generated samples seamlessly integrate with the authentic testinstances, indicating the potential of DistPred to reconstruct the inherent data generation process.This experiment visually demonstrates that DistPred effectively reconstructs the sample potentialdistribution of the target response variable. This indicates that the advantages of DistPred mentionedearlier can be fully harnessed in distribution prediction.",
  "UCI Regression Tasks": "For experiments conducted on real-world datasets, we utilize the same 10 UCI regression bench-mark datasets (Asuncion and Newman, 2007) and follow the experimental protocol introduced byHernndez-Lobato and Adams (2015), which has also been followed by Gal and Ghahramani (2016)and Lakshminarayanan et al. (2017), as well as by Han et al. (2022). The dataset information can befound in located in Appendix A. We compare DistPred with other state-of-the-art methods, including PBP (Hernndez-Lobato andAdams, 2015), MC Dropout (Gal and Ghahramani, 2016), DeepEnsemble (Lakshminarayanan et al.,2017), and another deep generative model that estimates a conditional distribution sampler, GCDS(Zhou et al., 2021b), as well as the diffusion model, CARD (Han et al., 2022). The multiple train-testsplits are applied with a 90%/10% ratio, following the same methodology as Hernndez-Lobato andAdams (2015) and Han et al. (2022) (20 folds for all datasets except 5 for Protein and 1 for Year). Thereported metrics are presented as the mean and standard deviation across all splits. As pointed out byHan et al. (2022), we compare the QICE of different methods on various UCI datasets. Additionalinformation regarding the experimental setup for these models is available in Appendix A.2. Theexperimental results, along with corresponding metrics, are presented in . The frequency withwhich each model achieves the best corresponding metric is reported in the penultimate row, whilethe frequency with which it achieves the top two positions is reported in the last row. The results demonstrate that DistPred outperforms existing methods, often by a considerable margin.It is worth noting that these impressive results are achieved in a single forward pass of the DistPredmethod. Crucially, as shown in , the performance of uncertain quantization can be furtherenhanced by leveraging DistPred+MCD, a hybrid approach that combines DistPred and MC Dropout.",
  "# Top 1---22285101100010000020": "The implementation of DistPred on UCI regression tasks follows a straightforward approach: Weemploy a basic multilayer perceptron (MLP) as the foundational framework, complemented by Eq. 13serving as the loss function for end-to-end training. Due to the fact that DistPred necessitates solely asingle forward inference, its inference speed is notably rapid. presents a comparison of thetraining and inference speeds of mainstream models. It should be noted that, for a fair comparison,the implementations of various models are constructed on the same backbone and utilize the sameequipment. It is evident that DistPred is approximately achieves at least 180x faster inference speedcompared to state-of-the-art models. The inference speed of DistPred is slower than its training speedbecause it involves calculating distribution statistical metrics like QICE and PICP.",
  "Ablation Study of The Number of Samples and Ensembles": "We investigate the influence of the number of samples generated by DistPred, as well as the numberof ensembles of DistPred+MCD, on their respective performances. In (a), we increase thenumber of samples of DistPred from 10 to 4000 to observe the changes in its QICE. In (b),we increase the number of ensembles of DistPred+MCD from 1 (DistPred) to 1000 to observe thechanges in its QICE. It can be found that with an increase in the number of output samples andensembles, the models performance shows a gradual improvement.",
  "Time Series Distribution Forecasting": "We extend time series forecasting (Zhou et al., 2021a; Wu et al., 2021; Zhou et al., 2022; Liu et al.,2023) from point estimation to the task of distribution prediction to infer about more statisticalinformation about a certain moment. Baselines: We employ recent 10 SOTA methods for comparisons, including iTransformer Liu et al.(2023), PatchTST Nie et al. (2022), SCINet Liu et al. (2022a), TimesNet Wu et al. (2022), DLinearZeng et al. (2023), FEDformer Zhou et al. (2022), Autoformer Wu et al. (2021), Informer Zhou et al.(2021a), LogTrans Li et al. (2019) and Reformer Kitaev et al. (2020). DistPred employs the samenetwork architecture as iTransformer. We use the same experimental setup as (Zhou et al., 2021a)and (Liu et al., 2022a) and follow the same experimental protocol as (Zhou et al., 2021a). Univariateresults can be found in Appendix E. Datasets and Setting: The detailed information pertaining to the datasets can be located in AppendixA. The models Liang et al. (2024) used in the experiments are evaluated over a wide range ofprediction lengths to compare performance on different future horizons: 96, 192, 336, and 720. Theexperimental settings are the same for both multivariate and univariate tasks. We use the average ofthe MSE and MAE ( MSE+MAE",
  "that DistPred provides an ensemble Y of response variable. Consequently, we employ the mean valueof Y as the point estimate at that moment": "Main Results: The results for multivariate TS forecasting are outlined in , with the optimalresults highlighted in bold and the second-best results emphasized with underlined. It can be foundthat, despite not utilizing MSE and MAE, DistPred achieves state-of-the-art performance across alldatasets and prediction length configurations. iTransformer and PatchTST stand out as the latestmodels acknowledged for their exceptional average performance. Compared with them, the proposedDistPred demonstrates an average performance increase of 3.5% and 16.5%, respectively, achieving asubstantial performance improvement. We provide metrics, e.g., CRPS, QICE, PICP, for comparisonby the future research community. Note that for long time series, computing these metrics on theentire testset can be very time-consuming and may lead to out-of-memory issues. Therefore, wepropose calculating these metrics for each batch and then averaging the results.",
  "Comparison with Conformal Prediction": "Since conformal prediction offers an alternative approach for distribution prediction, we compareDistPred with conformal prediction methods on the time series forecasting tasks, including CQR(Romano et al., 2019), EnbPI (Xu and Xie, 2021), SPCI (Xu and Xie, 2023). Since PICP is theprimary metric used by these methods, we adhere to their convention in this work. As shown in, DistPred achieves better performance than conformal prediction methods on all datasets andprediction lengths, with an average PICP improvement of 4.5%. This further underscores the highcompetitiveness of DistPred.",
  "Visualization of The Predictive Distribution": "We conducted thorough statistical analyses, including QQ-plots, histograms, and metrics like KL-divergence, skewness, and kurtosis, to validate the empirical distribution of the predictive responsevariable. KL-divergence, skewness, and kurtosis of the predictive response variable are shown in, and QQ-plots and histograms are shown in . These statistical analyses shows that theempirical distribution exhibits notable characteristics, such as skewness and heavy tails, etc., whichare typical of many real-world datasets. Furthermore, the predictive distribution of DistPred is visualized in . It can be observed thatDistPred provides an ensemble of predictions (only the top 10 are presented in the left subplot).Given all predictive ensemble values, the model can estimate the distribution of the response variable.Consequently, we can calculate confidence intervals at different levels, as shown in the right subplotof .",
  "InputOutput": ": Visualization of the prediction results and the confidence intervals with setting input-96-predict-96 on the Ettm2 dataset. (a) The left subplot shows the ensemble of predictions withK = 100. By utilizing subgraph (a), we can directly obtain the confidence intervals for subgraph (b),e.g, confidence intervals at 99%, 99.5% and 99.9% levels.",
  "Related Work": "In supervised learning contexts, the endeavor to characterize the conditional distribution p(y|x)beyond merely the conditional mean E[y|x] via deep neural networks has been a focal point ofexisting research efforts. These endeavors primarily concentrate on quantifying uncertainty, withseveral approaches having been proposed. In regression and forecasting tasks, predicting the underlying distribution of the response variable ispivotal. Traditional approaches (Bishop, 1994; Greene, 2003; Salinas et al., 2020; He et al., 2020)often rely on the assumption that the response variable conforms to a prior distribution, with the goalof estimating specific statistics derived from this distribution. Commonly, these methods transformthe challenge of distribution prediction and uncertainty quantification into the prediction of statisticalparameters such as the mean and variance, under the presumption of a known continuous distribution.For example, MDNs (Bishop, 1994) impose a predefined distributiontypically Gaussianweightedby certain parameters to approximate the final distribution. Similarly, heteroscedastic regression(Greene, 2003) predicts uncertainty by modeling the variability of residuals as a function of inde-pendent variables. DeepAR (Salinas et al., 2020), another notable approach, assumes a Gaussiandistribution for the response variable, thereby leveraging the GaussianNLLLoss (Nix and Weigend,1994) to directly optimize its mean and variance. While these methods offer computational efficiencyby simplifying predictions to statistical parameters, their reliance on strong distributional assumptionsoften limits their ability to capture the true underlying distribution, potentially leading to suboptimalperformance. Conformal prediction presents an alternative framework for distribution prediction, diverging fromtraditional parametric approaches. In their study, the authors in (Vovk et al., 2017, 2018) introduced arandom prediction system and proposed a nonparametric prediction method grounded in conformalassumptions. By integrating conformal prediction with quantile regression in (Romano et al., 2019; Xuand Xie, 2021, 2023), they developed a method for constructing prediction intervals for the responsevariable. However, the practical application of conformal prediction is not without limitations. Itseffectiveness is often constrained by the assumption of exchangeability of residuals, which maynot hold in all contexts, particularly in the presence of temporal dependencies. This limitation canlead to less reliable prediction intervals when applied to non-independent and identically distributed(non-i.i.d.) data, thereby challenging its robustness in real-world scenarios where data often exhibitcomplex dependencies. Uncertainty quantification is a method that indirectly reflects the potential distribution of the re-sponse variable. BNNs represent one such approach, aiming to capture such uncertainty by positingdistributions over network parameters, thereby encapsulating the models plausibility given theavailable data (Blundell et al., 2015; Hernndez-Lobato and Adams, 2015; Gal and Ghahramani,2016; Kingma et al., 2015; Tomczak et al., 2021). Another avenue is represented by Kendall and Gal(2017), which not only addresses uncertainties in model parameters but also incorporates an additivenoise term into the outputs to encompass uncertainties. In parallel, ensemble-based methodologies(Lakshminarayanan et al., 2017; Liu et al., 2022b) have emerged to address predictive uncertainty.These methods involve amalgamating multiple neural networks with stochastic outputs. Furthermore,the neural processes family (Garnelo et al., 2018b,a; Kim et al., 2019; Gordon et al., 2020) hasintroduced a suite of models tailored to capturing predictive uncertainty in a manner that extendsbeyond the distribution of available data, particularly tailored for few-shot learning. The aforementioned models have predominantly operated under the assumption of a parametric formin p(y|x), typically adopting a Gaussian distribution or a mixture of Gaussians. They optimize networkparameters by minimizing the negative log-likelihood of a Gaussian objective function. In contrast,deep generative models are renowned for their capacity to model implicit distributions without relyingon parametric distributional assumptions. However, only a sparse number of works have ventured intoleveraging this capability to address regression tasks. GAN-based models, as introduced by Zhou et al.(2021b) and Liu et al. (2021), have emerged as one such endeavor, focusing on conditional densityestimation and predictive uncertainty quantification. Additionally, Han et al. (2022) have proposed adiffusion-based model tailored for conditional density estimation. Nevertheless, it is imperative tonote that these models entail protracted training processes and computationally demanding inferenceprocedures.",
  "Conclusion": "In this paper, we propose a novel method named DistPred, which is a distribution-free probabilisticinference approach for regression and forecasting tasks. We transform proper scoring rules that mea-sure the discrepancy between the predicted distribution and the target distribution into a differentiablediscrete form and use it as a loss function to train the model end-to-end. This allows the modelto sample numerous samples in a single forward pass to estimate the potential distribution of theresponse variable. Experimental results demonstrate that DistPred outperforms existing methods,often by a considerable margin. We also extend time series forecasting from point estimation todistribution prediction and achieve state-of-the-art performance on multivariate and univariate timeseries forecasting tasks. In the future, we plan to extend DistPred to other tasks, such as classificationand reinforcement learning.",
  "Christopher M Bishop. Mixture density networks. Technical report, 1994": "Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty inneural network. In Francis Bach and David Blei, editors, Proceedings of the 32nd InternationalConference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages16131622, Lille, France, 0709 Jul 2015. Erik Daxberger, Agustinus Kristiadi, Alexander Immer, Runa Eschenhagen, Matthias Bauer, andPhilipp Hennig. Laplace redux-effortless bayesian deep learning. Advances in Neural InformationProcessing Systems, 34:2008920103, 2021.",
  "Armen Der Kiureghian and Ove Ditlevsen. Aleatory or epistemic? does it matter? Structural safety,31(2):105112, 2009": "Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model uncer-tainty in deep learning. In Maria Florina Balcan and Kilian Q. Weinberger, editors, Proceedings ofThe 33rd International Conference on Machine Learning, volume 48 of Proceedings of MachineLearning Research, pages 10501059, New York, New York, USA, 2022 Jun 2016. Marta Garnelo, Dan Rosenbaum, Chris J. Maddison, Tiago Ramalho, David Saxton, Murray Shana-han, Yee Whye Teh, Danilo J. Rezende, and S. M. Ali Eslami. Conditional neural processes. InProceedings of the 35th International Conference on Machine Learning, 2018a. Marta Garnelo, Jonathan Schwarz, Dan Rosenbaum, Fabio Viola, Danilo J. Rezende, S.M. Ali Eslami,and Yee Whye Teh. Neural processes. In ICML 2018 workshop on Theoretical Foundations andApplications of Deep Generative Models, 2018b.",
  "Francesco Laio and Stefania Tamea. Verification tools for probabilistic forecasts of continuoushydrological variables. Hydrology and Earth System Sciences, 11(4):12671277, 2007": "Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictiveuncertainty estimation using deep ensembles. Advances in neural information processing systems,30, 2017. Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang Wang, and XifengYan. Enhancing the locality and breaking the memory bottleneck of transformer on time seriesforecasting. In Advances in 33rd Neural Information Processing Systems (NeurIPS), volume 32,pages 52435253, Vancouver, Canada, 2019. Daojun Liang, Haixia Zhang, Dongfeng Yuan, Bingzheng Zhang, and Minggao Zhang. Minus-former: Improving time series forecasting by progressively learning residuals. arXiv preprintarXiv:2402.02332, 2024. Minhao Liu, Ailing Zeng, Muxi Chen, Zhijian Xu, Qiuxia Lai, Lingna Ma, and Qiang Xu. Scinet:Time series modeling and forecasting with sample convolution and interaction. In Advances inNeural Information Processing Systems, pages 58165828, 2022a.",
  "Shiao Liu, Xingyu Zhou, Yuling Jiao, and Jian Huang. Wasserstein generative learning of conditionaldistribution. arXiv preprint arXiv:2112.10039, 2021": "Shiwei Liu, Tianlong Chen, Zahra Atashgahi, Xiaohan Chen, Ghada Sokar, Elena Mocanu, MykolaPechenizkiy, Zhangyang Wang, and Decebal Constantin Mocanu. Deep ensembling with nooverhead for either training or testing: The all-round blessings of dynamic sparsity. In Proceedingsof the 10th International Conference on Learning Representations, 2022b. Yong Liu, Tengge Hu, Haoran Zhang, Haixu Wu, Shiyu Wang, Lintao Ma, and Mingsheng Long.itransformer: Inverted transformers are effective for time series forecasting. arXiv preprintarXiv:2310.06625, 2023. Yuqi Nie, Nam H Nguyen, Phanwadee Sinthong, and Jayant Kalagnanam. A time series is worth 64words: Long-term forecasting with transformers. In The Eleventh International Conference onLearning Representations, 2022. D.A. Nix and A.S. Weigend. Estimating the mean and variance of the target probability distribution.In Proceedings of 1994 IEEE International Conference on Neural Networks (ICNN94), volume 1,pages 5560 vol.1, 1994. doi: 10.1109/ICNN.1994.374138.",
  "Mark J Schervish, Joseph B Kadane, and Teddy Seidenfeld. Characterization of proper and strictlyproper scoring rules for quantiles. Preprint, Carnegie Mellon University, March, 18, 2012": "Marcin B. Tomczak, Siddharth Swaroop, Andrew Y. K. Foong, and Richard E. Turner. Collapsedvariational bounds for Bayesian neural networks. In Proceedings of the 35th Conference on NeuralInformation Processing Systems, 2021. Vladimir Vovk, Jieli Shen, Valery Manokhin, and Min-ge Xie. Nonparametric predictive distributionsbased on conformal prediction. In Conformal and probabilistic prediction and applications, pages82102. PMLR, 2017.",
  "Vladimir Vovk, Ilia Nouretdinov, Valery Manokhin, and Alexander Gammerman. Cross-conformalpredictive distributions. In conformal and probabilistic prediction and applications, pages 3751.PMLR, 2018": "Haixu Wu, Jiehui Xu, Jianmin Wang, and Mingsheng Long. Autoformer: Decomposition transform-ers with auto-correlation for long-term series forecasting. In Advances in Neural InformationProcessing Systems (NeurIPS), volume 34, pages 2241922430, Virtual Conference, 2021. Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, and Mingsheng Long. Timesnet:Temporal 2d-variation modeling for general time series analysis. In The Eleventh InternationalConference on Learning Representations, 2022.",
  "Jiayu Yao, Weiwei Pan, Soumya Ghosh, and Finale Doshi-Velez. Quality of uncertainty quantificationfor bayesian neural network inference. arXiv preprint arXiv:1906.09686, 2019": "Ailing Zeng, Muxi Chen, Lei Zhang, and Qiang Xu. Are transformers effective for time seriesforecasting? In Proceedings of the AAAI conference on artificial intelligence, volume 37, pages1112111128, 2023. Haoyi Zhou, Shanghang Zhang, Jieqi Peng, Shuai Zhang, Jianxin Li, Hui Xiong, and Wancai Zhang.Informer: Beyond efficient transformer for long sequence time-series forecasting. In Proceedingsof the 35th AAAI Conference on Artificial Intelligence (AAAI), volume 35, pages 1110611115,Virtual Conference, 2021a. Tian Zhou, Ziqing Ma, Qingsong Wen, Xue Wang, Liang Sun, and Rong Jin. FEDformer: Fre-quency enhanced decomposed transformer for long-term series forecasting. In Proceedings of the39th International Conference on Machine Learning (ICML), volume 162, pages 2726827286,Baltimore, Maryland, 2022.",
  "A.1Commonly Used TS Datasets": "The information of the experiment datasets used in this paper are summarized as follows: (1)Electricity Transformer Temperature (ETT) dataset Zhou et al. (2021a), which contains the datacollected from two electricity transformers in two separated counties in China, including the loadand the oil temperature recorded every 15 minutes (ETTm) or 1 hour (ETTh) between July 2016 andJuly 2018. (2) Electricity (ECL) dataset 1 collects the hourly electricity consumption of 321 clients(each column) from 2012 to 2014. (3) Exchange Lai et al. (2018) records the current exchange of 8different countries from 1990 to 2016. (4) Traffic dataset 2 records the occupation rate of freewaysystem across State of California measured by 861 sensors. (5) Weather dataset 3 records every 10minutes for 21 meteorological indicators in Germany throughout 2020. (6) Solar-Energy Lai et al.(2018) documents the solar power generation of 137 photovoltaic (PV) facilities in the year 2006,with data collected at 10-minute intervals. (7) The PEMS dataset Liu et al. (2022a) comprises publiclyavailable traffic network data from California, collected within 5-minute intervals and encompassing358 attributes. (8) Illness (ILI) dataset 4 describes the influenza-like illness patients in the UnitedStates between 2002 and 2021, which records the ratio of patients seen with illness and the totalnumber of the patients. The detailed statistics information of the datasets is shown in , and thedataset information in terms of their size and number of features is summarized in .",
  "A.2Implementation Details": "The model undergoes training utilizing the ADAM optimizer Kingma and Ba (2015) and minimizingthe Mean Squared Error (MSE) loss function. The training process is halted prematurely, typicallywithin 10 epochs. The DistPred architecture solely comprises the embedding layer and backbonearchitecture, devoid of any additional introduced hyperparameters. During model validation, twoevaluation metrics are employed: CRPS, QICE, PICP, MSE and MAE. Given the potential competitiverelationship between the two indicators, MSE and MAE, we use the average of the two ( MSE+MAE",
  "CDistribution Free v.s. Distribution Related": "If we assume that the response variable follows a continuous distribution, as done in (Salinas et al.,2020) where y is assumed to be followed Gaussian distribution, we can provide an analytical formulafor the Gaussian likelihood. Specifically, if y N (,), then we can parametrize the Gaussianlikelihood using its mean and standard deviation,",
  "DDistPred for Time Series with Missing Values": "The proposed DistPred is equipped to handle time series with missing values scenarios, as bothimputation and forecasting are done in a similar manner. Our experiments have demonstrated thatDistPred remains SOTA even when a substantial portion of the data is missing. Specifically, in caseswhere 80% of the PhysioNet2012 data points were absent, the model still maintained competitiveperformance, as shown in ."
}