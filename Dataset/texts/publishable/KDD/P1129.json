{
  "ABSTRACT": "Federated Learning (FL) enables model development by leveragingdata distributed across numerous edge devices without transferringlocal data to a central server. However, existing FL methods still facechallenges when dealing with scarce and label-skewed data acrossdevices, resulting in local model overfitting and drift, consequentlyhindering the performance of the global model. In response to thesechallenges, we propose a pioneering framework called FLea, incor-porating the following key components: i) A global feature bufferthat stores activation-target pairs shared from multiple clients tosupport local training. This design mitigates local model drift causedby the absence of certain classes; ii) A feature augmentation ap-proach based on local and global activation mix-ups for local train-ing. This strategy enlarges the training samples, thereby reducingthe risk of local overfitting; iii) An obfuscation method to minimizethe correlation between intermediate activations and the sourcedata, enhancing the privacy of shared features. To verify the superi-ority of FLea, we conduct extensive experiments using a wide rangeof data modalities, simulating different levels of local data scarcityand label skew. The results demonstrate that FLea consistently out-performs state-of-the-art FL counterparts (among 13 of the experi-mented 18 settings, the improvement is over 5%) while concurrentlymitigating the privacy vulnerabilities associated with shared fea-tures. Code is available at",
  "Federated learning, data scarcity, label skew, data privacy": "ACM Reference Format:Tong Xia, Abhirup Ghosh, Xinchi Qiu, and Cecilia Mascolo. 2024. FLea:Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature Augmentation. In Proceedings of the 30th ACM SIGKDD Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08",
  "INTRODUCTION": "Presently, there are billions of interconnected edge devices, includ-ing smartphones, tablets, and wearables, generating a continuousstream of data such as photos, videos, and audio . Such datapresents numerous opportunities for meaningful research and ap-plications. However, the conventional approach of aggregating thisdata in a central server is no longer sustainable, as the data canbe sensitive to share and the communication cost associated withtransferring such vast amounts of information can be prohibitive.Thanks to the advent of Federated Learning (FL), developing modelswith data remaining at edge devices becomes feasible .As illustrated in , in FL, edge devices, usually referredto as clients, train local models using their local data. These trainedmodels are then transmitted to the FL server and aggregated into aglobal model for real-world applications . However, the char-acteristics of the data across edge devices can present significantchallenges to FL, mainly because of:i) Data heterogeneity, specifically label-skewness. As shown in, edge devices may only possess a subset of the globalcategories in their acquired datasets. For example, in terms of im-ages, one mobile user may take photos of cats and indoor decora-tions, while another user may have images of dogs and outdoorviews. Such label-skewness can result in local model drift: localmodels are biased toward the local distribution and struggle togeneralize to the global distribution, leading to a sub-optimal globalmodel .ii) Local data scarcity. Datasets collected by edge devices are alsolimited in size, primarily due to limited data acquisition scenariosand the difficulty in annotations. As shown in , local datacould be much smaller than the desired data to optimize the localmodels. In the prominent FL strategy FedAvg , lower aggrega-tion weights are assigned to local models trained on smaller datasets,indicating their relatively weaker performance and lesser contribu-tion to the global model. However, in a situation where all clientspossess small-sized datasets, local models can be overfitted to thetraining samples and thus struggle to generalize to unseen testingdata, even if from the same distribution. Consequently, aggregatingthese models does not improve the global models generalizationability. This, as a result, slows down convergence and negatively",
  ": Edge devices as clients in federated learning, wherelocal data exhibits label skew (presented by different mark-ers) and scarcity (usually very small in size)": "impacts the performance of the global model (a detailed analysis ofthe effect of data scarcity is presented in Sec. 2.3).To fully harness the potential of FL for real-world edge applica-tions, addressing the two challenges mentioned above is pivotal.Despite numerous proposed approaches aimed at enhancing FL inthe presence of label skew, we find that the feasibility of these meth-ods, when confronted with data scarcity, remains an under-exploredarea. Methods that involve devising new learning objectives or aggregation strategies falter when local data is extremelyscarce, as they struggle to find a balance between local optimiza-tion and preserving global knowledge. On the other hand, certainapproaches leverage globally shareable information , such as aproportion of raw data, which may be effective when the data acrossedge devices are scarce and label-skewed. However, these strategiesoften come at the cost of sacrificing privacy. In light of this, werevisit the purpose of information sharing and pose a fundamentalquestion: Can we generate and share some privacy-preservinginformation as a robust proxy for global data distribution toaid local learning? This, in turn, could alleviate issues of localoverfitting and model drift caused by simultaneous challenges ofdata scarcity and label skew.The shared information, referred to as features in this study,should satisfy the following critical criteria: (1) To alleviate localdrift caused by label skew, it should cover all categories. (2) Toprevent local overfitting due to data scarcity, it needs to be usefulin extending the local training data. (3) To mitigate privacy risks, itrequires to contain minimal information from the raw data. Withthese considerations in mind, we introduce a novel method FLea (FLwith feature sharing). In FLea, the shared features are activationsfrom an intermediate layer of the model and the associated labels.Specifically, we maintain a global feature buffer that includes fea-tures from multiple clients, ensuring coverage of all categories. Theshared features are integrated with local data through a mix-up aug-mentation to extend the training samples in the representationspace. Moreover, these activations undergo a level of obfuscationby reducing their distance correlation with the source data ,while maintaining their classification characteristics through a cus-tomized loss function during training.Overall, this paper has the following contributions: The first in-depth study on a common but under-exploredscenario in FL, where all the clients possess extremely scarceand label-skewed data. We find that model overfitting causedby data scarcity is under-looked by existing methods. A novel framework FLea to address both the data scarcity andlabel skew challenges at the same time in FL. The key idea ofFLea is to share privacy-preserving features to augment localdata for model training. Extensive experiments with different levels of label skew anddata scarcity show that FLea consistently outperforms thestate-of-the-art baselines. We also empirically demonstratethat FLea mitigates privacy risk measured by informationleakage from the shared features.",
  "BACKGROUND2.1Fundamentals of FL": "This study focuses on learning a global model from a set of col-laborating clients, , with each client containing a small andlabel-skewed local dataset D. The FL system works in synchro-nous rounds. At the start of each round , the FL server broadcaststhe current global model parameters ( ) to the randomly selectedsubset of the clients K ( ) . Each client K ( ) takes a fewoptimization steps (e.g., using stochastic gradient descend) startingfrom ( ), resulting in an updated local model ( ). The local opti-mization aims to minimize the loss function L on local data D, i.e., = arg min L(, D | ( )) (L is the learning objective which isusually a cross-entropy loss for classification). Each round endswith model aggregation to derive the new global model (+1). Themost basic and popular aggregation method, FedAvg averagesthe model parameters weighted by the fraction of local data size inthe clients,",
  "Addressing label skew in FL": "To mitigate the client drift caused by label skew, many methodshave been proposed to improve the learning objective L. In addi-tion to classification loss, FedProx also regulates the discrep-ancy between the local and global model parameters. MOON leverages constructive learning to maximize the distance betweenlow-dimensional features and other classes, thereby improving fea-ture learning. To compensate for missing categories in the localdata, FedDecorr introduces regularization of the dimensionalcollapse in FL models, while FedNTD penalizes changes in thenon-ground-truth class logit distribution predicted by global andlocal models. FedLC directly re-scales the logits to derive acalibrated loss. Similarly, FedRS restricts the Softmax to limit theupdate of missing classes.Data augmentations have been explored for label skewed FL. shows that sharing a small proportion of local data globally,alongside the model parameters, can significantly enhance FedAvg(in later sections, we name this method FedData). Nevertheless,collecting private data would compromise the privacy-preservationbenefits of FL. Therefore, other global proxies that are less privacy-sensitive than raw data are explored. FedMix and FedBR average data over mini-batches and share this aggregated data glob-ally, while CCVR shares low-dimensional features with theserver to calibrate the global model on the server side. These low-dimensional features are also known as class prototypes, which areexplored to mitigate local classifier bias . FedGen , VHL ,",
  "Data scarcity in FL": "Through the literature review, we have found few studies focusingon the data scarcity problem in FL. As first observed by (cf.Finding 7), when developing the model with a fixed total number oftraining samples, the accuracy of FedAvg and FedProx decreases asthe number of clients increases, leading to a reduction in local datasize per client. Despite the proliferation of FL methods, includingthose mentioned earlier (cf. Sec. 2.2), most are evaluated on largelocal datasets, each containing thousands of samples. For example,the commonly used benchmark CIFAR10 contains 50, 000 trainingsamples, which are usually distributed among 10 to 100 clients,resulting in an average local data size of 500 to 5, 000 . Incontrast, in a scarce setting, the average local data size could beeven much smaller, such as 50 100. This leaves the effectivenessof existing FL methods in handling data scarcity unclear. Whilesome studies have presented results in a scarce setting , theyfail to justify whether the performance gain is from alleviating biasor overfitting caused by data scarcity, thus lacking in providing adeep understanding.FedScale introduced the first benchmark featuring thousands ofclients with limited training data . However, FedScale primarilyfocuses on system efficiency and offers limited insight into algo-rithm effectiveness. On the contrary, in the following, we conductan empirical study and provide insightful observations on how datascarcity can affect the performance of FL. 2.3.1Performance decline caused by data scarcity. To directly ob-serve how data scarcity affects FL, we conducted experimentscomparing several state-of-the-art FL algorithms at different datascarcity levels. Specifically, we compared FedAvg with the best loss-based methods FedDecorr and FedNTD, as well as the best dataaugmentation-based methods FedMix and FedData. To avoid beingaffected by label skew, we split the data in an IID (Independentand Identically Distributed) manner. We distributed the trainingset of CIFAR10 to 10, 100, and 500 clients, leading to a local datasize |D | of 5000 (not scarce), 500 (mildly scarce), and 100 (scarce),respectively, ensuring a uniform representation of all 10 classes.More experimental details are presented in Appendix A.The results are summarized in , from which we drawthe following observations: 1)FedAvg degrades remarkably asdata scarcity becomes more severe: Its accuracy, which starts",
  ": T-SNE for low-dimension features where the colordistinguishes classes and the class separation measurementDB under different numbers of training samples": ": Data augmentations. From (a) to (c), the privacyvulnerability is reduced. (b) is the average of a batch of sam-ples like (a), but if the local data contains individual contextinformation (e.g., (a*)), averaging over those samples cannotprotect such information (e.g., (b*)). (c) shows a feature of (a*)and (c*) shows its reconstruction.at 75% in (a) with sufficient data, decreases to 56% in (b) when|D | is reduced to 500, and further drops to 37% in (c) when |D |is reduced to 100. 2) The compared loss-based methods alsodecline as the data become scarce: From (a) to (c), althoughFedDeccor and FedNTD outperform FedAvg, the gain is marginal,and all their accuracy drops significantly. 3) The compared dataaugmentation-based methods outperform other methods:With internal data exchange, FedMix and FedData effectively im-prove local models, leading to remarkable performance gains overFedAvg. When data scarcity is significant (|D | = 100), they notablyoutperform loss-based FL methods, as shown in (c). 2.3.2Understanding the effect of data scarcity. From the above ob-servation, we hypothesize that data scarcity can lead to localmodel overfitting, and aggregating such models cannot continu-ally improve the global model. In light of this, the data augmentation-based methods can prevent the performance decline as more train-ing samples are available to alleviate the local overfitting. To verifythis, we carried out controlled experiments on CIFAR10 to ana-lyze the model update in one communication round with differentamounts of training samples.Specifically, we examined a communication round where localtraining begins with a global model possessing an accuracy of 40%.Following the IID setting outlined in Sec. 2.3.1, we compare theperformance of local models trained with |D | = 5000 and |D | =100| samples. To assess the models, we scrutinized the quality oflearned activations across different classes. For visualization, weadopted a commonly used tool that maps activations from thepenultimate layer of the model into a two-dimensional space .Quantitatively, we employed the clustering score, specifically theDavies-Bouldin Score (DB), to measure the separation of activationsamong classes. A detailed formulation can be found in Appendix A.",
  "KDD 24, August 2529, 2024, Barcelona, SpainTong Xia et al": "As illustrated in (left), a smaller DB indicates less overlapamong activations. The DBs before and after local training aresummarized in the bar chart presented in .For local models, after training, the DB was reduced from 4.8to 3.1 when |D | = 5000 and to 0.8 when |D | = 100 on thetraining set. However, a notable gap between DB values on thetraining set and testing set can be observed, suggesting theoccurrence of overfitting. As the number of samples decreases(|D | = 100), the gap widens, indicating severe overfitting. Con-sequently, after aggregation, the performance of the global modelvaries, and training with only |D | = 100 fails to enhance the globalmodel, as evidenced by an increased DB. These results uncover thenegative impact of data scarcity on the generalization of local mod-els, resulting in overlapped features and ultimately leading to anunder-performing global model.Furthermore, in the fourth group (|D | = 100 + 1000) wherelocal data contain 100 samples but a globally shared set with 1000samples is also used for training, a smaller gap between the trainingand testing sets is observed. This indicates that with more shareddata to aid local training, the generalization of the local model im-proves. Consequently, the global models performance is enhanced,as evidenced by a decreased DB. This observation supports thefeasibility of data augmentation-based methods for addressing datascarcity in FL.",
  "Privacy-preserving feature sharing": "The above analysis highlights the challenge of overfitting causedby data scarcity, and further suggests that globally sharing certaininformation can help mitigate this problem. In Sec. 2.2, severaldata augmentation-based FL methods are introduced; however,it is crucial to note that these methods may introduce privacyvulnerabilities.As illustrated in , FedData globally shares raw data andlabels, while FedMix shares aggregated data and labels globally.Although the averaging of samples in FedMix hinders data recon-struction, it remains privacy-vulnerable, as it releases contextualinformation. To illustrate, consider a scenario where a clients phonecamera has a sensor problem, resulting in a spot in each photo (see(a*)). Alternatively, imagine a client residing in a bustlingneighborhood, leading to a constant background score in all audioclips. Averaging over a batch of samples fails to protect such spe-cific context information, as depicted in (b*). Unlike theseexisting works, to improve the trade-offs between performanceand privacy protection, we propose to share the activations fromthe intermediary layers (see (c))). To enhance the privacymeasured by the information leakage from those activations, weemploy an obfuscation approach to reduce the distance correlationbetween activations and the source data. One example of data re-constructed from the activation of is shown in (c*), wheresensitivity information like color and context are not recovered.",
  ": Overview of FLea for -th communication round": "to address the challenges of data scarcity and label skew whileminimizing privacy risks associated with shared information.At an abstract level, FLea maintains a feature buffer containingactivation-target pairs from multiple clients. This shared buffer en-ables clients to have more training samples covering all classes forlocal training. To safeguard the privacy of shared features, we obfus-cate activations by minimizing the correlation between activationsand the source data when extracting these activations.Examining the training process, FLea operates iteratively, akinto FedAvg. Initially, the global model is randomly initialized, andthe buffer is empty. Then, for each round , as illustrated in ,FLea starts with synchronizing the global model parameters ( ) and feature buffer F ( ) to the selected clients K ( ). Once localtraining using D and F ( ) completes (the first round only usesD since the feature buffer is empty), those clients send the updatedmodel parameters to the server, to be aggregated into a newglobal model parameterized by (+1). Followed by that, FLea needsanother step to update the global feature buffer to F (+1). A detailedtraining procedure is summarized in Algorithm 1. We elaborate onthe main components of the procedure in the following sections.",
  "Formulation of feature buffer": "The shared feature buffer contains activation-target pairs frommultiple clients. An activation is the intermediate-layer output ofa model. Lets consider the model parameters to be divided intotwo parts at layer : [: ] and [ :]. For client , the activationextracted from data D is [: ]() = F . The feature bufferfrom this client is the set of pairs including activations and theirlabels, termed as ( F ,F ). Each client randomly selects a fractionof its local data to create its feature buffer to share with others. Theserver gathers those local feature buffers and merges them intothe global one F . Although data from a single client is skewed,aggregating features from multiple clients can cover many classesand thus alleviate the label-skew problem. Note that a client onlyextracts and contributes to the global feature buffer at the roundwhen it participates in training and the global buffer resets at everyround. This reduces the exposure and mitigates the privacy risk.",
  "FLea: Addressing Data Scarcity and Label Skew in Federated Learning via Privacy-preserving Feature AugmentationKDD 24, August 2529, 2024, Barcelona, Spain": "accuracy of the global model. We show the data splits for the first100 clients when || = 5000 in (a).Audio data: We also test FLea using UrbanSound8K dataset .This dataset contains 8, 732 labeled sound excerpts ( 4) of urbansounds from 10 classes: air conditioner, car horn, children playing,dog bark, drilling, engine idling, gunshot, jackhammer, siren, andstreet music. For experiments, we randomly hold out 20% (about1700 samples) for testing and distribute the rest (about 7000 samples)to clients for training. We split the data into || = 70 and || =140 folds, leading to an average local data size of the order of 100and 50, respectively. The distribution for | = 140|, Dir(0.5) ispresented in (c).Sensory data: Sensory data is another modality we experimentwith for its popularity, which can collected by wearable and mobiledevices. UCI-HAR is a commonly used human activity recogni-tion benchmark. It was collected by a waist-mounted smartphonewith an embedded accelerometer. Six activities including walking,walking upstairs, walking downstairs, sitting, standing, and lyingwere recorded. We employ HARNet which comprises 4 convolu-tional layers to recognize those activitie . We split the data intotraining and testing sets, then distributed the training set to 75 and150 clients to simulate different levels of scarcity, respectively. Weshow the data splits for 150 clients when|D | = 50 in (a).To better illustrate the data scarcity problem, we visualize thedistribution for the local data size in . As shown, when wedistribute the training set of CIAFR10 (50, 000 samples) to 10 clientsusing a Dirichlet distribution parameterized by 0.1, these clientswill present different class distributions, and the total number oflocal samples ranges from 2853 to 8199. This is the commonlyexplored non-IID setting. In this paper, we further explore scarcenon-IID data, and thus we split the data into 100 and 500 clients.As a result, the number of samples per client reduces significantly:the median number drops from 5685 to 90 when the number ofclients increases from 10 to 500, as shown in (a). Thisis the realistic scenario that we are interested in. It is also worthmentioning that data scarcity is independent of label skew andit can happen in the IID scenario. As shown in (b), thelocal data covers 10 classes uniformly, but the data scarcity problembecomes severe when the number of clients increases.",
  "probability is [] = ( []) ( []) . Mitigating this loss encourages": "the local model to make similar predictions to the global model.Besides, we aim to reduce the information leakage of the featuresbefore they are shared with other clients. As such, we learn thefirst layers while reducing the distance correlation between theactivations and the source data. Thus, the third term is formulated",
  "|B|2|B|, . is the Euclidean distance matrix for": "B, i.e., = || ||2. Similarly, = || ||2.They are then double-centered to and , by making their rowand columns sum zeros (cf. Eq. (10) and Eq. (11) in Appendix B)).After normalization, the distance correlation = L has thefollowing properties: (1) satisfies the relation 0 1, and asmaller suggests less mutual information between and ; (2) = 1 when is a linear transformation from . In our case,the model contains non-linear layers and thus < 1; (3) = 0when and are independent. In other words, = 0 if becomesrandom noise and this produces perfect privacy but is useless forclassification. Overall, we aim to reduce to project feature privacy.Our optimization function therefore is,",
  "Model aggregation and buffer updating": "Once the local training completes, the updated model parameterswill be sent to the server for aggregation (lines 13 in Algorithm 1).FLea utilizes the same aggregation strategy as FedAvg (Eq.(1)). Thenew model will be synchronized to the clients, and the featureswill be extracted and sent to the server to replace the old ones,updating the feature buffer to F ( + 1) (lines 14-18 in Algorithm 1).The iterations continue (restart from line 2) until the global modelconverges.",
  "Experimental setup": "4.1.1Datasets. We evaluate FLea on three data modalities. Im-ages: CIFAR10 is a commonly used FL benchmark contain-ing 10 classes of objectives. To classify those images, we use Mo-bileNet_V2 with 18 blocks consisting of multiple convolutionaland pooling layers. Audio: UrbanSound8K is an audio classifi-cation bookmark also containing 10 categories of sounds collectedin urban environments. Those audio samples are first transformedinto spectrograms and fed into a 4-layer CNN model called AudioNetfor classification . Sensory data: UCI-HAR is a public hu-man activity recognition database collected by a waist-mountedsmartphone with an embedded accelerometer. Six activities includ-ing walking, walking upstairs, walking downstairs, sitting, standing,and lying were recorded. We employ HARNet which comprises 4convolutional layers to recognize those activitie . A summar-ily of those datasets can be found in Appendix C , and thedetails of the models are presented in Appendix C.2. 4.1.2FL setup and baselines. To simulate label skew, we considerquantity-based skew (Qua() with being the number of presentedclasses) and distribution-based skew (Dir() with controlling theclass skewness) . To mimic different levels of data scarcity, wedistribute the training data to || clients, where || is determinedby the average local data size|D |, which is set to as small as 100and 50 for experiments. A visualization of the data distribution canbe found in Appendix C.1.We compare FLea against FedAvg, and then loss-based methods:) FedProx , ) FedDecorr , ) FedLC , and ) Fed-NTD , as well as data augmentation-based methods: ) FedBR ,) CCVR , ) FedGen , and ) FedMix . We also reportthe results of FedData for reference but it is not consideredas a baseline since raw data are exposed. All baselines are hyper-parameter optimized to report their best performances. The specificsetting can be found in Appendix C.3.",
  ": Comparison between FedMix and FLea usingUrbanSound8K with (3),|D | = 100": "For all methods, we use the Adam optimizer for local trainingwith an initial learning rate of 103 and decay it by 2% per com-munication round until 105. The size of the local batch is 32 andthe number of local epochs is set to 5. 10% of clients are randomlysampled at each round. We run 100 communications and reportthe best accuracy as the final result. For all settings, we report themean and standard deviation of the accuracy from five runs withdifferent random seeds. For FLea, without particular mention, weuse (2, 2) for Eq. (2), and 1 = 1, 2 = 3 for the loss inEq. (6), and extract the activations after several conventional layersof the model (as specified in Appendix C.2). We only share featuresfrom = 10% of the local data.",
  "Performance comparison (RQ1)": "The overall accuracy achieved by FLea and baselines are comparedin . Across various model architectures (x3) and differentlevels of local data skewness (x3) and scarcity (x2), FLea constantlyoutperforms the state-of-the-art baselines and significantly reducesthe gap compared to FedData which shares the raw data. In 13 outof the studied 18 scenarios, FLea presents an improvement of over5%, and among those, in 5 cases, the improvement is more than10%. These demonstrate the superiority and generality of FLea inaddressing the challenges caused by label skew and data scarcity.It can also be observed that the data-augmentation-based base-lines, particularly FedMix, outperform the loss-based baselines inmost cases, which again supports FLeas use of some global in-formation to aid local training in the presence of data scarcity. InFedMix, sample aggregations are shared to protect data privacy, yetthis inevitably harms the utility of the shared augmentations forthe training of classification models. On the contrary, FLea sharesthe intermediate layer activations, which are obfuscated to protectprivacy while retaining useful information for classification. Thisexplains why FLea can consistently outperform FedMix. FLea is alsomore efficient than FedMix. As illustrated in , FLea learnsfaster than FedMix after the first 5 rounds (cf. the left figure) andrequires a smaller proportion of augmentations to be shared toachieve the same accuracy as FedMix (cf. the right figure).",
  "Effects of key design choices (RQ2)": "4.3.1The role of augmentation. The feature buffer is a key compo-nent in FLea, designed to compensate for the missing classes in thelocal dataset. displays an example of the class distributionfor the global feature buffer F ( ) and the local data D at round .F ( ) contains features from all six classes, while D only has datafrom two classes. As introduced in Sec.3.3.1, a batch of features issampled from F ( ) and D, respectively. These features are thenmixed up to create the augmented input B, as shown in the redbar plots in : they also contain all six classes. This explainshow the feature buffer and mix-up augmentation help address thelocal label skew.",
  "FLea41.981.2642.011.1337.691.6554.350.8055.680.8745.051.3274.250.4473.980.4666.57 0.45": "Since we dynamically sample the weight for the mix-up aug-mentation, we can generate infinite combinations of global featuresand local features. An example of for one batch is given in Fig-ure 8, and the corresponding class distribution for the augmentedbatch in different epochs are shown in . It is worth notingthat the two red bar plots in are different, although they aregenerated using the same global and local features. Such diversity inthe training data can significantly enhance the generalization of thelocal model, ultimately alleviating local overfitting as introducedin Sec. 2.3.2 and improving the global model. 4.3.2Impact of hyper-parameters. We now analyze how the hyper-parameters including the weight in Eq. (2) and weights in theloss Eq. (6) affect the performance of FLea. We use UrbanSound8Kunder the setting of (3) and|D | = 100 as an example for adetailed analysis. We first look at the impact of . In , wevisualize the density function for (,) in the left, and themodel performance with varying hyper-parameter controllingthe shape of the distribution in the right. From the results, we canobserve that training with augmentation regardless of the viable of outperforms training without mix-up (FedAvg), while a choice of ranging from 1.5 to 5 yields the best performance. Thus we set = 2 in our experiments.Regarding the weights in the loss function, we first set 2 = 0(without obfuscating the features) and search the value for 1. Asshown in (the left one), we found that 1 > 1 can improvethe performance compared to that without the distilling loss (1 =0), but if the weight is too large (1 > 4) it harms the performance.The pattern is similar with other 2, and thus we informally use1 = 1 for all experiments. With 1 = 1, we further study how 2impacts the trade-off between privacy preservation (reflected by",
  ": Value of for one batch (batch size = 32)": "the reduced correlation) and the feature utility (reflected by themodel accuracy), as shown in (the right one). Enlarging2 can significantly enhance privacy protection (referring to theincreasing 1 ) but decreases the final performance. We finallyuse 2 = 3 when the reduces to about 0.72 while maintaining astrong accuracy of about 57%. We also suggest future applicationsusing 2 6 for the trade-off.",
  ": Impact of 1 and 2. denotes the expectation ofthe distance correlation between activations and source data": "in Sec. 2.4. We use CIFAR10 ((3), | D = 100|) as the exam-ple to demonstrate that FLea is more privacy-preserving than itscounterpart FedMix and FedData.Reducing feature exposure. As described in Sec. 3.4, in FLea,features from only a small fraction of local data are shared amongthe selected 10% of the clients each round (clients in round 1share with clients in ). To quantify the feature exposure, we definea feature exchange matrix R| || | (|| is the number of totalclients). ( ), = 1 denotes client and have exchanged features for",
  "feature exposure is measured by ( ) = , ( ), /||2 ( 0 ( )": "1), and a smaller ( ) is better. As FedData and FedMix gather dataor data averages and broadcast them to all clients before local modeltraining, ( ) = 100% consistently. We illustrate ( ) for FLea in(a): the exposure of FLea grows slowly. In our experiments,the model converges within 50 rounds (c.f. the learning curve in), by when ( ) 40%. Therefore, feature exposure isreduced by FLea.Moreover, feature exposure is not equivalent to privacy leakage.Based on the reduction of distance correlation between raw data andlearned activations during training (as shown in (b)), FLeais resilient to data reconstruction and context identification attacks.We construct test beds for a quantitative evaluation (detailed setupcan be found in Appendix D) and report the results below.Preventing data reconstruction. We built an attacker model byusing the activations from the FL model with and without reducing the distance correlation, respectively . The reconstruction error(MSE) for training the attacker is presented in (c). It canbe observed with L, MSE can never be reduced to the value of0.01 achieved with normal training without L, which suggeststhe data cannot be accurately reconstructed. To further illustratethis, lets look at an example: Assume one client is selected to sharethe activation of an image, e.g., the dog image in (a), in acertain communication round (when = 0.4), the attacker tries toreconstruct the image from the shared activation. Our experimentshows the recovered image ends up with (c*) (also shown in(c)). The original attribute, i.e., the color distribution cannotbe recovered and thus privacy is preserved.Impeding context identification. Our baseline FedMix also demon-strates to be resilient to data reconstruction attacks because rawdata are aggregated before sharing . However, FedMix can re-lease context information, while FLea can increase the difficulty ofidentifying the context. To quantify this, we constructed a contextidentification attacker, assuming that the context targeted for at-tack is represented by a colored square in the image (simulating amalfunctioning camera, see (a*))). We employed a binaryclassifier to predict the presence of the context. Half of the CIFAR10dataset was augmented with the marker for training and testingthe attacker. The identification accuracy achieved with varyingamounts of training samples is summarized in (d). Theresults indicate that FLea requires significantly more training data(hundreds of times) than FedMix to achieve comparable identifica-tion accuracy. For instance, to attain a 90% accuracy rate, FedMixneeds approximately 300 training samples, whereas FLea ( = 0.4)demands 10, 000 samples. Its important to note that real-world sce-narios pose greater challenges, as the context pattern may not beexplicit and the attacker might not have access to extensive trainingdata, resulting in reduced attacking accuracy. In such scenarios,FLea can effectively safeguard context privacy.",
  "CONCLUSIONS": "We proposed FLea, a novel approach to tackle scarce and label-skewed data in FL. Feature augmentation is employed to mitigateover-fitting and local drift simultaneously. Extensive experimentsdemonstrate that FLea remarkably outperforms the state-of-the-artbaselines while mitigating the privacy risk associated with featuresharing. In practice, FLea can introduce some additional overheads,such as increased communication and storage requirements, due tofeature sharing. We leave the task of improving efficiency for futurework. To enhance privacy, FLea can be combined with other meth-ods like differential privacy and homomorphic encryption .",
  "This work was supported by European Research Council Project833296 (EAR) and 805194 (REDIAL). We also thank Prof. NicholasLane and Lorenzo Sani for their insightful discussions": "Martin Abadi, Andy Chu, Ian Goodfellow, H Brendan McMahan, Ilya Mironov,Kunal Talwar, and Li Zhang. 2016. Deep learning with differential privacy. InProceedings of the 2016 ACM SIGSAC conference on computer and communicationssecurity. 308318. Zachary Charles, Zachary Garrett, Zhouyuan Huo, Sergei Shmulyian, and Vir-ginia Smith. 2021. On large-cohort training for federated learning. Advances inneural information processing systems 34 (2021), 2046120475.",
  "Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. 2009. Cifar-10 and cifar-100datasets. URL: (2009)": "Fan Lai, Yinwei Dai, Sanjay Singapuram, Jiachen Liu, Xiangfeng Zhu, HarshaMadhyastha, and Mosharaf Chowdhury. 2022. Fedscale: Benchmarking modeland system performance of federated learning at scale. In International Conferenceon Machine Learning. PMLR, 1181411827. Gihun Lee, Minchan Jeong, Yongjin Shin, Sangmin Bae, and Se-Young Yun. 2022.Preservation of the global knowledge by not-true distillation in federated learning.In Advances in Neural Information Processing Systems. Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He. 2022. Federated learningon non-iid data silos: An experimental study. In 2022 IEEE 38th InternationalConference on Data Engineering (ICDE). IEEE, 965978.",
  "Qinbin Li, Bingsheng He, and Dawn Song. 2021. Model-contrastive federatedlearning. In Proceedings of the IEEE/CVF conference on computer vision and patternrecognition. 1071310722": "Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar,and Virginia Smith. 2020. Federated optimization in heterogeneous networks.Proceedings of Machine learning and systems 2 (2020), 429450. Xin-Chun Li and De-Chuan Zhan. 2021. Fedrs: Federated learning with restrictedsoftmax for label distribution non-iid data. In Proceedings of the 27th ACM SIGKDDConference on Knowledge Discovery & Data Mining. 9951005. Wei Yang Bryan Lim, Nguyen Cong Luong, Dinh Thai Hoang, Yutao Jiao, Ying-Chang Liang, Qiang Yang, Dusit Niyato, and Chunyan Miao. 2020. Federatedlearning in mobile edge networks: A comprehensive survey. IEEE CommunicationsSurveys & Tutorials 22, 3 (2020), 20312063.",
  "Gaoyang Liu, Chen Wang, Xiaoqiang Ma, and Yang Yang. 2021. Keep your datalocally: Federated-learning-based data privacy preservation in edge computing.IEEE Network 35, 2 (2021), 6066": "Shunjian Liu, Xinxin Feng, and Haifeng Zheng. 2022. Overcoming Forgettingin Local Adaptation of Federated Learning Model. In Advances in KnowledgeDiscovery and Data Mining: 26th Pacific-Asia Conference, PAKDD 2022, Chengdu,China, May 1619, 2022, Proceedings, Part I. Springer, 613625. Mi Luo, Fei Chen, Dapeng Hu, Yifan Zhang, Jian Liang, and Jiashi Feng. 2021. Nofear of heterogeneity: Classifier calibration for federated learning with non-iiddata. Advances in Neural Information Processing Systems 34 (2021), 59725984. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, andBlaise Aguera y Arcas. 2017. Communication-efficient learning of deep networksfrom decentralized data. In Proc. Artificial Intelligence and Statistics. 12731282.",
  "Justin Salamon, Christopher Jacoby, and Juan Pablo Bello. 2014. A dataset andtaxonomy for urban sound research. In Proceedings of the 22nd ACM internationalconference on Multimedia. 10411044": "Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. 2018. Mobilenetv2: Inverted residuals and linear bottlenecks. InProceedings of the IEEE conference on computer vision and pattern recognition.45104520. Yujun Shi, Jian Liang, Wenqing Zhang, Vincent Tan, and Song Bai. 2022. TowardsUnderstanding and Mitigating Dimensional Collapse in Heterogeneous FederatedLearning. In The Eleventh International Conference on Learning Representations.",
  "Gbor J Szkely, Maria L Rizzo, and Nail K Bakirov. 2007. Measuring and testingdependence by correlation of distances. (2007)": "Yue Tan, Guodong Long, Lu Liu, Tianyi Zhou, Qinghua Lu, Jing Jiang, andChengqi Zhang. 2022. Fedproto: Federated prototype learning across hetero-geneous clients. In Proceedings of the AAAI Conference on Artificial Intelligence,Vol. 36. 84328440. Zhenheng Tang, Yonggang Zhang, Shaohuai Shi, Xin He, Bo Han, and XiaowenChu. 2022. Virtual homogeneity learning: Defending against data heterogeneityin federated learning. In International Conference on Machine Learning. PMLR,2111121132. Qi Teng, Kun Wang, Lei Zhang, and Jun He. 2020. The layer-wise trainingconvolutional neural networks using local loss for sensor-based human activityrecognition. IEEE Sensors Journal 20, 13 (2020), 72657274.",
  "(c) CIFAR10 is uniformly distributed to 500 clients. Each localdataset have a size of 100 (|D | = 100), 10 classes (IID) witheach class containing 10 samples": "For classification, we employ MobileNet_V2, which has 18 blocksconsisting of multiple convolutional and pooling layers . We usethe Adam optimizer for local training with an initial learning rate of103 and decay it by 2% per communication round until 105. For(a), all clients will participate in the training in each round, whilefor the other groups, we will randomly select 10% of the clients foreach round. The size of the local batch is 64, and we run 10 localepochs for each group. We run 100 communication rounds for allgroups to ensure global convergence.Experimental setup for : To compare the performanceof existing methods with , we use CIFAR10 dataset and report theclassification accuracy of the global model based on the globaltesting set. We compare FedAvg with loss-based methods such asFedDecorr and FedNTD, as well as data augmentation-based meth-ods like FedMix and FedData. They are the most representativemethods in each category. FedMix is implemented by averagingevery 10 samples and sharing the result globally. The shared av-eraged data is then combined with local data according to a Betadistribution (with the = 2) for local training. In the case of Fed-Data, we collect 10% of the data (randomly chosen) from each clientand share it globally, in the first communication round. To simulatevarying scarcity levels, we split the CIFAR10 training set (compris-ing 50, 000 samples in total) into 5000, 500, and 100 training sampleson average per client, which ends up with 10, 100 and 500 clientsfinally. Other settings are the same with the main experiments asintroduced in Sec. 4.1.Experimental setup for : DB score is defined asthe average similarity measuring each cluster with its most similarcluster, where similarity is the ratio of within-cluster distances tobetween-cluster distances. Thus, clusters which are farther apartand less dispersed will result in a better score. The minimum scoreis zero, with lower values indicating better clustering. To calculatethe score for features, we use the ground-true class labels as clusterlabels, and use Euclidean distance between features to measure thesimilarity.For a fair comparison, the local training for all clients startsfrom a same global status with an accuracy of 40%. The featuresof the testing set from the initial global model present a DB of4.8. We run one communication round and report the performancefor the global model. In this round, for |D | = 5000 we aggregate",
  "CIFAR1032 32 31050,00010,000MobiNet_V2UrbanSound8K2 64 344106,9861,732AudioNetUCI-HAR128 367,3522,947HARNet": "10 clients while for |D | = 100 we aggregate 50 clients, so thatthe total samples used for model training are kept unchanged. For|D | = 100+1000 group, we additionally give the selected 50 clients1000 samples (gathered in the first round) to aid local training. In, for local models, we report the averaged DB across clients.",
  "CDETAILS OF EXPERIMENTSC.1Data Distribution": "An overview of the data we used is presented in . Moredetails are given below.Image data: We test our algorithm on CIFAR10 . We dis-tribute CIFAR10 training images (containing 50, 000 samples for10 classes) to || = 500 and || = 1000 clients and use the globalCIFAR10 test set (containing 1, 000 samples per class) to report the",
  "C.2Model Architecture and Hyper-parameters": "We classify images in CIFAR10 using MobileNet_V2 that has18 blocks consisting of multiple convolutional and pooling layers.The architectures of MobileNet_V2 for CIFAR10 are summarized in.For audio classification, the audio samples are first transformedinto spectrograms and fed into a CNN model, which we termed asAudioNet. This model consists of four blocks, each comprising aconvolutional layer, a Relu activation layer, and a Batch Normaliza-tion layer, followed by a fully connected layer1. The details of theconvolutional layers are summarized in .For HAR data, we use a 4-layer CNN model, as summarized in. FLea shares the activation from the first layer.We use the Adam optimizer for local training with an initiallearning rate of 103 and decay it by 2% per communication round until 105. The size of the local batch is 32, and we run 10 localepochs for 100 clients setting and 15 local epochs for the rest. Forfeature augmentation, we use (2, 2). The weights in the lossfunction are set to 1 = 1 and 2 = 3. 10% of clients are randomlysampled at each round. We run 100 communications and take thebest accuracy as the final result. For all results, we report the meanand standard deviation of the accuracy from five runs with differentrandom seeds.",
  "FedProx: We adapt the implementation from . We test theweight for local model regularization in [0.1, 0.01, 0.001] andreport the best results": "FedLC: it calibrates the logits before softmax cross-entropyaccording to the probability of occurrence of each class .We test the scaling factor in the calibration from 0.1 to 1 andreport the best performance. FedDecorr: This method applies a regularization term duringlocal training that encourages different dimensions of the low-dimensional features to be uncorrelated . We adapted theofficial implementation2 and suggested hyper-parameter in thesource paper. We found that this method can only outperformFedAvg with fewer than 10 clients for CIFAR10.",
  "FedNTD: It prevents the local model drift by distilling knowl-edge from the global model . We use the default distillingweights from the original paper as the settings are similar3": "FedBR : this approach leverage 32 mini-batch data aver-ages without class labels as data augmentation. A min-maxalgorithm is designed, where the max step aims to make lo-cal features for all classes more distinguishable. In contrast,the min step enforces the local classifier to predict uniformprobabilities for the global data averages. We adopt the officialimplementation4 in our framework. CCVR: It collects a global feature set before the final fullyconnected linear of the converged global model, i.e., the modeltrained via FedAvg, to calibrate the classifier on the server .For a fair comparison, we use the same amount of features asour method for this baseline, and we fit the model using thefeatures instead of distributions as used in . This allows usto report the optimal performance of CCVR. FedGen: It is a method that trains a data generator using theglobal model as the discriminator to create synthetic data forlocal training . The generator outputs with input (,)where is a sample for Normal distribution. The generator isa convolutional neural network consisting of four ConvTrans-pose2d layers to upsample feature maps. We train the first 30rounds by normal FedAvg and after 30 rounds, we use the globalmodel as the discriminator to distinguish with the generateddata is real or not.",
  "(1)3 32 32(image)conv2d323132 32 321(2 5)32 32 32conv2d432, 32, 16, 161, 3, 1, 1,1, 1, 1, 116 32 32": "2(6 9)16 32 32conv2d496, 96, 24, 241, 3, 1, 11, 1, 1, 132 32 323(10 12)32 32 32conv2d3144, 144, 241, 3, 11, 1, 124 32 324(13 14)24 32 32conv2d3144, 144, 321, 3, 11, 2, 132 16 165&6(15 20)32 16 16conv2d3192, 192, 321, 3, 11, 1, 132 16 167(21 23)32 16 16conv2d3192, 192, 641, 3, 11, 2, 164 8 88, 9, &10(24 32)64 8 8conv2d3384, 384, 641, 3, 11, 1, 164 8 811(33 36)64 8 8conv2d4384, 384, 96, 961, 3,, 111, 1, 1, 19 8 812&13(37 42)96 8 8conv2d3576, 576, 961, 3, 11, 1, 196 8 814(43 45)96 8 8conv2d3576, 576, 1601, 3, 11, 2, 1160 4 415&16(46 51)160 4 4conv2d3960, 960, 1601, 3, 11, 1, 1160 4 417(52 54)160 4 4conv2d3960, 960, 3201, 3, 11, 1, 1320 4 418(55)320 4 4conv2d1280111280 4 4",
  "DPRIVACY STUDY": "Now we present the experimental setup for privacy attacks. We usethe Qua(3) data splits when || = 100 as an example for studying,as in other settings either the label is more skewed or the local datais more scarce, privacy attack can hardly be more effective thanthis setting. This is to present the attack defending for the mostvulnerable case. As the correlation between the features and thedata is continuously reduced (shown in (b)), we report thereconstruction and context detection performance for = 0.65 (the1 round) and = 0.40 (the 10 round) for reference.Data reconstruction. We first implemented a data reconstruc-tion attacker, following the approach described in , the attackerconstructed a decoder for reconstruction. Specifically, the attackertargeted the converged global model, ensuring a fair comparison.The decoder architecture, designed to match the MobileNet_V2architecture, comprised four conv2d layers (refer to ) toreconstruct the original data from the provided features. For visu-alization purposes, the CIFAR10 images were cropped to a size of32 32 pixels without any normalization. The decoder took thefeatures extracted from the global model as input and generated areconstructed image, which served as the basis for calculating themean squared error (MSE).To train the decoder, we utilized the entire CIFAR10 trainingset, conducting training for 20 epochs and employing a learningrate of 0.001. This approach allowed us to evaluate the fidelityof the reconstructed data and compare it with the original input,providing insights into the effectiveness of our proposed featureinterpolation method. We use the testing set and the target globalmodel ( = 0.65 and = 0.40 ) to extract features for reconstruction. (b) shows the training MSE while the exampled imagesare from the testing set. For = 0.65, i.e., after the first round, thesensitive attributes are removed (e.g., the color of the dog). After10 rounds when < 0.4, information is further compressed and theprivacy protection is enhanced. Overall, with L, the correlationbetween data and features is reduced, preventing the image frombeing reconstructed.Identifying context information. In this attack, we assumethat the attacker explicitly knows the context information and thuscan generate large amounts of negative (clear data) and positive(clear data with context marker) pairs to train a context classifier(which is very challenging and unrealistic but this is for the sake oftesting). Real-world attacks will be far more challenging than oursimulations.The context identification attacker is interested in finding out ifa given feature , is from the source data with a specific context ornot. We simulate the context information by adding a color squareto the image (to mimic the camera broken), as illustrated in .We use a binary classifier consisting of four linear layers to classifythe flattened features or images. To train the classifier, we add thecontext marker to half of the training set. To report the identificationperformance, we add the same marker to half of the testing set. In(c), the identification accuracy for FedMix and our FLea aregiven. We measure the attacking difficulty by how many trainingsamples the model needs to achieve a certain accuracy. The resultsin (c) suggest that FLea needs times of training sample thanFedMix for different correlations. This demonstrates that FLea canbetter protect the context privacy.All the above results lead to the conclusion that by reducingfeature exposure and mitigating the correlation between the fea-tures and source data, FLea safely protects the privacy associatedwith feature sharing while achieving favorable performance gainin addressing the label skew and data scarcity simultaneously."
}