{
  "ABSTRACT": "The increasing complexity of modern network environments presents formidable challenges toIntrusion Detection Systems (IDS) in effectively mitigating cyber-attacks. Recent advancements inIDS research, integrating Explainable AI (XAI) methodologies, have led to notable improvementsin system performance via precise feature selection. However, a thorough understanding of cyber-attacks requires inherently explainable decision-making processes within IDS. In this paper, wepresent the Interpretable Generalization Mechanism (IG), poised to revolutionize IDS capabilities. IGdiscerns coherent patterns, making it interpretable in distinguishing between normal and anomalousnetwork traffic. Further, the synthesis of coherent patterns sheds light on intricate intrusion pathways,providing essential insights for cybersecurity forensics. By experiments with real-world datasetsNSL-KDD, UNSW-NB15, and UKM-IDS20, IG is accurate even at a low ratio of training-to-test.With 10%-to-90%, IG achieves Precision (PRE)=0.93, Recall (REC)=0.94, and Area Under Curve(AUC)=0.94 in NSL-KDD; PRE=0.98, REC=0.99, and AUC=0.99 in UNSW-NB15; and PRE=0.98,REC=0.98, and AUC=0.99 in UKM-IDS20. Notably, in UNSW-NB15, IG achieves REC=1.0 and atleast PRE=0.98 since 40%-to-60%; in UKM-IDS20, IG achieves REC=1.0 and at least PRE=0.88since 20%-to-80%. Importantly, in UKM-IDS20, IG successfully identifies all three anomalousinstances without prior exposure, demonstrating its generalization capabilities. These results andinferences are reproducible. In sum, IG showcases superior generalization by consistently performingwell across diverse datasets and training-to-test ratios (from 10%-to-90% to 90%-to-10%), andexcels in identifying novel anomalies without prior exposure. Its interpretability is enhanced bycoherent evidence that accurately distinguishes both normal and anomalous activities, significantlyimproving detection accuracy and reducing false alarms, thereby strengthening IDS reliability andtrustworthiness.",
  "Introduction": "The Federal Bureau of Investigation (FBI) reports a 7% increase in cybercrime complaints in the U.S., with expectedlosses surpassing $6.9 billion . Globally, Barrons estimates cybercrime costs to reach an astounding $6 trillion .To combat these rising cyber threats, Intrusion Detection Systems (IDS) have been developed , , . However,traditional IDS often lack transparency, hindering administrators and security experts from fully understanding theautomated decision-making processes.",
  "Running Title for Header": "Rajendra Patil, Harsha Dudeja, and Chirag Modi. Designing an efficient security framework for detectingintrusions in virtual network of cloud computing. Computers & Security, 85:402422, 2019. Jianwu Zhang, Yu Ling, Xingbing Fu, Xiongkun Yang, Gang Xiong, and Rui Zhang. Model of the intrusiondetection system based on the integration of spatial-temporal features. Computers & Security, 89:101681, 2020. Rami Mustafa A Mohammad, Mutasem K Alsmadi, Ibrahim Almarashdeh, and Malek Alzaqebah. An improvedrule induction based denial of service attacks classification model. Computers & Security, 99:102008, 2020. Dogukan Aksu and Muhammed Ali Aydin. Mga-ids: Optimal feature subset selection for anomaly detectionframework on in-vehicle networks-can bus based on genetic algorithm and intrusion detection approach. Computers& Security, 118:102717, 2022. Zhendong Wang, Yaodi Liu, Daojing He, and Sammy Chan. Intrusion detection methods based on integrated deeplearning model. Computers & Security, 103:102177, 2021. Muataz Salam Al-Daweri, Salwani Abdullah, and Khairul Akram Zainol Ariffin. An adaptive method and a newdataset, ukm-ids20, for the network intrusion detection system. Computer Communications, 180:5776, 2021. Michael Zipperle, Florian Gottwalt, Elizabeth Chang, and Tharam Dillon. Provenance-based intrusion detectionsystems: A survey. ACM Computing Surveys, 55(7):136, 2022. Mahbod Tavallaee, Ebrahim Bagheri, Wei Lu, and Ali A Ghorbani. A detailed analysis of the kdd cup 99 data set.In 2009 IEEE Symposium on Computational Intelligence for Security and Defense Applications, pages 16. IEEE,2009. Nour Moustafa and Jill Slay. Unsw-nb15: a comprehensive data set for network intrusion detection systems(unsw-nb15 network data set). In 2015 Military Communications and Information Systems Conference (MilCIS),pages 16. IEEE, 2015.",
  "A Machine-learning Based IDS": "Machine learning has been effectively utilized in IDS. Notable examples include the integration of naive Bayes featureembedding with Support Vector Machine (SVM) , the development of the Outlier Dirichlet Mixture-based AnomalyDetection System (ODM-ADS) , and the application of Deep Neural Networks (DNN) informed by SimulatedAnnealing Algorithms (SAA) and Improved Genetic Algorithms (IGA). Moreover, the exploration of WrapperBased Feature Extraction Units (WFEU) in conjunction with Feed-Forward Deep Neural Networks (FFDNN) has beenreported . To assess their efficacy, these studies have employed datasets such as NSL-KDD, UNSW-NB15, andUKM-IDS20. A summary of the data processing techniques, feature sets, and train-test ratios used in these studiesis provided in . The results demonstrate high accuracy across these methods, with each employing a distinctapproach to feature engineering during data preprocessing. Indeed, feature engineering is pivotal in the context ofExplainable AI (XAI) as it substantially influences the interpretability and transparency of machine learning models. Inthe development of IG, our approach emphasizes preserving the original data structure, deliberately avoiding techniquessuch as the removal of irrelevant features, feature selection, and resampling for balance.",
  "Why Should We Need an Interpretable-generalization IDS?": "Recent advances in machine learning-based IDS have emphasized enhancing explainability. Techniques such asNeural Attention Models , Shapley Additive exPlanations (SHAP) , and Local Interpretable Model-agnosticExplanations (LIME) have been increasingly applied. A significant study utilized XAI methods to identifycritical features, thus reducing runtime and enhancing accuracy while providing clearer insights into the correlationbetween features and attacks. Nonetheless, to fully comprehend intrusion techniques, the core of an IDS must inherentlybe interpretable. Interpretable models provide essential insights into AI decision-making processes . While models like linearmodels, decision trees, and generalized additive models offer enhanced interpretability, they often fall short in predictiveaccuracy when compared to more complex, opaque black box models. To address this, an innovative approach,Transparent Classification (TC) , has been introduced, aiming to strike a balance between interpretability andaccuracy. Experiments with two datasets Contraceptive Method Choice and Breast Cancer Wisconsin demonstratedthat TC obtains perfect accuracy of recall, but lower accuracy of precision. Notably, TC faces a high false alarm rate.According to the third rule, TC optimizes the model by classifying an instance as positive only when it has a zero score",
  "Total: 12887 (69%, 31%); ARP poison-ing: 8909, 592; DoS: 8909, 1742; Scans:8909, 597; Exploits: 8909, 1047": "Data Preprocessing: Nave Bayes feature embedding , A modified Kolmogorov-Smirnov CorrelationBased Filter Algorithm , PCA and Pearson class label correlation , Binary Bat Algorithm with FeatureSimilarity-based Fitness Function and Classifier Accuracy based Fitness Function (BBA+FSFF+CAFF), Genetic Algorithms (GA) , The correlation-based Feature Selection technique , ModifiedGenetic Algorithm (MGA) m-feature selection , Denoising AutoEncoder .",
  "Methods": "presents the process of IG. In data preprocessing, we propose a reproducible manner to handle data issues suchas varying types, identical instances with different labels, and missing values. In training, we establish coherent patternsthat are occurred in only one class label, which are used for distinguishing normal and anomalous instances in thetest. In test, for an instance, we calculate its normal and anomalous scores by using coherent patterns. Then, threeregulations are utilized to determine whether an instance is normal or anomalous. To ensure comprehensiveness, thedata are divided using a range of ratios, from low training-to-test ratios to high ones. In information forensics, weprovide highlights of frequent intrusion techniques in different ratios of training-to-test.",
  "Data Preprocessing": "In this research, limitations due to large-scale data necessitated extracting only portions of the datasets for ourexperiments. To ensure reproducibility, instances were selected sequentially instead of randomly, as detailed in .In NSL-KDD, the first 10,000 instances from the Train+ subset and the first 5,000 instances from the Test+ subset wereutilized. In UNSW-NB15, a total of 14,714 instances were extracted from its four CSV files. These anomalous instanceswere evenly distributed across nine attack categories, with each category contributing 500 instances. Where an attackcategory had fewer than 500 instances, all available instances were included. In UKM-IDS20, the entire dataset fromboth training and testing subsets was used. presents the proportion of each attack type within these datasets. In the data preprocessing phase, instances with identical features but differing class labels were excluded to avoidcontradictions. For the UNSW-NB15 and UKM-IDS20 datasets, no contradictory instances were identified, whereas inthe NSL-KDD dataset, 133 instances required exclusion. The adjusted total number of instances is presented in ,which depicts the 1|9 training-to-testing ratio as 10%-to-90%. Moreover, details the distribution of normal andanomalous instances within the training and testing sets, emphasizing the variations in these distributions at varioustraining-to-testing ratios.",
  "Algorithm 1 Dataset preprocessing": "Input: Cybersecurity datasetOutput: Preprocessing cybersecurity dataset1: I Cybersecurity dataset2: Replace missing values in I with NotNumber3: ans Class labels from I4: for i := 0 to I.columns do5:if Ii = numerical then6:Ii ZSCORE(Ii)7:end if8: end for9: Ifiltered = I {x I | y I : (x = y) (ans(x) = ans(y))}10: M = {x Ifiltered | ans(x) = \"Anomalous\"}11: N = {x Ifiltered | ans(x) = \"Normal\"}",
  "Training": "We split data into training and test sets. Let the total number of instances in the dataset be K. Out of these, N instancesare normal, and M instances are anomalous. Then K is split into training and test sets based on a percentage ratio. LetTRratio represents the training ratio, which varies from 10% to 90% in increments of 10%. Consequently, the test ratioTEratio = 100% TRratio. For the training set at any given TRratio, the number of normal instances Ntrain andanomalous instances Mtrain are calculated as follows: Ntrain = N TRratio and Mtrain = M TRratio. Similarly,for the test set: Ntest = N TEratio and Mtest = M TEratio.",
  "Algorithm 2 Identify distinguishable patterns and score": "Input: Set of anomalous training instances Mtrain, set of normal training instances NtrainOutput: Distinguishable patterns and score1: Initialization: CNP , CAP ,2: for each pair of instances i, j Ntrain do3:NP Ni Nj4:if NP / Mtrain then5:Add NP to CNP6:end if7: end for8: for each pair of instances x, y Mtrain do9:AP Mx My10:if AP / Ntrain then11:Add AP to CAP12:end if13: end for",
  "As Algorithm 2, we discover coherent patterns by the following steps": "Step 1: Intersection of normal instances to generate normal patterns (NP).We perform pairwise intersections to generate normal patterns. The intersection operation Ni Nj (wherei = j) produces a set of common elements between any two normal instances, which is represented as Equation(2). Given N1 = (a, b, d, e), N2 = (a, b, e, f), N3 = (a, b, d, f), and N4 = (a, b, d, e), the intersectionN1 N2 yields the normal pattern N12 = (a, b, e). Moreover, Ntrain themselves are normal patterns.Subsequently, we quantify the frequency of each normal pattern, e.g., (a, b, e)_2, (a, b, d)_2, (a, b, f)_1,(a, b, d, e)_2, (a, b, e, f)_1, and (a, b, d, f)_1.",
  "Ni Nj = Nij = {x|x Ni and x Nj}(2)": "Step 2: Intersection of anomalous instances to generate anomalous patterns (AP).We do the same as step 1. Given M1 = (a, b, c, d), M2 = (a, b, d, g), and M3 = (b, c, d, g), we count theoccurrence as (a, b, d)_1, (b, c, d)_1, (b, d, g)_1, (a, b, c, d)_1, (a, b, d, g)_1, and (b, c, d, g)_1. Step 3: Derivation of coherent normal patterns (CNP)In Equation (3), we define CNP as those normal patterns that are not exactly replicated in the anomalousinstances. In this case, we obtain three CNP: (a, b, e)2, (a, b, d, e)1, and (a, b, f)1. The NP (a, b, d)2 is excludedbecause it is a subset of an instance in Mtrain.",
  "CNP = {Nij | Nij / {Mtrain}}(3)": "Step 4: Derivation of coherent anomaly patterns (CAP)In Equation (4), CAP are defined as those anomalous patterns that do not have an identical counterpart in thenormal instances. This case has five CAP: (b, c, d)_1, (b, d, g)_1, (a, b, c, d)_1, (a, b, d, g)_1, and (b, c, d, g)_1.",
  "Test": "We calculate whether a CNP or CAP is a subset of a test instance, which then informs the scoring and classificationprocess. As Equation (5), A pattern P (either CNP or CAP) is considered a subset of an instance T if every element ofP is contained in T.P T P, T(5) Step 1: Normal score calculation.For each test instance Ti, we calculate the normal score based on the occurrence and length of any CNP that isa subset of Ti. The normal-score NSTi is determined as Equation (6), where CNP is a CNP that is a subset ofTi.",
  "Step 3: Classification regulations.The classification of an instance into normal or anomalous categories is determined based on three regulations:": "Regulation 1: If the anomaly-score is greater than or equal to the normal-score, classify the instance asanomalous; otherwise, it is normal;Regulation 2: If both anomaly-score and normal-score are zero, classify the instance as anomalous;Regulation 3: If the normal-score is less than NSave r NSstd, classify the instance as anomalous, wherer is a user-defined parameter, NSave is the average of normal scores, and NSstd is the standarddeviation of normal scores. Regulation 3 tackles the challenge of detecting unknown new attacksduring the testing phase, especially when training data lack features of these attacks. Its principalstrategy is to identify potential new attacks that, despite having an anomaly-score of zero, exhibita normal-score considerably lower than the average. It flags instances as potential new attackswhen their normal-score falls below a user-defined threshold, set at a specific number of standarddeviations from the mean. This user-determined threshold, based on empirical rules, enhancesthe detection of novel attack types not encountered in the training stage. Here we provide a calculation example. Suppose we have four instances for a task of test: T1 = (a, b, c, d, e, f),T2 = (b, c, d, f), T3 = (a, b, d, g, f), and T4 = (s, t, u, ). After executing step 1 and step 2, we obtain NST1 = 13(32 from (a, b, e), 41 from (a, b, d, e), and 31 from (a, b, f)), AST1 = 3 (31 from (b, c, d)), NST2 = 0, AST2 = 3,NST3 = 3, AST3 = 3, NST4 = 0, and AST4 = 0. Step 3 produces the result of classification as follow. T1 is normal byRegulation 1. T2 is anomaly by Regulation 1. T3 is anomaly because of the following reason. Initially, by Regulation 1,T3 is normal. But, by Regulation 3, given r = 0.1, NST3 < NSave r NSstd as well as 3 < 4 (0.1 6.164) , andhence T3 is anomaly eventually. T4 is anomaly by Regulation 2.",
  "Information Forensics": "IG possesses the ability of knowledge discovery which helps cybersecurity experts in comprehending the underlyingcauses of attacks. The study has explored what attack is associated with a single feature, however we have proventhe single feature exists on normal instances as well. IG distinguish coherent patterns through set theory. Usually bothnormal and attack patterns exist simultaneously. Set theory proves that CAP are mutually exclusive from normal trafficpatterns, which eliminates a contradiction between anomalous and normal patterns. Without uncertainty, IG mapscoherent patterns onto comprehensive intrusion paths. Further, different intrusion paths share commonality, which ishelpful in understanding essentials of attacks. Specifically, the commonality provides not only frequency of the attacksbut also reflection of cybersecurity vulnerability. In the experiment, we show the most frequent attack intrusion paths atincremental ratios of training to test.",
  "Datasets Description": "We conducted experiments with three well-known public datasets NSL-KDD , UNSW-NB15 , and UKM-IDS20 as detailed in . The NSL-KDD dataset, a refined version of the original KDD99 dataset, was developed byTavallaee et al. to address certain limitations of KDD99. This refinement involved creating various subsets, namelyKDDTrain+, KDDTest+, KDDTrain_20Percent, and KDDTest-21. NSL-KDD is distinguished by the removal ofredundant records from KDD99 and the introduction of a metric called #successfulPrediction, derived from the resultsof 21 different experiments. Consequently, 125,973 records were selected for KDDTrain+ and 22,544 for KDDTest+,based on the success rate indicated by the successful prediction metric. The KDDTrain_20Percent subset comprises theinitial 20% of the KDDTrain+ dataset. KDDTest-21, another refined subset from KDDTest+, was created by excludingrecords that were consistently and correctly classified in all 21 experiments. NSL-KDD categorizes the anomalousrecords into four primary attack types: Denial of Service (DoS), Probe, Remote to Local (R2L), and User to Root (U2R).Regarding features, the NSL-KDD dataset builds upon the original 42 features of KDD99 by adding an additionalcolumn, which records the frequency of correct classifications in the 21 experiments, thereby providing an additionaldimension for analysis. The UNSW-NB15 dataset consists of four CSV files, which together contain 2,540,044 records. This dataset ischaracterized by its diversity, comprising 49 unique features and covering nine types of attacks: Worms, Shellcode,Reconnaissance, Generic, Fuzzers, Exploits, DoS, Backdoor, and Analysis. These features are classified into variouscategories, including basic, content, temporal, and flow features, in addition to several derived features. Each record inthe dataset is annotated with labels for both attack type and binary classification. Due to the considerable size of theUNSW-NB15 dataset, it has been divided into separate subsets for training and testing purposes. The UKM-IDS20 dataset, developed by Al-Daweri et al. , was created by collecting original network traffic datafrom the National University of Malaysia (UKM). This effort was undertaken to simulate attack activities in a realisticenvironment, with the data collection spanning over a period of two weeks. The dataset includes 48 distinct features,encompassing an attack type label, a binary classification label, basic features, connection flag features, connectioncount features, size-based features, and time-based features. This sentence was already clear and concise, accuratelydescribing the types of attacks covered by the dataset. Compared to benchmark datasets, UKM-IDS20 provides valuableinsights into contemporary network traffic and modern attack methods.",
  "Result": "Evaluating the performance of predictive models is essential, especially in the context of IDS, where accuratelydistinguishing between normal and anomalous activities is critical. The Confusion Matrix, a fundamental tool inclassification problems, plays a vital role in our experiments. In the proposed IG, the \"anomaly\" class is labeled aspositive, while the \"normal\" class is negative. Four aspects of this matrix were analyzed such as True Positive (TP),False Positive (FP), True Negative (TN), and False Negative (FN) rates. TP measures how well the system identifiesactual anomalies, FP indicates normal instances incorrectly labeled as anomalies, TN represents correct predictions ofnormal instances, and FN accounts for anomalies incorrectly labeled as normal. To thoroughly assess the capability of IG, we use the key metrics: accuracy, precision, recall, and the Area Underthe Receiver Operating Characteristic Curve (AUC). Accuracy is the proportion of all predictions (both anomaliesand normal) that a method correctly identifies, reflecting overall effectiveness. However, due to the imbalanceddistribution between normal and anomaly classes in cybersecurity data, precision and recall are critical for a moredetailed evaluation. Precision is the ratio of correctly predicted anomaly instances to all instances predicted as anomalies,essentially measuring the exactness of a method in identifying true threats. In contrast, recall, also known as thesensitivity, assesses the capability of a method to detect actual anomalies from all true anomaly instances. The AUC provides a comprehensive measure of a methods capability to distinguish between actual attacks and normalactivities across various decision-making points. Unlike precision and recall, which assess a methods performance ata single, specific point (like a fixed level of alertness), AUC evaluates a methods effectiveness across a spectrum ofconditions, offering a broader view of its overall performance. This range of conditions could represent different levelsof strictness or sensitivity in identifying threats, making AUC a crucial metric in assessing IDS effectiveness, especiallygiven the diverse nature of cyber threats. presents the performance of IG as:",
  "| 10.96710.96500.97760.99310.99441.00000.98120.99980.96201.00000.88910.9999": "1. Generalization Across Diverse Scenarios: IGs generalization capabilities are exemplified by its consistentperformance across datasets: achieving accuracies of 0.9389 to 0.9476 in NSL-KDD, 0.9690 to 0.9782 inUNSW-NB15, and 0.9554 to 0.9611 in UKM-IDS20, across varying training-to-test ratios. These resultshighlight its robust adaptability to different network environments. 2. Precision in Anomaly Detection: Precision, a critical metric for reducing false alarms in intrusion detection, isa standout feature of IG. In the UKM-IDS20 dataset, even with a training ratio as low as 20%, IG achievesa precision rate of at least 0.88. This high precision underlines IGs effectiveness in accurately detectinganomalies, thereby minimizing the occurrence of false positives. 3. Efficiency in Identifying True Threats: IG consistently achieves high recall rates across datasets, exemplifiedby rates of 1.0 in UNSW-NB15 and UKM-IDS20, and ranging from 0.9353 to 0.9476 in NSL-KDD. Theseresults highlight its capability to accurately identify genuine threats, ensuring minimal misses in detectingactual attacks. 4. Comprehensive Performance Evaluation with AUC: The AUC scores of IG across different datasets underscoreits comprehensive effectiveness in distinguishing between normal activities and actual threats. In NSL-KDD,IG achieves an AUC range of 0.9402 to 0.9504, with its peak at 0.9504, demonstrating robust discriminationcapability. In UNSW-NB15, the AUC scores hover around a high of 0.99, reflecting exceptional accuracy inthreat detection. Similarly, in UKM-IDS20, IG consistently shows AUC scores at 0.99, indicating its sustainedeffectiveness across various scenarios.",
  "offers a rigorous comparison of various methods in NSL-KDD, UNSW-NB15, and UKM-IDS20. Theperformance metrics used for comparison are Accuracy, Recall, Precision, and AUC": "1. In NSL-KDD Dataset: Method exhibited outstanding performance, achieving the highest metrics with99.86% accuracy, 99.93% recall, 99.83% precision, and 99.87% AUC. Its noteworthy that in NSL-KDD, achieved the best results but utilized only 12 features out of the original 41, and its training-to-testingratio was 52%-48%. This distinction in feature selection and data split ratio poses considerations for generalapplicability and robustness against sophisticated attack scenarios. IG, under a 10%-90% training-testing ratio,achieved a competitive performance with 93.89% accuracy, 94.26% recall, 93.53% precision, and 94.02%AUC, highlighting its robustness even with limited training data. 2. In UNSW-NB15 Dataset: Method reached a perfect score across all metrics, setting a high benchmark.However, its noteworthy that the top performance of the method used just 7 of 47 original features ata 50%-50% training-testing split. This reduction in feature space, while effective, may limit the modelsability to recognize diverse attack vectors. IG, under a 10%-90% training-testing ratio, showcased exemplaryperformance with 98.94% accuracy, 96.56% recall, 99.97% precision, and 99.88% AUC. These results areparticularly significant, reflecting IGs superior capability in accurately detecting anomalies with minimal falsepositives. 3. In UKM-IDS20 Dataset: Method displayed a strong performance with 94.66% accuracy, 96.91% recall,and 92.43% precision. IG stood out with its high scores of 98.10% accuracy, 94.36% recall, 99.80% precision,and 99.82% AUC, underscoring its effectiveness in diverse operational conditions. As illustrated in , , and , IG methodically discovers coherent patterns, delineating them as digitalfootprints that sharply distinguish between anomalous and normal network behaviors. These patterns, representedin distinct colors, serve as pivotal evidence in our analysis: blue for features unique to either anomalous or normalbehaviors, green for identical features, and red for commands shared between both but with differing parameters.This nuanced identification underscores IGs comprehensiveness to threat detection, leveraging the full feature setand offering a significant advancement over models restricted by a limited feature scope. Not only does this methoddemonstrate IGs robust capability in detecting a wide spectrum of cyber threats, but it also equips cybersecurityprofessionals with a precise forensic toolkit. Such detailed pattern recognition, devoid of ambiguity, transforms IG intoan indispensable asset for both intrusion detection and the meticulous scrutiny integral to digital forensics, highlightingits adaptability and precision in a real-world security landscape.",
  "Conclusion": "In this study, we proposed an interpretable generalization mechanism (IG) for intrusion detection systems (IDS), aimingto not only enhance the performance of intrusion detection by effectively detecting anomalies but also contribute toprovide comprehensive intrusion paths and interpretability for the decision-making process. The coherent patternsprovide interpretability in differentiating between normal and anomalous traffic, which enables experts to proactivelyprevent attacks rather than passively detecting them. IG has primarily five advantages. First, Interpretability, IG relies on coherent patterns to differentiate betweennormal and anomalous traffic, shedding light on the reasoning behind its decisions. Second, Forensics, combinations ofcoherent patterns provide deep insights to grasp comprehensive intrusion paths, facilitating development of cybersecurity.Previously, intrusion paths with partial patterns were indicated as certain type of attacks; however, we discoveredthe paths also frequently appear in normal traffic so that vast amounts of false alarms arise. In IG, coherent patternsprove comprehensive intrusion paths belong to anomalous traffic only. Third, Reproducibility, the entire processof IG is reproducible, which includes data preparation, training, test, evaluation, and inference. IG yields reliableresults in both experimental settings and inference scenarios. Fourth, Effectiveness, IG is accurate in identifyingboth normal and anomalous traffic in the real-world public datasets. In Particular, IG achieves high value of AUCeven when the proportion of training to test is low, such as AUC=0.94 and Training/Test=10%/90% in NSL-KDD,AUC=0.99 and Training/Test=10%/90% in UNSW-NB15, AUC=0.99 and Training/Test=10%/90% in UKM-IDS20.Fifth, Generalization, IG is qualified because it possesses the three capabilities: high PRE, REC, and AUC acrossvarious datasets and ratios; identification of anomalous instances without training inclusion; and reproducibility ofresults. In sum, IG paves the way for more advanced research and development in the realm of explainable and reliableAI-driven security solutions.",
  "avg_rr | 0.0 http_rqsts_count | 0.0~4.0 http_redirct_count | 0.0~3.0 http_clnt_error_count | 0 http_srv_error_count | 0": "ovrlp_count | 0 long_frag_count | 0 http_rqsts_count | 0.0~4.0 http_redirct_count | 0.0~3.0 http_clnt_error_count | 0 http_srv_error_count | 0 dns_ratio | 0.0 avg_rr | 0.0 http_rqsts_count | 0.0~4.0 http_redirct_count | 0.0~3.0 http_clnt_error_count | 0 http_srv_error_count | 0 ovrlp_count | 0 long_frag_count | 0 http_rqsts_count | 0.0~4.0 http_redirct_count | 0.0~3.0 http_clnt_error_count | 0 http_srv_error_count | 0 dns_ratio | 0.0 avg_rr | 0.0 http_rqsts_count | 0.0~4.0 http_redirct_count | 0.0~3.0 http_clnt_error_count | 0 http_srv_error_count | 0 ovrlp_count | 0 long_frag_count | 0 http_rqsts_count | 0.0~4.0 http_redirct_count | 0.0~3.0 http_clnt_error_count | 0 http_srv_error_count | 0 dns_ratio | 0.0 avg_rr | 0.0 http_rqsts_count | 0.0~4.0 http_redirct_count | 0.0~3.0 http_clnt_error_count | 0 http_srv_error_count | 0 ovrlp_count | 0 long_frag_count | 0 http_rqsts_count | 0.0~4.0 http_redirct_count | 0.0~3.0 http_clnt_error_count | 0 http_srv_error_count | 0",
  "ct_src_dport_ltm | 1 ct_dst_sport_ltm | 1": "30 31 32 33 34 35 36 37 38 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0 Dintpkt | 0.0~59.425765 tcprtt | 0.0~0.003247 synack | 0.0~0.001003 ackdat | 0.0~0.001099 is_sm_ips_ports | 0 ct_state_ttl | 2 ct_flw_http_mthd | 0.0 is_ftp_login | 0.0 ct_ftp_cmd | 0",
  "Jie Gu and Shan Lu. An effective intrusion detection approach using svm with nave bayes feature embedding.Computers & Security, 103:102158, 2021": "Nour Moustafa, Kim-Kwang Raymond Choo, Ibrahim Radwan, and Seyit Camtepe. Outlier dirichlet mixturemechanism: Adversarial statistical learning for anomaly detection in the fog. IEEE Transactions on InformationForensics and Security, 14(8):19751987, 2019. Murugaraj Odiathevar, Winston KG Seah, Marcus Frean, and Alvin Valera. An online offline framework foranomaly scoring and detecting new traffic in network streams. IEEE Transactions on Knowledge and DataEngineering, 34(11):51665181, 2021. Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Rana Omer, Pankesh Patel, Bin Qian, Zhenyu Wen,Tejal Shah, Graham Morgan, et al. Explainable ai (xai): Core ideas, techniques, and solutions. ACM ComputingSurveys, 55(9):133, 2023. Nour Moustafa, Nickolaos Koroniotis, Marwa Keshk, Albert Y Zomaya, and Zahir Tari. Explainable intrusiondetection for cyber defences in the internet of things: Opportunities and solutions. IEEE Communications Surveys& Tutorials, 2023.",
  "Sydney Mambwe Kasongo and Yanxia Sun. A deep learning method with wrapper based feature extraction forwireless intrusion detection system. Computers & Security, 92:101752, 2020": "Giuseppina Andresini, Annalisa Appice, Francesco Paolo Caforio, Donato Malerba, and Gennaro Vessio. Roulette:A neural attention multi-output model for explainable network intrusion detection. Expert Systems with Applica-tions, 201:117144, 2022. Ayodeji Oseni, Nour Moustafa, Gideon Creech, Nasrin Sohrabi, Andrew Strelzoff, Zahir Tari, and Igor Linkov.An explainable deep learning framework for resilient intrusion detection in iot-enabled transportation networks.IEEE Transactions on Intelligent Transportation Systems, 24(1):10001014, 2022. Erzhena Tcydenova, Tae Woo Kim, Changhoon Lee, and Jong Hyuk Park. Detection of adversarial attacks inai-based intrusion detection systems using explainable ai. Human-Centric Comput Inform Sci, 11, 2021. Marwa Keshk, Nickolaos Koroniotis, Nam Pham, Nour Moustafa, Benjamin Turnbull, and Albert Y Zomaya.An explainable deep learning-enabled intrusion detection framework in iot networks. Information Sciences,639:119000, 2023. Igor Linkov, Stephanie Galaitsi, Benjamin D Trump, Jeffrey M Keisler, and Alexander Kott. Cybertrust: Fromexplainable to actionable and interpretable artificial intelligence. Computer, 53(9):9196, 2020. Hao-Ting Pai and Chung-Chian Hsu. Explainable analytics: understanding causes, correcting errors, and achievingincreasingly perfect accuracy from the nature of distinguishable patterns. Scientific Reports, 12(1):18368, 2022."
}