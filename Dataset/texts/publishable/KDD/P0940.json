{
  "Abstract": "Identifying significant references within the complex interrelationsof a citation knowledge graph is challenging, which encompassesconnections through citations, authorship, keywords, and otherrelational attributes. The Paper Source Tracing (PST) task seeks toautomate the identification of pivotal references for given scholarlyarticles utilizing advanced data mining techniques. In the KDD CUPOAG-Challenge PST track, we design a recommendation-basedframework tailored for the PST task. This framework employsthe Neural Collaborative Filtering (NCF) model to generate finalpredictions. To process the textual attributes of the papers andextract input features for the model, we utilize SciBERT, a pre-trained language model. According to the experimental results, ourmethod achieved a score of 0.37814 on the Mean Average Precision(MAP) metric, outperforming baseline models and ranking 11thamong all participating teams. The source code is publicly availableat",
  "Team AoboSamaLeader of Team AoboSamaCorresponding author": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than theauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, orrepublish, to post on servers or to redistribute to lists, requires prior specific permissionand/or a fee. Request permissions from CUP 2024 OAG-Challenges, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.ACM ISBN 978-1-4503-XXXX-X/18/06",
  "Introduction": "Paper source tracing (PST) is vital for effective knowledge manage-ment. By linking common attributes between papers as relationaledges, a comprehensive citation knowledge graph is constructed.Successfully addressing the PST task enables the clear visualiza-tion of whether paper A primarily inspires or contributes to pa-per B, as illustrated in . Utilizing a citation knowledgegraph facilitates the identification of critical references, elucidatesthe evolution of disciplines and techniques, and foster academicconnections and collaborations. To this end, we propose a modelbased on Neural Collaborative Filtering (NCF) for the PST task.The model processes the textual attributes of papers obtained fromDBLP-citation-network (abbreviated as DBLP), with the as-sistance of SciBERT , a pre-trained language model. The pro-posed model demonstrates suitability for solving the PST task andachieves promising results on the Mean Average Precision (MAP)metric. The source code of our approach is publicly available at Our contributionsare as follows:",
  "Machine Learning Based Methods for PST": "The identification of significant references is generally framed as aclassification or regression problem. This process involves the man-ual engineering of features, such as metadata-based parameters ,citation counts , author overlap , textual similarity , among others. These features are then utilized for training andinference with various machine learning methods, such as support",
  ": Paper Source Tracing with the Citation KnowledgeGraph": "vector machine, random forest, decision tree, kernel logistic regres-sion, among others . Machine learning-based methodsoffer the advantages of automating the processing of extensive dataand efficiently extracting valuable insights for literature analysis.However, these methods may suffer from limitations in accuracyand interpretability, which can be attributed to factors such as dataquality and the inherent complexity of the models.",
  "Language Model Based Methods for PST": "Recent advancements in language models have significantly en-hanced text processing capabilities. Fine-tuning these models withannotated data has demonstrated promising results for PST task.Previous research has explored the integration of text embeddingtechniques such as Word2Vec and GloVe . By framing thePST as a binary classification problem for citation significance,the application of models such as SciBERT, GLM, and Galactica inconjunction with a Multi-Layer Perceptrons (MLPs) classifier hasyielded promising results . Building on these advancements,the PST-Bench dataset has been introduced, utilizing pre-trainedmodels like BERT and SciBERT, which further demonstrate theeffectiveness of these models in identifying significant references. Language model-based methods are widely used due to theirability in deeply understanding contextual semantics. Nevertheless,the full potential of these models remains largely untapped.",
  "the set of relations that describe the interactions between differenttypes of nodes. Each paper node is associated with various textattributes, such as the paper title, abstract and body": "3.1.2Recommendation Modeling. A conventional approach to ad-dress the PST task involves modeling it as a matching problem,where similarity between the query paper and potential referencesis calculated. Similarly, recommender systems operate by filteringitems based on user preferences through similarity measures. Giventhe conceptual overlap between the PST task and recommendationsystems, we frame the PST task as a recommendation problem. Fromthe perspective of recommender systems, the query papers can beconceptualized as \"users\" and references as \"items\". In this frame-work, \"citation\" relations represent interactions between \"users\"and \"items\", with \"critical citations\" interpreted as positive interac-tions. By reformulating the problem as a recommendation task, wecan leverage the family of algorithms used in recommender systems.Specifically, we focus on predicting the probability of a \"criticalcitation\" for each paper-reference pair (,), , E. To this end,we employ collaborative filtering algorithms, which, despite theirsimplicity, have proven to be effective.",
  "NCF-based PST Model with SciBERT": "We employ the Neural Collaborative Filtering (NCF) model, whichprocesses the features of papers and references separately in twochannels, subsequently computing their mutual similarity as theprediction output. Drawing inspiration from the potential of lan-guage models in text-attributed graphs , we utilize a pre-trainedlanguage model, specifically SciBERT, to process the textual at-tributes of the papers and references. The SciBERT module com-prises 12 BERT layers, each implementing attention and feed-forwardnetwork (FFN) mechanisms. Two separate SciBERT modules encodethe query paper and reference inputs independently, after whichthe [CLS] token representations from the outputs are merged andfed into Multi-Layer Perceptrons (MLPs) to calculate the predictionvalues. The model architecture is depicted as . Denotingthe inputs of query paper and reference as and respectively,the complete process of the model is as follows:",
  "Dataset": "We conduct experiments on the PST dataset provided by the orga-nizer. The text input for the query papers includes the title, abstract,keywords, and the first 500 characters of the body. For the refer-ences, the inputs comprise the title, keywords, and the contextualtext in which each reference appears within the full text. Nega-tive sampling is employed with a positive-to-negative sample ratioof 1:10. From the total of 788 training papers, we construct 8905samples. The dataset is divided into training and validation subsetswith a ratio of 8:2.",
  "Experimental Results": "The model is trained on a NVIDIA A100-PCIE-40GB GPU. The totalnumber of model parameters is approximately 2.3 109. For hyper-parameters, the batch size is set to 16, and the maximum length forboth paper and reference inputs is 512 tokens. The models memoryusage does not exceed 36 GB. We employ the ADAM optimizerwith an initial learning rate of 1 105.We evaluate the final performance of our model using the testdata provided by the organizer. As baseline comparisons, we se-lect the Random Forest, ProNE, and SciBERT methods proposedin . presents the results of various methods evaluatedusing the Mean Average Precision (MAP) metric. Our proposedmodel (NCF-SciBERT) achieves 0.37814 in MAP score, represent-ing a significant improvement over the baselines, with a 28.23%enhancement relative to the best-performing baseline.To demonstrate the significance of textual attributes in the task,we design an ablation experiment by introducing an NCF-id method,which excludes textual attributes and uses only the paper ID asinput. The ablation results shows the text attribute greatly improvethe performance, as shown in . Furthermore, the improve-ment of the NCF-SciBERT model over the SciBERT model alonesuggests that the NCF architecture has a positive impact on the PSTtask.",
  "Conclusion": "In this paper, we formalize the paper source tracing task as a prob-lem within the domain of recommender systems. We integrate theNeural Collaborative Filtering model with a language model, specif-ically SciBERT, by leveraging textual attributes retrieved from thecitation knowledge graph. The experimental results demonstratethat the model achieves a MAP score of 0.37814 on the test dataset,which is a notable improvement over baseline methods and ranking11th among all participating teams. Future work will explore theapplication of graph reasoning techniques to further address thistask. This work was supported by the National Key Research and Devel-opment Program of China under Grant Nos. 2021YFA1000100 and2021YFA1000104, Laboratory Project of Higher Education Institu-tions in Shandong Province-Energy System Intelligent Managementand Policy Simulation Laboratory at China University of Petroleum,and Youth Innovation Team of Higher Education Institutions inShandong Province-Data Intelligence Innovation Team at ChinaUniversity of Petroleum.",
  "KDD CUP 2024 OAG-Challenges, August 2529, 2024, Barcelona, SpainAobo Xu et al": "Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. SciBERT: A Pretrained LanguageModel for Scientific Text. In Proceedings of the 2019 Conference on EmpiricalMethods in Natural Language Processing and the 9th International Joint Conferenceon Natural Language Processing (EMNLP-IJCNLP). 36153620. Zhikai Chen, Haitao Mao, Hang Li, Wei Jin, Hongzhi Wen, Xiaochi Wei,Shuaiqiang Wang, Dawei Yin, Wenqi Fan, Hui Liu, et al. 2024. Exploring thepotential of large language models (llms) in learning on graphs. ACM SIGKDDExplorations Newsletter 25, 2 (2024), 4261. Saeed-Ul Hassan, Anam Akram, and Peter Haddawy. 2017. Identifying importantcitations using contextual information from full text. In 2017 ACM/IEEE jointconference on digital libraries (JCDL). IEEE, 18. Arshad Iqbal, Abdul Shahid, Muhammad Roman, Tanveer Afzal, and Muham-mad Yahya. 2023. Exploiting Contextual Word Embedding for Identification ofImportant Citations: Incorporating Section-Wise Citation Counts and MetadataFeatures. IEEE Access (2023). Shahzad Nazir, Muhammad Asif, Shahbaz Ahmad, Hanan Aljuaid, Rimsha Iftikhar,Zubair Nawaz, and Yazeed Yasin Ghadi. 2022. Important citation identificationby exploding the sentiment analysis and section-wise in-text citation weights.IEEE Access 10 (2022), 8799088000.",
  "Scientometrics 118 (2019), 2143": "Iqra Safder, Momin Ali, Naif Radi Aljohani, Raheel Nawaz, and Saeed-Ul Hassan.2023. Neural machine translation for in-text citation classification. Journal of theAssociation for Information Science and Technology 74, 10 (2023), 12291240. Jie Tang, Jing Zhang, Limin Yao, Juanzi Li, Li Zhang, and Zhong Su. 2008. Ar-netminer: extraction and mining of academic social networks. In Proceedings ofthe 14th ACM SIGKDD international conference on Knowledge discovery and datamining. 990998.",
  "Fanjin Zhang, Kun Cao, Yukuo Cen, Jifan Yu, Da Yin, and Jie Tang. 2024. PST-Bench: Tracing and Benchmarking the Source of Publications. arXiv preprintarXiv:2402.16009 (2024)": "Fanjin Zhang, Shijie Shi, Yifan Zhu, Bo Chen, Yukuo Cen, Jifan Yu, Yelin Chen,Lulu Wang, Qingfei Zhao, Yuqing Cheng, Tianyi Han, Yuwei An, Dan Zhang,Weng Lam Tam, Kun Cao, Yunhe Pang, Xinyu Guan, Huihui Yuan, Jian Song,Xiaoyan Li, Yuxiao Dong, and Jie Tang. 2024. OAG-Bench: A Human-CuratedBenchmark for Academic Graph Mining. In Proceedings of the 30th ACM SIGKDDConference on Knowledge Discovery and Data Mining."
}