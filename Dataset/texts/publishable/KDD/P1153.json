{
  "ABSTRACT": "In this paper, we propose a solution that won the 10th prize in theKDD Cup 2023 Challenge Task 2 (Next Product Recommendationfor Underrepresented Languages/Locales). Our approach involvestwo steps: (i) Identify candidate item sets based on co-visitation, and(ii) Re-ranking the items using LightGBM with locale-independentfeatures, including session-based features and product similarity.The experiment demonstrated that the locale-independent modelperformed consistently well across different test locales, and per-formed even better when incorporating data from other locales intothe training.",
  "Corresponding author.1": "Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDDCup 23, August 09, 2023, Long Beach, USA 2023 Copyright held by the owner/author(s). three tasks. Participants predicted the next item (Tasks 1 and 2) orthe title of the next item (Task 3) to be purchased based on the pre-vious session item set. Our focus is on the next product predictionsolution.SBRS predicts the next item based on the user interaction se-quence. In SBRS, sequential dependencies among the items in asession are highly relevant to recommendation contents . There-fore, SBRS aims to model users short-term and dynamic prefer-ences, unlike collaborative and content-based filtering, which cap-ture long-term preferences . E-commerce is one of the mostpopular cases of SBRS, which identifies a users explored topic andprovides relevant items from numerous number items publishedon a site . SBRS predicts a users preference for the next itembased on a series of user activities, such as clicking, viewing, andpurchasing items on a website . The relationship betweenthese interactions is useful for estimating a users search intentionsand interesting topics . Traditional approaches used in SBRSare based on Markov chains and k-nearest neighbor. Markov chainsmodel the transition relationship between interactions. Rendle etal. and He et al. combined matrix factorization and Markov chains. -nearest neighbor uses the similarity between interactions.Grag et al. proposed STAN , which includes both sequential andtime information. Recent methods are mostly based on recurrentneural network (RNN) because of its advantages in modeling se-quential relationships . GRU4Rec is a representative RNN-based method that introduced Gated Recurrent Units. Quadrana etal. enhanced GRU4Rec by incorporating hierarchical relationshipsacross sessions . In addition, assuming an anonymous user whodoes not log in, some studies have proposed methods that focus ona single session and are not linked to user information .It is important for such a setting to capture the changes in userpreferences and interaction transitions in the shorter term.In this paper, we propose an approach for predicting the nextproduct in a single session. We used Item2Vec similarity andUniversal Sentence Encoder similarity in addition to theco-visitation relations between products, to better capture the tran-sition relationships between products. To handle massive numbersof candidate products, we first extracted several hundred candidateproducts and then re-ranked them using LightGBM.",
  "TASK DESCRIPTION2.1Dataset": "Amazon-M2 dataset consists of two types: user sessions and productattributes. These are multilingual data from six different locales:English (UK), German (DE), Japanese (JP), French (FR), Italian (IT),and Spanish (ES). The statistics of the dataset are presented in . In this paper, we will refer to three locales with sufficient data(DE, JP, and UK) as SL and to other locales with insufficient data(ES, FR, and IT) as IL.User sessions are divided into train and test sessions. Sessions aremade up of locale and chronologically ordered item sets (prev_items)and are not personally identifiable. The length of prev_items is twoor more and different from each session. In the case of train ses-sions, it also has one item next to prev_items (next_item). The testsessions contain no information regarding the next_item. Task 1was the next product prediction for the test sessions of the SL, andTask 2 was for that of the IL. For both tasks, 100 candidate items ofthe next_item were listed for each session.Product attributes include records such as the title, price, andbrand. Participants can use them for recommendations.",
  "Rank()": "where is the test session set, is the length of the set ( = | |),and Rank() is the rank where the ground truth (next_item) appearsin the top- recommended list for the test session (if the top-list does not have the next_item, 1/Rank() = 0). For these tasks, was set to 100.",
  "METHOD3.1Basic Strategy": "The tabular data approach was chosen for this task, that is, weextracted features from sessions and items and built a supervisedmodel to predict whether an item was the next_item or not. Thereason for this choice was that the matrix factorization approach, which is commonly used in recommendation tasks, does not workwell. We believe this is because the data were too sparse to berepresented in 100 or 300 dimensions.The candidate items were selected using the co-visitation fea-tures for each session before training the model. Ideally, we shouldpredict for every session and every item. However, this is too muchto do not only for task 1 with large data, but also for task 2 withrelatively small data.LightGBM was used for binary classification, and the outputprobability for ranking the items was used. If there were fewerthan 100 candidate items, they were added using the Item2Vec andUniversal Sentence Encoder model.An overview of the proposed approach is presented in .",
  "We have four groups of features": "3.2.1Co-Visitation based features. We created multiple versionsof concurrent visits in prev_items; This is not simply the number ofco-occurrences of items A and B (we denote by (, ) ), but thenumber of B after A ( (, ) ), B immediately after A ( (, ) ),and B immediately before A ((, ) ). Of course, we also use co-visitation information, including the next_item. The interaction ofitem A in prev_items and the next_item B are counted in two ways:The count of occurrences where A is in previous items (we denoteby (, ) ) and B is the next_item and that A is the last item inprevious items and B is the next_item ( (, ) ).For example, if a session has A, B, A, C as prev_items and Das next_item, (, ) is added by 2, (, ) is added by 1, (, ) is added by 2, and (, ) is added by 1.Note that the actual calculation was performed by the per-sessioncross-join, not on every item pair. Thus, the calculations are feasi-ble. Note that the same items but different locales were treated asdifferent items.These features are expected to be the numerator of similarity, andthe similarity between all items in prev_items and a candidate itemcan be obtained with a simple data join operation. We narroweddown the calculations to the last few items in the session to limitthe number of columns in the table. For example, limiting it to thelast 10 items means that we obtained 60 similarity features. 3.2.2Item count features. These features are expected to be thedenominators for co-visitation-based similarity discussed above.We simply counted how many times it appeared in prev_items andhow many times it appeared as next_item.Since we took a tabular data approach, for each session and acandidate item, count features for the candidate item and last fewitems extracted from prev_items. 3.2.3Text based similarity. A quick look at the data reveals thatthere are nearly identical products, such as different sizes, differentcolors, and different quantities, and that there are many sessionswhere the next_item is almost the same as one of the prev_items.We must define the similarity between items based on productinformation to take advantage of this property.",
  ": The overview of our approach": "We used the Universal Sentence Encoder (USE) 2 for this; This isbecause we wanted to use language-agnostic features as much aspossible and because we felt the data were not big enough to learnlanguage embedding.Similarity calculation was performed in a simple manner. Com-bining product information strings with the conjunction \":\" andembedding them with USE yields a 512-dimensional vector, and thesimilarity between the two items is defined by the Euclidean innerproduct. 3.2.4SBRS based prediction. We used the Item2Vec model usedin session-based recommendations to capture the relationshipsbetween items across sessions. The models were trained per locale.They were implemented using gensim. The hyper-parameterswere determined for each locale and tuned for the number of vectordimensions and the subsampling thresholds [0.01,0.001, 0.0001]. These values are listed in . Gensim defaultvalues were used for all other parameters.",
  "Cross Validation": "For parameter tuning, we used 5-fold cross-validation (CV) basedon the sequential number of sessions. Simple cross-validation aloneis not enough because some features are created by looking atthe next_item. , , the count features for the next_item, andItem2Vec-based predictions have the potential for severe overfitting,similar to target encoding.To address this issue, these features were calculated outside thefold to which the session belonged; that is, we had five versions foreach feature, and for each record, the version that did not use therecord was used.",
  "Candidates Generation": "Co-Visitation-based features were used in the candidate genera-tion process. All items suggested by one of the co-visitation-basedfeatures were considered candidates. More precisely, item B is acandidate for the session if (, ) > 0 or (, ) > 0 for someitem A in the session.After candidate items were picked, text-based similarity wascomputed between the candidate items and the last 10 items of",
  "DE1000.001JP1000.0001UK1000.0001IT1000.001FR750.001ES1000.0001": "prev_items for each session. That is, we obtained 10 similarityfeatures for each candidate item.Item2Vec-based predictions also suggested items; however, wedecided to simply use them as features because the co-visitation-based features scored much higher. 1) If an item is a candidate inboth methods, the prediction is used as a feature. 2) If an item isa candidate in a co-visitation-based manner and not in Item2Vec-based predictions, null is set. 3) If an item is a candidate in Item2Vec-based predictions and not in a co-visitation-based manner, the itemis not a candidate in the first place. As an exception, if candidateitems are less than 100, Item2Vec-based predictions are used to fillup to 100. If the number of candidate items is still less than 100 afterfilling in the Item2Vec-based predictions, USE-based predictions,which recommend items with high text similarity to the last itemin prev_items, are used to fill up to 100.",
  "EXPERIMENT": "Our primary goal was to improve the score of Task 2, and we appliedthe pre-trained LightGBM model obtained in the process to Task 1.The results of the leaderboard MRR comparison for various trainingdata locales for each task are listed in . (IL + DE) + (IL +JP) + (IL + UK) is an ensemble of IL + DE, IL + JP, and IL + UK.In , the best values are in bold. In Task 2, we can see thatusing data from other SL as training data in addition to IL improvedthe performance by up to 0.88%. The results for IL with only oneof the SL and their ensembles showed no significant change. Incontrast, in Task 1, the results for SL-only were not good, and theIL-only model for Task 2 was better. Applying the same model withlocal-independent features to both tasks got some results, especiallyin Task 2, where we won the 10th place. Furthermore, while theremay be some influence of experimental settings and sampling of",
  "IL0.375840.43718SL0.371130.41827IL + DE0.378930.44008IL + JP0.380100.44007IL + UK0.380550.43996(IL + DE) + (IL + JP) + (IL + UK)0.369750.44007IL + SL0.370650.44101": "candidate items, the result of SL-only and IL-only in Task 1 suggeststhat large training data may not be necessary and that small datatransfers may be enough.The top-20 feature importance of the LightGBM model is pre-sented in . From , it is clear that features of thenew item in prev_items and the similarity features have high im-portance. In addition, item2vec_similarity, which is an SBRS-basedfeature, exhibited a high value.",
  "CONCLUSION": "In this study, we present our solution for the Amazon KDD Cup2023. We propose a completely locale-independent model, whichgenerates a candidate item for a session and predicts whether theitem is the next_item or not, based on four types of features. Theexperimental results demonstrated that incorporating data fromlocales with ample training data into data from locales with limitedtraining data enhanced recommendation accuracy.In future studies, we aim to implement two improvements to oursolution model. Firstly, given the significant number of candidateitems, particularly in Task 1, we plan to explore more efficient meth-ods for narrowing down the selection. This investigation will leadto further enhancement in the systems performance and scalability. Secondly, we intend to enrich the model by incorporating featuresfrom other state-of-the-art session-based recommendation systems(SBRS) like GRU4Rec, as introduced in . By integratingthese features and constructing ensembles based on diverse SBRSmethods, we expect to achieve improved recommendation accuracyand enhanced robustness in our predictions.",
  "Oren Barkan and Noam Koenigstein. 2016. Item2Vec: Neural Item Embeddingfor Collaborative Filtering. (2016). arXiv:1603.04259": "Daniel Cer, Yinfei Yang, Sheng yi Kong, Nan Hua, Nicole Limtiaco, Rhomni St.John, Noah Constant, Mario Guajardo-Cespedes, Steve Yuan, Chris Tar, Yun-Hsuan Sung, Brian Strope, and Ray Kurzweil. 2018. Universal Sentence Encoder.(2018). arXiv:1803.11175 Muthuraman Chidambaram, Yinfei Yang, Daniel Cer, Steve Yuan, Yun-HsuanSung, Brian Strope, and Ray Kurzweil. 2018. Learning Cross-Lingual SentenceRepresentations via a Multi-task Dual-Encoder Model. (2018). arXiv:1810.12836 Diksha Garg, Priyanka Gupta, Pankaj Malhotra, Lovekesh Vig, and Gautam Shroff.2019. Sequence and Time Aware Neighborhood for Session-Based Recommenda-tions: STAN. In Proceedings of the 42nd International ACM SIGIR Conference onResearch and Development in Information Retrieval. 10691072.",
  "Balzs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk.2015. Session-based Recommendations with Recurrent Neural Networks. (2015).arXiv:1511.06939": "Dietmar Jannach and Malte Ludewig. 2017. When Recurrent Neural NetworksMeet the Neighborhood for Session-Based Recommendation. In Proceedings ofthe Eleventh ACM Conference on Recommender Systems. 306310. Wei Jin, Haitao Mao, Zheng Li, Haoming Jiang, Chen Luo, Hongzhi Wen, HaoyuHan, Hanqing Lu, Zhengyang Wang, Ruirui Li, Zhen Li, Monica Xiao Cheng,Rahul Goutam, Haiyang Zhang, Karthik Subbian, Suhang Wang, Yizhou Sun,Jiliang Tang, Bing Yin, and Xianfeng Tang. 2023. Amazon-M2: A MultilingualMulti-locale Shopping Session Dataset for Recommendation and Text Generation.(2023). arXiv:2307.09688",
  "Malte Ludewig and Dietmar Jannach. 2018. Evaluation of Session-Based Recom-mendation Algorithms. 28, 45 (2018), 331390": "Ruihong Qiu, Jingjing Li, Zi Huang, and Hongzhi Yin. 2019. Rethinking theItem Order in Session-based Recommendation with Graph Neural Networks.In Proceedings of the 28th ACM International Conference on Information andKnowledge Management,CIKM 2019, Beijing, China, November 3-7, 2019. 579588. Massimo Quadrana, Alexandros Karatzoglou, Balzs Hidasi, and Paolo Cremonesi.2017. Personalizing Session-Based Recommendations with Hierarchical Recur-rent Neural Networks. In Proceedings of the Eleventh ACM Conference on Recom-mender Systems. 130137. Steffen Rendle, Christoph Freudenthaler, and Lars Schmidt-Thieme. 2010. Factoriz-ing Personalized Markov Chains for Next-basket Recommendation. In Proceedingsof the 19th International Conference on World Wide Web. 811820."
}