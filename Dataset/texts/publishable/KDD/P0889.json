{
  "Duen Horng ChauGeorgia TechAtlanta, GA, USA": ": Our method, Nested Fusion, radically accelerates the exploratory analysis of nested measurement datasets by learningthe latent structure at high resolution to produce distributions of phenomena at a greater fidelity and scientific impactfulnessthan previous approaches. In the figure the DOURBES target location is shown, out of over a hundred locations on Mars scannedby the Perseverance Rover at the time of writing.",
  "ABSTRACT": "The Mars Perseverance Rover represents a generational changein the scale of measurements that can be taken on Mars, howeverthis increased resolution introduces new challenges for techniquesin exploratory data analysis. The multiple different instrumentson the rover each measures specific properties of interest to sci-entists, so analyzing how underlying phenomena affect multipledifferent instruments together is important to understand the full Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08. picture. However each instrument has a unique resolution, mak-ing the mapping between overlapping layers of data non-trivial.In this work, we introduce Nested Fusion, a method to combinearbitrarily layered datasets of different resolutions and produce alatent distribution at the highest possible resolution, encodingcomplex interrelationships between different measurements andscales. Our method is efficient for large datasets, can perform in-ference even on unseen data, and outperforms existing methods ofdimensionality reduction and latent analysis on real-world Marsrover data. We have deployed our method Nested Fusion within aMars science team at NASA Jet Propulsion Laboratory (JPL) andthrough multiple rounds of participatory design enabled greatlyenhanced exploratory analysis workflows for real scientists. Toensure the reproducibility of our work we have open sourced ourcode on GitHub at",
  "Latent Representation Learning, Dimensionality Reduction, DataVisualization, Planetary Science": "ACM Reference Format:Austin P. Wright, Scott Davidoff, and Duen Horng Chau. 2024. NestedFusion: A Method for Learning High Resolution Latent Structure of Multi-Scale Measurement Data on Mars. In Proceedings of the 30th ACM SIGKDDConference on Knowledge Discovery and Data Mining (KDD 24), August2529, 2024, Barcelona, Spain. ACM, New York, NY, USA, 11 pages.",
  "INTRODUCTION": "In scientific data analysis the initial exploratory phase of visualizingand conceptualizing the relevant empirical phenomena in a datasetis both an essential aspect for effective work and comparatively un-der studied in the context of scientific applications, where skippingsuch inductive explorations in favor of immediately utilizing knownmodels for analysis is the de facto standard. However, recent workhas shown how unanticipated or anomalous phenomena can oftenmislead such analysis, motivating a workflow that at least startswith purely empirical exploration of data in the initial phases ofwork after making measurements in order to have a more informedprior of the distribution of actual phenomena within a dataset be-fore applying the more rigorous scientific models to ensure thechosen models are appropriate . While common data-centrictechniques of exploratory analysis such as dimensionality reduc-tion visualization have proven to be very effective in many domainsof scientific inquiry , in domainswith multiple measurement apparatuses of different resolutions andscales, existing techniques can fail to model some of the phenomenawe wish to discover. This is because the standard formalization fordimensionality reduction techniques is that of a single dataset ofmeasurements of identical shape which corresponds one to onewith the set of objects and patterns between objects that the analy-sis aims to visualize. However it is often the case that underlyingphenomena are differentiated at levels that do not align with theresolutions of measurement each apparatus perfectly . Rather,there may be multiple methods of measurement which each elu-cidate different aspects of an underlying structure but which allhave varying resolution scales and thus are sensitive to the differentproperties of various aggregations of the structure.One such domain where scientists require more powerful ex-ploratory analysis tools is the work done by the PIXL Science teamwith the Mars Perseverance Rover at NASA (National Aeronau-tics and Space Administration). In service of the high-level goalof searching for signs of a history of life on Mars, scientists areinterested in the fine-grain mineral structure of target locationson the Martian surface . The Perseverance Rover contains two(among many) scientific instruments to assist in this task: the Plan-etary Instrument for X-ray Lithochemistry (PIXL) instrument , which includes an X-ray fluorescence (XRF) spectrometer, and aMicro-Context Camera (MCC) for multi-spectral imaging. Whenobserving a specific target location of geological interest, the roverwill use both of these instruments to conduct two co-aligned scansas shown in . While both of the instruments scan over thesame physical location, their resolutions are much different, wherefor each scan point, a single XRF spectrum corresponds to a largerpatch of approximately 100 MCC imaging pixels. At the same time,each instrument elucidates different aspects of the underlying min-eralogy of the target. While the spatial precision of each MCC pixelcorresponds much more closely to individual homogeneous min-eral grains, it lacks a nuanced depth of information to accuratelydifferentiate minerals based on chemistry. On the other hand, eachXRF spectrum produces a detailed quantified distribution of thechemical composition of the scan point, but the larger diameterof this point may encompass multiple grains of different mineralsthus producing an aggregate chemical distribution. The ultimatescientific question is about understanding the distribution of under-lying minerals. While both measurements offer extremely powerfulsignals concerning this distribution, neither alone encompasses allthe possible information to explore, leading to the need for mod-eling these different measurement scales together. To tackle thesesignificant scientific challenges, we present the following majorcontributions: (1) A novel problem formulation tailored to exploratory analy-sis of nested measurement datasets, which consist of irregularlyoverlapping measurements of multiple scales (Sec 3.1). Thisformulation is rooted in addressing the practical needs of PIXLscientists at NASA who analyze XRF and MCC data collectedby the Mars Perseverance Rover. (2) The Nested Fusion algorithm, a new model for latent anal-ysis and dimensionality reduction for nested measurementdatasets (Sec 3.2), This method is significantly more effectivethan alternatives, yielding latent encodings at a resolution farhigher than what existing dimensionality reduction techniquescan achieve. We evaluate the effectiveness of Nested Fusionboth qualitatively within the context of initial data explorationand quantitatively in data reconstruction fidelity. Nested Fusionoutperforms the state of the art in dimensionality reductionfor nested measurement datasets, providing more interpretableand practically useful results (Sec 4). (3) Deployment of Nested Fusion in scientific practice withinthe PIXL team for the Mars Perseverance Rover, enabling scien-tifically meaningful visual interpretation and efficient discov-ery of cross-modal patterns (Sec 5). We analyze how NestedFusion is utilized in practice and how it fits within the sci-entists existing analytic workflows. To ensure reproducibil-ity of our technique and findings, we have open-sourced it at",
  "Mars Perseverance PIXL Data": "The PIXL instrument aims to measure the mineral structure of smallrock samples (called targets) on the surface of Mars contributing to-ward the larger inquiry towards any potential evidence of a historyof life on Mars. For each individual target on the martian surfacemultiple scans are taken. First is the MCC Multi-spectral imagingcamera, which takes a series of four images illuminated by specificwavelengths of near-visible light: Near-Infrared (NIR), Green, Blue,and Ultraviolet (UV). This produces a single color image for eachtarget with 4 primary channels, as opposed to the standard 3 chan-nel RGB, and is often analysed using the 16 distinct ratios betweenthem. Each image will contain on average about 500,000 of these16 channel pixels, spanning a region of approximately 100 squarecentimeters with each pixel corresponding to a resolution of approx-imately 15 microns. At roughly the same time a scan is taken of thesame target with the PIXL instrument for X-Ray spectroscopy. Thisinstrument produces much more detailed quantitative data, consist-ing of a grid of X-Ray fluorescence spectra which are quantified torepresent the distribution of elemental weight percentages at eachscan point, we call this distribution a quantification. Each scan canconsist of between 1000 and 10,000 individual spectra (dependingon the particular shape of the target) covering a smaller region ofapproximately 30 square millimeters. Each scan point is measuredwith a beam diameter of 50-200 microns1, thus corresponding to aregion covering approximately 100 MCC pixels as shown in .Thus far, at the time of writing, during the time that the Perse-verance Rover has been in operation, there have been 103 targetlocations scanned producing a total of 295,602 52-dimensional (thenumber of unique elements included in all quantifications) quan-tified spectra, as well as 26,966,169 MCC pixels. However, not allscans include both data types and so for this work focusing oncombining information from both measurements, we are restrict-ing to a total of 103,005 scan points which each contain a singlequantification as well as 100 corresponding MCC pixels.",
  "Related Work": "Previous work in collaboration with PIXL scientists has shownhow data science techniques can form an essential componentof their scientific workflow by focusing specifically on modelinganomalies and visualizing distinct empirical phenomena. Thiswork focuses on the problem of initial visualization and thus ondimensionality reduction as an effective technique for enablingsuch visualization for the high dimensional PIXL data.Dimensionality reduction techniques such as UMAP , T-SNE , MDS , Isomap , and the most commonly usedPCA are fairly ubiquitous in a variety of scientific domains, and even specifically XRF spectroscopy , aswell as Mars multi-spectral imaging. 1This beam diameter is energy dependent and since there is a nonlinear transforma-tion between the energy levels of the spectrum and the final quantified elementaldistribution where each element is quantified using the full energy range, we treatthe upper range of the beam diameters as representing the region encompassed in aquantified scan point. Another conceptualization that can produce comparable visu-alizations is the approach of latent analysis which takes a more,generally Bayesian, probabilistic framework to the problem of learn-ing low dimensional representations. These approaches mostly stemfrom the development of variational autoencoders (VAE) , anddifferent latent models have been introduced to handle many sci-entific problems including planetary science amongmany other domains.",
  "PROPOSED METHOD: NESTED FUSION": "Grounded in understanding from previous work with PIXL sci-entists our aim is to develop a method for visualizing anddetermining the distribution of mineral phenomena within eachPIXL target, and to assist in their identification based on their rela-tionship between the past history of targets. Focusing on targetswhere both XRF and MCC data are present and overlapping, wehope to enable work to discover new patterns that each individualinstrument cannot differentiate independently. While scientific in-terpretation is the end goal, the specific interpretations (i.e., wesee a grain of olivine here or a potential aqueous intrusion there)enabled by the method are out of the scope of this work. Thereforewe introduce a precise formalized problem statement which aimsto properly encode the scientific priors and goals of the problemwith specific consideration to the non-standard mixed scale mea-surements present in PIXL data, while simultaneously laying thefoundation for how such methods can be more easily generalizedto new domains. Finally after introducing the problem formulationwe will describe our proposed method, Nested Fusion, which looksto solve this problem.",
  "Problem Formalization of NestedMeasurements": "As shows the nested hierarchical structure of PIXL datais not immediately amenable to standard data science techniquesbarring some flattening operation which leads to over aggregationand loss of resolution (see Joint Models in .3). Thus weintroduce a formalization of nested measurement datasets whichwe will use to model this structure and subsequently perform betteranalysis on the data in a more natural manner, while also outliningprecisely the requirements that any other dataset must meet in orderto utilize the methods introduced in in other domains. summarizes the notations and terminology introduced inthis section and used throughout this paper.We recursively define a nested measurement dataset as consist-ing of a tuple of two components: = (,). The first component = { R}=1 is simply a standard dataset of independentand identically distributed samples of dimensional data repre-senting the particular measurements at some specific scale. Then is what we define as the nested scale. The nested scale is a tuple(,) of another nested measurement dataset = ( ,) aswell as a nesting function ( : 2 ) which maps each datapoint in to a set of corresponding data points in that coverthe same underlying physical and latent area. In order to terminatethis regress there must be a final scale which has no furthernested scale and thus is notated as . Having no further nestedscale means that is the highest resolution available in the nested",
  "Nesting Function ()A function which maps a specific data point at a scale to the set of data points in the correspondingnested scale that cover the same physical space": "Maximum Resolution Latent Scale()The scale for which no further nested scales exist, defining the highest resolution available in thedataset and thus the resolution at which latent structure can be modeled Latent Base Scale Correspondence()A function which maps a specific data point at any scale to the set of data points at the maximumresolution latent scale that cover the same space as defined by repeated nesting.",
  ": Notations and terminology used in this paper": "measurement dataset, and so we refer to it as the maximum reso-lution latent scale since our aim to model latent structure at thismaximum resolution.The key assumption is that all of the information at lower res-olution scales supervenes on latent information at the maximumresolution. That is, that there is some more basic structure under-lying the dataset that is approximately modeled at the maximumresolution as an unobserved latent variable, where each sample is generated from a random process involving the latentvalue that has a prior probability distribution (), producingsome conditional distribution (|) that we aim to learn2. Forall other scale samples with nesting function we then define the correspondence which returns the set of all latents at the basemaximum resolution that correspond to a sample :",
  "( )()(2)": "The supervenience assumption then can be restated probabilisti-cally that all lower resolution scale variables are generated fromthe conditional distributions (|()), and thus are conditionallyindependent of measurements at any scale other than the maxi-mum. This structure is outlined in the graphical model for the PIXLdataset in .While seemingly fairly abstract and obscure, this underlyingstructure and supervenience assumptions of a nested measurementdataset is in fact pervasive in the sciences . The natural sciencesin particular commonly share the physicalist reduction assump-tion (at least within a single domain), that any given compositeobject of study is fully reducible to the set of underlying physical",
  "Note for notation, we include indices for actual measurement samples, while notincluding indices when referring to the random variable that generates the samples": "objects of which it is composed . This assumption necessi-tates that if multiple kinds of measurement apparatus measure anoverlapping subject in time and space, then there must be somecorrespondence relation between the two measurement modalities.Furthermore this assumption enables us to study the intersectionsbetween these different layers of composed abstraction, as eachclass of composite structure is often best observed using separatekinds of measurement that very often do not have perfectly alignedscale and resolution. More complex composite structures will tendto exhibit additional complexity and depth (note the high dimen-sionality of the PIXL quantified spectra) however at the expenseof necessarily being more spatially diffuse. While higher resolu-tion measurements may be possible at the expense of more limiteddepth.3",
  "The Nested Fusion Algorithm": "The previous section describes the formalized problem of learn-ing latent maximum resolution scale variables from nested data.One important aspect to note when introducing our solution isthat the formulation of the latent variables at this scale is itself al-ready a modeling approximation. In reality we expect fundamentalstructures within a domain to exist at finer scales than are directlyaccessible, and so we simply use the highest resolution availablein any given nested measurement dataset as a proxy scale for atrue latent . What this lends support to is the use of variationalinference as a method to efficiently learn approximate distributionsof , which is acceptable as we do not in general actually havestrong enough priors about the structure and properties of a true to justify other methods which have significant computational",
  "Nested Fusion: A Method for Learning High Resolution Latent Structure of Multi-Scale Measurement Data on MarsKDD 24, August 2529, 2024, Barcelona, Spain": "Hernandez, E. Hertzberg, R.P. Hodyss, J.R. Holden, C. Hummel, M.A. Jadusingh,J.L. Jrgensen, J.H. Kawamura, A. Kitiyakara, K. Kozaczek, J.L. Lambert, P.R.Lawson, Y. Liu, K.M. Macneal, McLennan. S., P. McNally, P.L. Meras, J. Napoli, B.J.Naylor, P. Nemere, N. Pootrakul, R.A. Romero, R. Rosas, J. Sachs, M.E. Schein, T.P.Setterfield, V. Singh, E. Song, M.M. Soria, N.R. Tallarida, D.R. Thompson, M.M.Tice, L. Timmermann, V. Torossian, A. Treiman, S. Tsai, K. Uckert, J. Villalvazo,M. Wang, D.W. Wilson, S.C. Worel, P. Zamani, M. Zappe, and R. Zimmerman.2020. PIXL: Planetary instrument for X-ray lithochemistry. Space Science Reviews216, 8 (2020), 1132. Frederik Otzen Bagger, Savvas Kinalis, and Nicolas Rapin. 2019. BloodSpot: adatabase of healthy and malignant haematopoiesis updated with purified andsingle cell mRNA sequencing profiles. Nucleic acids research 47, D1 (2019), D881D885. Etienne Becht, Leland McInnes, John Healy, Charles-Antoine Dutertre, Im-manuel WH Kwok, Lai Guan Ng, Florent Ginhoux, and Evan W Newell. 2019.Dimensionality reduction for visualizing single-cell data using UMAP. Naturebiotechnology 37, 1 (2019), 3844. Eli Bingham, Jonathan P. Chen, Martin Jankowiak, Fritz Obermeyer, NeerajPradhan, Theofanis Karaletsos, Rohit Singh, Paul Szerlip, Paul Horsfall, andNoah D. Goodman. 2018. Pyro: Deep Universal Probabilistic Programming.Journal of Machine Learning Research (2018). Ingo Brigandt and Alan Love. 2023. Reductionism in Biology. In The StanfordEncyclopedia of Philosophy (Summer 2023 ed.), Edward N. Zalta and Uri Nodelman(Eds.). Metaphysics Research Lab, Stanford University. Carl Craver and James Tabery. 2023. Mechanisms in Science. In The StanfordEncyclopedia of Philosophy (Fall 2023 ed.), Edward N. Zalta and Uri Nodelman(Eds.). Metaphysics Research Lab, Stanford University. Kenneth A. Farley, Kenneth H. Williford, Kathryn M. Stack, Rohit Bhartia, AlChen, Manuel de la Torre, Kevin Hand, Yulia Goreva, Christopher D. K. Herd, Ri-cardo Hueso, Yang Liu, Justin N. Maki, German Martinez, Robert C. Moeller, AdamNelessen, Claire E. Newman, Daniel Nunes, Adrian Ponce, Nicole Spanovich,Peter A. Willis, Luther W. Beegle, James F. Bell, Adrian J. Brown, Svein-ErikHamran, Joel A. Hurowitz, Sylvestre Maurice, David A. Paige, Jose A. Rodriguez-Manfredi, Mitch Schulte, and Roger C. Wiens. 2020. Mars 2020 Mission Overview.Space Science Reviews 216, 8 (03 Dec 2020), 142.",
  "()()(4)": "Once a sequence of tokens is generated this sequence is passedinto some sequence-to-sequence encoder model which outputsa sequence of corresponding estimated latent parameterizationmeans and variances. However only the output positions actuallycorresponding to inputs are then taken to sample a latent fromthe reparamtetrized distribution N (, ).For decoding, remember the conditional distribution for datapoints defined as (|()). Thus, what is required for decoding isa unique model for each scale in , where a model either takes asinput a single latent in the case of the maximum resolution scale ora set of latents as defined by the correspondence set . For the latentscale decoder, a simple multi-layer perceptron is an appropriatearchitecture, while for the higher levels needing to decode sets oflatents we can use transformers . Importantly, in order to theprevent the potential pitfall of the model merely using positionalinformation to encode information only used in the aggregate de-coding step not corresponding to the actual specific latent at eachpoint, our approach uses a transformer without positional embed-dings in this step as they are order invariant, thus ensuring that the",
  "KDD 24, August 2529, 2024, Barcelona, SpainAustin P. Wright, Scott Davidoff, and Duen Horng Chau": "full distribution of latents, rather than a few arbitrary picked outlatents, properly encodes lower resolution aggregate information.Finally, given the encoder and decoder models, as well as thelatent prior distributions, the models are trained using stochasticvariational inference on the evidence lower bound as is standardfor a VAE based architecture; implemented in our case usingthe probabilistic programming framework, Pyro.To evaluate our method of Nested Fusion we test the model per-formance on the real, large-scale Mars Perseverance PIXL datasetintroduced in .1 comparing to existing dimensionality re-duction and latent analysis techniques. As analysis of this uniquedataset representing the frontier of Mars exploration is the raisondtre for this work as a whole, we specifically focus on evaluationwith direct relevance towards the scientific goals and capabilitiesof scientists actively working at NASA JPL and around the globeon this data.First, in order to utilize nested fusion we have to define therelevant nested measurement dataset formulation for the PIXLdataset, which we define as:",
  ":= (, ((, ),))(5)": "This includes which consists of 103,005 of quantified spectrawhich are represented as 52 dimensional non-negative real valuedvectors whose elements are the elemental weight percentage valuesproduced from PIXL XRF scan points. Here is the set of 1,983,506MCC multispectral imaging pixels which are 16 dimensional non-negative real valued vectors6. Finally we have which is thenesting function of XRF scan points to corresponding pixels. Thisis generated by utilizing the known range of XRF beam diametersof the PIXL instrument being approximately 150 microns, as wellas the calibrated location alignment of MCC images with XRF scanpoints. This alignment allows us to have a shared coordinate systemand thus calculate physical distance between scan-point centroidsand MCC pixels. Thus we can define the nesting function to selectall pixels within 75 microns of an XRF scan point, which results inthe 100 pixel aggregations previously discussed:",
  "Comparing with Alternative Models": "To demonstrate the effectiveness of Nested Fusion, we compare itwith alternative dimensionality reduction models that can combineboth scales of data. Since this problem is non-standard we mustintroduce the set of alternative models that allows utilization ofexisting methods to our problem. We categorize these models intothree types based on how they handle the nested structure of thePIXL nested measurement dataset, Nested Fusion (our method),Concatenative Models, and Joint Models. We describe these three 6This number is less than what you would expect given that each scan point with aquantification covers an area of 100 pixels, however in reality many of these areasoverlap, meaning the same pixel can be included in multiple different scan points.Our formalization of nested measurement datasets allows this without issue and infact it is preferred to strict partitioning as we can better models the actual resolutionof dependency for each measurement. The only issue occurs when converting backinto physical space such as with the color plot from . We address this bysimply averaging the multiple produced pixel level decoded inferences for overlappingpixels, however introducing more sophisticated techniques of dis-aggregation is a verypromising direction for future work classes of models in using the language of Bayesian graph-ical models, which illustrates how these classes encompass a fulltaxonomy of problem conceptualizations for nested measurementdatasets7. However within each of these classes any particularmodel type (e.g., UMAP or VAE) can be used. For our comparisonswe took both alternative modeling frameworks and for each trainedthree representative models. First representing the most commonapproach to dimensionality reduction used ubiquitously in practiseis Principle Component Analysis (PCA). Then to represent state ofthe art dimensionality reduction we used UMAP over t-SNEas it provides state of the art performance, has a well documentedhistory of applications in science, and is among the techniquesleast sensitive to hyperparameters, and is much more computa-tionally efficient for our scale of data. Finally we also trained avariational autoencoder to represent the most standard approach togenerative latent analysis. Since Nested Fusion and the variationalautoencoder methods are agnostic to the specific neural networksizes and architectures used, for our evaluation we trained multiplenetworks using simple multi-layer perceptron models (with theexception of using a transformer encoder for the Nested Fusiondecoding step as described in ) with hidden layer sizesfrom 64 to 256 and a number of hidden layers from 4 to 16 andselected the best-performing models at each latent dimensionality.Nested Fusions open-source repository provides the pretrainedtested models at Thesemethods together cover the most common latent analysis and di-mensionality reduction techniques used in practice, including bothparametric and non-parametric methods. Furthermore, as PIXL sci-entists are the ultimate users who visualize the latents in 1-, 2-, and3- dimensions we compare Nested Fusion with these alternativesat such dimensions. Joint Models. The first class of alternative model we will considerare joint models which attempt to model the joint distribution ofa low resolution data point and its entire corresponding nestedscales in a single latent. For the PIXL dataset we can describe thisframework as trying to find a single latent for each XRF scan point:",
  ". ( , ( ))(7)": "Concatenative Models. The other class of model considered areconcatenative models, where each high resolution data point is usedas the latent scale, and lower resolution corresponding measure-ments are simply concatenated to the high resolution sample vector.For PIXL we describe this as taking each XRF scan quantificationand duplicating it and concatenating on top of each individual MCCpixel and using this to learn a high resolution latent:",
  "EVALUATION:NESTED FUSION EFFECTIVENESS4.1Conceptual Drawbacks of AlternativeMethods Compared to Nested Fusion": "Despite covering the full set of possible alternative approaches(given the nested measurement dataset framework), each of thesemethod classes has substantial conceptual drawbacks, illustratedin . A joint model has a much more difficult encoding taskwhere each latent value is overloaded with encoding the wholeset of ( ) making fidelity with low latent dimensionality verydifficult. Furthermore it will also only produce a latent at the lowestpossible resolution, the exact opposite of the high resolution latentsin Nested Fusion. Concatentative models can perform somewhatbetter, as they produce latents as similarly high resolution to Nested Fusion. However the concatenative method of combining layerserases all scale contextualization of each high resolution data point,thus encoders and decoders do not have access to more complexdistributional information within each nesting scale, which poten-tially can have an effect on the accuracy of final low resolutionestimates when such information is important. For instance, if weconsider a case where two scan points includes the same kindsof minerals but in different proportion, this will affect the valuesof and in such a way that any concatenative model mustnecessarily produce different embeddings even for the exact samekind of mineral! This false encoding of the confounding distribu-tional information on the individual scale is inextricable from theconcatenative method. However since Nested Fusion has accessto this distributional information for its encoder and decoder, inprinciple it could learn something close to a true embedding which",
  "Qualitative Evaluation": "It is important to restate that the success or failure of any of thepresented latent analysis and dimensionality reduction techniquesis determined entirely within the context of their actual use, forthe purposes of this paper being in their application within PIXLscience. Previous work has outlined the basic structure of how ma-chine learning techniques have been successfully applied withinthe PIXL science team, by enabling an iterative semantic phenom-ena modeling process that helps scientists map out the spaceof considerations before continuing with standard domain model-ing. Therefore we begin our evaluation of the different methods oflatent analysis at the same point that PIXL scientists begin theiranalysis by visualizing the resultant latent distributions producedby each method directly, as two dimensional heatmaps, in orderto try to discover the distinct phenomena to consider in their latermodeling. shows the output of each of the methods appliedto the Dourbes target from . Specifically, for such a twodimensional heatmap plot of the latents scientists expect to seea small number of distinguishable regularities which can eitherbe regions visualized in the heatmap as distinct areas of higherdensity in bright green or as separable clusters which need notbe high density but otherwise must be otherwise identifiable as astandalone feature to consider.In , notice how all of the joint methods (right column)learn a comparatively small set of regularities, each showing onlythree distinct modes. While this regularity and differentiability iscertainly a positive, we know from previous authoritative analysison this specific target that there are at least more than threerelevant phenomena that must be distinguished and so we havereasonably high confidence that these representations are overlyabstracting. The high resolution methods (left column) are morevaried. Concatenative VAE, like the joint models, produces threeprimary clusters, while Concatenative PCA encodes a continuousglobal structure with limited local differentiation, which in thiscontext makes mineral identification much more difficult. Finallyconcatenative UMAP produces an extremely complex distributionwhich shows no consistent high-density regions. Like a Rorschachinkblot, such complexity cannot serve as a reliable basis for buildingtrustworthy shared interpretations between scientists focused onfinding specific, repeatable, and understandable regularities. Indeed,the UMAP visualization produced in this context is perhaps the leastscientifically helpful of all the options for PIXL scientists working onmineral identifications. Finally, we see that Nested Fusion (top left)produces the most distinguishable structure consisting of two largehigh-density regions on the left (which each are themselves clearlycomposed of a mixture of multiple overlapping but non-identicalmodes) accompanied by two more lower-density clusters on theright and another on the left. The distribution produced by NestedFusion matches the scientific priors much more closely, where areasonable number (more than three and less than a few hundred) : Comparison of 2D Latent Distributions from dif-ferent methods applied to Dourbes target (RGB map of MCCImage shown in top right). Axes are unitless latent values.High resolution models (left column: Nested Fusion and con-catenative models ) displayed with 300 bins across each axis,while low resolution joint models (right column) has 200 binsdue to the differing number of samples in each model type. of identifiable regularities likely corresponding with minerals canbe clearly seen.To further explore this effect, we compare the latent sub dis-tributions of the highest performing methods (UMAP and NestedFusion) when selecting known mineral grains to see the reliabilityof how well the latent space can be used to identify minerals. Based",
  "Quantitative Evaluation": "Besides the qualitative properties of the distributions that makethem practically scientifically useful, PIXL scientists also requirethat the latent models are trustworthy enough in retaining mostof the meaningful information present in the underlying data, andsince we do not know a-priori what is or is not meaningful we mustensure that a representation retains as much information as possibleabout the original data to reconstruct it completely. Good fidelitythen is a necessary but not sufficient condition for effective utiliza-tion, in particular considering the fidelity of quantifications whichscientists trust as more authoritative when grounding mineral iden-tification. Thus, we compare Nested Fusion with alternative modelsusing reconstruction fidelity, a standard metric in evaluating auto-encoding models, to quantify how much information is preservedin the latent encodings. For each model we calculate the coefficientof determination 2 for both as well as reconstructions in.Our results show that Nested Fusion significantly outperformsall joint models (Joint VAE, Joint UMAP, and Joint PCA) at eachreduced latent dimensionality used by PIXL scientists. This is ex-pected, as explained .1, because the same dimensionallatent values are tasked with a much greater amount of encodingand thus would be expected to perform worse at the low dimension-alities tested, and it confirms the observations from the qualitativeevaluation that important information is likely being lost in the en-coding. Concatenative models however tend to perform relativelybetter in these metrics. Among the concatenative models, concate-native PCA performs universally worst across all metrics, which isnot surprising due to PCA being a linear model with limited model-ing capacity. Concatenative VAE and UMAP both perform similarlyin reconstructing the imaging layer as effectively as Nested Fusion. : Comparison of Nested Fusion and ConcatenativeUMAP wit latent dimension 2 in differentiating distinct min-erals in the Dourbes target. In green is shown a region of thetarget identified as Pyroxene while in red is a region iden-tified as Olivine based on existing analysis. Comparingthe latent sub-distributions of these two samples, Nested Fu-sion produces a distribution which has a greater degree ofseparation between the different minerals. However, this layer contributes significantly less towards buildingtrust for scientific interpretations as a standalone measurement butis most effective only when augmented with the more solid sourceof scientific semantic grounding in the XRF quantifications. Whenconsidering then the quantification reconstructions, what we find isthat as predicted in .1 Nested Fusion significantly outper-forms concatenative VAE in reconstructing the XRF quantificationlayer. Finally, concantenative UMAPs reconstruction fidelityis lower but comparable to Nested Fusions however, given theother significant drawback of UMAPs inability to use this accu-racy to practically assist in scientific exploration, its reconstructionperformance is essentially irrelevant.In summary, Nested Fusion attains higher reconstruction fidelitythan the state of the art in dimensionality reduction and latentmodeling while producing substantially more useful latent codesfor scientific analysis.",
  "Concatenative VAE0.890.810.940.900.990.93Concatenative PCA0.870.020.880.470.890.65Concatenative UMAP--0.960.960.980.97": ": Model reconstruction fidelity, measured as recon-struction fidelity 2 values for both the MCC imaging layer (denoted as 2) and the XRF quantification layer (de-onted as 2) for latent dimensions of 1,2, and 3 needed byPIXL scientists. Nested Fusion outperforms all models acrossall latent dimensions on 2 (highlighted in bold font), thecrucial metric used by PIXL scientists when assessing thescientific trustworthiness of methods.",
  "SCIENTIFIC DEPLOYMENT AND IMPACT": "The ultimate importance of Nested Fusion is not found in its evalu-ation metrics but in its ability to have scientific impact by assist-ing PIXL scientists in visualizing and exploring combinations ofdatasets they simply could not easily or efficiently do otherwise.Towards this end, we deployed Nested Fusion in multiple capaci-ties within the PIXL science team. The primary method thus farscientists have been able to utilize Nested Fusion is through itsstandalone implementation which is now open source at This implementation directlyworks on existing and continuously incoming PIXL data, and pre-trained models are also available. Pre-trained models include multi-ple different latent dimensionalities as well as models that includelatent categorical class assignments that have the latent prior dis-tribution being a sample of some latent class from a Dirichlet prioras well as a regular continuous latent code vector which allowsthe model to differentiate automatically seemingly categoricallydistinct regions.With this implementation, PIXL scientists are able to easily visu-alize the distribution of multiple kinds of latent encodings acrossmany targets at once. PIXL scientists choose to visualize these dis-tributions in a number of ways, including direct distributions inlatent space (see ) as well as visualizing various mappingsinto color overlaying the target image such as the plot in .These two methods together allow scientists to see both abstract aswell as spatial patterns and regularities in the data. These visualiza-tion techniques help PIXL scientists firstly discover quick heuristicunderstandings of the distribution of empirical phenomena presentin a single target as well as commonalities in phenomena acrossmultiple targets.Through participatory design sessions over 6 months with nearlya dozen scientists, we have discovered a primary (though not ex-clusive) workflow that Nested Fusion enables within the contextof exploratory data analysis. When a new dataset is generated, theprocess by which PIXL scientists begin to come to a consensus on itsmineral composition is highly iterative, involving bringing forwardvarious hypotheses and then coming up with ways to test these hypotheses given the data. The mechanics of how a hypothesis istested can be complex and difficult, and so a method that couldassist in having a more informed starting position in this iterationcan greatly increase the efficiency of the whole process, saving ahuge amount of extremely valuable and limited time. By forming alatent space over the whole history of PIXL data, and an encoderthat can efficiently process this new data before having to retrain,new data can be quickly visualized and broken down into a fewkey regularities which can be compared to historical precedent ofregions or even individual grains which bare a strong resemblanceto regions or grains in the new dataset. This then helps to forma better initial assessment of the minerals present at a target andthus substantially speed up the overall identification process. Thistransforms the workflow of initial exploratory analysis, which his-torically would take the roughly 10-person team of spectroscopistsapproximately 21 days in collaboration to come to an initial deter-mination of minerals into one which a single scientist can generateinstantly a latent distribution and through refinement generate anidentification of comparable quality in a matter of hours.We found how the combination of the high fidelity of NestedFusion along with its computational efficiency at inference timewere both essential components compared to existing or alternativemodels to achieve buy-in by scientists. Furthermore we found thatnon-parametric alternative methods such as UMAP proved to beineffective despite competitive fidelity due to the inability to formdistributions for new data efficiently and producing distributionsthat are difficult or impossible to reliably interpret within the con-text of looking to understand specific phenomena, and thus doesnot help solve the scientific workflow problem that Nested Fusionaddresses.Nested Fusion provides a fundamentally new way for PIXL scien-tists to quickly visualize distributions of phenomena that span mul-tiple measurement types and scales and thus explore new data moreefficiently and effectively than was previously possible. This hasprovided a lesson for any interested applied data scientist: increas-ing the alignment between machine learning problem statementand scientific problem ontology, in this case by more accuratelymodeling multiple scale relationships, is an absolutely essentialcomponent of achieving genuine impact with these tools. There-fore we hope that future work will continue to develop ways inwhich we can improve the very frame from which we pose datascience problems just as much as improving the methods for howwe solve them, in order to make sure we can not only do betterdata science, but just do great science.",
  "This research was carried out in part at the Jet Propulsion Labora-tory, California Institute of Technology, under a contract with theNational Aeronautics and Space Administration (80NM0018D0004)": "Abigail C Allwood, Lawrence A Wade, Marc C Foote, William Timothy Elam,Joel A Hurowitz, Steven Battel, Douglas E Dawson, Robert W Denise, Eric M Ek,Martin S Gilbert, M.E. King, C.C. Liebe, T. Parker, D.A.K. Pedersen, D.P. Randall,R.F. Sharrow, M.E. Sondheim, G. Allen, K. Arnett, M.H. Au, C. Basset, M. Benn, J.C.Bousman, R.J. Calvet, L. Cinquini, B. Clark, S. Conaby, H.A. Conley, S. Davidoff, J.Delaney, T. Denver, E. Diaz, G.B. Doran, J. Ervin, M. Evans, D.O. Flannery, N. Gao,J. Gross, J. Grotzinger, B. Hannah, J.T. Harris, C.M. Harris, C.M. Heirwegh, C.",
  "Leland McInnes, John Healy, and James Melville. 2020.UMAP: Uni-form Manifold Approximation and Projection for Dimension Reduction.arXiv:1802.03426 [stat.ML]": "Karolyn A Oetjen, Katherine E Lindblad, Meghali Goswami, Gege Gui, Pradeep KDagur, Catherine Lai, Laura W Dillon, J Philip McCoy, and Christopher S Houri-gan. 2018. Human bone marrow assessment by single-cell RNA sequencing, masscytometry, and flow cytometry. JCI insight 3, 23 (2018). Alexander Pletl, Michael Fernandes, Nicolas Thomas, Angelo Pio Rossi, andBenedikt Elser. 2023. Spectral Clustering of CRISM Datasets in Jezero CraterUsing UMAP and k-Means. Remote Sensing 15, 4 (2023), 939.",
  "Joshua B Tenenbaum, Vin de Silva, and John C Langford. 2000. A global geometricframework for nonlinear dimensionality reduction. science 290, 5500 (2000), 23192323": "David R Thompson, David T Flannery, Ravi Lanka, Abigail C Allwood, Brian DBue, Benton C Clark, W Timothy Elam, Tara A Estlin, Robert P Hodyss, Joel AHurowitz, et al. 2015. Automating X-ray fluorescence analysis for rapid astrobi-ology surveys. Astrobiology 15, 11 (2015), 961976. Michael M Tice, Joel A Hurowitz, Abigail C Allwood, Michael WM Jones, Bren-dan J Orenstein, Scott Davidoff, Austin P Wright, David AK Pedersen, JesperHenneke, Nicholas J Tosca, et al. 2022. Alteration history of Stah formationrocks inferred by PIXL x-ray fluorescence, x-ray diffraction, and multispectralimaging on Mars. Science Advances 8, 47 (2022), eabp9084.",
  "Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.Journal of machine learning research 9, 11 (2008)": "Raphael van Riel and Robert Van Gulick. 2023. Scientific Reduction. In TheStanford Encyclopedia of Philosophy (Winter 2023 ed.), Edward N. Zalta and UriNodelman (Eds.). Metaphysics Research Lab, Stanford University. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,Aidan N Gomez, ukasz Kaiser, and Illia Polosukhin. 2017. Attention is allyou need. Advances in neural information processing systems 30 (2017). Eli N Weinstein and Debora Marks. 2021. A structured observation distributionfor generative biological sequence prediction and forecasting. In InternationalConference on Machine Learning. PMLR, 1106811079. Austin P Wright, Peter Nemere, Adrian Galvin, Duen Horng Chau, and ScottDavidoff. 2023. Lessons from the Development of an Anomaly Detection Interfaceon the Mars Perseverance Rover using the ISHMAP Framework. In Proceedingsof the 28th International Conference on Intelligent User Interfaces. 91105. Chenling Xu, Romain Lopez, Edouard Mehlman, Jeffrey Regier, Michael I Jordan,and Nir Yosef. 2021. Probabilistic harmonization and annotation of single-celltranscriptomics data with deep generative models. Molecular systems biology 17,1 (2021), e9620."
}