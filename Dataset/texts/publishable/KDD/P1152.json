{
  "ABSTRACT": "Tabular data is foundational to predictive modeling in various cru-cial industries, including healthcare, finance, retail, sustainabil-ity, etc. Despite the progress made in specialized models, thereis an increasing demand for universal models that can transferknowledge, generalize from limited data, and follow human in-structions. These are challenges that current tabular deep learningapproaches have not fully tackled. Here we introduce GenerativeTabular Learning (GTL), a novel framework that integrates theadvanced functionalities of large language models (LLMs)suchas prompt-based zero-shot generalization and in-context learn-inginto tabular deep learning. GTL capitalizes on the pre-trainingof LLMs on diverse tabular data, enhancing their understandingof domain-specific knowledge, numerical sequences, and statisti-cal dependencies critical for accurate predictions. Our empiricalstudy spans 384 public datasets, rigorously analyzing GTLs con-vergence and scaling behaviors and assessing the impact of varieddata templates. The GTL-enhanced LLaMA-2 model demonstratessuperior zero-shot and in-context learning capabilities across nu-merous classification and regression tasks. Notably, it achieves thiswithout fine-tuning, outperforming traditional methods and rival-ing state-of-the-art models like GPT-4 in certain cases. ThroughGTL, we not only foster a deeper integration of LLMs sophisti-cated abilities into tabular data comprehension and applicationbut also offer a new training resource and a test bed for LLMs toenhance their ability to comprehend tabular data. To facilitate repro-ducible research, we release our code, data, and model checkpointsat",
  "Han did this work during his internship at Microsoft Research Asia, Beijing, China": "Permission to make digital or hard copies of part or all of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08.",
  "tabular data, large language models, generative modeling, instruc-tion following, in-context learning, zero-shot learning": "ACM Reference Format:Xumeng Wen, Han Zhang, Shun Zheng, Wei Xu, and Jiang Bian. 2024. FromSupervised to Generative: A Novel Paradigm for Tabular Deep Learning withLarge Language Models. In Proceedings of the 30th ACM SIGKDD Conferenceon Knowledge Discovery and Data Mining (KDD 24), August 2529, 2024,Barcelona, Spain. ACM, New York, NY, USA, 11 pages.",
  "INTRODUCTION": "Tabular data, with its widespread presence across numerous criticalindustrial domains such as healthcare, finance, retail, sustainabil-ity, and climate , serves as a cornerstone for predic-tive modeling . This modeling underpins a diverse array ofreal-world applications, including disease risk stratification, creditassessment, sales volume prediction, grid stability measurement,climate estimation, etc. Given its significance, it has attracted sub-stantial research attention from the machine learning community.While there have been considerable advancements in developingspecialized predictive models for individual tasks within tabulardata, employing effective learning models such as tree ensemblemodels based on gradient boosting decision trees andmore recent neural networks , the rich and diverseapplication scenarios across various domains have underscored acritical need for universal models. These models should possess theability to seamlessly transfer to new datasets and exhibit robustgeneralization capabilities, especially in scenarios with few-shotlabels. This necessity has catalyzed the emergence of tabular deeplearning as a research focus, which explores the concept of pre-training a universal neural network on a broad spectrum of tabulardata. This approach aims to create models that, once pre-trained, canbe effortlessly adapted to a wide range of tasks, thereby enhancingtheir utility and efficiency across different applications .The rapidly evolving foundation models in language and mul-timodal domains have illuminated the potential for pre-traininguniversal deep models for tabular data, showcasing remarkable gen-eralization capabilities . Specifically, these foundationmodels highlight two key attributes: Firstly, upon pre-training, theycan rapidly adapt to new tasks simply by specifying a task-oriented",
  "KDD 24, August 2529, 2024, Barcelona, SpainXumeng Wen, Han Zhang, Shun Zheng, Wei Xu, and Jiang Bian": "language data. Specifically, GTL explicitly stimulates LLMs to dis-cern complex dependencies between prediction target tokens andfeature tokens. It encourages the capture of intricate relationshipsbetween current features and in-context examples, and fosters theestablishment of effective connections between diverse languageinstructions and numerical data. Adaptation to Downstream Tasks. Given an LLM, we refer to itsvariant after the GTL process as LLM-GTL. When adapting to anew task, irrespective of the data schema or task type, LLM-GTLfacilitates direct inference by simply specifying a prompt. For in-stance, if the objective is to optimally utilize prior knowledge forzero-shot inference on semantically-rich tasks, the T-lang tem-plate can be used to transform data samples, which are then fedinto the LLM-GTL for output generation. In situations that neces-sitate the inclusion of more in-context examples and also requireleveraging meta information about the tabular task, the T-tabletemplate emerges as the best practice. Furthermore, even in the ab-sence of meta information, LLM-GTL can still offer predictions viathe T-anony template, relying on the inherent statistical learningacquired during the GTL process.",
  "From Supervised to Generative: A Novel Paradigm for Tabular Deep Learning with Large Language ModelsKDD 24, August 2529, 2024, Barcelona, Spain": "format into an instruction-oriented language format to support thesubsequent GTL procedure.This instruction-oriented format primarily consists of three com-ponents. The first component pertains to task instructions, detailingthe background and the objective of this prediction task. The secondcomponent offers detailed descriptions of the features, encompass-ing both their values and associated meanings (when available).Its important to highlight that we have the ability to incorporatein-context examples within this component, preceding the currentdata sample. Additionally, we can introduce a prompt indicatingthe presence of in-context demonstrations for reference. The thirdcomponent encompasses answer descriptions, typically prefacedwith an answer instruction, followed by the prediction targets.Adhering to these guidelines, we devise various templates thatcater to different ways of expressing feature descriptions and vary-ing requirements.Initially, we formulate the T-lang template, which delineatestabular features in a manner akin to natural language, similar toprevious research in feeding tabular data to LLMs . The ma-jor advantage of this template is that it emulates human languagestyle, facilitating smoother knowledge transfer for LLMs, giventheir extensive training on human language data. A language-styledescription of a tabular data instance may induce improved per-formance. Detailed composition of this template is provided inAppendix A.3.1. However, it is important to note that this templatefalls short in efficiently integrating in-context examples, as it neces-sitates the conversion of each example into a description, resultingin repetitive descriptions for feature meanings.To address this limitation, we introduce the T-table template,which employs a Markdown table format to encapsulate tabular fea-ture values. This approach ensures that irrespective of the numberof in-context examples added, we only need to specify a single tableheader containing brief tags for different features. Feature meaningsare positioned ahead of this Markdown table. The T-table tem-plate efficiently handles tabular data, particularly in the in-contextlearning setup. However, it also poses challenges for the long-termassociation capabilities of LLMs, as they inherently need to link afeature value with its corresponding table column and subsequentlyassociate it with the correct feature meaning explanations. Detailedcomposition of this template is provided in Appendix A.3.2.The T-anony template, a derivative of the T-table template,omits all meta-information. This is designed to simulate a practicalscenario where we possess tabular data samples, but lack knowledgeof their background or feature meanings. This setup is more akinto TabPFN , which did not utilize semantic information aboutfeature columns and task background. Detailed composition of thistemplate is provided in Appendix A.3.3.By employing these templates, we can adapt to an array of tabulartasks and data schemas across diverse domains. Additionally, wehave the capability to utilize meta information associated withthese tabular datasets when available, and also have mechanisms inplace for situations where such information is absent. Furthermore,we can regulate the number of in-context examples incorporated,thereby effortlessly incorporating both zero-shot and in-contextlearning scenarios.",
  "Our literature review encompasses four aspects": "Predictive Modeling on Tabular Data. The development of effec-tive algorithms for predictive modeling on tabular data has been alongstanding research topic. In the early days, tree-based modelswere found to be particularly suitable for tabular data, leading to thedevelopment of several gradient boosting decision trees .Subsequently, as deep learning gained prominence , numer-ous studies attempted to create suitable network architectures fortabular data and introduced self-supervised learningschemes . Despite these tabular neural networks notconsistently outperforming tree-based models , furtherresearch has advanced tabular deep learning and established newstate-of-the-art results in few-shot and transfer learningscenarios . However, these techniques typically requiredre-training or fine-tuning to adapt to new data schemas and tasks.Moreover, as mentioned in the introduction, while some advance-ments have introduced support for either zero-shot or in-contextlearning capabilities, they usually address limited scenarios. Incontrast, this paper embarks on a comprehensive exploration ofzero-shot and in-context generalization within the sphere of tabu-lar deep learning. Our focus lies in the ease of adaptation withoutthe necessity for parameter tuning, extreme data efficiency, andwide-ranging transferability across diverse domain knowledge, dataschemas, and tasks. These are areas that have not been sufficientlyexplored in the existing literature on tabular deep learning. When LLMs meet Tabular Deep Learning. The remarkable successof LLMs, scaled to unprecedented sizes and trained on massive textcorpus, has demonstrated their broad knowledge and phenomenalcapabilities in transfer learning and instruction following .This success has spurred the application of LLMs to tabular deeplearning with the aims of 1) leveraging the comprehensive worldknowledge already acquired, 2) enabling instruction following tosupport diverse tasks without the need for tuning or even data,and 3) effectively harnessing meta-information in tabular data,such as column names, task descriptions, and background knowl-edge. In this domain, several pioneering studies have set the stage.For instance, LIFT introduced language-interfaced fine-tuning,which fine-tuned GPT-3 and GPT-J on multiple tabular learning datasets, revealing that the performance of fine-tunedLLMs was roughly on par with traditional solutions. Specifically,it examined the comparison between fine-tuning and in-contextlearning, albeit only on six classification tasks using the accuracymetric. TabLLM , a subsequent study that adopted T0 asthe base LLM, demonstrated competitive performance of fine-tunedLLMs in very few-shot scenarios, and it slightly underperformedin comparison to classical tabular models when more shots wereavailable. TabLLM explored zero-shot learning on tabular data, butit only covered classification tasks, its inference design necessitatedmultiple forward passes over the base LLM for multi-class tasks,and it did not explore in-context learning. Moreover, MediTab ,which focused on the healthcare domain, utilized LLMs to generatesupplementary data for a specific target task, and TapTap em-ployed LLMs to create synthetic tabular data. Additionally, we haverecently identified two contemporaneous studies, TP-BERTa and UniPredict , which also investigated the pre-training ofLLMs on tabular data. However, these studies still conformed to thesupervised learning paradigm for downstream tasks. Distinct fromthese explorations merging LLMs with tabular deep learning, ourresearch accentuates a generative learning paradigm for LLMs ontabular data, promoting comprehensive instruction-following ca-pabilities for both zero-shot and in-context learning. Furthermore,our approach supports not only binary classification tasks but alsomulti-class and regression cases across various domains. Augmented LLMs. Since the groundbreaking success of LLMs ,ongoing efforts have been made to augment LLMs with capabili-ties that are difficult to acquire through next-token predictions onpure text alone . These efforts can generally be divided intotwo categories. The first category leverages external sources ortools to gather additional information, thereby endowing LLMswith unprecedented capabilities. Notable examples in this categoryinclude ReAct , which augments LLMs with a simple WikipediaAPI, PAL , which combines LLMs with Python interpreters,and Toolformer , which teaches LLMs to use multiple tools.The second category introduces an additional learning procedureon new data, thereby inherently acquiring some new abilities. Forinstance, further trained LLMs to align with human values,and trained LLMs on code data, facilitating remarkable codeunderstanding and generation. Viewed from the lens of augmentedLLMs, this paper aligns with the second category. Our distinct con-tributions encompass the introduction of tabular data as a novellearning resource and testing platform for LLMs, along with theformulation of effective learning objectives for this data type.",
  "Answer Prompt": "You are an expert in health and fitness. Based on the gender, height, and weightof the individual, Features: The gender of the individual is female The height of the individual in centimeters is Predict the BMI category. Answer: 5 Based on these statistics, please evaluate the level of sustainable development in this country. Answer: 38.676",
  "Problem Formulation": "Notations. In the field of tabular learning, we typically handlea tabular task T : X Y, which associates a tabular instance X, consisting of features, {}=1, with a prediction target, Y. For regression tasks, Y R1 and for -class classificationtasks, Y = {0, 1, , 1}. Note that tabular features are generallydivided into numerical and categorical types, while we do not explic-itly distinguish between them here. Besides, each tabular task mayalso be associated with various meta-information elements, such asthe task background, prediction target interpretation, and featuredescriptions. We denote the comprehensive meta-information oftask T as M T.Traditional tabular data learning methods primarily focus on con-structing a discriminative model to learn the dependency, (|),between the target and features using the training data. However,such a model strongly tied to the training data faces significantchallenges when adapting to a new tabular task, T, with a differentdata schema X and prediction targets Y. Zero-shot Learning. In the realm of tabular data, zero-shot learn-ing is typically characterized by the ability to predict out-comes for data samples from a previously unseen task, T. Thisnew task possesses an unknown data schema, X, but it has meta-information M T, which encapsulates the meaning of features andprediction targets. Formally, we define the input of a zero-shot",
  "learning task as a tuple (M T, ), where M T denotes the meta-information for the new task and represents a novel datasample for which we aim to make predictions": "In-context Learning (Few-shot Learning). In-context learning re-sembles zero-shot learning but with an additional dimension: itincludes a set of exemplars from the new task T as demonstrations,represented as T = {( , )}=1, where signifies the quan-tity of in-context examples. We formally characterize the input ofan in-context learning task as a tuple (M T, T, ), where themeta-information M T can be omitted if the model does not utilizeit, as in the case of TabPFN . In-context learning can seamlesslytransition into few-shot learning by allowing the model to undergofurther fine-tuning on T before making predictions on .",
  "Construction of Tabular Data in anInstruction-Oriented Language Format": "The upper part of depicts the pipeline for our data con-struction. Our preliminary step is to collect a significant amountof tabular datasets, which cover a broad spectrum of predictivetasks across multiple domains. This process, with more details in.1, requires the acquisition of both features and labels, bet-ter including meta-information (optional). Then, for each specifiedtabular task, T, and any accompanying meta information M T, it isessential to transform the data samples from their original tabular",
  "The bottom part of intuitively depicts the training andadaptation of GTL. Next, we formally introduce the GTL paradigm": "Notations for Tokenized Instruction-oriented Language Data. Be-low we mainly leverage the T-lang template to derive the nota-tions for a tokenized instruction-oriented language sample. Recall-ing in the last section, an instruction-oriented language formatfor tabular data primarily incorporates three components, encom-passing a task instruction, a feature description, and an answerprompt. Formally, we represent the tokenization results of the firstpart as: = [1, ,| |], where | | is the operation to denotethe length of a token sequence. Besides, we denote the -th fea-ture as = , where = [ 1 , , | |] includesall tokens of feature descriptions on the left of this feature value, = [1 , ,| |] denotes the token sequence for the feature",
  "= ,(1)": "which systematically unifies task background (), feature meanings({, }=1), and feature values ({ }=1) and supports variousprediction targets via a variable-length sequence (). Please notethat, the above tokenization notations also apply for other templates,such as T-table, merely with a different way of specifying featuremeanings. Besides, we need to mark the positions of feature valuetokens and prediction target tokens of the current tabular datasample to support the subsequent GTL procedure.",
  "=1( |< ),(2)": "where we introduce additional notations to ensure the concise for-mulation, using = to denote allmeta information, = to represent all tokens re-lated to feature values, and < to include all tokens ahead of in equation 1. Here (,) denotes the joint distribution in theinitial feature and label spaces, while (, |) represents thesame joint distribution conditioned on all meta information usingthe text representation, which can further be decoupled autoregres-sively into (|, ) =1 ( |< ). It is thus straightforwardto leverage LLMs, especially those using auto-regressive architec-tures, to characterize this decoupled formulation. The only mod-ification needed is to mask out the losses on meta-informationtokens. While GTL employs the next-token prediction loss akin toLLMs, it distinguishes itself from auto-regressive pre-training on",
  "EXPERIMENTS": "This section presents extensive empirical investigations to addressthe following key research questions: 1) How does the application ofGTL to an LLM impact its convergence and generalization behaviorson tabular deep learning? 2) What are the crucial scaling lawsassociated with GTL? 3) How do different text templates influencethe performance? 4) How do GTL-enhanced LLMs compare againstboth traditional tabular models and contemporary LLMs?",
  "Experimental Setups": "Dataset Collection. We have curated a collection of 384 publictabular datasets from Kaggle1, which includes 176 classification and208 regression tasks spanning a wide range of industrial domains.For the purpose of holdout evaluation, we have randomly selected44 tasks, consisting of 20 classification and 24 regression tasks, andcarefully examined to ensure no overlap with the remaining tasksutilized for the continued pre-training with GTL. Further detailspertaining to the statistics of the datasets and the covered domainscan be found in Appendix A.2. Configurations for Pre-training. For the 340 tabular datasets allo-cated for continued pre-training, we examine six different scenariosof zero-shot or in-context learning, with the number of in-contextexamples in {0, 4, 8, 16, 32, 64}. To further enrich the diversity oflearning experiences, we have created up to four unique tasks foreach dataset by judiciously selecting various columns as labels andthe remainder as features. Each scenario is tested with all three texttemplates, resulting in a total of 14k cases. Typically, we randomlyselect 64 data samples for each case, obtaining 880k tokenized se-quences for GTL. We impose a maximum sequence length of 4, 096and discard any data samples that exceed this limit, yielding a totalof 640k data samples for pre-training. We also sample a small subsetof test samples, distinct from these pre-training samples, to assess in-domain generalization on these pre-training datasets across dif-ferent instruction categories. We sample 16 per classification caseand 4 per regression case (the latter requiring multi-step decodingwhich is highly time-consuming during evaluation). We have uti-lized the 7B and 13B versions of LLaMA 2 as our base LLMs.The corresponding GTL-enhanced variants are denoted as LLaMA-7B-GTL and LLaMA-13B-GTL, respectively. Implementation detailscan be found in Appendix B.2. Configurations for Holdout Evaluation. For the 44 holdout datasets,we adopt a similar approach to that of pre-training data, consider-ing different in-context examples and text templates. To achieve arobust evaluation that mitigates the effects of randomness, we usethree distinct random seeds to sample evaluation examples for eachcase, where one case is a combination of a dataset, a in-contextconfiguration, and a text template. We increase the sample size to64 for classification cases and 16 for regression cases. By observingperformance variations across different seeds within the same case,we ascertain that this configuration balances the computationalcost of running diverse experiments with the statistical significanceof the results obtained. In total, we have around 88k data samplesfor holdout evaluation. The primary metrics used for evaluationare the Area Under the Receiver Operating Characteristic (AUROC)for classification tasks and the Normalized Mean Absolute Error(NMAE) for regression tasks. Baselines. Our baseline includes both competitive tabular mod-els and contemporary large language models (LLMs). For the tab-ular models, we have included classic tree-based models such asXGBoost , CatBoost , and LightGBM . We have alsoconsidered the state-of-the-art in-context model, TabPFN , acompetitive neural model, FTT , and a logistic regression (LR)baseline, known for its robustness in extremely few-shot scenarios.As for the LLMs, we have included the initial versions of LLaMA2, denoted as LLaMA-7B and LLaMA-13B, and proprietary LLMssuch as GPT-3.5 and GPT-4 . We assessed the proprietarymodels by invoking their APIs on our holdout data. To calculateAUROC using prediction probabilities, we instructed these modelsto output probabilities. For LLaMA and GTL models, due to ouraccess to their networks, we instructed them to predict class indicesdirectly and collected logits over the class tokens to acquire outputprobabilities. For the NMAE metric, all LLMs require multi-stepdecoding, for which we allowed a maximum of ten steps for LLaMAmodels, sufficient for all cases under consideration in this study.",
  "Understanding GTL": "We investigate the generalization behaviors during the optimizationof GTL, as depicted in . Notably, a significant gap emergesbetween the improvements of in-domain and out-of-domain gen-eralization in the zero-shot scenario. Initially, both generalizationabilities enhance swiftly, but as training progresses, in-domaingeneralization continues to improve while out-of-domain general-ization plateaus. This plateau occurs due to the presence of domain-specific knowledge in holdout data, which is not covered by eitherthe LLMs prior understanding or pre-train data. Consequently,early training steps primarily improve tabular data understanding.As training deepens, the model continues to learn patterns within",
  "AUROC": "T-langT-tableT-anony # In-context examples 0.00 0.25 0.50 0.75 1.00 NMAE T-langT-tableT-anony : The influence of template variability on datasetcoverage, given a maximum sequence length, and on gen-eralization performance, considering different numbers ofin-context examples on holdout datasets. pre-train domains but acquires no further universal abilities forholdout datasets. However, the introduction of in-context examplesnarrows this gap. Specifically, when more than 32 in-context exam-ples are included, the gap between in-domain and out-of-domaingeneralization nearly disappears, whereas they roughly convergeafter 8, 192 steps. This analysis suggests that early stopping of GTLoptimization can be beneficial for generalization on unseen datasetsand domains. Therefore, in subsequent experiments on scaling laws,we halt pre-training at step 8, 192.The study of scaling laws seeks to identify key factors influenc-ing generalization to holdout data, which could indicate potentialavenues for future breakthroughs. We primarily focus on the impactof scaling the number of data samples per task, the number of tasksused for GTL, and the model size. As shown in , scaling the number of data samples per tabular task improves generalizationquickly when LLMs have limited exposure to tabular data. However,beyond a certain threshold, such as 64, further increases to 256 donot significantly enhance holdout data generalization. In contrast,scaling the number of tasks consistently improves generalization,suggesting that expanding task coverage beyond the 340 datasetsused for pre-training here could further enhance GTL performance.Moreover, increasing the model size, for example from 7B to 13B,significantly boosts performance.Additionally, we thoroughly compare the effects of different datatemplates on holdout generalization across various in-context sce-narios. As depicts, the T-lang template, which best adheresto language conventions, excels in semantic-dominant scenarios,particularly zero-shot and few-shot classification tasks. However,due to its inefficient token usage, it becomes less effective as thenumber of in-context examples increase, with a significant drop-offobserved at 16 examples. In contrast, regression tasks, which pri-marily involve fitting a numerical target based on different features,do not heavily rely on semantic information. Based on these find-ings, we propose a template usage strategy: T-lang for zero-shotclassification cases, T-table for other scenarios when meta infor-mation is available, and T-anony when the origin of the tabulardata is unknown.",
  "Performance Comparisons withCompetitive Tabular Models and LLMs": "We further contrast our approach with competitive tabular modelsand contemporary LLMs, as illustrated in and .When compared to tabular models, our approach excels in nu-merous few-shot cases, including classification tasks with in-contextexamples ranging from 4 to 16, and regression tasks with examplesfrom 4 to 32. These findings validate the effectiveness of the GTL",
  "LLaMA-13B-GTL0.641[0.565,0.752]0.767[0.663,0.919]0.811[0.681,0.960]0.823[0.752,0.955]0.850[0.777,0.955]0.816[0.733,0.918]2.5003.903": ": Regression results. We display the mean, 25th percentile, and 75th percentile NMAE (Normalized Mean Absolute Error)scores across all datasets for both zero-shot and in-context learning scenarios. NMAE values are truncated at a maximum of 1.0to account for certain baselines diminished performance due to inadequate training data. Rank denotes the average rank inzero-shot settings, while Rank signifies the average rank in in-context settings.",
  "GPT-40.583[0.241,0.958]0.229[0.083,0.304]0.233[0.072,0.297]0.229[0.064,0.286]0.214[0.054,0.268]0.146[0.030,0.240]3.2502.918": "LLaMA-7B-GTL0.523[0.223,0.957]0.316[0.102,0.417]0.299[0.082,0.387]0.311[0.081,0.513]0.291[0.068,0.511]0.229[0.031,0.315]2.7924.589LLaMA-13B-GTL0.430[0.172,0.671]0.288[0.079,0.403]0.271[0.059,0.398]0.295[0.063,0.415]0.260[0.050,0.355]0.165[0.035,0.263]2.0833.946 paradigm in integrating prior knowledge and tabular data under-standing, a fusion that could be invaluable in addressing data-scarcechallenges in many practical applications, such as rare disease clas-sification or new material property prediction. A closer look atthe classification results reveals TabPFN to be a robust baseline,outperforming us in average rank due to its superior handling oflarger in-context examples. Regarding regression tasks, our un-tuned LLaMA-13B-GTL model frequently surpasses other modelsthat have been tuned on in-context examples, also demonstratingthe effectiveness of GTL. Besides, we note a rise in error with ourmodel when 64 contexts are used, potentially due to the limitedinclusion of such examples in pre-training regression tasks. Weexpect this limitation can be mitigated by scaling up the maximumsequence length, model size, and task quantity.Our GTL-enhanced LLMs, potentially utilizing smaller model sizes,surpass GPT-4 in numerous classification scenarios and significantly narrow the performance gap in regression tasks. GPT-4, being propri-etary with undisclosed pre-training data, raises potential concernsof data contamination since all tabular datasets used in our studyare publicly available on Kaggle. Despite this potential issue, theexceptional performance exhibited by our LLaMA-GTL series, de-rived from open-source LLMs, affirms the effectiveness of the GTLparadigm in bolstering tabular deep learning capabilities for LLMs.Beyond the realm of tabular data, our findings suggest that open-source LLMs should integrate instruction-oriented tabular data intotheir pre-training corpus. This could amplify their data comprehen-sion capabilities, especially considering the ubiquity of tabular dataacross various fields, and possibly spark new discoveries throughthe amalgamation of diverse data types. Finally, we conjecture thatthe superior performance of our GTL methodology over GPT-4 inclassification tasks might be ascribed to different approaches inprediction probability computation, as we are limited to accessingGPT-4s prediction probabilities via instruction-based API calls.",
  "CONCLUSION": "This study introduces GTL, an generative paradigm that fuses LLMsinstruction-following capabilities with tabular deep learning. Thepreliminary results demonstrate its effectiveness, particularly intackling data scarcity issues, and our scaling analyses suggest av-enues for further performance enhancements. Limitations. Despite these encouraging outcomes, our study doeshave limitations. The context length constraint of LLMs restrictsthe number of in-context examples we can use, which can hinderlearning over large-scale data. Besides, using a text format to rep-resent tabular data is not token-usage efficient. Furthermore, thecomputational cost of LLMs is considerably higher than traditionaltechniques, raising financial and environmental concerns. Lastly,despite using 384 datasets in this study, the diversity and scale maynot fully represent the potential and applicability of GTL across alltabular data fields. Future Directions. In the meanwhile, we are optimistic aboutthis research directions future prospects. For example, the GTLparadigm opens doors for conversational tabular deep learning,where models could refine predictions through dialogue. GTL couldalso promote interpretable learning over tabular data, as LLMscan generate explanations with predictions, albeit with challengesin ensuring explanation faithfulness. There is potential for betterintegration between LLMs and traditional models, merging theirstrengths. Furthermore, our work provides a valuable asset forthe LLM community, serving both as a benchmark for evaluatingdata comprehension capabilities and as a source to enrich existingpre-training corpora.",
  "Sebastian Bordt, Harsha Nori, and Rich Caruana. 2023. Elephants Never Forget:Testing Language Models for Memorization of Tabular Data. In NeurIPS 2023Second Table Representation Learning Workshop": "Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan,Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, ChrisHesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, andDario Amodei. 2020. Language Models are Few-Shot Learners. In NeurIPS. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de OliveiraPinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman,et al. 2021. Evaluating large language models trained on code. arXiv preprintarXiv:2107.03374 (2021).",
  "Foster Provost and Tom Fawcett. 2013. Data Science for Business: What you needto know about data mining and data-analytic thinking. \" OReilly Media, Inc.\"": "Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, ZaidAlyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari,Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, TaewoonKim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, MikeTian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, HarshitPandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, AbheeshtSharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven LeScao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush. 2022.Multitask Prompted Training Enables Zero-Shot Task Generalization. In ICLR. Timo Schick, Jane Dwivedi-Yu, Roberto Dess, Roberta Raileanu, Maria Lomeli,Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. 2023. Toolformer: Lan-guage models can teach themselves to use tools. arXiv preprint arXiv:2302.04761(2023).",
  "Ravid Shwartz-Ziv and Amitai Armon. 2022. Tabular data: Deep learning is notall you need. Information Fusion (2022)": "Gowthami Somepalli, Micah Goldblum, Avi Schwarzschild, C Bayan Bruss, andTom Goldstein. 2021. SAINT: Improved neural networks for tabular data via rowattention and contrastive pre-training. arXiv preprint arXiv:2106.01342 (2021). Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-BaptisteAlayrac, Jiahui Yu, Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth,et al. 2023. Gemini: a family of highly capable multimodal models. arXiv preprintarXiv:2312.11805 (2023). Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yas-mine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhos-ale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXivpreprint arXiv:2307.09288 (2023).",
  "ADATAA.1Detailed Statistics of Collected Datasets": "To empower Large Language Models (LLMs) to build foundationalknowledge and abilities across a variety of domains through gener-ative tabular learning, the compilation of a diverse and substantialcollection of tabular datasets is pivotal. We have carefully curateda collection of 384 public datasets, comprised of high-quality, func-tional tabular classification datasets procured from Kaggle.",
  ": Domain distribution of pre-training and holdoutdatasets": "A.3.2The T-table Template. The T-table template maintains thetabular format of the data samples. Meta information, such as fea-ture description and label description, is added prior to the dataand is not repeated with each example when in-context examplesare introduced. An instance of the T-table template with in-contextexamples is showcased in List 1. A.3.3The T-anony Template. The T-anony template eliminates allmeta information pertaining to the task, feature, and label. Similarto the T-table template, it organizes the tabular data in a markdownformat.",
  "BIMPLEMENTATION DETAILSB.1Baseline Models": "Our experiments encompass two categories of baselines: large lan-guage models (LLMs) and traditional tabular models. For LLMs, weemploy instruction following to predict the answer in both zero-shot and in-context scenarios. In the case of tabular models, weonly compare results in few-shot settings. Specifically, for learning-based models such as XGBoost , CatBoost , LightGBM ,FTT , and logistic regression (LR), we utilize in-context exam-ples for training. Conversely, for TabPFN and our GTL model,no parameter tuning is required; direct inference is achieved usingthe same examples through in-context learning. In order to con-duct a fair comparison for all these baselines, we would samplecategory-balanced in-context samples for classification tasks. B.1.1LLMs Baseline. We assess the instruction following capa-bilities of several large language models, dividing them into twocategories: black box models and white box models. Black box mod-els include the GPT series, where we can only access the responserather than model parameters and prediction logits. In contrast,white box models like LLaMA, allow us to access the entire modeland obtain logits for each class. The descriptions of each baselinemodel are as follows: GPT-3.5 : We employ the GPT-3.5-turbo version, whichis the most capable GPT-3.5 model optimized for chat anddesigned for diverse tasks such as natural language under-standing, translation, and summarization. To encourage themodel to provide predictions and minimize instances whereit refuses to make predictions, we incorporate an additionalanswer instruction prompt when querying GPT-3.5. Thisapproach allows GPT-3.5 to predict the probabilities for eachcategory, which can then be used to calculate AUROC. GPT-4 : A powerful baseline renowned for its top perfor-mance in numerous language tasks due to its larger modelsize and architectural refinements. We also fine-tune theanswer instruction prompt for GPT-4. Compared to GPT-3.5,GPT-4 demonstrates superior performance in both zero-shotand in-context learning. The instruction prompt and theresponse format is the same with GPT-3.5.",
  "data | Age | BMI | FBS | HbA1c | Gender | BloodPressure | FamilyHistory | Smoking | Diet | E x e r c i s e | Diagnosis |": "| 4 8 | 4 7 . 0 | 2 0 0 . 0 | 9 . 2 | Male | High | Yes | Yes | Poor | No | 0 || 7 0 | 3 5 . 0 | 1 4 0 . 0 | 7 . 1 | Female | Normal | No | No | Healthy | Regular | 0 || 1 2 | 1 0 . 0 | 8 0 . 0 | 5 . 0 | Male | Low | No | Yes | Poor | No | 1 || 7 5 | 4 0 . 0 | 1 6 0 . 0 | 7 . 8 | Female | High | Yes | Yes | Poor | No | 1 || 3 0 | 2 0 . 0 | 1 0 0 . 0 | 5 . 7 | Female | Normal | No | No | Healthy | Regular | <MASK>|P le a s eusethesu p p l ieddatatop r e d i c tthe <MASK> Diagnosis .Diagnosedwithd i a b e t e s ornot ?",
  "Answer :0": "include z-score normalization for numerical features and labels, andone-hot encoding for categorical features. The performance of thesebaseline models, following the application of these pre-processingstrategies, are included in our results. Logistic Regression: A linear model used to predict binaryresponse probabilities based on predictor variables. BothLogistic Regression and its regression counterpart, LinearRegression, are straightforward and efficient, often serving asbaseline models in classification and regression tasks respec-tively. To enhance model performance, we employ z-scorenormalization on numerical features and one-hot encodingon categorical features.",
  "LightGBM : A gradient boosting framework employingtree-based learning algorithms, designed for efficiency andscalability, offering faster training speeds and lower memoryusage than other techniques": "CatBoost: A high-performance gradient boosting li-brary that handles categorical features directly, providingan efficient and accurate model. We implemented z-scorenormalization on numerical features and regression tasklabels. FTTransformers: This model employs transformer-based architectures for tabular data, offering a dynamic andadaptable framework that can be fine-tuned for various tasks.In these deep learning-based models, weve found that the results largely depend on pre-processing strategies and thenumber of training epochs. Therefore, we selected the opti-mal strategy based on results from the holdout datasets. Weimplemented z-score normalization on numerical featuresand regression task labels. TabPFN A deep learning model that combines Posi-tional Feature-wise Networks with transformer-based ar-chitectures for tabular data, capturing both local and globalfeature interactions to enhance performance in various tasks.",
  "B.2Generative Tabular Learning (GTL)": "Hyper-parameters. We employ the LLaMA-2 7B and 13Bversion models as the backbone for our experiments. For generativetabular learning, we utilize a fixed learning rate of 1e-5 and a batchsize of 512, without incorporating any scheduler or warmup. Thetraining procedure involves gradient updates with the optimizerAdamW . We set the limitation of maximum token numbersto 4096, which ensures that all samples are within the acceptablerange and prevents truncation. Experimental Environments. The GTL-enhanced LLaMA modelis implemented using PyTorch version 2.1.0 and executed on CUDA12.1, running on NVIDIA Tesla A100 GPUs. As for GTL, pre-trainingis performed on a single node equipped with 8 A100 GPUs and themicro batch size is 4 for LLaMA-7B and 2 for LLaMA-13B. With anoverall batch size of 512, the gradient accumulation steps amountto 16 for LLaMA-7B and 32 for LLaMA-13B. In LLaMA-13B-GTL,updating the gradient for 256 batches, which comprises 131,072samples, takes approximately 26 hours."
}