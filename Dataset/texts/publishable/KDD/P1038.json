{
  "ABSTRACT": "In multivariate time series (MTS) classification, finding the impor-tant features (e.g., sensors) for model performance is crucial yet chal-lenging due to the complex, high-dimensional nature of MTS data,intricate temporal dynamics, and the necessity for domain-specificinterpretations. Current explanation methods for MTS mostly focuson time-centric explanations, apt for pinpointing important timeperiods but less effective in identifying key features. This limita-tion underscores the pressing need for a feature-centric approach,a vital yet often overlooked perspective that complements time-centric analysis. To bridge this gap, our study introduces a novelfeature-centric explanation and evaluation framework for MTS,named CAFO (Channel Attention and Feature Orthgonalization).CAFO employs a convolution-based approach with channel atten-tion mechanisms, incorporating a depth-wise separable channelattention module (DepCA) and a QR decomposition-based loss forpromoting feature-wise orthogonality. We demonstrate that this or-thogonalization enhances the separability of attention distributions,thereby refining and stabilizing the ranking of feature importance.This improvement in feature-wise ranking enhances our under-standing of feature explainability in MTS. Furthermore, we developmetrics to evaluate global and class-specific feature importance.Our frameworks efficacy is validated through extensive empiricalanalyses on two major public benchmarks and real-world datasets,both synthetic and self-collected, specifically designed to highlightclass-wise discriminative features. The results confirm CAFOs ro-bustness and informative capacity in assessing feature importancein MTS classification tasks. This study not only advances the un-derstanding of feature-centric explanations in MTS but also sets afoundation for future explorations in feature-centric explanations.The codes are available at Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for third-party components of this work must be honored.For all other uses, contact the owner/author(s).KDD 24, August 2529, 2024, Barcelona, Spain 2024 Copyright held by the owner/author(s).ACM ISBN 979-8-4007-0490-1/24/08",
  "INTRODUCTION": "With the advancement of Internet of Things (IoT) technologies, timeseries classification (TSC) tasks have proliferated in recent years.A notable characteristic of TSC data derived from these sources isthat they are usually 1) multivariate; that is, they contain multiplemeasurements or sensors and 2) characterized by patterns thatare complex and intertwined, which poses challenges for semanticinterpretation by humans, a stark contrast to more intuitivelygraspable domains of image and text data. These multivariate timeseries (MTS) data have found practical applications ranging fromthe classification of human activities to the detection of industrialfaults , demonstrating its broad applicability.As MTS data find broader applications, an essential need emergesin the phase of model development. Engineers and domain ex-perts seek not just to use these models but to understand howthey process data. This understanding is vital; it can drastically re-duce computational and manufacturing costs and foster confidencein the models deployment, ensuring it leverages features recog-nized as important . In this context, the role of explainableAI (XAI) is not just beneficial but indispensable. Yet, a concern-ing observation arises: XAI research in MTS has predominantlyconcentrated on generating time-step-specific or instance-specificexplanations , focusing narrowly on segments oftime critical to the models decision-making in a given instance.Such local explanations, while invaluable in contexts like healthcare,reveal a significant gap for a more comprehensive, feature-centricoverview that can provide a broader understanding of the data.In MTS, a feature is commonly identified as a separate channel ormeasurement variable, which is independent of the time axis. This",
  "KDD 24, August 2529, 2024, Barcelona, SpainJaeho Kim, Seok-Ju Hahn, Yoontae Hwang, Junghye Lee, and Seulki Lee": ": (A) The GI (Global Importance) score for the MS Dataset is provided. x0 to x5 denotes the feature index. (B) An exampleof WhichFingers CWRI (Class-Wise Relative Importance) score:columns represent sensors (features), rows denote classes, and cellvalues convey CWRI scores. Red indicates the higher relative impor-tance of the feature for the class, whereas blue denotes features oflesser importance in the context of the specific class. Accuracy (DA), which is the drop in model performance after ex-cluding 20% of the important features. Second, to complement themanual selection of K% of features to be removed, we introducethe Weighted Drop in Accuracy (WDA) metric, which measures thedecrease in accuracy when important features are removed sequen-tially, giving greater weight to scenarios where a smaller fractionof features is dropped. In real-world scenarios, practitioners anddevelopers are often more interested in discerning the most or leastimportant features rather than knowing mediocre features. Suchscenarios arise when we have to extensively reduce the number offeatures to fit in a small memory budget or remove features thatdo not contribute to model performance. This weighting schemeensures that the impact of removing high ranked GI feature is morepronounced (see Appendix C.1). Third, as an enhancement to theROAR, we introduce the Area Between Curves (ABC) metric (Eq. (6))based on the trapezoid rule , quantifying the area enclosedby the inverse ( ()) and truth curve (()) between the interval; a larger ABC value denotes a more precise feature rankingassessment, highlighted as gray areas in .",
  "Given number of MTS samples, the -th MTS instance X() =x()1 , ..., x()": "R encompasses times steps and features.In this context, a univariate time series is defined as a single -th fea-ture sequence x()= [1, ..., ], and an aggregation of such uni-variate sequences constitutes an MTS. Traditional time-step-basedexplanations offer insights along the temporal () dimension, butour research pivots towards elucidating the feature () dimension.",
  "CAFO: Feature-Centric Explanation on Time Series ClassificationKDD 24, August 2529, 2024, Barcelona, Spain": "SquidGame. The SquidGame task is a synthetic 3-class classification dataset designed to validate the efficacy of CWRI scores. This taskfeatures distinct, non-overlapping feature sets, each representing a specific class. Initially, all features are populated with random Gaussiannoise. These time series instances are then treated as images, and an empty mask is created with circle, triangle, and square shapes. Eachmask is filled with characteristic time signals from the sinusoidal series, with the length, size, and center coordinates generated randomlyfor each instance. Here, = 32 and = 30. Feature indices are divided into three groups: G = {1, ..., 10}, G = {11, ..., 20}, andG = {21, ..., 30}. G indicates that feature indices 1 to 10 contain a circular mask with characteristic time signals representing thefirst class. The complement of the circle masks in indices 1 to 10 and the remaining indices (11 to 30) are filled with Gaussian noise for thefirst class. This scheme is also applied to the second and third classes. As a result, only the first class contains characteristic time signals infeature indices 1 to 10, while the other classes have random Gaussian noises. The datasets name was inspired by the popular Netflix series\"Squid Game.\"WhichFinger. The WhichFinger task utilizes a real-world smart glove dataset that we have gathered in order to verify the effectiveness ofthe CWRI scores. In this task, we set = 120 and = 10. A comprehensive discussion of the datasets details can be found in Appendix G,which is dedicated to this particular topic.",
  "Image Encoding of MTS": "Image encoding of MTS involves transforming time series data intoimage formats, such as a Recurrence Plot (RP) or Gramian Angu-lar Fields (GAF) . Encoding time series into images offers severalbenefits in analyzing feature-wise importance. First, image encod-ing operates independently of specific standardization methods ,which is often crucial due to the heterogeneity of features, e.g., thevarying scales of accelerometers and gyroscopes. This can evensignificantly impact the end performance of a modeling . Imageencoding, however, primarily relies on point-wise relations (e.g.,inner products with threshold) to represent time series, therebyliberating the feature representation from the implicit biases of anyparticular scaling method. This aspect ensures a more equitablecomparison and ranking of features. Second, image encoding en-hances the representation of temporal dependency within features.By converting the original feature x R into a X R image,recurrent patterns become more explicit and discernible , whichallows for the use of well-curated vision models, e.g., ViT . Ourempirical results (Appendix C) suggest these models more effec-tively discern feature importance in our study, potentially owingto image encoding or inherent model capabilities. We use Recur-rence Plot to capture the recurrence patterns in MTS, and explorealternative encoding techniques such as GAF in Appendix B.",
  "Channel Attention (CA) Modules": "CA is primarily used in the image classification domain to improvemodel performance by emphasizing relevant feature channels. Thepioneering SENet , BAM , CBAM , and SIMAM har-ness CA by collating channel specific statistics (e.g. global average),passing them through parametrized functions to obtain channel orspatial attention. In contrast to the use of CA in the image domain,which integrates CA at multiple points within the latent space, ourapproach applies CA singularly and directly to the input rep-resentation, to obtain the attention scores for each feature.We note that in the time series domain, the joint usage of imageencoding and CA has been previously explored in temporal ,frequency , and wavelet -based literature, often to augmentmodel performance, and occasionally to offer interpretative insightsvia raw attention visualizations. Our research pioneers the use ofCA scores to systematically evaluate feature importance on a globaland class-specific scale in MTS data.",
  "Multivariate Time Series Explanation": "Post-hoc explanation in multivariate time series (MTS) eluci-date model decisions by deriving explanations from their output,making them generally agnostic to the underlying model. In MTSexplanation, several post-hoc methods employed in the image do-main have been repurposed for MTS by viewing the raw time seriesas a image. A recent study by Turb et al. has undertakena comprehensive assessment of various post-hoc interpretabilitymethods Integrated Gradients , GradientSHAP , and Shap-ley value sampling in the context of TSC, highlighting substan-tial discrepancies in time-centric explanation across methods, alsonoted by Schlegel et al . Our research extends these observa-tions, confirming these inconsistencies in feature-centric explana-tions of MTS, and first identifying the impact of train/validationdistribution on feature importance inconsistency. The study also highlights the limitations on the use of synthetic data in priortime-centric explanation research , emphasizing the need forreal-world datasets with clear discriminative features for validatingMTS explanation methods. In the pursuit of enhancing these meth-ods, past works have applied these post-hoc methods on LSTM ,TCN , and Transformer models for time-based explana-tions. Orthogonal to these approaches, DynaMask is a post-hocmethod, providing an explanation based on optimizing perturbationmasks for MTS. However, its requirement for numerous optimiza-tion steps per instance presents a challenge, limiting its efficiencyin global and class-specific importance calculation.Model-based explanation for time series rely on specific neuralarchitecture such as recurrent neural networks (RNNs), as thesemodels inherently handle sequential inputs. Nevertheless, recentworks show that they suffer from saliency vanishing and mayhave limitations in explaining time series data . For example,TimeSHAP is a recurrent explainer extending KernelSHAP to the temporal domain by grouping sequential data into coali-tions. Shapley-based methods are known to be computationally-intensive , while TimeSHAP provides efficient pruning methodsto overcome this. However, pruning relies on the assumption thatrecent events have a predominant influence on model outcomemight not apply universally, such as in continuous event recordinglike human activity monitoring. Another recurrent-based approach,FIT , assigns significance to events using counterfactuals withina generative model. Unfortunately, training a generator adds anextra cost, and the explanation depends on the generators perfor-mance. LAXCAT is another model-based explanation methodutilizing both temporal and variable attention scores using 1D con-volution methods. Our CAFO method, however, distinguishes itselfby employing 2D convolutions and channel attention (CA), offeringa unique structural approach to derive attention scores.",
  "CAFO: CHANNEL ATTENTION ANDFEATURE ORTHOGONALIZATION": "provides an overview of CAFO for extracting feature-centricimportances from MTS data. Starting with image encoding (specif-ically recurrence plot (RP) ), the raw MTS is transformed intoimage-like data, where our DepCA module (Sec. 3.1) is used tocompute the channel attention score a R. These scores are thenelement-wise multiplied with their respective channels, which are",
  "Depthwise Channel Attention (DepCA)": "In our work, a raw time series XR is encoded into an image-like format X R , with each channel representing a dis-tinct feature. The CA (Channel Attention) module evaluates thesechannels, employing attention scores a = [1, ...,] for globaland class-specific metric computation. Its essential that attentionscores, a, precisely captures each features unique information. Toachieve this, we introduce the Depthwise Channel Attention(DepCA) module, which surpasses traditional CA techniques inextracting comprehensive information from each channel. Whereprevious CA methods rely on simple statistics like global max-imaapt for latent channel spaces for efficiencyour methodol-ogy, with its depthwise convolution, allows the model to learninformative statistics from each feature representation. By apply-ing depthwise convolutions, we treat each feature independently,capturing distinct details without inter-feature interference. It effi-ciently extracts clear, differentiated information, as shown by ourt-SNE visualizations in .The DepCA module begins by applying a set of depthwise con-volutional filters to the input X. We use number of filters pereach feature channel (with = 3 in all experiments). This yields thefeature descriptor as Conv (X) = Fout R()HW, where is the number of channels, H and W denotes the height and widthof the output channels, respectively. Following this, DepCA per-forms two pooling operations on Fout: an average and max pooling,executed channel-wise (CW) to produce Favg, Fmax R.These pooled features are then averaged across the channels com-ing from the same original feature (i.e., feature-wise; FW). As weaim to provide a feature-centric explanation, we performed FWpooling to get an attention score for each feature. Finally, the twooutput features are combined through element-wise summation toobtain the aggregated feature representation and then passed tothe sigmoid function () = 1/(1 + exp()), to constrain the CAscore between zero and one. Putting it all together, the CA scoreof the image X, denoted as CA(X) = [1, ...,] where : Orthogonal regularization on the feature-dimension of theattentions enhances separability. Using QR-Ortho loss, we demon-strate an enhanced distinction between previously overlapping at-tentions in the Gilon dataset , consistent across five-fold CV.",
  "CA(X) (FWAvgPool(Favg) + FWAvgPool(Fmax)) a(1)": "The CA score, a, is element-wise multiplied with the image represen-tation X, expressed as a X. Here, attention values determinethe retention or suppression of features; values near 1 retainfeatures, while those close to 0 suppress them. Consequently, theseattention scores are crucial in constructing feature importance met-rics and determining the relevance of different features.",
  "Enhancing Feature Separability: QR-Ortho": "During the development of DepCA, we observed an overlappingdistribution of CA (channel attention) scores between each fea-ture (see ). This overlap complicates the derivation of precisefeature importance rankings, which are essential for computingboth global and class-specific metrics. To address this issue, we en-force an orthogonal regularization on the feature average of the CAscores to obtain distinguished CA distribution, leading to enhancedand distinct feature rankings of MTS data. illustrates theclear separation of previously overlapping CA distributions whenorthogonality is enforced. This enhanced separation contributes tothree key outcomes: (1) distinct CA distributions for each feature,(2) improved ranking measures for global and class-wise featureimportance, and as a result (3) overall better explainability of theMTS data. In our evaluation, we observe a substantial improvementin the explainability of MTS data with feature-wise orthogonality,empirically verifying its critical role in TSC model explanations.To this end, we propose QR-Ortho Loss that enforces feature-wise orthogonality along the feature dimension of the CA scoresthrough QR decomposition that factorizes a given matrix A into",
  "R(3)": "The Q matrix embodies the orthogonal basis of the feature di-mension of A, and the upper diagonal elements of the R matrix,i.e., R ( ) = q, A:,, signify the dot products between classfeature representation A:, and the orthonormal basis q. The decom-position process ensures direct orthogonality, as the orthonormalcolumns of Q inherently exhibit orthogonal properties. Also, byleveraging the widely-used Gram-Schmidt or Householder algorithms, it maintains numerical stability while guaranteeing aunique set of orthogonal vectors.Thus, by penalizing the upper off-diagonals of R, i.e., R (<),feature-wise orthogonality of the channel attentions can be effec-tively regularized. From this, we define QR-Ortho loss as:",
  "FEATURE EXPLANATION MEASURES": "We present two feature importance measures: (1) Global Impor-tance (GI) and (2) Class-Wise Relative Importance (CWRI),which provide reliable feature-wise explanations of MTS data ().While we elucidate GI and CWRI in terms of the attention scores,the computation of both measures does not favor or rely on at-tention scores. Rather, both measures can be effectively appliedin conjunction with any attribution method capable of produc-ing instance-wise attributions, as in prior studies . This isachieved by averaging the scores across the time dimension, align-ing with Eq. (5). This comprehensiveness ensures that our measuresare broadly applicable across various attribution methodologies.Global Importance (GI). The GI score quantifies the significanceof each feature in relation to classification performance over theentire data and thus simplifies the interpretation and comparisonbetween features. A feature with a high GI score is globally essentialfor accurate classifications, while a low GI score suggests negligibleinfluence on the overall model performance. We denote the GI scoreof the -th feature x as GI(x), and it is calculated by averaging the-th channel attention (CA) scores of all data samplesover all classes, as shown in Eq. (5).",
  "=1()(5)": "GI Evaluation. The evaluation on the GI score focuses on twoaspects: (1) the removal of high GI ranked feature should have ahigher drop in model performance compared to low GI rankedfeature, and (2) the order of GI ranks should be consistent withinmodels. For model performance, we employ the renowned RemOveAnd Retrain (ROAR) method , which sequentially eliminatesthe most important (truth) and least important (inverse) featuresbefore retraining the model to maintain consistent train and testdistributions (See ). Based on ROAR, we report the Drop-in",
  "(6)": "To assess the consistency in GI rankings produced for differ-ent model runs, we utilize the Spearman correlation () andKendall correlation () based on a 5-fold cross-validation (CV).Class-Wise Relative Importance (CWRI). While GI offers aglobal view of feature importance, CWRI provides detailed, class-specific insights into the role of each feature for every class {1, ...,}. This approach is particularly valuable because a featurewith a high GI score may not necessarily be of high importancefor each individual class. CWRI, therefore, provides a class-centricperspective of feature importance in MTS data. We define the CWRIscore for class , denoted as CWRI() R, as outlined in Eq. (7).For instance, the rows of -B shows the CWRI score for eachclass in the WhichFinger dataset. This class-specific score is derived",
  "a, a: see Eq. (2)(7)": "A key aspect of CWRI is its relative computation across differ-ent classes, ensuring that the sum of CWRI scores for any givenfeature is zero. This method naturally produces both positive andnegative CWRI values for the same feature across various classes.To illustrate, in a situation with three classes, the CWRI for featurex might be +1.7 for Class 1, -1.4 for Class 2, and -0.3 for Class 3.Here, a positive CWRI of feature x for Class 1 indicates higherrelative importance of this feature in classifying Class 1 comparedto Classes 2 and 3. The negative scores in Classes 2 and 3 indicatethat these features were relatively unimportant. This approach inrelatively calculating the difference is advantageous over simpleclass average scoring, which can be ambiguous and less informative,particularly when classes exhibit similar scores. CWRI Evaluation. We utilize the CWRI scores to categorize eachclass and feature into relatively important (positive scores, x 0;red cells in -B) and relatively unimportant sets (negative scores,x < 0; blue cells). Our evaluation compares these categorized fea-ture sets against the established ground truth to determine theaccuracy of feature importance identification. Given the lack ofpublic datasets with known class discriminative feature importance,we created both real-world and synthetic datasets specifically forthis purpose (detailed in Sec. 5). The comparison between our iden-tified important/unimportant sets and the ground truths employsbinary classification metrics like the F1 score, Jaccard index, andaccuracy (we use the term interpretative accuracy (IACC) for clarityover standard model accuracy). The methodology for establishingthese ground truths is elaborated in Appendix E.",
  "DATASET AND BASELINE": "GI Datasets. For GI measure, we curated two large public datasets,chosen for their substantial size and relevance (Appendix F). TheGilon Activity (7-class) comprises 14 features collected from smartinsoles utilized by 72 users . The Microsoft (MS) Activity (10-class) contains 6 features from armbands worn by 92 users .The details of all the datasets can be found in Appendix F.CWRI Datasets. Evaluating the CWRI measure on existing publicdatasets is challenging due to: (1) lacking in-depth comprehensionof the features that influence the performance for each class ,and (2) unmet requirements for ample classes ( 3), features( 3), and samples ( 10, 000) for generalization. Thus, weintroduce synthetic and real-world MTS datasets, as follows.Dataset 1: SquidGame ( = 3; = 10; = 54, 000). We designedthe SquidGame dataset (-A), a 3-class synthetic MTS data,comprising of 30 features, which are divided into sets Gcircle ={1, ..., 10}, Gtriangle = {11, ..., 20}, and Gsquare = {21, ..., 30}. ForClass 1, distinct time signals, such as sine waves, are producedwithin the circular mask in the feature set Gcircle. Meanwhile, Gauss-ian noise fills the remaining areas (grey region) outside the circularmask in Gcircle. This process mirrors the approach taken by Ismailet al. . Similarly, Classes 2 and 3 have unique time signals withintheir respective feature sets, Gtriangle and Gsquare. For each MTS",
  "CE+QR(Ours)0.6362.0460.4560.5020.3890.9240.12810.9620.5300.1200.0930.706": ": Performance Evaluation of GI Metrics on Gilon and MS datasets. Each performance metric is explained in Sec. 4. Optimal performanceis indicated by values in bold red, while the second-highest performance is marked in bold black. See Appendix C for full comparison (includingstandard deviation from five-fold cross validation) of explainers based on raw MTS data such as LSTM, and TCN. : (A) Class-specific signals in Circle, Triangle, and Squaremasks; grey regions are filled with Gaussian noise. (B-1) The smartglove has 10 sensors, two per finger. (B-2, 3) We depict the data ac-quisition process for Class 1 and 2 for the WhichFinger. Specifically,Class 1 involves folding and unfolding movements of the thumb. Incontrast, Class 2 is the complement of Class 1, focusing on the fold-ing and unfolding of the remaining four fingers (See Appendix G). instance, the location and size of the masks are randomly generatedwithin the three feature sets to increase complexity.Dataset 2: WhichFinger ( = 10; = 10; = 18, 010). We gath-ered a real-world MTS dataset using a smart glove from 19users, called WhichFinger (-B), to validate the CWRI measure.The smart glove incorporated with two sensors for each fingermeasures the resistance change in response to the tensile forceexerted by each finger. We capture ten unique finger movements,achieved by either flexing and extending a single finger or a groupof four fingers. Owing to the interlinked nature of hand muscles,we observe realistic correlations among features, making the taskboth intricate and non-trivial, providing a valuable MTS dataset forXAI applications. Detailed descriptions of the task design and datacollection methodologies are provided in Appendix G. Implementation and Baselines. We compare CAFO to severalpost-hoc explanation methods i.e., Gradient Shap (GS) , ShapleyValue Sampling (SVS) , Saliency , Feature Ablation (FA) ,Integrated Gradients (IG) , and DynaMask (DM) . We uti-lized several deep architectures including vision-based deep models:ShuffleNet , ResNet , MLP-Mixer , and Vision Trans-former (ViT) , and sequence based deep models like LSTM and TCN. We adopt FIT , an explainer designed for recurrentmodels. We also employ LAXCAT , a 1-D CNN based MTSexplainer. A detailed description is in Appendix H.",
  "RESULTS6.1Evaluation of Global Importance": "We evaluated CAFOs performance in the GI measure using Gilonand MS datasets. The results for vision-based models like ShuffleNet,ResNet, MLP-Mixer, and ViT are in Tab. 1. Models using raw MTSformat (e.g., LSTM, TCN, LAXCAT) and post-hoc methods relyingon raw MTS (e.g., FIT, DynaMask) are detailed in Appendix C.Generally, vision-based models excel in most scenarios.CAFO consistently demonstrates superior performance acrosskey metrics (ABC, DA, WDA), highlighted in bold red in the Gilondataset: notably, ShuffleNet (1.227), MLP-Mixer (1.144), and ViT (0.636)in the ABC metric. The use of QR-Ortho with cross-entropy (CE)significantly improved GI metric performance in most cases: 10of 12 in Gilon and 9 of 12 in MS datasets. Notably, several base-lines showed negative ABC scores, indicating a mismatch betweencritical feature identification and the drop in model accuracy, asseen in ROARs inverse and truth lines (). This suggests somebaseline explainers inadequately measure GI rankings. Our find-ings show minimal difference in model accuracy between with andwithout QR-Ortho integration. The regularization parameter in",
  "Consistency in GI Ranks": "6.2.1Within Models. Establishing consistency in model explana-tions is imperative for fostering user trust, as highlighted by Riberioet al. . Conversely, models that yield divergent feature rank-ings across multiple runs undermine confidence in users decision-making processes. Although prior research has underscoredthe variability in time-step importance produced with post-hocexplanation methods, our study is the initial effort to identify andquantitatively evaluate such variability in the context of feature-based importance. Our evaluation involves executing each modelthrough 5 iterations of CV, with each fold serving once as a valida-tion set and the remaining as training. This process yields 5 distinctfeature rankings for the same left-out test set, from which we com-pute the pairwise Spearmans and Kendalls coefficients togauge rank consistency, with the findings presented in Tab. 1. No-tably, CAFO demonstrates the highest consistency in 11 out of 16instances. Across the board, our results reveal there exists a hugevariability in feature rankings, even under constant model architec-tures and explanatory methods. Alarmingly, certain explanatorymethods yield negative correlations, indicating inverted rankingorders across different runs. These findings raise the need for morerobust explanatory frameworks that can deliver dependable andstable feature rankings. 6.2.2Between Models. Our analysis extends to assessing featurerank consistency across different models. The Spearman correlationcoefficients, visualized as a heatmap in , reveal that the use ofQR-Ortho significantly improves feature ranking consistency acrossmodels compared to CE alone, demonstrating CAFOs robustnessin providing consistent feature rankings, independent of modelarchitecture. While different models naturally prioritize varyingfeatures for optimal performance, a degree of ranking consistencyis a robustness indicator, fostering model trust. Additionally, ana-lyzing ranking discrepancies offers deep insights. For example, asindicated by the yellow arrow in , we observe an anomaly : The GI metric at each training epoch is visualized, withbold red lines representing the irrelevant signal, while the thin greylines correspond to the actual variables in the Gilon task. Over thecourse of training, the pseudo signals (i.e., bold red lines) consistentlyconverge to the lowest GI values. where a single run from the ViT model presents an entirely reversedfeature ranking relative to all other runs. Such an outlier warrantsfurther investigation by developers to ascertain the presence of po-tential errors or anomalies in the model training or data processing.These insights can prove invaluable in enhancing model reliability.",
  "Robustness to Irrelevant Signals": "In real world MTS problems, the overabundance of data often resultsin the accumulation of measurements from superfluous sensors .Eliminating such irrelevant feature is, therefore, a critical task forpractitioners. To assess the efficacy of CAFO in filtering out in-significant variables during model training, we generate pseudosignals from time series processes: White noise, Sinusoidal,and Gaussian Process (detailed in Appendix J). The GI measurefrom each training epoch is visualized in . Initially, the pseudo-variables GI value is near 0.5, but it converges to the lowest GIranking as training advances. This demonstrates CAFOs robust-ness against non-significant variables and its potential to identifyand discard non-significant features.",
  "Class-Wise Relative Importance": "Assessing feature relevance for specific classes is critical in applica-tions like predictive maintenance in Heating, Ventilating, and AirConditioning (HVAC) systems, where sensor importance varies byfault (class) type (Appendix A). Our CWRI methodologyoffers valuable information for sensor prioritization for each class.In this study, we evaluate the ability of CAFO to identify crit-ical class-wise features using the CWRI metric on two datasets:SquidGame and WhichFinger. As discussed in Sec. 5, these datasetscome with ground truth labels indicating the relevance of featureson a class-wise basis. As detailed in Tab. 2, CAFO surpasses other ex-planatory models in accurately identifying class-specific features in13 out of 24 scenarios. We also note that integrating QR-Ortho Lossconsistently enhances the discernment of class-wise relevant fea-tures across the table, compared to the standalone use of CE (cross-entropy) loss. Moreover, we observe a general performance degra-dation of all explainers in the WhichFinger dataset compared toSquidGame dataset, which may be attributed to the increased com-plexity inherent in real-world data. Such observation underscoresthe need for the development of real-world data oriented for XAI,especially in the time series domain.",
  "Other Image Encoding Methods. We provide several mainexperiment results with the Gramian Angular Field image encodingmethod in Appendix B": "6.5.2Effect of . We evaluated the effect of -a key hyperparam-eter in our model which modulates the QR-Ortho Loss (Eq. (4))-(ranging from 0 to 1) on two tasks: SquidGame and WhichFinger.Results indicate that increasing improves CWRI-related metrics,but excessively high values can reduce model accuracy. Detailedfindings are in Appendix K. 6.5.3Alignment with Domain Knowledge. Using Gilon and MSdatasets, we demonstrated CAFOs alignment with established do-main insights. For the Gilon task, accelerometer features were cru-cial for speed differentiation, and in the MS task, similar activitiesyielded similar attention scores. Visual evidence of these correla-tions is provided in Appendix L.",
  "Limitations and Discussions": "We discuss the following limitations of CAFO. As our evaluationstrategy for the GI method inherits the ROAR method , theretraining and re-evaluation cost is computationally intensive. Con-sequently, there is a need for alternative explanation methodolo-gies that either do not rely on model accuracy or employ morecomputationally efficient evaluation techniques for the GI method.Additionally, our CAFO leverages image encoding to represent atime series into an image-like representation. While this approachhas its merits, it also restricts the type of models used. As such,our research agenda includes the development of evaluation meth-ods that are not only less demanding in terms of computationalresources but also architecture-agnostic.",
  "CONCLUSION": "In this paper, we introduce CAFO, a feature-centric explanationframework for MTS classification. An in-depth discussion regardingthe feature-centric explanation for MTS has been missing in muchof the previous literature despite its huge importance, due to thelack of evaluation protocols, pertinent benchmarks, and method-ologies. Addressing these problems, our contribution is threefold:First, we present CAFO, a channel attention-based feature explainerwhich combines a novel depth-wise channel attention module, De-pCA, with QR-Ortho regularization for feature explanation in timeseries. Second, we curate a collection of both real-world and syn-thetic datasets, each annotated with known discriminative featureimportance. Third, we introduce a set of feature importance met-rics designed to quantify both global and class-specific importance,complete with corresponding evaluation schemes. We believe thatour work will serve as a new groundwork for understanding featureimportance within MTS classification. This work was supported by the National Research Foundation ofKorea(NRF) grant funded by the Korea government(MSIT) (RS-2023-00277383), and Institute of Information & communications Technol-ogy Planning & Evaluation(IITP) grant funded by the Korea govern-ment(MSIT) (No.RS-2020-II201336, Artificial Intelligence graduateschool support(UNIST)). The authors extend their gratitude to theGilon Corporation for inspiring this work. Special thanks are dueto Prof. Sunghoon Lim, Gyeongho Kim, Sujin Jeon, and Jae GyeongChoi for providing the smart glove essential for the WhichFingerdata collection and for their valuable insights into our research. Weare also grateful to MyoungHoon Lee, Prof. Suhyeon Kim, WonhoSohn, and Hyewon Kang for their initial discussions that shaped ourpaper. Appreciation is further extended to Yeonjoo Kim, Solang Kim,Bosung Kim, Isu Jeong, Jaewook Lee, and Changhyeon Lee for theirthorough review of our manuscript. Lastly, we thank the numerousanonymous reviewers whose constructive feedback significantlyenhanced our work.",
  "Herv Abdi. 2007. The Kendall rank correlation coefficient. Encyclopedia ofMeasurement and Statistics. Sage, Thousand Oaks, CA (2007), 508510": "Joo Bento, Pedro Saleiro, Andr F Cruz, Mrio AT Figueiredo, and Pedro Bizarro.2021. Timeshap: Explaining recurrent models through sequence perturbations.In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery &Data Mining. 25652573. Jonas Beuchert, Friedrich Solowjow, Sebastian Trimpe, and Thomas Seel. 2020.Overcoming bandwidth limitations in wireless sensor networks by exploitationof cyclic signal patterns: An event-triggered learning approach. Sensors 20, 1(2020), 260.",
  "Jean-Pierre Eckmann, S Oliffson Kamphorst, David Ruelle, et al. 1995. Recurrenceplots of dynamical systems. World Scientific Series on Nonlinear Science Series A16 (1995), 441446": "Pavel Filonov, Andrey Lavrentyev, and Artem Vorontsov. 2016. Multivariateindustrial time series with cyber-attack simulation: Fault detection using anlstm-based predictive data model. arXiv preprint arXiv:1612.06676 (2016). Colin R Goodall. 1993. 13 Computation using the QR decomposition. (1993). Jianing He, Xiaolong Gong, and Linpeng Huang. 2021. Wavelet-temporal neu-ral network for multivariate time series prediction. In 2021 International JointConference on Neural Networks (IJCNN). IEEE, 18.",
  "Jie Hu, Li Shen, and Gang Sun. 2018. Squeeze-and-excitation networks. In Proceed-ings of the IEEE conference on computer vision and pattern recognition. 71327141": "Aya Abdelsalam Ismail, Mohamed Gunady, Hector Corrada Bravo, and SoheilFeizi. 2020. Benchmarking deep learning interpretability in time series predictions.Advances in neural information processing systems 33 (2020), 64416452. Aya Abdelsalam Ismail, Mohamed Gunady, Luiz Pessoa, Hector Corrada Bravo,and Soheil Feizi. 2019. Input-cell attention reduces vanishing saliency of recurrentneural networks. Advances in Neural Information Processing Systems 32 (2019). Maowei Jiang, Pengyu Zeng, Kai Wang, Huan Liu, Wenbo Chen, and Haoran Liu.2022. FECAM: Frequency Enhanced Channel Attention Mechanism for TimeSeries Forecasting. arXiv preprint arXiv:2212.01209 (2022). Jaeho Kim, Hyewon Kang, Jaewan Yang, Haneul Jung, Seulki Lee, and JunghyeLee. 2023. Multi-task Deep Learning for Human Activity, Speed, and BodyWeight Estimation using Commercial Smart Insoles. IEEE Internet of ThingsJournal (2023). Colin Lea, Michael D Flynn, Rene Vidal, Austin Reiter, and Gregory D Hager.2017. Temporal convolutional networks for action segmentation and detection.In proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.156165. Jiyoon Lee, Hyungrok Do, Mingu Kwak, Hyungu Kahng, and Seoung Bum Kim.2021. Hierarchical segment-channel attention network for explainable multi-channel signal classification. Information Sciences 567 (2021), 312331.",
  "Jongchan Park, Sanghyun Woo, Joon-Young Lee, and In So Kweon. 2018. Bam:Bottleneck attention module. arXiv preprint arXiv:1807.06514 (2018)": "Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. \" Why should itrust you?\" Explaining the predictions of any classifier. In Proceedings of the 22ndACM SIGKDD international conference on knowledge discovery and data mining.11351144. Udo Schlegel, Hiba Arnout, Mennatallah El-Assady, Daniela Oelke, and Daniel AKeim. 2019. Towards a rigorous evaluation of XAI methods on time series. In2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW).IEEE, 41974201.",
  "Saman Taheri, Amirhossein Ahmadi, Behnam Mohammadi-Ivatloo, and SomayehAsadi. 2021. Fault detection diagnostic for HVAC systems via deep learningalgorithms. Energy and Buildings 250 (2021), 111275": "Ilya O Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, XiaohuaZhai, Thomas Unterthiner, Jessica Yung, Andreas Steiner, Daniel Keysers, JakobUszkoreit, et al. 2021. Mlp-mixer: An all-mlp architecture for vision. Advances inneural information processing systems 34 (2021), 2426124272. Sana Tonekaboni, Shalmali Joshi, Kieran Campbell, David K Duvenaud, andAnna Goldenberg. 2020. What went wrong and when? Instance-wise featureimportance for time-series black-box models. Advances in Neural InformationProcessing Systems 33 (2020), 799809. Hugues Turb, Mina Bjelogrlic, Christian Lovis, and Gianmarco Mengaldo. 2023.Evaluation of post-hoc interpretability methods in time-series classification.Nature Machine Intelligence 5, 3 (2023), 250260.",
  "Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE.Journal of machine learning research 9, 11 (2008)": "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,Aidan N Gomez, ukasz Kaiser, and Illia Polosukhin. 2017. Attention is allyou need. Advances in neural information processing systems 30 (2017). Zhiguang Wang, Tim Oates, et al. 2015. Encoding time series as images forvisual inspection and classification using tiled convolutional neural networks. InWorkshops at the twenty-ninth AAAI conference on artificial intelligence, Vol. 1.AAAI Menlo Park, CA, USA.",
  "Sanghyun Woo, Jongchan Park, Joon-Young Lee, and In So Kweon. 2018. Cbam:Convolutional block attention module. In Proceedings of the European conferenceon computer vision (ECCV). 319": "Feiyu Xu, Hans Uszkoreit, Yangzhou Du, Wei Fan, Dongyan Zhao, and Jun Zhu.2019. Explainable AI: A brief survey on history, research areas, approachesand challenges. In Natural Language Processing and Chinese Computing: 8th CCFInternational Conference, NLPCC 2019, Dunhuang, China, October 914, 2019,Proceedings, Part II 8. Springer, 563574. Lingxiao Yang, Ru-Yuan Zhang, Lida Li, and Xiaohua Xie. 2021. Simam: Asimple, parameter-free attention module for convolutional neural networks. InInternational conference on machine learning. PMLR, 1186311874.",
  "Liang Zhang and Jin Wen. 2019. A systematic feature selection procedure forshort-term data-driven building energy forecasting model development. Energyand Buildings 183 (2019), 428442": "Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. 2018. Shufflenet: An ex-tremely efficient convolutional neural network for mobile devices. In Proceedingsof the IEEE conference on computer vision and pattern recognition. 68486856. Zhibin Zhao, Tianfu Li, Jingyao Wu, Chuang Sun, Shibin Wang, Ruqiang Yan,and Xuefeng Chen. 2020. Deep learning algorithms for rotating machineryintelligent diagnosis: An open source benchmark study. ISA transactions 107(2020), 224255.",
  "A.1Case Studies": "Case Study 1: Optimization of Fault Detection and Diagnosis (FDD) in Heating, Ventilation, and Air Conditioning (HVAC)Systems is an important issue in energy preservation as it can prevent excessive energy consumption in buildings . Preemptivemaintenance in HVAC systems aims to predict potential equipment failure, using data from Internet of Things (IoT) sensors embeddedwithin the system . Despite the integration of numerous sensors and controllers to monitor a variety of system faults, fault detection inHVAC systems remains a complex task due to the non-linearity of fault patterns and strong feature correlations. The situation is furthercomplicated by the hundreds of sensors indicating different types of defects across varying operational modes, such as air conditioning andheating . Thus, identifying the sensors most contributory to a specific fault can aid maintenance specialists in accurately diagnosing themalfunction. Prioritizing sensors capable of diagnosing a broad spectrum of faults can enhance system efficiency. This comprehension of theglobal and class-specific importance of features provides invaluable insights into sensor design and placement, beneficial for manufacturers.Armed with these insights, domain experts can elucidate the role of each feature in fault detection, aiding engineers in the development ofmore effective fault detection models.Case Study 2. The Smart insole contains numerous sensors, such as an accelerometer, force-sensitive resistor (FSR), and gyroscope, tocapture various gait characteristics. The data acquired from these sensors serve to monitor a range of human activities. Notably, in theprocess of recognizing these activities, some sensors may prove multi-functional across several classes, while others may be specificallycritical for a distinct task. For example, an accelerometer may be instrumental in detecting varying speed ranges of movement, whereas anFSR sensor could effectively discern the users posture. Yet, how can we ascertain that the black-box model is appropriately employing thesefeatures? In this scenario, the Global Importance (GI) and Class-Wise Relevant Importance (CWRI), calculated from CAFO, offer invaluableinsights into the models sensor prioritization. While GI denotes the sensor that contributes most significantly to enhanced classificationaccuracy, a high GI score for an accelerometer, for instance, does not necessarily confer high importance to each class (e.g., Squat, Lunge).CWRI, on the other hand, provides class-specific insights into feature prioritization.Understanding the role of each sensor affords substantial benefits for both engineers and practical applications. Engineers, for instance,can harness this information to implement feature selection and extraction strategies for predictive models. Moreover, manufacturers canleverage this knowledge to design more efficient and cost-effective smart insoles, by eliminating redundant sensors in the production phase,thus lowering both production and data transfer costs for cloud processing.",
  "BIMAGE ENCODING METHODSB.1Recurrence Plot": "A univariate time series x = [1, ..., ] is converted to a two-dimensional recurrence plot (RP) image by composing ( 1)number of new vectors v1, ..., v, where v is a vector consisting of raw time series as in Eq. (8). Here is the time delay, and is theembedding dimension selected as a hyperparameter.",
  "v = [,+,+2, ...,+(1)](8)": "These vectors are finally transformed into an RP image by measuring the pairwise distance between all vectors v1, ..., v, leading to an image. Each element of the RP image is defined in Eq. (9). The threshold distance , Heaviside step function H, and a norm function || ||should be properly selected.",
  "B.2Gramian Angular Field": "The Gramian Angular Field (GAF) is an image encoding method used for time series data. It has two subtypes: the Gramian AngularSummation Field (GASF) and the Gramian Angular Difference Field (GADF). In our supplementary experiment, we utilized the GASF subtypeof GAF and referred to them as GAF unless otherwise indicated.The data is first scaled between the range to represent the time series in a polar coordinate system using = arccos () for1, ...,. A Gram matrix is calculated between all pairs of =1,..., as in Eq. (10) and is used as the GAF.",
  "Baseline(None)Laxcat-0.458-4.217-0.230-0.0160.34-0.0070.250.711-0.2251.0030.1390.0740.460.0930.400.759": ": Performance Evaluation of GI Metrics: This table presents the evaluation of GI metrics such as ABC, DA, WDA, , from a five-foldcross-validation (CV) process. As ABC, DA, and WDA are metrics that are derived from the averaged outcomes of the five-fold CV, it is notpossible to calculate a standard deviation for these metrics. For clarity, the top-performing result for each model is indicated in red bold,while the second-highest performance is denoted in black bold. The evaluation is divided into two sections: Panel A focuses on the outcomesof vision-based deep learning models, whereas Panel B details the performance of LSTM and TCN models, assessed using various explainermethods including Gradient Shap (GS), Shapley Value Sampling (SVS), Saliency, Feature Ablation (FA), Integrated Gradients (IG), FIT, andDynaMask (DM). Here, Laxcat is featured both as an explainer method and as a model in its own.",
  "CGI FULL RESULTS": "CAFO Models. ShuffleNet , ResNet , MLP-Mixer , and ViT (Vision Transformer) .Baseline Models. LSTM (long short-term memory) and TCN (temporal convolutional network) .Baseline Explainers. Gradient Shap (GS) , Shapley Value Sampling (SVS) , Saliency , Feature Ablation (FA) , IntegratedGradients (IG) , DynaMask (DM) , FIT , and LAXCAT .",
  "C.1GI Metric Calculation": "Area between curve (ABC). Here, we assume that we have a training set which is split into five-fold cross-validation (CV), and a left-outtest set. Each CV fold serves as a validation set against this test set. We start with a complete set of features, performing five-fold CV toderive feature rankings based on Global Importance (GI) scores from each run, which are then averaged to establish the final GI rankings.These features are arranged in descending order for the truth rank and ascending order for the inverse rank. Sequentially, we remove eachfeature from both training and test sets to assess model performance, hypothesizing that removing a critical feature decreases accuracy,while removing a non-essential feature doesnt impact performance significantly. After eliminating all features, we calculate the ABC metricby measuring the area between the two resulting performance curves ( (),()),",
  "=1( () () + (+1) (+1))": "Drop in accuracy (DA). The drop in accuracy (DA) calculates the percentage decrease in accuracy of a model when % percentage ofthe most important features (denoted as K_acc) identified by the model are dropped, compared to the base accuracy (when no features aredropped; denoted as base_acc). This is done by subtracting the accuracy after dropping % of the total features from the base accuracy andthen dividing by the base accuracy. The result is multiplied by 100 to express it as a percentage. Here, we set = 20%. This metric helps inunderstanding the impact of removing the most important features on the models performance. Mathematically, DA is given as",
  ": The ROAR plot on the Microsoft Activity task for all baseline models": "Weighted drop in accuracy (WDA). While DA provides a snapshot of the degraded model performance at a specific , the weighteddrop in accuracy (WDA) complements DA by considering the impact of dropping each feature individually and combines these impacts ina weighted manner. To compute WDA, consider as the total number of features in the dataset. For each feature indexed by (where ranges from 0, ..., 1), the weight is calculated as follows:",
  "( 1)": "In this formula, the weight decreases linearly with the index d, reflecting the diminishing marginal impact of removing additional features.For instance, given 14 features as in the Gilon task, the weights are given as 1.0, 0.923, 0.846, 0.769, 0.692, 0.615, 0.538, 0.461, 0.384, 0.307,0.230, 0.153, 0.077. The WDA is calculated as below. Here, base_acc is the base accuracy, and d_acc represents the accuracy of model when features are removed.",
  "=0(base_acc d_acc)": "Spearman and Kendall . As in the area between curve (ABC) metric computation, we assume a training-set consisting of five-fold CV,with a left-out test set. Using each fold as a validation set, we can obtain five feature ranks. We calculate the pairwise spearman correlationand Kendall correlation, and state the average value.",
  "Random0.4000.060.2520.050.5010.050.4980.060.3340.050.4990.05NoneLAXCAT0.5680.050.3980.050.5180.070.5450.070.3770.070.5700.06": ": Performance Evaluation of CWRI Metrics. This table presents the evaluation of CWRI metrics using F1 Score, Jaccard, and Accuracy(IACC). We use the term IACC to differentiate with model accuracy. The metrics are measured based on the predicted class-wise importance ofeach explainer methods against the established ground truth class-wise importance. All experiments were conducted with a five-fold crossvalidation.",
  "EEVALUATION OF CWRI METRICS": "During the evaluation of the CWRI measure, we encountered a dilemma regarding the establishment of ground truth for each class. Whilewe can identify the exact features relevant to each class, the model is not obligated to base its predictions on these features exclusively.For instance, flexing the thumb (class 1-Thumb only; )) implies that the remaining four fingers remain still, which also serves as auseful identifier for the class. This deviates from spurious correlation, as the association between features and class predictions is not merelycoincidental. : Ground Truth Design of SquidGame. (A) The design of SquidGame task. (B) & (C). Two distinct ground truth label types are establishedfor the SquidGame task. In this context, the red feature sets signify more critical or influential features, whereas the blue feature sets representthose that are comparatively less important or impactful. : An example of a predicted CWRI score for the WhichFinger task. (A) The CWRI score is predicted using MLP-Mixer. (B) & (C). Twodistinct ground truth label types are established for the WhichFinger task. In this context, (A) follows the ground truth label of (C) rather than(B). In order to quantitatively assess the CWRI score, we generated two distinct sets of ground truth labels, as illustrated in and .Each of these ground truth label sets was utilized to evaluate the predicted CWRI score. We selected the ground truth label that produced ahigher F1 score, as it represented the only feasible approach for evaluating the CWRI score. This decision was grounded in the understandingthat the model may have considered these feature sets crucial during that particular run.Throughout our experimentation, we observed that a model adheres to a consistent ground truth label, notwithstanding variations inseed and cross-validation folds. Nevertheless, the choice of ground truth may shift between different architectures and the application ofQR-Ortho Loss. Determining which ground truth label the model will adopt remains an open question and constitutes a challenge that weintend to investigate in future work.",
  ": Smart insole used to collect the Gilon Activity task. Used with permission": "Gilon Activity . This dataset comprises smart insole measurements gathered from 72 distinct users in South Korea. The smart insolerecords 14 different sensor measures, split evenly between the left and right feet. These metrics include three-dimensional accelerometerreadings (X, Y, Z) and data from four force-sensitive resistors (FSRs). These participants engaged in seven specific activities while equippedwith the smart insole. The activities include standing still (0), walking on the ground (1), walking on a treadmill at a constant speed (2),running on a treadmill at a constant speed (3), performing lunges (4), squats (5), and jumping jacks (6). The original study establishedpredefined train/test splits based on the users. As a result, the training set is composed of data from 50 users, amounting to 33,368 samples,while the test set consists of data from 22 users, totaling 14,279 samples. Further, within the training set, the data is divided into five-folds.Each fold uses a different group of users as a validation set, ensuring a balanced evaluation across the dataset. The dataset was segmentedinto windows size of 160 with an overlapping length of 120. The five-fold cross validation in our research was conducted by using eachvalidation split with the fixed test set. The dataset ( can be accessed by request.The dataset is protected under CC-BY-NC-ND-4.0 license.MS Activity . The original dataset (exercise_data.50.0000_singleonly.mat) contains 114 users performing 72 distinct gym exercises,recorded in 4,686 sessions with wearable arm sensors. The armband includes a 3-axis accelerometer (X, Y, Z) and gyroscope (X, Y, Z). To addressthe imbalance in the number of sessions across activities, we refined the dataset by selecting exercises with session counts ranging between 25and 70, based on an empirical analysis of the data distribution. We then focused on activities featuring similar physical motions to effectivelyshowcase our class-wise importance metric. This resulted in a curated set of activities, including Bicep Curl (0), Biceps Curl with Band (1),Jump Rope (2), Plank (3), Pushups (4), Squat (5), Squat with Hands Behind Head (6), Squat Jump (7), Walk (8), and Walking Lunge (9). The datawas segmented into non-overlapping windows of 200 samples each. The final processed dataset comprises training (65 users; 10,892 samples)and testing subsets (28 users; 3,309 samples), with the training data further divided into five-fold cross validation, following the approachused in the Gilon dataset. The raw dataset can be accessed in (",
  ": The figure illustrates the detailed finger movement for each class. (a) and (b) for each class are repeated for more than one minute": "The WhichFinger Dataset is a multivariate time series (MTS) dataset, designed for eXplainable Artificial Intelligence (XAI) applications.This dataset offers comprehensive information on the data collection process for each class, as well as the features relevant to specific classes,which facilitates the validation of the CWRI measure. We created this dataset because, to the best of our knowledge, no public MTS datasetsmet the following three criteria: (1) strong prior knowledge or information regarding each features contribution to specific classes, (2) asufficient number of classes ( 2) and features ( 2), and (3) an adequate number of samples ( 1, 000). In this section, we describethe detailed data collection process and the preprocessing steps involved in the creation of the dataset.",
  "G.3Data Collection Process": "Experiment Condition. Participants were instructed to wear the smart glove on their right hand. The supervisor sat adjacent to eachparticipant, closely monitoring the data collection process during the entire experiment. The supervisor also provided a thorough explanationof the experimental procedures and specific actions required from the participants.Experiment Procedure. A total of 10 unique finger movements, corresponding to 10 different categories, were recorded. The fingermovements captured included: (1) Thumb only, (2) Thumb except, (3) Index only, (4) Index except, (5) Middle only, (6) Middle except, (7)Ring only, (8) Ring except, (9) Pinky only, and (10) Pinky except. These specific finger movements are depicted in detail in . For eachcategory, participants carried out the actions for one minute. Upon completing every two categories, a one-minute break was provided, orextended if requested by the participant. The entire data recording process took approximately 20 minutes for each participant to complete.As the experiment aimed to identify specific features contributing to each class, it was necessary to minimize undesired finger movements.However, due to the interconnected nature of finger muscles, it is impossible to keep the other fingers completely still while moving onefinger. Therefore, participants were encouraged to use their left hand to support and constrain the fingers that needed to remain stationary.When required, duct tape was also employed to reinforce these constraints. Despite these measures to reduce extraneous movements, theycould not be entirely eliminated, leading to sensor measurements that still captured some unintended finger motions.Data Exclusion. One participant had to be excluded from the study as a result of data records being lost during the data collection process,resulting in 19 user information in the final dataset.",
  "G.4Data Preparation for Model Training": "Data Shape. We dropped the first and last 150 recordings (approximately 2 seconds) from each class measurement. The resulting dataset foreach class contains on average 4190 268 recordings (rows) for each finger activity.Data Preprocessing. We adopted a similar preprocessing approach for the recorded data as described in the work of . The multivariatetime series (MTS) data was segmented into consecutive 2-second time windows (120 rows) with a 75% overlap (80 rows) between windows.This segmentation was performed within each class and participant. Consequently, for each class, we obtained an average of 102 MTSinstances, calculated as ( (4190120) 12080+ 1) = 102 for each class recording.Data Split. Out of the 19 participants, four were randomly chosen for the test set. The remaining 15 participants were divided into fivegroups, with each group serving as a validation set. This resulted in a 5-fold cross-validation (CV) setup.",
  "H.2CAFO": "Throughout our experiments, we set the expansion filter number = 3 in the DepCA module. The task-specific hyperparameter inQR-Ortho loss requires a grid search, which we perform for {0.1, 0.2, 0.5, 1.0} in each task, selecting based on the best validationaccuracy. Consequently, we used = 0.5 for Gilon, = 0.1 for Microsoft, and = 1.0 for both SquidGame and WhichFinger.",
  "H.3Deep Architectures": "ShuffleNet We utilized grouped convolution, setting the group number to 3, and configuring the output channels as follows: .Here, is the number of input feature channels.ResNet. We used the original implementation of the ResNet but with 9 layers.MLP-Mixer. For MLP-Mixer, we used the implementation from We set the number ofMixer layers to 3 and the feed-forward layer dimension to 256.Vision Transformer. We used the implementation from We configured the Transformer architec-ture with three blocks, each containing a multi-head attention mechanism with three heads. Additionally, the dimensions of all feed-forwardlayers were set to 256. For both MLP-Mixer and Vision Transformer, the patch size was set to 1/10th of the original input image for Gilon,Microsoft, and WhichFinger, while 1/8th was used for SquidGame due to its smaller image size.",
  "H.4Baselines": "All explainers produce attributions for each time step, yielding an attribution size of R . We average the attributions feature-wise andutilize these values to compute metrics in our study.FIT. We trained a feature generator using a gated recurrent unit (GRU) as in the original implementation of . The hidden dimension wasset to 256, and 1 layer was used for GRU. We generated ten monte carlo samples for each time stamp.DynaMask. We used the original implementation of . However, due to the immense computational complexity in optimizing theperturbation mask, we reduced the optimization step to 50 for each instance.LAXCAT. We set a task specific kernel and stride size for 1-D convolution. As the original paper did not release the code, we used a thirdparty implementation from We used the implementations from the CAPTUM library .",
  "JPSEUDO VARIABLES": "We generate random pseudo signals from three different time series process using the TimeSynth library. The pseudo signal wasgenerated for each MTS instance. We used the default setting from the library. (1) WhiteNoise. Gaussian noise with a zero mean and a 0.3 standard deviation(2) Sinusoidal. Sine waves with an amplitude of one and a frequency of 0.25(3) Gaussian Process. Matern kernel was used with nu=1.5",
  "KEFFECT OF": ": (Top row) CWRI related metrics are visualized for the SquidGame task. Here, = 0 is equivalent to using the CE loss only. We observea general upward trend as is increased. (Bottom row) The general upward trend observed in the SquidGame is weaker in the WhichFinger. We conduct a grid search of {0, 0.1, 0.2, 0.5, 1.0}, a task-specific hyperparameter that controls the strength of QR-Ortho Loss( Eq. (4)),for SquidGame and WhichFinger tasks. As shown in , metrics related to the evaluation of CWRI generally improve with larger .",
  "LALIGNMENT WITH DOMAIN KNOWLEDGE": "In the domains of vision and natural language processing, XAI methodologies have aimed to demonstrate the alignment of their explanationswith human intuition. This is typically achieved by superimposing attention maps onto images highlighting class-related features orvisualizing the intensity of attention signals connecting pairs of related words . Our methodology adopts a parallel strategy but byvisualizing the differences between attention vectors derived from closely related classes. By doing so, we show that the explanations madewith CAFO align with domain knowledge but also provide a deeper insight into the subtleties differentiating one class from another.We employ real-world datasets, namely Gilon and MS, to illustrate this methodology. For visual analysis, we gather class attentionprototypes a R(Eq. (2)) for each epoch , forming a class attention matrix A R. Here, we visualize | A A |( ). Our firstvalidation, showcased in -A, tests the hypothesis that similar activities should yield similar attention scores. The comparison between(a) Bicep Curl (w/o band) and Bicep Curl with Band, and (b) Bicep Curl (w/o band) and Jump Rope from the MS data, supports this. Theattention scores of similar activities (Bicep Curl (w/o band) and Bicep Curl with Band) show minor divergence, whereas there is a largedifference in the attention scores when comparing Bicep Curl to Jump Rope.Subsequently, we verify that accelerometer features should be the main feature in differentiating varying speed ranges in -B. For thisexperiment, we utilized a downstream regression task from the Gilon, where the objective is to regress the speed at which the users aremoving on a treadmill. Here, we train with mean square error loss and without QR-Ortho regularizer on the Gilon dataset. We visualize thedifference between the 0km/hr (stationary position) and the remaining speed labels (3, 5, 7, and 8 km/hr). We first observe that the attentiondivergence is large for accelerometer features across all speed ranges. Moreover, this divergence escalates with larger speed difference,denoted by the brightness in the heatmap. This change in color difference highlights the role of accelerometer features in differentiatingspeed ranges, a finding that is consistent with established knowledge.",
  "Niima Es-Sakali, Moha Cherkaoui, Mohamed Oualid Mghazli, and Zakaria Naimi. 2022. Review of predictive maintenance algorithms applied to HVAC systems. Energy Reports8 (2022), 10031012": "Narine Kokhlikyan, Vivek Miglani, Miguel Martin, Edward Wang, Bilal Alsallakh, Jonathan Reynolds, Alexander Melnikov, Natalia Kliushkina, Carlos Araya, Siqi Yan, et al. 2020.Captum: A unified and generic model interpretability library for pytorch. arXiv preprint arXiv:2009.07896 (2020). Jiangyan Liu, Daliang Shi, Guannan Li, Yi Xie, Kuining Li, Bin Liu, and Zhipeng Ru. 2020. Data-driven and association rule mining-based fault diagnosis and action mechanismanalysis for building chillers. Energy and Buildings 216 (2020), 109957. Ilya Loshchilov and Frank Hutter. 2017. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101 (2017). Setu Madhavi Namburu, Mohammad S Azam, Jianhui Luo, Kihoon Choi, and Krishna R Pattipati. 2007. Data-driven modeling, fault diagnosis and optimal sensor selection forHVAC chillers. IEEE transactions on automation science and engineering 4, 3 (2007), 469473. Jeffrey Schein and Steven T Bushby. 2006. A hierarchical rule-based fault detection and diagnostic method for HVAC systems. Hvac&r Research 12, 1 (2006), 111125. Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. 2017. Grad-cam: Visual explanations from deep networksvia gradient-based localization. In Proceedings of the IEEE international conference on computer vision. 618626."
}