{
  "Abstract": "In recent years, online social networks have been the target of adversaries who seek to introducediscord into societies, to undermine democracies and to destabilize communities. Often the goal is not tofavor a certain side of a conflict but to increase disagreement and polarization. To get a mathematicalunderstanding of such attacks, researchers use opinion-formation models from sociology, such as theFriedkinJohnsen model, and formally study how much discord the adversary can produce when alteringthe opinions for only a small set of users. In this line of work, it is commonly assumed that the adversaryhas full knowledge about the network topology and the opinions of all users.However, the latterassumption is often unrealistic in practice, where user opinions are not available or simply difficult toestimate accurately.To address this concern, we raise the following question: Can an attacker sow discord in a socialnetwork, even when only the network topology is known? We answer this question affirmatively. Wepresent approximation algorithms for detecting a small set of users who are highly influential for thedisagreement and polarization in the network. We show that when the adversary radicalizes these usersand if the initial disagreement/polarization in the network is not very high, then our method gives aconstant-factor approximation on the setting when the user opinions are known. To find the set ofinfluential users, we provide a novel approximation algorithm for a variant of MaxCut in graphs withpositive and negative edge weights. We experimentally evaluate our methods, which have access only tothe network topology, and we find that they have similar performance as methods that have access to thenetwork topology and all user opinions. We further present an NP-hardness proof, which was left as anopen question by Chen and Racz [IEEE Transactions on Network Science and Engineering, 2021].",
  "Introduction": "Online social networks have become an integral part of modern societies and are used by billions of people ona daily basis. In addition to connecting people with their friends and family, online social networks facilitatesocietal deliberation and play an important role in forming the political will in modern democracies.However, during recent years we have had ample evidence of malicious actors performing attacks on socialnetworks so as to destabilize communities, sow disagreement, and increase polarization. For instance, a reportissued by the United States Senate finds that Russian trolls monitored societal divisions and were poised topounce when new events provoked societal discord and that this campaign [was] designed to sow discord inAmerican politics and society . Another report found that both left- and right-leaning audiences weretargeted by these trolls . Similarly, a recent analysis regarding the Iranian disinformation claimed thatthe main goal is to control public opinionpitting groups against each other and tarnishing the reputationsof activists and protesters .The study of how such attacks influence societies can be facilitated by models of opinion dynamics, whichstudy the mechanisms for individuals to form their opinions in social networks. Relevant research questions",
  "arXiv:2306.10313v2 [cs.SI] 12 Sep 2023": "have been investigated in different disciplines, e.g., psychology, social sciences, and economics .A popular model for studying such questions in computer science is the FriedkinJohnsen model (FJ) , which is a generalization of the DeGroot model .To understand the power of an adversarial actor over the opinion-formation process in a social network,there are two popular measures of discord: disagreement and polarization; for the rest of the paper, we usethe word discord to refer to either disagreement or polarization; see for the formal definitions.Previous works studied the increase of discord that can be inflicted by a malicious attacker who canchange the opinions of a small number of users. As an example, Chen and Racz showed that even simpleheuristics, such as changing the opinions of centrists, can lead to a significant increase of the disagreement inthe network. They also presented theoretical bounds, which were later extended by Gaitonde, Kleinberg andTardos .Crucially, the previous methods assume that the attacker has access to the network topology as well asthe opinions of all users. However, the latter assumption is rather impractical: user opinions are either notavailable or difficult to estimate accurately. On the other hand, obtaining the network topology is morefeasible, as networks often provide access to the follower and interaction graphs.As knowledge of all user opinions appears unrealistic, we raise the following question: Can attackers sowa significant amount of discord in a social network, even when only the network topology is known? In otherwords, we consider a setting with limited information in which the adversary has to pick a small set of users,without knowing the user opinions in the network. Our Contributions. Our main contributions are as follows. First, we provide a formal connection betweenthe settings of full (all user opinions are known) and limited information (the user opinions are unknown).Informally, we show that if the variance of user opinions in the network is not very high (and some othermild technical assumptions), then an adversary who radicalizes the users who are highly influential for thenetwork obtains a O(1)-approximation for the setting when all user opinions are known. Thus, we answer theabove question affirmatively from a theoretical point of view.Second, we implement our algorithms and evaluate them on real-world datasets. Our experiments showthat for maximizing disagreement, our algorithms, which use only topology information, outperform simplebaselines and have similar performance as existing algorithms that have full information. Therefore, we alsoanswer the above question affirmatively in practice.Third, we provide constant-factor approximation algorithms for identifying (n) users who are highlyinfluential for the discord in the network, where n is the number of users in the network. We derive analyticallythe concept of highly-influential users for network discord and we formalize an associated computational task(.1). Our formulation allows us to obtain insights into which users drive the disagreement and thepolarization in social networks. We also show that this problem is NP-hard, which solves an open problemby Chen and Racz .Fourth, we show that to find the users who are influential on the discord, we have to solve a version ofcardinality constrained MaxCut in graphs with both positive and negative edge weights. For this problem,we present the first constant-factor approximation algorithm when the number of users to radicalize is(n). Here the main technical challenge arises from the presence of negative edges, which imply that theproblem is non-submodular and which rule out using averaging arguments that are often used to analyzesuch algorithms [5, A.3.2]. Hence, existing algorithms do not extend to our more general case and we proveanalogous results for graphs with positive and negative edge weights. In addition, our NP-hardness proofprovides a further connection between maximizing the disagreement and MaxCut.We discuss some of the ethical aspects of our findings regarding the power of a malicious adversary whohas access to the topology of a social network in the conclusion (). Related work. A recently emerging and popular topic in the area of graph mining is to study optimizationproblems based on FJ opinion dynamics. Papers considered minimizing disagreement and polarizationindices , maximizing opinions , changes of the network topology or changes of the susceptibilityto persuasion . Xu et al. show how to efficiently estimate quantities such as the polarization anddisagreement indices. Our paper is also conceptually related to the topic of maximizing influence in socialnetworks, pioneered by Kempe, Kleinberg and Tardos ; the influence-maximization model has recently been combined with opinion-formation processes . Furthermore, many extensions of the classic FJ modelhave been proposed .Most related to our work are the papers by Chen and Racz and by Gaitonde, Kleinberg and Tardos ,who consider adversaries who plan network attacks. They provide upper bounds when an adversary can takeover k nodes in the network, and they present heuristics for maximizing disagreement in the setting withfull information. A practical consideration of this model has motivated us to study settings with limitedinformation. While their adversary can change the opinions of k nodes to either 0 or 1, in this paper we aremainly concerned with adversaries which can change the opinions of k nodes to 1; we consider the adversarysactions as radicalizing k nodes. Our setting is applicable in scenarios when opinions near opinion value 0(1) correspond to non-radicalized (radicalized) views.Our algorithm for MaxCut in graphs with positive and negative edge weights is based on the SDP-rounding techniques by Goemans and Williamson for MaxCut, and by Frieze and Jerrum forMaxBisection. While their results assume that the matrix A in Problem (3.2) is the Laplacian of a graphwith positive edge weights, our result in Theorem 3.3 applies to more general matrices, albeit with worseapproximation ratios. Currently, the best approximation algorithm for MaxBisection is by Austrin etal. . Ageev and Sviridenko gives LP-based algorithms for versions of MaxCut with given sizes of parts,Feige and Langberg extended this work to an SDP-based algorithm; but their techniques appear to beinherently limited to positive edge-weight graphs and cannot be extended to our more general setting ofProblem (3.2).",
  "Preliminaries": "Let G = (V, E, w) be an undirected weighted graph representing a social network. The edge-weight functionw: E R>0 models the strengths of user interactions. We write |V | = n for the number of nodes, anduse N(u) to denote the set of neighbors of node u V , i.e., N(u) = {v : (u, v) E}. We let D bethe n n diagonal matrix with Dv,v = uN(v) w(u, v) and define the weighted adjacency matrix W byWu,v = w(u, v). The Laplacian of the graph G is given by L = D W.In the FriedkinJohnsen opinion-dynamics model (FJ) , each node u V corresponds to a person whohas an innate opinion and an expressed opinion. For each node u, the innate opinion su is fixed overtime and kept private; the expressed opinion z(t)u is publicly known and it changes over time t Ndue to peer pressure. Initially, z(0)u= su for all users u V . At each time t > 0, all users u V update theirexpressed opinion z(t)uas the weighted average of their innate opinion and the expressed opinions of theirneighbors, as follows:",
  "+ vN(u) wuv.(2.1)": "We write z(t) = (z(t)1 , . . . , z(t)n ) to denote the vector of expressed opinions at time t. Similarly, we sets = (s1, . . . , sn) for the innate opinions. In the limit t , the expressed opinions reach the equilibriumz = limt z(t) = (I + L)1s.We study the behavior of the following two discord measures in the FJ opinion-dynamics model:",
  "n )(I + L)1": "Note that the disagreement index measures the discord along the edges of the network, i.e., it measures howmuch interacting nodes disagree. The polarization index measures the overall discord in the network byconsidering the variance of the opinions. We note that the matrices D(L) and P(L) may have positive and negative off-diagonal entries and it isnot clear whether they are diagonally dominant; this is in contrast to graph Laplacians that have exclusivelynon-positive off-diagonal entries and are diagonally dominant. Having positive and negative entries will beone of the challenges we need to overcome later. The following lemma presents some additional properties.",
  "Lemma 2.1. Let A {D(L) , P(L) }. Then A is positive semidefinite and satisfies A1 = 0, where 1 is theall-ones vector and 0 is the all-zeros vector": "While we consider opinions in the interval , for the NP-hardness results presented later, for technicalreasons, it will be useful to consider opinions in the interval . In Appendix B.1, we show that thesolutions of optimization problems are maintained under scaling, which implies that our NP-hardness resultsand our O(1)-approximation algorithm also apply for opinions in the interval.We present all omitted proofs in Appendix B.",
  "Problem definition and algorithms": "We start by defining the problem of maximizing the discord when k user opinions can be radicalized, i.e., whenfor k users the innate opinions can be changed from their current value s0(u) to the extreme value 1. Thisproblem is of practical relevance when opinions close to 0 correspond to non-radicalized opinions (covid-19vaccines are generally safe) and opinions close to 1 correspond to radicalized opinions (covid-19 vaccinesare harmful). Then an adversary can radicalize k people by setting their opinion to 1, for instance, bysupplying them with fake news or by hacking their social network accounts. Formally, our problem is statedas follows. Problem 3.1. Let A {D(L) , P(L) }. Consider an undirected weighted graph G = (V, E, w), and innateopinions s0 n. We want to maximize the discord where we can radicalize the innate opinions of k users.In matrix notation, the problem is as follows:",
  "(3.1)": "Note that if we set A = D(L) the problem is to maximize the disagreement in the network. If we setA = P(L) we seek to maximize the polarization.Further observe that for Problem (3.1), the algorithm obtains as input the graph G and the vector ofinnate opinions s0. Therefore, we view this formulation as the setting with full information.Central to our paper is the idea that the algorithm has access to the topology of the graph G, but itdoes not have access to the initial innate opinions s0. As discussed in the introduction, we believe that thisscenario is of higher practical relevance, as it seems infeasible for an attacker to gather the opinions of millionsof users in online social networks. On the other hand, assuming access to the network topology, i.e., thegraph G, appears more feasible because networks, such as Twitter, make this information publicly available.Our approach for maximizing the discord, even when we have limited information, i.e., we only haveaccess to the graph topology, has two steps:1. Detect a small set S of k users who are highly influential for the discord in the network.2. Change the innate opinions for the users in the set S to 1 and leave all other opinions unchanged.In the rest of this section, we will describe our overall approach for finding a set of k influential userson the discord (.1) and then we will discuss approximation algorithms (.2) and heuristics(.3) for this task. Then, we prove computational hardness (.4).",
  "Next, we describe the implementation of Step (1) discussed above. In other words, we wish to find a set S ofk users who are highly influential for the discord in the network": "To form an intuition about highly-influential users for the network discord in the absence of informationabout user innate opinions, we consider scenarios of non-controversial topics. Since the topics are non-controversial, we expect most users to have opinions near a consensus opinion c. In such scenarios, anadversary who aims to radicalize k users so as to maximize the network discord, will seek to find a set S ofk users and set s0(u) = 1, for u S, so as to maximize the discord sAs, where A {D(L) , P(L) }.Since we assume most opinions to be near consensus c, it seems natural that the concrete value of c has no big effect on the choice of the users picked by the adversary (see also Theorem 3.2 which formalizesthat this intuition is correct). Hence, we consider c = 0 and study the idealized version of the problem,where s0(u) = 0 for all users u in the network. In this case, the adversary will need to solve the followingoptimization problem:",
  "(3.2)": "The result of the above optimization problem is a vector s that has k non-zero entries, all of which are equalto 1. Thus, we can view the set S = {u | s0(u) = 1} as a set of users who are highly influential for the discordin the network.We provide a constant-factor approximation algorithm for this problem in Theorem 3.3. We also showthat the problem is NP-hard in Theorem 3.9 when A = D(L) , which answers an open question by Chen andRacz .Relationship between the limited and full information settings. At first glance, it may not beobvious why a solution for Problem (3.2) with limited information implies a good solution for Problem (3.1)with full information. However, we will show that this is indeed the case when there is little initial discord inthe network; we believe this is the most interesting setting for attackers who wish to increase the discord.Slightly more formally (see Theorem 3.2 for details), we show the following. If initially all innate opinionsare close to the average opinion c and some mild assumptions hold, then an O(1)-approximate solution forProblem 3.2 (when only the network topology is known) implies an O(1)-approximate solution for Problem 3.1(when full information including user opinions are known).Before stating the theorem, we define some additional notation. For a set of users X V , we write sX todenote the vector of innate opinions when we radicalize the users in X, i.e., sX n satisfies sX(u) = 1if u X and sX(u) = s0(u) if u X. Furthermore, given X and a vector v, we write v|X to denote therestriction of v to the entries in X, i.e., v|X(u) = v(u) if u X and v|X(u) = 0 if u X. We discuss ourtechnical assumptions after the theorem. Theorem 3.2. Let A {D(L) , P(L) }. Let c [0, 1) and r [c, 1 c]n be such that s0 = c1 + r. Let1, 2, 3 (0, 1) be parameters. Furthermore, assume that for all sets X V with |X| = k it holds that:1. (sX s0)As0 1s0As0,",
  "+2(1c)3+2 },even if we only have access to the graph topology (but not the user opinions)": "One may think of c as the average innate opinion and r as the vector that indicates how much each innateopinion deviates from c. Indeed, for topics that initially have little discord, one may assume that most entriesin r are small.The intuitive interpretation of the technical conditions from the theorem is as follows. Condition (1)corresponds to the assumption that no matter which k users the adversary radicalizes, the discord will notdrop by more than a 1-fraction. This rules out some unrealistic scenarios in which, for example, all butk users have initial innate opinion 1 and one could subsequently remove the entire discord by radicalizing the",
  "(1 )2": ":The approximation ratio from Theorem 3.3 as function of . We present numerical approximationratio results compared with a piece-wise quadratic function defined by the formulas: 2.0592 for 0 < < 0.448,1.36(1 )2 for 0.448 < 0.5, 1.362 for 0.5 < 0.552, and 2.059(1 )2 for 0.552 < 1. remaining k users. Conditions (2) and (3) are of similar nature and essentially state that if only k users havethe opinions given by r and all other users have opinion 0, then the discord in the network is significantlysmaller than the initial discord when all n users have the opinions in s0.Note that when k n, it is reasonable to assume that 1, 2, 3 are upper-bounded by a small constant,say 1 5. In this case the theorem states that if we have a -approximation algorithm for the setting withlimited information then we obtain an O()-approximation algorithm for the setting with full information,even though we only use the network topology but not the innate opinions.",
  "-Balanced MaxCut": "In this section, we study the -Balanced-MaxCut problem for which we present a constant-factorapproximation algorithm. This algorithm allows us to solve Problem (3.2) (maximizing discord with limitedinformation) approximately. Combined with Theorem 3.2 above, this implies that (under some assumptions)adversaries with limited information only perform a constant factor worse than those with full information(see Corollary 3.5 below).In the -Balanced-MaxCut problem, the goal is to partition a set of nodes into two sides such thatone side contains an -fraction of the nodes and the cut is maximized. Formally, we are given a positivesemidefinite matrix A Rnn and a parameter . The goal is to solve the following problem:",
  "(3.3)": "Note that the optimal solution vector x takes values in {1, 1} (since the objective function is convex, as Ais positive semidefinite) and thus it partitions the set V into two sets S = {u: xu = 1} and S = {u: xu = 1}.The first constraint ensures |S| = n and S = (1 )n, i.e., one side contains an -fraction of the nodesand the other side contains a (1 )-fraction. If A is the Laplacian of a graph and = 1 2, this is the classicMaxBisection problem . Hence, we will sometimes refer to x and the corresponding partition (S, S) asa cut and to xAx as the cut value.Our main result for Problem (3.3) is as follows. Theorem 3.3. Suppose is a constant and A is a symmetric, positive semidefinite matrix with1A = 0. Then for any 0 < < 1, there exists a randomized polynomial time algorithm that with probabilityat least 1 , outputs a solution for the -Balanced-MaxCut (Problem (3.3)) with approximation ratiopresented in . The algorithm runs in time O(1/ log(1/)poly(n)). In we visualize the approximation ratios for different values of . In particular, observe that forany constant (0, 1], our approximation ratio is (1) and that for most values of it performs within at a least a factor of 10 of the optimal solution. Furthermore, for close to 0.5, our approximation is better than13.Before we discuss Theorem 3.3 in more detail, we first present two corollaries. First, we observe that thetheorem implies that we obtain a constant-factor approximation algorithm for maximizing the discord withlimited information (Problem (3.2)).",
  "Proof. Observe that a solution for Problem (3.3) implies a solution for Problem (3.2) as follows: Suppose inProblem (3.3) we set A = 4D(L) or A = 4P(L) and = k": "n to obtain a solution x. Now we define a solutions for Problem (3.3) by setting s(u) = 1 if x(u) = 1 and s(u) = 0 if x(u) = 1. Observe that s0 = k asdesired. Since the last step can be viewed as rescaling opinions from to , the objective functionvalues of xAx and sAs only differ by a factor of 4 (see Appendix B.1). Second, observe that by combining Theorems 3.2 and Corollary 3.4, we immediately obtain the followingresult for solving the setting with full information, even when we only have access to the network topology.",
  ".Then there exists a polynomial time algorithm for Problem (3.1) with full information that has approximationratio O(1) and only uses the graph topology (but not the user opinions)": "Next, let us discuss Theorem 3.3 in more detail.The theorem generalizes previous results and its approximation ratios are only a small constant factorworse than classic results . In particular, the previous results assumed that A is the Laplacian ofa graph with positive edge weights, and thus A has the structure that all off-diagonal entries are nonpositive.In contrast, in our result we do require the latter assumption and allow for positive off-diagonal entries, whichappear, for instance, in graphs with negative edge weights. Indeed, this is the case for the matrices D(L)and P(L) from , which may have positive off-diagonal entries. Therefore, our generalized theorem isnecessary to maximize the discord in Problem (3.2).Furthermore, we note that to apply Theorem 3.3 on graphs with both positive and negative edge weights,we have to assume that their Laplacian is positive semidefinite. This assumption cannot be dropped, aspointed out by Williamson and Shmoys [41, .3]. This is crucial since, while for graphs with positiveedge weights the Laplacian is always positive semidefinite, this is not generally true for graphs with negativeedge weights.1 However, this assumption holds in our use cases due to Lemma 2.1.In the theorem we require to be a constant and thus k = (n). While this is somewhatundesirable, there are underlying technical reasons for it: the SDP-based approach by Frieze and Jerrum also has this requirement; LP-based algorithms which work for k = o(n) (as shown, for instance, by Ageevand Sviridenko ) do not generalize to the setting in which the matrices are not graph Laplacians; the sameis the case for the SDP-based approach by Feige and Langberg .Algorithm. Our algorithm is based on solving the SDP relaxation of Problem (3.3) and applying randomhyperplane rounding , followed by a greedy step in which we adjust the sizes of the sets S and S. Later,we will see that our main technical challenge will be to prove that the greedy adjustment step still works inour more general setting.To obtain our SDP relaxation of Problem (3.3), we observe that by the convexity of the objective functionwe can assume that s {1, 1}n (see Appendix B.4) and thus, we can rewrite the constraint x + 10 = nas 2 ni<j xixj = n2(1 2)2 n. 1We note that this property of graphs with positive and negative edges also rules out simple algorithms of the type: Randomlycolor the graph, pick the color for which the induced subgraph has the highest edge weights and then solve unconstrainedMaxCut in this subgraph. The issue here is that the Laplacian of such a randomly picked subgraph is not necessarily positivesemidefinite (even if the Laplacian of the original graph is positive semidefinite). Thus such simple tricks cannot be applied hereand we need other solutions.",
  "OPT and E[|S| S] 0.878 (1 )n2,where OPT is the optimal solution for -Balanced-MaxCut": "The second part of the analysis is novel and considers the greedy procedure that ensures that S contains kelements. When A is the Laplacian of a graph with nonnegative edge weights, an averaging argument (see,e.g., [5, A.3.2]) implies that there exists u S such that we can move u from S to S and the cut value dropsby a factor of at most 1/ |S|. However, for more general matrices A this may not hold, e.g., when A is theLaplacian of a signed graph with negative edge weights or when A is the matrix that corresponds to thedisagreement index, as in Problem (3.2). We also illustrate this in Appendix B.5. However, we show that inour setting there always exists a node in S such that if we move u from S to S then the cut value drops by afactor of at most 2/ |S|.",
  "M": "|S| = 0, i.e., we would not be able to obtain our desiredapproximation result. However, this analysis is too pessimistic because it assumes that after each applicationof the lemma, the cut decreases by a2|S|-fraction with respect to the initial cut. Therefore, the followinglemma presents a more refined analysis, which takes into account that during each application of Lemma 3.7,the cut only decreases by a2|S|-fraction with respect to the previous cut. A similar idea was used by Srivastavand Wolf [38, Lemma 1] to solve the densest k-subgraph problem.Intuitively, in the lemma (S, S) corresponds to the cut we obtain from the hyperplane rounding and (T, T)corresponds to the -balanced solution that we wish to return.",
  "Greedy heuristics": "Next, we discuss two greedy heuristics, which can be applied in two different ways. First they can be used tosolve Problem (3.1) in the model with full information, i.e., when the graph topology and the innate opinionsof all users are available.Second, by setting s0 = 0, these greedy heuristics can be used to solve Problem (3.2), and thus, be used assubroutines for the first step of our approach in the model with limited information. In other words, they canbe used to substitute the SDP-based algorithm that we presented in the previous section. This is particularlyuseful, since solving an SDP is not scalable for large graphs, while the greedy methods are significantly moreefficient.Adaptive greedy () initializes s = s0 and performs k iterations. In each iteration, for all indices u itcomputes how the objective function changes when setting su = 1. Then it picks the index u that increasesthe objective function the most.Non-adaptive greedy works similarly. In a first step, it initializes s = s0 and computes for all indices uthe score that indicates how the objective function changes when setting su = 1. Then it orders the indicesu1, . . . , un such that the score is non-increasing. Now it iterates over i = 1, . . . , n and for each i, it sets sui = 1if this increases the objective function; otherwise it proceeds with i + 1. The non-adaptive greedy algorithmstops after it has changed k entries.",
  "Computational hardness": "Chen and Racz left it as an open problem to prove that maximizing the disagreement of the expressedopinions is NP-hard; they studied a version of Problem 3.1 in which they had an inequality constraints s0 k rather than the equality constraint we study and in which the adversary could pick a solutionvector s n. We show that this problem, as well as Problems (3.1) and (3.2) are NP-hard. In addition,in Corollary 3.10, we show that these two problems are NP-hard even when k = (n), which implies thatProblem (3.3) is also NP-hard when is constant.",
  "suffix -F to indicate that they use full information. For AG-F we adapt the implementation of Chen andRacz .3": "Second, we use the suffix -L to refer to our methods with limited information, which only know thenetwork structure (see ). For picking the seed nodes, we consider the following algorithms: AG is theadaptive greedy algorithm with s0 = 0, NAG is the non-adaptive greedy algorithm with s0 = 0, and SDP isthe SDP-based algorithm from Theorem 3.3. IM finds the seed nodes by solving the influence-maximizationproblem and our implementation is based on the Martingale approach, i.e., IMM, proposed by Tang etal. ; we set the graph edge weights as in the weighted cascade model . Rnd randomly picks k nodes,and Deg picks the k nodes of the highest degree.Datasets. We present statistics for our smaller datasets in and for our larger datasets in .For each of the datasets, we provide the number of vertices and edges. We also report the normalizeddisagreement index DG,s = DG,s105",
  "different datasets and we multiply with 105 because DG,s": "|E| is typically very small. We also report averageinnate opinions s0 and the standard deviation of the innate opinions (s0).We note that the datasets karate, books, blogs, SBM and Gplus:L2 do not contain ground-truth opinions.However, the these datasets contain ground-truth communities; thus, we set the nodes innate opinions bysampling from Gaussian distributions with different parameters, based on the community membership. Moredetails for all datasets are presented in Appendix A.1. Evaluation. To evaluate our methods, we compare the initial disagreement with the disagreement after thealgorithms changed the innate opinions. More concretely, let s0 denote the initial innate opinions and let sdenote the output of an algorithm. We report the score sAss0 As0 s0 As0, where A is one of the matrices D(L)or P(L) from . For example, if A = D(L) then we measure the relative increase in disagreementcompared to the initial setting.Maximizing disagreement on small datasets. We start by studying the performance of our methodsfor maximizing disagreement. We present the results on small datasets in , where k = 10% n. Weconsider these small datasets as they allow us to evaluate our SDP-based algorithm, which does not scale tolarger graphs.Our results in show that for all datasets, our limited-information algorithms, i.e., SDP-L, NAG-L,and AG-L, perform surprisingly well. Indeed, on all datasets these algorithms have performance similar tothe algorithms using full information. Surprisingly, on karate, books, and Twitter, SDP-L outperforms the bestalgorithms with full information, even though only by very small margins. Since SDP-L is the best methodonly on the three smallest datasets, we believe that this exceptionally good performance is an artifact of thedatasets being small.Among the three algorithms with limited information, SDP-L performs best on all datasets, but the gapto the two greedy algorithms is relatively small. This answers RQ1.",
  "|V ||E|DG,s0s0(s0)NAG-FAG-FNAG-LAG-LDeg-LIM-LRnd-L": "Tweet:S21 99940 49829.0240.2160.2580.2430.2430.2150.2190.0120.0110.075Tweet:S43 999222 26810.7650.5680.3020.0740.0740.0530.0500.0090.0060.001Tweet:M54 999245 0851.2560.0750.0773.3403.3403.1483.0410.0270.0240.524Tweet:L221 999860 8845.8900.1060.1360.8560.8560.8440.8080.0240.0130.222Gplus:L222 9995 474 1330.0590.3000.1017.1067.1337.0987.1200.0150.0160.502 We also observe that the SDP and greedy algorithms with limited information achieve better results thanthe baselines.Next, we note that for the Reddit dataset, the disagreement increases by a factor of more than 48. A closelook at the ground-truth opinions on Reddit reveals that the standard deviation of the innate opinions isjust 0.042, and the normalized initial disagreement is also among the second smallest. These two factorsmake the dataset susceptible to increasing the disagreement by a large amount.Maximizing disagreement on larger datasets. Next, we consider the larger datasets in withk = 1% n. Here, we drop SDP-L due to scalability issues.First, we observe that for the larger datasets, the dataset properties, such as, the normalized initialdisagreement, the mean of the innate opinions, and the standard deviations of the innate opinions are similarto those of the smaller datasets. Due to these similarities, we expect a similar gap between the full-informationalgorithms and the limited-information algorithms as in the smaller datasets.Second, we observe that the methods with full information indeed are just slightly better than NAG-L andAG-L over all the datasets. The biggest gap in performance is on Tweet:S4 where the full-information methodsare about 40% better. Note that both s0 = 0.568 and (s0) = 0.302 are large for Tweet:S4; this is somewhatuncharacteristic for our other datasets, which have either smaller s0 or smaller (s0). We also observe thatthe there is no clear winner between NAG and AG in the limited information setting, which have very similarperformance. In addition, the greedy algorithms clearly outperform the baseline algorithms. We present therunning time analysis in Appendix A.5.Summarizing our results, we can answer RQ2: we find that the setting with limited information is atmost a factor of 1.4 worse than the setting with full information.Relationship of dataset parameters and the gap between full and limited information. Tounderstand how the dataset parameters influence the performance of our algorithms with limited information,we perform a regression analysis and report the results in . On the y-axis, we consider the ratiobetween the best of NAG-L and AG-L, which only use limited information, and the best method with fullinformation. Observe that this ratio can be viewed as the gap between having full and having limitedinformation. On the x-axis, we plot the dataset parameters DG,s, s0 and (s0).First, we find that there is a low correlation between the ratio of limited/full-information algorithms andthe average innate opinions s0 (R2 = 0.17) and the initial disagreement DG,s (R2 = 0.08) in the datasets.Second, we find that the correlation between the standard deviation of the innate opinions (s0) is moderatelyhigh (R2 = 0.62).These finding align well with the intuition that if (s0) is high, an adversary that only knows the graphlacks more information than when (s0) is small; additionally, note that if (s0) is small, then the vector rfrom Theorem 3.2 will have small norm and the second and the third condition of the theorem should besatisfied on our datasets. Similarly, it is intuitive that s0 should not have a large impact on the adversarysdecisions if it is not too high (here we consider datasets with s0 0.61). However, in preliminary experiments(not reported here) we also observed that if s0 is very large (s0 0.8) then the performance of the algorithmsbecomes much worse. Furthermore, it might be considered somewhat surprising that the correlation with DG,s",
  ": Results for the relative increase of the disagreement on Tweet:L2 and Gplus:L2. Here, we varyk = 0.5% n, 1% n, . . . , 2.5% n": "is low, since one might intuitively expect that DG,s and (s0) should be closely related. For this discrepancy,we note that DG,s also involves the network structure.Hence, we can answer RQ3: we find that the standard deviation of the initial opinions is the mostimportant for determining the gap between full and limited information, while the average innate opinionsand initial disagreement play no major role.Dependency on k. For k = 0.5% n, 1% n, . . . , 2.5% n, we present our results on Tweet:L2 and Gplus:L2 in. The figure indicates that the disagreement grows linearly in k; this behavior was also suggested bythe upper bounds of Chen and Racz and Gaitonde et al. who considered a slightly stronger adversary.Similar to the results in , AG-F is the best method, followed by NAG-L and AG-L. The ranking of thealgorithms is consistent across the different values of k. This answers RQ4. Additional experiments. In the appendix we present additional experiments. First, in Appendix A.3 weevaluate the algorithms for solving Problem (3.2). Second, in Appendix A.2 we also use our algorithms tomaximize the polarization in the network; we remark that all of our results extend to this setting, includingthe guarantees from Theorem 3.3.",
  "Conclusion": "We have studied how adversaries can sow discord in social networks, even when they only have access to thenetwork topology and cannot assess the opinions of the users. We proposed a framework in which we firstdetect a small set of users who are highly influential on the discord and then we change the opinions of theseusers. We showed experimentally that our approach can increase the discord significantly in practice and that it performs within a constant factor to the greedy algorithms that have access to the full informationabout the user opinions.Our practical results demonstrate that attackers of social networks are quite powerful, even when theycan only access the network topology. From an ethical point of view, these findings showcase the power ofmalicious attackers to sow discord and increase polarization in social networks. However, to draw a finalconclusion further study is needed, for example because the assumption that the adversary can radicalizek opinions arbitrarily much may be too strong. Nonetheless, the upshot is that by understanding attackerswith limited information, one may be able to make recommendations to policy makers regarding the datathat social-network providers can share with the public.Furthermore, in this paper we only studied one possible definition for disagreement that is common in thecomputer science literature . Klofstad et al. point out that in the political science literature thereare different viewpoints on how disagreement should be defined, and that these different definitions will leadto different conclusions, with different empirical and democratic consequences. Understanding the connectionof our definition and the ones in political science is an interesting question. Also, Edenberg argues thatto solve current societal problems like polarization, purely technical solutions, such as social media literacycampaigns and fact checking, are not enough; instead we must find ways to cultivate mutual respect for ourfellow citizens in order to reestablish common moral ground for political debate. While certainly true, suchconsiderations and course of actions are out of the scope of our paper.As we already mentioned above, in future work it will be interesting to validate which adversary models arerealistic in practice. Theoretically, it is interesting to obtain approximation algorithms for Problem (3.1) andthe problem by Chen and Racz ; note that such algorithms must generalize our result from Theorem 3.3,as Problem (3.2) is a special case of Problem (3.1).",
  "Acknowledgements": "We are grateful to Tianyi Zhou for providing the Twitter datasets with innate opinions. We thank SebastianLuderssen for pointing out a mistake in an earlier version of this paper. This research is supported by theAcademy of Finland project MLDB (325117), the ERC Advanced Grant REBOUND (834862), the EC H2020RIA project SoBigData++ (871042), and the Wallenberg AI, Autonomous Systems and Software Program(WASP) funded by the Knut and Alice Wallenberg Foundation. The computations were enabled by resourcesin project SNIC 2022/22-631 provided by Uppsala University at UPPMAX. Rediet Abebe, T-H Hubert Chan, Jon Kleinberg, Zhibin Liang, David Parkes, Mauro Sozio, andCharalampos E Tsourakakis. 2021.Opinion Dynamics Optimization by Varying Susceptibility toPersuasion via Non-Convex Local Search. TKDD 16, 2 (2021), 134.",
  "Claudio Castellano, Santo Fortunato, and Vittorio Loreto. 2009. Statistical physics of social dynamics.Reviews of modern physics 81, 2 (2009), 591": "Mayee F. Chen and Miklos Z Racz. 2021. An Adversarial Model of Network Disruption: Maximizing Dis-agreement and Polarization in Social Networks. IEEE Transactions on Network Science and Engineering(2021), 11. Abir De, Sourangshu Bhattacharya, Parantapa Bhattacharya, Niloy Ganguly, and Soumen Chakrabarti.2019. Learning Linear Influence Models in Social Networks from Transient Opinion Dynamics. ACMTrans. Web 13, 3 (2019), 16:116:33.",
  "David Kempe, Jon Kleinberg, and Eva Tardos. 2015. Maximizing the Spread of Influence through aSocial Network. Theory Of Computing 11, 4 (2015), 105147": "Casey A Klofstad, Anand Edward Sokhey, and Scott D McClurg. 2013. Disagreeing about disagreement:How conflict in social networks affects political behavior. American Journal of Political Science 57, 1(2013), 120134. Jerome Kunegis. 2013. KONECT: The Koblenz Network Collection. In Proceedings of the 22nd Interna-tional Conference on World Wide Web (WWW 13 Companion). Association for Computing Machinery,New York, NY, USA, 13431350.",
  "United States Senate Select Committee on Intelligence. 2019. Russian Active Measures Campaigns andInterference in the 2016 U.S. Election, Volume 2: Russias Use of Social Media with Additional Views": "Anand Srivastav and Katja Wolf. 1998. Finding dense subgraphs with semidefinite programming.In Approximation Algorithms for Combinatiorial Optimization: International Workshop APPROX98Aalborg, Denmark, July 1819, 1998 Proceedings 1. Springer, 181191. Youze Tang, Yanchen Shi, and Xiaokui Xiao. 2015. Influence maximization in near-linear time: Amartingale approach. In Proceedings of the 2015 ACM SIGMOD international conference on managementof data. 15391554.",
  "AOmitted Experiments": "We present further details of our experiments. In Section A.1, we present details about our datasets. InSection A.2, we present how our algorithms perform when the goal is to maximize the polarization. InSection A.3 we compare different algorithms for finding users that are influential on the disagreement in thenetwork (Problem (3.2)). In Section A.4 we discuss the stability of SDP-L and Rnd-L, which use randomization.In Section A.5 we present the running time of our algorithms.Our algorithms are implemented in Python, except IMM (related to our IM-L algorithm) which isimplemented in Julia. We use Mosek to solve semidefinite programs.",
  "A.1Datasets": "The datasets Tweet:S2, Tweet:S4, Tweet:M5, Tweet:L2 are sampled from a Twitter dataset with innate opinions,which we obtained from Tianyi Zhou. The original Twitter dataset is collected in the following way. We startfrom a list of Twitter accounts who actively engage in political discussions in the US, which was compiledby Garimella and Weber . Then we randomly sample a smaller subset of 50 000 accounts. For theseactive accounts, we obtained the entire list of followers, except for users with more than 100 000 followersfor whom we got only the 100 000 most recent followers (users with more than 100 000 followers account forless than 2% of our dataset). Based on this obtained information, we construct a graph in which the nodescorrespond to Twitter accounts and the edges correspond to the accounts following relationships. Then weconsider only the largest connected component in the network. To obtain the innate opinions of the nodes inthe graphs, we proceed as follows. First, we compute the political polarity score for each account using themethod proposed by Barbera , which has been used widely in the literature . The polarity scoresrange from -2 to 2 and are computed based on following known political accounts. Then we re-scale theminto the interval . To create our smaller datasets, we select a seed node uniformly at random, and runbreadth-first search (BFS) from this seed node, until a given number of nodes have been explored.We note that for Tweet:M5 and Tweet:L2, the innate opinions were very large (s0 0.85) and thus forthese datasets we flipped the innate opinions around 0.5 (i.e., we set s0 = 1 s0). In other words, weassume that initially most people are not on the extreme side of the opinion spectrum. By flipping theinnate opinions, we guarantee that the attacker can still radicalize the opinions. We note that this has noinfluence on the the initial indices for polarization and disagreement (since for A {D(L) , P(L) } it holdsthat s0As0 = (1 s0)A(1 s0) which is implied by Lemma 2.1).The dataset Gplus:L2 is sampled from the ego-Gplus dataset obtained from SNAP using the sameBFS-approach as above. The innate opinions for Gplus:L2 are drawn independently from N(0.3, 0.1). Here,N(, ) denotes the Gaussian distribution with mean and standard deviation .We also use the public3 datasets Twitter and Reddit from De et al. , which have previously been usedby Musco et al. and Chen and Racz . The Twitter dataset was obtained from tweets about the Delhilegislative assembly elections of 2013 and contains ground-truth opinions. The opinions for the Reddit datasetwere generated by Musco et al. using a power law distribution.Furthermore, we consider the datasets karate, books, blogs, which we obtained from KONECT andwhich do not contain ground-truth opinions. However, these datasets contain two ground-truth communities.For the first community, we sample the innate opinions of the users from the Gaussian distribution N(0.1, 0.1),and for the second community we use N(0.3, 0.1).Last, we consider graphs generated from the Stochastic Block Model. We generate a Stochastic BlockModel graph that consists of 1000 nodes divided equally into 4 communities. The intra-community edgeprobability is 0.4 and an the inter-community edge probability is 0.1. The innate opinions for each communityare drawn from N(0.2, 0.1), N(0.3, 0.1), N(0.4, 0.1) and N(0.5, 0.1), respectively.",
  "NAG-FAG-FNAG-LAG-LDeg-LIM-LRnd-L": "Tweet:S21 99940 498182.8790.2160.2580.7900.7920.6920.6920.0160.0140.053Tweet:S43 999222 268176.5250.5680.3020.2730.2730.1880.1860.0080.0060.003Tweet:M54 999245 08535.0050.0750.0775.8755.8765.2585.2580.0350.0350.160Tweet:L221 999860 884117.7900.1060.1361.8591.8651.5791.4810.0290.0220.140Gplus:L222 9995 474 1331.8030.3000.10130.35130.80430.33830.7860.0020.0010.441 : Results on the small datasets for the relative increase of the polarization, where we set k = 10% n.For each dataset, we have marked the highest value in bold and we have made the highest value for eachsetting italic.",
  "We report our results on larger datasets with k = 1%n in . For each of the datasets, we providethe number of vertices and edges. We also report the normalized polarization index PG,s = PG,s105": "|V |, wherewe normalize by the number of vertices for better comparison across different datasets. Further, we reportaverage innate opinions s0 and the standard deviation of the innate opinions (s0). Finally, as before, foreach algorithm we report the score sP(L) ss0 P(L) s0 s0 P(L) s0.We see that the results for polarization are somewhat similar to those for disagreement: algorithms withfull information are the best, but the best algorithm that only knows the topology still achieves similarperformance.Furthermore, the best algorithms with limited information, i.e., AG-L and NAG-L, consistently outperformthe baselines Deg-L, IM-L, and Rnd-L; this shows that our strategy leads to non-trivial results. Furthermore,we observe that across all settings, simply picking high-degree vertices, or picking nodes with large influencein the independent cascade model are poor strategies.In addition, we show results for the increase of polarization in the small datasets in . Again, themethods with full information perform best, and again our methods generally perform quite well and clearlyoutperform the baseline methods.",
  "A.3Finding influential users": "In this section, we evaluate different methods for finding the influential users which can maximize thedisagreement. More specifically, we evaluate different methods for solving Problem (3.2).We report our results in . Notice that when s = 1 and k = 0, the disagreement is 0. Thus, instead ofevaluating the relative gain of the Disagreement Index, we report absolute values of the Disagreement Index.We observe that the baselines which pick random seed nodes, high degree nodes, and nodes with highinfluence in the independent cascade model are clearly the worst methods. Among the other methods, theSDP-based methods are typically the best. We observe that when k is below 0.25n, the greedy methodsAG and NAG often perform as well as SDP; however, when k is larger than 0.3n, the SDP-based algorithmperforms better. These observations are in line with the analysis of Theorem 3.3 which achieves the bestapproximation ratios when k is close to 0.5n (see also ).",
  "A.4Stability of randomized algorithms": "In this section, we study how the randomization involved in some of the algorithms affects their results. Inparticular, Rnd-L and SDP-L randomly select nodes and we wish to study how this impacts their performance.We report the Disagreement Index and output the mean over 5 runs of the algorithms, together with errorbars that indicate standard deviations.In we present the Disagreement Index and the standard deviation with randomized algorithmson small datasets. We observe that as the number of nodes increases, the standard deviations of differentalgorithms becomes relatively small (note that the largest dataset below is blogs). Besides, we also observethat the outputs of SDP-L are stable, with standard deviations close to 0.In we present results on larger graphs, Tweet:L2 and Gplus:L2; here, we omit SDP-L due toscalability issues.",
  "A.5Running time of algorithms": "Next, we present the running time of the algorithms to maximize the disagreement on different datasets.Note that for full information algorithms we directly present the running time, while for limited informationalgorithms we report the running time for solving Problem (3.2). This is because the running time for settingthe innate opinions to 1 is negligible. In addition, since the running times of AG-F and AG-L are almost thesame, we only report the running time of AG-F. The same holds for NAG-F and NAG-L.In , we notice that AG-F and IM-L are the two most costly algorithms, but even for those algorithmthe running time increases moderately in terms of k. However, on the less dense graph Tweet:L2, IM-L runsfaster than on the denser graph Gplus:L2, even though they have almost the same number of vertices. This isconsistent with the time complexity of IMM . The graph density does not influence the running time ofthe adaptive greedy algorithm AG-F. Interestingly, we observe that that NAG-F is orders of magnitude fasterthan AG-F.In we report the absolute running times (in seconds) of our algorithms on the small datasets. We",
  "B.1Rescaling Opinions": "In , we mention that we consider the opinions in the interval . In this appendix we provethat scaling the opinions from an interval [a, b] to an interval [x, y] only influences the disagreement in the network by a fixed factor ofyxba2. In particular, we show that the optimizers of optimization problemsare maintained under scaling. This implies that all NP-hardness results we derive in this paper carry overto the setting with -opinions and our O(1)-approximation algorithms for -opinions also yieldO(1)-approximation algorithms for -opinions.Consider real numbers a < b and x < y. Suppose that we have innate opinions su [a, b] and we wish torescale them into the interval [x, y]. Then we set",
  "B.2Proof of Lemma 2.1": "We start by recalling two facts about positive semi-definite matrices. First, a matrix A is positive semi-definiteif A = BCB, where C is a positive semi-definite matrix. Second, A is positive semi-definite if we can writeit as A = BB.Let us consider the matrix P(L) = (I + L)1 I 11",
  "n(I + L)1 for polarization. Observe that I 11": "nis the Laplacian of the full graph with edge weights 1/n and, hence, this matrix positive semi-definite. Byour first property from above and the fact that (I + L)1 is symmetric, this implies that P(L) is positivesemidefinite. Proving that D(L) = (L + I)1L(L + I)1 is positive semi-definite works in the same way.Next, we observe that (I + L)1 satisfies (I + L)11 = 1 since (I + L)1 = 1 + L1 = 1 and by multiplyingwith (I + L)1 from both sides we obtain the claim.Now we apply the previous observation for our matrices from the table and obtain",
  "where in the first step we used the assumption s0 = c1 + r and the definitions of ALG and OPT. Inthe second step we used that A1 = 0 by Lemma 2.1 and that A is symmetric. In the fourth step we used": "Assumption (1) and the observations that sALG s0 = ALG and s0A = (c1+r)A = rA using Lemma 2.1.In the fifth step we used that 2rAOPT OPTAOPT + rAr. The last fact can be seen by lettingA = DD for a suitable matrix D (which exists since A is positive semi-definite by Lemma 2.1) and observingthat 0 ||D(OPT r)||22 = (OPT r)DD(OPT r) = OPTAOPT 2rAOPT + rAr; byrearranging terms we obtain the claimed inequality.Next, we let OPT V denote the set of nodes such that s0(u) = sOPT(u) and similarly we set ALG Vto the set of nodes with s0(u) = sALG(u). Observe that since sOPT = c1 + r + OPT and sOPT(u) = 1 forall u OPT, we have that OPT = (1 c)1|OPT r|OPT. Similarly, ALG = (1 c)1|ALG r|ALG.Then we get that",
  "Now we show prove a lemma about optimal solutions of Problem (B.1), where we write x(i) to denote theith entry of a vector x": "Lemma B.1. Suppose that A is a positive semi-definite matrix. Then there exists an optimal solution s forProblem B.1 such that s(i) {1, 1} for all entries i with s(i) = s0(i). In particular, if s0 {1, 1}n ork = n then there exists an optimal solution s {1, 1}n. Proof. First, note that since A is positive semi-definite, the quadratic form f(s) = sAs is convex.Second, consider an optimal solution s. If s satisfies the property from the lemma, we are done. Otherwise,there exists at least one entry i such that s(i) = s0(i) and s(i) (0, 1). Now let t1 denote the vector whichhas its ith entry set to 1 and in which all other entries are the same as in s, i.e., t1(j) = s(j) for all j = iand t1(i) = 1. Similarly, we set t1 to the vector with t1(j) = s(j) for all j = i and t1(i) = 1. Note thatt1 and t1 are feasible solutions to Problem (B.1).Third, observe that there exists an (0, 1) such that s = t1 + (1 )t1. Now by the convexity off(s) we get that",
  "max{f(t1), f(t1)}": "Thus, at least one of t1 and t1 achieves an objective function value that is at least as large as that of s.Hence, we can assume that the ith entry of s is from the set {1, 1}. Repeating the above procedure for allentries with s(i) = s0(i) and s(i) (0, 1) proves the first part of the lemma.The second part of the lemma (if s0 {1, 1}n or k = n) follows immediately from the first part.",
  "B.5An illustration of graphs with mixed weights": "shows how the cut of a graph can be influenced by positive and negative weights. We use thisexample to show that badly-behaved graphs with negative weights can make the cut value drop significantly,whereas in graphs with only positive edges this is not the case. The graphs we discuss in the paper are in theclass of well-behaved graphs.",
  "(a) Graph with(b) Well-behaved(c) Badly-behavedpositive weightsgraph withgraph withnegative weightsnegative weights": ": We visualize cuts in a graph that partition the vertices into sets S and S; edge weights are alsoillustrated. The cut shown here has value 2+. Figure (a): A graph with positive edge weights. An averagingargument reveals that there must exist a vertex in S that we can move to S such that the cut value is atleast 2+",
  "|S| 2": "3. Indeed, if we move u from S to S, the cut value drops only by . Figure (b): In graphs withboth positive and negative edge weights, the situation is less clear: if we move u from S to S, the cut valuebecomes 1. However, in this example we could move the top-left vertex from S to S. Then we would stillmaintain a positive cut value, but it would drop to 1 + . Note that this new cut value is strictly less thanwhat the averaging argument from above revealed. Figure (c): In the worst case, it can happen that thereexists no vertex in S, which we can move from S to S without obtaining a negative cut value. In our proofs,we have to show that this scenario cannot occur in our setting. We prove this in Lemma 3.7.",
  "B.6Proof of Theorem 3.3": "We start by defining notation. Let OPT denote the optimal solution for -Balanced-MaxCut, let M0 bethe objective function value obtained through randomized rounding after solving Problem (3.4), and let Mbe the cut value for (T, T) we obtain in the end. Let M be the optimal solution for Problem (3.4).We start with an overview of our analysis which is similar to the one by Frieze and Jerrum . Bysolving the SDP and applying the hyperplane rounding enough times, we show that Lemma 3.6 impliesthat M0 is close (1 ) 2 OPT and simultaneously |S0| S0 = |S0| (n |S0|) does not differ too much from(1 )n2. This then implies that that the loss from the greedy procedure for ensuring the -balancednessconstraint is not too large. To bound the loss from our greedy procedure for the size adjustments, we applyLemma 3.8 with (S0, S0) corresponding to the (unbalanced) solution (S, S) from the hyperplane roundingand (T, T) corresponding to the -balanced solution that we return.Next, we proceed with the concrete details of the proof. First, observe that since the objective functionof the optimization problem is convex (see Section B.4) there exists an optimal solution with s {1, 1}n.Hence, we can focus on solutions with s {1, 1}n.Consider the p-th iteration of Algorithm 1. Let Xp denote the cut value of (S, S), and let Yp = |S| S.Let Zp = Xp",
  "+ 0.878(1 ) ).Now consider the (non--balanced) solution (S, S) from the -th iteration with cut-value M0 := X. Weset s = |S|": "n and t = and apply Lemma 3.8 to obtain a solution that satisfies the -balancedness constraint.Suppose that in the -th run, X = M for suitable . Then it follows that Y ((1 )(0.878(1 ) +2) )N. By replacing Y with Y = n2(1 s)s, we obtain (1 )(",
  "B.6.1Proof of Lemma 3.6": "Proof. The analysis by Williamson and Shmoys [41, Theorem 6.16] shows that the expected cut of (S, S)is not less than2M , where M denotes the optimal solution for Problem 3.4. Their analysis assumesthat there is no 0 constraint; however, their proof still holds in our setting, since the 0 constraint and itsrelaxation do not influence the analysis and since Problem (3.4) is a relaxation of Problem (3.2). To provethat E[|S| S] 0.878 (1 )n2, we use the same method as [19, ].For the sake of completeness, we now present the details of the analysis.",
  "OPT,": "where the second step is based on Lemma B.3, and the third step is based on Lemma B.5.To prove the second part of Lemma 3.6, we bound the imbalance of the partition that we get from therandom rounding procedure. We will show that |S| S does not deviate from (1 )n2 too much.",
  "B.6.2Proof of Lemma 3.8": "Proof. We repeatedly apply Lemma 3.7 until our set has size tn. More concretely, if |S0| > tn, we useLemma 3.7 to remove vertices from S0 one by one, and if |S0| < tn, we use Lemma 3.7 to remove verticesfrom S0 one by one. We let Si be the set of vertices after removing i vertices. When this process terminateswe denote the resulting set by T. Let Mi denote the value of the cut given by the partition (Si, Si). We willdistinguish the two cases s < t and s > t.First, suppose s > t. Observe that by Lemma 3.7,",
  "B.7Proof of Theorem 3.9": "We dedicate the rest of this section to the proof of this theorem. For technical reasons, it will be convenient forus to consider opinion vectors s, s0 n. Our hardness results still hold for opinions vectors s, s0 n by the results from Section B.1 which shows that we only lose a fixed constant factor and that maximizers ofoptimization problems are the same under a simple bijective transformation.We also note that in the following, we prove that Problem (B.4) is NP-hard. Notice that Problem (B.4)is a variant of Problem (3.1) by removing cardinality constraint, setting A = D(L) , and setting s0 = 1:",
  "such thats(u) {1, 1} for all u V.(B.4)": "We thus answer the question by Chen and Racz , by setting the k in their problem to be n. Weremark the hardness of Problem (B.4) implies hardness for Problem (3.1) as follows: If we can solve theProblem (3.1), i.e. the problem with an equality constraint s s0 = k, then we can solve the problemwith s0 = 0 and for all values k = 1, . . . , n, and take the maximum over all answers. This gives us anoptimal solution for Problem (B.4). Since there are only n choices for k and since we show hardness forProblem (B.4), we obtain hardness for Problem (3.1).We first prove the hardness of two auxiliary problems and then give the proof of the theorem. We startby introducing Problem (B.7), which is a variant of MaxCut; compared to classic MaxCut, we scale theobjective function by factor 4 and consider the constraints s n rather than s {1, 1}n. We showthat the problem is NP-hard.",
  "Note that by substituting the constraint z = (I + 1": "QL)1s in the objective function, we obtain our originalobjective function from Problem (3.1) and Problem (B.4) for Q = 1.Next, we show that Problem (B.9) is NP-hard. Here, our proof strategy is as follows. Consider an instanceof Problem (B.7). Then, intuitively, for large Q it should hold that z = (I + 1 QL)1s (I + 0)1s = s and inthis case the optimal solutions of Problems (B.9) and (B.7) should be almost identical. Indeed, we will beable to show that both problems have the same maximizer and that their objective function values are almostidentical (up to rounding). This implies the hardness of Problem (B.9) via Lemma B.8. We summarize ourresult in the following lemma, where we use the following notation: OPTB.7(V, E, w) and OPTB.9(V, E, w)denote the optimal objective values of Problems (B.7) and (B.9), respectively, and [] denotes rounding to thenearest integer.",
  "B.7.2Proof of Lemma B.10": "The proof has four steps. (1) We argue that the optimal solution s for Problem B.9 must be from theset {1, 1}n. (2) We derive a useful characterization of the entries zi of z. (3) We exploit the previouscharacterization by showing that there exists a large enough Q such that [zLz] = sLs. (4) We prove that s is also an optimal solution for Problem B.7.Step (1): We observe that Problem B.9 is a convex maximization problem over the hypercube, where theobjective function is a quadratic form with a positive semidefinite matrix. Thus the optimal solution must befrom the set {1, 1}n (see Section B.4). Thus, for the remainder of the proof we consider the optimizationwith s {1, 1}n.Step (2): We derive a useful characterization of zi, which we obtain through the updating rule of the FJmodel. Given an undirected graph G = (V, E, 1",
  "M 3 and that zLz sLs +4M +5": "2M 3 < sLs + 0.5. Thus [zLz] = sLs. Thisproves that the optimal solutions for Problem B.9 and B.7 are identical up to rounding. This also impliesthat Problem B.9 is NP-hard.Step (4): We prove that the optimal solution s for Problem B.9 is also the optimal solution for Problem B.7.We prove this by contradiction. Assume so is the optimal solution for Problem B.7, and soLso > sLs.Since the feasible areas for Problem B.7 and Problem B.9 are the same, so is also a feasible solution for thelatter. Let zo = (I + 1",
  "all t and j. For t = 0 we have that z(0)j= sj and the claim is true. Now observe that the update rule for": "z(t+1)iimplies that at each iteration it holds that, min{si, z(t)j| j = i} z(t+1)i max{si, z(t)j| j = i}. Nowby induction we obtain that each zi is always upper bounded by max{si | i = 1, 2, . . . , n} and lower boundedby min{si | i = 1, 2, . . . , n}. Since we have that 1 si 1 for all i, we obtain our result for i.Next, we obtain the following bounds on sLs for s {1, 1}n:",
  "M 3": "Proof of Theorem 3.9. We prove that Problem (B.4) is NP-hard. Notice that since the objective function ofthe problem is convex (see Section B.4) the optimal solution s for Problem (B.4) will be a vector with allentries in the set {1, 1}.Consider an input (G = (V, E, w), Q) for Problem (B.9). We use an algorithm for Problem (B.4) andapply it on the graph with edge weights w",
  ". Wedenote the latter problem with cardinality constraint k = n": "2 as Problem C. We apply the same techniquethat shows that Bisection is NP-hard given that MaxCut is NP-hard .Consider an instance of Problem (B.4) with n = k vertices, where the disagreement index matrix isrepresented as DL = (I + L)1L(I + L)1. We construct an instance of Problem C by adding n isolatednodes. Note that in the new instance we have 2n = n vertices and k = n",
  ",": "i.e., DL can be partitioned into four blocks, where each block is an n n matrix, with three of them being0 matrices. The remaining block is the n n matrix DL from our instance of Problem (B.4).Now consider the solution s of our instance DL for Problem C. Observe that the solutions objectivefunction value is given by sDLs. Note that, due to the block structure of DL, only the final n entries ofs create a non-negative disagreement. Furthermore, the first n entries of s do not contribute to the finaldisagreement and can be set arbitrarily.Hence, since our cardinality constraint is k = n, the algorithm can pick the solution for the final n verticessuch as to maximize the disagreement DL on our instance of Problem (B.4); the first n entries of s can bepicked such that the cardinality constraint is satisfied. Therefore, the optimal objective function values of ournew instance and the original instance for Problem (B.4) are identical.Consequently, we conclude that Problem (B.4) can be solved by utilizing a solver for Problem C, and thereduction is in polynomial time."
}