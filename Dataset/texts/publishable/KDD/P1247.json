{
  "Abstract": "Typically, Open Information Extraction (OpenIE) focuses on ex-tracting triples, representing a subject, a relation, and the object ofthe relation. However, most of the existing techniques are based ona predefined set of relations in each domain which limits their appli-cability to newer domains where these relations may be unknownsuch as financial documents. This paper presents a zero-shot openinformation extraction technique that extracts the entities (value)and their descriptions (key) from a sentence, using off the shelfmachine reading comprehension (MRC) Model. The input questionsto this model are created using a novel noun phrase generationmethod. This method takes the context of the sentence into accountand can create a wide variety of questions making our techniquedomain independent. Given the questions and the sentence, ourtechnique uses the MRC model to extract entities (value). The nounphrase corresponding to the question, with the highest confidence,is taken as the description (key).This paper also introduces the EDGAR10-Q dataset which isbased on publicly available financial documents from corporationslisted in US securities and exchange commission (SEC). The datasetconsists of paragraphs, tagged values (entities), and their keys (de-scriptions) and is one of the largest among entity extraction datasets.This dataset will be a valuable addition to the research community,especially in the financial domain. Finally, the paper demonstratesthe efficacy of the proposed technique on the EDGAR10-Q and Adecorpus drug dosage datasets, where it obtained 86.84 % and 97%accuracy, respectively.1.",
  "Dataset and the script to generate it is freely available at": "Permission to make digital or hard copies of all or part of this work for personal orclassroom use is granted without fee provided that copies are not made or distributedfor profit or commercial advantage and that copies bear this notice and the full citationon the first page. Copyrights for components of this work owned by others than ACMmust be honored. Abstracting with credit is permitted. To copy otherwise, or republish,to post on servers or to redistribute to lists, requires prior specific permission and/or afee. Request permissions from ., , 2021 Association for Computing Machinery.ACM ISBN 978-x-xxxx-xxxx-x/YY/MM...$15.00",
  "Introduction": "Majority of the information in an enterprise flows through docu-ments, and extracting relevant information from these documentsis at the heart of digital transformation journeys for the enterprise.More specifically, financial documents such as audited reports, an-nual statements, exchange filings etc. are important documentsthat needs to be analysed for multiple compliance and risk relatedapplications such as underwriting, risk rating etc. Extracting in-formation from financial documents in a structured format (i.e.key-value pairs) and analysing them unlocks the opportunitiesto make faster and confident decisions, improve operational effi-ciency by making extracted structured information available todownstream applications. However, Financial documents are verydifferent from traditional natural language English corpus which ismostly used in research and development of traditional informationextraction techniques. Therefore, traditional information extractiontechniques do not generalize well on financial documents whichare loaded with statements conveying facts and claims using avocabulary rich in currency, integral or floating-point values, anddate-time types etc. Mostly, organizations end up employing humanresources to examine and analyze these financial documents. Sincethese documents are generally lengthy (anywhere between 200-300pages) and captures a huge amount of factual or numeric details, itbecomes very time-consuming, error-prone and laborious task tomanually extract and analyse such information.Therefore, there is a need to build an efficient information ex-traction technique that could extract relevant information fromdocuments (possibly from multiple domains) in a structured man-ner i.e., an entity (value) and its description (key) as key-valuepairs. Such an automated solution could have two practical benefits.Firstly, a highly accurate system, which extracts important entities",
  ", ,Himanshu Gupta, Amogh Badugu, Tamanna Agrawal, and Himanshu S. Bhatt": "automatically increases. The performance can also be improvedby fine-tuning the model for open IE Task. There is still scope toextract better noun phrases which in turn will improve extractedvalues. Handling active and passive sentences separately in thepipeline stages is a future direction to be explored. To further ad-vance the research in this direction, we have made EDGAR10-Qdataset extraction code publicly available. Alan Akbik, Tanja Bergmann, Duncan Blythe, Kashif Rasul, Stefan Schweter, andRoland Vollgraf. 2019. FLAIR: An easy-to-use framework for state-of-the-artNLP. In Proceedings of the 2019 Conference of the North American Chapter of theAssociation for Computational Linguistics (Demonstrations). 5459. Gabor Angeli, Melvin Jose Johnson Premkumar, and Christopher D Manning.2015. Leveraging linguistic structure for open domain information extraction. InProceedings of the 53rd Annual Meeting of the Association for Computational Lin-guistics and the 7th International Joint Conference on Natural Language Processing(Volume 1: Long Papers). 344354.",
  "Related Work": "Etzioni et al. refers to a schema-less approach to extract factsfrom texts. This is traditionally done via extracting relations be-tween the facts. The relations are typically verbs in the sentencesand used for the Open IE Relationship paradigm. However, relation-ships are based on the assumption that they connect two entities.In the case of Financial data, we have an entity and its descriptionand its relation not aiding us to link them.We aim to extract key-value pairs using zero-shot Open Infor-mation Extraction. This scenario is complicated than extractingkey-value pairs using relations as done by Li at al. and Levy et al.. Levy et al. also uses a zero-shot approach to train his MRCmodel on templatized questions and then uses that model on unseenrelations. He has pointed out that generating natural questions ischallenging and uses human-generated questions for his zero-shotscenario. Li et al.s work was based on Levy et al. and formalizesrelation extraction as multi-turn question answering. The authoruses both natural and templatized questions based on the relations.In both scenarios, the number of questions that the author canmake is limited. Both the type of questions would not perform wellif the relation they encounter is unseen. Li et al. has also trainedMRC models to return blank or no answer when they could notfind any relevant context. We exercise this ability differently, asexplained in Miwa et al. approached relation extraction by extractingentities and relations together using neural network models (multi-class classification model based on tree LSTMs). The performanceof all such approaches drops on unseen relations. Li and Ji use perceptron and efficient beam search to extract entities andrelations together. They also develop global features to capturethe dependency between entity and relation extraction. Sun et al. build on the previously mentioned framework and uses a jointlearning framework and a flexible global loss function to capturethe interactions of the entities and their relationships.Most of the prior work for entity relation extraction has reliedupon template-based question answering methods where a questionwas predefined based on relation. We do not rely on templatizedquestions which makes it scalable. Since the advancement of Bi-directional Attention mechanisms , various improvements havebeen made in the machine reading comprehension field by differ-ent models like BERT, XLNet, ALBert that extract textfrom the passages given queries. Answer Extraction can be further",
  "lease liabilities as of September 26, 2020 were10.3 years and 2.0%, respectively2.0%Percentdiscount rateaverage lease termWhat is discount rate ?2.00%": "decomposed into a multi-class text classification task that predictsstarting and ending position of the answer.McCann et al. introduced decaNLP, where various challeng-ing tasks like relation extraction, question answering, semantic rolelabeling, etc., were presented as problems of spanning MRC overcontext. He further introduced a Multitask question answering net-work, which learns from all the challenges raised in the paper. Theirframework showed improvements in NER and zero-shot capabilityin text classification. To extract entities, several state-of-the-artframeworks like Stanford CoreNLPs NER, Spacy, NLTK, Flair arepresent as open source libraries. .",
  "Proposed Solution": "This paper presents a simple yet efficient technique to extract the en-tities and their descriptions from the sentences. As shown in , it starts with data cleaning and entity extractions. For entity ex-traction, this paper leverages ner-ontonotes-fast by Flair2, whichis an 18-class named entity recognition model. Next, it presentsa comprehensive phrase generation method and the phrases arefurther used to frame questions to the machine reading comprehen-sion (MRC) or QA model. Finally, given the generated questionsand sentences, the output from MRC model is used to associate theentities to their corresponding descriptions. The key stages of theproposed technique are elaborated below:",
  "Phrase generation": "A noun phrase (NP) includes a nouna person, place, orthingand the modifier that distinguishes it. Open IE is predicatedon the idea that the relation (which are action verbs in most cases)is the central element of study, from which all other considerationsflow. However, in many instances, the verb is no help, particularlyin financial data. Consider the sentence: \"The Deferred revenue for2020 is $20 billion.\" Like most financial records are of the form \"is,was, be,\" etc., the verb \"is\" in this sentence is an auxiliary verb anddoes not describe any particular event nor give any informationabout the entity.We extract two types of phrases from the sentences, namelysimple and complex. In simple phrase extraction, each sentencecomprises subject-object and verb connecting them where Subjector Object is usually a noun or pronoun. After searching for a nounand pronoun, we check for any noun compound or adjective. Onthe other hand, for complex phrase extraction we first start withpreposition extraction. We then follow similar steps as in simplephrase extraction to look for phrases in both left and right of thepreposition. It has to be noted that simple phrases are not alwaysfound on both sides of the preposition. Algorithm 1 further sum-marizes the process of simple and complex phrase extraction fromthe sentences.Now we demonstrate the extraction of simple and complex nounphrases for the sentence, In connection with the refinance we reducedthe loan amount by $6.8 million.. The syntactic tree for the abovesentence is shown in . We search if the tokens POS tag isa noun or pronoun as we are looking just for noun phrases. We",
  "29return phrase_list": "also ensure that phrase lies either in the Subject or Object of thesentence to ensure we are skipping the relations. In this case, wegot \"amount\" the first word of the phrase. After that, we iteratethe node to see its children named subtoken in Algorithm 1. Wesearch for subtokens dependency relation with the token as acompound relation, or we search if the subtoken is an adjective.The intuition behind this is that if the subtoken and token have acompound relationship, they form a meaningful noun phrase. Inthis case, \"amount\" has a compound relationship with its subtoken\"loan\" so they together form \"loan amount\" as the meaningful nounphrase. Similar logic is followed for searching adjectives. ComplexNPs are identified as series of noun phrases with a prepositionseparating them, so we start by identifying them. In this example,the preposition identified was \"in\". Then we iterate both up anddown the node to find noun phrases that follow the same methodmentioned above. The noun phrases identified from the top were\"connection\" and the bottom was \"refinance\". The entire complexNP was formed as NP from top + preposition in the middle and +NP from below. The resultant was \"connection with refinance\". In this paper, we use Spacy 3 library for POS tags of the wordwhich were leveraged in Algorithm 1. Similarly, using Algorithm1, we obtain the following simple and complex noun phrases forsentences mentioned in .",
  ": Syntactic tree structure for extraction of simpleand complex noun phrases": "allows our technique to be domain agnostic and thus can be easilyexpanded to newer domains. The process to leverage noun phrasesto generate the questions and further using the MRC model to as-sociate entities with their corresponding descriptions is describedbelow: Each paragraph in the document is broken down into sen-tences. For each sentence, the following are extracted: Phrases(using simple and complex noun phrases described in Algo-rithm 1) and Entities using the Flair NER Model. Based on the entity type and the noun phrases, the questionsare framed accordingly. For instance, if the entity found outwas of type date then, the question would be \"when is\" + NP?.In our example, the question for the 1st sentence of would be, \"how much is borrowing capacity on revolvingcredit loan ?\". In instances where the entity type is of integer, float, orpercent where appending \"when is\" or \"how much is\" doesnot give an advantage. For such cases, to keep the questiongeneric we append \"what is\" to the noun phrase. For example,in the 2nd sentence in , The question \"What is loanbalance ?\" was created based on the entity type of 2% and1%. Once these questions are generated, they are fed into theMRC Model, and its answer is checked if it contains theentity. To give an example, in the 1st sentence of , thefollowing questions are created, and the model returns theircorresponding answers and their confidence values:",
  "\"How much is revolving credit loan ?\" answer: \"$33,000\",confidence score: 0.856": "\"How much is available credit facility ?\" answer: \"$60,000to $93,000\", confidence score: 0.5762If there are multiple questions whose answer has the entity,we select the question whose answer is of the highest confi-dence value. In the above example, \"borrowing capacity onrevolving credit loan\" is chosen as the key for $30,000, and\"revolving credit loan\" is chosen as the key for both $60,000to $93,000. If the entity is not present in the response of the MRC Model,the question is discarded. In the 2nd Sentence of , thefollowing questions are created : \"What is penalty of % ?\" \"What is loan balance ?\"None of them are returning \"13-24 or 25-36\" so the phrases\"penalty of %\" and \"loan balance\" are discarded. There are instances where none of the generated questionsreturned an answer with the target entity or returned re-sponses with a different entity as shown above. For thosecases, we create the question \"what is\" entity?. Here its re-sponse would be considered as the key (opposite to the caseabove). In the 2nd sentence of the Table, none of the ques-tions returned relevant answers, So the following questionswere created: \"What is 13-24 or 25-36 ?\" \"What is 2% and 1% ?\" In the above cases, where questions are formed based onentities, the answers are checked if they have given any otherentity as the answer. For instance, the questions, \"what is 2%and 1% ?\" return \"2\" as the answer for the 2nd sentence of. If the cases mentioned above hold then, the responseis discarded. Here all the cases to identify the noun phraseassociated with the entity fail, so no answer is returned. If they do not fail, then the response is also considered aviable answer. For instance, In the 2nd sentence, the questionwas framed: \"What is 13-24 or 25-36 ?\" which returned \"loanis paid during months\" as the answer. Using the rules stated above, entity and their associated nounphrases are identified. The last two columns of show thequestions which were generated and their responses from the MRCmodel. Inspired by the success of the pre-trained transformer model,we employ distilled BERT by Hugging Face trained onSQuAD dataset as the MRC model for our zero-shot questionanswering 4.",
  "Data Sets": "This paper presents results on two datasets; 1) EDGAR10-Q whichcomprises financial documents and 2) Ade_corpus which comprisesmedical domain documents. The characteristics of two datasets arefurther described below: 4.1.1EDGAR10-Q Dataset: Mostly, publicly available datasets areintended for noun-verb-noun extraction (triplet extraction) and arelimited in terms of total number of sentences, entities per sentence;therefore, does not accurately represent the real-world scenarios.To bridge this gap, this paper introduces a new financial datasetEDGAR10-Q, consisting of 18752 documents with 973655 sen-tences from quarterly and annual financial reports (10-Q and 10-K),filed by approximately 4000 listed companies at the U.S. Securitiesand Exchange Commission (SEC) over the last two years (2019,2020). To the best of our knowledge, this is one of the largest real-world dataset for NER extraction in finance domain, as describedin .All the SEC filings are standardized where all the entities ina sentences are tagged with their corresponding NER labels. Asshown in a, there are four types of entities namely; money,time (duration), percent, and cardinal values (pure, shares and in-teger). further enumerates the rich information present inthe EDGAR10Q dataset and compares this dataset with theexisting NER Dataset. We observed that the EDGAR10-Q dataset islargest and richest among all the datasets on multiple parameters.We assert that this data set is the first-of-its-kind in finance domain",
  "and will pave the way for new research and collaborations in infor-mation extraction from financial documents. The script to generatethe dataset and its examples are given in the github repo. 5": "4.1.2Ade Corpus: Since we are not using relations to form a triplet,instead directly tagging Entities with their associated descriptions,we found fewer datasets in this particular domain. However, thedrug dosage relation dataset of (Ade_corpus_v2_drug_dosage_relation)ade corpus was used for this. The corpus is in the form of a sentence,the drug tagged in the sentence, and its dosage required. 6",
  "Performance on EDGAR10-Q Dataset": "Setup: We ran our technique on 19468 documents, with approx-imately 5 10-Q documents per company and stored the accuracyscore for each document.as first column shows the Accuracy statistics for theEDGAR10-Q dataset. The overall accuracy obtained from the docu-ments is 0.8684. The per-document accuracy differs from the overallaccuracy by 0.01. The model gives consistent performance acrossdocuments with a standard deviation of only 0.07. The consistencyof the model is also observed in b.As we can see from Tables 1, the dataset has many complicatedsamples. The model performed linearly with increasing difficultywith the maximum accuracy in sentences with just one entity andcontinues to decline as the number of entities in a sentence in-creases. However, most sentences contain less than three entities(75.34%), and our model gives a high accuracy score (0.926, 0.897,and 0.888) in them.",
  "shows the instances where our pipeline achieves exact": "matches and incorrect matches. As seen in the 3rd and 4th row ofthe table, the sentences are fairly complex and its arduous to getthe corresponding description of the entities from the sentences.To compare our methods with existing Open IE model, we ranStanfords Open IE and Stanovsky et al. Open IE models onEDGAR10-Q dataset. We realize that Open IE models fail to performwhen dealing with long range dependencies. shows relationextraction on sentences given in . The detailed results abouthe performance can be found in the github repo. 7",
  "Ablation Study: Effect of Phrase Generation": "To understand the importance of phrase generation in our pro-posed technique, we ran it on the EDGAR10-Q corpus withoutgenerating phrases. Algorithm 1 was omitted entirely and the ques-tions were asked simply using the entity. For instance, all the ques-tions were asked as \"What is Entity ?\" .The results of this study aretabulated in a and compared with the original techniquewith phrase generation step. It is evident from both the tables thatour technique works much better with the generated phrases. Theperformance is highly impacted as seen in b.The probable reason for this is that phrases take the sentencescontext into the picture, and hence many more sentence-specificnatural language questions are asked. The higher number of rele-vant questions, in turn, will give us a much higher probability ofgetting correct answers.",
  "Conclusion": "In this paper, we introduced a zero-shot technique for the Open IEtask on financial documents. We presented a simple yet efficienttechnique which begins by extracting entities along with simple andcomplex phrases from the sentences. With the extracted phrases andthe given sentence, we formulate a zero-shot question-answeringtask to associate the entities to the phrases as their correspondingdescriptions. We demonstrated the efficacy of the proposed tech-nique which do not rely on predefined relations and thus can beeasily scaled to newer domains such as finance or medical. We alsointroduce a financial document corpus on which we evaluate ourmodel and achieve 86.84% accuracy.However, this problem is far from being solved. Our pipeline iscurrently limited by the performance of MRC models. Once thesemodels improve, then the performance of MRC dependent tasks",
  "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is allyou need. arXiv preprint arXiv:1706.03762 (2017)": "Thomas Wolf, Julien Chaumond, Lysandre Debut, Victor Sanh, Clement Delangue,Anthony Moi, Pierric Cistac, Morgan Funtowicz, Joe Davison, Sam Shleifer, et al.2020. Transformers: State-of-the-art natural language processing. In Proceedingsof the 2020 Conference on Empirical Methods in Natural Language Processing:System Demonstrations. 3845. Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov,and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretraining for languageunderstanding. arXiv preprint arXiv:1906.08237 (2019)."
}