{
  "Abstract": "The ability for individuals to constructively en-gage with one another across lines of differenceis a critical feature of a healthy pluralistic soci-ety. This is also true in online discussion spaceslike social media platforms. To date, much so-cial media research has focused on preventingillslike political polarization and the spreadof misinformation. While this is important, en-hancing the quality of online public discourserequires not just reducing ills but also promot-ing foundational human virtues. In this study,we focus on one particular virtue: intellectualhumility (IH), or acknowledging the potentiallimitations in ones own beliefs. Specifically,we explore the development of computationalmethods for measuring IH at scale. We manu-ally curate and validate an IH codebook on 350posts about religion drawn from subreddits anduse them to develop LLM-based models forautomating this measurement. Our best modelachieves a Macro-F1 score of 0.64 across labels(and 0.70 when predicting IH/IA/Neutral at thecoarse level), higher than an expected naivebaseline of 0.51 (0.32 for IH/IA/Neutral) butlower than a human annotator-informed upperbound of 0.85 (0.83 for IH/IA/Neutral). Ourresults both highlight the challenging natureof detecting IH onlineopening the door tonew directions in NLP researchand also laya foundation for computational social scienceresearchers interested in analyzing and foster-ing more IH in online public discourse.1",
  "Co-first author. Co-corresponding author": "social media has also created an environment thatoften rewards the forgetting of our virtuous selvesleading to the spread of misinformation (Vosoughiet al., 2018), embedding users within echo cham-bers (Gillani et al., 2018), and leading individu-als to harbor negative affect towards those whohold different beliefs (Iyengar et al., 2019). Manyefforts to foster more constructive discourse on-line focus on addressing these ills, for example,by developing interventions that try to reduce af-fective polarization (Saveski et al., 2022b), curtailthe spread of misinformation (Pennycook et al.,2021), and increase healthy politically cross-cutting exposures (Gillani et al., 2018; Saveskiet al., 2022a; Santoro and Broockman, 2022; Levy,2021). Yet few focus on cultivating deeper-seatedhuman virtues that might prevent such ills frommanifesting in the first place.Intellectual humility is one such virtue and in-volves acknowledging the potential limitations ofones own beliefs, in part by welcoming diverseperspectives (Porter and Schumann, 2018; Whit-comb et al., 2017). Greater intellectual humilityhas been associated with higher scrutiny of misin-formation (Koetke et al., 2022), less political myside bias (Bowes et al., 2022), and less effectivepolarization (Bowes et al., 2020): the degree towhich individuals dislike political outgroups (Iyen-gar et al., 2019).Contemporary literature on intellectual humil-ity (IH) has mostly been published in the so-cial sciences and philosophy, exploring it asa cognitive phenomenon and thereby develop-ing taxonomies and other measurement frame-works through questionnaire-based behavioraltasks (Leary, 2023). Yet fostering greater IH on so-cial media requires first developing scalable meth-ods for detecting its presence or absence.This paper introduces a novel task within thefield of natural language processing: the automateddetection and classification of intellectual humility (IH) and its opposite, intellectual arrogance (IA), inonline public discourse. By developing methods toautomatically detect IH and IA, we aim to deepenour understanding of which discussionsand par-ticipantstypically exhibit these traits. This in-sight is crucial for designing and deploying inter-ventions that promote greater intellectual humil-ity online. Such interventions are similar to thosetargeting related issues like polarization and civildiscourse (Gillani et al., 2018; Santoro and Broock-man, 2022; Argyle et al., 2023). This researchoffers a fundamental step towards enhancing thequality and constructiveness of online interactions.We present a detailed development of a com-prehensive codebook and ontology for this task,accompanied by a systematic annotation processto refine these tools. Our study evaluates off-the-shelf large language models (LLMs) and exposesthe substantial challenges these models encounterin accurately identifying IH and IA. Related workincludes Abedin et al. (2023), which estimates IHfor study participants using standard psychologicalassessments and then analyzes language patternsfrom participant journals to identify predictors ofIH. However, our study diverges significantly in itsobjectives and methods. Specifically, we employmore recent advances in NLP, focus on a differentprediction tasknamely, the multi-class classifi-cation of existing written content based on a pre-defined taxonomy rather than predicting IH scoresgenerated by participantsand our research is setin the context of online Reddit discussions.Specifically, our findings indicate that while hu-man annotators achieve strong agreement, with aCohens Kappa of 0.67, the performance of LLMs,as evaluated by a Macro-average F1 score of 0.64using GPT-4-turbo-2024-04-09, falls significantlyshort of human levels. Even treating the detec-tion of Intellectual Humility as a three-class clas-sification problem (IH/IA/Neutral) achieves a rela-tively low Macro-F1 score of 0.7, which falls sig-nificantly below a human annotator score of 0.83.Various advanced prompting methods, includingChain of Thought and automatic prompting, didnot markedly improve model performance. Theseresults highlight the promise of using computa-tional methods to assess the presence or absenceof intellectual humility at scale but also illustratehow doing so can be challenging, opening the doorto new directions for research at the intersectionof natural language processing and computationalsocial science. Our specific contributions include: 1. Development of an Intellectual HumilityCodebook: We synthesized insights from socialscience and philosophy to create a frameworktailored for analyzing online religious discourse.This codebook serves as a foundational tool foroperationalizing the assessment of intellectualhumility. 2. Iterative Annotation Process: Two trained an-notators applied this codebook to 350 discus-sion threads from various religious subreddits,refining our approach through iterative codingto ensure robustness and repeatability of ourannotations. 3. Benchmarking LLM-Based Classifiers: Weassessed the capability of existing LLMs, par-ticularly using the GPT-4-turbo-2024-04-09model, in automating the detection of IH andIA. Our benchmarks reveal the current limita-tions of LLMs and underscore the necessity fordeveloping more sophisticated models.",
  "Related work": "ReligionandHumilityPsychologistsandphilosophers have found that perceiving greaterintellectual humility in ones selfas well as onesopponent in a religious conflictis positivelyassociated with the ability to forgive the offendingparty (Zhang et al., 2015).This may, in part,underlie another finding in the religious domain:that greater intellectual humility can be positivelyassociated with religious tolerance (Hook et al.,2017). The latter study also identifies a positivecorrelation between intellectual humility andexposure to diversity, such that those reportinggreater IH are more likely to express religioustolerance when exposed to diverse groups. Thisfinding is underscored by recent work on relatedtopics (Evolvi, 2018), and adds nuance to existingtheories extolling the value of diverse exposures(Pettigrew and Tropp, 2006): such exposures mayhave a substantive positive impact on downstreamoutcomes of interest (like religious tolerance)when participants approach them with greaterintellectual humility. This is particularly crucialonline, where evidence supports that poorlypresented exposure to diverse views can worsendivisions by amplifying extreme opinions fromdifferent sides rather than bridging gaps (Bail et al.,2018; Mims, 2020).Intellectual humility in the religious domain isalso relevant to interactions between religious and",
  ": The flow chart for developing our IH Codebook": "non-religious people.Contemporary discoursehighlights that science and religion are often pit-ted against one another (Dennett, 2006), despitethe fact that religious or spiritual practices mayhelp augment scientifically grounded practices likecounseling (Gordon, 2018) or offer ways of in-terpreting scientific phenomena (Lightman, 2023).With diverse discourse on religion becoming moreprevalent across online settings (Saha et al., 2023;Evolvi, 2018; Parthasarathi and Kumari, 2022;Evolvi, 2019), where the large scale of datasetsoften require computational modeling and analy-ses, there is a growing need to develop a computa-tional infrastructure to both measure and enhanceintellectual humility in digital discourse. Promoting Constructive Discourse OnlineRe-cent experimental studies have assessed how fos-tering constructive discourse online can be accom-plished through tool-based interventions. Specif-ically, scholars have identified how ranking algo-rithms used by current social media platforms maycontribute to greater affective polarization. Manyexperts suggest that implementing mechanisms todiversify the content consumed by users could re-duce this polarization (Levy, 2021). Researchersstudying misinformation have found that prompt-ing social media users to consider accuracy be-fore sharing articles can reduce the spread of falseinformation (Pennycook et al., 2021). Similarly,inoculating users against lower-quality contentthrough light-touch coaching interventions has alsobeen proven effective (Roozenbeek et al., 2022).Some have even designed randomized interven-tions that connect people from opposing politicalgroups to facilitate synchronous dialoguefindingthat such dialogue can reduce affective polarization,but generally when discussing non-controversialtopics (Santoro and Broockman, 2022).More recent work (Argyle et al., 2023) has ex-plored how generative LLMs may assist partic-ipants involved in contentious conversations inrephrasing their contributions to be less toxic andmore civilpointing towards potential methods for fostering enhanced inclusivity in public settings.While these are important studies, most focus onreducing existing ills on social media platformsinstead of seeking to promote virtues whose lackmay be at the root of such ills to potentially pro-duce more sustainable positive transformations indiscourse and behavior (Bowes et al., 2023).",
  "Data Collection": "We focus on discussions on Reddit centered aroundreligious topics. This is chosen due to religions en-during influence on global sociopolitical dynamics,notably in shaping policy and public dialogue in theUnited States and beyond. Furthermore, the inher-ently subjective nature of religious truth under-scores the necessity for intellectual humility in fos-tering meaningful exchanges across diverse beliefs.Specifically, our study utilizes the r/ReligionHubsDirectory of Religion-Related Subreddits2, whichlists 48 religion-oriented subreddits, to define ourdataset. From these, we downloaded all posts andcomments spanning from June 2005 to December2023 using the Academic Torrents archive.In each subreddit, we randomly selected up to500 posts and their associated comments, ensuringa broad representation of discussions. To avoidbiases introduced by highly active users, we ex-cluded posts from individuals who have made over10,000 contributions to any single subreddit, astheir views might not reflect those of the generaluser base. After preprocessing and applying thesecriteria, our dataset consisted of 17,160 posts. Thiscollection was then used to develop and refine anIH taxonomy. : Manually identifying and eliminating similar labels for broader terms. The terms highlighted in greenwere then added to the first iteration of the codebook. The terms highlighted in red were the ones eliminated.",
  "Defining the Codebook": "We started assembling the codebook by firstprompting ChatGPT (i.e., GPT 3.5) with a randomsample of posts from religious subreddits and ask-ing it to 1) classify each post as \"intellectually hum-ble\" or \"not intellectually humble\", and 2), offera justification for its classification. These outputswere then manually categorized into 21 broad cate-gories: 12 reflecting intellectual humility (IH) and9 reflecting its oppositewhich, for convenience,we describe as intellectual arrogance (IA). Thesame exercise was repeated, but this time, GPT wasprompted to provide classifications and justifica-tions that were more specific to religionasking itto indicate whether or not posts demonstrated reli-gious intellectual humility. This exercise yielded14 additional categories: 7 reflecting IH and an-other 7 reflecting IA.Next, we turned to existing literature describingdifferent features of intellectual humility (Porteret al., 2022; Whitcomb et al., 2017; Leary et al.,2017; Porter and Schumann, 2018). Porters andLearys work on taxonomizing intellectual humil-ity served as the main source for curating IH cate-gories, which we condensed into shorter labels toinclude in the codebook (Porter et al., 2022; Whit-comb et al., 2017; Leary et al., 2017). This resultedin 20 additional terms: 12 reflecting IH and 8 re-flecting IA.We then used ChatGPT to identify similaritiesbetween the 55 terms and definitions and com-bine labels into a smaller codebook to begin apply-ing to the Reddit posts through manual annotation.Combining labels and consolidating the codebookyielded a v1 codebook consisting of 25 labels: 12",
  "Refining the Codebook": "Two human annotators iteratively applied the code-book to annotate a random sample of Reddit posts(see Appendix A.1 for the background of the anno-tators). We sampled up to 40 threads (if available)from each subreddit, yielding over 1,400 sampledthreads across the 48 subreddits. For each thread,we also randomly determined whether the first orsecond comment (following the submission textthat accompanied the start of the thread) wouldserve as the basis for annotation. In cases wherethe first comment was selected as the annotationtarget, only the submission text was chosen as con-text for that annotation; in cases where the secondcomment was selected, both the submission textand first comment served as context.Out of the 1,400 threads, human annotators readand collectively annotated 350 across a series ofannotation waves (the remaining were not anno-tated due to the time intensiveness and complexityof the annotation task). Each annotation wave in-cluded the following steps: 1) selecting a subsetof 50 to 100 posts to annotate (after reading therelevant post context), 2) after annotating, com-puting inter-annotator agreement (average CohensKappa (McHugh, 2012) across all applied codes),3) analyzing per-code Kappa values to understandwhich codes had more or less agreement, 4) dis-cussions between annotators to align on or refinecodebook definitions before the next annotation wave.Cohens Kappa values of 0.41-0.6 typically in-dicate moderate agreement; 0.61-0.8 indicate sub-stantial agreement; and 0.81-1.0 indicate almostperfect agreement (McHugh, 2012). Annotatorsengaged in four successive annotation waves, withthe first three involving 100 posts and the last oneinvolving 50. The first wave was conducted withongoing discussion and communication betweenannotators, yielding a Cohens Kappa of 0.62. An-notations in the next wave were performed indepen-dently, yielding a much lower score of 0.35. Afterthis, the annotators discussed disagreements andadjusted the codebook, obtaining average Kappavalues of 0.6 and 0.7 in the remaining waves. It isimportant to note that the annotators did not revisitand re-annotate data from previous waves.As the waves progressed, step 4 yielded sev-eral adjustments to the codebook. These adjust-ments typically involved eliminating or consolidat-ing codes or updating code definitions. The deci-sion to make these adjustments was typically madebased on three factors: 1) significant overlap be-tween the application of certain labels (like demon-strating self-righteousness and a condescendingattitude, which often occurred together); 2) poorly-defined codes, particularly those reflecting a lack ofsome activity (like Avoids Challenging ReligiousCustomsa post not challenging religious cus-toms wouldnt necessarily mean it is demonstratingIA), and 3) related to 2), insufficient demonstrationof intellectual humility or arrogance.We computed a final average of Cohens Kappaacross all data from the various annotation wavesusing only the codes in the final codebook, yield-ing a score of 0.67. This score indicates strongagreement. We opted for this more conservativemethod rather than reporting only the highest Co-hens Kappa, which was obtained after our finalwave. This approach ensures a more comprehen-sive representation of the kappa score, encompass-ing all data used to create the gold standard dataset.Many codes that led to lower agreement scores inearlier waves were either eliminated or merged asthe annotation process progressed. Consequently,while the final kappa score is higher than those ofearlier waves, it remains below the score achievedin the last wave, as expected.Across all waves, 194 of the 350 posts were as-signed at least one code from the final codebook. summarizes the final codebook and inter-annotator agreement across codes. Some labels,",
  "# Unique Labels1.160.694.00# Context Words266.44 344.66 2699.00# Context Sentence 14.4716.90129.00# Target Words98.0316.90129.00# Target Sentence5.856.7858.00": ": The descriptive statistics for the dataset includethe mean, standard deviation (Std), and maximum (Max)number of unique labels per sample (# Unique Labels),as well as the number of words in the context (# Con-text Words), the number of sentences in the context (#Context Sentences), the number of words in the targetcomment (# Target Words), and the number of sentencesin the target comment (# Target Sentences). such as Displays Prejudice, appear infrequentlyin our datasets due to the limited scale. However,their importance to the concept of intellectual hu-mility made it essential to retain them, as they ad-dress aspects specific to protected groupslikerace, gender, and religionthat are not covered byother categories such as condescending attitudeand ad hominem. In addition to categorizing byindividual labels, we assigned a composite IH/I-A/Neutral label to all 194 posts. This binary classi-fication was inferred from the cumulative presenceof IH-related versus IA-related labels: a post witha predominance of IH labels was classified as IH,and vice versa for IA. Of the total, 134 posts wereclassified as IH, of which 5 included at least oneIA label. Conversely, of the 60 posts classified asIA, one included an IH label. There were no postswith an equal number of IH and IA labels. presents the descriptive statistics of our dataset.Appendix A.2 displays sample comments corre-sponding to each label in the final codebook.4Evaluating LLMs for Automated IHLabeling We utilized our developed codebook to conductexperiments with LLMs, aiming to assign IH andIA codes to posts using various prompt designs andmodel configurations. To ensure determinism inthe generated responses, we set the temperatureparameter of the LLMs to zero. This practice isrecommended to ensure that the generated text ismore focused and deterministic.",
  "Unsupported Claim (UC)IAAssertion that lacks evidence oradequate support, making itunreliable or unverifiable.0.45310": ": Final intellectual humility codebook (abbreviations per code are included in parentheses). Kappa indicatesthe computed Cohens Kappa for each label across all annotation waves, # Agreed indicates how many posts wereassigned each label by both annotators, # Samples shows the number of samples for each label in our dataset. the taxonomy outlined in the codebook.We used the human-annotated data as a standardfor evaluation, calculating the Macro-F1 score formodel predictions. The F1 score reported is anaverage derived from comparing the labels gener-ated by two annotators on a subset of samples andlabels. Its important to note that annotators do notdirectly label the IH/IA/Neutral classification;instead, it is inferred from the aggregation of indi-vidual labelsif a post receives more IH-relatedthan IA-related labels, it is classified as IH, andconversely as IA. Samples without either an IH orIA code are labeled as Neutral.Each experiment also includes a calculation ofa baseline and an upper-bound F1 score: (1) TheBaseline Macro-F1 score represents the expectedperformance of a naive model that randomly as- signs labels based on the distribution of codes inthe human-annotated data. (2) The inter-annotatoragreement determines the Upper Bound. We treatthe labels from Annotator A as the reference setto calculate the Macro-F1 score for Annotator Band vice versa. The upper bound is the mean ofthese two scores, providing a benchmark for themaximum achievable performance by the modelsunder ideal inter-annotator consensus.",
  "Prompt Design and Evaluation": "Prompt design is critical when conducting exper-iments with LLMs. To explore the impact of var-ious prompt styles, we manually created multipleprompts, differing in both content and format.Content Variations: (1) Code-Only (C): Theprompt includes only the name of the code. (2) Description-Only (D): The prompt includes onlythe description of the code, omitting its name.Code-and-Description (C&D): This comprehen-sive format includes both the name and the descrip-tion of the code, allowing us to assess whether theintegration of these elements influences model per-formance.Format Variations:(1) Multiple-Selection(MS): This format presents all codes in a list, in-structing the model to select codes that apply tothe post. (2) Binary Question (BQ): In this format,each code is considered individually; the model de-termines whether a specific code applies to a givenpost. We introduced these format variations to ex-plore the primacy effects observed in LLMs, wheremodels tend to prefer choices appearing earlier ina list (Wang et al., 2023; Guo and Vosoughi, 2024).Note that for the IH/IA/Neutral prediction, it is im-possible to format the question into BQ; therefore,we only test with MS.These variations resulted in six distinct promptconfigurations. After the initial development, weiteratively refined the prompts to ensure the gener-ated text adhered closely to the instructions. De-tailed designs of these prompts can be found inAppendix C.1.We assessed the effectiveness of these promptsusing GPT-3.5-turbo-0125 and GPT-4-turbo-2024-04-09, the most recent versions of the GPT-3.5and GPT-4 models at the time of our experiments. displays these prompts performance met-rics, detailing the average outcomes for all IH/I-A/Neutral labels (All) and their efficacy in theIH/IA/Neutral binary classification.For the aggregated IH/IA/Neutral classifica-tion, the performance across all prompt designs isrelatively uniform for each model and significantlyexceeds the naive baseline. This uniformity sug-gests that the prompt design and model choice min-imally impact the IH/IA/Neutral task outcomes.Conversely, for the Mean of Labels (All), we ob-serve notable variability in results depending on theprompt design and model used. Generally, GPT-4outperforms GPT-3.5 using the same prompt de-signs, with the Code-and-Description and BinaryQuestion format (C&D-BQ) yielding the best re-sults across both tasks. For Content Variations,the Code-and-Description (C&D) configurationconsistently delivers superior performance for bothmodels, likely due to its richer contextual input.Regarding Format Variations, the Binary Ques-tion (BQ) format is more effective with GPT-4,",
  "BaselineDistribution0.320.51Upper boundMutual0.830.85": ": Performance metrics for IH and IA labelsacross various prompt designs. The table presents meanscores for all labels, labeled as All and the classifica-tion of samples as IH, IA or Neutral is indicated underthe column IH/IA/NE. The best performance for eachlabel is highlighted in bold, while the second best isunderlined. while the Multiple-Selection (MS) format showsbetter results with GPT-3.5. This difference maystem from GPT-3.5s susceptibility to the primacyeffect, where altering the order of labels signifi-cantly impacts performance. However, it is unclearif this performance dip is solely due to primacyeffects or if it is also influenced by changes in theprompt structure itself. Despite the LLMs superiority over the naivebaseline, a significant discrepancy remains be-tween the models performance and the humanannotation-informed upper bounds, particularlyin the task of label-wise prediction.The best-performing combinations of prompt and model fallshort of the upper bounds by 0.13 for the IH/I-A/Neutral task and 0.21 for Labels. GPT-4consistently outperforms GPT-3.5 across all labels,which is anticipated given GPT-4s larger modelsize. The Code-and-Description (C&D) formatachieves the highest scores for IH-specific labels,likely due to the richer context provided by theseprompts. Detailed performance metrics for each la-bel, excluding the overall mean performance acrossall labels, are presented in Appendix D.1. For IA-specific codes, the Description-only (D)strategy proves most effective. Conversely, theCode-and-Description (C&D) format exhibits theweakest performance, suggesting that LLMs mayprocess IA codes differently from IH codes. Whensynthesizing the results for both IH and IA codes, it",
  ": The top 5 positive/negative important words for IH, IA, and Neutral (NE), produced using LogisticRegression with TF-IDF features": "is essential to recognize that performance can varysignificantly among individual codes. The best-performing combinations of prompt and model stillfall short of the upper bounds by 0.23 for the IHMean and 0.15 for the IA Mean.All these results, especially the label-wise resultsshown in Appendix D.1, underscore the inherentchallenges in this task. Except for the methodsbased on LLMs, we also conducted experimentswith classical methods on the IH/IA/Neutral task,utilizing TF-IDF or Bag-of-words for feature ex-traction followed by prediction based on the Logis-tic Regression. These methods perform similarlyto our naive baseline based on the class distribu-tion (with Macro-averaged F1 scores across fivecross-validation folds of 0.36 and 0.39, respec-tively), highlighting the superiority of the LLM-based method.",
  "Interpretable Model Analysis": "Following previous work (Abedin et al., 2023), weshow the top 5 positive/negative important wordsfor IH, IA, and Neutral class. For this, we first uti-lize Logistic Regression with the TF-IDF featureto predict the coarse class (IH/IA/Neutral) and thenutilize the Python ELI5 library for interpretablemachine learning to understand the extent to whichdifferent features might influence the models clas-sifications. The keywords for each class are shownin .We can observe that words that influence pos-itive predictions in the model for the IH and IAclasses demonstrate several patterns. For instance,the word absolutely tends to sway classificationstowards IA, whereas less interpretable terms likehttps (perhaps indicating links to other resources)and did appear to reduce the likelihood of a pieceof content being labeled IH.In addition to this keyword-based analysis, inAppendix E.1, we demonstrate how label descrip-tions can impact model understanding, with LLMssometimes mislabeling contextually tangible con-cepts like the Kingdom of Heaven as mystical.These discrepancies, possibly arising from ambi-",
  "Performance with Multiple Boost Methods": "The experiments with various prompts and modelsunderscore the challenges of label-wise predictiontasks. Given the significant performance gap be-tween human annotators and our models, we imple-mented several boosting methods to enhance modelperformance, particularly using the C&D-BQ set-tings with GPT-4, which provided the best initialresults.We explored few-shot learning, chain-of-thought (CoT), automatic prompt optimization(Auto-Optimization), and iterative refinement withself-feedback (Self-Refinement). These methodsare detailed in Appendix B and C.2. illustrates the impact of these methodscompared to the human annotators upper bounds,as detailed in Appendix D.3. All methods, exceptFew-shot, significantly improved performance onlabel-wise prediction tasks, achieving near-humanlevels for the \"IH/IA/Neutral\" (IH/IA/NE) task.The dip in performance observed in Few-shot learn-ing is potentially due to overfitting, as discussedin Zhao et al. (2021). The effectiveness of thesemethods varies by label. For IA labels, all methodstypically surpass the original settings, while theirimpact on IH labels is less uniform. This suggestsdifferent underlying mechanisms in how LLMs pro-cess IH and IA labels. In general, considering thetrade-off between performance and cost, no boost-ing method is suggested for this task, so promptingengineering should be more promising.Except for the GPT family, we also testedwith other models, with outcomes detailed in Ap-pendix D.2.",
  "Generalizability of the Dataset": "The generalizability of the dataset is crucial to itsutility and faces two main challenges: 1) extendingthe application of Intellectual Humility/IntoleranceAmbiguity (IH/IA/Neutral) beyond religious con-texts and 2) expanding the datasets scope withinthe religious domain. These challenges are compli- IH/IA/NE APB RDP EM RL RB SO MF IH Mean DAL CDP CA AH DP UC IA Mean",
  ": Comparison between different boosting meth-ods and the human annotator upper bound; negativevalues indicate performance below the upper bound.Original refers to the results without any boosting": "cated by the reliance on expert judgment to identifyIH/IA/Neutral, adding layers of complexity to bothtasks.To broaden IH to additional domains, it is nec-essary to supplement the existing codebook withnew, domain-specific codes. While many existingcodes are adaptable across various contexts whereIH is relevant, the codebook has primarily been de-veloped focusing on religious codes that resonateacross broader domains. For example, the princi-ple of respecting diverse perspectives is crucialfor nurturing constructive dialogue across religiousdivides and serves as a foundation of intellectual hu-mility in wider discussions. Similarly, the conceptof embracing mystery, though initially tailoredfor religious discourse, can be interpreted morebroadly to encompass an appreciation for the un-known in conversationsa fundamental aspect ofintellectual humility that acknowledges the limitsof our knowledge.Addressing the datasets size involves straightfor-wardly increasing the number of expert-annotatedsamples. However, training new experts presentschallenges, given the specialized expertise requiredfor precise annotation. Alternatively, consideringthe high quality of our current labeled data, wepropose using our dataset for validation and utiliz- ing labels generated by LLMs as training samples.This method employs techniques such as few-shotlearning or classifiers fine-tuned with these samplesfor automated labeling. While this approach mayintroduce some noise, the integrity of the dataset ismaintained through the quality of the initial anno-tations. Appendix F displays examples of samplesidentified or generated by LLMs using this method.",
  "Conclusion and Future Work": "This paper introduces a methodology for the auto-mated detection and classification of intellectualhumility and its counterpart, intellectual arrogance,in online religious discourse. Our comprehensivecodebook development and systematic annotationprocess underpins this novel task, providing a ro-bust framework for operationalizing the nuancedmeasurement of these intellectual virtues and vices.Despite achieving significant inter-annotator agree-ment and developing advanced prompting strate-gies, our experiments reveal that current LLMs,including the state-of-the-art GPT-4, fall short ofreplicating human-like discernment in this complexdomain. The findings from this research demonstrate thepotential of LLMs to assist in the proactive en-hancement of online discourse and expose the lim-itations inherent in current technology. These in-sights encourage further academic inquiry and col-laboration to refine these models. Detecting intellectual humility in online dis-course can be practically helpful in several ways.For example, the classifiers we develop may powerfuture technological tools like (Katsaros et al.,2022) and others previously deployed on socialmedia platforms to detect opportunities for discus-sion participants to enhance the IH of their postsand encourage them to do so before posting. Socialmedia platforms or independent developers mightalso design LLM-powered tools that enable par-ticipants to update posts to help others feel moreunderstood, akin to how intellectually humble postsmight function. These applications, some of whichwe describe in the paper, could be pursued furtherthrough field experiments on platforms like Red-dit or with standing panels of social media users.Defining and detecting an amorphous concept likeintellectual humility is a starting point for buildingthese tools and understanding where they need tobe deployed in digital discourse settings.",
  "Limitations": "This research confronts several limitations that un-derscore the challenges inherent in the computa-tional modeling of complex social concepts likeIntellectual Humility and Intellectual Arrogance.Firstly, defining IH and IA through a codebook,a necessary step for operationalization introduces adegree of abstraction from the more nuanced, real-world expressions of these virtues and vices. Ourcodebook captures features indicative of IH and IAwithin online discourse, but these indicators mayonly be approximate correlates of the underlyingintellectual traits. Despite achieving substantialinter-annotator agreement, the variability in thisagreement across different codes reflects the sub-jective nature of these constructs and the difficultyin attaining a universally accepted operational defi-nition.Moreover, the scale of our annotated dataset isanother significant constraint. With only 350 postsevaluated, of which fewer than 200 were codedwith IH or IA labels, our findings are based on arelatively small data pool. This sample size lim-its the generalizability of our conclusions and re-flects the intensive nature of the annotation process,which can be both time-consuming and complex.Quality concerns drove our decision against usingcrowdsourced platforms like Prolific.com to obtainannotations; however, scaling up the dataset willnecessitate finding a balance between data quantityand annotation quality.Lastly, the performance of the LLMs used in thisstudy may have been constrained by the designsof our prompts. Despite careful engineering, theprompts might not have adequately captured thecomplexity needed to elicit accurate discernmentof IH and IA from the models. This limitationwas observed across various model configurationsand might have also impacted the efficacy of theautomatic prompting methods.These limitations highlight the need for ongoingrefinement of both the methodological approachesand the theoretical frameworks used in studies ofthis nature. As we advance our understanding andtechniques, we must continually evaluate and adaptour strategies to better capture the intricate dynam-ics of intellectual virtues in online communication.",
  "Our research is driven by the goal of promotingmore respectful and open-minded discourse online": "However, we recognize that the tools we developfor the scalable detection and measurement of In-tellectual Humility could potentially be misused.There is a risk that these tools might be employedfor censoring speech, enforcing uniformity in dis-course, or other controlling measures that could un-dermine the diversity of perspectives essential for apluralistic society. Such misuse would directly con-tradict our objective of cultivating a broad spectrumof views on social media, a goal that fundamentallyrequires intellectual humility and a readiness toembrace diverse viewpoints.Furthermore, we must consider the inherentlynormative aspect of defining IH. Our codebook andthe annotations it guides are influenced by a spe-cific cultural and philosophical perspective, whichmay not universally capture the essence of IH orits antithesis, Intellectual Arrogance. There is alsoa risk that employing LLMs for automating IHdetection could perpetuate existing biases or cre-ate illusions of understanding, as highlighted byKidd and Birhane (2023) and Messeri and Crockett(2024). Such risks necessitate ongoing vigilance toensure these tools do not simplify or distort com-plex interpersonal traits.As IH classifiers evolve and potentially surpasscurrent baselines, it is essential to continuouslyreflect on and refine what IH entails. Tools likethe ones we introduce in this paper should be useddiagnostically to enhance understanding and fosterintellectual virtues rather than to dictate or limit theexpression of ideas.Ultimately, this project does not claim to offera definitive method for defining or measuring in-tellectual humility. Instead, it aims to initiate thedevelopment of frameworks that can enhance thedetection and, eventually, promotion of intellectualhumility in online discourse settings. By providingthese tools, we hope to support those committedto practicing and promoting intellectual humility,thereby enriching online discourse and contributingto a more thoughtful and tolerant virtual commu-nity.",
  ". Exploring intellectual humility through thelens of artificial intelligence: Top terms, features anda predictive model. Acta Psychologica, 238:103979": "Lisa P. Argyle, Ethan C. Busby, Joshua Gubler, ChrisBail, Thomas Howe, Christopher Rytting, andDavid Wingate. 2023. AI Chat Assistants can Im-prove Conversations about Divisive Topics. arXiv:2302.07268. Christopher Bail, Lisa Argyle, Taylor Brown, JohnBumpus, Haohan Chen, Fallin Hunzaker, JaeminLee, Marcus Mann, Friedolin Merhout, and Alexan-der Volfovsky. 2018. Exposure to opposing viewson social media can increase political polarization.Proceedings of the National Academy of Sciences,115(37):92169221. Shauna M. Bowes, Madeline C. Blanchard, Thomas H.Costello, Alan I. Abramowitz, and Scott O. Lilien-feld. 2020. Intellectual humility and between-partyanimus Implications for affective polarization in twocommunity samples. Journal of Research in Person-ality, 88. Shauna M. Bowes, Thomas H. Costello, Caroline Lee,Stacey McElroy-Heltzel, Don E. Davis, and Scott O.Lilienfeld. 2022. Stepping Outside the Echo Cham-ber: Is Intellectual Humility Associated With LessPolitical Myside Bias? Personality and Social Psy-chology Bulletin, 48(1).",
  "Xiaobo Guo and Soroush Vosoughi. 2024. Serial posi-tion effects of large language models. arXiv preprintarXiv:2406.15981": "Joshua N. Hook, Jennifer E. Farrell, Kathryn A. John-son, Daryl R. Van Tongeren, Don E. Davis, andJamie D. Aten. 2017. Intellectual humility and reli-gious tolerance. The Journal of Positive Psychology,12(1):2935. Shanto Iyengar, Yphtach Lelkes, Matthew Levendusky,Neil Malhotra, and Sean J. Westwood. 2019. TheOrigins and Consequences of Affective Polarizationin the United States.Annual Review of PoliticalScience, 22:129146. Matthew Katsaros, Kathy Yang, and Lauren Fratam-ico. 2022. Reconsidering tweets: Intervening duringtweet creation decreases offensive content. In Inter-national AAAI Conference on Web and Social Media.",
  "Post Title: I am an satrar, I believe in theAesir ; Vanir. AMA": "Content: I am a Pagan, an satrar. I followOdin, Loki, Thor, Freya, Frigg, Tyr, and manyother gods and goddesses. They are calledthe Aesir and Vanir. I have been of this faithfor a little over two years now, converted bymy husband. Before that, I didnt really labelmyself. Ive always known that something isout there, and had moments where I have feltthe Gods presence around me. I believe myGods; Goddesses were once real people, whodid great things. Thus were immortalized inthe ancient Norse \"\"myths\"\". I do not believethe Gods to be omnipotent or anything of thesort, but I do believe they have influence overtheir \"\"aspects\"\". For example, Freya is theGoddess of Fertility(among other things), soif you were to pray to her and build her analtar, she would have the power from Valhallato influence your chances of being fertile orbecoming pregnant. Could also go for if youwere attempting to have a garden, she couldinfluence the fertility and growth of the garden.Please, ask me anything. :)",
  "Auto-Optimization: Adopting techniques from": "Ye et al. (2023), we applied automatic prompt op-timization to GPT-4. For each label, six samplesand the current prompt were given to the modelfor analysis and updating. Over ten rounds, threenew prompts were generated each round; the oneshowing the best performance was selected forsubsequent rounds. This iterative process contin-ued without significant overfitting issues. Self-Refinement: Based on Madaan et al. (2024),this method uses prediction, feedback, and recon-sider cycles to iteratively improve outputs. In-corporating the chain of thought, two rounds ofrefinement were conducted per sample, as addi-tional rounds did not yield further improvements.",
  "{{~/user}}": "where{Post_title},{Post_content},{First_comment},and{Second_comment}arethecontentfromthesamples,{fo-cus_on_second_comment} is a mark to showwhether we analyze the first or second comment,{Focal_comment} is the content of the analyzedcomment, and the {Label} is the label to ask. C.2Prompts for Different Boost MethodsC.2.1Prompts for Few-shot and CotIn this section, we list all the prompts for the boostmethods used in our paper. All the prompts arecreated based on the Coda-and-Description setting",
  "where {System_Prompt} is the one designed inthe Appendix C.1, {Curr_Prompt} is the currentoptimized prompt which will be the user_promptdesigned in the Appendix C.1, {Examples} are a": "list of 6 samples with 3 positive and 3 negativethe same as CoT, {history_performance} is a listof historical optimizing summary and the corre-sponding performance, {Analysis} is the analy-sis from the LLMs for the current prompt, andthe {change_summary} is a brief summary of thechanges for this iteration generated by the LLM. C.2.3Prompts for the Self-RefinementFor the Self-Refinement, we adjusted the previousprompts. Here are the prompts we use to guide themodels in generating feedback.For the task of IH/IA/Neutral, we have:",
  "C.3Optimized Prompt": "In figure C1, we show the original and the opti-mized prompts for the code Recognizes limita-tions in ones own knowledge or beliefs. As wecan observe, compared with the original prompt, itincludes much more data for guiding the model toemphasize on certain situations. This will increasethe performance on certain samples while it willalso decrease the performance when the samplesare very different since it might guide the modelwrongly.",
  "Analysis of Table D3 reveals that Claude-3 andGemini-1.0-pro underperform compared to GPT-4,": "likely due to the prompts being specifically opti-mized for GPT-4. Moreover, while CoT generallyboosts the IH/IA/Neutral task performance forthese models, it tends to diminish efficacy acrossother coding tasks. This behavior is also differentfrom what we observed in the GPT-4 model. Weare not sure what the cause of this observation is,but it also might be because of the prompt design.",
  "BaselineDistribution0.470.510.520.480.490.490.49Upper boundMutual0.870.780.890.860.750.830.83": "Table D2: Performance metrics for IH and IA labels across various prompt designs. The table presents mean scoresfor all Intellectual Humility (IH) and Intellectual Arrogance (IA) labels, labeled as IH Mean and IA Meanrespectively. The best performance for each label is highlighted in bold, while the second best is underlined",
  "Table D3: The performance of Gemini-1.0 and Claude-3 with the settings C&D-BQ with/without chain ofthoughts": "Loki. The commenter openly admits their lim-ited knowledge, which is based only on whatthey have read on Wikipedia and basic storiesthey have heard. This admission of limitedknowledge and the phrasing of the questionin a non-confrontational manner indicates agenuine curiosity and a respectful approachto learning more about someone elses beliefs.The commenters approach is mindful of oth-ers feelings in several ways: 1. **Acknowl-edgment of Limited Knowledge**: By statingtheir limited understanding, the commentershows respect for the complexity and depthof the satrar faith, implying that they donot wish to make assumptions or judgmentsbased on incomplete information. 2. **Open-ness to Learning**: The question is framedin a way that invites explanation and dialogue",
  "Table D4: The performance of different boost methods as well as the one without any boost method": "rather than challenging or dismissing the be-liefs being discussed. 3. **Respectful Cu-riosity**: The specific inquiry about Loki, afigure who might be controversial or misun-derstood due to his portrayal in popular me-dia and mythology, is asked in a manner thatseeks to understand the religious and culturalsignificance rather than perpetuate stereotypes.Given these considerations, the target text canbe described as \"Mindful of others feelings\"because it demonstrates a respectful and open-minded approach to discussing religious be-liefs that are different from ones own. There-fore, the answer is **Yes**. Description-Only:\"The Target Text is aquestion from a commenter asking about thepurpose of invoking or praying to Loki, a fig-ure in the satrar faith. The commenter alsomentions their limited knowledge of satrar,indicating they are seeking information or clar-ification. This text does not explicitly or im-plicitly consider how religious discussions oractions might affect others emotionally. In-stead, it focuses on gaining understanding orinformation about a specific practice within areligion. There is no mention or implication ofemotional impacts on others due to religiousdiscussions or actions. Therefore, the answeris No.\"",
  "Code-and-Description Reason: The TargetText is a comment asking a question about the": "satrar religion, specifically about the pur-pose of invoking or praying to Loki. The com-menter acknowledges their limited knowledgeabout the religion, indicating a willingness tolearn and understand more. However, thereis no explicit or implicit consideration of howreligious discussions or actions might affectothers emotionally. The commenter is simplyseeking information. No By comparing these generated texts, we observethat the code-only approach wrongly labels thetext as it interprets Mindful of others feelingsas a respectful and open-minded approach to dis-cussing. The main issue is that the model gener-ates a definition for the code based on its learnedknowledge, which may not align with a general orexpert understanding of the code. This highlightsthe importance of providing clear descriptions ofthe codes.",
  "E.2Chain of Thoughts Example": "In Figure E2, we display two samples generatedby GPT-4-turbo-2024-04-09 using the Chain ofThought settings. We can observe that for bothsamples, the model first outlines what the text cov-ers and then compares it with the definition of thecode. In the first sample, it correctly understandsthat the subject is seeking new information. How-ever, in the second sample, the model mistakenlyinterprets the afterline as something beyond fullcomprehension, ignoring that this knowledge ispossessed by the model itself, not the speaker. This",
  "Post Title: Exploring the Concept of Divinityin Different Religions": "Content: Ive always been fascinated by thevaried concepts of divinity across the worldsreligions. From the monotheism of Christian-ity and Islam to the polytheism of Hinduismand the non-theistic approaches of Buddhism,each tradition offers a unique perspective on what it means to be divine. Im particularlyintrigued by how these beliefs shape the moraland spiritual lives of their followers. For in-stance, the belief in a singular, omniscientGod in Abrahamic traditions can provide asense of universal order and purpose, whilethe myriad gods of Hinduism reflect the com-plexity and diversity of life itself. Buddhismsfocus on enlightenment through self-effortand meditation offers a different approach,one that does not center around a divine figurebut on the potential for divinity within eachperson. Id love to learn more about theseideas and hear how others perceive and in-teract with the divine in their own religiouspractices. Target Comment: As someone who has stud-ied comparative religion, I find the diversityof divine concepts fascinating as well. How-ever, I must admit that my understanding ofeach religions view of divinity is still quitelimited. I recognize that even within a sin-gle religious tradition, there are often multipleinterpretations and practices.",
  "Post Title: How Does Hinduism AddressModern Ethical Dilemmas?": "Content: Hinduism, with its rich tapestry ofphilosophies and teachings, offers unique per-spectives on modern ethical dilemmas suchas genetic modification, artificial intelligence,and global warming. The concepts of Dharma(duty/righteousness) and Karma (action andconsequence) can provide guiding principlesfor believers. For example, the principle ofahimsa (non-violence) might influence how aHindu approaches environmental issues. Imcurious to see how other members of this fo-rum think Hinduism can contribute to discus-sions on these pressing global challenges. Target Comment: You clearly dont get theessence of Hinduism at all. Just another out-sider trying to critique without understand-ing. Stick to topics you know, maybe moderntechnology or something, not deep religiousphilosophies that require actual spiritual in-sight to discuss.",
  "Post Title: Vegan Diets are Divine Mandate": "Content: Ive been a vegan for five yearsnow, and I truly believe that adopting a ve-gan diet is a divine command to all humanity.The world would be a much more compas-sionate and peaceful place if we all stoppedconsuming animal products. The evidence canbe seen in many religious texts that highlightcompassion, though they may not expresslymention veganism. It just makes sense that akind and benevolent deity would prefer us toavoid causing harm to other living beings.",
  "Target Comment: Absolutely, Ive read someobscure texts suggesting ancient societieswere strictly vegan, and thats where they drewtheir power from. Modern science just hasntcaught up yet to prove it": "We can observe that GPT-4 can generate bothIH and IA labels about general religion topics andcontent specific to one religion. Even with thelabel with not good performance (UnsupportedClaim with an F1 score of 0.44), the generatedtext can still be regarded as Unsupported Claim.This suggests that we can rely on LLMs such asGPT-4 to automatically generate samples based onthe annotated data. We also observe that, if notspecifically required; the LLM prefers generating",
  "Content: Why are people who are Saved-by-Grace afraid to die? Fear of the unknown.Faith doesnt always equate to complete be-lief": "Target Comment: I have thought about this,and I can only speak for myself. Its the un-known. Is death going to be painful, what isthe experience of passing on going to be like,also eternity itself is an overwhelming concepteven if it was in regards to something that Ido know and understand. Self-doubt is alsoalways going to be a little present, and in theface of something like death and eternity, thatdoubt is exponentially magnified."
}