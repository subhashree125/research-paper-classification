{
  "Abstract": "Despite the remarkable progress made by largelanguage models in mathematical reasoning, in-teractive theorem proving in formal logic stillremains a prominent challenge. Previous meth-ods resort to neural models for proofstep gen-eration and search. However, they suffer fromexploring possible proofsteps empirically ina large search space. Besides, they directlyuse a less rigorous informal proof for proof-step generation, neglecting the incomplete rea-soning within. In this paper, we propose BC-Prover, a backward chaining framework guidedby pseudo steps. Specifically, BC-Prover pri-oritizes pseudo steps to proofstep generation.The pseudo steps boost the proof constructionin two aspects: (1) Backward Chaining thatdecomposes the proof into sub-goals for goal-oriented exploration. (2) Step Planning thatmakes a fine-grained planning to bridge thegap between informal and formal proofs. Ex-periments on the miniF2F benchmark show sig-nificant performance gains by our frameworkover the state-of-the-art approaches. Our frame-work is also compatible with existing proversand further improves their performance withthe backward chaining technique.",
  "Introduction": "Recent years have seen a surge of interest in math-ematical reasoning tasks, such as premise selec-tion (Mikula et al., 2023), autoformalization (Zhouet al., 2024a; Wu et al., 2022) and automated theo-rem proving (Wang et al., 2023b; Azerbayev et al.,2023). Automated theorem proving poses a signif-icant challenge, as it requires the prover to gener-ate validated formal proofs fully automatically ina prohibitively large search space (Lample et al.,2022; Trinh et al., 2024). Therefore, interactivetheorem proving (ITP) has emerged as an alterna-tive method for automating theorem proving. ITP",
  "proof goal with existing hypotheses. The have tacticsuccessfully proves h3 reversely by observing the goal.It corresponds to the color sentence in the informalproof": "typically involves prover writing steps to interactwith proof assistants like Isabelle (Nipkow et al.,2002) and Lean (de Moura et al., 2015). Sucha process highlights understanding of hypothesesand efficient search strategies to reach the proofgoal (Zhang et al., 2023). Besides its huge poten-tial to accelerate research in mathematics, ITP hasdemonstrated excellent application value in codegeneration (Polu et al., 2023), synthetic theoremgeneration (Lin et al., 2024; Huang et al., 2024)and proof refactoring (Zhou et al., 2024b).",
  "As Lean becomes prevalent due to its superior-ity in interactive mathematical expression, a lineof work has explored using language models forprogrammatically interacting with Lean (Yeh et al.,": "2023; Brandfonbrener et al., 2024; Welleck andSaha, 2023). In this paper, we also focus on ITPwith Lean. Generally, the ITP task aims at con-structing a proof (a sequence of tactics) of a proofstate (transformed from a theorem statement) asillustrated in . Tactics are proofsteps forupdating the proof state. They must be strictly ver-ified by the proof assistant and utilize hypothesesto achieve the proof goal. Unlike conventional pro-gram languages, formal proof language adheres torigorous mathematical logic, leaving no room forhallucination (Ji et al., 2023). Therefore, the ITPtask presents a significant challenge for LLMs. Existing research on ITP mainly falls into twoparadigms: task-specific finetuning and prompt-ing. Task-specific finetuning methods have shownexceptional performance (Han et al., 2022; Wanget al., 2023b). They rely on prohibitive trainingcosts on private datasets, making it impractical inreal scenarios without open-source code or models(Polu et al., 2023; Lample et al., 2022). Promptingmethods, on the other hand, have already provento be a powerful copilot in real-world applica-tions (Song et al., 2024). They explore the in-context learning ability of LLMs to infer proofsteps(Thakur et al., 2024; Ying et al., 2024). Our methodis also based on the prompting paradigm. To produce more reliable tactics, most prompt-ing methods involve informal proofs prior to proofconstruction (Jiang et al., 2023). The informalproofs are solutions in natural language as shownin : Proof Construction. However, directlyapplying the informal proofs as in-context exam-ples can mislead the LLMs, as there are gaps be-tween formal and informal proofs. Specifically,informal proofs are often less rigorous and tendto skip steps, making them less reliable. To thebest of our knowledge, both prompting and finetun-ing methods focus on generating forward-chainingtactics, ignoring the backward-chaining strategy.Backward chaining is an inference method de-scribed colloquially as working backward from thegoal (Huang and Chang, 2023). Ignoring backwardchaining could trap the exploration of proofsteps.As shown in : Interaction at S0, in orderto prove the goal, a hypothesis h3 should be provedfirst instead of using existing hypotheses.",
  "In order to alleviate the above problems, we pro-pose BC-Prover, a framework to operate backward-chaining for ITP in Lean. Specifically, given atheorem and its informal statement, our framework": "first derives an informal proof and pseudo steps.Pseudo steps are specific proof steps further elab-orated based on the informal proof, aimed at pro-viding a reference for the formal proof. Duringproof construction, vanilla provers proposed in pre-vious works generate forward-chaining tactics tointeract with Lean(Han et al., 2022; Yang et al.,2023). Instead, inspired by literature in logic rea-soning (Poole and Mackworth, 2010), our approachperforms (1) backward chaining: drawing auxil-iary hypotheses about the internal reasoning. Asthe pseudo steps indicate intermediate steps towardthe goal, we employ LLMs to recursively discoverprovable sub-goals for ultimate proof-finding. Toavoid producing misleading steps, our approachperforms (2) step planning: planning the nextproofstep conditioned on the current state. Addi-tionally, it augments the next proofstep with re-trieval lemmas and plans similar to Yang et al.(2023). Experiments show that BC-Prover achievesa higher pass rate on the miniF2F benchmark com-pared with several SOTA baselines. BC-Prover canalso collaborate with finetuned models to obtainsubstantial improvement.We summarize our contributions as follows:",
  "Formal Theorem Proving": "Early approaches search proofs in first-order logicautomatically (Robinson and Voronkov, 2001;Kovcs and Voronkov, 2013). However, the in-herent vast search space often limits their practical-ity in higher-order mathematical problems (Bridgeet al., 2014). Later works on theorem proving havethereby focused on ITP paradigm.With the remarkable achievements of genera-tive models in recent years, task-specific finetuningmodels are widely used for ITP (Sanchez-Sternet al., 2020; Polu and Sutskever, 2020a). Yang et al. (2023) implements a retrieval-augmented languagemodel to search appropriate lemmas for tactic gen-eration. Welleck and Saha (2023) makes furtherimprovement by scaling the language model. Re-cent researches also explore advanced LLMs withsophisticated prompting methods (Poulsen et al.,2024; Yousefzadeh and Cao, 2023). Jiang et al.(2022) integrates LLM and Sledgehammer, a pow-erful automated prover in Isabelle, for theoremproving. First et al. (2023) investigates LLM forrepairing the whole proof after interaction withthe proof assistant. Similarly, Thakur et al. (2024)repeatedly corrects proofsteps from assistant feed-back. These previous approaches begin with estab-lished hypotheses and keep applying tactics in aforward-chaining fashion until the goal is reached.We integrate a backward-chaining strategy to un-cover possible facts for proving the goal.",
  "Proof Autoformulation": "The goal of proof autoformalization is to convert in-formal theorems and proofs into machine-verifiableformats. It has been studied since the early stageof neural models (Kaliszyk et al., 2014). In theera of LLMs, proof autoformulation demonstratesits value in automated theorem proving by trans-lating mathematical statements in natural languageinto formal proofs (Wang et al., 2020; Wu et al.,2022; Zhao et al., 2023). It promises to facilitatethe verification of mathematical papers (Szegedy,2020). Jiang et al. (2023) introduces a draft-sketch-prove pipeline to formulate informal proof auto-matically. Subsequent research builds dynamiclemma libraries and achieved substantial improve-ment (Wang et al., 2023a). Thakur et al. (2024)guides the next tactic generation with informalproof in ITP but only yields a little increment.Despite their contributions, none of the aforemen-tioned methods have investigated pseudo steps asintermediate results toward final proof, nor do theyformulate backward-chaining steps in the ITP task.",
  "Proofstep Generation and Search": "Combining language models for proofstep genera-tion and heuristic algorithms for proofstep searchhas been the key to ITP. A thread of researchtrains a language model and simply adopts best-first-search (Polu and Sutskever, 2020a; Wellecket al., 2022; Polu et al., 2023; Zheng et al., 2023;Jiang et al., 2021). Subsequent advancements fo-cus on deriving more efficient search strategies likeMCTS (Lample et al., 2022). Wang et al. (2023b) adjusts search steps to accommodate proof statecomplexity, mirroring human reasoning over theentire proof trajectory. Besides, some studies trainLLMs on extensive general mathematical corporaand build strong LLM agents for proofstep gener-ation (Shao et al., 2024; Azerbayev et al., 2023;Rozire et al., 2023). These studies are highly rel-evant to our work, as our goal is to build an LLMagent that uses backward chaining to reduce thesearch space of forward chaining.",
  "Methodology": "A problem statement consists of a theorem state-ment Xt and its informal statement Xh. Xt willbe transformed into an initial proof state S0 ={h1, ..., hl, g1, ..., gm} that holds l hypotheses hand m goals g. A problem example is illustratedin : Problem Example. The ITP task canbe formulated as follows: given Xt, Xh and S0,a prover needs to generate tactics iteratively toconstruct a proof. In each iteration, the proversearches for tactics to update the state. The itera-tions \"S0 S1 \" finish until all goals areaccomplished or the search ends.",
  "Basic Prover": "In general, a basic prover is composed of a proof-step generator and a proofstep search mechanism.The proofstep generator iteratively generates tac-tics based on the proof state. The proofstep searchmechanism controls the overall search process,maintaining states and selecting tactics duringproof construction.Proofstep Generator.Following Polu andSutskever (2020b), we use a decoder-only languagemodel LM as the proofstep generator. The genera-tor takes a proof state Si and generates k tactics:",
  "{t0i , ..., tki } = LM(Si)(1)": "Formally, the above process is defined as forwardchaining.Proofstep Search. The goal of the proofstepsearch is to build a proof tree that incrementallyevolves the state through tactic invocations. Start-ing from the initial state S0, the prover expandsproof states by executing tactics in each iteration.The intermediate states are maintained in a priorityqueue and expanded based on the cumulative logprobability. The cumulative log probability is thesummation of the log probabilities of tactics that",
  "BC-Prover": "Upon the basic prover, we propose our BC-Proverframework, as shown in . BC-Prover firstsketches an informal proof and pseudo steps forthe input mathematical problem. Subsequently,BC-Prover engages in proof construction throughiterative processes. In each iteration, the backwardchaining mechanism utilizes the LLMs reasoningability to discover goal-driven hypotheses. Thestep planning module derives next-step planningconditioned on the current state. Additionally, BC-Prover retrieves potentially useful lemmas with thehelp of a retriever and a re-ranking agent. Finally,the proof state is augmented with the aforemen-tioned information for tactic generation.Pseudo Steps Generation. BC-Prover proceedspseudo steps generation before proof construction.It formalizes the input problem following recentadvances in proof autoformulation (Jiang et al.,2023). Accordingly, the problem is mapped into an",
  "M : (Xt, Xh, Ph) Ps(4)": "where M is parameterized by LLM, indicatesprompting and parsing procedure to generate thedesired results1. Ph and Ps denote informal proofand pseudo steps respectively. Pseudo steps aremore structured, filling up steps that require explicitproving but are taken for granted in informal proof.In the following, BC-Prover conducts proof con-struction. It is guided by the pseudo steps andupdates the proof state iteratively. The iterationsend when the goals are achieved or the search isfinished.Backward Chaining. Backward chaining startsfrom the goal and recursively breaks it into sub-goals, which should be asserted as facts for goalachievement (Al-Ajlan, 2015). Analogously, BC-Prover performs backward chaining in each itera-tion to establish provable hypotheses. The informalproof briefly outlines the proof path. The pseudosteps decompose it into commented proofsteps. Aspseudo steps declare necessary sub-goals, our back-ward chaining is guided by it to establish d sub-goals gsub and corresponding tactics tsub, usingLLMs reasoning ability:",
  "Si = [Si, Hg](7)": "where [] is the augmentation operation.Step Planning. Step Planning augments thecurrent state with step-level planning to bridge thegap between informal and formal proofs. Since theproof state involves obscure mathematical notions,we annotate the proof state with a description D.Then an LLM reasons out a next-step planningunder the current state. The whole procedure isaccomplished by prompting M, denoting as:",
  "M : (D, Si , Ps) N(9)": "where Si , Ps, and N are the state, pseudo steps,and planning of the next proofstep respectively.The planning gives instructions on the effectivetactics to progress the current state.Following LeanDojo (Yang et al., 2023), we em-ploy its premise retriever to query a set of lemmasLr from mathlib2. Afterward, an LLM re-rankingagent selects n lemmas and summarizes plans fortheir use in the next proofstep (Sun et al., 2023):",
  "Mathlib is a user maintained library for the Lean. Itcontains a large amount of lemmas for theorem proving": "The best-first search is impractical since the logprobability is inaccessible by calling LLMs API.Inspired by DT-Solver (Wang et al., 2023b), wealternatively select proofsteps based on state com-plexity. Specifically, the current proof state is ex-panded with tactic tj that leads to the simplest Sj.The simplicity of Sj is measured by the number oftokens. The selected tactic is to interact with Leanas described in Equation 2.The basic prover searches exhaustively in a for-ward chaining manner. Our framework, in eachiteration, recursively establishes goal-driven hy-potheses. Hence, our proofstep search mechanismis actually a bidirectional search, which reduces thesearch space with backward chaining.",
  "Experiment Setup": "In this section, we introduce the experiment setupfor BC-Prover. Following Polu et al. (2023), weevaluate BC-Prover in Lean. More experimentaldetails and hyperparameters are in Appendix A.Baselines.Baselines of two paradigms arecompared, encompassing the state-of-the-art ITPprovers in Lean.(1) Task-specific finetuning. PACT (Han et al., 2022) co-trains the GPT-f model with nine auxiliarytasks. Expert Iteration (Polu et al., 2023) trains thelanguage model by self-synthetic data from proofsearches. ReProver (Yang et al., 2023) proposesa premise-augmented model for theorem proving.LLMStep (Welleck and Saha, 2023) scales themodel of ReProver without premise retrieving.(2) Prompting.CodeLama (Rozire et al., 2023),Deepseek-Math (Shao et al., 2024),LLEMMA (Azerbayev et al., 2023) are LLMstrained on various large-scale mathematical corpuswith reinforcement learning technique. We choosetheir 7B version because 7B models perform thebest in their reports. Copra (Thakur et al., 2024)devises a GPT-4-based agent to search and correcttactics from the assistants feedback. GPT-4 base-line is implemented with gpt-4-turbo-2024-04-09 version under few-shot settings like LLEMMA.Note that we exclude some baselines that are in-feasible to compare with (details in Appendix A.2).For example, approaches across different proof as-sistants are not comparable because of differentexperiment settings.Implementation details. In this paper, the LLMis instantiated to be gpt-4-turbo-2024-04 -09.In each iteration, BC-Prover generates k = 16",
  "BC-Prover1629.5%30.7%BC-ReProver1632.0%31.6%BC-LLMStep1635.2%32.0%BC-Prover1638.9%36.9%": ": Pass@1 results on the miniF2F benchmark. BC-Prover denotes the cumulative pass rate of the miniF2Fdataset, considering the total number of problems solved using our framework. API cost of our framework is shownin Appendix B. tactics and d = 8 sub-goals. We set n = 5 forlemma re-ranking. The temperature is set as 0 inprompting the LLM. We adapt the basic proversinto our framework by only augmenting the currentstate with goal-driven hypotheses. They implementbest-first search. More implementation details canbe found in Appendix A.3.Theorem Proving Experimental Setup. In ITPtask, we adopt the miniF2F benchmark (Zhenget al., 2022) for comparison with other works. Thisbenchmark contains two split datasets: miniF2F-valid and miniF2F-test, which includes total 488theorems sourced from Olympiad mathematicalproblems (AIME, AMC, and IMO) as well as high-school and undergraduate math classes. We followprevious works (Lample et al., 2022) and evaluateon these two splits. We primarily use Lean 3 as theproof assistant. We evaluate the performance usingPass@1 metric: the prover has only one attemptand must find the proof within 100 iterations.",
  "Main Result": "We present the performance of our framework un-der two different settings. shows the over-all performance of the baselines and our proposedmodel.BC-Prover Settings. We compare BC-Proverwith task-specific finetuning and prompting base- lines. Overall, BC-Prover achieves better perfor-mance with smaller search-k. Our framework sig-nificantly improves over the GPT-4 by at least6.5% and 7.3% on the miniF2F-valid and miniF2F-test, respectively. BC-Prover outperforms anotherGPT-4-based Copra with lower search-k on the setand surpasses LLMs of mathematics domains by10.2% at most. It hints that backward chaining andstep planning are important to guide LLMs to pro-duce accurate tactics. Furthermore, task-specificfinetuning methods thoroughly explore the searchspace with 64 search-k while BC-Prover achievesa higher pass rate with 16 search-k. We think it ismainly due to the backward chaining mechanism asanalyzed in .3. In conclusion, BC-Proverpresents competitive performance compared withSOTA baselines on the miniF2F benchmark. Collaborative Settings. Our framework is plug-and-play with task-specific finetuning models. Un-der collaborative settings, we employ ReProver andLLMStep in Equation 11 to generate tactics. Thecollaborative models are denoted as BC-ReProverand BC-LLMStep. For a fair comparison with BC-Prover, both BC-ReProver and BC-LLMStep areconstrained to only generate 16 tactics. It can beobserved that collaborative models performs betterthan BC-Prover. The possible reason behind thisis that LLMs are not particularly trained on Lean.Also, the Lean-related data is scarce and hard to ac-",
  ": The number of tactics in the constructed proofs. There is an obvious increase in the number of backwardchaining tactics after applying our framework": "cess publicly (Han et al., 2022). Besides, both Re-Prover and LLMStep achieve substantial improve-ment in collaboration with our framework. On theminiF2F-valid, backward chaining can bring abouta 9.0% increase for LLMStep and about 8.2% in-crease for ReProver. It is worth noting that thecollaborative models can reach the final goal with4 times less search-k. We argue that backwardchaining effectively introduces intermediate goalsto narrow the search paths for forward chaining.In line with prior works (Lample et al., 2022),BC-Prover adds up the number of theorems solvedwith our framework. In total, our framework suc-cessfully carries out 38.9% (95/255) problems onthe valid split and 36.9% (90/244) on the test split.The collaboration of our framework and finetuningmodels is able to discover more new proofs than theoriginal BC-Prover. More experiments and resultsrefer to Appendix D",
  ": Ablation Study. Pass@1 results on the miniF2F": "We remove backward chaining (w/o BC) andstep planning (w/o SP) respectively to reveal theeffect of each module in our model. The Pass@1 ofthe miniF2F benchmark is reported in . Allof our proposed modules can bring performance im-provements. In particular, applying the BC to ourframework contributes about 4.1% and 5.7% passrate on valid set and test set, respectively, show-ing the effectiveness of our proposed BC in proof-finding. Also, it can be observed that removing SP also leads to a drop in performance. One big fac-tor is that SP gives comprehensive suggestions onwhat to do next and how to achieve with extra lem-mas, and removing it may exponentially enlargethe forward-searching space.",
  "Forward vs. Backward Chaining": "Forward chaining tactics are machine-validatedproofsteps generated by the proofstep generator,while backward chaining tactics (tsub) are proof-steps that draw goal-driven hypotheses for proofconstruction. To validate the effectiveness of back-ward chaining, we measure the changes of types oftactics after implementing our framework on thebaseline models. From the results in , itcan be seen that none of the baseline models is ableto iteratively decompose the proof goal and cre-ate helpful hypotheses, thus limiting their abilityto search forward. Also, the number of forwardchaining tactics indeed increases with the help ofour framework. To be specific, LLMStep generates84 more forward proofsteps with 118 backwardchaining tactics. ReProver, likewise, finds 62 moretactics during proofstep generation. Our LLM-based BC-Prover searches for sug-goals in eachiteration, resulting in about 132 useful hypotheses.The above results suggest that backward chainingcan steer the search in the correct direction.",
  "BC-Prover Output:": "01 theorem mathd_algebra_20902 ( : equiv )03 (h : .inv_fun 2 = 10)04 (h : .inv_fun 10 = 1)05 (h : .inv_fun 1 = 2) :06 .to_fun (.to_fun 10) = 1 :=07 begin08 have f_10eq2: .to_fun 10 = 2, 09 by {rw h, exact .right_inv 2},10 have f_2eq1: .to_fun 2 = 1, 11 by {rw h, exact .right_inv 1},12 have f_f10eqf2: 13 .to_fun (.to_fun 10) = .to_fun 2,14 by {rw f_10eq2},15 have id_apply_10_eq_10: id 10 = 10, 16 by {refl},17 have f_f10eq1: 18 .to_fun (.to_fun 10) = 1, 19 by {rw [f_f10eqf2, f_2eq1]},20 exact f_f10eq1,21 end",
  "17": ": Example outputs and search trees of \"theorem mathd_algebra_209\". The node is annotated with the linenumber of the outputs. Left: GPT-4 reaches the end of the search and fails to solve the goal. Right: BC-Proverreaches the goal with backward chaining, where the dash lines denote the backward chaining route. We highlightthe proofsteps of forward chaining: 01-07-08-09-10-11-12 (left) and 01-07-17-20-21 (right). To better demonstrate why our proposed frame-work works, we carry out an analysis of the searchefficiency. We compute several metrics from theproof results as shown in . During the proof-steps construction, the prover tries to find the cor-rect path in the search tree. Avg.P reflects howdeep it reaches in the tree. GPT-4 uses up to 61iterations with 2.07 Avg.P, which means GPT-4spends most of its efforts in exploring proof paths.Our BC-Prover is lower in Avg.P, Avg.I and Max.I,showing that it can finish searching in 1.80 proof-steps on average and find the correction directionwithin fewer iterations. In conclusion, BC-Proverexhibits higher search efficiency by incorporatingsteps planning and backward chaining.",
  "Case Study": "In this section, we present a theorem example thatis successfully solved by our framework in Fig-ure 4. More examples are shown in AppendixE. The trees beside the proof are the proof treesin proof constructions. We compare proof fromGPT-4 and our BC-Prover. The theorem states thesame problem as in , where our goal is.to_fun(.to_fun 10) = 1.From left, we can see GPT-4 triesto rewrite the existing hypotheses.For ex-ample,line 09 rewrites the h1 into h1:.inv_fun(.inv_fun 10) = .inv_fun 1. Thetransformation makes h1 look like the goal but ac-tually does not drive the search towards the goal. After the tactic in line 11, GPT-4 can not produceany new tactic to update the state. Such a search ispurely forward chaining and ends up unsuccessfulin 25 iterations (25 nodes in total). In right,BC-Prover is guided by pseudo steps and iterativelyestablished sub-goals and tactics. For example, line08 states a sub-goal .to_fun 10 = 2 and tacticrw h0, exact .right_inv 2. Line 08-09 isvalidated by the Lean and introduce a new hypoth-esis .to_fun 10 = 2, which is later used in line12-14. The backward chaining makes the searchdirectly find a fowrad path (01-07-17) close to thefinal goal. By applying line 20, BC-Prover accom-plished the proof with less iteration and proofsteps.We find that the new hypothesis introduced in Line15 is useless in proving the goal. Similar hypothe-ses can also be found in other cases as analyzedin Appendix C. How to avoid generating these hy-potheses to improve backward chaining is left forfuture work.",
  "Conclusion": "In this work, we propose a novel framework, BC-Prover. At the beginning, BC-Prover generatespseudo steps for constructing proofs. During proofconstruction, BC-Prover operates backward chain-ing and step planning to construct proofs in formallogic. The backward chaining searches for proof-step in a goal-driven manner. The step planningmakes a detailed planning for each proofstep to in-voke more accurate tactics. The experiment results",
  "Limitations": "Unlike informal natural language, formal theoremsin Lean are rigorous with lots of notions in mathe-matical language. Although our framework mini-mizes the gap between informal and formal lan-guage, general LLMs are still prone to predicttactics with grammar errors. Unfortunately, BC-Prover outperforms several baselines but fails tosolve IMO-level Olympiad problems. Future re-search could explore devising an LLM agent in theLean domain to alleviate these problems. Duringthe proof construction, the pseudo steps are notupdated as the proof goes on. BC-Prover relieson the self-correction ability of LLM to adjust theproofstep, which could be a weakness for proofconstruction. The step planning module producescomplex instructions. Therefore, it cannot be ap-plied to task-specific fine-tuning models and maydegrade LLMs of a small scale (e.g., 7B). We onlyuse ReProver and LLMStep to collaborate with ourframework. Consequently, for future research, weaim to evaluate with more finetuning models toverify the effectiveness of the backward chainingtechnique.",
  "Ethics Statement": "We adhere strictly to the licenses and policies ofLLMs and publicly available datasets. We followthe usage policy of OpenAI for constructing math-ematical proofs and generate no harmful content.The dataset contains mathematical theorems in for-mal logic and does not involve any ethical prob-lems. This work was supported by Damo Academythrough Damo Academy Research Intern Program.This work was partially supported by the NationalNatural Science Foundation of China 62176076,NaturalScienceFoundationofGuangDong2023A1515012922, the Shenzhen FoundationalResearch Funding JCYJ20220818102415032, theMajor Key Project of PCL2021A06, GuangdongProvincial Key Laboratory of Novel Security Intel-ligence Technologies 2022B1212010005.",
  "Ajlan Al-Ajlan. 2015. The comparison between forwardand backward chaining. International Journal ofMachine Learning and Computing, 5(2):106": "Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster,Marco Dos Santos, Stephen McAleer, Albert Q.Jiang, Jia Deng, Stella Biderman, and Sean Welleck.2023. Llemma: An open language model for mathe-matics. CoRR, abs/2310.10631. Haniel Barbosa, Clark W. Barrett, Martin Brain, GereonKremer, Hanna Lachnitt, Makai Mann, AbdalrhmanMohamed, Mudathir Mohamed, Aina Niemetz, An-dres Ntzli, Alex Ozdemir, Mathias Preiner, AndrewReynolds, Ying Sheng, Cesare Tinelli, and Yoni Zo-har. 2022. cvc5: A versatile and industrial-strengthSMT solver. In Tools and Algorithms for the Con-struction and Analysis of Systems - 28th InternationalConference, TACAS 2022, Held as Part of the Euro-pean Joint Conferences on Theory and Practice ofSoftware, ETAPS 2022, Munich, Germany, April 2-7,2022, Proceedings, Part I, volume 13243 of LectureNotes in Computer Science, pages 415442. Springer. David Brandfonbrener,Sibi Raja,Tarun Prasad,Chloe Loughridge, Jianang Yang, Simon Henniger,William E. Byrd, Robert Zinkov, and Nada Amin.2024. Verified multi-step synthesis using large lan-guage models and monte carlo tree search. CoRR,abs/2402.08147.",
  "James P. Bridge, Sean B. Holden, and Lawrence C. Paul-son. 2014. Machine learning for first-order theoremproving - learning to select a good heuristic. J. Autom.Reason., 53(2):141172": "Leonardo Mendona de Moura and Nikolaj S. Bjrner.2008. Z3: an efficient SMT solver. In Tools andAlgorithms for the Construction and Analysis of Sys-tems, 14th International Conference, TACAS 2008,Held as Part of the Joint European Conferences onTheory and Practice of Software, ETAPS 2008, Bu-dapest, Hungary, March 29-April 6, 2008. Proceed-ings, volume 4963 of Lecture Notes in ComputerScience, pages 337340. Springer. Leonardo Mendona de Moura, Soonho Kong, JeremyAvigad, Floris van Doorn, and Jakob von Raumer.2015. The lean theorem prover (system description).In Automated Deduction - CADE-25 - 25th Interna-tional Conference on Automated Deduction, Berlin,Germany, August 1-7, 2015, Proceedings, volume9195 of Lecture Notes in Computer Science, pages378388. Springer. Emily First, Markus N. Rabe, Talia Ringer, and YuriyBrun. 2023. Baldur: Whole-proof generation andrepair with large language models. In Proceedings ofthe 31st ACM Joint European Software EngineeringConference and Symposium on the Foundations ofSoftware Engineering, ESEC/FSE 2023, San Fran-cisco, CA, USA, December 3-9, 2023, pages 12291241. ACM. Jesse Michael Han, Jason Rute, Yuhuai Wu, Edward W.Ayers, and Stanislas Polu. 2022. Proof artifact co-training for theorem proving with language models.In The Tenth International Conference on LearningRepresentations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net. Jie Huang and Kevin Chen-Chuan Chang. 2023. To-wards reasoning in large language models: A survey.In Findings of the Association for ComputationalLinguistics: ACL 2023, Toronto, Canada, July 9-14,2023, pages 10491065. Association for Computa-tional Linguistics. Yinya Huang, Xiaohan Lin, Zhengying Liu, QingxingCao, Huajian Xin, Haiming Wang, Zhenguo Li, LinqiSong, and Xiaodan Liang. 2024. MUSTARD: mas-tering uniform synthesis of theorem and proof data.CoRR, abs/2402.08957. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu,Dan Su, Yan Xu, Etsuko Ishii, Yejin Bang, AndreaMadotto, and Pascale Fung. 2023. Survey of halluci-nation in natural language generation. ACM Comput.Surv., 55(12):248:1248:38.",
  "Albert Qiaochu Jiang, Wenda Li, Jesse Michael Han,and Yuhuai Wu. 2021. Lisa: Language models ofisabelle proofs. In 6th Conference on Artificial Intel-ligence and Theorem Proving, pages 378392": "Albert Qiaochu Jiang, Wenda Li, Szymon Tworkowski,Konrad Czechowski, Tomasz Odrzygzdz, Piotr Mi-los, Yuhuai Wu, and Mateja Jamnik. 2022. Thor:Wielding hammers to integrate language models andautomated theorem provers. In Advances in NeuralInformation Processing Systems 35: Annual Confer-ence on Neural Information Processing Systems 2022,NeurIPS 2022, New Orleans, LA, USA, November 28- December 9, 2022. Albert Qiaochu Jiang, Sean Welleck, Jin Peng Zhou,Timothe Lacroix, Jiacheng Liu, Wenda Li, MatejaJamnik, Guillaume Lample, and Yuhuai Wu. 2023.Draft, sketch, and prove: Guiding formal theoremprovers with informal proofs. In The Eleventh In-ternational Conference on Learning Representations,ICLR 2023, Kigali, Rwanda, May 1-5, 2023. Open-Review.net. Cezary Kaliszyk, Josef Urban, Jir Vyskocil, and Her-man Geuvers. 2014. Developing corpus-based trans-lation methods between informal and formal mathe-matics: Project description. In Intelligent ComputerMathematics - International Conference, CICM 2014,Coimbra, Portugal, July 7-11, 2014. Proceedings,volume 8543 of Lecture Notes in Computer Science,pages 435439. Springer. Laura Kovcs and Andrei Voronkov. 2013. First-ordertheorem proving and vampire. In Computer AidedVerification - 25th International Conference, CAV2013, Saint Petersburg, Russia, July 13-19, 2013.Proceedings, volume 8044 of Lecture Notes in Com-puter Science, pages 135. Springer. Guillaume Lample, Timothe Lacroix, Marie-AnneLachaux,Aurlien Rodriguez,Amaury Hayat,Thibaut Lavril, Gabriel Ebner, and Xavier Martinet.2022. Hypertree proof search for neural theoremproving. In Advances in Neural Information Pro-cessing Systems 35: Annual Conference on NeuralInformation Processing Systems 2022, NeurIPS 2022,New Orleans, LA, USA, November 28 - December 9,2022.",
  "J. Robinson and Andrei Voronkov. 2001. Handbookof Automated Reasoning: Volume 1.MIT Press,Cambridge, MA, USA": "Baptiste Rozire, Jonas Gehring, Fabian Gloeckle, StenSootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,Jingyu Liu, Tal Remez, Jrmy Rapin, ArtyomKozhevnikov, Ivan Evtimov, Joanna Bitton, Man-ish Bhatt, Cristian Canton-Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Dfossez, Jade Copet,Faisal Azhar, Hugo Touvron, Louis Martin, Nico-las Usunier, Thomas Scialom, and Gabriel Synnaeve.2023. Code llama: Open foundation models for code.CoRR, abs/2308.12950. Alex Sanchez-Stern, Yousef Alhessi, Lawrence K. Saul,and Sorin Lerner. 2020.Generating correctnessproofs with neural networks.In Proceedings ofthe 4th ACM SIGPLAN International Workshop onMachine Learning and Programming Languages,MAPL@PLDI 2020, London, UK, June 15, 2020,pages 110. ACM. Stephan Schulz. 2004. System description: E 0.81. InAutomated Reasoning - Second International JointConference, IJCAR 2004, Cork, Ireland, July 4-8,2004, Proceedings, volume 3097 of Lecture Notes inComputer Science, pages 223228. Springer. Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu,Junxiao Song, Mingchuan Zhang, Y. K. Li, Y. Wu,and Daya Guo. 2024. Deepseekmath: Pushing thelimits of mathematical reasoning in open languagemodels. CoRR, abs/2402.03300.",
  "Peiyang Song, Kaiyu Yang, and Anima Anandkumar.2024. Towards large language models as copilots fortheorem proving in lean. CoRR, abs/2404.12534": "Weiwei Sun, Lingyong Yan, Xinyu Ma, ShuaiqiangWang, Pengjie Ren, Zhumin Chen, Dawei Yin, andZhaochun Ren. 2023. Is ChatGPT good at search?investigating large language models as re-rankingagents. In Proceedings of the 2023 Conference onEmpirical Methods in Natural Language Process-ing, pages 1491814937, Singapore. Association forComputational Linguistics. Christian Szegedy. 2020. A promising path towardsautoformalization and general artificial intelligence.In Intelligent Computer Mathematics - 13th Interna-tional Conference, CICM 2020, Bertinoro, Italy, July26-31, 2020, Proceedings, volume 12236 of LectureNotes in Computer Science, pages 320. Springer.",
  "Haiming Wang, Ye Yuan, Zhengying Liu, Jianhao Shen,Yichun Yin, Jing Xiong, Enze Xie, Han Shi, YujunLi, Lin Li, Jian Yin, Zhenguo Li, and Xiaodan Liang.2023b. Dt-solver: Automated theorem proving with": "dynamic-tree sampling guided by proof-level valuefunction. In Proceedings of the 61st Annual Meetingof the Association for Computational Linguistics (Vol-ume 1: Long Papers), ACL 2023, Toronto, Canada,July 9-14, 2023, pages 1263212646. Association forComputational Linguistics. Qingxiang Wang, Chad E. Brown, Cezary Kaliszyk, andJosef Urban. 2020. Exploration of neural machinetranslation in autoformalization of mathematics inmizar. In Proceedings of the 9th ACM SIGPLANInternational Conference on Certified Programs andProofs, CPP 2020, New Orleans, LA, USA, January20-21, 2020, pages 8598. ACM. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V.Le, Ed H. Chi, Sharan Narang, Aakanksha Chowd-hery, and Denny Zhou. 2023c.Self-consistencyimproves chain of thought reasoning in languagemodels. In The Eleventh International Conferenceon Learning Representations, ICLR 2023, Kigali,Rwanda, May 1-5, 2023. OpenReview.net. Christoph Weidenbach. 2001. Combining superposi-tion, sorts and splitting. In John Alan Robinson andAndrei Voronkov, editors, Handbook of AutomatedReasoning (in 2 volumes), pages 19652013. Elsevierand MIT Press. Sean Welleck, Jiacheng Liu, Ximing Lu, HannanehHajishirzi, and Yejin Choi. 2022.Naturalprover:Grounded mathematical proof generation with lan-guage models. In Advances in Neural InformationProcessing Systems 35: Annual Conference on Neu-ral Information Processing Systems 2022, NeurIPS2022, New Orleans, LA, USA, November 28 - Decem-ber 9, 2022.",
  "Sean Welleck and Rahul Saha. 2023.LLMSTEP:LLM proofstep suggestions in lean.CoRR,abs/2310.18457": "Yuhuai Wu, Albert Qiaochu Jiang, Wenda Li, Markus N.Rabe, Charles Staats, Mateja Jamnik, and ChristianSzegedy. 2022. Autoformalization with large lan-guage models. In Advances in Neural InformationProcessing Systems 35: Annual Conference on Neu-ral Information Processing Systems 2022, NeurIPS2022, New Orleans, LA, USA, November 28 - Decem-ber 9, 2022. Kaiyu Yang, Aidan M. Swope, Alex Gu, Rahul Chala-mala, Peiyang Song, Shixing Yu, Saad Godil, Ryan J.Prenger, and Animashree Anandkumar. 2023. Le-andojo: Theorem proving with retrieval-augmentedlanguage models. In Advances in Neural InformationProcessing Systems 36: Annual Conference on Neu-ral Information Processing Systems 2023, NeurIPS2023, New Orleans, LA, USA, December 10 - 16,2023. Eric Yeh, Briland Hitaj, Sam Owre, Maena Quemener,and Natarajan Shankar. 2023. Coprover: A recom-mender system for proof construction. In IntelligentComputer Mathematics - 16th International Confer-ence, CICM 2023, Cambridge, UK, September 5-8,",
  ", Proceedings, volume 14101 of Lecture Notesin Computer Science, pages 237251. Springer": "Huaiyuan Ying, Shuo Zhang, Linyang Li, Zhejian Zhou,Yunfan Shao, Zhaoye Fei, Yichuan Ma, Jiawei Hong,Kuikun Liu, Ziyi Wang, Yudong Wang, Zijian Wu,Shuaibin Li, Fengzhe Zhou, Hongwei Liu, SongyangZhang, Wenwei Zhang, Hang Yan, Xipeng Qiu, JiayuWang, Kai Chen, and Dahua Lin. 2024. Internlm-math: Open math large language models toward veri-fiable reasoning. CoRR, abs/2402.06332.",
  "Decomposing the enigma: Subgoal-based demon-stration learning for formal theorem proving. CoRR,abs/2305.16366": "Chuanyang Zheng, Haiming Wang, Enze Xie, Zhengy-ing Liu, Jiankai Sun, Huajian Xin, Jianhao Shen,Zhenguo Li, and Yu Li. 2023. Lyra: Orchestratingdual correction in automated theorem proving. CoRR,abs/2309.15806. Kunhao Zheng, Jesse Michael Han, and Stanislas Polu.2022. minif2f: a cross-system benchmark for for-mal olympiad-level mathematics. In The Tenth In-ternational Conference on Learning Representations,ICLR 2022, Virtual Event, April 25-29, 2022. Open-Review.net. Jin Peng Zhou, Charles Staats, Wenda Li, ChristianSzegedy, Kilian Q. Weinberger, and Yuhuai Wu.2024a. Dont trust: Verify - grounding LLM quan-titative reasoning with autoformalization.CoRR,abs/2403.18120.",
  "A.1Prompts for BC-Prover": "For reproducibility, we provided detailed promptsduring the proof construction.Concretely, theprompt we used for generating the pseudo steps(Equation 3 and 4) is in and 6. The promptfor backward chaining (Equation 5) is in . The prompt for generating next-step planning As a mathematician and expert, your task is to provide a correct, concise,and clear mathematical answer according to the theorem and its informalstatement. Note that the theorem is provable.{examples}## Formal theorem:{theorem_statement}## Informal statement:{informal_statement}## Informal proof:",
  ": The prompt for generating informal proof": "As a mathematician and expert in Lean theorem prover, your task is towrite a pseudo code in Lean 3 in response to a problem statement. Yourpseudo code should be structured and clearly written, meeting the followingcriteria:- It is readable and must be broken down into numerical steps like Step1,Step2 ...- Steps of the proof should be explained in detail using comments enclosedin /- and -/- Be clear and concise, avoiding any unnecessary or apologetic language.- Make sure each step of the pseudo-code can be easily converted intoformal Lean 3 code.- Please use NO sorry tactic or placeholders for proofs or assumptions inthe pseudo-code.- Assume you have already imported the necessary Mathematic Library tofinish the proof.## informal problem statement:{informal_statement}## informal proof of the problem:{informal_proof}Please wirte the pseudo code:{theorem_statement}PSEUDO-CODE:",
  "A.2Justification for Excluding Baselines": "In , we compare BC-Prover with recently re-leased LLM in mathematics to our knowledge. Weempirically excluded three task-specific finetunedprovers targeting ITP in Lean. Here, we focusthe discussion on reasons for excluding the threeprovers (Lample et al., 2022; Polu and Sutskever,2020b; Polu et al., 2023). Most importantly, itis infeasible to reproduce their work with reason-able effort because they didnt release any code,pre-trained models, or available training datasets.Therefore, we can only compare the Pass@1 met-rics reported in their papers. However, it is alsoimpractical due to several reasons: As a mathematician and expert in Lean theorem prover, your task is toanalyze the pseudo-code. Please consider what is missing to decomposeand achieve the proof goal in a backward reasoning manner. Request usefuland reusable hypotheses, meeting the following criteria:- The hypotheses should be created with Structured Tactic Proofs. That isthey should be introduced with the tactic let, have, or suffices(it addsthe hypothesis to the current goal).- Please make sure that the hypotheses are valid in Lean and you have tosuccessfully proof them in the format: have hypo: (sub-goal_statement),by {{<valid_proof>}},.- You can try smart tactics to prove the hypothesis like ring(proveequalities in commutative rings) and nlinarith(handles some goals innonlinear arithmetic).- The hypotheses should be non-trivial and able to cover a large step inproofs. You can refer to the pseudo-code for inspiration.- Please use NO placeholders for proofs or assumptions in the<valid_proof>.- DO NOT generate hypotheses that already exist in the proof state.- DO NOT generate the keyword sorry.## Pseudo-code:{pseudo_steps}## Please provide {k} effective hypotheses according to the Current ProofState:{current_state}#1leanhave hypothsis1: (<sub-goal_statement>), by {{<tactics>}},#2",
  ": The prompt for backward chaining": "Lample et al. (2022) only report the Pass@64on the miniF2F benchmark with their ap-proach. They constructed a synthetic train-ing dataset named Equations, which is notpublicly available. Their model is also inac-cessible. As a result, we cannot make a faircomparison or reproduce their work. Polu and Sutskever (2020b) didnt report theirresult on the miniF2F benchmark because theypublished their works before the miniF2F wasofficially released. They didnt make theirmodel public so it is also difficult to reproducetheir work. Polu et al. (2023) further fine-tuned their mod-els on new proofs collected through their in-teraction with Lean on miniF2F benchmarkwhich is supposed to be used in the evaluation.They also construct extra proofs to transfer tominiF2F. Considering the potential overfittingissue, we compare with a generalized modelresult reported in their paper (Expert Iterationin ). We would like to evaluate them under ourframework to verify the backward chainingmechanism, whereas none of them make themodels public. Hence, we only use ReProverand LLMStep to collaborate with our frame-work. As a mathematician and expert in Lean theorem prover, your task is toshortly explain the current proof state. Your explanation should:- Be clear and concise, avoiding any unnecessary or apologetic language.- Only briefly state the existing hypotheses and the goal.- There is no need to provide an approach or solution.## Current State:{proof_state}",
  ": The prompt for generating proof state descrip-tion": "As a mathematician and expert in Lean theorem prover, your task is toderive exactly one next proof step according to the current state, meetingthe following criteria:- You should analyze the state and align the next step with one step in thepseudo-code.- If the aligned target in the pseudo-code is missing or unprecise, thepredicted next step should be further decomposed.- The predicted next proof step must be close to Lean code.- Do not fabricate hypotheses or lemmas that didnt appear in the context.- Please use NO sorry or placeholders for proofs and assumptions.## Pseudo Code:{pseudo_steps}## Current State:{proof_state}{description}## The predicted step should be clear, concise, and easy to translate intoLean code:",
  ": The prompt for generating next-step planning": "Besides formal theorem proving in Lean, we no-tice that recent researchers also target other proofassistants like Isabelle, Coq, Holight, and Meta-math. Unfortunately, it is generally impractical tocompare with their work for mainly three reasons: Different proof assistants have different char-acteristics. As for Isabelle, it has powerfulautomatic reasoning tools like Sledgeham-mer. Sledgehammer integrates automated the-orem provers (ATPs) into Isabelle environ-ment. When Sledgehammer is called, it willtry to prove the conjecture using strong, ex-ternal ATPs like E (Schulz, 2004), SPASS(Weidenbach, 2001), Vampire (Kovcs andVoronkov, 2013), Z3 (de Moura and Bjrner,2008), or cvc5 (Barbosa et al., 2022). And yet,Lean does not have equally powerful tools.Many ITP frameworks in Isabelle make use ofthis characteristic and achieve higher scoresin miniF2F benchmark. Different evaluation metrics. Most studies onITP in Isabelle evaluate their approaches withthe pass rate within 100 or 200 attempts(Wanget al., 2023a; Zheng et al., 2023). Our frame-work, however, adopts Pass@1 as the metric.",
  "Use of human-verified informal proof. Jianget al. (2023) and Wu et al. (2022) use human-": "As a mathematician and expert in Lean theorem prover, your task isto recall the lemmas in the mathlib3 library and find at least {k} mosthelpful lemmas for theorem proving. You are required to both analyze thepseudo-code and select appropriate premises from the premise list, meetingthe following criteria:- The pseudo-code provides valuable information about which lemmashould be selected.- Please only select lemmas that help solve the current proof state.- You should think step by step: make a brief analysis in one single sentenceand select the lemma.- Your response should be clear and concise, ignoring the useless lemmas:textAnalysis_1: <analysis_holder>Selection_1: <selectioin_holder>Analysis_2: <analysis_holder>Selection_2: <selection_holder>##Pseudo-code:{pseudo_steps}##Lemma List:{retrieved_lemmas}##Proof State:{proof_state}Please select at least {k} useful lemmas in the Lemma List or the mathlib3library.",
  "A.3More Implementation Details": "In this section, we provide more implementationdetails of our framework.(1) How do we implement backward chaining?By definition, backward chaining starts from thegoal and recursively breaks it into sub-goals, whichshould be asserted as facts for goal achievement(Al-Ajlan, 2015). The key is to generate a Leanformat statement that opens up a sub-goal and statetactics to prove the sub-goal. We implement Equa-tion 5 using structured tactic proofs in Lean 3. Inparticular, we define backward chaining as havestatements in structured tactic proofs: have hgoal :gsub by { tsub } . The LLM is required to generatehave statements. After verifying the statement, wecan introduce the goal-driven hypothesis hgoal byinteracting with Lean.(2) How do we parse the responses from LLM?We officially set k = 16 in forward chaining and",
  "#introducing-auxiliary-subgoals": "As a mathematician and expert in Lean 3 theorem prover, your task is toanalyze the current proof state (telling you what facts you have alreadyestablished and what goals remain to prove) and given theorem (includingthe pseudo-code, informal statement, and some potentially useful lemmas).You should provide {k} tactic(s) helpful toward proving the proof state,meeting the following criteria:- Pseudo-code gives valuable hints. The generated tactic should STRICTLYcorrespond to steps in the pseudo-code.- Assume you have already imported all lemmas from mathlib3 libraries tofinish the proof. You are strongly encouraged to wisely apply, exact, orrw with lemmas to solve the proof state.- You are encouraged to decompose and reduce the proof state usingrewrite, field_simp, let.- revert (move hypotheses into the goal and yield an implication) andintros/simp_intros (inverse to revert) some hypotheses are helpful torestructure and simplify the state.- Each tactic should be explained in detail using comments enclosed in /-and -/.- Please use NO placeholders for proofs or assumptions in the tactic.- DO NOT use the keyword sorry in your tactic.- Do not fabricate hypotheses that didnt appear in the context window.## Potentially Useful Lemmas from mathlib3 (For example):{lemmas_plans}## Pseudo Code:{next_step_planning}## Do not change the current proof state because you are only focusingon solving the current problem. Please provide at least {k} effective andcommented tactic(s) according to the pseudo-code. Restate the current statebefore the tactic{augmented_proof_state}",
  ": The prompt for generating proofsteps inforward chaining": "d = 8 in backward chaining. Occasionally, wemay end up getting less or more than the predefinedamount because the generative models could notstrictly follow the input instructions. In such cases,we cut off the results to make sure we get amountless than k or d.(3) How does our framework collaborate withtask-specific finetuning models? Task-specific fine-tuning models are finetuned on sequences of theform:",
  ": We consider hypotheses that contributelittle to a proof goal to be of low quality": "Although our framework invokes the backwardchaining in mathematical proving, we still wonderwhat else can be done to further prompt ITP. Weconduct a quality analysis of our hypotheses pro-duced by backward chaining. First of all, we sam-ple around 200 hypotheses from the constructedproofs. Some examples are listed in . Wefound that most of them are not of high quality.They are either trivial or rather similar to exist-ing lemmas. This sort of hypothesis might con-tribute little to finding the proofs. Furthermore,we estimated the number of reusable hypothesesby whether they are invoked throughout the wholeproof. We found out that only around 16% tacticsmake a difference in proof-finding. Even so, ourframework managed to solve some of the complexproblems and cause no performance degradation.In conclusion, it still remains a problem how towork in backward chaining to generate high-qualityhypotheses, which is left for future work.",
  "DMore Experiment Result": "Autoformulation Settings. Autoformalization isthe task of automatically translating natural lan-guage mathematics into a formal language that canbe verified by a program. It requires a profoundunderstanding of semantics across informal and for-mal mathematics. Here, we evaluate BC-Prover in proof autoformalization task settings, where a cor-rect human-written informal proof is given. As re-sults in illustrate, BC-Prover can find moreproofs in miniF2F-test. Concretely, the Pass@1improves by 3.3% on the miniF2F-test. It impliesthat LLM still struggles to generate a correct infor-mal proof. A possible solution is to vote for thebest informal proof from multiple candidates likeself-consistency (Wang et al., 2023c), which weplan to study in future work.",
  "BC-Prover29.5%30.7%BC-Prover + human informal29.9%34.0%": "Category of Solved Proofs.The MiniF2Fbenchmark contains 488 problems in various cat-egories. The problems can be categorized intoOlympiad problems (AIME, AMC, and IMO),number theory problems, algebra problems, andinduction problems. Among them, the Olympiadproblems are the most difficult. In total, we findproofs of 97 algebra problems, 67 number the-ory problems, 21 Olympiad problems (19 AMC, 2AIME, 0 IMO), and 0 induction problems.",
  "Here, we present more proofs found by our frame-work in , 17 and 18. The informal prob-lem statements and human-written informal proofsare displayed for readers to understand": "InputAs a mathematician and expert in Lean theorem prover, your task is to analyze the pseudo-code.Please consider what is missing to decompose and achieve the proof goal in a backward reasoningmanner. Request useful and reusable hypotheses, meeting the following criteria:- The hypotheses should be created with Structured Tactic Proofs. That is they should be introducedwith the tactic let, have, or suffices(it adds the hypothesis to the current goal).- Please make sure that the hypotheses are valid in Lean and you have to successfully proof them inthe format: have hypo: (sub-goal_statement), by {{<valid_proof>}},.- You can try smart tactics to prove the hypothesis like ring(prove equalities in commutative rings)and nlinarith(handles some goals in nonlinear arithmetic).- The hypotheses should be non-trivial and able to cover a large step in proofs. You can refer to thepseudo-code for inspiration.- Please use NO placeholders for proofs or assumptions in the <valid_proof>.- DO NOT generate hypotheses that already exist in the proof state.- DO NOT generate the keyword sorry.## Pseudo-code:{pseudo_steps}## Please provide {k} effective hypotheses according to the Current Proof State:n : N,h : n % 7 = 5 5 * n % 7 = 4#1leanhave hypothsis1: (<sub-goal_statement>), by {{<tactics>}},#2 Output#2leanhave h_mul_mod : 5 * 5 % 7 = (5 % 7) * (5 % 7) % 7, from nat.mul_mod 5 5 7,#3leanhave h_25_mod_7 : 25 % 7 = 4, by norm_num,#4leanhave h_mul_mod : a b n : N, (a * b) % n = ((a % n) * (b % n)) % n, from nat.mul_mod,......",
  ": Prompt example for sub-goal and tactic pairs generation in Backward Chaining": "InputAs a mathematician and expert in Lean theorem prover, your task is to recall the lemmas in themathlib3 library and find at least {k} most helpful lemmas for theorem proving. You are requiredto both analyze the pseudo-code and select appropriate premises from the premise list, meeting thefollowing criteria:- The pseudo-code provides valuable information about which lemma should be selected.- Please only select lemmas that help solve the current proof state.- You should think step by step: make a brief analysis in one single sentence and select the lemma.- Your response should be clear and concise, ignoring the useless lemmas:textAnalysis_1: <analysis_holder>Selection_1: <selectioin_holder>Analysis_2: <analysis_holder>Selection_2: <selection_holder>## Pseudo-code:{pseudo_steps}## Lemma List:[Premise_0] lemma <a>nat.mul_mod</a> (a b n : N) : (a * b) % n = ((a % n) * (b % n)) % n[Premise_1] lemma <a>nat.add_mod</a> (a b n : N) : (a + b) % n = ((a % n) + (b % n)) % n[Premise_2] lemma <a>nat.mod_add_div</a> (m k : N) : m % k + (m / k) * k = m[Premise_3] ......## Proof State:{proof_state}Please select at least {k} useful lemmas in the Lemma List or the mathlib3 library. OutputSelection_1: none required directly, as the hypothesis itself provides the needed relationship, so wemove on to implications of the hypothesis.Analysis_2: The transition from modular equivalence to a statement about the modulus operationsresult is required to conclude the proof. We need a lemma that directly allows converting a \"lessthan\" relationship into an equality under modulus.Selection_2: <a>nat.mod_eq_of_lt</a> - This lemma can be used to convert the modular equivalencebetween ((5 * n) mod 7) and 4 into an equality statement, assuming we have established that5 n < 7 which isnt directly required here but is implied in the kind of transition we are making.......Therefore potentially useful premises are:[nat.mul_mod] lemma <a>nat.mul_mod</a> (a b n : N) : (a * b) % n = ((a % n) * (b % n)) % n[nat.mod_eq_of_lt] lemma <a>nat.mod_eq_of_lt</a> a b : nat (h : a < b) : a % b = a......",
  ": Prompt example for lemmas and plans generation in Step Planning": "InputAs a mathematician and expert in Lean theorem prover, your task is to derive exactly one next proofstep according to the current state, meeting the following criteria:- You should analyze the state and align the next step with one step in the pseudo-code.- If the aligned target in the pseudo-code is missing or unprecise, the predicted next step should befurther decomposed.- The predicted next proof step must be close to Lean code.- Do not fabricate hypotheses or lemmas that didnt appear in the context.- Please use NO sorry or placeholders for proofs and assumptions.## Pseudo Code:{pseudo_steps}## Current State:n : N, h : n % 7 = 5, h_mod_25_4 : 25 % 7 = 4, h_5_mod_7 : 5 % 7 = 5, h_final_mod : 5 % 7 * 5 %7 = 4, h_5_mul_5_mod_7 : 5 * 5 % 7 = 4, h_mul_mod : (a b n : N), a * b % n = a % n * (b % n)% n 5 % 7 * n % 7 = 4{description}## The predicted step should be clear, concise, and easy to translate into Lean code:OutputGiven the current state and the hypotheses provided, we observe that the hypotheses.......So, the predicted Lean code as the next logical step would be to apply h_mul_mod using our values5, n, and 7, followed by substituting n % 7 with 5, guided by h.leanhave h_step : 5 % 7 * n % 7 % 7 = 5 * 5 % 7, from eq.trans (h_mul_mod 5 n 7) (by rw [h,h_5_mod_7]),This step uses eq.trans to transform the application of h_mul_mod into an intermediate steptowards our goal by rewriting n % 7 as 5, utilizing h and recognizing the modulo property of 5as per h_5_mod_7. The application of by rw [h, h_5_mod_7] rewrites the expression accordingto our hypothesis h and the property of modulo 5 modulo 7.",
  ": Prompt example for next proofstep planning in Step Planning": "informal_statement:One dimension of a cube is increased by $1$, another is decreased by $1$, and the third is left unchanged. The volume of the new rectangular solid is $5$ less than that of the cube. What was the volume of the cube? $\\textbf{(A)}\\ 8 \\qquad \\textbf{(B)}\\ 27 \\qquad \\textbf{(C)}\\ 64 \\qquad \\textbf{(D)}\\ 125 \\qquad \\textbf{(E)}\\ 216$ Show that it is \\text{(D)}.",
  ": An example proof of BC-Prover": "informal_statement:If $f(x)=ax^4-bx^2+x+5$ and $f(-3)=2,$ then what is the value of$f(3)$? Show that it is 8.informal_proof:Evaluating $f(x)$ for $x=3$ and $x=-3$, we have\\[\\left\\{ \\begin{aligned} f(3)& = a \\cdot 3^4 - b \\cdot 3^2 + 3 + 5,\\\\ f(-3) &= a \\cdot (-3)^4 - b \\cdot (-3)^2 + (-3) + 5. \\end{aligned}\\right.\\]If we subtract the second equation from the first equation,all the terms but one cancel out, and we get \\[f(3) - f(-3) = 3 - (-3)= 6.\\]Thus, if $f(-3) = 2,$ then $f(3) = f(-3) + 6 = 2 + 6 = 8.$"
}