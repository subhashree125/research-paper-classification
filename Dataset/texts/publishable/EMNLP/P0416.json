{
  "Abstract": "Identifying and understanding user intents isa pivotal task for E-Commerce. Despite itsessential role in product recommendation andbusiness user profiling analysis, intent under-standing has not been consistently defined oraccurately benchmarked. In this paper, we fo-cus on predicative user intents as how a cus-tomer uses a product, and pose intent under-standing as a natural language reasoning task,independent of product ontologies. We identifytwo weaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph: category-rigidity and property-ambiguity. They limitits ability to strongly align user intents withproducts having the most desirable property,and to recommend useful products across di-verse categories. Following these observations,we introduce a Product Recovery Benchmarkfeaturing a novel evaluation framework andan example dataset. We further validate theabove FolkScope weaknesses on this bench-mark.Our code and dataset are availableat",
  "Introduction": "User intents are a crucial source of informationfor E-Commerce (Deng et al., 2023; Er-Rahmadiet al., 2023; Zhang et al., 2016; Hao et al., 2022).Intents reveal users motivation in E-Commerceinteractions: suppose a user plans to go for out-door barbecue, their intent may not refer only tobarbeque smoker grills but also to other productsthat can be useful, such as disposable cutlery orplates. In these cases, traditional product recom-mendation approaches would fail to handle thesequeries or to remind customers of the products theymay need but have forgotten. Intent Understand-ing offers great benefits in recommending distinctproducts based on common user intents they fulfil.",
  ": A graphic illustration of the usage-centricparadigm of intent understanding": "It involves identifying user intents and connectingthem with products: a profile of user intents is ex-tracted using user interactions (e.g. co-buy records,reviews) for each product listing. Then, a map-ping from intents to product listings can be built topredict useful products based on user intents.One significant challenge towards effective in-tent understanding is the vague definition of user in-tents, which precludes effective intent identificationand can easily result in contaminated intent-productassociations. In prior work (Yu et al., 2023; Luoet al., 2021), user intents are often blended withproduct properties or similar products, whichwe argue are related to the products and not theusers. These shortcuts may benefit existing productrecommendation benchmarks, but are not alignedwith the intent understanding objective, namely,to retrieve superficially distinct kinds of productsserving common intents (Huang et al., 2024).Therefore, we propose a usage-centric paradigmfor intent understanding (demonstrated in ). In this paradigm, user intents are focused onnatural language predicative phrases, i.e. how users use a product; also, instead of individual productlistings, we aim to predict kinds of products usefulfor an intent. In particular, we define user intentsas activities to accomplish (e.g. outdoor barbecue)or situations to resolve (e.g. lower-back pain); and,kinds of products as clusters of product listingspossessing the same category (e.g. scrub brush)and property (e.g. stiff bristle). Predicting at thelevel of the kinds of products guarantees that the listof relevant predictions is not endless. Our task is anatural language reasoning task, closely related tocommonsense reasoning (Sap et al., 2019; Bosselutet al., 2019): The user has intent I entails Thekind of product P is useful for the user. Knowledge Graphs (KGs) are important to manyenterprises today, providing factual knowledge andstructured data that steer many products and makethem more ready to be used in automatic processesand thus supporting more intelligent applications.In this paper, we present an analysis of a SOTAE-Commerce intent knowledge graph, FolkScope(Yu et al., 2023), which reported promising resultson an intrinsic co-buy prediction task. Refactoringtheir KG to build associations between kinds ofproducts and their usage user intents, we discovertwo unsatisfactory characteristics in their KG topol-ogy: 1) property-ambiguity: generated user intentsare poorly aligned with relevant product proper-ties, such that the KG often maps user intents tokinds of products with relevant category but fairlyrandom properties; 2) category-rigidity: each in-tent is strongly associated with a single categoryof product, such that the KG is unable to recom-mend diverse products across different categoriesthat serve common intents. In light of these findings, we develop a Prod-uct Recovery Benchmark, including an evalua-tion framework that aligns with the usage-centricparadigm, isolating product-specific confounders,such as product price or ratings. Also, we providea dataset based on the Amazon Reviews Dataset(ARD) (Ni et al., 2019) where we further validatethe impact of the weaknesses in FolkScope. All in-tent understanding methods developed on the ARDcan be evaluated using this benchmark. To summarize, in this paper: 1) we propose ausage-centric paradigm for intent understanding;2) we introduce a product recovery benchmark fea-turing a novel evaluation framework, and reportresults with SOTA baselines; 3) we identify crucialweaknesses in existing SOTA as category-rigidity",
  "Usage-Centric Intent Understanding": "We propose a usage-centric paradigm of intent un-derstanding, focusing on usage user intents andthe kinds of useful products, where the goal isto ground usage user intents in kinds of usefulproducts. Differently from the informal queriesin Luo et al. (2021), and similarly to Ding et al.(2015), our usage user intents are generic eventual-ities/situations, independent of product ontologies.We introduce kinds of products as the target gran-ularity level, as it abstracts away the nuanced dif-ferences among individual listings, and yields apurely natural language setup, independent of prod-uct ontologies. It contains just enough information(category + property) to represent the product list-ings inside for intent understanding.User intents rarely require combinations of prop-erties in a product category. Therefore, to avoidgenerating factorial numbers of kinds of product,we impose a mild constraint that only one propertyis specified for each kind of product.We demonstrate the specificity trade-off withan example below: for outdoor barbecues, a stiff-bristle scrub brush is useful for cleaning the greaseon the grill. To that end, there are many listingsof hard-bristle scrubs but the exact choice amongthem is irrelevant to the user intent and could beidentified by downstream recommendation systemsusing other factors (customer habit, geo-location,etc.). However, the stiff bristle property is essentialfor a listing to be suitable for outdoor barbecues. Inshort, grouping based on kinds of products strikesa balance between sparsity that comes with speci-ficity, and ambiguity that comes with generality.",
  "KG Refactoring": "We refactor FolkScope based on our usage-centricintent understanding paradigm. FolkScope KG con-nects products with their user intents, which aregenerated with OPT-30B (Zhang et al., 2022) whengiven pairs of co-bought products sourced fromARD (Ni et al., 2019), along with manually definedcommonsense relations.Among their 18 commonsense relations, we fil-ter out all item relations as well as 3 functionrelations (SymbolOf, MannerOf, and DefinedAs), 0.00.10.20.30.40.50.60.7 0% 5% 10% 15% 20% 25% JSD distribution for Clothing 0.00.10.20.30.40.50.60.7 0% 5% 10% 15% 20% 25% JSD distribution for Electronics : Histograms of Jensen-Shannon Divergencefor each intent-category pair. Values are packed around0: property-distributions of edge weights conditionedon intents are close to unconditioned frequency priors. since they are nominal in nature, and are irrelevantto product usage. We keep the remaining 5 predica-tive relations, UsedFor, CapableOf, Result, Cause,CauseDesire, as legitimate user intents.To group the product listings into kinds of prod-ucts, we take the fine-grained product categoriesfrom ARD (e.g. Kids Backpacks), and borrowthe attributes under the relation PropertyOf in theoriginal FolkScope KG as properties.1 We compute the association strengths from se-lected user intents to common kinds of productsby aggregation. Let e(Ii, Pj) be the connection ofintent Ii with product listing Pj, Pj belongs to akind of products Kk. The association strength foredges in the refactored KG are then computed as:e(Ii, Kk) = PjKk pmi(Pj, Kk) e(Ii, Pj). 2",
  "Statistical Analysis": "We identify two major weaknesses of FolkScopeKG under the usage-centric paradigm: it is over-specific about categories of useful products, butunder-specific about the required properties ofthese products within each category. Intents inFolkScope tend to be associated with products hav-ing vague properties from few categories, ratherthan specific kinds of products across a variety ofcategories.",
  "Property-AmbiguityFor each user intent, welook into the distribution of its edge weights among": "1These attributes do not fit the criteria for usage user in-tents, but they are acquired through generic LLM promptedsummarization, and thus are borrowed as product properties.2The pmi term penalizes product listings with multiplekinds of products (e.g. multiple properties in one listing). 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0 0% 20% 40% 60% 80% 100% 63% 23% 2%1%1% Entropy of Intents in Clothing 0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0 2.2 2.4 2.6 2.8 3.0 0% 20% 40% 60% 80% 100% 67% 20% 2% Entropy of Intents in Electronics",
  ": Histograms of category-entropy for each userintent. Values are concentrated at 0.0 and 0.7, meaningthe intent is associated with only 1 / 2 categories": "kinds of products from one category with differ-ent properties. We compare these posterior edge-weight distributions, conditioned on intent, withthe prior distributions across differently-propertiedkinds of products within that category. We calcu-late Jensen-Shannon Divergence (JSD) betweenthese conditional and prior distributions (see Fig-ure 2): for up to 20% of cases, JSD is < 0.1, whereonly 2% of cases have JSD > 0.5.This shows, the KGs edge weights amongdifferently-propertied kinds of products within thesame category are strongly predicted by their priordistribution, and are insensitive to the specific us-ages depicted by user intents. For example, for theuser intent of outdoor barbecues, its edge weightsdistribution among different kinds of scrub brushproducts should depend on this specific usage sce-nario. In this case, a stiff bristle scrub brush mayreceive much higher weights than other kinds ofscrub brushes, rather than having the distributionalign more closely with the prior distribution ofkinds of scrub brush products. We credit this tothe mismatch between property and intent mining:each product listing may have multiple propertiesand serve multiple intents, but the mappings be-tween these properties and intents are underspeci-fied. Category-RigidityIn the refactored KG, we cal-culate the category diversity by measuring howdiverse the edge weights are w.r.t. categories forone user intent. For each user intent, we add upits edge weights to kinds of products grouped byproduct categories (e.g. edge weights to stiff bristlescrub brush and scrub brush with wooden handle are added together), and compute the entropy ofthe converted category distribution. shows the entropy meta-distributions:entropy values are concentrated in 2 narrow ranges,[0, 0.02) and [0.68, 0.70). We notice that an en-tropy in [0, 0.02) indicates that the associationsabout this intent are focused on only one productcategory; [0.68, 0.70) indicates that the associa-tions are focused on two product categories. There-fore, from we can conclude that over 80%of the intents are associated with only one or twocategories. This category-rigidity in FolkScopehampers its ability to recommend diverse kinds ofproducts, as we will discuss in 4.2.",
  "Benchmark Design": "Following our intent understanding paradigm in 2,we introduce a usage-centric evaluation framework,which aims to recover kinds of products based onretrieved user intents. Under this framework, anintent understanding method first predicts a profileof user intents for a product listing (using productdescription, user reviews, etc.). Then, using solelythe predicted intent as input, the method recoversuseful kinds of products based on its knowledgeof E-Commerce demands (e.g. in symbolic KGsor LLMs). The predictions are compared against:1) bought-product-recovery: kinds of product towhich the current product belongs; 2) co-bought-product-recovery: kinds of co-bought products thatbelong to other categories.We take bought-product-recovery as our mainevaluation setup, since it focuses on intent-to-kinds-of-product associations. We also include the co-bought-product-recovery setup to validate statisti-cal findings on cross-category recommendation per-formance. Compared to the product recommenda-tion evaluation in Yu et al. (2023), this frameworkmarginalizes factors inciting co-buy behaviour (e.g.brand loyalty, geolocation, etc.).We instantiate the proposed evaluation frame-work with a product recovery benchmark, based onthe ARD (Ni et al., 2019), using available resources.We utilise the pool of product listings in ARD,enriched with product descriptions, category in-formation, anonymized user purchase records andreviews. We additionally borrow kinds of productsfrom refactored FolkScope, as in 3.1.3",
  "We evaluate the FolkScope KG (refactored in 3.1)with the Product Recovery benchmark. We offerthe baseline results in , and highlight belowthe impact of weaknesses discussed in 3.2": "Property-AmbiguityTo understand how prop-erty ambiguity affects FolkScope performance, wecompare it with another prior property baselinederived from it: for each evaluation entry, we cor-rupt the FolkScope predictions by replacing theproperty in the predicted kinds of products basedon the property popularity. The popularity of aproperty is defined as the frequency with which itappears in the product listings that belong to thesame fine-grained category (e.g. scrub brush) asthe evaluation entry (kinds of products). To avoidmaking duplicate predictions after substitution, ifmultiple kinds of products from the same categoryare predicted, we draw properties top-down w.r.t.popularity for each prediction.From , we observe that FolkScope properties reached respectable performance with acknowledge that re-using information from FolkScope maygrant it an unfair advantage, however, we show below, that itnevertheless suffers from the aforementioned weaknesses andfails to perform intent understanding effectively.",
  "and 0.033 for Clothing and Electronics domains,respectively: the FolkScope KG cannot effectivelyrecommend superficially distinct kinds of productsconnected with the same user intents": "Notably, between the two domains, FolkScopereaches a slightly higher MRRmax in Clothing.This is consistent with our findings in ,where category-entropy values are slightly morespread than in Electronics (i.e. category rigidity isless severe). LLM RerankWe also evaluate LLM perfor-mance on usage-centric intent understanding usingour benchmark, using GPT-3.5-turbo (Brown et al.,2020). Ideally, we would like the LLM to predictuseful kinds of products end-to-end. However, dueto the difficulty of reliably matching LLM predic-tions with gold kinds of products4, we instead adopta re-ranking paradigm, where we prompt the LLMto re-rank the top-10 kinds of products predictedby FolkScope. As shows, we observe no clear benefitwith LLM-reranking. We investigate this failureby looking into where hits are met in the predic-tions. From , we find that most hits areeither at first or not in the top 10. These polarizeddistributions leave little room for re-ranking to takeeffect. We raise the warning that dataset artefacts fromthe common source corpus (AWD) could be behindthis abnormally high hit-at-1 rate (compared withthe MRRmax value), where the reported MRRmaxvalues may have been inflated. Due to the lackof another large E-Commerce Reviews corpus, weleave further investigations for future work.",
  "Discussions and Conclusion": "In this paper, we revisit intent understanding froma usage-centric perspective, as a natural languagereasoning task, to detect superficially distinct kindsof products useful for common usage intents. Wedeveloped a Product Recovery benchmark, and in-vestigated two weaknesses of the SOTA FolkScopeKG in supporting usage-centric intent understand-ing: Property Ambiguity and Category-Rigidity.We advocate for adopting the usage-centric in-tent understanding paradigm, and for consideringuser reviews, in addition to co-buy records. De-sired product properties and their respective intentsare likely to co-occur in product reviews, relievingproperty-ambiguity; the same usage intents tendto be described consistently in user reviews acrossdifferent categories, relieving category-rigidity.As for future work, one idea is to use our pro-posed benchmarks to test some entailment graphsin E-commerce. We might further investigate someabstract inference capabilities that are related toconceptual understanding.",
  "Limitations": "In this paper, we have proposed to study E-Commerce intent understanding from a usage-centric perspective. Due to the lack of consistenttask definition and limited computational budget,we are only able to analyse one SOTA intent under-standing KG (namely FolkScope) and one SOTALLM. We encourage more research attention onthe usage-centric E-commerce intent understand-ing task for a more diverse landscape.We have established that weaknesses of Prop-erty Ambiguity and Category Rigidity exist in theSOTA KG, and we have offered a principled hy-pothesis that utilizing genuine user reviews couldhelp with these weaknesses. However, due to lim-its to the scope of this paper, we do not provideempirical evidence for this hypothesis and leave itas a promising direction of future work.We note that as this paper is related to recommen- dation, there exists risks that methods developedon the Product Recovery Benchmark may be usedto bias customer decisions; on the other hand, wealso note that our task definition is purely naturallanguage and does not involve any individual prod-uct listings, therefore it would not bias customerchoices among directly competing listings of thesame kinds of products.",
  "Acknowledgements": "We would like to thank the reviewers for their valu-able comments and suggestions. This work waspartly funded by a Mozilla PhD scholarship at In-formatics Graduate School and by the Universityof Edinburgh Huawei Laboratory. Antoine Bosselut, Hannah Rashkin, Maarten Sap, Chai-tanya Malaviya, Asli Celikyilmaz, and Yejin Choi.2019.COMET: Commonsense Transformers forAutomatic Knowledge Graph Construction. In Pro-ceedings of the 57th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 47624779, Florence, Italy. Association for ComputationalLinguistics. Tom B. Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,Clemens Winter, Christopher Hesse, Mark Chen, EricSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,Jack Clark, Christopher Berner, Sam McCandlish,Alec Radford, Ilya Sutskever, and Dario Amodei.2020.Language Models are Few-Shot Learners.arXiv:2005.14165 [cs]. ArXiv: 2005.14165.",
  "Li Chen and Feng Wang. 2013. Preference-based clus-tering reviews for augmenting e-commerce recom-mendation. Knowledge-Based Systems, 50:4459": "Shumin Deng, Chengming Wang, Zhoubo Li, NingyuZhang, Zelin Dai, Hehong Chen, Feiyu Xiong, MingYan, Qiang Chen, Mosha Chen, Jiaoyan Chen, Jeff Z.Pan, Bryan Hooi, and Huajun Chen. 2023. Construc-tion and applications of billion-scale pre-trained mul-timodal business knowledge graph. In Proc. of the2023 IEEE 39th International Conference on DataEngineering (ICDE). Xiao Ding, Ting Liu, Junwen Duan, and Jian-Yun Nie.2015. Mining User Consumption Intention from So-cial Media Using Domain Adaptive ConvolutionalNeural Network. Proceedings of the AAAI Confer-ence on Artificial Intelligence, 29(1). Number: 1. Btissam Er-Rahmadi, Arturo Oncevay, Yuanyi Ji, andJeff Z Pan. 2023. KATIE: A System for Key At-tributes Identification in Product Knowledge GraphConstruction. In Proceedings of the 46th Interna-tional ACM SIGIR Conference on Research and De-velopment in Information Retrieval (SIRIR 2023). Zhenyun Hao, Jianing Hao, Zhaohui Peng, SenzhangWang, Philip S. Yu, Xue Wang, and Jian Wang. 2022.Dy-hien: Dynamic evolution based deep hierarchi-cal intention network for membership prediction. InProceedings of the Fifteenth ACM International Con-ference on Web Search and Data Mining, WSDM 22,page 363371, New York, NY, USA. Association forComputing Machinery. Wenyu Huang, Andr Melo, and Jeff Z Pan. 2024. ALarge-scale Offer Alignment Model for PartitioningFiltering and Matching Product Offers. In Proceed-ings of the 47th International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval (SIRIR 2024). Xusheng Luo, Le Bo, Jinhang Wu, Lin Li, Zhiy Luo,Yonghua Yang, and Keping Yang. 2021. AliCoCo2:Commonsense Knowledge Extraction, Representa-tion and Application in E-commerce. In Proceedingsof the 27th ACM SIGKDD Conference on KnowledgeDiscovery & Data Mining, pages 33853393, VirtualEvent Singapore. ACM. Jianmo Ni, Jiacheng Li, and Julian McAuley. 2019. Jus-tifying Recommendations using Distantly-LabeledReviews and Fine-Grained Aspects. In Proceedingsof the 2019 Conference on Empirical Methods inNatural Language Processing and the 9th Interna-tional Joint Conference on Natural Language Pro-cessing (EMNLP-IJCNLP), pages 188197, HongKong, China. Association for Computational Lin-guistics. Maarten Sap, Ronan Le Bras, Emily Allaway, Chan-dra Bhagavatula, Nicholas Lourie, Hannah Rashkin,Brendan Roof, Noah A. Smith, and Yejin Choi. 2019.ATOMIC: An Atlas of Machine Commonsense forIf-Then Reasoning. Proceedings of the AAAI Confer-ence on Artificial Intelligence, 33:30273035. Changlong Yu, Weiqi Wang, Xin Liu, Jiaxin Bai,Yangqiu Song, Zheng Li, Yifan Gao, Tianyu Cao, andBing Yin. 2023. FolkScope: Intention KnowledgeGraph Construction for E-commerce CommonsenseDiscovery. ArXiv:2211.08316 [cs]. Chenwei Zhang, Wei Fan, Nan Du, and Philip S. Yu.2016. Mining user intentions from medical queries:A neural network based heterogeneous jointly mod-eling approach. In Proceedings of the 25th Interna-tional Conference on World Wide Web, WWW 16,page 13731384, Republic and Canton of Geneva,CHE. International World Wide Web ConferencesSteering Committee.",
  "A.1Benchmark data split": "We follow Yu et al. (2023), and we split productinstance in FolkScope KG into training, validationand test splits with respective portions of 80%, 10%and 10%. Please refer to for detailed statis-tics. Note that Clothing stands for the Clothing,Shoes and Jewelry domain in the Amazon Re-views Dataset, and Electronics simply stands forthe Electronics domain in the Amazon ReviewsDataset.",
  "FolkScope0.5270.671": ": MRRmax score when evaluating using GPT-4as the judge for matching. Values for GPT-3.5-turbo andour baseline refactored FolkScope KG are both higherin absolute values due to the more benign matchingcriterion; the LLM baseline with GPT-3.5-turbo doesnot outperform the KG baseline. Note that in this setting and in B.1.1, we stilluse the term category in LLM prompts to referto kinds of products, because during preliminaryexperiments we found that LLMs do not respondwell to the term kind of product.",
  "BGPT End-to-End Evaluation": "We perform an additional experiment to directlypredict kinds of products in an end-to-end setup,with an LLM, for our proposed product recoverytask. Again, we use GPT-3.5-turbo as the LLM anddesign the zero-shot prompt as in B.1.1. However,due to the absence of the complete ontology of theAmazon Reviews Dataset, it is challenging for GPT-3.5-turbo to predict the exact ground truth kinds ofproducts. To sidestep the difficulty of evaluatingwhether the predicted strings are semantically iden-tical to the ground truth labels, we use GPT-4 tojudge whether there is a match between predictedand ground truth labels. The relevant prompt isspecified in B.1.2. The detailed evaluation resultsis presented in .From , we can observe that GPT-3.5-turbo does not outperform the FolkScope KG base-line on the product recovery benchmark. Com-pared to the strict string matching results in ,GPT-4 evaluation has a significantly more permis-sive criterion on matching, yielding much higherMRRmax values. We find many of these matchedverdicts by GPT-4 to be spurious (see ), andconclude that GPT-4 cannot easily achieve reliablematching for the product recovery benchmark, andmore robust criteria are needed before replacingthe exact match criterion.",
  "LLM End-to-End15.57 $14.56$": ": API costs of our LLM-related experiments.For the LLM Rerank experiment, we re-rank all thedata samples in the test set while for the End-to-Endevaluation, we only sample 1000 data samples in thetest set. Given the intents, please predict the top10 kinds of products that will be usefulfor these intents.A kind of product is the concatenationof a fine-grained category from the Ama-zon Review Dataset and a useful prop-erty. For example: Clothing, Shoes &Jewelry|Men|Watches|Wrist Watches ###leather.Kinds of products:1.",
  ". Clothing, Shoes & Jewelry|Women|Earrings|Stud Earrings ### elegant and beautiful.": ": Here we list two examples that GPT-4 validate with RRmax = 1. In the first example, it validates the firstprediction as true by matching the property part of the ground truth 3 with the main category of prediction 1. Inthe second example, the property part of prediction 1 is too general compared to all the ground truth kinds ofproducts, but it still validates it as true."
}