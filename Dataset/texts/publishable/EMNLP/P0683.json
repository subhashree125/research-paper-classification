{
  "Abstract": "In the age of mobile internet, user data, oftenreferred to as memories, is continuously gen-erated on personal devices. Effectively manag-ing and utilizing this data to deliver servicesto users is a compelling research topic.Inthis paper, we introduce a novel task of craft-ing personalized agents powered by large lan-guage models (LLMs), which utilize a userssmartphone memories to enhance downstreamapplications with advanced LLM capabilities.To achieve this goal, we introduce EMG-RAG, asolution that combines Retrieval-AugmentedGeneration (RAG) techniques with an EditableMemory Graph (EMG). This approach is fur-ther optimized using Reinforcement Learningto address three distinct challenges: data col-lection, editability, and selectability. Extensiveexperiments on a real-world dataset validatethe effectiveness of EMG-RAG, achieving an im-provement of approximately 10% over the bestexisting approach. Additionally, the personal-ized agents have been transferred into a realsmartphone AI assistant, which leads to en-hanced usability.",
  "Introduction": "In the era of mobile internet, personal informationis constantly being generated on smartphones. Thisdata, referred to as personal memories, is oftenscattered across everyday conversations with AIassistants (e.g., Apples Siri), or within a usersapps (e.g., screenshots), including emails, calen-dars, location histories, travel activities, and more.As a result, managing and utilizing these personalmemories to provide services for users becomes achallenging yet attractive task. With the emergenceof advanced large language models (LLMs), newopportunities arise to leverage their semantic un-derstanding and reasoning capabilities to developpersonal LLM-driven AI assistants.",
  "Corresponding author": "Motivated by this trend, we study the problemof crafting personalized agents that enhance the AIassistants with the capabilities of LLMs by lever-aging users memories on smartphones. Unlikeexisting personal LLM agents (Li et al., 2024b),such as those designed for psychological counsel-ing (Zhong et al., 2024), housekeeping (Han et al.,2024), and medical assistance (Zhang et al., 2023a),the personalized agents face unique challenges dueto practical scenarios and remains relatively unex-plored in current methods. These challenges can be summarized below.(1) Data Collection: Personal memories should en-compass valuable information about a user. Extract-ing these memories from everyday trivial conver-sations presents unique challenges in data collec-tion, especially considering that existing datasetslike personalized chats sourced through crowd-sourcing (Zhang et al., 2018) or psychological di-alogues (Zhong et al., 2024) lack this property.Moreover, constructing annotated data, such as QApairs, is essential for enabling effective trainingof personalized agents. (2) Editability: Personalmemories are dynamic and continuously evolving,requiring three types of editable operations: inser-tion, deletion, and replacement. For example, 1)insertion occurs when new memories are added;2) deletion is necessary for time-sensitive memo-ries, such as a hotel voucher that expires and needsto be removed; 3) replacement is required whenan existing memory, such as a flight booking, un-dergoes a change in departure time and needs up-dating. Therefore, a carefully designed memorydata structure is essential to support this editability.(3) Selectability: To enable the memory data ser-vices for real-world applications, it often requiresquerying a combination of multiple memories. Forexample, in a QA scenario (illustrated in ),the AI assistant answering a question about a sec-retarys bosss flight departure time needs severalmemories: the secretary booked a flight to Ams- terdam for her boss (M1); the flights number isEK349 (M2); the departure time for EK349 is at01:40 on 2024-05-12 (M4). To achieve this, oneintuitive approach is to use Retrieval-AugmentedGeneration (RAG) (Lewis et al., 2020) to find rel-evant memories and form a context that is fedinto a LLM to generate answers. Here, we dis-cuss two potential solutions and their limitations,which motivate the proposed solution. 1) Needlesin a Haystack (NiaH) (Briakou et al., 2023): itorganizes all memories into a single context (theHaystack) and inputs this into a LLM, relying onthe capability of a LLM itself to identify relevantmemories (the Needles) for generating an answer.However, this method incurs significant overheadby extending the LLMs context window and intro-duces noise from irrelevant memories, hinderingthe LLMs ability to generate accurate answers.2) Advanced RAG (Wang et al., 2024; Ma et al.,2023): many advanced RAG techniques still relyon Top-K retrieval to identify relevant memories.However, a fixed parameter K may limit the LLMsability to uncover all relevant memories, especiallyfor the questions requiring diverse memory combi-nations. Thus, an adaptive selection mechanism isessential for the personalized applications. To this end, we introduce a new solution calledEMG-RAG, which presents the first attempt of itskind to address these challenges. We discuss thesolution along with the rationales behind it below.For (1), we utilize a business dataset collected froma real AI assistant, which includes daily conver-sations with the assistant, and users app screen-shots, to extract personal memories. Specifically,we leverage the capabilities of GPT-4 (OpenAI,2023) to clean the raw data into memories. Weorganize the memories chronologically, and thenuse GPT-4 to generate QA pairs within each ses-sion (a set of consecutive memories). We alsotag the memories involved in generating these QApairs, which are then used for subsequent trainingpurposes. For (2), we introduce a three-layer datastructure, called Editable Memory Graph (EMG).The first two layers form a tree structure in accor-dance with the business scopes, while the thirdlayer consists of a users memory graph parsedfrom the memory data. This design is motivatedby three considerations: 1) the tree structure allowsfor partitioned management of various memory cat-egories, facilitating expansion to other categories;and 2) memory data is partitioned under different categories, with the graph structure to capture theircomplex relationships, and 3) this enables efficientretrieval to locate specific memories for editing, bysearching within relevant partitions rather than theentire dataset. For (3), we introduce a reinforce-ment learning (RL) agent that adaptively selectsmemories on the EMG, without being constrainedto a fixed Top-K approach. The rationale of us-ing RL resembles a boosting process. Specifically,when the agent selects relevant memories (actions),it prompts a LLM (frozen) to generate improvedanswers. The quality of these answers is evalu-ated by a downstream task metric (reward), whichthen guides the agent to refine its policy for bettermemory selection. This results in an end-to-end op-timization process aimed at achieving the desiredgoal for downstream tasks.Overall, we make the following contributions.(1) We introduce a novel task of crafting LLM-driven personalized agents, leveraging users per-sonal memories to enhance their experiencethrough LLM capabilities. This task differs fromexisting personal LLM agents in three key chal-lenges: data collection, editability, and selectabil-ity. (2) We propose EMG-RAG, a novel solution thatcombines EMG and RAG to address the three chal-lenges. We show that it enables an end-to-end op-timization process through reinforcement learningto achieve the goal of personalized agents. (3) Weconduct extensive experiments on a real-world busi-ness dataset across various LLM architectures andRAG methods for three downstream applications:question answering, autofill forms, and user ser-vices. Our approach demonstrates improvementsof approximately 10.6%, 9.5%, and 9.7% over thebest existing approach for these tasks, respectively.Moreover, the personalized agents have been trans-ferred into an AI assistant product, resulting in anotable improvement in user experience.",
  "Related Work": "Personalized Dialogue System. To develop a per-sonalized dialogue system (PDS), the PersonaChatdataset (Zhang et al., 2018) is collected throughcrowdsourcing, which comprises Personas (eachpersona is defined by a set of profile sentences) andChats (each chat is collected by two crowdwork-ers with two randomly assigned personas). Basedon the dataset, various techniques have been stud-ied to address challenges in PDS, including mu-tual persona perception (Liu et al., 2020; Xu et al., 2022a; Kim et al., 2020), persona-sparsity (Songet al., 2021; Welch et al., 2022), long-term personamemory (Xu et al., 2022b; Zhong et al., 2024),etc. For example, P2BOT (Liu et al., 2020) isa GPT-based framework (Radford et al., 2018),specifically designed to enrich personalized dia-logue generation through mutual persona percep-tion. It aims to model the underlying understanding,such as character traits, within a conversation tofacilitate mutual acquaintance between interlocu-tors. In addition, a PDS can be further enhanced byintegrating internal reasoning techniques (Hongruet al., 2023) or external acting techniques (Wanget al., 2023b), which aim to generate more per-sonalized and factual responses. In this study, weconstruct user-personalized agents using practicalmemory data gathered from smartphone AI assis-tants. Leveraging these agents, we introduce threedistinct applications: question answering, autofillforms, and user services. Retrieval-Augmented Generation on KnowledgeGraph.We review the literature on RAG onknowledge graphs across various tasks, includingKBQA (Ye et al., 2021; Das et al., 2021; Wanget al., 2023a; Shu et al., 2022), open-domain sce-narios (Yang et al., 2023), table-related tasks (Jianget al., 2023), human-machine conversation (Zhanget al., 2020), and image captioning (Hu et al., 2023).This paper (Zhao et al., 2024) provides a detailedsurvey on these tasks with RAG techniques. Specif-ically, TIARA (Shu et al., 2022) stands out as aKBQA model employing multi-grained retrieval(entities, logical forms, and schema items) fromknowledge graphs. This approach aids pre-trainedlanguage models in mitigating generation errors.In this study, we introduce a novel EMG structureto manage users personal memories. Further, weemploy RL to model the RAG process, which opti-mizes the memory selection on the graph. Model Editing. Model editing represents a re-cent research area focused on correcting modelpredictions in light of evolving real-world dynam-ics. It edits the behavior of pre-trained languagemodels within specific domains, and preservingperformance across other domains without compro-mise. Some existing methods (De Cao et al., 2021;Mitchell et al., 2021) employ learnable model ed-itors, which are trained to predict the weights ofthe base model undergoing editing. Other meth-ods (Meng et al., 2022a,b; Li et al., 2024a) aredesigned to identify stored facts (such as specific neurons in the network) and adjust correspondingactivations to reflect changed facts. Additionally,SERAC (Mitchell et al., 2022) utilizes an externalmemory to store edits, adaptively altering the basemodels predictions by retrieving relevant edits. Inour study, we leverage a LLM to focus on userpersonal memories rather than global knowledge.Additionally, we support dynamic user edits onthe EMG and utilize RAG with a frozen LLM torespond to these changes.",
  "Problem Statement": "We study the problem of developing personalizedagents for users on smartphone AI assistant plat-forms (such as Apples Siri or Samsungs Bixby).These agents are designed to assist users in perform-ing personalized tasks, requiring the fulfillment ofthe following two properties in practical scenarios: - Editability: The responses from the agents maybe editable based on the users dynamic memorydata, which involves insertion, deletion, and re-placement operations corresponding to differentusage scenarios, as illustrated in (a). - Selectability: The agents can select relevantmemories to respond to users queries, with somequeries requiring the combination of multiplememories to generate responses through a baselanguage model, as illustrated in (b). By satisfying these properties, the agents aimto enhance the user experience during interactionswith their smartphone AI assistants. These agentsoffer essential functionalities to support personal-ized applications, including question answering,autofill forms, and user services like reminders forimportant events and times, and travel navigation(further details will be discussed in .4).",
  "Data Collection": "The process entails (1) gathering raw data, such aseveryday conversations or screenshots from userinteractions with the smartphone AI assistants; (2)extracting crucial information from this raw data,referred to as memories (denoted by M); and (3)generating QA pairs (denoted by < Q, A >), andoutputting the required memories to facilitate thispairing. For (1), we acquire data from real AIassistant products and employ text processing tech-niques like OCR to extract content from screen-shots. Subsequently, for (2) and (3), we leverage My boss is going to Amsterdam for abusiness trip next month, and I need tohelp him arrange the flight and hotel.I suggest booking a convenientlylocated hotel and confirming all travelarrangements in advance. I've already booked the EK349 flight formy boss and the Crowne Plaza hotelnear Central Station. That's a very considerate arrangement.The location of the hotel is indeedconvenient. The boss will be satisfied. Booking Time 2024-04-15 Order number: I2109459340",
  "Completed": ": An example of data collection. Step-1: Raw data is gathered on smartphone AI assistant platforms, e.g.,everyday conversations between users and assistants, and the extraction of app screenshot contents through OCR. : An example of data collection. Step-2: GPT-4 generates memories from raw data. Step-3: GPT-4 formsQA pairs using several memories, and produces the required memories, which are utilized for training the EMG-RAG.",
  "Step-2: Memories (generated by GPT-4)Step-3: QA pairs with memories (generated by GPT-4)": "M1: My boss is traveling to Amsterdam next month,I assist with flight and hotel arrangements.Q: What time is my bosss flight to Amsterdam?A: Your boss flight EK349 departs at 01:40 on 2024-05-12.Required memories: M1, M2, M4M2: I booked the EK349 flight.M3: I booked the Crowne Plaza near Central Station.M4: The EK349 flight departs at 01:40 on 2024-05-12.",
  "M5: The Crowne Plaza reservation is for2024-05-12 to 2024-05-18.M6: The Crowne Plaza reservation includes a QueenBed Standard Accessible room with breakfast": "the capabilities of LLMs, such as GPT-4 (OpenAI,2023), to extract key memories from the raw dataand create QA pairs. These pairs serve the purposeof training personalized agents for the proposedEMG-RAG. To illustrate the collection process, weprovide a running example in and ,which involve the three primary steps. Further de-tails are outlined in Appendix A.1.We discuss the rationales of the data collec-tion. First, as a users personalized agent integratedwithin the smartphone AI assistant, the conversa-tions and screenshots provide natural data sourcesfor crafting these agents. Second, leveraging GPT-4s language generation capabilities enables us togenerate a wide range of memories from the rawdata, significantly reducing manual effort. Third,the involved memories and collected QA pairsserve as labels to supervise the training of the re-trieval and generation processes in our framework.",
  "Editable Memory Graphs": "The EMG Construction and Insights. Utilizing ausers memories, we establish the Editable MemoryGraph with a multilayered structure, depicted in(a), where the user is the root node.Memory Type Layer (MTL): Aligned with thebusiness scope, we categorize memories into 4 pre-defined types: Relationship, Preference, Event, andAttribute. Details are provided in Appendix A.2. Memory Subclass Layer (MSL): The MSL fur-ther outlines subclasses for each type, where theMTL and MSL are organized in a hierarchical treestructure to manage the memories. Detailed sub-classes with examples are listed in Appendix A.2.Memory Graph Layer (MGL):The memorygraph is built by utilizing the collected memories,employing entity recognition for nodes and relationextraction for edges. In this graph, each in-degreenode is associated with its corresponding mem-ory, e.g., the in-degree node (01:40 on 2024-05-12)contains M4, as shown in (a). Further,to establish the connection between the MSL andMGL, TransE embeddings (Bordes et al., 2013) areemployed to capture semantic information of nodesin MSL (subclasses) and MGL (entities), respec-tively. Then, each entity is assigned to its closestclasses based on these embeddings. It is notewor-thy that entity nodes are categorized into differentsubclasses, and their connections may span acrossdifferent classes, e.g., Boss and Amsterdamare linked across Colleague and Arrangementclasses in (a). This design enables furthertraversal across various parts of the whole graph.We discuss the insights of the EMG construction:1) the tree hierarchy (MTL and MSL) offers a parti-tioned memory management approach, to facilitatethe expansion of additional types and subclasses inaccordance with business needs; 2) the entity nodes",
  "Voucher": "$20 off SeatNo ExpireBy 2024-05-14 LocatedNearCheckIn CheckOut DepartAt TravelTo BookHotelBookFlight M8 : What time is my boss's flight to Amsterdam? LLM : Your boss flight EK349departs at 01:30 on 2024-05-12 What time is my boss's flight toAmsterdam? Your boss flight EK349 departsat 01:30 on 2034-05-12 Joey, your boss flights to Amst. today, Please remind him. ReminderSingaporeAmsterdam 2024-05-12 01:30 Passenger 1 Adult Contact Jam Nationality Singapore Passport S1234567E Mobile No. +65-12345678 Question AnsweringAutofill FormsUser Services (c) Downstream Applications MTL Nodes MSL Nodes",
  "Travel": "Navigate to my hotel : The architecture of the proposed EMG-RAG, demonstrated with the running example in data collection(.1). It supports three editability operations: insertion (e.g., M7), deletion (e.g., M8), and replacement(e.g., M9), based on the EMG structure (.2). Subsequently, the edited EMG undergoes RAG to selectrelevant memories (e.g., M1, M2, M9) for a given question Q via a MDP (.3). The generated answers Aby a frozen LLM further facilitates three downstream applications (.4). and corresponding memories are organized intoseparate subclass partitions, with the graph struc-ture (MGL) to capture their complex relationshipsbetween memories; 3) it enables efficient retrievalof memories for further editing operations by firstlocating a relevant partition, e.g., querying parti-tion centers (the mean of the memory embeddings),instead of searching through all memories. The EMG Editing. When editing a given mem-ory within the EMG (e.g., insertion, deletion, orreplacement), the process involves three steps. Ini-tially, a model such as CPT-Text (Neelakantan et al.,2022) is employed to acquire memory representa-tions. Then, the memory is assigned to its nearestsubclass (partition), and the Top-1 retrieved mem-ory within the partition is then returned, and edit-ing operations are performed based on comparingthe relations between the given memory and theretrieved memory. Specifically, as illustrated in, (1) Insertion: It introduces a new relationto be added, e.g., obtaining a new memory contain-ing flight seat number. (2) Deletion: It introduces anew relation, but it is valid for a specific period oftime. e.g., a hotel voucher will expire on May 14,2024. (3) Replacement: It provides an existing re-lation, and updates the corresponding entity nodesbased on this relation, e.g., changing the departuretime to 01:30 on May 12, 2024.",
  "MDP for Selecting Memories on EMGs": "Next, we outline the task of selecting memoriesbased on an edited EMG. To achieve this, we em-ploy an agent to traverse the EMG. Specifically,given a question Q, the agent selects a set ofmemories from the EMG denoted by M = {Mi},where 1 i |M|. The question Q and mem-ory set M are concatenated to generate an answerA LLM(Q M) using a LLM. We assess thegeneration quality using ( A, A), where A repre-sents the collected ground truth answer for Q, and(, ) denotes a specific metric (e.g., ROUGE (Lin,2004) or BLEU (Post, 2018)). We note that a high-quality answer A benefits from the selected mem-ories M, which can then provide feedback with(, ) for subsequent selections. As a result, it iter-ates in a boosting process, and we optimize it usingreinforcement learning. The environment, states,actions, and rewards are introduced below.Constructing Environment (Nodes activated byQuestions). Given an EMG, which often containsnumerous memories in practice. Here, we confinethe movement of the RL agent to a subset of memo-ries to facilitate more focused selection. To achievethis, we first retrieve Top-K memories for a givenquestion Q, and based on these memories, we ac-tivate the corresponding nodes on the EMG (e.g.,the nodes highlighted in yellow in (b)). Subsequently, the agents traversal starts from eachactivated node via depth-first search.Modeling Memory Selection (Nodes activatedby MDPs). We model the graph traversal processas a MDP, involving states, actions, and rewards.States: In the context where we have an inputquestion Q, and visit a node NG (associated with amemory Mi to be included into M), and its relationRG on the EMG. We first extract the entity NQ andrelation RQ from the Q, and the state s is definedby three cosine similarities C(, ), i.e.,",
  "s = {C(vNQ, vNG), C(vRQ, vRG), C(vQ, vMi)},(1)": "where v denotes the embedding vector for entities,relations, questions, or memories.Actions: We denote an action as a, and it hastwo choices during the graph traversal: includingthe visiting memory Mi into M, and searching itsconnected nodes; or stopping the current search,and restarting a search from other branches. Thus,the action a is defined as:",
  "a = 1 (including) or 0 (stopping).(2)": "Consider the consequence of performing an action,it transitions the environment to the next state s,and affects which memory to be selected for con-structing the state.Rewards: We denote the reward as r, which cor-responds to the transition from the current state stto the next state st+1 after taking action at. Specif-ically, when a memory M is selected into M, thegenerated answer by a LLM changes from A to A",
  "r = ( A, A) ( A, A),(3)": "where A denotes the ground truth answer. We notethat the objective of the MDP, which aims to max-imize cumulative rewards, aligns with the goal ofdiscovering memories to answer the question. Toillustrate, consider a process through a sequenceof states: s1, s2, ..., sN, concluding at sN. Therewards received at these states, except for the ter-mination state, can be denoted as r1, r2, ..., rN1.When future rewards are not discounted, we have:",
  "(4)": "where ( AN, y) corresponds to the result of thefinal answer found throughout the entire iteration,and ( A1, y) represents an initial result that re-mains constant. Therefore, maximizing cumulativerewards is equivalent to maximizing the quality ofthe final generated answer. Training Policies of MDPs. Training the MDPpolicy involves two stages: warm-start stage (WS)and policy gradient stage (PG). In WS, we employsupervised fine-tuning to equip the agent with thebasic ability to select memories given a question Q.Specifically, based on a state s, the agent undergoesa binary classification task to predict whether thememory Mi should be included. This prediction issupervised according to whether the memory fallsinto the required memories (presented in the Step-3 in ). Thus, the objective is trained withbinary cross-entropy, formulated as:",
  "LWS = y log(P) + (y 1) log(1 P),(5)": "where y denotes the label (1 if the memory fallsinto the required memory set, and 0 otherwise), andP is the predicted probability of the positive class.In PG, our main objective is to develop a policy(a|s) that guides the agent in selecting actionsa based on constructed states s, aiming to maxi-mize the cumulative reward RN. We utilize theREINFORCE algorithm (Williams, 1992; Silveret al., 2014) for learning this policy, where the neu-ral network parameters are denoted by . The lossfunction is formulated as:",
  "Discussion on Applications and Cold-start": "Applications of the Personalized Agents. Asshown in (c), we explore the capabilities ofpersonalized agents in three scenarios: (1) questionanswering, (2) autofill forms, and (3) user services.For (1), EMG-RAG can generate answers to usersquestions when they interact with the smartphoneAI assistants. For (2), the goal is to extract personal information from users EMGs to automatically fillout various online forms, such as flight and hotelbookings. To achieve this, we input form-relatedquestions (e.g., What is the users mobile num-ber?) into the LLM and use the generated enti-ties to complete the forms. For (3), we focus ontwo specific domains. a) reminder service: It in-volves reminding users of recent events and times.To achieve this, we query a LLM for informationabout a users recent events and their associatedtimes. b) travel service: We assist users with nav-igation by providing the address of a destinationthey might want to visit. Further, we integrate thegenerated answers (e.g., events, times, addresses)with external tools such as calendar or map apps toprovide the services for users. Handling the Cold-start Problem. Given thatEMG-RAG relies on generated questions for train-ing, it may encounter a potential cold-start issuewhen deploying to answer real user questions. Toaddress this issue, we utilize online learning to con-tinuously fine-tune the agent using newly recordedquestions and manually written answers, as out-lined in Equation 6. This approach aims to ensurethat the models policy remains up-to-date for on-line usage. We validate this method through onlineA/B testing, and the results demonstrate improve-ments in user experience, highlighting the positiveimpact of this strategy in practice.",
  "Experimental Setup": "Dataset and Ground Truth. We conduct experi-ments on a real-world business dataset containingapproximately 11.35 billion raw text data (includ-ing conversations and screenshot contents) from anAI assistant product collected between March 2024and June 2024. After data cleaning, the datasetforms around 0.35 billion memories. We follow thedata distribution to randomly sample 2,000 usersfor training and 500 users for testing.As detailed in .1, we establish theground truth for the applications of question an-swering and autofill forms/user services using GPT-4 generated answers and key entities (e.g., identi-fication number, address, and time), respectively.We provide a quality evaluation for the collecteddataset in .2.Baselines.We compare EMG-RAG with the fol-lowing RAG methods. 1) NiaH (Briakou et al.,2023): It simply inputs all of the users memo- ries into a LLM within the context window size togenerate the answer. 2) Naive (Ma et al., 2023):It implements a basic RAG execution process in-volving indexing, retrieval, and generation. 3) M-RAG (Wang et al., 2024): It partitions a databaseand employs Multi-Agent RL to train two agentsfor RAG. Agent-S selects a database partition,while Agent-R refines the stored memories withinthat partition to generate a better answer. In ouradaptation, we omit Agent-R since, in our scenario,the generated answers must be grounded in theusers personal memories, which cannot be altereddue to potential risks. 4) Keqing (Wang et al.,2023a): The knowledge graph-based method de-composes a question into sub-questions, retrievescandidate entities, generates answers for each sub-question, and then integrates them into a compre-hensive final answer.In addition, we integrate the RAG methods intothree typical LLM architectures. 1) GPT-4 (Ope-nAI, 2023) is a Transformer-based pre-trainedmodel known for its human-level performance. 2)ChatGLM3-6B (Du et al., 2022) is a long-text di-alogue model with a sequence length of 32K. 3)PanGu-38B (Ren et al., 2023) is a dialogue sub-model of the PanGu series, which follows a Mix-ture of Experts (MoE) architecture.Evaluation Metrics. We evaluate the effectivenessof EMG-RAG in three downstream applications. Forquestion answering, we assess the quality of gener-ated answers with the ground truth, and reportingROUGE (R-1/2/L) (Lin, 2004) and BLEU (Post,2018) scores.For autofill forms and user ser-vices, we generate key entities and report ExactMatch (EM) accuracy. Overall, higher values (i.e.,ROUGE, BLEU, EM) indicate better results 1.Implementation Details. We implement EMG-RAGand other baselines in Python 3.7, using theFaiss library 2 for index construction. We utilizeTransE (Bordes et al., 2013) to obtain embeddingsof entities and relations, and CPT-Text (Neelakan-tan et al., 2022) to obtain embeddings of questionsand memories. The RL agent is implemented witha two-layer neural network, where the hidden layerconsists of 20 neurons and uses the tanh activationfunction. The output layer has 2 neurons corre-sponding to the action space. Several built-in RLcodes are available in (Wang et al., 2021; Zhanget al., 2023b). The hyperparameter K for activated",
  "w/o Act. Nodes90.9682.7286.1365.07w/o WS92.9582.5286.4969.13w/o PG90.5980.6986.1965.65": "nodes is empirically set to 3. We generate 1,000episodes for the warm-start stage and 100 episodesfor the policy gradient stage. We use the Adamstochastic gradient descent with a learning rate of0.001 to optimize the policy, and the reward dis-count is set to 0.99. We cache the generated QApairs 3 during training to boost efficiency.",
  "Experimental Results": "(1) Effectiveness evaluation (question answer-ing). We compare the EMG-RAG with other RAGmethods for question answering on three LLMs. Asshown in , we observe that the performanceof EMG-RAG consistently outperforms the baselines.For example, it improves upon the best baselinemethod, M-RAG, by 5.3%, 8.3%, 3.9%, and 18.4%in terms of R-1, R-2, R-L, and BLEU, respectively.This improvement is due to two main factors: 1) itcaptures complex relationships between memorieswith the EMG, and 2) it effectively selects essentialmemories for the RAG execution. Additionally,GPT-4 demonstrates superior performance com-pared to other LLMs, and EMG-RAG shows compa-rable performance to M-RAG even when deployedon the relatively smaller ChatGLM3-6B.(2) Effectiveness evaluation (autofill forms). We",
  "further evaluate the EMG-RAG for autofill forms, andit shows consistent improvement, as detailed in. For example, it surpasses M-RAG by 2.2%in terms of exact match accuracy": "(3) Effectiveness evaluation (user services). Wetarget two specific domains of user services: 1)reminders of important events and their times, and2) travel services involving destination addressesfor navigation. We report the exact match accuracyfor events and times (reminders), and addresses(travel) in . The improvements over M-RAGfor the two tasks are 2.9% and 5.5%. (4) Effectiveness evaluation (continuous edits).We evaluate the effectiveness of EMG-RAG in sup-porting continuous edits over a period of 4 weeks.The results, in terms of R-L for question answering(QA), and exact match accuracy for autofill forms(AF) and user services (US, combining reminderand travel results), are presented in . Weobserve that EMG-RAG consistently outperforms M-RAG, by approximately 10.6%, 9.5%, and 9.7%for QA, AF, and US, respectively. This is owing tothe editability of EMG-RAG, whereas M-RAG sim-ply incorporates edits into a database, where manymemories may become outdated for answering. Ad-ditionally, we report the total number of edits in-volved in the testing set for each week. (5) Ablation study. To evaluate the effectivenessof different components in EMG-RAG, we conduct anablation study. (1) We omit the design of activatednodes, and the search starts from the root of EMG.(2) We remove the warm-start stage (WS) and onlytrain the policy in the policy gradient stage (PG).(3) We remove the PG and use the WS only. For",
  "QA88.0691.994.5%AF92.8695.853.2%US94.6697.563.1%": "(1), it results in a performance drop (e.g., R-1 from93.46 to 90.96), because many irrelevant memories(as noises) may be retrieved if the search starts fromthe root. For (2) and (3), we observe that the PGcontributes the most to the result (e.g., R-1 from93.46 to 90.59), because it can explicitly optimizethe performance end-to-end, and WS provides abasic memory selection ability for the agent.(6) Parameter study (K for activated nodes). Wevary the value of K from 1 to 5 and report the R-Lscore for the question answering task, along withthe corresponding inference times. As shown in, we observe that K = 3 provides the besteffectiveness while maintaining reasonable infer-ence time. When K is smaller, the limited numberof activated nodes for graph traversal restricts theability to find crucial memories. Conversely, whenK is larger, it activates many nodes and returnsnumerous memories, potentially introducing noisethat hinders the LLM generation. As expected, theinference time increases as K increases.(7) Online A/B test. We perform an online A/B testover one month to compare the new system withthe existing one. During this period, we collectreal users questions and manually written answersto fine-tune the model. The results, presented in, show further improvements across all ap-plications. It highlights a cold-start problem causedby distributional shifts between questions gener-ated by GPT-4 and those posed by real users. Weuse GPT-4-generated questions for model trainingbecause they cover diverse scenarios and allow forthe automatic collection of required memories, en-abling large-scale training. Once the trained modelis deployed, we fine-tune it using real user ques-tions and manually written answers through onlinelearning as described in .4.(8) Data quality evaluation. We evaluate dataquality across three data collection steps. For Step-1, we note that OCR is a well-established technol-",
  "Human Evaluation91.1%87.5%97.4%GPT-4 Evaluation93.3%98.7%99.3%": "ogy used to extract information from app screen-shots in our study. Given that the printed fontsfrom apps are typically standard, OCR is not ex-pected to face significant challenges. For Step-2and Step-3, we utilize the powerful GPT-4 modelfor memory and QA pair collection and assess qual-ity from two perspectives: (1) Qualitatively: Wepresent memory samples from our focus domainsas shown in , which generally meet the ex-pected precision. (2) Quantitatively: We assessquality using human evaluation and LLM evalu-ation. The results are reported in . Forhuman evaluation, we randomly selected 10% ofthe user data and asked five participants to annotatethe answers (for QA) and entities (for AF and US)based on the collected questions and memories. Bycomparing the human-annotated answers and en-tities with those generated by GPT-4, we report aR-L score of 91.1% for QA and exact match scoresof 87.5% for AF and 97.4% for US. These resultsdemonstrate the high accuracy of the collected data.For LLM evaluation, we employ a method whereGPT-4 self-verifies whether it can generate answers(or entities) that are consistent with those obtainedduring the data collection, based on the collectedquestions and required memories. The evaluationreveals the scores of 93.3%, 98.7%, and 99.3% forthe three applications, respectively, demonstratinga high level of consistency and effectiveness.",
  "Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding,Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022. Glm:General language model pretraining with autoregres-sive blank infilling. In ACL, pages 320335": "Dongge Han, Trevor McInroe, Adam Jelley, Stefano VAlbrecht, Peter Bell, and Amos Storkey. 2024. Llm-personalize: Aligning llm planners with human pref-erences via reinforced self-training for housekeepingrobots. arXiv preprint arXiv:2404.14285. WANG Hongru, Rui Wang, Fei Mi, Yang Deng, WANGZezhong, Bin Liang, Ruifeng Xu, and Kam-FaiWong. 2023. Cue-cot: Chain-of-thought promptingfor responding to in-depth dialogue questions withllms. In EMNLP (Findings), pages 1204712064. Ziniu Hu, Ahmet Iscen, Chen Sun, Zirui Wang, Kai-Wei Chang, Yizhou Sun, Cordelia Schmid, David ARoss, and Alireza Fathi. 2023. Reveal: Retrieval-augmented visual-language pre-training with multi-source multimodal knowledge memory. In CVPR,pages 2336923379. Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye,Wayne Xin Zhao, and Ji-Rong Wen. 2023. Struct-gpt: A general framework for large language modelto reason over structured data.arXiv preprintarXiv:2305.09645.",
  "Alec Radford, Karthik Narasimhan, Tim Salimans, IlyaSutskever, et al. 2018. Improving language under-standing by generative pre-training": "Xiaozhe Ren, Pingyi Zhou, Xinfan Meng, XinjingHuang, Yadao Wang, Weichao Wang, Pengfei Li,Xiaoda Zhang, Alexander Podolskiy, Grigory Arshi-nov, et al. 2023. Pangu-{\\Sigma}: Towards trillionparameter language model with sparse heterogeneouscomputing. arXiv preprint arXiv:2303.10845. Pedro Ribeiro, Pedro Paredes, Miguel EP Silva, DavidAparicio, and Fernando Silva. 2021. A survey onsubgraph counting: concepts, algorithms, and ap-plications to network motifs and graphlets. ACMComputing Surveys (CSUR), 54(2):136. Yiheng Shu, Zhiwei Yu, Yuhan Li, Brje Karlsson,Tingting Ma, Yuzhong Qu, and Chin-Yew Lin. 2022.Tiara: Multi-grained retrieval for robust questionanswering over large knowledge base. In EMNLP,pages 81088121.",
  "Julian R Ullmann. 1976. An algorithm for subgraphisomorphism. Journal of the ACM (JACM), 23(1):3142": "Chaojie Wang, Yishi Xu, Zhong Peng, Chenxi Zhang,Bo Chen, Xinrun Wang, Lei Feng, and Bo An. 2023a.keqing: knowledge-based question answering is a na-ture chain-of-thought mentor of llm. arXiv preprintarXiv:2401.00426. Hongru Wang, Minda Hu, Yang Deng, Rui Wang, FeiMi, Weichao Wang, Yasheng Wang, Wai ChungKwan, Irwin King, and Kam-Fai Wong. 2023b.Large language models as source planner for person-alized knowledge-grounded dialogues. In EMNLP(Findings), pages 95569569.",
  "A.1Data Collection Details": "The data collection process involves three key steps,which are presented below:Step-1: Raw Data Collection. We explore twoapproaches, termed Active Remember (AR) andPassive Remember (PR), for collecting raw dataderived from users daily conversations with AI as-sistants and screenshots from their apps. With AR,the AI assistant is trained to actively classify data(such as conversation sentences) into supportedsubclasses outlined in , and filter out noisedata. With PR, users have the option to directlylet the assistant to remember specific content forfuture use. Leveraging AR and PR, we remove asignificant volume of trivial data, and then extractmemories from the refined dataset.Step-2: Memory Data Construction. We uti-lize a LLM, such as GPT-4, with the refined datasetto generate structured memories from the raw data.Additionally, we integrate various natural languageprocessing techniques, including absolute date andtime conversion, entity anaphora resolution, andevent coreference resolution, to further clean thememories and facilitate graph construction.Step-3: QA Pairs Construction. We organizethe memory data chronologically and partition itinto separate conversation sessions. Then, a LLMgenerates QA pairs for each session. To createcomplex questions for targeted training, such asthose requiring multiple memories for answering,we explicitly instruct the LLM to utilize multipleassociative relationships between memories to gen-erate questions, ensuring that at least one or morememories are needed for accurate responses.",
  "A.2Memory Types and Subclasses": "We describe the 4 memory types: (1) Relationship,which involves recognizing users surrounding rela-tionships and attributes of related individuals, suchas birthdays and names of family members; (2)Preference, where we identify users likes and dis-likes for various topics or entities; (3) Event, fo-cusing on key event information about users, suchas their status, recent experiences, and upcomingschedules; and (4) Attribute, encompassing userspersonal details such as name, gender, age, posses-sions, and other relevant information.We enumerate the supported business subclassesof the EMG with memory examples in .",
  "A.3Further Discussion": "Q1. The necessity of using a graph if the usermemory size is small.We analyze the user memory size based on sta-tistical data. We list the number of memories gen-erated from user interactions with the intelligentassistant over the past one day, in descending order:the Top-1,000 user has 296 memories; the Top-10,000 user has 101 memories; and the Top-20,000user has 72 memories. Notably, around 20,000users produce at least 70 memories each day, andthe memory size increases over time. These usersrepresent a significant portion that should not beoverlooked, necessitating a graph structure (suchas EMG) for effective management.Moreover, using a graph enhances effectivenessby naturally capturing semantic relationships be-tween memories, which improves reasoning duringRAG. As demonstrated by the experimental resultsin and , our approach outperformsthe NiaH, Naive, and M-RAG baselines, achiev-ing approximately a 10% improvement over thebest baseline M-RAG, which manages the memoryinstances independently.Q2. What would be the storage and compu-tation costs of EMG if the number of users islarger? Is it possible to share some commonpatterns of different users in this design?We clarify that EMGs are independently man-aged and computed on each users personal de-vice, and the storage and computation costs arenot impacted by the number of users in practice.To reduce storage costs, we consider a potentialsolution of sharing common patterns across differ-ent users EMGs. We aim to mine common sub-graph patterns using classic subgraph isomorphismalgorithms (Ribeiro et al., 2021; Ullmann, 1976;Cordella et al., 2004). On the server side, we willmanage the common patterns identified by GraphID (GID), and link user-specific data identified byUser ID (UID) to them. On the user side, GIDsand UIDs will replace the corresponding data inthe EMGs, minimizing duplication across differentusers EMGs.Q3. Privacy discussions in data collection andmodel training, e.g., is the model trained in asingle user-based? Will the model output otherusers information during inference?In data collection, we clarify that the data is col-lected solely for individual use to provide relevantapplications. Each users EMG is independently",
  "OccupationI am a research scientist": "built based on the collected data, and will not beshared. Additionally, all user information presentedin this research has been de-identified.In model training, we use a single-user approachand address privacy concerns as follows: (1) EMGsare independently managed for each user and arenot shared. (2) The RL agent is a simple neuralnetwork that includes or excludes nodes (actions 1or 0) in the personal graph. (3) The LLM remainsfrozen, ensuring it does not memorize user data oroutput information from other users.",
  "Please help me organize the following raw user data into standardized memory data": "Here is an example format:1. My name is Zhang Zhenqiang.2. My zodiac sign is Aquarius.3. My companys address is Oriental International, Pudong New District, Shanghai.4. My mothers birthday is April 8, 1982.5. My fathers favorite sport is basketball.6. I watched the movie Fast and Furious at Orange Cinema in July 2023.7. Next Saturday, I will attend a high school friends wedding.",
  ": Prompt for generating reasoning as the required memories for QA pairs": "You have many memories from one person. Explore all possible associations, including multi-hopand connections around the same event, person, or entity. Records can intersect between differentassociations. Here is an example: Assume the following memory records exist:{ID: 1, Memory Content: Recently, my sleep hasnt been good and lacks deep sleep.,Memory Location: Lychee Garden Apartment, Longgang District, Shenzhen, GuangdongProvince, Memory Time: 2024-04-22 08:31:19}{ID: 2, Memory Content: My girlfriend likes to eat durian., Memory Location: WuheAvenue, Longgang District, Shenzhen, Guangdong Province, Memory Time: 2021-11-1415:31:54}{ID: 3, Memory Content: Baiguoyuan is having a durian promotion next week, and I wantto buy some., Memory Location: Tianan Cloud Valley Building 1, B Section, XuegangNorth Road, Longgang District, Shenzhen, Guangdong Province, Memory Time: 2022-10-1009:30:27} Based on the above memory records, you can extract multiple sets of associations as follows:The memory mentions that your girlfriend likes to eat durian (Memory Point 2), and Baiguoyuanis having a durian promotion next week (Memory Point 3). You could buy some durian fromBaiguoyuan during the promotion, so these memories are related (Memory Points 2|3). Please extract the associations from the following memory records as thoroughly as possible basedon the above example. Multi-hop reasoning relationships, associations around the same event,person, or entity can all be considered as existing connections. Memory records within eachassociation group can intersect; for example, a memory point appearing in one set of associationscan also appear in another set if it is reasonable. Please meet the above requirements and return theoutput following the example. + {memories}",
  ": Prompt for generating QA pairs": "You currently have a set of historical memory records from the same mobile user and hints ofmultiple associations between these memories. Based on all the memory information and theirassociations, design some intent statements or questions with the corresponding answers outputtingas <questions, answers> for the mobile assistant that require at least one memory record to providean accurate response. Below is an example: Example:Given the following memory records:{ID: 1, Memory Content: Recently, my sleep hasnt been good and lacks deep sleep.,Memory Location: Lychee Garden Apartment, Longgang District, Shenzhen, GuangdongProvince, Memory Time: 2024-04-22 08:31:19}{ID: 2, Memory Content: My girlfriend likes to eat durian., Memory Location: WuheAvenue, Longgang District, Shenzhen, Guangdong Province, Memory Time: 2021-11-1415:31:54}{ID: 3, Memory Content: Baiguoyuan is having a durian promotion next week, and I wantto buy some., Memory Location: Tianan Cloud Valley Building 1, B Section, XuegangNorth Road, Longgang District, Shenzhen, Guangdong Province, Memory Time: 2022-10-1009:30:27} Based on the above memory information, there are the following association hints:Your girlfriend likes durian (Memory 2), and Baiguoyuan has a durian promotion next week(Memory 3). You could buy some durian at Baiguoyuan during the promotion. These memories arerelated around durian (Memory 2|3). Based on the above memory information and associations, you can construct the following intentstatements or questions:I want to buy something delicious for my girlfriend. Any recommendations? (Requires Memory2|3)The corresponding answers:You could buy some durian at Baiguoyuan during the promotion Please construct intent statements or questions from the following memory information and associ-ations, meeting all of the following requirements:1. The statements or questions should be directed from the user to the mobile assistant, notquestions from the assistant to the user (important requirement).2. They should require at least one memory record to provide an accurate response (importantrequirement).3. Keep the content concise and avoid including details already mentioned in the memory records(important requirement).4. Avoid intent statements or questions related to reminders (important requirement).5. Include both questions and casual statements (important requirement).6. End with the required memory points for response in parentheses (important requirement).",
  ": Prompt for synthesizing memories": "Please act as a conversation context manager and help me generate personal memory-related data.Below are some examples; please use them as a reference for generating memory data:{ID: 1, Memory Content: My girlfriend likes to eat durian., Memory Location: WuheAvenue, Longgang District, Shenzhen, Guangdong Province, Memory Time: 2021-11-1415:31:54}{ID: 2, Memory Content: Baiguoyuan is having a durian promotion next week, and I wantto buy some., Memory Location: Tianan Cloud Valley Building 1, B Section, XuegangNorth Road, Longgang District, Shenzhen, Guangdong Province, Memory Time: 2022-10-1009:30:27} The generated data should meet the following requirements:1. The memory data is generated from conversations with a mobile assistant and reflects everydayscenarios. The protagonist is a single individual. You may create realistic content including, butnot limited to, basic information about the individual and their family and friends (birthdays,anniversaries, zodiac signs, ID information, passport information, bank card information, etc.),events (meetings, gatherings, travels, renovations, etc.), and order information (movie tickets, hotelreservations, train tickets, flight tickets, etc.). Make sure there are no logical conflicts between thegenerated data.2. The memories should exhibit logical multi-step reasoning and not be completely unrelated.For example: My moms older brother is named Li Aiguo and My uncles address is a smallshop next to Tiananmen Square. These two memories are linked through the fact that my momsolder brother (my uncle) acts as a reasoning hub, allowing me to deduce that Li Aiguos address isthe small shop next to Tiananmen Square.3. Ensure that there are no real-world logical conflicts between memory content, locations,and times. For example, earlier memories should have earlier timestamps than later ones. Avoidgenerating two memories with locations far apart within a short timeframe, such as a memory fromBeijing at 20:15:47 and another from Guangzhou at 20:16:20 on the same day.4. Memory locations can include scenarios like business trips and travel; they do not all need tobe in the same city. Memories can be generated in multiple cities."
}