{
  "Abstract": "Large Language models (LLMs) have exhib-ited remarkable abilities in understanding com-plex texts, offering a promising path towardshuman-like translation performance. However,this study reveals the misalignment betweenthe translation-specific understanding and thegeneral understanding inside LLMs.Thisunderstanding misalignment leads to LLMsmistakenly or literally translating some com-plicated concepts that they accurately com-prehend in the general scenarios (e.g., QA).To align the translation-specific understand-ing to the general one, we propose a noveltranslation process, DUAT (Difficult wordsUnderstanding Aligned Translation), explic-itly incorporating the general understandingon the complicated content incurring incon-sistent understanding to guide the translation.Specifically, DUAT performs cross-lingual in-terpretation for the difficult-to-translate wordsand enhances the translation with the gener-ated interpretations. Furthermore, we reframethe external tools to improve DUAT in detect-ing difficult words and generating helpful in-terpretations. We conduct experiments on theself-constructed benchmark Challenge-WMT1,consisting of samples that are prone to mis-translation. Human evaluation results on high-resource and low-resource language pairs in-dicate that DUAT significantly facilitates theunderstanding alignment, which improves thetranslation quality (up to +3.85 COMET) andreduces the literality of the translation by - 25% - 51%.",
  "when explaining its meaning": ": Illustration of the misalignment betweenthe general understanding (Fig a) and the translation-specific language understanding (Fig b) inside the LLM(gpt-3.5-turbo-0125). More examples are reportedin Appendix A. 2023). However, existing research reports thatLLMs have yet to achieve as significant advances inmachine translation as they have achieved in othernatural language processing fields (Hendy et al.,2023; Pang et al., 2024; Zhang et al., 2023a; Jiaoet al., 2023; Zhu et al., 2023b). In this study, we discover the misalignment be-tween the general understanding and translation-specific understanding inside LLMs, as illustratedin . This understanding misalignment leads toLLMs mistakenly or literally translating some com-plicated concepts that they accurately comprehendin general scenarios. We refer to these failures aslanguage models generalization failures on trans-lation. Human evaluation on a total of 600 sam-pled sentences across six language pairs show thatgeneralization failures account for a considerableproportion of all mistranslations (16%-32%), indi-cating serious understanding misalignment (6.1). To align the translation-specific understandingto the general one, we propose a novel transla-tion process, DUAT (Difficult words Understand-ing Aligned Translation), explicitly incorporatingthe general understanding on the complicated con- tent incurring inconsistent understanding to guidethe translation. Specifically, DUAT first detects thedifficult-to-translate words in the source sentence,which could cover the generalization failures in-tuitively. Next, the LLM is prompted to interpreteach difficult word with the target language, i.e.,cross-lingual interpretation, unleashing the pow-erful general understanding and transforming thisunderstanding into the target language space. Afterthat, DUAT conducts translation under the guid-ance of these interpretations. Unlike the CoT-basedprocess mimicking junior translators to sequen-tially translate all words (Peng et al., 2023), DUATworks like senior translators to analyze the compli-cate words, which helps the model deep understandthe source sentence and produces more nuancedtranslations. Furthermore, we reframe the externaltool of token-level QE (Rei et al., 2023) to enhancethe detection of difficult words, and design a strat-egy of interpretation quality control to filter hal-lucinated interpretations based on sentence-levelQE (Rei et al., 2020).To better analyze the understanding misalign-ment, we proposed the Challenge-WMT bench-mark, which contains more sentences prone to mis-translation. These sentences were collected frommulti-year WMT datasets and represent difficultsamples that multiple state-of-the-art (SOTA) sys-tems translate poorly. Human evaluation resultsindicate that DUAT significantly facilitates the un-derstanding alignment, reducing 80%88% of gen-eralization failures. Moreover, this alignment im-proves the translation quality, as evidenced by auto-matic metrics (up to +3.85 COMET), and alleviatestranslation literalness by -25% -51%.",
  "LLM-based MT": "Considering the translation from source languageLs to target language Lt, LLM-based machinetranslation converts the source sentence x to an in-struction using a translation-specific template andgenerates the translation by feeding the instructionto the LLM . To make the LLM better followthe instruction, the in-context learning (ICL) strat-egy (Brown et al., 2020; Dong et al., 2023) injectsa few examples/demonstrations of translation intothe instruction, which is shown as:",
  "Quality estimation (QE)": "QE for machine translation, i.e., reference-free MTevaluation, aims to predict the quality of the giventranslation only according to the source sentence,which has shown auspicious correlations with hu-man judgments (Rei et al., 2020, 2021). Given asource sentence x and a translation y, QE score isdenoted as (y | x).Thanks to the recent advance in the interpretabil-ity of neural MT metrics (Rei et al., 2023), token-level QE is proposed to score the error degree ofthe given translation span by calculating the mis-alignment of this span against the source sentence.Given a source sentence x and the candidate trans-lation y, token-level QE () annotates the errordegree of the specific span wt in the translation,i.e., (wt | y, x) where wt y.",
  "Approach: DUAT": "In this section, we first introduce our translationframework DUAT (3.1). Specifically, DUAT con-sists of three components: difficult word detection(3.2), cross-lingual interpretation (3.3), and in-terpretation quality control (3.4). To make theLLM follow the procedure of each component asexpected, we adopt the in-context learning strategyand design an automatic method for constructingdemonstrations of DUAT (3.5).",
  "Framework": "The progress of DUAT is illustrated in . Giventhe source sentence, DUAT first detects the diffi-cult words or phrases in the source sentence. Oncethe difficult words are identified, DUAT requeststhe LLM to interpret each difficult word with thetarget language, unleashing the powerful under-standing capability inside the LLM and transform-ing these understandings into the target languagespace. Finally, to avoid the interference of incor-rect and useless interpretations, DUAT removesthe negative interpretations through the interpreta-tion quality control and outputs the final translationguided by the helpful interpretations.",
  "Step-1: Difficult Word Detection": "In practice, we found that directly inquiring LLMsto identify difficult-to-translate words is challeng-ing. To tackle this challenge, we first conduct apreliminary translation for the given source sen-tence and then extract the mistranslated wordsand phrases in the source sentence as the difficultwords. Concretely, we invent DUAT-I to do thisleveraging the Intrinsic ability of LLMs at first. DUAT-I.Given source sentence x, DUAT-I firstobtains the preliminary translation y (also known asdraft translation) by prompting the LLM to trans-late x with the in-context learning strategy, whichis shown in Eq. (1). Next, the LLM is requestedto output the difficult words based on the sourcesentence and the preliminary translation: Request: Given a [Ls] sentence and its draft [Lt] trans-lation, output the mistranslated words and phrases inthe [Ls] sentence.# followed by [ N Demonstrations Ediff ]Source Sentence:[ Given Sentence x ]Draft Translation: [ Draft Translation y ]",
  "where is the LLM, which is prompted with Ndemonstrations of difficult word detection Ediff ={xi, yi, Di}Ni=1": "DUAT-E.It is frequently observed that the LLMfails to recognize the mistranslated words, due totheir limitation in self-knowledge (Yin et al., 2023)Therefore, we devise DUAT-E to boost the de-tection with the External tool. First, DUAT-Erequests the LLM with the same prompt as DUAT-I while performing temperature sampling for Ktimes. Next, the union of all sampling results istaken as the candidate set of difficult words Dcand:",
  "Dcand =Kk=1 Dk P(Ediff, x, y, T),(3)": "where T is the hyperparameter of sampling tem-perature, which is set to 0.5 to capture more candi-dates, and K is set to 5 empirically.Finally, DUAT-E annotates each candidate wordwith its degree of misalignment with respect tothe draft translation, which reflects the translation-specific difficulty. To implement this function, weadopt an external tool of token-level QE (). Asshown in 2.2, token-level QE is originally used toscore the mistranslation degree of the given trans-lation span with respect to the source sentence, i.e.,(wt | y, x) where wt y. Differently, we uti-lize this tool in a dual manner. That is, we use() to annotate the misalignment degree of thegiven source span with respect to the translation,i.e., (ws | x, y ) where ws x. Formally, the mis-alignment score of each difficult word candidate iscalculated as:",
  "where Eintp= {xi, Di, Ai}Ni=1, which is thedemonstrations of the cross-lingual interpretation": "Prob and cons.Under the guidance of generatedinterpretations, DUAT can align the translation-specific understanding to the general one. However,LLMs may generate hallucinated interpretationssometimes (e.g., the interpretation of \"\" in), which biases the resulting translation fromthe original semantics. Besides, helpless interpreta-tions that can not provide useful information alsopose a risk of disturbing the translation process.",
  "Step-3: Interpretation Quality Control": "To overcome the potential interference of the gener-ated negative interpretations, DUAT removes themthrough the interpretation quality control (IQC)and outputs the final translation guided by the help-ful interpretations.Concretely, given a set of interpretations A,DUAT ablates each interpretation Ai sequentiallyand uses the remaining interpretations to guide thetranslation. The interpretation-guided transla-tion is implemented in a fashion of refinement:",
  "y = argmax P(Eigt, x, y, A),(6)": "where Eigt = {xi, yi, Ai, yi}, which is the demon-stration set of interpretation-guide translation.If the better translation performance is achievedby ablation, which is measured by the QE2 tool dueto the unavailable access to the reference transla-tion, the interpretation Ai is removed from A andthe current translation is taken as the best transla-tion. We also detail this process in Alg.1.",
  "Demonstrations Synthesis for DUAT": "To make the LLM follow the procedure of DUATas expected, we adopt the ICL strategy. Commonpractice constructs demonstrations manually, neces-sitating human translators proficient in N (N 1)language pairs for N languages. To overcome thisconsiderable cost, we devise a method for syn-thesizing high-quality demonstrations of DUATbased on parallel data. This process of synthesiz-ing demonstrations is accomplished in a manner ofpost-explanation by asking the LLM to comparethe baseline translation and the reference transla-tion. We describe this process in Appendix B.2.",
  "Testbed: Challenge-WMT": "To better analyze the understanding misalignmentproblem of LLMs, we propose the benchmarkChallenge-WMT, which contains challenge sen-tences that are prone to mistranslation. This bench-mark is constructed by collecting samples that mul-tiple SOTA systems translate poorly from multi-year WMT testsets of six language pairs (Chinese(zh), Estonian (et), and Icelandic (is) to/fromEnglish (en)). Additionally, we believe that thisdataset could promote future research in under-standing the limitations of existing MT systems.We select three SOTA MT systems: GoogleTranslate, ChatGPT, and NLLB (NLLB Team et al.,2024). Due to the poor performance of NLLBin the zhen translation, we additionally train azhen translation model based on DeltaLM (Maet al., 2021) on the parallel corpus from OPUS3.Next, all of the system translations are scored withCOMET metric, and the of samples with thelowest score for each system are extracted as itsdifficult samples set. We vary the value of acrossdifferent language pairs to ensure an appropriate",
  "OursDUAT-I76.9256.1672.9459.9482.9272.1979.9667.0576.6457.7178.4566.8077.9763.31DUAT-E77.5756.8673.2560.1683.0772.3080.0166.9177.0457.3878.7066.9378.2763.42": ": Main results on Challenge-WMT. The bold indicates the highest value. +SimDems represents thetranslation strategy with demonstrations similar to the source sentence. The strategies +Topic, +Keywords, and+SimDems are proposed in MAPS. The baselines and our approaches are implemented based on GPT-3.5-turbo. scale for each difficult sample set. Finally, the in-tersection of all systems difficult sample sets istaken as the Challenge-WMT testbed. Challenge-WMTcomprises around 600+ sentence pairs foreach language pair, which is illustrated in Tab.6.We equally split this dataset into the validation setand the test set.We report the translation performance measuredby COMET on Challenge-WMT and the com-plete WMT set in , which shows that theperformance decreases dramatically on Challenge-WMT (84.573.6 averagely). Next, we conduct amulti-aspect comparison for Challenge-WMT andthe complete set in Appendix C, and find that thesamples of Challenge-WMT have higher perplex-ity (214252 averagely). This result indicates thatsentences in Challenge-WMT are more complex.",
  "MAPS (He et al., 2024), incorporating the knowl-edge of keywords, topic words, and demonstra-tions similar to the given source sentence to en-hance the translation process, respectively": "Commercial and open-source systems.Wealso report the performance of Google Trans-late, NLLB (in zhen translation, we replaceNLLB with our trained MT model based onDeltaLM), and zero-shot translation based onGPT4 (GPT-4-turbo). For DUAT and other ICL-based methods, we se-lect K=8 demonstrations (i.e., 8-shot) to achievea strong baseline performance. More details ofre-implementing the baselines under the few-shotsetting are illustrated in Appendix D. Metrics.Following previous research of LLM-based MT (Garcia et al., 2023; Chen et al.,2023), we adopt COMET (Rei et al., 2020) andBLEURT (Sellam et al., 2020) as the evaluationmetrics as their high correlations with human judg-ment than BLEU (Papineni et al., 2002).",
  ": Results on the complete WMT2022 testset.The result of WMT22 Best is reported for comparison": "(1) DUAT achieves significant improvements.On average, DUAT-E surpasses the baselineICL by +1.82 COMET and +1.32 BLEURT,and improves Zero-shot by +3.41 COMET and+3.33 BLEURT. In the low-resource translation ofEnIs, DUAT-E improves ICL by +3.85 COMETand Zero-shot by +5.87 COMET. These improve-ments show that, DUAT largely elicits the trans-lation ability via aligning the translation-specificunderstanding to the general one. (2) DUAT achieves state-of-the-art performanceon Challenge-WMT.DUAT achieves the high-est scores in EnZh and EnEt translation interms of COMET and BLEURT. In EnIs trans-lation, GPT-4 achieves the best results due to itssuperior multilingual capabilities. To verify the ef-fectiveness of DUAT on LLMs with stronger mul-tilingual capabilities, we implement DUAT basedon GPT-4 in EnIs translation, as shown in Ta-ble 2. The results suggest that DUAT can alsobenefit stronger multilingual LLMs by facilitatingthe understanding misalignment. (3) CoT works poorly in machine translation.In , CoT incurs a dramatic performancedrop over the baseline ICL. Our case studies revealthat CoT produces extremely wordy translations,which is also observed by Peng et al. (2023). Weconjecture that CoT makes LLMs imitate juniortranslators rather than advanced translators.",
  "(4) Difficult words are the bottleneck in trans-lating complex sentences.The results show thatincorporating the analysis of keywords and top-ics (He et al., 2024) has yet to gain significant": "improvements as DUAT. It suggests that it is thedifficult words that lead to the performance bottle-neck in translating intricate sentences. We also fol-low He et al. (2024) to experiment under the reranksetting as shown in Appendix.E, which shows theeffectiveness of our method further. (5) The external tool helps LLMs better identifydifficult words.DUAT-I achieves an average im-provement of +1.52 COMET, demonstrating theeffective performance of LLMs in recognizing dif-ficult words. And DUAT-E gains a further improve-ment of +0.3 COMET, showing the effectivenessof the external token-level QE tool in this task.",
  "Results on the complete WMT": "Experimental results on Challenge-WMT show theeffectiveness of DUAT in translating complex sen-tences, raising the question of its impact on trans-lating simple sentences. Therefore, we conductadditional experiments on the complete WMT2022testset of ZhEn translation. As the results shownin Tab.3, our method achieves comparable resultsto the baseline ICL in both translation directions.These results show that DUAT has no negative im-pact on translating simple sentences.",
  "Human Evaluation": "To quantitatively analyze the understanding mis-alignment problem, we employ one senior humantranslator for each language direction to assessgeneralization failures and translation literalness.Specifically, in each direction, we randomly sam-ple 100 sentences4 from Challenge-WMT and askthe senior translator to annotate the mistranslatedwords and phrases (i.e., mistranslation) and scorethe literalness (1 to 5 score) of the translationsgenerated by the strong baseline (GPT-3.5-turbowith ICL). Next, we ask the LLM to generate in-terpretations of the mistranslated content. Theseinterpretations are presented to the translator, whojudges whether they contain the correct understand-ing of the content. If the interpretation is accurate,the content is annotated as a generalization failure.Finally, the translator is asked to annotate the gener-alization failures of DUATand score the literalnessof the translations produced by DUAT.",
  ": Ablation Study. indicates the performancedrop after removing the specific component": "count for a considerable proportion of all mis-translations (16%32%). Our method (DUAT-E)largely resolves these failures by 71%88%. Wefurther study the unresolved failures and find thatmost of these unresolved failures are because theyare not identified as difficult words by the LLMsin the stage of difficult word detection (Eq.3) de-spite actually hard to translate. It indicates that thedifficult word detection remains an open question. Analysis of translation literalness.As the re-sults shown in Tab.4, the baseline translations arehighly biased towards literal translation. DUAT-significantly reduces the bias towards literal trans-lation, indicating that the process of interpretingthe difficult words first and then translating alignsbetter with sense-for-sense translation.",
  "Ablation Study": "DUAT introduces the processes of (1) draft trans-lation to precisely detect the difficult words and (2)IQC to improves the helpfulness of interpretations.To clearly elucidate the contribution of these twocomponents, we conduct an ablation study in Ta-ble 5. Specifically, we analyze the effect of the drafttranslation by asking the LLM to detect difficultwords directly without the draft translation. Theimpact of IQC is analyzed by evaluating the per-formance of the generated translations guided bythe original noisy interpretations (i.e., without theprocessing of IQC). The results show that remov-ing either component leads to performance drops,",
  "Analysis of Difficult Word Detection": "To offer an in-depth insight into the process of dif-ficult word detection, we illustrate the relation be-tween the number of difficult words interpreted andthe resulting performance by adjusting the valueof the difficulty threshold (), which is shown in. Concretely, a smaller value of allows moredifficult words to be interpreted. From the results,we have the following observations: Increasing the number of interpretations doesnot necessarily lead to performance improve-ments, but increasing high-quality ones can.Specifically, without controlling the quality of theinterpretations (i.e., w/o. IQC), increasing the num-ber of interpretations (the green lines) yields un-predictable performance changes (as shown by thegreen bins), as introducing either valuable infor-mation or noise. Fortunately, with IQC filteringnegative interpretations, increasing the number ofinterpretations (the blue lines) leads to constantimprovements (as the blue bins show). Interpreting words that are more difficultbrings larger improvements.Specifically, in theEnZh translation, decreasing the value of from0.19 to 0.17, the average number of helpful inter-pretations is increased from 0.23 to 0.49 (+0.26),and the performance is increased from 76.52 to76.98 (+0.46). However, decreasing the value of from 0.15 to 0.10, the average number of help-ful interpretations is increased from 0.91 to 1.47(+0.56), and the performance is increased from77.17 to 77.57 (+0.40). It should be noted that in-terpreting more words incurs more inference costs.Therefore, a modest value of (i.e., 0.13 0.15)is recommended to reach a compromise betweenefficiency and performance of DUAT.",
  "Analysis of Interpretation Generation": "Languages of interpretations.Given a difficultword, DUAT generates the corresponding interpre-tation with the target language (i.e., cross-lingualinterpretation), which implicitly comprises twostages: (1) generating the interpretation in thesource language and (2) translating the interpre-tation into the target language. Compared with con-ducting these two stages explicitly, DUAT is moreefficient and avoids error accumulation, which is il-lustrated in . As demonstrated, interpretationsin the target language (the blue bins) are morebeneficial than the ones in the source language(the purple bins) owing to aligning the general un-derstanding into the target language space, whichcould provide more benefits for translation. Andthe implicit two-stage process (the blue bins) isbetter than the explicit one (the green bins).",
  "Evaluation of LLMs translation capabilities.With the remarkable progress of LLMs, researchers": "have assessed their translation abilities in variousaspects. Zhang et al. (2023a); Vilar et al. (2023);Garcia et al. (2023); Bawden and Yvon (2023) firstinvestigate LLM-based MT in terms of the prompttemplate and examples selection. Next, the eval-uation is extended across more domains (Hendyet al., 2023), more languages (Zhu et al., 2023a),and document-level translation (Hendy et al., 2023;Wang et al., 2023). Other lines of work have per-formed in-depth assessments on the important at-tributes beyond accuracy, like literalness (Raunaket al., 2023) and culture awareness (Yao et al.,2023). As existing studies have shown that LLMshave achieved promising performance, our workturns out to benchmark them on hard instances to-wards detecting more underlying issues.",
  "LLM-based translation strategies.Lu et al": "(2023) obtain the multilingual translations of key-words in the source sentence via the translatorNLLB to augment the LLM, which improves thetranslation of low-resource languages while hurtingthe performance of high-source languages. Chenet al. (2023) demonstrate that iterative refinementreduces translationese significantly. He et al. (2024)incorporate the knowledge of keywords, topics, andreference demonstrations to enhance the translationprocess, and use a rerank strategy to combine allcandidate translations. However, there is no sig-nificant improvement to be observed when solelyutilizing each single type of knowledge. Differ-ent from previous works that utilize the intrinsicknowledge of LLM, DUAT focuses on dealing withthe difficult-to-translate words instead of the key-words for the reason that we argue the difficult-to-translate words lead to the performance bottleneckdue to the long-tail distribution of knowledge. LLM-based Automatic Post-Editing (APE).APE corrects the errors in the generated translation,aiming to bias the translation towards the distri-bution of the target language (Chen et al., 2023;Koneru et al., 2024). Differently, our work aimsto leverage the powerful understanding abilities ofLLMs to correct the misunderstanding of compli-cated concepts in the source sentence. Our work isin parallel with APE.",
  "In this work, we propose a novel translation pro-cess, DUAT, to take the first step in resolving themisalignment between the translation-specific un-": "derstanding and the general understanding. Further-more, we utilize the token-level QE tool to enhancethe detection of difficult words and the sentence-level QE tool to remove harmful interpretations.Human evaluation results on high-resource and low-resource language pairs indicate that DUAT sig-nificantly facilitates the understanding alignment,which improves the translation quality and allevi-ates translation literalness.",
  "Limitations": "Even though DUAT elicits the translation abilitiesof LLMs via unleashing the general understanding(intrinsic knowledge) of LLMs, they still struggleto translate concepts that require the incorporationof extrinsic knowledge, such as the translation ofneologisms. However, Our approach lays the foun-dation for researching when and how to incorporateexternal knowledge. Besides, DUAT requires toprompt the LLM for several times, leading to anincrease in latency. This latency is mainly causedby our interpretation quality control (IQC) strategy,which sequentially ablates each generated inter-pretation. Concretely, if |D| difficult words areidentified, IQC needs to prompt the LLM for |D|times.",
  "Acknowledgements": "Bing Qin is the corresponding author of this work.We thank the anonymous reviewers for their in-sightful comments.This work was supportedby the National Natural Science Foundation ofChina (NSFC) (U22B2059, grant62276078), theKey R&D Program of Heilongjiang via grant2022ZX01A32, the International CooperationProject of PCL, PCL2022D01 and the FundamentalResearch Funds for the Central Universities (GrantNo.HIT.OCEF.2023018). Rachel Bawden and Franois Yvon. 2023. Investigatingthe translation performance of a large multilinguallanguage model: the case of BLOOM. In Proceed-ings of the 24th Annual Conference of the EuropeanAssociation for Machine Translation, pages 157170,Tampere, Finland. European Association for MachineTranslation. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020.Language models are few-shot learners.In Ad-vances in Neural Information Processing Systems,volume 33, pages 18771901. Curran Associates,Inc.",
  "Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, ZhiyongWu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, andZhifang Sui. 2023. A survey on in-context learning": "Xavier Garcia, Yamini Bansal, Colin Cherry, GeorgeFoster, Maxim Krikun, Melvin Johnson, and OrhanFirat. 2023. The unreasonable effectiveness of few-shot learning for machine translation. In Proceedingsof the 40th International Conference on MachineLearning, ICML23. JMLR.org. Zhiwei He, Tian Liang, Wenxiang Jiao, ZhuoshengZhang, Yujiu Yang, Rui Wang, Zhaopeng Tu, Shum-ing Shi, and Xing Wang. 2024. Exploring Human-Like Translation Strategy with Large Language Mod-els. Transactions of the Association for Computa-tional Linguistics, 12:229246. Amr Hendy, Mohamed Abdelrehim, Amr Sharaf,Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita,Young Jin Kim, Mohamed Afify, and Hany HassanAwadalla. 2023. How good are gpt models at ma-chine translation? a comprehensive evaluation. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, Llio Renard Lavaud,Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,Thibaut Lavril, Thomas Wang, Timothe Lacroix,and William El Sayed. 2023. Mistral 7b.",
  "Wenxiang Jiao, Wenxuan Wang, Jen tse Huang, XingWang, Shuming Shi, and Zhaopeng Tu. 2023. Is chat-gpt a good translator? yes with gpt-4 as the engine": "Sai Koneru, Miriam Exel, Matthias Huck, and JanNiehues. 2024. Contextual refinement of translations:Large language models for sentence and document-level post-editing. In Proceedings of the 2024 Con-ference of the North American Chapter of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies (Volume 1: Long Papers), pages27112725, Mexico City, Mexico. Association forComputational Linguistics.",
  "Hongyuan Lu, Haoyang Huang, Dongdong Zhang, Hao-ran Yang, Wai Lam, and Furu Wei. 2023. Chain-of-dictionary prompting elicits translation in largelanguage models": "Shuming Ma, Li Dong, Shaohan Huang, Dong-dong Zhang, Alexandre Muzio, Saksham Singhal,Hany Hassan Awadalla, Xia Song, and Furu Wei.2021. Deltalm: Encoder-decoder pre-training forlanguage generation and translation by augmentingpretrained multilingual encoders. NLLB Team, Marta R. Costa-juss, James Cross, Onurelebi, Maha Elbayad, Kenneth Heafield, Kevin Hef-fernan, Elahe Kalbassi, Janice Lam, Daniel Licht,Jean Maillard, Anna Sun, Skyler Wang, GuillaumeWenzek, Al Youngblood, Bapi Akula, Loic Bar-rault, Gabriel Mejia Gonzalez, Prangthip Hansanti,John Hoffman, Semarley Jarrett, Kaushik RamSadagopan, Dirk Rowe, Shannon Spruit, ChauTran, Pierre Andrews, Necip Fazil Ayan, ShrutiBhosale, Sergey Edunov, Angela Fan, CynthiaGao, Vedanuj Goswami, Francisco Guzmn, PhilippKoehn, Alexandre Mourachko, Christophe Ropers,Safiyyah Saleem, Holger Schwenk, and Jeff Wang.2024. Scaling neural machine translation to 200 lan-guages.",
  "Jianhui Pang, Fanghua Ye, Longyue Wang, Dian Yu,Derek F. Wong, Shuming Shi, and Zhaopeng Tu.2024. Salute the classic: Revisiting challenges ofmachine translation in the age of large language mod-els": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evalu-ation of machine translation. In Proceedings of the40th Annual Meeting of the Association for Compu-tational Linguistics, pages 311318, Philadelphia,Pennsylvania, USA. Association for ComputationalLinguistics. Keqin Peng, Liang Ding, Qihuang Zhong, Li Shen,Xuebo Liu, Min Zhang, Yuanxin Ouyang, andDacheng Tao. 2023. Towards making the most ofChatGPT for machine translation. In Findings of theAssociation for Computational Linguistics: EMNLP2023, Singapore. Association for Computational Lin-guistics. Vikas Raunak, Arul Menezes, Matt Post, and Hany Has-san. 2023. Do GPTs produce less literal translations?In Proceedings of the 61st Annual Meeting of theAssociation for Computational Linguistics (Volume2: Short Papers), pages 10411050, Toronto, Canada.Association for Computational Linguistics. Ricardo Rei, Ana C Farinha, Chrysoula Zerva, Daanvan Stigt, Craig Stewart, Pedro Ramos, TaisiyaGlushkova, Andr F. T. Martins, and Alon Lavie.2021. Are references really needed? unbabel-IST2021 submission for the metrics shared task. In Pro-ceedings of the Sixth Conference on Machine Trans-lation, pages 10301040, Online. Association forComputational Linguistics.",
  "Ricardo Rei, Nuno M. Guerreiro, Marcos Treviso, LuisaCoheur, Alon Lavie, and Andr Martins. 2023. The": "inside story: Towards better understanding of ma-chine translation neural evaluation metrics. In Pro-ceedings of the 61st Annual Meeting of the Associa-tion for Computational Linguistics (Volume 2: ShortPapers), Toronto, Canada. Association for Computa-tional Linguistics. Ricardo Rei, Craig Stewart, Ana C Farinha, and AlonLavie. 2020. COMET: A neural framework for MTevaluation. In Proceedings of the 2020 Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP), pages 26852702, Online. Associationfor Computational Linguistics.",
  "Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020": "BLEURT: Learning robust metrics for text genera-tion. In Proceedings of the 58th Annual Meeting ofthe Association for Computational Linguistics, pages78817892, Online. Association for ComputationalLinguistics. David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo,Viresh Ratnakar, and George Foster. 2023. Prompt-ing PaLM for translation: Assessing strategies andperformance.In Proceedings of the 61st AnnualMeeting of the Association for Computational Lin-guistics (Volume 1: Long Papers), pages 1540615427, Toronto, Canada. Association for Computa-tional Linguistics. Longyue Wang, Chenyang Lyu, Tianbo Ji, Zhirui Zhang,Dian Yu, Shuming Shi, and Zhaopeng Tu. 2023.Document-level machine translation with large lan-guage models. In Proceedings of the 2023 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 1664616661, Singapore. Associationfor Computational Linguistics. Jason Wei, Xuezhi Wang, Dale Schuurmans, MaartenBosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,and Denny Zhou. 2022. Chain of thought prompt-ing elicits reasoning in large language models. InAdvances in Neural Information Processing Systems.",
  "Binwei Yao, Ming Jiang, Diyi Yang, and Junjie Hu.2023. Empowering llm-based machine translationwith cultural awareness": "Zhangyue Yin, Qiushi Sun, Qipeng Guo, Jiawen Wu,Xipeng Qiu, and Xuanjing Huang. 2023. Do largelanguage models know what they dont know? InFindings of the Association for Computational Lin-guistics: ACL 2023, pages 86538665, Toronto,Canada. Association for Computational Linguistics. Biao Zhang, Barry Haddow, and Alexandra Birch.2023a. Prompting large language model for machinetranslation: A case study.In Proceedings of the40th International Conference on Machine Learning,ICML23. JMLR.org.",
  "Zhuosheng Zhang, Aston Zhang, Mu Li, and AlexSmola. 2023b. Automatic chain of thought prompt-ing in large language models. In The Eleventh Inter-national Conference on Learning Representations": "Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,Xiaolei Wang, Yupeng Hou, Yingqian Min, BeichenZhang, Junjie Zhang, Zican Dong, Yifan Du, ChenYang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu,Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. Asurvey of large language models. Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu,Shujian Huang, Lingpeng Kong, Jiajun Chen, andLei Li. 2023a. Multilingual machine translation withlarge language models: Empirical results and analy-sis.",
  "# the format description is omitted.Source Sentence:[ Source Sentence x ]Target Translation: [ Target Translation y ]": "Then, the response is parsed via regular expres-sion to extract the difficult words D and interpreta-tions A. Next, we remove the noisy interpretationsthrough a process similar to IQC (Alg. 1). The onlydifference is that the QE metric is replaced withthe reference-based COMET (Rei et al., 2020) dueto the available access to the reference translation.Finally, the generated difficult words D and inter-pretations A can be assembled with the source andtarget sentence (x, y) as demonstrations for eachstep of DUAT.",
  "end": "LLM to output the step-by-step translation processin a manner of post-explanation (i.e.,, given thesource sentence and its translation, requesting theLLM to generate the intermediate process). Toobtain the ones of MAPS, we let the LLM to per-form translation with the specific strategy on thevalidation set, and assemble the generated inter-mediate process (e.g., keywords) and the referencetranslation as demonstrations.",
  "EResults under the Rerank setting": "We follow He et al. (2024) to conduct experimentsadditionally under the rerank setting. For the base-line ICL, we run for 4 times with different setsof demonstrations, which are sampled randomlywith seeds {1, 2, 3, 4}, and adopt QE to select thebest candidate as the final translation. For MAPS,the final translation is selected from the candidatesgenerated by the three strategies (+topic, +Key-words, and +SimDems) and ICL (seed=1). ForDUAT, we select the final translation from the re-sults of DUAT and ICL (seed=1). The results areshown in ."
}