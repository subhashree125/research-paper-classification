{
  "Abstract": "Recent studies highlight the potential of largelanguage models in creating educational toolsfor children, yet significant challenges remainin maintaining key child-specific propertiessuch as linguistic nuances, cognitive needs, andsafety standards. In this paper, we explorefoundational steps toward the development ofchild-specific language models, emphasizingthe necessity of high-quality pre-training data.We introduce a novel user-centric data collec-tion pipeline that involves gathering and val-idating a corpus specifically written for andsometimes by children. Additionally, we pro-pose a new training objective, Stratified Mask-ing, which dynamically adjusts masking proba-bilities based on our domain-specific child lan-guage data, enabling models to prioritize vocab-ulary and concepts more suitable for children.Experimental evaluations demonstrate that ourmodel excels in understanding lower grade-level text, maintains safety by avoiding stereo-types, and captures childrens unique prefer-ences. Furthermore, we provide actionable in-sights for future research and development inchild-specific language modeling.1",
  "Introduction": "Children constitute one in three internet users glob-ally, according to a UNICEF study (Keeley andLittle, 2017), with the average screen time forkids aged 8-12 estimated to be over five hoursper day (Rideout et al., 2022). This level of dig-ital engagement presents both opportunities andchallenges for enhancing childrens learning ex-periences. Large Language Models (LLMs) havesignificantly lowered the barriers to building edu-cational tools and applications (Huber et al., 2024),with some studies suggesting these models enhancechildrens learning by facilitating engaging andemotionally responsive conversations (Seo et al.,",
  "-2426.3%18-2541.8%25-3447.4%25-3540.7%35-4410.5%35-4512.1%45-5410.5%45-553.0%55-645.3%55-651.2%": ": Annotators Age Distribution in the Instruct-GPT (Ouyang et al., 2022) and Aya Dataset (Singhet al., 2024) used for supervised fine-tuning (SFT). Thetop two percentages for each dataset are marked in bold. 2024b) and supporting visual programming learn-ing (Chen et al., 2024). Despite these opportunities,there are notable risks associated with (1) the biasand toxicity of language models (Deshpande et al.,2023), stemming from the vast, unvetted data theyare trained on (Longpre et al., 2024), (2) a lackof sufficient contextual appropriateness to engagechildren (Seo et al., 2024a,b), and (3) the challengeof maintaining lexical simplicity that is appropriatefor the children (Valentini et al., 2023). These chal-lenges highlight the necessity for a safer and morereliable approach to designing and auditing LMsto vulnerable populations like children. This pa-per investigates whether a language model for kidscan be constructed with desirable features such assafety, contextual appropriateness and simplicitybuilt into the language model.Two dominant approaches for adapting languagemodels to a specific domain, task, or language arecontinual pre-training and instruction tuning or su-pervised fine-tuning (SFT). LLMs rely on large-scale self-supervised pre-training on Internet textdata, as described by (Brown et al., 2020), anddecoder-only LLMs use a causal language mod-eling objective to predict the next token based onprevious tokens (Bengio et al., 2000). Continualpre-training involves further training a pre-trainedlanguage model on additional data relevant to aspecific domain or language, such as Biomedi- cal (Bolton et al., 2024), Mathematics (Azerbayevet al., 2024), or languages like those in SoutheastAsia (Dou et al., 2024). SFT, on the other hand,trains a language model with specific instructionsor guidelines to align with specific tasks (Wei et al.,2022) and user preferences via RLHF (Ouyanget al., 2022), using data consisting of pairs of in-structions and their corresponding desired outputs.A key component of both continual pre-training andSFT is the existence of high-quality data, whethersynthetic or human-annotated (AI et al., 2024; Liuet al., 2024). However, annotators for SFT data arepredominantly from the age group 18-35 (),whose distinct linguistic and cognitive preferences,as well as safety needs, differ significantly fromthose of children. For example, annotators on Ama-zon Mechanical Turk (MTurk) must be at least18 years old.2 Consequently, the SFT data maynot adequately address the unique requirements ofyounger users. This limitation prompts an intrigu-ing question: Can a language model be developedspecifically for a particular user group, such aschildren in our case?Language models for children3 are expected topossess three essential properties: (1) the abil-ity to generate simpler words and understandlower grade-level texts, (2) free from any stereo-types (Bozzola et al., 2022), and (3) the capacityto model childrens unique preferences and emo-tions for personalized engagement. We argue thatachieving these properties simultaneously in a lan-guage model necessitates the use of high-qualitypre-training data. Modern LLMs typically pre-train on corpora containing hundreds of billionsto several trillions of tokens from vast internet textdata (Touvron et al., 2023; Penedo et al., 2023).Two often disregarded aspects of this text data are:(i) the demographics and intentions of its creators,and (ii) the intended audience for whom it waswritten. Both factors can significantly influence thecomposition and distribution of the data, and con-sequently, the resulting behavior of a user-centriclanguage model (e.g., children).With the aforementioned requirements for lan-guage models tailored for children, we curatedhigh-quality, kid-appropriate content specificallywritten for children and occasionally by them. Thiscontent was meticulously reviewed and validated 2Information about annotators can be found as an answerof the question \"Who completes the tasks on Amazon Mechan-ical Turk and how do they complete them?\" in this link.3We use the terms kids and children interchangeably. by website editors or moderators to ensure its suit-ability and the absence of inappropriate content orsensationalism. Our data collection pipeline is com-prehensive, diverse, and appropriately tailored forchildrens language models, while also being scal-able to support the accumulation of more sourcesfor future development. Given the size of our col-lected pre-training data and available resources, weopted to train a masked language model (MLM) tovalidate the corpus quality and ensure support forthe kid-specific properties discussed above. Thismodel introduces the stratified masking method,which offers a way to prioritize words relevantto children and is also applicable in low-resourcelearning scenarios. Furthermore, we offer sugges-tions for future directions to extend our findings.Our main contributions are summarized as fol-lows:",
  ": User-Centric Data Collection Pipeline for our KidLM (corpus)": "editors or moderators to ensure its suitability, ap-propriateness, and absence of sensationalism orinappropriate material. Our user-centric approachto data collection carefully considers two criticalaspects: (i) the demographics and intentions ofthe content creators (Who?), and (ii) the in-tended audience for whom the content is written(Whom?). Source IdentificationThe initial phase of ourdata collection methodology involved using GoogleSearch to identify a preliminary set of websites, de-noted as X = [Time for Kids, News for Kids, ...,Kids Press]. Subsequently, we employed ChatGPT,prompting it with List websites similar to Xi thatoffer kid-specific content, to expand our list. Thisprocess yielded an additional collection of relevantwebsites, which were then merged with the initialset X. Finally, we utilized SimilarWeb 4, a web an-alytics tool, to further extend our list. Specifically,we used the Similar Sites feature of SimilarWebto identify analogous sites. Manual Data VerificationWe manually veri-fied and filtered the data sources by reviewing theabout sections of the identified source websites,as detailed in Tables (Description col-umn) of the Appendix. Quality FilteringArticles were filtered based onspecific criteria, depending on the availability of in-formation from the sources, such as (1) Extractingarticles tagged specifically for children, (2) Identi- fying those labeled as kidspost, (3) Excludingarticles tagged as potentially inappropriate contentwith colors such as red, and (4) Selecting data rele-vant to specific grade levels (K-1, 2-3, 4-5, and 6).5",
  "These criteria are further explained in Tables (Additional Notes column) of the Appendix": "Additional FilteringWe included only Englishtext and removed sentences involving code-mixingand code-switching. Additionally, we eliminatedany Personal Identifying Information (PII) fromthe corpus. Details of these processes are providedin Appendix A. Data DiversityTo ensure genre diversity, the cor-pus includes articles on science, sports, history, an-imals, geography, technology, current events, bookreviews, and more, all tailored to meet the inter-ests of young readers. We collected data from 21sources originating from various regions: USA (4),India (4), Canada (3), Australia (1), UK (1), NewZealand (1), and other global sources (7), aimingto avoid geographic and cultural biases (detailed inTables of the Appendix). Data QuantityOur KidLM corpus contains over286,000 documents, approximately 2.91 millionsentences, and 50.43 million words. Upon process-ing with the RoBERTa tokenizer (Liu et al., 2019),this amounted to approximately 67.97 million to-kens. in the Appendix shows the detailedstatistics of the collected data across sources.",
  "KidLM Models": "We use our KidLM corpus to develop languagemodels tailored for children. Given the corpus sizeand available resources, we opt to train an MLM tovalidate corpus quality and ensure support for kid-specific properties. Our model has two variations(1) KidLM: We continue to pre-train RoBERTa(Liu et al., 2019) using our KidLM corpus (2.1)with an MLM learning objective, which involvesrandomly masking 15% of the input sequenceswords to predict these masked words from theircontext. (2) KidLM+: This version introduces anovel masking strategy called Stratified Masking,varying the probability of masking based on wordclasses. This approach enhances the models focuson tokens that are more informative and specificallytailored to children, making it particularly usefulfor low-resource learning scenarios where the pre-training corpus is relatively smaller and designed toinject specific properties into the language model. 2.2.1Stratified MaskingWe aim to steer LM predictions towards kid-specific words from our high-quality corpus. Toachieve this, we introduce Stratified Maskingbased on two principles: (1) all words in our corpushave a non-zero probability of being masked, and(2) words more likely to be found in a general cor-pus are masked with lower probability. With theseprinciples, each word in our corpus is assigned toone of the following three strata: Stopwordswhich are generally the most fre-quent words in a language. Utilizing NLTKs list of179 stopwords (Bird, 2006), we apply a 0.15 mask-ing rate to these words. Our hypothesis for maskingis that children use stopwords distinctively, often inreference to specific nouns like cars, trains, andbutterflies. Additionally, many pronouns such ashe, she, his, and her are categorized as stop- Today is her sixth birthday, and shefeels like a fairytale princess. Shewears a sparkly dress with a rainbowof butterflies for her magical party. Today is her sixth birthday, and shefeels like a fairytale princess. Shewears a sparkly dress with a rainbowof butterflies for her magical party. (a) Random Masking (b) Stratified Masking : (a) In default random masking, all wordshave a equal probability of 0.15 of being masked. (b) Inour proposed stratified masking, stopwords are maskedwith a probability of 0.15, Dale-Chall words with aprobability of 0.20, and other words with a probabilityof 0.25, to enhance learning focus on kid-specific words.",
  "words. By masking them, we aim to learn debiasedrepresentations from the data during pre-training": "Dale-Chall Easy Words Listcomprises 2950words that are reliably understood by stu-dents (Chall and Dale, 1995). Of these, 4.85%overlap with stopwords, which we subsequently re-move. We then mask the remaining 2807 words ata slightly higher masking rate of 0.20 to prioritizethe linguistic simplicity specific to children. Other WordsIn our KidLM corpus (2.1), it isunsurprising that stopwords are dominant, account-ing for 45.93%, while Dale-Chall Easy words makeup 21.82%, and other words constitute 32.45%.We assume that these other words often includenouns and entities, reflecting childrens preferencesor safe alternatives introduced by website editors ormoderators. Consequently, we assign them a highermasking rate of 0.25 to emphasize their informa-tive importance during training. presentsa Venn diagram of different classes of words withassociated probability. Formally, given a text se-quence, the model generates a masked text TM byapplying the following procedure to each token xi:",
  "where is the parameters of the model. We uti-lized the pre-trained checkpoint of the RoBERTa": "base model and its pre-trained tokenizer, avoid-ing the use of any custom vocabulary. presents an illustration of stratified masking ap-plied to an example input text. Note that there areno hyperparameter differences between the KidLMand KidLM+ models; the only distinction lies intheir masking approaches. Detailed hyperparame-ter settings are presented in Appendix B.",
  "Evaluation": "We evaluate our KidLM models based on the fol-lowing two criteria: (1) How well does KidLMunderstand lower grade-level texts (3.1)? (2) Howrobust is KidLM in maintaining safety standardsby avoiding the generation of stereotypes (3.2)?We compared our model with base LMs to ensurea fair and consistent comparison, highlighting theimpact of our high-quality pre-training data.",
  "Evaluating on Grade-Level Texts": "Our objective is to compare various language mod-els against our KidLM models. We employ Perplex-ity (PPL) as an evaluation metric, which measuresthe uncertainty of a language model when predict-ing the next word in a sequence (Radford et al.,2019; Salazar et al., 2020). A lower perplexityscore indicates that the model is more confidentand accurate in its predictions, suggesting a betterunderstanding of the language and context (Bengioet al., 2000). To assess this, we use texts acrossdifferent lower grade-levels, allowing us to mea-sure how well each model handles the linguistic,syntactic, and semantic simplicity of texts. Theholdout Newsela Corpus (Xu et al., 2015) is usedfor this purpose. We randomly selected 40 docu-ments for each of the lower grade-levels, such as2nd, 3rd, and 4th grades, and segmented these doc-uments into sentences to compute sentence-levelperplexity scores (for holdout test data statistics,refer to ). Results & AnalysisAs shown in ,general-purpose LLMs demonstrate decreasing per-plexity as grade levels increase, indicating lessuncertainty in predicting relatively more complextexts. At the 2nd grade level, perplexity values arehighest across all these LLMs, highlighting the dif-ficulty in comprehending simpler texts. The Llamafamily models show that more training data doesntalways improve performance with simpler texts.For example, Llama 2, trained on 2 trillion tokens,and Llama 3, trained on 15 trillion tokens, illustrate",
  ": Sentence-level average PPL scores for variousLLMs, Causal LMs, and MLMs divided into grade-level.() indicates lower values for better performance. Sizes(in parameters) >= 1B are considered as LLMs": "this point, suggesting a need for more user-centeredtraining data. In contrast, our models, KidLM andKidLM+, show a reversing trend with generallyless uncertainty in predicting lower grade levelsand consistently less uncertainty across all gradelevels, demonstrating their effectiveness in under-standing simpler language. Further, we present aqualitative analysis of our model outputs in gener-ating simpler words within a given context (4).",
  "Evaluating Stereotype": "Our evaluation involves querying a range of pre-trained LMs, LLMs, and debiased LMs, usinga structured prompt: why are {group} so ....While Baker and Potts (2013) utilized promptssuch as why do {group}, how do {group}, andwhat do {group} to effectively elicit stereotypes,our prompt is specifically designed to extract rea-sons associated with a groups characteristics, fo-cusing on adjectives. The placeholder {group}is replaced with terms from a broad range of so-cial groups. For selecting these groups, we re-ferred to lists from (Choenni et al., 2021) and theStereoSet (Nadeem et al., 2021), which are com-monly used in assessing stereotypes in LMs. Fol-lowing (Leidinger and Rogers, 2023), we mergedand reorganized these sources to create a compre-",
  "hensive list of 151 social groups, categorized into 8distinct categories (Appendix ()). Our eval-uation encompasses a wider range of social groupsfor thoroughly analyzing stereotypes in LMs": "Masked LMs (MLMs) and Debiased LMsForMLMs, such as RoBERTa, KidLM (ours), andKidLM+ (ours), we prompt the models with whyare {group} so [MASK] to predict completionsfor the [MASK] position. We also compare ourmodels with two debiased models where debi-asing occurs during the pre-training stage, (1)Auto Debias (Guo et al., 2022), and (2) ContextDebias (Kaneko and Bollegala, 2021). Since thesemodels are debiased MLMs, we employed the sameprompt settings designed for MLMs. Causal Language ModelsWe compared ourmodels with several open-sourced causal languagemodels such as GPT-2 (base and large) (Rad-ford et al., 2019), Llama 2 (7B and 13B) (Tou-vron et al., 2023), Llama 3 (8B), and Mistral7B (Jiang et al., 2023). We employed the promptwhy are {group} so as a context to generatewords that reflect stereotypical reasoning or biases.This method offers insights into potential biasesembedded within their training data and predictivealgorithms. We configured the generator to producea maximum of one token by setting the parametermax_new_tokens = 1. We filtered out the com- pletions that were duplicates, non-words, less thanthree characters, grammatically incorrect, or non-adjectives (e.g., so often, so sure, so far, somuch, so into, so so, etc). We opted not tocompare our models with closed-source models, asdetailed in Appendix C. Evaluation MethodTo thoroughly analyze thestereotypical biases present in LMs, we sampledmultiple completions (n=5) for each LM for eachgroup, ranking them according to the probability ofcompletions. Our analysis includes a total of 151groups, divided into 8 categories.Social bias or stereotypes in language modelsmanifest as prejudiced outputs that associate targetconcepts to demographic groups (Gallegos et al.,2023). To evaluate these stereotypes, we analyzesentiment and toxicity scores of model comple-tions, a common method in assessing stereotypes inlanguage generation (Blodgett et al., 2020; Nadeemet al., 2021; Akyrek et al., 2022; Deshpande et al.,2023; Liang et al., 2023). Toxicity refers to of-fensive, harmful, or discriminatory language (Kir-itchenko et al., 2021), while sentiment reflectshuman perceptions, attitudes, and emotions (Ek-man and Davidson, 1994). Notably, content fromhumans may display more pronounced stereotyp-ing, as observed through negative sentiments orincreased toxicity (Liu, 2024).",
  ": Lexical simplification probing comparison withour KidLM models to human labels": "Sentiment & Toxicity ScoresTo quantify senti-ment, we utilized SiEBERT (Hartmann et al., 2023),a language model fine-tuned for sentiment classi-fication, chosen for its extensive training acrossdiverse English datasets, including tweets and re-views6. For toxicity assessment, we utilize theToxicity Scorer7 (Leong et al., 2023), a fine-tuned DeBERTa-v3-large model (He et al., 2023)that offers superior estimation accuracy and higherthroughput compared to the Perspective API8.Both sentiment and toxicity are measured on a scalefrom 0 to 100, with higher scores reflecting morepositive sentiment and reduced toxicity, allowing amore fine-grained analysis. Results presents average sentiment andtoxicity scores for various models, including PLMs,LLMs, and debiased models. KidLM, fine-tunedon our corpus with standard (random) masking,outperforms typical PLMs in sentiment scores andshows a reduced tendency for reinforcing negativestereotypes. Its performance in toxicity scores in-dicates an ability to minimize toxic completions,even with less positive sentiments. KidLM+ excelsin both sentiment and toxicity, benefiting from ourStratified Masking technique. Mistral 7B, with itsemphasis on high-quality pre-training data (Jianget al., 2023), emerges as a close contender in senti-ment, underscoring the significance of data quality.Sample outputs in of the Appendix.",
  "6sentiment-roberta-large-english7deberta-v3-large_toxicity-scorer8": "7 of Appendix) to analyze the models ability tocapture and reflect childrens unique preferences,emotions, and wishes. These analyses aim to high-light the impact of our corpus and the effectivenessof our stratified masking procedure in generatingcontextually preferred responses for children.To structure the analysis, we employ the clozetest (Taylor, 1953) to design queries, where cer-tain words in a query are masked, and the modelstask is to predict or fill in these blanks. Formally,Let Q = {q1, q2, . . . , qk} represent a set of probequeries, where each query qi is a sentence withone or more masked positions. Each query can berepresented as:",
  "qi = {w1, w2, , [MASK], , wN}(2)": "where wj is a word or a token in the query,[MASK] represents the masked position(s), and Nis the total number of words in the sentence. ALM, M, is employed to predict plausible wordsfor each masked position. For each masked posi-tion in query qi, the model outputs a probabilitydistribution over a predefined vocabulary V . Thisprobability distribution is denoted by P(v|qi, M),representing the probability of a vocabulary wordv V being a plausible completion at the maskedposition in qi. The objective is to identify the topK most likely words from V , this set of words isrepresented as TopK(qi) and is defined as:",
  "TopK(qi) = argmaxKvVP(v|qi; M)(3)": "Lexical Simplificationinvolves replacing a wordin context with a simpler alternatives (Paetzold andSpecia, 2016). To analyze the ability of our KidLMmodels to generate simpler words within a givencontext, we utilized the TSAR-EN dataset (tajneret al., 2022), annotated by MTurk annotators whoare required to be at least 18 years old. For eachsentence, we selected the annotated complex word(highlighted in bold in ), replaced it with[MASK], and then probe LMs to generate words forthe masked position and rank them according totheir output probability. compares the sam-ple outputs generated by our models to human la-bels. While human annotators, influenced by theirage (over 18), tend to list simpler synonyms of theknown complex word, our KidLM+ model excelsin generating simpler, preferred, and stereotype-free completions. This behavior can be attributedto our proposed stratified masking procedure. More",
  "detailed comparisons and additional sample outputscan be found in the Appendix ()": "Preference Probinginvolves creating a set ofprobe queries and using language models to pre-dict preferences for these queries (Appendix []). By generating completions with associatedprobabilities, we examine the models confidencein each preferred completion. We compare the out-puts of our models with those of RoBERTa, whichwas initially trained with BooksCorpus (Zhu et al.,2015) and English Wikipedia and then we usethis model to continue pre-train with our KidLMcorpus to develop KidLM models.In , we present sample outputs com-paring KidLM and KidLM+ models againstRoBERTa through diverse probe tests.Un-der Preferences, KidLM and KidLM+ demon-strated a strong ability to generate child-friendlycompletions.KidLM+ suggested chicken,spaghetti, and noodles with high confi-dence, reflecting common preferences among chil-dren. This contrasted with RoBERTa, which sug-gested more adult-oriented foods like pizza,sushi, and seafood. For Emotions and Feel-ings, KidLM models showed a nuanced understand-ing of common childhood fears. KidLM+ gen-erated spiders and everything with highprobabilities, aligning closely with typical child-hood fears, while RoBERTa generated less spe-cific completions like death and him. In theWishes and Desires category, KidLM models accu-rately reflected typical childrens wishes. KidLM+offered chocolate and cake with high confi-dence, capturing common birthday desires amongkids. In contrast, RoBERTa suggested more generalor abstract terms. The higher confidence observedin the KidLM+ model can be attributed to our strat-ified masking approach (additional sample outputs can be found in Appendix ()).We qualitatively analyze and interpret themodels preferred completions, but a critical ques-tion remains: how can we evaluate this with actualhuman feedback? In next section, we discuss futuredirections involving human-centered evaluations.",
  "Discussion and Future Directions": "Pre-training DataDecoder-only LLMs operateon a causal language modeling objective, learningto predict the next token based on the sequenceof previous tokens (Touvron et al., 2023; Penedoet al., 2023). Consequently, they may require sig-nificantly more pre-training data compared to ourcurrent KidLM corpus. On a positive note, our user-centric data collection pipeline is not only compre-hensive but also extensible, allowing continuous in-tegration of new sources to expand our corpus. Ad-ditionally, quality filtering and controlled repetitionof available data, as shown in recent studies (Muen-nighoff et al., 2023), can significantly enhance theperformance of LLMs in data-constrained settings. Alignment to ChildrenBase LLMs pre-trainedwith unsupervised text corpora are typically inad-equate as open-domain conversational assistants.Fine-tuning is essential, but using existing SFTdata can compromise the kid-specific propertiesdeveloped during pre-training stage (). Fur-thermore, MTurk is unsuitable for collecting suchdata due to age demographic restrictions.Re-cent studies demonstrate that a small set of exam-ples (e.g., 1,000) can achieve significant alignmentperformance (Zhou et al., 2023). Another studyhighlights that base LLMs and their alignment-tuned versions perform nearly identically (Lin et al.,2024), with base LLMs achieving effective conver-sational alignment purely through in-context learn-",
  "ing (ICL). These studies support our hypothesisthat high-quality, user-centered pre-training data isessential for developing kid-specific LMs": "Human-Centered EvaluationCurrent LLMevaluation methods focus on developing datasetsand benchmarks (Liang et al., 2023; Changet al., 2024) but often fail to address thesociotechnical gap (Weidinger et al., 2023).Assessing models in isolated lab settings lim-its the incorporation of human factors (Ibrahimet al., 2024). Human-Computer Interaction (HCI)offers diverse metrics to meet the evaluation needsof different stakeholders (Damacharla et al., 2018).Interdisciplinary research between HCI and NLPis essential for responsible, human-centered evalu-ation and auditing of LLMs (Xiao et al., 2024). Asa potential research direction, we suggest an evalu-ation framework that integrates insights from bothfields. This process may involve various stakehold-ers at different stages: (1) Pre-deployment (e.g.,educators, psychologists, parents), and (2) Post-deployment (e.g., children, parents, educators).",
  "Related Work": "Children and Language TechnologyPrior stud-ies from the HCI community have explored howtechnology can support children in learning andsharing their emotions (Santos et al., 2020; J. Ryuet al., 2021), as well as enhancing parents aware-ness of their childrens emotional well-being (Pep-ping et al., 2020). These studies demonstrated thatchatbots and tangible artifacts can accurately detectchildrens emotions and promote emotional regu-lation. However, they often overlook childrensperceptions and preferences regarding emotionalcommunication (Seo et al., 2024b) and are limitedby the technical constraints of rule-based chatbots(Seo et al., 2024a). LLMs have simplified the de-velopment of educational tools and applications(Huber et al., 2024). Research suggests these mod-els can enhance childrens learning through engag-ing, emotionally responsive interactions (Seo et al.,2024b) and support visual programming (Chenet al., 2024). However, significant risks includebias and toxicity from unvetted datasets (Desh-pande et al., 2023), insufficient contextual appropri-ateness (Seo et al., 2024a,b), and difficulty in main-taining lexical simplicity suitable for young users(Valentini et al., 2023). These challenges highlightthe need for child-specific LMs with built-in safety,contextual relevance, and simplicity. Masking Strategies & RatesEntityBERT (Linet al., 2021) employs a masking strategy that tar-gets entities identified by a domain-specific pre-trained named entity recognizer (NER) model. Sim-ilarly, Salient Span Masking (Guu et al., 2020)uses an NER model to mask entities for open-domain QA tasks. Both methods rely on a domain-specific NER, and their masking strategy is con-sistent across any applied domain. In contrast,Selective Masking (Gu et al., 2020) tailors tokenmasking during continued pre-training based ondata and labels from the downstream task. Mean-while, Difference Masking (Wilf et al., 2023)automatically selects tokens for masking by iden-tifying unique anchor words in the target domaindata, distinguished from the general domain usinga TF-IDF-like scoring function. Wettig et al. (2023)found that a 15% masking rate is not universallyoptimal for MLMs, suggesting that larger modelsshould adopt a higher rate when pre-training fromscratch. Moreover, Yang et al. (2023) introducedtime-variant masking, adjusting the masking rateat different training stages to enhance pre-trainingefficiency. Our method, on the other hand, groupswords into classes or strata, with our novel Strati-fied Masking adjusting masking probabilities basedon the strata to which they belong. This enhancesthe models focus on tokens that are more informa-tive and specifically tailored to children, facilitatingthe smoother integration of kid-specific propertiesinto the language model. Unlike other methods, ourapproach does not depend on any external models,task-specific signals, custom vocabulary, or a fixedmasking rate for all tokens. The works related todomain adaptation of LMs are in Appendix D.",
  "Conclusion": "In this paper, we take the important first steps to-ward designing child-specific language models tomake NLP systems more accessible to children. Wecurated a high-quality pre-training corpus using ourproposed user-centric data collection pipeline andintroduced novel Stratified Masking to enhancethe models focus on tokens that are more informa-tive and specifically tailored to children. Experi-mental evaluations demonstrate that our model ef-fectively understands lower grade-level text, main-tains safety standards by avoiding the generation ofstereotypes, and captures childrens unique prefer-ences. Furthermore, based on our insights, we offersuggestions for future research and development.",
  "Limitations": "Resource ConstraintsRecognizing the impor-tance of this vulnerable population, we took a stepback to carefully consider their unique needs andbegan our work from the ground up, starting withthe data. Given the size of our pre-training data, weopted to train an MLM to validate the corpus qual-ity and ensure the integration of kid-specific prop-erties into the language model. Additionally, devel-oping KidLM in resource-constrained academicsettings prompted us to propose Stratified Masking,a novel training objective for data-efficient, user-centric language modeling. Our approach alignswith recent research that emphasizes the impor-tance of curating pre-training data to derive mean-ingful insights for future developments and to opti-mize models in resource-constrained settings (Lucyet al., 2024). Our insights and observations pavethe way for future research and development. Wehope that our efforts will inspire the community toadvance this work, guided by our future directions. Discussions on Stratified Masking ratesWe as-signed masking rates of 0.15 to stopwords, 0.20 toDale-Chall easy words, and 0.25 to other words,focusing on more informative and kid-specific vo-cabulary.This approach led to a masking ra-tio of stopwords : Dale-Chall words : otherwords = 0.15:0.20:0.25, increasing in incrementsof 0.05. We recognize that alternative ratios, suchas 0.15:0.25:0.35 with increments of 0.10, are alsofeasible. However, due to limited computationalresources and the extensive training required, wewere unable to experiment with finding the optimalmasking ratios. Other Harm CategoriesAlthough our modeldemonstrates a reduced likelihood of reinforcingnegative stereotypes and generating toxic comple-tions across 151 social groups in 8 categories, wewere unable to explore other harm categories suchas hate speech, sexual content, and violent crimesfrom the MLCommons taxonomy of hazards9. Weencourage future work to investigate these addi-tional harm categories to provide a more compre-hensive assessment of language model safety.",
  "9mlc-aisafety-v0-5-poc": "tactic, and semantic simplicity. Depending on theavailability of grade level information, we aim tolimit the documents to the 6th grade, which corre-sponds to the age of 12 in the elementary schooldivision. However, we cannot guarantee that allcontent meets our criteria when such information isnot directly available. These criteria are explainedin Appendix Tables (Additional Notescolumn).",
  "Ethics Statement": "Data CrawlingWe took ethical considerationinto account when scraping data from the sourceslisted in Tables . The data we have col-lected is intended exclusively for non-commercialresearch purposes. We conducted our web scrapingactivities at a reasonable rate, with no intention ofcausing a Distributed Denial of Service (DDoS)attack. Additionaly, we read the instructions listedin robots.txt10 of each website to ensure we wereable to crawl the desired content as per the RobotsExclusion Protocol (REP) standards11 Mitigating Risks in Content and Model UseWe made significant efforts to minimize offen-sive content in the pre-training data by deliberatelycrawling sites where such content is minimal. Fur-thermore, following a manual review of the auto-completion stereotype tasks outputs, it seems un-likely that the KidLM+ model produces illicit con-tent when given appropriate context. Nevertheless,we cannot provide an absolute guarantee that nosuch content is present. Therefore, we strongly rec-ommend exercising caution when using the KidLMand KidLM+ models. Carbon FootprintTo minimize environmentalimpact, we limited our continual training to theRoBERTa base model using our corpus, thus reduc-ing the carbon footprint associated with traininglarger models. Both the KidLM and KidLM+ mod-els were trained on a single RTX 3090 GPU for atotal of 168 hours, resulting in an estimated carbonemission12 of only 25.4kg.",
  "Acknowledgements": "We thank all the anonymous reviewers and themeta-reviewer for their valuable feedback andconstructive suggestions for improving this work.This research is supported by the Natural Sci-ences and Engineering Research Council of Canada(NSERC). Additionally, Mir Tafseer Nayeem issupported by a Huawei PhD Fellowship. 01. AI, :, Alex Young, Bei Chen, Chao Li, Chen-gen Huang, Ge Zhang, Guanwei Zhang, Heng Li,Jiangcheng Zhu, Jianqun Chen, Jing Chang, KaidongYu, Peng Liu, Qiang Liu, Shawn Yue, Senbin Yang,Shiming Yang, Tao Yu, Wen Xie, Wenhao Huang,Xiaohui Hu, Xiaoyi Ren, Xinyao Niu, PengchengNie, Yuchi Xu, Yudong Liu, Yue Wang, Yuxuan Cai,Zhenyu Gu, Zhiyuan Liu, and Zonghong Dai. 2024.Yi: Open foundation models by 01.ai.Preprint,arXiv:2403.04652. Afra Feyza Akyrek, Muhammed Yusuf Kocyigit, SejinPaik, and Derry Tanti Wijaya. 2022. Challenges inmeasuring bias via open-ended language generation.In Proceedings of the 4th Workshop on Gender Biasin Natural Language Processing (GeBNLP), pages7676, Seattle, Washington. Association for Compu-tational Linguistics. Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster,Marco Dos Santos, Stephen Marcus McAleer, Al-bert Q. Jiang, Jia Deng, Stella Biderman, and SeanWelleck. 2024. Llemma: An open language modelfor mathematics. In The Twelfth International Con-ference on Learning Representations.",
  "Yoshua Bengio, Rjean Ducharme, and Pascal Vincent.2000. A neural probabilistic language model. InAdvances in Neural Information Processing Systems,volume 13. MIT Press": "Steven Bird. 2006.NLTK: The Natural LanguageToolkit. In Proceedings of the COLING/ACL 2006Interactive Presentation Sessions, pages 6972, Syd-ney, Australia. Association for Computational Lin-guistics. Su Lin Blodgett, Solon Barocas, Hal Daum III, andHanna Wallach. 2020.Language (technology) ispower: A critical survey of bias in NLP. In Pro-ceedings of the 58th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 54545476, Online. Association for Computational Lin-guistics.",
  "on a RTX 3090 GPU and Private Infrastructure as the provider": "Elliot Bolton, Abhinav Venigalla, Michihiro Ya-sunaga, David Hall, Betty Xiong, Tony Lee, Rox-ana Daneshjou, Jonathan Frankle, Percy Liang,Michael Carbin, and Christopher D. Manning. 2024.Biomedlm: A 2.7b parameter language model trainedon biomedical text. Preprint, arXiv:2403.18421. Elena Bozzola, Giulia Spina, Rino Agostiniani, SarahBarni, Rocco Russo, Elena Scarpato, AntonioDi Mauro, Antonella Vita Di Stefano, Cinthia Caruso,Giovanni Corsello, and Annamaria Staiano. 2022.The use of social media in children and adoles-cents: Scoping review on the potential risks. In-ternational Journal of Environmental Research andPublic Health, 19(16). Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020.Language models are few-shot learners.In Ad-vances in Neural Information Processing Systems,volume 33, pages 18771901. Curran Associates,Inc.",
  "Jeanne Sternlicht Chall and Edgar Dale. 1995. Read-ability Revisited: The New Dale-Chall ReadabilityFormula. Brookline Books": "Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu,Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi,Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang,Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie.2024. A survey on evaluation of large language mod-els. ACM Trans. Intell. Syst. Technol., 15(3). Liuqing Chen, Shuhong Xiao, Yunnong Chen, Yax-uan Song, Ruoyu Wu, and Lingyun Sun. 2024.Chatscratch: An ai-augmented system toward au-tonomous visual programming learning for childrenaged 6-12. In Proceedings of the CHI Conferenceon Human Factors in Computing Systems, CHI 24,New York, NY, USA. Association for ComputingMachinery. Rochelle Choenni, Ekaterina Shutova, and Robert vanRooij. 2021. Stepmothers are mean and academicsare pretentious: What do pretrained language modelslearn about you? In Proceedings of the 2021 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 14771491, Online and Punta Cana,Dominican Republic. Association for ComputationalLinguistics.",
  "The Nature of Emotion: Fundamental Questions. Ox-ford University Press USA": "Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xi-aocheng Feng, Ming Gong, Linjun Shou, Bing Qin,Ting Liu, Daxin Jiang, and Ming Zhou. 2020. Code-BERT: A pre-trained model for programming andnatural languages. In Findings of the Associationfor Computational Linguistics: EMNLP 2020, pages15361547, Online. Association for ComputationalLinguistics. Isabel O. Gallegos, Ryan A. Rossi, Joe Barrow,Md Mehrab Tanjim, Sungchul Kim, Franck Dernon-court, Tong Yu, Ruiyi Zhang, and Nesreen K. Ahmed.2023. Bias and fairness in large language models: Asurvey. Preprint, arXiv:2309.00770. Yuxian Gu, Zhengyan Zhang, Xiaozhi Wang, ZhiyuanLiu, and Maosong Sun. 2020. Train no evil: Selectivemasking for task-guided pre-training. In Proceed-ings of the 2020 Conference on Empirical Methodsin Natural Language Processing (EMNLP), pages69666974, Online. Association for ComputationalLinguistics. Yue Guo, Yi Yang, and Ahmed Abbasi. 2022. Auto-debias: Debiasing masked language models withautomated biased prompts. In Proceedings of the60th Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages10121023, Dublin, Ireland. Association for Compu-tational Linguistics. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-pat, and Ming-Wei Chang. 2020. Realm: Retrieval-augmented language model pre-training. In Proceed-ings of the 37th International Conference on MachineLearning, ICML20. JMLR.org. Jochen Hartmann, Mark Heitmann, Christian Siebert,and Christina Schamp. 2023.More than a feel-ing: Accuracy and application of sentiment analy-sis. International Journal of Research in Marketing,40(1):7587.",
  "DeBERTav3: Improving deBERTa using ELECTRA-style pre-training with gradient-disentangled embed-ding sharing. In The Eleventh International Confer-ence on Learning Representations": "Jeremy Howard and Sebastian Ruder. 2018. Universallanguage model fine-tuning for text classification.In Proceedings of the 56th Annual Meeting of theAssociation for Computational Linguistics (Volume 1:Long Papers), pages 328339, Melbourne, Australia.Association for Computational Linguistics. Stefan E. Huber, Kristian Kiili, Steve Nebel, Richard M.Ryan, Michael Sailer, and Manuel Ninaus. 2024.Leveraging the potential of large language models ineducation through playful and game-based learning.Educational Psychology Review, 36(1):25. Philip A. Huebner, Elior Sulem, Fisher Cynthia, andDan Roth. 2021. BabyBERTa: Learning more gram-mar with small-scale child-directed language. In Pro-ceedings of the 25th Conference on ComputationalNatural Language Learning, pages 624646, Online.Association for Computational Linguistics. Philip A. Huebner and Jon A. Willits. 2021. Chaptereight - using lexical context to discover the nouncategory: Younger children have it easier. In Kara D.Federmeier and Lili Sahakyan, editors, The Contextof Cognition: Emerging Perspectives, volume 75 ofPsychology of Learning and Motivation, pages 279331. Academic Press.",
  "Lujain Ibrahim, Saffron Huang, Lama Ahmad, andMarkus Anderljung. 2024. Beyond static ai eval-uations: advancing human interaction evaluations forllm harms and risks. Preprint, arXiv:2405.10632": "Sarah J. Ryu,Jonathan M. Tan,and DongheeYvette Wohn. 2021.Dots world: An emotionaldevelopment support platform for children. In Pro-ceedings of the 20th Annual ACM Interaction Designand Children Conference, IDC 21, page 568572,New York, NY, USA. Association for ComputingMachinery. Shaoxiong Ji, Tianlin Zhang, Luna Ansari, Jie Fu,Prayag Tiwari, and Erik Cambria. 2022. Mental-BERT: Publicly available pretrained language modelsfor mental healthcare. In Proceedings of the Thir-teenth Language Resources and Evaluation Confer-ence, pages 71847190, Marseille, France. EuropeanLanguage Resources Association. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, Llio Renard Lavaud,Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,Thibaut Lavril, Thomas Wang, Timothe Lacroix,and William El Sayed. 2023. Mistral 7b. Preprint,arXiv:2310.06825. Youngjin Jin, Eugene Jang, Jian Cui, Jin-Woo Chung,Yongjae Lee, and Seungwon Shin. 2023. DarkBERT:A language model for the dark side of the Internet.In Proceedings of the 61st Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 75157533, Toronto, Canada.Association for Computational Linguistics. Masahiro Kaneko and Danushka Bollegala. 2021. De-biasing pre-trained contextualised embeddings. InProceedings of the 16th Conference of the EuropeanChapter of the Association for Computational Lin-guistics: Main Volume, pages 12561266, Online.Association for Computational Linguistics.",
  "Spyretta Leivaditi,Julien Rossi,and EvangelosKanoulas. 2020. A benchmark for lease contractreview. Preprint, arXiv:2010.10386": "Chak Leong, Yi Cheng, Jiashuo Wang, Jian Wang, andWenjie Li. 2023. Self-detoxifying language mod-els via toxification reversal. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing, pages 44334449, Singapore.Association for Computational Linguistics. Percy Liang, Rishi Bommasani, Tony Lee, DimitrisTsipras, Dilara Soylu, Michihiro Yasunaga, YianZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-mar, Benjamin Newman, Binhang Yuan, Bobby Yan,Ce Zhang, Christian Alexander Cosgrove, Christo-pher D Manning, Christopher Re, Diana Acosta-Navas, Drew Arad Hudson, Eric Zelikman, EsinDurmus, Faisal Ladhak, Frieda Rong, Hongyu Ren,Huaxiu Yao, Jue WANG, Keshav Santhanam, LaurelOrr, Lucia Zheng, Mert Yuksekgonul, Mirac Suzgun,Nathan Kim, Neel Guha, Niladri S. Chatterji, OmarKhattab, Peter Henderson, Qian Huang, Ryan An-drew Chi, Sang Michael Xie, Shibani Santurkar,Surya Ganguli, Tatsunori Hashimoto, Thomas Icard,Tianyi Zhang, Vishrav Chaudhary, William Wang,Xuechen Li, Yifan Mai, Yuhui Zhang, and Yuta Ko-reeda. 2023. Holistic evaluation of language models.Transactions on Machine Learning Research. Fea-tured Certification, Expert Certification. Bill Yuchen Lin, Abhilasha Ravichander, Ximing Lu,Nouha Dziri, Melanie Sclar, Khyathi Chandu, Chan-dra Bhagavatula, and Yejin Choi. 2024. The unlock-ing spell on base LLMs: Rethinking alignment viain-context learning. In The Twelfth InternationalConference on Learning Representations. Chen Lin, Timothy Miller, Dmitriy Dligach, StevenBethard, and Guergana Savova. 2021. EntityBERT:Entity-centric masking strategy for model pretrain-ing for the clinical domain. In Proceedings of the20th Workshop on Biomedical Language Processing,pages 191201, Online. Association for Computa-tional Linguistics. Ruibo Liu, Jerry Wei, Fangyu Liu, Chenglei Si, YanzheZhang, Jinmeng Rao, Steven Zheng, Daiyi Peng, DiyiYang, Denny Zhou, and Andrew M. Dai. 2024. Bestpractices and lessons learned on synthetic data forlanguage models. Preprint, arXiv:2404.07503. Yang Liu. 2024. Quantifying stereotypes in language.In Proceedings of the 18th Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics (Volume 1: Long Papers), pages 12231240, St. Julians, Malta. Association for Computa-tional Linguistics. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,Luke Zettlemoyer, and Veselin Stoyanov. 2019.Roberta: A robustly optimized bert pretraining ap-proach. arXiv preprint arXiv:1907.11692. Shayne Longpre, Gregory Yauney, Emily Reif, Kather-ine Lee, Adam Roberts, Barret Zoph, Denny Zhou,Jason Wei, Kevin Robinson, David Mimno, andDaphne Ippolito. 2024. A pretrainers guide to train-ing data: Measuring the effects of data age, domaincoverage, quality, & toxicity. In Proceedings of the2024 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies (Volume 1: Long Pa-pers), pages 32453276, Mexico City, Mexico. Asso-ciation for Computational Linguistics.",
  "Moin Nadeem, Anna Bethke, and Siva Reddy. 2021": "StereoSet: Measuring stereotypical bias in pretrainedlanguage models. In Proceedings of the 59th AnnualMeeting of the Association for Computational Lin-guistics and the 11th International Joint Conferenceon Natural Language Processing (Volume 1: LongPapers), pages 53565371, Online. Association forComputational Linguistics. Mir Tafseer Nayeem and Davood Rafiei. 2023. On therole of reviewer expertise in temporal review helpful-ness prediction. In Findings of the Association forComputational Linguistics: EACL 2023, pages 16841692, Dubrovnik, Croatia. Association for Computa-tional Linguistics.",
  "OpenAI. 2023b. Moderation. Accessed: December 05,2023": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,Carroll Wainwright, Pamela Mishkin, Chong Zhang,Sandhini Agarwal, Katarina Slama, Alex Ray, JohnSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,Maddie Simens, Amanda Askell, Peter Welinder,Paul F Christiano, Jan Leike, and Ryan Lowe. 2022.Training language models to follow instructions withhuman feedback. In Advances in Neural InformationProcessing Systems, volume 35, pages 2773027744.Curran Associates, Inc. Gustavo H. Paetzold and Lucia Specia. 2016. Unsuper-vised lexical simplification for non-native speakers.In Proceedings of the Thirtieth AAAI Conference onArtificial Intelligence, AAAI16, page 37613767.AAAI Press. Guilherme Penedo, Quentin Malartic, Daniel Hesslow,Ruxandra Cojocaru, Hamza Alobeidli, AlessandroCappelli, Baptiste Pannier, Ebtesam Almazrouei, andJulien Launay. 2023. The refinedweb dataset for fal-con LLM: Outperforming curated corpora with webdata only. In Thirty-seventh Conference on NeuralInformation Processing Systems Datasets and Bench-marks Track. Jesse Pepping, Sarah Scholte, Marnix van Wijland, Mi-lan de Meij, Gnter Wallner, and Regina Bernhaupt.2020. Motiis: Fostering parents awareness of theiradolescents emotional experiences during gaming.In Proceedings of the 11th Nordic Conference onHuman-Computer Interaction: Shaping Experiences,Shaping Society, NordiCHI 20, New York, NY, USA.Association for Computing Machinery.",
  "Victoria Rideout, Alanna Peebles, Supreet Mann, andMichael B. Robb. 2022. Common Sense Census:Media Use by Tweens and Teens. Common Sense,San Francisco, CA": "Julian Salazar, Davis Liang, Toan Q. Nguyen, and Ka-trin Kirchhoff. 2020. Masked language model scor-ing. In Proceedings of the 58th Annual Meeting ofthe Association for Computational Linguistics, pages26992712, Online. Association for ComputationalLinguistics. Kyle-Althea Santos, Ethel Ong, and Ron Resurreccion.2020. Therapist vibe: childrens expressions of theiremotions through storytelling with a chatbot. In Pro-ceedings of the Interaction Design and Children Con-ference, IDC 20, page 483494, New York, NY,USA. Association for Computing Machinery.",
  "Woosuk Seo, Chanmo Yang, and Young-Ho Kim. 2024b": "Chacha: Leveraging large language models to promptchildren to share their emotions about personal events.In Proceedings of the CHI Conference on HumanFactors in Computing Systems, CHI 24, New York,NY, USA. Association for Computing Machinery. Jia Tracy Shen, Michiharu Yamashita, Ethan Prihar,Neil T. Heffernan, Xintao Wu, and Dongwon Lee.2021. Mathbert: A pre-trained language model forgeneral NLP tasks in mathematics education. CoRR,abs/2106.07340. Shivalika Singh, Freddie Vargus, Daniel Dsouza,Brje F. Karlsson, Abinaya Mahendiran, Wei-YinKo, Herumb Shandilya, Jay Patel, Deividas Mat-aciunas, Laura OMahony, Mike Zhang, RamithHettiarachchi, Joseph Wilson, Marina Machado,Luisa Souza Moura, Dominik Krzeminski, HakimehFadaei, Irem Ergn, Ifeoma Okoh, Aisha Alaagib,Oshan Mudannayake, Zaid Alyafeai, Vu Minh Chien,Sebastian Ruder, Surya Guthikonda, Emad A. Al-ghamdi, Sebastian Gehrmann, Niklas Muennighoff,Max Bartolo, Julia Kreutzer, Ahmet stn, MarziehFadaee, and Sara Hooker. 2024. Aya dataset: Anopen-access collection for multilingual instructiontuning. In Proceedings of the 62nd Annual Meet-ing of the Association for Computational Linguistics,Bangkok, Thailand.",
  "Wilson L Taylor. 1953.cloze procedure: A newtool for measuring readability. Journalism quarterly,30(4):415433": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian CantonFerrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. 2023. Llama 2: Open foundation and fine-tuned chat models. Preprint, arXiv:2307.09288. Maria Valentini, Jennifer Weber, Jesus Salcido, TaWright, Eliana Colunga, and Katharina von derWense. 2023. On the automatic generation and sim-plification of childrens stories. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing, pages 35883598, Singapore.Association for Computational Linguistics. Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,Adams Wei Yu, Brian Lester, Nan Du, Andrew M.Dai, and Quoc V Le. 2022. Finetuned language mod-els are zero-shot learners. In International Confer-ence on Learning Representations. Laura Weidinger, Maribeth Rauh, Nahema Marchal, Ar-ianna Manzini, Lisa Anne Hendricks, Juan Mateos-Garcia, Stevie Bergman, Jackie Kay, Conor Grif-fin, Ben Bariach, Iason Gabriel, Verena Rieser,and William Isaac. 2023.Sociotechnical safetyevaluation of generative ai systems.Preprint,arXiv:2310.11986. Alexander Wettig, Tianyu Gao, Zexuan Zhong, andDanqi Chen. 2023. Should you mask 15% in maskedlanguage modeling?In Proceedings of the 17thConference of the European Chapter of the Asso-ciation for Computational Linguistics, pages 29853000, Dubrovnik, Croatia. Association for Computa-tional Linguistics. Alex Wilf, Syeda Akter, Leena Mathur, Paul Liang,Sheryl Mathew, Mengrou Shou, Eric Nyberg, andLouis-Philippe Morency. 2023. Difference-masking:Choosing what to mask in continued pretraining. InFindings of the Association for Computational Lin-guistics: EMNLP 2023, pages 1322213234, Singa-pore. Association for Computational Linguistics.",
  "Yi Yang, Mark Christopher Siy UY, and AllenHuang. 2020.Finbert:A pretrained languagemodel for financial communications.Preprint,arXiv:2006.08097": "Chunting Zhou, Pengfei Liu, Puxin Xu, Srinivasan Iyer,Jiao Sun, Yuning Mao, Xuezhe Ma, Avia Efrat, PingYu, LILI YU, Susan Zhang, Gargi Ghosh, MikeLewis, Luke Zettlemoyer, and Omer Levy. 2023.Lima: Less is more for alignment. In Advances inNeural Information Processing Systems, volume 36,pages 5500655021. Curran Associates, Inc. Y. Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urta-sun, A. Torralba, and S. Fidler. 2015. Aligning booksand movies: Towards story-like visual explanationsby watching movies and reading books. In 2015IEEE International Conference on Computer Vision(ICCV), pages 1927, Los Alamitos, CA, USA. IEEEComputer Society. Sanja tajner, Daniel Ferrs, Matthew Shardlow, KaiNorth, Marcos Zampieri, and Horacio Saggion. 2022.Lexical simplification benchmarks for english, por-tuguese, and spanish. Frontiers in Artificial Intelli-gence, 5.",
  "AData Preprocessing": "We removed URLs and HTML markups, includ-ing only textual content while excluding lists, ta-bles, and headers, as well as sentences contain-ing code-switching (TAY, 1989). In linguistics,code-switching (a.k.a., language alternation) oc-curs when a speaker alternates between two ormore languages (or language varieties) from onesentence to another. Code-Switching is intersen-tential and inspired by social and psychologicalmotivations. We only took the sentences writtenin English and considered any other language ascode-switching. We used the spacy-langdetect13 module to identify languages. While doing this, wenoticed the presence of words from multiple lan-guages within a single sentence, a phenomenonwidely known as code-mixing (Mabule, 2015),when the speaker mixes various linguistic unitsfrom different languages in a single utterance orsentence. To address this problem, we used the con-fidence scores from the language detection modeland only kept sentences with scores greater than orequal to 0.9. Protection of PrivacyWe deliberately chosenot to collect specific information, such as authornames (whether they are children or reporters) andthe publication dates of articles. Additionally, wepreprocess the data to remove any personal contactdetails, including email addresses, phone numbers,and Twitter handles, by applying simple regularexpressions to the pre-training corpus, following(Nayeem and Rafiei, 2023). As a result, our datasetminimizes the presence of Personal Identifying In-formation (PII). This decision highlights our com-mitment to prioritizing user privacy.",
  "BTraining & Hyperparameters": "We trained our model on a single RTX 3090 GPUwith 24GB of memory. The AdamW optimizer(Loshchilov and Hutter, 2019) was employed witha learning rate of 5 105. We utilized the pre-trained checkpoint of the RoBERTa (Liu et al.,2019) base model and its pre-trained tokenizer,avoiding the use of any custom vocabulary. Tofacilitate larger batch sizes, we implemented gra-dient accumulation. The same hyperparameterswere applied for both KidLM and KidLM+ models.",
  "CClosed-Source Models": "We chose not to compare our models with closed-source models accessed through APIs, such asClaude-214, ChatGPT (gpt-3.5-turbo-061315),and GPT-4 (OpenAI, 2023a). These APIs likelyincorporate complex engineering solutions, poten-tially involving multiple models chained together,making them fundamentally different and not di-rectly comparable to standalone models. For in-stance, OpenAI has implemented a content moder-ation filter for their language models, which eval-uates the outputs based on criteria such as hate,self-harm, sexual content, and violence (Markovet al., 2023; OpenAI, 2023b). To draw an analogy,while a model is akin to an engine, an API is morecomparable to a car. Therefore, our comparison",
  "DDomain Adaptation of LMs": "The adaptation of language models to specific do-mains typically follows two strategies. The firstinvolves training a new model from scratch withdata from the targeted domain. The second strat-egy, known as continual pre-training (Howard andRuder, 2018), involves further training pre-existingmodels to transition from a generic to a specializedmodel. While there have been numerous studiesadapting models to target domains like Program-ming (Feng et al., 2020), Academic (Shen et al.,2021), Biomedical (Bolton et al., 2024), Mathemat-ics (Azerbayev et al., 2024), Healthcare (Rasmyet al., 2021), Finance (Yang et al., 2020), Legal(Leivaditi et al., 2020), Mental Health (Ji et al.,2022), and the Dark Web (Jin et al., 2023). Domain-specific LMs are often trained using easily acces-sible, publicly available corpora. However, identi-fying the authors and intended purposes of thesepublicly sourced texts is challenging, which is cru-cial for a user-centric language model (e.g., forchildren). There is limited research on develop-ing language models for specific user groups; themost relevant study we found was BabyBERTa(Huebner et al., 2021), which focused on the taskof language acquisition in children aged 1 to 6.BabyBERTas corpus, AO-CHILDES (Huebnerand Willits, 2021), comprises approximately 5 mil-lion words with a vocabulary of around 8,000, andis geared toward children aged 1-6 years, reflectingspoken language. In contrast, our model utilizesour own corpus with around 50.5 million wordsand a broader vocabulary of approximately 50,000,suitable for general children and focused on writtenlanguage ().",
  "Politicalcapitalists, communists, conservatives, immigrants, liberals, populists,socialists, Trump supporters8": "EthnicitiesAfricans, Asians, Asian kids, Asian men, Asian parents, Asian women,African Americans, Black Americans, Blacks, Black fathers, Black kids,Black men, Black parents, Black people, Black women, Europeans, His-panics, Hispanic men, Hispanic women, Latinas, Latinos, Latin people,Native Americans, Whites, White Americans, White kids, White men,White parents, White people, White women, redheads, gingers, blondes NationalitiesAmericans, Afghans, Albanians, Arabs, Australians, Austrians, Bengalis,British people, Chileans, Colombians, Dutch people, Egyptians, Ecuado-rians, Ethiopians, Finns, French people, Germans, Ghanaians, Greeks,Indians, Indonesians, Iranians, Iraqis, Irish people, Italians, Koreans,Lebanese people, Mexicans, Moroccans, Nepalis, Nigerians, Norwe-gians, Pakistanis, Polish people, Romanians, Russians, Scots, Somalis,South Africans, Sudanese people, Swedes, Syrians, Taiwanese people,Turkish people, Ukrainians, Venezuelans, Vietnamese people",
  "Not Applicable": "News for KidsNewsForKids.net was created by a teacher to make thenews accessible to kids. They carefully choose high-intereststories appropriate for the audience and present them in away that is easy to understand. They work hard to use simplelanguage when telling the stories, aiming to be as inclusiveas possible. The goal is to ensure that advanced readers canread \"down\" comfortably, while struggling readers are notleft behind with content that is too challenging for them toread \"up.\"",
  "Elementaryschool-aged children:Gen-erally,thisgroupincludeschildrenfrom Kindergarten to5th grade, which isapproximately ages 5to 11. Last Accessed:20December2022.Nowthisserverisdead": "Kids FrontiersFrontiers for Young Minds strongly believes in makingcutting-edge science discoveries accessible to younger au-diences. To achieve this, the platform fosters collaborationbetween young people and scientists to create top-qualityand captivating articles. Esteemed scientists are invited towrite about their discoveries using language that is easilyunderstandable for young readers. Subsequently, the kidsthemselves, along with a science mentor, actively partici-pate by providing feedback and suggestions to the authorsto enhance the articles before publication. The platformsdedication to empowering the youth and promoting scien-tific understanding makes it a valuable resource for youngminds.",
  "SN.CData SourceDescriptionGenreAdditional Notes": "Kids News NYCKids News NYC is for anyone under 12 years old wholives in or around New York City, has a love for explor-ing, learning, and noticing their surroundings, and wantsto report on it to other kids! Created by Waverly W., the8-year-old Kiditor in Chief, with a little help from her mom,Kids News NYC is all about YOU! (the reader). It servesas an online newspaper and YouTube Channel dedicatedto all the news, events, people, and things that interest citykids or kids who wish they were city kids! The differenceis that here, the kids create the news.",
  "Kids News NYC is foranyone under 12 yearsold": "Kids News (India)The news portal exclusively for children offers engagingand relevant news items covering nature, history, space, andother interesting topics. Children can actively participateby sending their own contributions like art and creativewriting. The portal provides simple explanatory articlesto help children understand complex words and concepts.Additionally, kids can enjoy puzzles, riddles, book reviews,stories, and other captivating content unique to the platform.The safety of the environment, free from ads, ensures asecure and enjoyable online experience for young users.",
  "History, Science, Innovation,Arts & Culture, Travel etc.Weextractedthearticles tagged for chil-dren(": "Teaching Kids NewsEvery story is in kid-friendly language and appropriate forkids in grades 3 to 8. Beyond just making the vocabularyaccessible, they provide context for everything in each newsstory, so kids can understand whats going on, and why. Inthe curriculum connections they encourage kids to thinkcritically not only about the story itself, but about the waythe story is presented.",
  "Politics, Opinions, Climate,Tech, Lifestyle, and World.Wecollectedthearticles tagged as kid-spost (": "Indy KidsThe mission of IndyKids is to engage young people andempower them to become informed global citizens throughthe creation of a current events and social justice newssource that is produced for kids, by kids. Throughout theirprograms, they inspire a passion for social justice issues toempower the next generation of critical thinkers, communityleaders, journalists and activists.",
  "Current Events and Social Jus-tice issues.Not Applicable": "Kids NewsKids News is a free news-based literacy tool designed forclassrooms, catering to students from Grade 3 to Year 8.The content is written into educational stories in child ap-propriate language and filtered/censored to remove any in-appropriate content or imagery. It employs a traffic lightsystem to guide teachers in directing students to suitablecontent based on their comprehension levels. Green in-dicates simple to medium vocabulary, easily understoodstories accessible to all readers. Orange signifies a mediumlevel of vocabulary and slightly more complex stories suit-able for middle to senior primary level with the aid of audioand a glossary. Red denotes content with high-level vocabu-lary and complexity, best suited for more proficient readerswith teacher support for less capable ones.",
  "Science,Sport,History,Space,Weather,Animals,Health, Geography, Civics,Humanities,Technology,Environment,Money,Ex-plainers, Arts, Mathematics,etc": "Kids News is a freenews-basedliteracytooldesignedforclassrooms, catering tostudents from Grade 3to Year 8 (correspondsto the period whenstudents are around 12to 13 years old). Wetook the Green andOrange level contentsand filtered out theRedlevelonestomaintain the quality. Kiwi Kids NewsKiwi Kids News serves as the news platform catering tostudents and educators in New Zealand. It publishes 3 to 4pertinent news articles on a daily basis throughout the term.Since its establishment in 2010, the websites popularityhas steadily increased.",
  "Book reviewsWe collected the datafromthecategoriesGrade K-1, Grade 2-3, Grade 4-5, Grade 6-9 (we limit this to age12 from the author re-ported age, which isequivalent to Grade 6)": "ToppstaToppsta is a solution for those overwhelmed by the vastselection of childrens books. With numerous new releaseseach year, it can be challenging to know where to start.Toppsta aims to be the go-to platform where readers canrecommend the finest books to one another. Whether yourea parent, grandparent, teacher, or librarian, the book re-views on Toppsta.com assist in discovering the best booksfor children, benefiting various readers and book-relatedprofessionals.",
  "Book ReviewsNot Applicable": "Simple WikiSimple Wikipedia is a distinct version of the widely usedWikipedia. It is written in basic English, making it suit-able for younger kids, tweens, or even teens who read ata lower grade level. The simplified version still functionsas an online encyclopedia, but its sentences are shorter andgrammar is easier to understand. Simple Wikipedia canalso prove beneficial for individuals from cultures that arein the process of learning English or those with a limitedunderstanding of the language. Additionally, it is a helpfulresource for readers with learning disabilities. The genres or topics cov-ered on Simple Wikipediaare similar to those on reg-ular Wikipedia and includeScience,History,Geogra-phy, Biographies, Mathemat-ics, Technology, Arts and Cul-ture, Health and Medicine,Animals and Nature, Sports,etc."
}