{
  "Abstract": "Dialogue Aspect-based Sentiment Quadrupleanalysis (DiaASQ) extends ABSA to morecomplex real-world scenarios (i.e., dialogues),which makes existing generation methods en-counter heightened noise and order bias chal-lenges, leading to decreased robustness andaccuracy. To address these, we propose theSegmentation-Aided multi-grained Denoisingand Debiasing (SADD) method. For noise, wepropose the Multi-Granularity Denoising Gen-eration model (MGDG), achieving word-leveldenoising via sequence labeling and utterance-level denoising via topic-aware dialogue seg-mentation. Denoised Attention in MGDG inte-grates multi-grained denoising information tohelp generate denoised output. For order bias,we first theoretically analyze its direct cause asthe gap between ideal and actual training objec-tives and propose a distribution-based solution.Since this solution introduces a one-to-manylearning challenge, our proposed Segmentation-aided Order Bias Mitigation (SOBM) methodutilizes dialogue segmentation to supplementorder diversity, concurrently mitigating thischallenge and order bias. Experiments demon-strate SADDs effectiveness, achieving state-of-the-art results with a 6.52% F1 improvement.",
  "Introduction": "Dialogue Aspect-based Sentiment Quadruple Ex-traction task (DiaASQ) (Li et al., 2023a) is a sub-task of Aspect-based Sentiment Analysis (ABSA),aiming to extract sentiment quadruples in dia-logues, i.e., Target: mentioned objects, Aspect:components of targets, Opinion: expressions con-veying comments, and Sentiment: polarity of tar-gets. Recently, Li et al. (2023a) proposed a dis-criminative model to control the information fusionamong utterances, ultimately classifying differentelements separately. However, this method failsto utilize the connections between tuple elements",
  "Previous Mothed": "After watching the OLED screen for a long time, the eyes are tired and sore. Especially in the case of low brightness,it becomes strenuous to discern details, straining the eyes further. There is no eye problem with the LCD screen before. After changing to the iPhone X, my eyesight has deteriorated a lot. Now using xr back, my eyes is comfortable again",
  "MGDG Encoder": "After watching the OLED screen for a long time, the eyes are tired and sore. Especially in the case of low brightness,it becomes strenuous to discern details, straining the eyes further. There is no eye problem with the LCD screen before. After changing to the iPhone X, my eyesight has deteriorated a lot. Now using xr back, my eyes is comfortable again",
  "exchange position": ": Noise refers to irrelevant words in dialogue(highlighted in orange), which lead the model to gen-erate incorrect quadruples. Order Bias occurs whenthe model erroneously learns non-existent tuple orderdependencies (highlighted in yellow boxes). Throughdenoising and debiasing, our SADD method enhancesthe performance of quadruple extraction. fully. Generative methods (Zhang et al., 2021a,b;Mao et al., 2022; Gou et al., 2023) succeeded inframing ABSA as a text-to-text task with robustgeneralization capabilities and fully leverage ele-ment connections, which inspired us.However, generative methods still face two sig-nificant challenges: Noise and Order Bias, as illus-trated in Fig 1. 1. Noise is extraneous words indialogues that interfere with the quadruple gener-ation process, as illustrated by the orange wordsin . These extraneous words often disruptthe predicted quadruples; for instance, the termsbrightness and low interfere with previous meth-ods, leading to an incorrect quadruple. 2. OrderBias is an irrational causal relationship caused bythe fixed order of quadruple labels, like the yellowrelationships in . As shown in , weformulate Diaasq task as a text-to-text problem: In-put text Q1, Q2 (just like ) , where thelabel is a sequence of tuples. However, the orderbetween the tuples does not inherently exist, andthe generation of Q2 should not be conditioned on Q1. This labeling scheme compels previous mod-els to establish an order dependency from Q2 to Q1(xr->iPhone) and a causal relationship betweenthe input and the order of tuples. However, suchorder dependency and causal relationships do notactually exist. These incorrect constraints hinderthe models generalization. A further explanationof noise and bias is shown in Appendix A.1. Toaddress these, we propose a novel Segmentation-Aided multi-granularity Denoising and Debiasing(SADD) method, including the following modules.Denoising: Specifically, we first propose a novelMulti-Granularity Denoising Generation (MGDG)module to reduce noise at the word and utterancelevels. As shown in , our MEDG moduleidentifies and eliminates the noise \"Especially in... before.\", thereby achieving denoising. At theword level, we employ sequence labeling to labeltuple elements. At the utterance level, we adopttopic-aware dialogue segmentation to achieve topic-centric utterance clustering, followed by generatingtopic masks based on clusters. Finally, we mergeprobability from the sequence labeling task andtopic masks from the segmentation task into thedecoders denoised attention to generate denoisedoutput. By emphasizing in-tuple and topic-relatedelements, denoised attention effectively makes themodel more accurate and robust in tuple extractiontasks.Our Topic-Aware Dialog Segmentation (TADS)differs from previous segmentation methods by ex-plicitly introducing fine-grained topics information.Unlike existing methods (Wu et al., 2020a; Xieet al., 2021) that directly analyze complex contextsbetween utterances, we establish fine-grained rela-tions between topic words and utterance sentencesby cross-attention interaction, ultimately indirectlyanalyzing relationships between sentences. Theseimprove models robustness and accuracy in thesegmentation of complex dialogue.Debiasing: For the second challenge, we be-gin with theoretically analyzing the direct cause oforder bias: the gap between the ideal and actualtraining objectives. By further analyzing the gapand the Maximum Likelihood Estimation (MLE)from a distribution perspective, we find a solutionto augment order diversity at the data level, yet thisposes a one-to-many learning problem. To solvethese challenges, we propose a Segmentation-aidedOrder Bias Mitigation (SOBM) method to tackleorder bias as shown in the lower part of . Weleverage dialogue segmentation to generate multi- ple inputs that meet a specific criterion. We thenpair these inputs with various feasible labels to cre-ate new samples, thereby increasing the diversityof tuple orders. The SOBM narrows the gap be-tween ideal and actual training objectives, therebymitigating order bias in the generation method.In summary, our contributions are as follows:1. We introduce a novel multi-granularity de-noising generation model to mitigate interferencenoise through word-level sequence labeling andutterance-level topic masks.2. We propose a topic-aware dialogue segmenta-tion model to streamline context analysis and estab-lish fine-grained relationships between utterancesby introducing topic words as a bridge.3. We uncover the direct cause of order bias andmitigate its impact by enhancing the data distribu-tion through dialogue segmentation.4. Our SADD method is validated on the widelyused dataset and achieves state-of-the-art perfor-mance with a 6.52% F1 improvement.",
  "Related Works": "Aspect-Based Sentiment Analysis (Thet et al.,2010) primarily focuses on short texts (i.e., 1 or 2sentences text) like reviews and emphasizes senti-ment interpretability. ABSA methods analyze ele-ments such as target (Li et al., 2019a,b), target cate-gories (Zhang et al., 2021a), specific aspects, directopinions (Peng et al., 2020) and so on. Quadru-ple extraction, involving four key elements, is amore comprehensive sentiment analysis task. Main-stream ABSA methods include sequence labeling(Wu et al., 2020b; Chen et al., 2022; Liang et al.,2023) and generative methods (Gao et al., 2022;Yu et al., 2023; Gou et al., 2023), with the latterknown for robustness and generalization. However,existing ABSA models face challenges in dealingwith complex textual content and structures whenapplied to dialogue texts, highlighting the need foradvancements in this domain.Dialogue Segmentation aims to segment a dia-logue into pieces based on topics discussed, enhanc-ing comprehension for downstream tasks (Zhonget al., 2022). Existing unsupervised Deep Learn-ing(DL) methods use a pre-trained model withoutfine-tuning for segmentation (Xu et al., 2021b; De-vlin et al., 2019; Xing and Carenini, 2021). DL-based methods directly analyze the context of twoutterances and predict their relationships with fine-tuned CLS tokens, like TOD-BERT (Wu et al., 2020a) and RetroTS-T5 (Xie et al., 2021). How-ever, analyzing two utterances directly can be chal-lenging, especially with complex contexts involv-ing multiple topics or lacking explicit topics.Previous Methods for Addressing Tuple Or-der Bias mainly focused on addressing the orderbias by modifying the model.They used non-autoregressive transformers (Sui et al., 2021; Tanet al., 2021) or set up multiple output heads (Yeet al., 2021) to generate results in an unorderedmanner. However, these methods have limited thegenerality of the model. \"Set\" (Li et al., 2023b)adjusts the loss function to force the model to min-imize overall loss for all feasible labels globally.However, this approach actually forces models tolearn a one-to-many mapping, hindering them fromconverging to optimal performance.",
  "Task Definition": "The input of the DiaASQ task is a n-utterance andN-word dialogue D={u1, . . . , un}, where ui repre-sents the i-th utterance. DiaASQ aims to extract allquadruples (target, aspect, opinion, sentiment)from the dialogue, where the target, aspect, andopinion are sub-strings of D, and sentiment {pos , neg, other}. In the example \"I didnt buy itsince my friend said the Xiaomi 11 has poor bat-tery life,\" the corresponding quadruple is (Xiaomi11, battery life, poor, neg).",
  "Method": "In the DiaASQ task, generation models facetwo significant challenges: noise and order bias.To mitigate noise, we propose a novel Multi-Granularity Denoising Generation approach involv-ing sequence labeling, topic-aware dialogue seg-menting, and denoising generation, as shown in. By employing sequence labeling and topic-aware dialogue segmentation, we acquire denoisinginformation at both the utterance and word levels.Then, we integrate this multi-grained denoising in-formation to guide the model in generating quadru-ples more accurately and robustly. For order bias,we uncover its cause as the gap between the ac-tual and the ideal training objective. We propose anovel Segmentation-aided Order Bias Mitigation(SOBM) method to narrow the gap with dialog seg-mentation. This method simultaneously addressesboth the one-to-many training challenge and theorder bias.",
  "Multi-Granularity Denoising Generation": "Due to the extensive content and intricate struc-ture of dialogues, the model is susceptible tonoise.To address noise, we propose a novelMulti-Granularity Denoising Generation methodto reduce the noise at the word and utterance lev-els. Specifically, we leverage sequence labelingto mitigate noise at the word levels, and employtopic-aware dialogue segmentation to cluster sen-tences with the same topics, thereby eliminatingnoise from irrelevant sentences. We generate de-noised outputs with the decoders denoised atten-tion which combines multi-grained information. 4.1.1Labeling for Word-level DenoisingWord-level denoising identifies and emphasizesquadruple elements to reduce noise. For a dia-logue D, we concatenate all utterances and en-code them using the generation models encoder:e=Encoder([u1; . . . ; un]).Then, we employ aclassification layer to label the quadruple elementsin e with a loss Llabeling. Each word ei in e isclassified into one of four categories (None, Target,Aspect, Opinion) using pi=Softmax(W1 ei + b1),where pi R4. This process classifies all words ine to generate P RN4.",
  "Topic-aware Dialogue Segmentation forUtterance-level Denoising": "Existing dialog segmentation methods directly an-alyze the complex context between utterances todetermine their relationship, i.e., whether they be-long to the same topic. However, these methodscan struggle with complex utterance contexts, es-pecially those involving multiple topics or lackingexplicit topic mentions. To simplify the contextanalysis, we indirectly establish fine-grained rela-tionships between utterances by examining theirrelationships with the same topic. This employstopics as bridges, streamlining the contextual anal-ysis and enhancing the models robustness in com-plex contexts. Moreover, we utilize cross-attentionfor fine-grained information fusion between topicsand utterances, which helps resolve semantic-levelcoreferences for topics (Experiment 5.3.3).Fine-grained Interaction We designate thosewords labeled as \"Target\" (in section 4.1.1) asthe primary \"topics\" of the utterances becausethe target words are the cores of the quadru-ples and are highly relevant to the utterance top-ics. The topic embedding ti for i-th topic (i.e.,target) is selected from e according to its posi-",
  "utterances": ": (a) Overview of the MGDG model. (b) Topic-aware Dialogue Segmentation module utilizes cross-attentionto explore fine-grained correlations between utterances and topics, facilitating topic-centric clustering of utterances.Subsequently, we create a topic mask for each cluster. (c) The Denoising-Constrained Generation module integratesthe denoising information into cross-attention to guide generation, resulting in denoised outputs. tion. All topic embeddings are concatenated intoTtp=[t1; . . . ; tk]Rkdim. The utterance embed-ding eui for i-th utterance ui is directly extractedfrom e without pooling. eui R|ui|dim, where|ui| means the number of words in ui. Feed themto cross-attention layers (Ttp as Query, ui as Key",
  "eui, where": "O Rkdim. Pass O to a classification layer topredict whether ui has fine-grained associations(e.g. discussing relations) with {t1, . . . , tk} con-currently, with loss Ltopic. During training, the po-sitions of the \"Target\" words are determined by theground truth; during testing, they are determinedby the predictions of the preceding module.Topic Mask Applying these steps to all utter-ances {u1, . . . , un}, we predict the relationshipsbetween all utterances and {t1, . . . , tk}. If bothui and uj discuss tv, these two utterances can begrouped into the same v-th cluster. In this way, weestablish fine-grained relations between utterancesand aggregate utterances with the same topic intotopic-centric clusters. Based on these clusters, wegenerate topic masks. Each topic mask m(i) RN",
  "wi =rj exp (wi,j)j rj exp (wi,j)(2)": "where Pj,0 denotes probabilities of the input dia-logues j-th word belonging to the \"None\" category,Pj RN denotes probabilities of j-th input wordbeing quadruple elements, m(k)j {0, 1} indicateswhether the j-th word is masked r RN is multi-granularity denoising information, w RNN isthe original cross-attention weights, wi,j signifiesthe weight of the i-th generated token relative tothe j-th input token, and wi is the weights afteradjusted to incorporate the multi-granularity de-noising information. During training, the topicmasks are replaced by ground truth masks; duringtesting, we employ the predicted topic masks.Multi-granularity denoising To ensure the com-patibility of our method with pre-trained models,we can directly replace the cross-attention in pre-trained generation models decoders with the De-noised Attention. Train this generation task witha loss Lgeneration. The topic mask mi enablesutterance-level denoising by constraining cross-attention scope to utterances within i-th topic clus-ter. This diminishes noisy utterances that do notmention the potential targets. The probabilities P facilitate word-level denoising by guiding themodel to prioritize words identified as quadrupleelements by the sequence labeling module. This ef-fectively reduces noise from non-quadruple words.This multi-granularity denoising approach controlsattention scope and adjusts attention weight to re-duce noise, thereby enhancing extraction accuracyand robustness.Overall loss L=Llabeling+Ltopic+Lgeneration.",
  "Order Bias Mitigation": "Although previous works have shown the effective-ness of generative extraction methods, they oftenoverlooked the accompanying issue of order bias,as shown in . Existing solutions for orderbias exhibit poor generalizability and scalability.To address order bias and ensure strong generaliz-ability, we begin with a theoretical analysis reveal-ing that the gap between practical and ideal trainingobjectives leads to order bias. By further analyzingthe gap and MLE from a distribution perspective,we find a data-driven solution to narrow the gap.However, this solution faces a one-to-many train-ing challenge. To address this, we leverage dialogsegmentation to enrich the order diversity withinthe data distribution, thereby mitigating the one-to-many training issue and order bias.",
  "(3)": "where p represents the data distribution, and p(x)denotes the probability of x occurring in the natu-ral language context. When training a generativemodel for DiaASQ, for each input x, the associatedideal goal S is an unordered set of quadruples. Byconcatenating the quadruples in S in all possiblepermutation orders , we get a set of all feasiblelabels ((S)={1(S), 2(S), . . . }). According toAppendix B.2.1, for each sample with input as x,the ideal training loss (MLE) needs learning allfeasible labels:",
  "= 0(7)": "where |S| is the number of elements in S. Thedifference in Eq. (7) cannot be approximated to0, indicating a gap between the actual and idealtraining objectives. Clearly, the ideal training ob-jective needs learning all feasible labels (S) tocapture the unordered nature of quadruples. How-ever, in practice, the model is trained on only onefeasible label (S), neglecting training with otherfeasible labels. This may lead the model to learnnon-existent order biases and spurious causal rela-tionships between input and order. 4.2.2Segmentation-aided Order BiasMitigationIdea and Challenge Inspired by the MLE in-sights from the distribution perspective in Ap-pendix B.2.1, a straightforward idea to narrow thegap is to augment the dataset with feasible labelsamples, allowing the model to learn more feasiblelabels to approximate the ideal training objective:",
  "(8)": "where paug represents the data distribution afteraugmenting with feasible labels. However, as men-tioned earlier, its challenging for a model to learnmultiple outputs y for a single input x.Order Diversity Augmentation: To addressthis issue, we propose constructing an input setAg(x) for x (xAg(x)). Each xAg(x) sharesthe same quadruples and similar semantics withx.Then we pair xAg(x) with feasible labelsy (S) in a one-to-one manner to create new",
  "min (x,y)(Ag(x),(S)) paug(x)paug(y|x) logpaug(y|x)p(y|x) (9)": "Clearly, in this augmented dataset, the trainingobjective can approximate the ideal objective, asdemonstrated in Appendix B.3.1.AI rewriting tools (such as ChatGPT) and tradi-tional data augmentation methods struggle to gen-erate dialogue inputs with the same quadruples andsimilar semantics without human intervention, asshown in Appendix B.1.1 and Experiment C.6. Wepropose a cost-effective solution based on dialoguesegmentation to address this problem, which di-vides the dialogue into segments based on theirsemantic topics, ensuring they are semantically iso-lated. These segments are then rearranged andconcatenated in all possible orders to form an aug-mented dialogue input set like Ag(x). Each inputin this set shares similar semantics because rear-ranging semantically independent segments doesnot affect the overall semantics. Each input inthis set contains the same quadruples, as all thewords remain unchanged. We then pair these inputswith multiple feasible labels to create new samples,thereby increasing order diversity and enhancingthe data distribution. In this augmented dataset,as mentioned earlier, the actual training objectiveclosely approximates the ideal training objective,thus alleviating order bias. For simplicity, our dia-log segmentation scheme is based on the inherentreply thread structure (shown in section 5.1) withinthe dataset. It works because utterances connectedby reply relationships often share similar semantictopics, making them inseparable, while others areseparable. Utterance1 Utterance2 Utterance3 Utterance4Utterance5 Utterance6 Utterance7 Reply ThreadsReply Relations1 Thread 1 21 means 2 replies to 1",
  "Dataset The Diaasq dataset (Li et al., 2023a) com-prises both English(EN) and Chinese(ZH) datasetsand provides dialogue texts with reply threads. Areply thread is a collection of utterances linked by": "reply relationships, as shown in . More detailis in Appendix C.1.Metrics We use micro F1 for the pair extrac-tion task and both Micro F1 and Identification F1(Barnes et al., 2021) for the quadruple extractiontask, following the dataset creators recommenda-tions. Micro F1 considers tuples with all wordscorrect as TP and any incorrect word as FP. Identifi-cation F1 is similar but ignores sentiment elements.Baselines We compared with generative mod-els like ParaPhrase (Zhang et al., 2021a) anddiscriminative models like CRF-ExtractClassify(CEC)(Cai et al., 2021), SpERT(Eberts and Ulges,2020), Span-ASTE(Xu et al., 2021a), and MvI(Liet al., 2023a). ParaPhrase(Zhang et al., 2021a)introduces a novel paraphrase modeling paradigmto frame the ASQP task as a paraphrase generationprocess. MvI (Li et al., 2023a) uses multi-viewinformation to control information fusion and thenextracts quadruples by decoding Tagging Grid.Settings We use BART (Lewis et al., 2020)(440M) for both EN and ZH datasets. We trainthe model for 10 epochs (2 hours) on 4 3090 GPUswith a batch size of 5 and a learning rate of 5e-5.The ratio of the three losses is 1:1:1. The numberof cross-attention layers is 3(Appendix C.8). Moredetail is in Appendix C.3. All reported results areaveraged over multiple runs.",
  "Main Result": "The results are presented in . In the quadru-ple extraction task, our SADD method achieves amaximum improvement of 5.56% micro F1 and6.52% Iden F1 in the EN dataset compared to theprevious best model(MvI), demonstrating the ef-fectiveness of our method. Because discriminativemodels are not influenced by bias, our methodsmajor advantage over them lies in denoising. Withthe multi-granularity denoising generation module,we achieve up to a 6.52% Iden F1 improvementcompared to the best discriminative method(MvI)on the EN dataset. Compared to generative models,our methods greatest strength lies in order biasmitigation. With the segmentation-aided order biasmitigation module, we achieve up to a 16.56% IdenF1 improvement compared to the ParaPhrase in theEN dataset. Further insights into the impact oforder bias on the results can be found in the Ap-pendix C.5. In the Pair Extraction task, our modelachieved an average 3.19% micro F1 improvementin all datasets over the previous best approaches.This underscores the effectiveness of our method in : Main Results. D denotes discriminative methods, while G indicates generation methods. T-A means thetarget-aspect pair extraction task, T-O refers to target-opinion, and A-O refers to aspect-opinion.",
  "SADD (Ours)50.8249.6449.7038.8743.3251.1346.7247.8737.8041.05": "enhancing extraction performance across varioustasks, indicating its generalizability. By employingtopic-aware dialogue segmentation to form target-centric clusters, our model effectively diminishesnoise from quadruples with different targets dur-ing aspect and opinion extraction tasks associatedwith a specific target (TA, TO task). Furthermore,in aspect-opinion pair extraction (AO task), ourmodel primarily benefits from the sequence label-ing probability, which diminishes non-quadruplenoise.",
  "SADD (Ours)38.3642.9437.8041.05": "We conducted an ablation study to validate theeffectiveness of our Multi-Granularity DenoisingGeneration (MGDG) and Segmentation-aided Or-der Bias Mitigation (SOBM) components, detailedin . Compared to the baseline, integratingthe MGDG module brings a maximum 8.34% IdenF1 improvement in the EN dataset. It indicates thatthe MGDG module significantly enhances tuple ex-traction accuracy and robustness by reducing noise.We also compared our MGDG module with exist-ing segmentation methods in .3.3. Fur-thermore, the integrated SOBM module brings amaximum 5.65% micro F1 improvement in the ENdataset compared to the baseline. It demonstratesthe effectiveness of SOBM in mitigating order bias.We also compared our SOBM module with existingdebias methods in .3.4 and investigated",
  "Statistics and Case Studies": "We conducted a comparative analysis between ourproposed method and the SOTA method (MvI) re-garding the proportion of errors attributed to noise,as shown in . The significant proportionof errors, amounting to 79.88%, underscores theinadequacy of previous methods in handling noiseeffectively, thereby highlighting the necessity fordenoising techniques. Furthermore, our denois-ing approach resulted in a notable reduction of31.21% in the proportion of errors attributed tonoise, affirming our methods effectiveness. presents several case studies where the previousSOTA method (MvI) failed to provide good pre-dictions, whereas our model demonstrated superiorperformance. The two examples primarily illus-trate how noise leads to an increase in irrelevantquadruples and a decline in quadruple quality. Inthe first example, due to the interference of noisywords like \"Meizu 18\", \"machine,\" \"backup,\" and\"main,\" MvI produced several erroneous and irrel-evant quadruples. In the second example, the MvImodels prediction of the quadruple \"(mate series,appearance, much better, pos)\" is compromised bythe noise word \"p series,\" leading to the erroneousgeneration of \"(p series, appearance, much better,pos)\" instead. Noise detrimentally affects the qual-ity of predicted quadruples. In contrast, our modelremains unaffected by such disturbances.",
  "DiloguesMvISADD(our)LabelExplanation": "speaker0:...speaker1:\"After watching your 5 - minute long test , I bought the p40pro . It 's really good [ hee hee ] . Taking photo is stable and the workmanship is excellent . 90hz is well optimized .\",speaker0:...speaker1:...speaker2:\"Why is P40Pro and not mate40Pro ? Meizu 18 is just a backup machine , what about the main machine ?\",speaker3:\"The mate40p feels too bad , not suitable for holding it all the time , but it has full functions and is more suitable for the main machine in life\",speaker2:...speaker4:... (mate40p, feels, too bad, neg)(p40pro, Taking photo, stable, pos)(p40pro, 90hz, well optimized, pos)(mate40p, functions, full, pos)(p40pro, workmanship, excellent, pos)(Meizu 18, machine, backup, neg)(mate40p, machine, main, pos)",
  "\"Machine\" is not an aspect of Meizu or Mate40p; instead, it refers to their entities. Therefore, the two additional quadruples predicted are incorrect": "speaker0:...speaker1:...speaker2:\"When the Android phone of Dimensity 9000 comes out , such as OPPO 's , it will definitely be good . And Huawei 's flagship is really no better than Oppo 's flagship . Oppo 's flagship machine has good quality control and texture . But it is very cheap , much cheaper than Huawei .\",speaker1:...speaker3:...speaker0:...speaker4:\"Honestly , I personally think the appearance of the mate series is much better than the p series .\"speaker5: ...",
  ": Case Study. The orange words represent the noise that causes errors in the MvI model": "pare it with existing methods detailed in AppendixC.7, as shown in . Compared to TOD-BERT(Wu et al., 2020a) , our methods achieved amaximum of 6.23 % Iden F1 improvement in theZH dataset. This underscores the effectiveness ofincorporating topic information to simplify contex-tual analysis, enhancing segmentation accuracy androbustness by avoiding the direct analysis of com-plex utterances. Compared to TSP, our methodsachieved a maximum of 3.74% Iden F1 improve-ment in the ZH dataset. This demonstrates thatutilizing cross-attention to mine fine-grained as-sociations can enhance the models robustness incomplex situations, such as utterances with multi-ple topics and implicit topics. Compared to SMGD,our methods achieved a maximum 12.1% Iden F1improvement in the EN dataset. This highlights thatthe pre-labeling topic words are necessary for thetopic-aware dialogue segmentation module. TheSMGD method, which segments dialogues with-out pre-labeling topics, struggles to analyze com-plex context interactions between utterances. Incontrast, our method benefits from pre-labelingtopics, which simplifies contextual analysis by fo-cusing only on interactions between topics and ut-terances. Compared to RT, our methods achieveda maximum 3.96% Iden F1 improvement in the ENdataset. This indicates that our method can han-dle utterances related to multiple topics, therebyperforming more accurate dialogue segmentationand denoising without removing any topic-relatedinformation. Compared to TWM, our methodsachieved a maximum 6.74% Iden F1 improvementin the EN dataset. This demonstrates that utilizingcross-attention to mine fine-grained associationscan help resolve topic-level coreferences.",
  "SOBM(Ours)34.9637.8635.7038.39": "5.3.4Further Ablation Study on SOBMTo evaluate the effectiveness of our debiasing solu-tion, we compare it with an existing method calledSet (Li et al., 2023b) introduced in , asshown in . Our method outperforms Set bya maximum of 5.89% micro F1 in the ZH dataset,highlighting its effectiveness in mitigating orderbias. In contrast to Sets struggle with one-to-manylearning at the loss level, our approach augmentsinputs to avoid learning one-to-many mappingsand mitigate order bias at the data level, therebyimproving performance and generalizability.",
  "Conclusion": "This paper introduces a novel Segmentation-Aidedmulti-grained Denoising and Debiasing (SADD)model for denoising and debiasing in the DiaASQtask. For noise, we propose a Multi-GranularityDenoising Generation(MGDG) model to denoiseat both word and utterance levels with denoisedattention. For order bias, we analyze its directcauses and propose a distribution-based solution. We then introduce the Segmentation-aided OrderBias Mitigation (SOBM) method, which utilizesdialogue segmentation to increase order diversity,thereby simultaneously alleviating the challengesof one-to-many learning and order bias. Extensiveexperiments show SADDs SOTA performance.",
  ". A limitation we encountered is the increasedtraining time due to the augmented dataset": "2. The BART model encounters challenges whenprocessing long-text inputs, particularly in di-alogue scenarios, due to the increasing timecomplexity of attention mechanisms as theinput length grows. This results in highertime overhead compared to short-text ABSA.More efficient attention mechanisms tailoredfor long textual inputs in dialogue contextsneed to be developed to mitigate this issue.",
  "Ethics Statement": "In all our experiments, we utilized pre-existingdatasets widely used in previous research. Whileanalyzing experimental results, We made diligentefforts to maintain fairness and honesty, ensuringthat our work did not cause harm to any individuals.Regarding broader impacts, this work can con-tribute to further research in sentiment analysis andthe utilization of generative methods for simplify-ing and automating the extraction of user opinionsin real-world applications. However, its notewor-thy that this work utilizes fine-tuning large-scalepre-trained language models for generating senti-ment triplets. Since the large-scale pre-trainingcorpora originate from the internet, predicted senti-ment polarity may be subject to unintended biasesassociated with gender, race, and intersectionalidentities (Tan and Celis, 2019). Large pre-trainedlanguage models often inherit biases present intheir training data, potentially leading to biasedsentiment analysis results, particularly when evalu-ating texts from underrepresented or marginalizedgroups, thereby perpetuating and amplifying so-cietal prejudices. It is crucial for the natural lan-guage processing community to consider these bi- ases more extensively. Fortunately, these issues areactively being addressed within the research com-munity, including efforts to standardize datasetsand methodologies.We obtained licenses for all artifacts used inour study, and our data was obtained from open-source repositories. Our use of existing artifacts isconsistent with their intended use. Our methodsspecific intended use is to extract quadruples fromdialogues and is compatible with the original ac-cess conditions. We read and checked each sampleto ensure that the data used does not contain infor-mation that names or uniquely identifies individualpeople or offensive content.",
  "Julius Berner, Philipp Grohs, Gitta Kutyniok, andPhilipp Petersen. 2021. The modern mathematicsof deep learning. CoRR, abs/2105.04026": "Hongjie Cai, Rui Xia, and Jianfei Yu. 2021. Aspect-category-opinion-sentiment quadruple extractionwith implicit aspects and opinions. In Proceedingsof the 59th Annual Meeting of the Association forComputational Linguistics and the 11th InternationalJoint Conference on Natural Language Processing(Volume 1: Long Papers), pages 340350, Online.Association for Computational Linguistics. Hao Chen, Zepeng Zhai, Fangxiang Feng, Ruifan Li,and Xiaojie Wang. 2022. Enhanced multi-channelgraph convolutional network for aspect sentimenttriplet extraction. In Proceedings of the 60th AnnualMeeting of the Association for Computational Lin-guistics (Volume 1: Long Papers), pages 29742985,Dublin, Ireland. Association for Computational Lin-guistics.",
  "Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, andLuke Zettlemoyer. 2024. Qlora: Efficient finetuningof quantized llms. Advances in Neural InformationProcessing Systems, 36": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. BERT: Pre-training ofdeep bidirectional transformers for language under-standing. In Proceedings of the 2019 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, Volume 1 (Long and Short Papers), pages41714186, Minneapolis, Minnesota. Association forComputational Linguistics. Markus Eberts and Adrian Ulges. 2020. Span-basedjoint entity and relation extraction with transformerpre-training. In ECAI 2020 - 24th European Confer-ence on Artificial Intelligence, 29 August-8 Septem-ber 2020, Santiago de Compostela, Spain, August29 - September 8, 2020 - Including 10th Conferenceon Prestigious Applications of Artificial Intelligence(PAIS 2020), volume 325 of Frontiers in Artificial In-telligence and Applications, pages 20062013. IOSPress. Tianhao Gao, Jun Fang, Hanyu Liu, Zhiyuan Liu, ChaoLiu, Pengzhang Liu, Yongjun Bao, and Weipeng Yan.2022. LEGO-ABSA: A prompt-based task assem-blable unified generative framework for multi-taskaspect-based sentiment analysis. In Proceedings ofthe 29th International Conference on ComputationalLinguistics, pages 70027012, Gyeongju, Republicof Korea. International Committee on ComputationalLinguistics. Zhibin Gou, Qingyan Guo, and Yujiu Yang. 2023. Mvp:Multi-view prompting improves aspect sentiment tu-ple prediction. In Proceedings of the 61st AnnualMeeting of the Association for Computational Lin-guistics (Volume 1: Long Papers), ACL 2023, Toronto,Canada, July 9-14, 2023, pages 43804397. Associa-tion for Computational Linguistics.",
  "Edward J Hu, Yelong Shen, Phillip Wallis, ZeyuanAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,and Weizhu Chen. 2021.Lora: Low-rank adap-tation of large language models.arXiv preprintarXiv:2106.09685": "Mike Lewis, Yinhan Liu, Naman Goyal, MarjanGhazvininejad, Abdelrahman Mohamed, Omer Levy,Veselin Stoyanov, and Luke Zettlemoyer. 2020.BART: denoising sequence-to-sequence pre-trainingfor natural language generation, translation, and com-prehension. In Proceedings of the 58th Annual Meet-ing of the Association for Computational Linguistics,ACL 2020, Online, July 5-10, 2020, pages 78717880.Association for Computational Linguistics. Bobo Li, Hao Fei, Fei Li, Yuhan Wu, Jinsong Zhang,Shengqiong Wu, Jingye Li, Yijiang Liu, Lizi Liao,Tat-Seng Chua, and Donghong Ji. 2023a. Diaasq: Abenchmark of conversational aspect-based sentimentquadruple analysis. In Findings of the Association",
  "for Computational Linguistics: ACL 2023, Toronto,Canada, July 9-14, 2023, pages 1344913467. Asso-ciation for Computational Linguistics": "Jiangnan Li, Yice Zhang, Bin Liang, Kam-Fai Wong,and Ruifeng Xu. 2023b. Set learning for genera-tive information extraction. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing, EMNLP 2023, Singapore, De-cember 6-10, 2023, pages 1304313052. Associationfor Computational Linguistics. Xin Li, Lidong Bing, Piji Li, and Wai Lam. 2019a. Aunified model for opinion target extraction and targetsentiment prediction. In The Thirty-Third AAAI Con-ference on Artificial Intelligence, AAAI 2019, TheThirty-First Innovative Applications of Artificial In-telligence Conference, IAAI 2019, The Ninth AAAISymposium on Educational Advances in ArtificialIntelligence, EAAI 2019, Honolulu, Hawaii, USA,January 27 - February 1, 2019, pages 67146721.AAAI Press. Zheng Li, Xin Li, Ying Wei, Lidong Bing, Yu Zhang,and Qiang Yang. 2019b. Transferable end-to-endaspect-based sentiment analysis with selective adver-sarial learning. In Proceedings of the 2019 Confer-ence on Empirical Methods in Natural Language Pro-cessing and the 9th International Joint Conferenceon Natural Language Processing, EMNLP-IJCNLP2019, Hong Kong, China, November 3-7, 2019, pages45894599. Association for Computational Linguis-tics. Shuo Liang, Wei Wei, Xian-Ling Mao, Yuanyuan Fu,Rui Fang, and Dangyang Chen. 2023. STAGE: spantagging and greedy inference scheme for aspect senti-ment triplet extraction. In Thirty-Seventh AAAI Con-ference on Artificial Intelligence, AAAI 2023, Thirty-Fifth Conference on Innovative Applications of Artifi-cial Intelligence, IAAI 2023, Thirteenth Symposiumon Educational Advances in Artificial Intelligence,EAAI 2023, Washington, DC, USA, February 7-14,2023, pages 1317413182. AAAI Press. Yue Mao, Yi Shen, Jingchao Yang, Xiaoying Zhu, andLongjun Cai. 2022. Seq2path: Generating sentimenttuples as paths of a tree. In Findings of the Asso-ciation for Computational Linguistics: ACL 2022,Dublin, Ireland, May 22-27, 2022, pages 22152225.Association for Computational Linguistics. Ravil I. Mukhamediev, Yelena Popova, Yan Kuchin,Elena Zaitseva, Almas Kalimoldayev, AdilkhanSymagulov, Vitaly Levashenko, Farida Abdoldina,Viktors Gopejenko, Kirill Yakunin, Elena Muhamedi-jeva, and Marina Yelis. 2022. Review of artificialintelligence and machine learning technologies: Clas-sification, restrictions, opportunities and challenges.Mathematics, 10(15). Haiyun Peng, Lu Xu, Lidong Bing, Fei Huang, WeiLu, and Luo Si. 2020.Knowing what, how andwhy: A near complete solution for aspect-based sen-timent analysis. In The Thirty-Fourth AAAI Con-ference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of ArtificialIntelligence Conference, IAAI 2020, The Tenth AAAISymposium on Educational Advances in Artificial In-telligence, EAAI 2020, New York, NY, USA, February7-12, 2020, pages 86008607. AAAI Press. Dianbo Sui, Chenhao Wang, Yubo Chen, Kang Liu, JunZhao, and Wei Bi. 2021. Set generation networks forend-to-end knowledge base population. In Proceed-ings of the 2021 Conference on Empirical Methodsin Natural Language Processing, pages 96509660,Online and Punta Cana, Dominican Republic. Asso-ciation for Computational Linguistics. Yi Chern Tan and L. Elisa Celis. 2019. Assessing so-cial and intersectional biases in contextualized wordrepresentations. In Advances in Neural InformationProcessing Systems 32: Annual Conference on Neu-ral Information Processing Systems 2019, NeurIPS2019, December 8-14, 2019, Vancouver, BC, Canada,pages 1320913220. Zeqi Tan, Yongliang Shen, Shuai Zhang, Weiming Lu,and Yueting Zhuang. 2021. A sequence-to-set net-work for nested named entity recognition. In Pro-ceedings of the Thirtieth International Joint Confer-ence on Artificial Intelligence, IJCAI 2021, VirtualEvent / Montreal, Canada, 19-27 August 2021, pages39363942. ijcai.org.",
  "Rocio Vargas, Amir Mosavi, and Ramon Ruiz. 2017.Deep learning: a review": "Chien-Sheng Wu, Steven C.H. Hoi, Richard Socher,and Caiming Xiong. 2020a. TOD-BERT: Pre-trainednatural language understanding for task-oriented di-alogue. In Proceedings of the 2020 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 917929, Online. Association forComputational Linguistics. Zhen Wu, Chengcan Ying, Fei Zhao, Zhifang Fan,Xinyu Dai, and Rui Xia. 2020b. Grid tagging schemefor aspect-oriented fine-grained opinion extraction.In Findings of the Association for Computational Lin-guistics: EMNLP 2020, pages 25762585, Online.Association for Computational Linguistics. Huiyuan Xie, Zhenghao Liu, Chenyan Xiong, ZhiyuanLiu, and Ann Copestake. 2021. TIAGE: A bench-mark for topic-shift aware dialog modeling. In Find-ings of the Association for Computational Linguis-tics: EMNLP 2021, pages 16841690, Punta Cana,Dominican Republic. Association for ComputationalLinguistics. Linzi Xing and Giuseppe Carenini. 2021.Improv-ing unsupervised dialogue topic segmentation withutterance-pair coherence scoring. In Proceedingsof the 22nd Annual Meeting of the Special Inter-est Group on Discourse and Dialogue, pages 167177, Singapore and Online. Association for Compu-tational Linguistics. Lu Xu, Yew Ken Chia, and Lidong Bing. 2021a. Learn-ing span-level interactions for aspect sentiment tripletextraction. In Proceedings of the 59th Annual Meet-ing of the Association for Computational Linguisticsand the 11th International Joint Conference on Natu-ral Language Processing (Volume 1: Long Papers),pages 47554766, Online. Association for Computa-tional Linguistics. Yi Xu, Hai Zhao, and Zhuosheng Zhang. 2021b. Topic-aware multi-turn dialogue modeling. In Thirty-FifthAAAI Conference on Artificial Intelligence, AAAI2021, Thirty-Third Conference on Innovative Ap-plications of Artificial Intelligence, IAAI 2021, TheEleventh Symposium on Educational Advances in Ar-tificial Intelligence, EAAI 2021, Virtual Event, Febru-ary 2-9, 2021, pages 1417614184. AAAI Press. Jiacheng Ye, Tao Gui, Yichao Luo, Yige Xu, andQi Zhang. 2021.One2Set: Generating diversekeyphrases as a set. In Proceedings of the 59th An-nual Meeting of the Association for ComputationalLinguistics and the 11th International Joint Confer-ence on Natural Language Processing (Volume 1:Long Papers), pages 45984608, Online. Associationfor Computational Linguistics. Chengze Yu, Taiqiang Wu, Jiayi Li, Xingyu Bai, and Yu-jiu Yang. 2023. Syngen: A syntactic plug-and-playmodule for generative aspect-based sentiment analy-sis. In IEEE International Conference on Acoustics,Speech and Signal Processing ICASSP 2023, RhodesIsland, Greece, June 4-10, 2023, pages 15. IEEE. Wenxuan Zhang, Yang Deng, Xin Li, Yifei Yuan, Li-dong Bing, and Wai Lam. 2021a. Aspect sentimentquad prediction as paraphrase generation. In Pro-ceedings of the 2021 Conference on Empirical Meth-ods in Natural Language Processing, pages 92099219, Online and Punta Cana, Dominican Republic.Association for Computational Linguistics. Wenxuan Zhang, Xin Li, Yang Deng, Lidong Bing, andWai Lam. 2021b. Towards generative aspect-basedsentiment analysis. In Proceedings of the 59th An-nual Meeting of the Association for ComputationalLinguistics and the 11th International Joint Confer-ence on Natural Language Processing, ACL/IJCNLP2021, (Volume 2: Short Papers), Virtual Event, Au-gust 1-6, 2021, pages 504510. Association for Com-putational Linguistics. Ming Zhong, Yang Liu, Yichong Xu, Chenguang Zhu,and Michael Zeng. 2022.Dialoglm: Pre-trainedmodel for long dialogue understanding and summa-rization. In Thirty-Sixth AAAI Conference on Artifi-cial Intelligence, AAAI 2022, Thirty-Fourth Confer- ence on Innovative Applications of Artificial Intelli-gence, IAAI 2022, The Twelveth Symposium on Ed-ucational Advances in Artificial Intelligence, EAAI2022 Virtual Event, February 22 - March 1, 2022,pages 1176511773. AAAI Press.",
  "A.1Definition and Example of Noise and Bias": "Noise is words that interfere with the genera-tion process when the model generates a certainquadruple.Order Bias: Due to the constraints of seq2seqtasks, the model learns a nonexistent causal rela-tionship from the input to the order of quadru-ples. The model ends up overfitting to a specific or-der weve arbitrarily defined, which affects its gen-eralization ability. We term this as \"Order Bias.\"Example:Input : Utterance 1: . . . The battery of theiPhone was quite good and the system was smooth. . .Utterance 2: . . . The battery of Samsung phonesis worse. . . . I also bought a Samsung phone formy girlfriend. . .Utterance 3: . . . Xiaomi can also be considered,mainly because the price is very low. . .Output :iPhone Quads: (iPhone, battery, quite good,POS), (iPhone, system, smooth, POS)Samsung Quads: (Samsung, battery, worse,NEG)Xiaomi Quads: (Xiaomi, price, very low,POS).Example of Noise: Specifically, when the modelgenerates the quadruple \" (iPhone, battery, quitegood, POS)\", it selects words from the input .Words in the input but not in the quadruple arethe words that interfere with the generation pro-cess of the quadruple . So, these words are thenoise (The definition of Noise). For instance, wordssuch as \"bought\" and \"considered\" can introducesignificant noise, potentially leading the model togenerate incorrect quadruples.Example of Bias:When we transform thequadruple extraction task into a text-to-text gen-eration task, we need to design a sentence as the la-bel. Considering the quadruples (Samsung, battery,worse, NEG) and (Xiaomi, price, very low, POS),we have to decide the order between them whenconstructing labels for the seq2seq task. Whetherits (Samsung, battery, worse, NEG) (Xiaomi,price, very low, POS) or (Xiaomi, price, very low, POS) (Samsung, battery, worse, NEG), themodel is forced to learn the corresponding orderand move away from the other orders. But in fact,any order is correct. This confusion leads the modelto seek semantic clues from the input to find outwhy this order. The model attempts to find a nonex-istent causal relationship between the input and theorder of quadruples to find why this order exists.As a result, the model overfits to our arbitrarilydefined order, impacting its generalization ability,thus leading to a bias.",
  "B.1Appendix for section 4.1": "B.1.1Augment with ChatgptWe aim to keep the quadruple elements unchangedwhile constructing semantically similar inputs.However, AI paraphrasing tools like ChatGPT 3.5and ChatGPT 4 often fail to preserve the quadru-ple elements and may alter the original semantics.Firstly, theres the issue of maintaining quadrupleelements. ChatGPT often modifies the opinionpart of the quadruples. Changing the quadrupleelements renders the original labels incompatiblewith the input, resulting in a failed input construc-tion. It is nearly impossible to determine whetherthe original quadruple elements remain unchangedthrough code analysis, as the appearance of char-acters in the text does not necessarily imply theirassociation with the same quadruple or a quadruplerelationship between them. Additionally, manu-ally verifying whether quadruple elements havechanged would require significant effort. Secondly,theres the issue of preserving the original inputssemantics. ChatGPT also frequently alters seman-tics, disregarding certain parts of the content oreven producing dialogues with entirely oppositemeanings. We demonstrate some examples whereChatGPT rewriting resulted in changes to quadru-ple elements and altered semantics, as shown in and . Therefore, AI rewritingtools like ChatGPT may not be suitable for ouraugmentation task.",
  "= H + MLE()(15)": "where H is the \"Entropy\" and is independent ofmodel parameters , it can be disregarded in thetraining loss. Hence, MLE loss and KL divergenceshare the same minimum. By minimizing the MLEloss, we encourage the predicted distribution p toalign with the data distribution p closely.Learning All Feasible Lables It is worth notingthat Equation 12 indicated that we need to learnall feasible labels for the input. In many spe-cific tasks, only one label y corresponds to a giveninput, with a probability p(y|x) = 1, and the prob-abilities p(other|x) for other texts are all 0. How-ever, in some tasks, there may be multiple labels{y1, y2, . . . } that match a given input, with proba-bilities p(y1|x), p(y2|x), . . . all non-zero. Unfortu-nately, these probabilities are often immeasurable,which has led to prior research overlooking mul-tiple feasible labels and instead focusing only onone label. Failing to learn all feasible labels fully,and instead focusing on just one, increases therisk of introducing bias into the model.",
  "(17)": "In this task, all feasible labels contain the samequadruples but in different orders. Moreover, allpermutation orders are equivalent. Therefore, all la-bels are equivalent, resulting in equal probabilitiesfor each label. That is, for p(y|x), the probabil-ity of each feasible label y (S) is the same,so p(y|x) =1 |(S)|. In the augmented dataset, xand x share the same quadruple elements, implyingthat all feasible labels associated with them are thesame. Furthermore, as our augmented dataset en-compasses all feasible labels, we have paug(y|x) =1",
  "C.1Dataset Detail": "The dataset used is called Diaasq, including botha Chinese and an English dataset. The dataset isdivided into train/test/dev sets in an 8:1:1 ratio.Aside from the dialogue text, the dataset also in-cludes important details such as the speaker foreach utterance, dialogue reply relationships, and re-ply thread relationships. Every dialogue originatesfrom a root utterance, and multiple speakers takepart in responding to preceding utterances. Multi-threaded and multi-turn dialogues form a tree struc-ture based on reply relationships. In other words,dialogues are structured like trees, following replyrelationships. Each reply thread consists of allthe utterances along the path from a leaf node",
  "to the root node, as illustrated in . Thedataset labels consist of ground truth tuples and thepositions of their element. The statistical informa-tion of the dataset is shown in": "I regret buying Xiaomi 11. # What do you think of Xiaomi mobile phone # I didnt buy since my friend said the battery life of Xiaomi 11 is not well. Thats right, and as far as Ive experienced, WiFi module is also a bad design. Here I am! Rabbit has seen your issues and please check your private message. A 4-year holder of Xiaomi 6 is here! Me too, the screen quality of it is very nice! Me too. Reply threads Multi-thread Multi-turn Dialogue Thread 1",
  "C.2Detail of Metrics": "We use micro F1 for the pair extraction task andboth micro F1 and identification F1 for the quadru-ple extraction task, as stated in (Barnes et al., 2021).In micro F1, predicted tuples with all correct wordsare considered true positives (TP), while tupleswith any incorrect word are considered false posi-tives (FP). Tuples that were not predicted correctlyare considered false negatives (FN). On the otherhand, Identification F1 is similar to Micro F1, butit does not take sentiment elements into account.",
  "C.3Detail of Experiment Setting": "We use BART (Lewis et al., 2020) (440M) for bothEN and ZH datasets. We train the model for tenepochs (2 hours) on 4 3090 GPUS with a batchsize of 5 and a learning rate of 5e-5, while otherlayers employ a learning rate of 8e-5. We use 3cross-attentithreen layers. During testing, the beamsearch size is set to 2. All reported results areaveraged over multiple runs.",
  "C.4Detail of Compared Baseline": "CRF-ExtractClassify(CEC)(Cai et al., 2021) isa two-stage model that initially extracts aspect-opinion pairs and then predicts category-sentimentbased on the extracted aspect-opinion pairs.SpERT(Eberts and Ulges, 2020) is a span-basedtransformer model for joint entity and relation ex-traction, initially extracting spans, filtering them,and finally classifying relationships among the spans. Modify this model to support quadrupleextraction classification. Span-ASTE(Xu et al.,2021a) is a span-based model that explicitly consid-ers interactions between the entire span of targetsand opinions when predicting sentiment relations.Modify the final stage of SpanASTE to enumeratetriplets, aligning it with the DiaASQ task. Para-Phrase(Zhang et al., 2021a), an end-to-end genera-tion approach, introduces a novel paraphrase mod-eling paradigm to frame the ASQP task as a para-phrase generation process. MvI(Li et al., 2023a)method leverages speaker information, reply rela-tionships, and thread information in dialogues tocontrol information fusion between dialogues. Fi-nally, it extracts quadruples based on the decodingoutput of Grid Tagging.",
  "C.5More analysis for main ExperimentResults": "ParaPhrase is a generative model that outperformsthe discriminative model Span-ASTE on short textdatasets but falls short on dialogue datasets. This isbecause the dialogue dataset has an increasing num-ber of tuples, which widens the gap between theactual and ideal training objectives, i.e., increasinggap in (S) and k(S) as indicated by Equation 4and 5. This amplifies the order bias interference inParaPhrase. In contrast, Span-ASTE remains unaf-fected by tuple order bias, resulting in a reversal ofperformance on dialogue datasets shown in .",
  "C.6Augmentation Strategies in SOBM": "To investigate the effectiveness of the augmenta-tion strategy in SOBM, we compared it with otheraugmentation methods. By determining whether toshuffle the tuples in labels and the segmented frag-ments in inputs, we get various augmented datasets.We also compared SOBM with traditional data aug-mentation methods: synonyms, replacement, anddeletion (SRD). The results are presented in . Compared to row 1, our method surpasses thefirst method by a maximum of 2.52 %(micro F1)on the EN dataset. The first method creates biasedsamples, while our method helps alleviate biases,improving the models robustness and generaliz-ability. The second method is actually a type ofstandard data augmentation method. So, it outper-forms the first method by a maximum of 1.04%(mi-cro F1) in the ZH dataset. However, the compari-son between rows 5 and 2 shows that our methodoutperforms the second method by a maximum of",
  "SOBM (Our)38.8743.3237.8041.05": "1.64%(Iden F1) in the EN dataset. This empha-sizes that our approach isnt merely an optionaldata augmentation technique but rather a neces-sary debiasing technique. Compared to row 3, ourmethod outperforms the third method by a maxi-mum of 2.43%(micro F1) in the EN dataset. Thesecond method introduces a one-to-many learningchallenge, while our method avoids this by pairingfeasible labels with newly constructed inputs, facil-itating models to converge to optimal performance.Compared to row 4, our method outperforms thefourth method by a maximum of 1.93%(Iden F1)in the EN dataset. This highlights the superior-ity of our augmentation technique over traditionalmethods in dialogue processing.",
  "C.7Compared Dialogue SegmentationMethods": "Here is the detail of the compared dialogue seg-mentation methods:1. TOD-BERT (Wu et al., 2020a): This method di-rectly classifies the utterance relationships with-out introducing topic information. The methodinteracts with the contextual information be-tween two utterances, and the classification isperformed on the fused contextual informationto achieve dialogue segmentation.Pass thefused contextual information through an MLPlayer and then classify to determine whether thetwo utterances share the same topic or whetherthey need to be segmented. This method isthe most commonly used approach in existingworks.",
  ". Topic-Sentence Pair: This approach introduces": "\"topics\" and then performs classification ontopic-utterance pairs, similar to our method.However, instead of using cross-attention forfine-grained information fusion, it uses a con-catenation operation to pool information.Firstly, it performs average pooling on a topicword and on an utterance. Then, it concatenatesthe two pooled embeddings and passes themthrough an MLP layer for classification to deter-mine whether the utterance belongs to the giventopic. Apply this process to all the topics andutterances to finish the segmentation. 3. Simultaneously Multi-Granularity Denoising:This method incorporates sequence labeling anddialogue segmentation into the dialogue seg-mentation module. It doesnt need to pre-labeltopics topics. Instead, it views each word in anutterance as a potential topic and categorizes theconnection between each word and the utterance.Based on the classification results, the methodidentifies words linked to any sentence as topics,while those without connections are not con-sidered topics. This approach achieves bothtopic-centric clustering and topic labeling simul-taneously. However, this means that whenwe perform dialogue segmentation, there isno explicit guidance from topic information.Consequently, it must deal with the intricatecontextual interactions between utterances. 4. Reply Thread (RT): This method doesnt em-ploy neural networks. Instead, it directly usesthe inherent reply thread structures (as shownin Section C.1) in the dataset as the final dia-logue segmentation scheme. In this segmen-tation scheme, every utterance, except for theinitial dialogue, is assigned to a single topic-centric cluster. However, this approach lacksfiner segmentation granularity, as seen in caseswhere an utterance may relate to multiple topics,as illustrated by the black utterances in .",
  ". Topic Word Match(TWM): This technique be-gins by labeling topic words within the utter-": "ances. Then, it utilizes string-matching algo-rithms to determine whether an utterance be-longs to a specific topic. Specifically, it checksif an utterance contains the topic string at thestring level. If the topic is found in the utterance,its considered to belong to that topic; otherwise,its not. However, this method is limited to es-tablishing connections between an utterance anda topic only when the utterance explicitly men-tions the topic at the string text level. Whenan utterance indirectly references a topic or dis-cusses related content, such as using pronouns,this approach proves ineffective.",
  ": Results for the different number of cross at-tention layers": "We also investigated the impact of the numberof cross-attention layers on model performance,keeping the batch size constant at four due to GPUmemory limitations. The results are shown in Fig-ure 6. The figure illustrates that increasing thenumber of cross-attention layers initially enhancesmodel performance but then diminishes it. Whenthere are fewer cross-attention layers, the modellacks sufficient interaction between topic and utter-ance information, limiting the exploration of theirrelationship. Conversely, an excessive number ofcross-attention layers leads to overfitting due to asurplus of parameters and limited data, resulting inthe incorporation of non-topic-related informationduring interaction.",
  ": LLMs Performance. The x-axis representsthe logarithmic values of Loras rank number, and they-axis represents the Iden F1 results": "Please rewrite the following dialogues in their original language so that change the content, but keep the general semantics and the elements in the quadruples unchanged:Quadruples:[ \"neg\", \"k50\", \"take photos\", \"a little better\"], [ \"pos\", \"pro\", \"photo\", \"far worse than\"], [\"neg\", \"12\", \"photo\", \"far worse than\"], [ \"neg\", \"K40\", \"game\", \"always 460\"], [\"pos\", \"Xiaomi\", \"taking pictures\", \"better\"], [\"neg\", \"Redmi\", \"taking pictures\", \"Don't consider\"] Here is the dialogue: [\"I hope k50 can take photos a little better [ School Season][School Season][School Season ]\", \"Taking photos is really important !\", \"No matter how good the camera parameters are , it is useless without technology [ doge ]\", \"I went to the store to try the 12 and 12pro , the 12 's photo is far worse than the pro 's\", \"I agree with the photo too ! The top - level configuration version of the camera can also be enhanced\", \"The light is dark at night , and it is inconvenient to scan the code when going out .\", \"The telephoto scan code is even more fragrant .\", \"Do n't consider taking pictures using Redmi , Xiaomi is better [ DOGE ] .\", \"[ Doge ] [ Doge ] [ Doge ] Yes , I do n't know if you have encountered it , my K40 game is always 460 [ Tears ] [ Tears ] [ Tears ] .\"] [\"I hope the K50 can improve its photo-taking capabilities just a bit. [School Season][School Season][School Season]\", \"Taking photos really matters!\", \"No matter how impressive the camera specs are, without the right technology, they're useless. [doge]\", \"I visited the store to test out the 12 and 12 Pro. The 12's camera performance is far worse than the Pro's.\", \"I totally agree about the camera! Even the highest-tier camera setup can be further enhanced.\", \"It gets really dark at night, making it inconvenient for scanning codes when out and about.\", \"Scanning codes with the telephoto lens is even more satisfying.\", \"If you're considering photo quality, go for Xiaomi over Redmi. Xiaomi performs better. [DOGE]\", \"[Doge] [Doge] [Doge] You know what, I've been experiencing this issue too. My K40's gaming performance is consistently at 460. [Tears] [Tears] [Tears].\" Unexpected Changed Quaruples:[ \"neg\", \"k50\", \"take photos\", \"a little better\"], [ \"neg\", \"K40\", \"game\", \"always 460\"], [\"pos\", \"Xiaomi\", \"taking pictures\", \"better\"], [\"neg\", \"Redmi\", \"taking pictures\", \"Don't consider\"]",
  ": Chatgpt example 1": "Please rewrite the following dialogues in their original language so that change the content, but keep the general semantics and the elements in the quadruples unchanged:Quadruples:[ \"pos\", \"vivo\", \"rear camera module\", \"better\"], [\"neg\", \"11U\", \"rear camera module\", \"stands out too much\"], [ \"pos\", \"11U\", \"design\", \"recognizable\"], [\"pos\", \"11U\", \"design\", \"very beautiful\"], Here is the dialogue: [\"The price is not bad\", \"11U said ( all are little brothers [ doge ] refers to the back design )\", \"The 11U rear camera module stands out too much , which vivo has done better . The next generation of Ultra has changed again , and Xiaomi really has no inheritance . . . In fact , the design of 11U is very beautiful , and it is also recognizable .\", \"The recognition is too great\", \"iQOO can be regarded as a firm high - end , Xiaomi has not hurry to learn [ doge ] ?\", \"Now I really do n't understand which of the X series and iQOO is the son of vivo ?\"] [\"The price is quite reasonable.\", \"Regarding the 11U, all the younger models (referred to as 'little brothers' [doge]) have similar rear designs.\", \"The rear camera module of the 11U stands out too much, which contrasts with vivo's more subtle approach. The next generation of Ultra has made further changes, highlighting Xiaomi's lack of design continuity. However, the design of the 11U is undeniably beautiful and distinctive.\", \"The design is truly remarkable.\", \"iQOO can definitely be considered a solid high-end option. Is Xiaomi in any hurry to catch up? [doge]\", \"Honestly, I'm confused about whether the X series or iQOO is the true heir to vivo.\"]"
}