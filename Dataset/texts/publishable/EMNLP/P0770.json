{
  "Abstract": "The diversity of text can be measured beyondword-level features, however existing diversityevaluation focuses primarily on word-level fea-tures. Here we propose a method for evaluatingdiversity over syntactic features to characterizegeneral repetition in models, beyond frequentn-grams. Specifically, we define syntactic tem-plates (e.g., strings comprising parts-of-speech)and show that models tend to produce tem-plated text in downstream tasks at a higher ratethan what is found in human-reference textsWe find that most (76%) templates in model-generated text can be found in pre-training data(compared to only 35% of human-authoredtext), and are not overwritten during fine-tuningor alignment processes such as RLHF. The con-nection between templates in generated textand the pre-training data allows us to analyzesyntactic templates in models where we do nothave the pre-training data. We also find thattemplates as features are able to differentiate be-tween models, tasks, and domains, and are use-ful for qualitatively evaluating common modelconstructions. Finally, we demonstrate the useof templates as a useful tool for analyzing stylememorization of training data in LLMs 1.",
  "Introduction": "An open question about large language models(LLMs) is what patterns such models learn frompre-training data (Goldberg, 2019; Petroni et al.,2019; Bender et al., 2021; Chen et al., 2024),and whether the same patterns appear generallyacross downstream tasks and datasets (Hupkeset al., 2023). While prior work has focused onthe quality of generation (Zhang et al., 2019; Douet al., 2022; Kryscinski et al., 2020), and more re-cently on text generation novelty (McCoy et al.,2023; Merrill et al., 2024), there has been limitedwork on characterizing the sorts of lexical patternsthat are learned by LLMs.",
  "DT NN VBZ RB VBN VBN IN PRP$ 56/500": "The Last Black Man in San Francisco is a poignant, beautifully shot film [] creates a unique and intense viewing experience. [] The film has been praised for its gorgeous cinematography, []. The film has also been praised for its portrayal of male friendship []. The film is a highly original and impressive debut for director Joe Talbot, and it is a must-see for anyone interested in the human experience. \"The Last Black Man in San Francisco\" is a poetic and visually stunning film written and directed by Jimmie Fails and Joe Talbot []. The story follows Jimmie, a young black man living in San Francisco, []. The film is a poignant exploration of friendship, [] The film's interplay between reality and artifice, and its blend of documentary authenticity and political allegory, creates an intensity that is both magical and thought-provoking. : Sample movie meta-reviews generated byOLMo-7B (top) and Mistral-7B (bottom) by promptingthe Rotten Tomatoes dataset. Templates appear at vary-ing rates (frequency shown out of 500 generations), anddiffer across models. We extract templates from the en-tire corpus of generated text for each model, and matchthe text to the part-of-speech templates (highlighted),following by the frequency of each template. Consider, for instance, the generated text fromOLMo-Instruct in , which is sampled froma corpus of movie review summaries. This wasproduced by prompting the model to summarize acollection of human-written movie reviews: TheLast Black Man in San Francisco is a poignant,beautifully shot film [...] creates a unique andintense viewing experience [...]. While this gen-erated text was not seen in Dolma (Soldaini et al.,2024), OLMos pre-training data, we find a totalof 35 unique repeated sequences of part-of-speech(POS) tags of lengths n = 5 to 8 in the summarizedmovie reviews. Further, we find that 33 out of the35 (95%) sequences appear in the pre-training data.As such, while the generated text itself is novel, itrelies on common syntactic sequences seen in thetraining data.In this work, we quantify and measure LLMs us-",
  "RQ3 Can syntactic templates be used for detectionof data memorization?": "We start by introducing syntactic templates, anddefining methods for detecting and measuring suchtemplates in generated texts (3). We evaluate eightmodels on three different tasks (5). We show howtraining data templates are memorized and subse-quently generated by models trained on them (6).We then show how such insights allow one to drawconclusions about the training data used by closedmodels in a downstream summarization task (7).Finally, we show that our metrics can also be usedas a softer version of memorization. For instance,while Carlini et al. (2022) estimates that 1% of textsto be memorized, we find between 0.8 - 3.1% moresoft-memorized texts over verbatim memorization,often by replacing numbers and synonyms (8).",
  "Related Work": "Diversity in Text GenerationPast evaluationsof diversity in LLM outputs have primarily focusedon token-level diversity (Montahaei et al., 2019;Bache et al., 2013). Diverse sampling strategieshave been introduced to address the lower tokendiversity observed in neural text generation (Holtz-man et al., 2020; Roberts et al., 2020), however itis unclear whether such sampling strategies alsoincrease the diversity of the syntactic structure inLLMs. Beyond lexical diversity, Padmakumar andHe (2023) extend definitions for measuring contentdiversity, which has broad applications in down-stream tasks such as summarization and creativestory generation. Recent work has quantified thedrop in generated-text diversity specifically rela-tive to the RLHF training process, however thisagain focused primarily on token level diversity(Kirk et al., 2024). Our work aligns more closelywith the first body of work; we measure the syn-tactic structure of text rather than its semantic con-tent. Most similar to our work is Br et al. (2012),which broadly evaluates text repetition metrics at the stylistic, content, and lexical level. Our meth-ods do not address repetition in content but ratherfocus on extending the characterization of lexi-cal and stylistic repetition with text abstractionsin LLMs.",
  "Structural Analysis of TextDiMarco and Hirst": "(1993) provide a computational approach compris-ing lexical and syntactic components to describestylistic elements in model-generated text. The dis-cussion around style in writing has been adoptedbroadly for a variety of downstream tasks such asauthor or model attribution (Wu et al., 2023; Lam-ple et al., 2018; Rosenfeld and Lazebnik, 2024).While our main goal is to provide measurementsand characterizations of repetitive syntactic fea-tures in text, definitions of stylistic elements areclosely related and help contextualize our findings.One can use our definitions of templates to askbroader questions about the prevailing syntacticstyle in a given corpus. Indeed, recent works adoptvarious measures of linguistic analysis to addressdifferences in writing style in both human-writtenand model-generated texts (Krishna et al., 2020;Soler-Company and Wanner, 2017). AI Text DetectionIn identifying n-gram featuresthat appear in high frequencies in model-generatedtext, a natural question arises as to whether suchfeatures can be used to reliably detect model-generated text. Prior work has established that thisis difficult, and that text-level features at the cor-pus level correlate with text being model-generated(Liang et al., 2024a,b). In this work, we make noclaims for the use of templates in AI-text detection.Our aim is to characterize patterns rather than de-tect generated outputs, and to provide a basis forfuture work on model linguistic diversity.",
  "Detecting Syntactic Templates": "Our goal is to search for abstract representations oftexts to capture more subtle repetitions than meretext memorization. Repeated strings of literal to-kens may not be sufficient for describing such re-dundancy nor why a summary produced by, e.g.,ChatGPT, might seem familiar.Focusing on syntactic patterns rather than tokensallows us to capture such repetitions For example,a pattern consisting of the part-of-speech sequenceDT JJ NN IN DT JJ NN will match to phrasesin movie reviews (a romantic comedy about acorporate executive) and in news summarization",
  "Defining Templates": "Given a sequence of tokens T = (t1, t2, . . . , tn),and a function f that computes an abstraction overT (e.g., part-of-speech tags), we define a tem-plate as a sub-sequence of abstractions over thetokens f(T) that repeats at least times in T. Fig-ure 1 shows examples of templates and their countsacross the Rotten Tomatoes dataset (Leone, 2020).",
  "Extracting Syntactic Templates from Text": "We operationalize the definition in 3.1 as parts-of-speech (POS). For sub-sequences of POS we con-sider templates of length n {4, 5, 6, 7, 8}. Tem-plates are characterized by their high frequencyacross the texts in a given corpus (e.g., one com-prising texts generated by a particular LLM) Prac-tically, we choose relative to the sample size. ForRotten Tomatoes we retain the top 100 most com-mon template where the least frequent templateappears 4 times in the dataset.To extract templates we use diversity (Shaibet al., 2024),2 a library providing tools to evalu-ate token and POS diversity in a dataset. We usethis tool to first tag all tokens in a corpus withtheir corresponding POS tags, then search for thetop 100 most frequent n-grams across these tags.diversity uses the SpaCy POS tagger,3 which re-lies on the Penn Treebank set of 36 tags (Tayloret al., 2003). After tagging, we return frequentn-grams of POS, the corresponding matched text. illustrates the output of running the tem-plate extraction process.The pipeline for identifying templates can be fur-ther extended to other tagging libraries and types. For example, we also explore constituency parsesas an alternative to POS tags. Extracting templatesand matching over tokens is non-trivial for con-stituency parses. We provide examples of the pat-terns identified by this abstraction in Appendix Aand leave further analysis to future work.",
  "Metrics for Measuring Templates": "Our goal for extracting templates is to assess andcharacterize different levels of repetition in LLMs.We calculate three metrics using templates, (1) thediversity of the POS tags that are generated usingCR-POS (2) the fraction of texts generated with atemplate using template rate and count, and (3) thenumber of templates that appear within each textusing templates-per-token. We now elaborate oneach one. CR-POS.At the most granular level, we are in-terested in quantifying the n-gram diversity of thePOS tag sequences present in the text. Lossless textcompression algorithmssuch as gZipare opti-mized to detect repeated characters in sequences,and rely on this to compress documents withoutany loss of information. If a document containsfrequent repeated strings, the document will bemore compressible, resulting in a larger differencein compressed size relative to the original docu-ment size. Shaib et al. (2024) show that using gZipto calculate a compression ratio (CR) can providean efficient measure for capturing lexical diversity,specifically n-gram repetition.We calculate CR over a set of POS-tagged text,with higher values indicating that text is highlycompressable (and therefore shows lower diver-sity). To calculate the CR, we concatenate all POS-tagged text into a sequence, and measure the ratiobetween the original document size and the com-pressed document size:",
  "1if text i contains at least 1 template0otherwise": "Templates-per-TokenIn practice, text can con-tain many templates. Measures of diversity are con-founded by text length (Salkar et al., 2022), whichalso applies to template counts; if a model tends toproduce longer texts, there is a higher chance thatany given output will contain a template. To com-pare between text sources, we can length normalize:",
  "Models": "Open ModelsWe first evaluate the incidence oftemplated text in two open-ended generation tasksusing OLMo-7B Instruct (Groeneveld et al., 2024),a fully open source model that released model train-ing checkpoints and its training data. This allows usto evaluate templates in its training datasets: Dolma(Soldaini et al., 2024), Tulu-V2 (Ivison et al., 2023),and Ultra-feedback (Cui et al., 2023).We then evaluate templates across closed sourcemodels (which do not release training data), specifi-cally: Mistral, Llama (-2, -3), Alpaca, and GPT-4o. Fine-tuned (Instruction) ModelsWe experi-ment with a total of 8 instruction-tuned models.We use Mistral (Instruct, 7B; Jiang et al. 2023), Al-paca (7B, 13B; Taori et al. 2023; Wang et al. 2022;Touvron et al. 2023a). In addition, 5 models arefurther trained on human preferences: OLMo (In-struct, 7B; Groeneveld et al. 2024), Llama-2 (Chat-HF, 7B-70B; Touvron et al. 2023b), and Llama-3(Instruct, 70B Dubey et al. 2024).",
  "While greedy decoding is a common decoding strat-egy for many popular downstream generation tasks,": "one can explicitly control token diversity at infer-ence time via choice of decoding hyperparameterssuch as temperature. We evaluate generation undervarious decoding strategies and model sizes. Werefer to Wiher et al. (2022) for an in-depth discus-sion on the impact of sampling on generated text,and here focus specifically on varying hyperparam-eters and resultant impact of the appearance andfrequency of templates. For the former, we usegreedy decoding, and separately vary temperatureand top-p for decoding with sampling. Top-p (nu-cleus) sample restricts the subset of tokens suchthat the combined probability reaches a thresholdp (Holtzman et al., 2020).",
  "Tasks and Datasets": "Open-Ended GenerationTo evaluate intrinsictemplate behaviour we evaluate open-ended gen-eration tasks in two settings. In the first setting,we sample generations from the model given onlya special token denoting beginning of sequence([BOS]). In the second, we randomly sample 100tokens from Dolma and use these tokens to promptfurther open-ended generation from the model. Synthetic Data GenerationLLMs are increas-ingly used to create synthetic training datasets,which are often used to train downstream mod-els (e.g., Wang et al. 2022). We evaluate templatesin Cosmopedia, a synthetic dataset generated byprompting Mixtral-8x7B-Instruct with instructionsto produce text relating to textbooks, blogposts, sto-ries, posts and WikiHow articles (Ben Allal et al.,2024). We prompt OLMo-7B with the Cosmopediainstructions and evaluate the resulting generations. SummarizationSummarization is a commonbenchmark for long text generation. We evaluatemodels on a handful of summarization datasets, in-cluding single- and multi-document tasks. Suchdatasets allow us to study templates in longer se-quences that would not be evident in tasks whereonly a few tokens are generated.For generalEnglish-language tasks, we generate summariesand reviews over news (CNN/Daily Mail; Nallap-ati et al. 2016), movies (Rotten Tomatoes; Leone2020), and books (BooookScore; Chang et al.2023).We also look at templates in the biomedicaldomain as an example of a domain-specific task.Cochrane is a dataset of systematic reviews sum-marizing the evidence over medical interventions",
  "Dolma5.6582.6 (0.012)Cosmopedia5.7699.1 (0.014)": ": CR-POS, template-per-token, and templatecounts for templates of size n = 6 reported for OLMo-7B text generated with Cosmopedia Instructions, and100 sampled tokens from the Dolma dataset, with greedydecoding. (Wallace et al., 2020). We prompt models to gener-ate systematic reviews. Importantly, these datasetsinclude human-written reference summaries, whichserve as a baseline to compare our task-specifictemplate analysis.",
  "Templates in Model-Generated Text": "We first evaluate OLMo-7B Instruct on 3 tasks:open-ended generation, synthetic data generation,and summarization, using both greedy and varyingtemperature and top-p sampling strategies (RQ1). shows the effect of varying sampling hy-perparameters temperature and top-p on the overalldiversity of the generated text with OLMo-7B withopen-generation and summarization. Varying sam-pling strategies in the open-generation task resultsin a higher variance of template rates (74.4% 2.1) compared to templates rates in the summariza-tion task (96.8% 0.6). These results indicate thattemplatic text in summarization appears in spiteof sampling strategies intended to increase (lex-ical) diversity. Overall, the rate of templates ismuch higher in the Rotten Tomatoes dataset thanfor open-generation, indicating downstream tasks",
  "Emergence of Templates in Training": "We first aim to understand when during trainingmodels start to generate templates. We measurethe perplexity of matched texts from a set of previ-ously extracted templates (following 3.2) acrossOLMos checkpoints. Higher perplexity values in-dicate the templates are assigned low likelihood atthat checkpoint.For each model checkpoint, we average the per-plexities of templates of length n = 6 and compareto the perplexities of randomly sampled 6-grams.We calculate the average perplexity for the datasetusing:1|D|1|N|",
  "k=12H(pk)(4)": "Where N is the total number of templates in thedocument, and D the total number of documentsin the dataset We repeat this process for randomlysampled 6-grams (distinct from the templates) tomatch the number of templates. Results shows the average perplexitiesacross model checkpoints. We find that templatesare learned quicklyby the first model checkpoint(which was trained on 4B tokens). Average perplex-ity drops to around 500 for non-template tokens,compared to 200 for templates. These findings aresurprising, and indicate that templates are learnedearly in pre-training, rather than during the fine-tuning process. The average perplexities remainlower for template tokens for the remainder of thetraining process.",
  "Templates in Pre-training Data": "The lower perplexities in the above finding indi-cates that templates are seen fairly early on in pre-training compared to non-templated sequences oftraining data text. We next measure the incidenceand types of templates in the pre-training data, andwhether they correspond to the templates that mod-els produce.To search for template coverage by OLMo, westart by selecting a random subset of the Dolmadataset, containing 10 billion tokens. We then an-notate all of the sequences with a POS tagger usingthe Dolma toolkit (Soldaini et al., 2024). Finally,we find the 50K most common POS-grams in thedata for sequence length of six using the WIMBDtoolkit (Elazar et al., 2023), which is optimized forsearch and count at large scales. Results shows the coverage of templatesproduced by OLMo in the pre-training data, thefine-tuning data, and their concatenation. We findthat 75% of templates produced by OLMo arefound in the pre-training data, indicating that amajority of templates are not a novel constructionlearned during fine-tuning, Rather, they are learneddirectly from pre-training data. In comparison,only 34% of randomly sampled non-templated se-quences are found in the pre-training data. Further, shows that the templates OLMo generatesconsistently rank higher in frequency in the pre-training dataset, compared to randomly samplednon-templates. The difference in ranks betweenthe templates and non-templates is statistically sig-nificant; the median rank in templates and non-templates are 337.5 and 9651.0 (MannWhitneyU = 6043, p < 0.05 two-tailed). Overall we find Pre-trainingFine-tuningBoth",
  "Templates in Closed-Source Models": "With OLMo, we find that 75% of templates arefound at high frequencies in the pre-training data(6.2). Most available models however do not re-lease their pre-training data. Here we evaluate theincidence of templates in other closed-source mod-els, which we define as models that do not releasetheir training data. Addressing RQ1, we charac-terize the rates of templatic texts in these models,and posit that templates may be indicators of thepre-training data sources models are trained on.",
  "Reference5.3146.4 (0.040)5.6383.3 (0.049)5.3336.0 (0.013)Input Documents5.8229.3 (0.001)5.9698.5 (0.021)5.5498.4 (0.020)": "OLMo-7B6.4597.0 (0.041)6.5374.0 (0.030)5.8391.2 (0.025)Mistral-7B6.2999.6 (0.043)6.1099.5 (0.043)5.7089.9 (0.029)Llama-2-7B6.8793.0 (0.047)6.4388.4 (0.042)5.7190.4 (0.028)Llama-2-13B6.7099.0 (0.060)6.6595.1 (0.052)5.9197.4 (0.042)Llama-2-70B6.3699.3 (0.123)6.5199.7 (0.042)5.6987.4 (0.027)Llama-3-70B6.3999.2 (0.151)6.5099.5 (0.030)5.6683.2 (0.024)Alpaca-7B6.6592.4 (0.070)7.8275.9 (0.051)6.6590.0 (0.027)Alpaca-13B6.2889.2 (0.053)6.2667.0 (0.043)5.5985.4 (0.028)GPT-4o6.1198.2 (0.041)6.1295.7 (0.011)5.7191.0 (0.026) : Compression ratio with POS (CR-POS) reported for each model-generated output over a random sample(n=500) of the Rotten Tomatoes, Cochrane, and CNN/DM datasets using greedy decoding, and the prompt Writea short summary\". For Cochrane, we use the prompt Write a meta-analysis\" to match the task. Largervalues in CR-POS indicate less diversity in the sequences. We report the percentage of generated outputs with atleast 1 template of size n = 6, and the rate of templates-per-token in parentheses (avg. num. templates per summarynormalized by avg. length). Models producing higher templates-per-token than the human-written references aremarked in bold. : Incidence of generated text with at least 1 tem-plate of sizes n = 4, 5, 6, 7, 8 over the (a) Rotten Toma-toes and (b) Cochrane datasets. Longer templates appearless frequently but at higher rates in model-generatedtext than in human-written references (dashed lines). reviews, biomedical evidence, and news ().We find that, on average in the Rotten Tomatoesdataset, 95% of outputs contain templates of lengthn = 6 across different model types and sizes. Thisis in contrast to human-written reference and inputdocuments, which contain templates of the samesize on average in 38% of cases. We find a similartrend for templates of length n = ().While the average number of templates is higher in model-generated output, this could be attributedto models simply producing lengthier texts than thehuman written references. To quantify this, we alsocompute the template-per-token as a length nor-malized value capturing the average templates persummary. Even controlling for length, most mod-els produce more templates per token than humanauthors, as shown in .The CNN/DM datasets show similar trends, butwith lower rates of templates (average 89.6% con-tain templates) compared to the Rotten Tomatoesdataset. In contrast, the percentage of templatesis high for model-generated (average 88.3%) andhuman-written references (83.3%) in the Cochranedataset. This owes to the nature of meta-analysistexts, which are formulaic (Higgins and Green,2010).5 illustrates the rate of templates foreach model as the template length grows fromlength n = 4 to 8 for Rotten Tomatoes andCochrane. For Rotten Tomatoes (and CNN; Ap-pendix B), all models produce templates at higherrates than human-written summaries across all tem-plate lengths. With Cochrane, template lengths 6show the majority of models produce higher ratesof templates than human authored references. Thisindicates that differences between templatedness inhuman-authored references and LLM summariessurface only at longer template lengths.",
  "Claude-20485.6395.0 (0.010)Claude-880005.6094.0 (0.004)ChatGPT-20486.17100.0 (0.017)GPT4-20486.04100.0 (0.013)GPT4-40966.0199.0 (0.013)Mixtral-20486.01100.0 (0.017)": ": Compression ratio with POS (CR-POS) re-ported for the BooookScore dataset. We report the per-centage of generated outputs with at least 1 templateof size n = 6, and the rate of templates-per-token inparentheses. 13k - 14k 14k - 16k 16k - 18k 18k - 21k 21k - 24k 24k - 31k 31k - 33k 33k - 41k 41k - 68k 68k - 352k # Repetitions (Training Data) Memorized Templates (%) Exact MemorizedPOS Memorized",
  "Effect of Model Size on Template Rates": "reports differences in the rate of templates betweendifferent sizes of Llama-2 and Alpaca. In the caseof Alpaca, the larger model yields outputs with lessrepetition and fewer templates. With the Llama-2and Llama-3 models, we observe a surprising trendas model size increases: CR-POS and average textlength decrease, however the rate of summaries thatcontain one or more templates stays the same (andincreases slightly in some cases). These results in-dicate that larger models do not necessarily produceless templated outputs. The templates-per-tokenvalue further supports this, showing an increase intemplate rate (per token) for larger models.",
  "Style Memorization": "Past work has shown that models memorize por-tions of pre-training data. Carlini et al. (2022) showa lower bound of 1% verbatim memorized data.We next show how our syntactic template analysiscan be used to evaluate how much models mem-orize from pre-training data, beyond strict tokensequence matches (RQ3). Definition: Exact-Text MemorizationWe bor-row the definition for extractable memorizationfrom Carlini et al. (2022). A string s is memorizedby a model M if, when prompted with contextp, M(p) produces a string g that is an exact textmatch to the source string s under greedy decoding. Definition:Style (POS) MemorizationForstyle memorization, we follow the same definitionfor Exact-Text, but modified to operate over POS(rather than token) sequences to capture instancesof syntactic style. Specifically, given a POS tag-ger f, sequence f(s) is memorized by if, whenprompted with context p, (p) produces a sequenceg such that f(g) is an exact match to the sourcestring f(s).",
  "Experimental Setup": "We follow a similar experimental setup as Carliniet al. (2022), focusing on creating sampled datasetsthat contain n-grams repeated in the pre-trainingdataset. We use WIMBD to build our subset overthe Dolma dataset and return the top 50k most com-mon 100-grams in the Dolma dataset from 6.2.For each 100-gram, we tokenize the sequence withNLTK and truncate to 50 tokens (Carlini et al.,2022). Following the setup for extracting mem-orized sequences, we prompt OLMo-7B with 50tokens of the training data sequence and generate amaximum of 1000 tokens using greedy decoding.We apply NLTKs POS model to tag the original",
  "Results": "We randomly sample 10k documents and look atthe fraction of memorized outputs based on exact-match and the POS sequence (style) memoriza-tion using the diversity package (e.g., ).We average the fraction memorized over 1,000seeds for sampling the datasets.On average, the POS memorization definitionfinds 6.4% ( 0.7) memorized, whereas exact textmatch only reports 5.3% ( 0.6) memorized ofthe training dataset. shows the percenttemplates memorized stratified by frequency of the100-gram in the training dataset. We divide thesampled data point into 10 buckets each containing4,138 samples with counts that fall in each bucket.In all buckets, POS memorization captures a higherrate of memorized sequences.The implications of our looser definition of mem-orization allows us to capture instances of mem-orization where exact tokens may be substitutedduring generation, but where an output span isnonetheless structurally the same as a source string.Note that this method will by default also captureduplicate text in addition to softly memorized se-quence. In , we provide sampled examplesof substitutions that occur that are not captured byexact-memorization definitions, yet demonstratethat the particular style of that training point hasbeen memorized. We find that these cases often in-clude synonym swaps, or different numbers beinggenerated.",
  "Conclusions": "In this work, we introduce syntactic templates asa framework for analyzing subtle repetitive char-acteristics in model-generated text. We show thatthis analysis can also extend to human-written ref-erences and downstream tasks, and find that thepre-training data contains many of these identifiedtemplates. We show that evaluating repetition inparts-of-speech sequences is useful for detectingsubtle types of data memorization. Our hopeis that this work inspires additional research intocharacterizing where (in data) observed stylisticpatterns in LLM outputs originate.",
  "There are a few limitations to this work that weaddress here": "First, this type of analysis requires an entire cor-pus that is representative of a text source. For paidmodels, this can be costly to obtain. For largedatasets, this can be resource intensive. Theseconsiderations provide a potential barrier basedon available resources.Second, we use third party tools to tag our textabstractions; however these tools are determinis-tic, but can contain errors in the tags they assignto sequences, particularly if a sequence containstext from another language. We assume that themajority of the text we analyze is in English, andthat any errors are superseded by the frequency ofcommon templates.Finally, this work only examines English texts,in part due to availabilty of datasets at the scalenecessary to evaluate models.",
  "Chrysanne DiMarco and Graeme Hirst. 1993. A compu-tational theory of goal-directed style in syntax. Com-putational Linguistics, 19(3):451500": "Yao Dou, Maxwell Forbes, Rik Koncel-Kedziorski,Noah A Smith, and Yejin Choi. 2022. Is gpt-3 textindistinguishable from human text? scarecrow: Aframework for scrutinizing machine text. In Proceed-ings of the 60th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 72507274. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,Akhil Mathur, Alan Schelten, Amy Yang, AngelaFan, Anirudh Goyal, Anthony Hartshorn, Aobo Yang,Archi Mitra, Archie Sravankumar, Artem Korenev,Arthur Hinsvark, Arun Rao, Aston Zhang, AurelienRodriguez, Austen Gregerson, Ava Spataru, Bap-tiste Roziere, Bethany Biron, Binh Tang, BobbieChern, Charlotte Caucheteux, Chaya Nayak, ChloeBi, Chris Marra, Chris McConnell, Christian Keller,Christophe Touret, Chunyang Wu, Corinne Wong,Cristian Canton Ferrer, Cyrus Nikolaidis, Damien Al-lonsius, Daniel Song, Danielle Pintz, Danny Livshits,David Esiobu, Dhruv Choudhary, Dhruv Mahajan,Diego Garcia-Olano, Diego Perino, Dieuwke Hupkes,Egor Lakomkin, Ehab AlBadawy, Elina Lobanova,Emily Dinan, Eric Michael Smith, Filip Radenovic,Frank Zhang, Gabriel Synnaeve, Gabrielle Lee, Geor-gia Lewis Anderson, Graeme Nail, Gregoire Mi-alon, Guan Pang, Guillem Cucurell, Hailey Nguyen,Hannah Korevaar, Hu Xu, Hugo Touvron, IliyanZarov, Imanol Arrieta Ibarra, Isabel Kloumann, IshanMisra, Ivan Evtimov, Jade Copet, Jaewon Lee, JanGeffert, Jana Vranes, Jason Park, Jay Mahadeokar,Jeet Shah, Jelmer van der Linde, Jennifer Billock,Jenny Hong, Jenya Lee, Jeremy Fu, Jianfeng Chi,Jianyu Huang, Jiawen Liu, Jie Wang, Jiecao Yu,Joanna Bitton, Joe Spisak, Jongsoo Park, JosephRocca, Joshua Johnstun, Joshua Saxe, Junteng Jia,Kalyan Vasuden Alwala, Kartikeya Upasani, KatePlawiak, Ke Li, Kenneth Heafield, Kevin Stone, Khalid El-Arini, Krithika Iyer, Kshitiz Malik, Kuen-ley Chiu, Kunal Bhalla, Lauren Rantala-Yeary, Lau-rens van der Maaten, Lawrence Chen, Liang Tan, LizJenkins, Louis Martin, Lovish Madaan, Lubo Malo,Lukas Blecher, Lukas Landzaat, Luke de Oliveira,Madeline Muzzi, Mahesh Pasupuleti, Mannat Singh,Manohar Paluri, Marcin Kardas, Mathew Oldham,Mathieu Rita, Maya Pavlova, Melanie Kambadur,Mike Lewis, Min Si, Mitesh Kumar Singh, MonaHassan, Naman Goyal, Narjes Torabi, Nikolay Bash-lykov, Nikolay Bogoychev, Niladri Chatterji, OlivierDuchenne, Onur elebi, Patrick Alrassy, PengchuanZhang, Pengwei Li, Petar Vasic, Peter Weng, Pra-jjwal Bhargava, Pratik Dubal, Praveen Krishnan,Punit Singh Koura, Puxin Xu, Qing He, QingxiaoDong, Ragavan Srinivasan, Raj Ganapathy, RamonCalderer, Ricardo Silveira Cabral, Robert Stojnic,Roberta Raileanu, Rohit Girdhar, Rohit Patel, Ro-main Sauvestre, Ronnie Polidoro, Roshan Sumbaly,Ross Taylor, Ruan Silva, Rui Hou, Rui Wang, SagharHosseini, Sahana Chennabasappa, Sanjay Singh,Sean Bell, Seohyun Sonia Kim, Sergey Edunov,Shaoliang Nie, Sharan Narang, Sharath Raparthy,Sheng Shen, Shengye Wan, Shruti Bhosale, ShunZhang, Simon Vandenhende, Soumya Batra, SpencerWhitman, Sten Sootla, Stephane Collot, Suchin Gu-rurangan, Sydney Borodinsky, Tamar Herman, TaraFowler, Tarek Sheasha, Thomas Georgiou, ThomasScialom, Tobias Speckbacher, Todor Mihaylov, TongXiao, Ujjwal Karn, Vedanuj Goswami, VibhorGupta, Vignesh Ramanathan, Viktor Kerkez, VincentGonguet, Virginie Do, Vish Vogeti, Vladan Petro-vic, Weiwei Chu, Wenhan Xiong, Wenyin Fu, Whit-ney Meers, Xavier Martinet, Xiaodong Wang, Xiao-qing Ellen Tan, Xinfeng Xie, Xuchao Jia, XueweiWang, Yaelle Goldschlag, Yashesh Gaur, YasmineBabaei, Yi Wen, Yiwen Song, Yuchen Zhang, YueLi, Yuning Mao, Zacharie Delpierre Coudert, ZhengYan, Zhengxing Chen, Zoe Papakipos, Aaditya Singh,Aaron Grattafiori, Abha Jain, Adam Kelsey, AdamShajnfeld, Adithya Gangidi, Adolfo Victoria, AhuvaGoldstand, Ajay Menon, Ajay Sharma, Alex Boesen-berg, Alex Vaughan, Alexei Baevski, Allie Feinstein,Amanda Kallet, Amit Sangani, Anam Yunus, An-drei Lupu, Andres Alvarado, Andrew Caples, An-drew Gu, Andrew Ho, Andrew Poulton, AndrewRyan, Ankit Ramchandani, Annie Franco, Apara-jita Saraf, Arkabandhu Chowdhury, Ashley Gabriel,Ashwin Bharambe, Assaf Eisenman, Azadeh Yaz-dan, Beau James, Ben Maurer, Benjamin Leonhardi,Bernie Huang, Beth Loyd, Beto De Paola, BhargaviParanjape, Bing Liu, Bo Wu, Boyu Ni, Braden Han-cock, Bram Wasti, Brandon Spence, Brani Stojkovic,Brian Gamido, Britt Montalvo, Carl Parker, CarlyBurton, Catalina Mejia, Changhan Wang, ChangkyuKim, Chao Zhou, Chester Hu, Ching-Hsiang Chu,Chris Cai, Chris Tindal, Christoph Feichtenhofer, Da-mon Civin, Dana Beaty, Daniel Kreymer, Daniel Li,Danny Wyatt, David Adkins, David Xu, Davide Tes-tuggine, Delia David, Devi Parikh, Diana Liskovich,Didem Foss, Dingkang Wang, Duc Le, Dustin Hol-land, Edward Dowling, Eissa Jamil, Elaine Mont-gomery, Eleonora Presani, Emily Hahn, Emily Wood, Erik Brinkman, Esteban Arcaute, Evan Dunbar, EvanSmothers, Fei Sun, Felix Kreuk, Feng Tian, FiratOzgenel, Francesco Caggioni, Francisco Guzmn,Frank Kanayet, Frank Seide, Gabriela Medina Flo-rez, Gabriella Schwarz, Gada Badeer, Georgia Swee,Gil Halpern, Govind Thattai, Grant Herman, GrigorySizov, Guangyi, Zhang, Guna Lakshminarayanan,Hamid Shojanazeri, Han Zou, Hannah Wang, Han-wen Zha, Haroun Habeeb, Harrison Rudolph, He-len Suk, Henry Aspegren, Hunter Goldman, IbrahimDamlaj, Igor Molybog, Igor Tufanov, Irina-ElenaVeliche, Itai Gat, Jake Weissman, James Geboski,James Kohli, Japhet Asher, Jean-Baptiste Gaya,Jeff Marcus, Jeff Tang, Jennifer Chan, Jenny Zhen,Jeremy Reizenstein, Jeremy Teboul, Jessica Zhong,Jian Jin, Jingyi Yang, Joe Cummings, Jon Carvill,Jon Shepard, Jonathan McPhie, Jonathan Torres,Josh Ginsburg, Junjie Wang, Kai Wu, Kam HouU, Karan Saxena, Karthik Prasad, Kartikay Khan-delwal, Katayoun Zand, Kathy Matosich, KaushikVeeraraghavan, Kelly Michelena, Keqian Li, KunHuang, Kunal Chawla, Kushal Lakhotia, Kyle Huang,Lailin Chen, Lakshya Garg, Lavender A, LeandroSilva, Lee Bell, Lei Zhang, Liangpeng Guo, LichengYu, Liron Moshkovich, Luca Wehrstedt, MadianKhabsa, Manav Avalani, Manish Bhatt, Maria Tsim-poukelli, Martynas Mankus, Matan Hasson, MatthewLennie, Matthias Reso, Maxim Groshev, MaximNaumov, Maya Lathi, Meghan Keneally, Michael L.Seltzer, Michal Valko, Michelle Restrepo, MihirPatel, Mik Vyatskov, Mikayel Samvelyan, MikeClark, Mike Macey, Mike Wang, Miquel Jubert Her-moso, Mo Metanat, Mohammad Rastegari, Mun-ish Bansal, Nandhini Santhanam, Natascha Parks,Natasha White, Navyata Bawa, Nayan Singhal, NickEgebo, Nicolas Usunier, Nikolay Pavlovich Laptev,Ning Dong, Ning Zhang, Norman Cheng, OlegChernoguz, Olivia Hart, Omkar Salpekar, OzlemKalinli, Parkin Kent, Parth Parekh, Paul Saab, Pa-van Balaji, Pedro Rittner, Philip Bontrager, PierreRoux, Piotr Dollar, Polina Zvyagina, Prashant Ratan-chandani, Pritish Yuvraj, Qian Liang, Rachad Alao,Rachel Rodriguez, Rafi Ayub, Raghotham Murthy,Raghu Nayani, Rahul Mitra, Raymond Li, RebekkahHogan, Robin Battey, Rocky Wang, Rohan Mah-eswari, Russ Howes, Ruty Rinott, Sai Jayesh Bondu,Samyak Datta, Sara Chugh, Sara Hunt, SargunDhillon, Sasha Sidorov, Satadru Pan, Saurabh Verma,Seiji Yamamoto, Sharadh Ramaswamy, Shaun Lind-say, Shaun Lindsay, Sheng Feng, Shenghao Lin,Shengxin Cindy Zha, Shiva Shankar, ShuqiangZhang, Shuqiang Zhang, Sinong Wang, Sneha Agar-wal, Soji Sajuyigbe, Soumith Chintala, StephanieMax, Stephen Chen, Steve Kehoe, Steve Satterfield,Sudarshan Govindaprasad, Sumit Gupta, SungminCho, Sunny Virk, Suraj Subramanian, Sy Choudhury,Sydney Goldman, Tal Remez, Tamar Glaser, TamaraBest, Thilo Kohler, Thomas Robinson, Tianhe Li,Tianjun Zhang, Tim Matthews, Timothy Chou, TzookShaked, Varun Vontimitta, Victoria Ajayi, VictoriaMontanez, Vijai Mohan, Vinay Satish Kumar, VishalMangla, Vtor Albiero, Vlad Ionescu, Vlad Poenaru,Vlad Tiberiu Mihailescu, Vladimir Ivanov, Wei Li, Wenchen Wang, Wenwen Jiang, Wes Bouaziz, WillConstable, Xiaocheng Tang, Xiaofang Wang, Xiao-jian Wu, Xiaolan Wang, Xide Xia, Xilun Wu, XinboGao, Yanjun Chen, Ye Hu, Ye Jia, Ye Qi, Yenda Li,Yilin Zhang, Ying Zhang, Yossi Adi, Youngjin Nam,Yu, Wang, Yuchen Hao, Yundi Qian, Yuzi He, ZachRait, Zachary DeVito, Zef Rosnbrick, Zhaoduo Wen,Zhenyu Yang, and Zhiwei Zhao. 2024. The llama 3herd of models. Yanai Elazar, Akshita Bhagia, Ian Magnusson, Abhi-lasha Ravichander, Dustin Schwenk, Alane Suhr,Pete Walsh, Dirk Groeneveld, Luca Soldaini, SameerSingh, et al. 2023. Whats in my big data? arXivpreprint arXiv:2310.20707.",
  "Yoav Goldberg. 2019. Assessing berts syntactic abili-ties. arXiv preprint arXiv:1901.05287": "Dirk Groeneveld, Iz Beltagy, Pete Walsh, Akshita Bha-gia, Rodney Kinney, Oyvind Tafjord, A. Jha, HamishIvison, Ian Magnusson, Yizhong Wang, Shane Arora,David Atkinson, Russell Authur, Khyathi RaghaviChandu, Arman Cohan, Jennifer Dumas, YanaiElazar, Yuling Gu, Jack Hessel, Tushar Khot, WilliamMerrill, Jacob Daniel Morrison, Niklas Muennighoff,Aakanksha Naik, Crystal Nam, Matthew E. Peters,Valentina Pyatkin, Abhilasha Ravichander, DustinSchwenk, Saurabh Shah, Will Smith, Emma Strubell,Nishant Subramani, Mitchell Wortsman, PradeepDasigi, Nathan Lambert, Kyle Richardson, LukeZettlemoyer, Jesse Dodge, Kyle Lo, Luca Soldaini,Noah A. Smith, and Hanna Hajishirzi. 2024. Olmo:Accelerating the science of language models. ArXiv,abs/2402.00838.",
  "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, andYejin Choi. 2020. The curious case of neural text de-generation. In International Conference on LearningRepresentations": "Dieuwke Hupkes, Mario Giulianelli, Verna Dankers,Mikel Artetxe, Yanai Elazar, Tiago Pimentel, Chris-tos Christodoulopoulos, Karim Lasri, Naomi Saphra,Arabella Sinclair, Dennis Ulmer, Florian Schottmann,Khuyagbaatar Batsuren, Kaiser Sun, Koustuv Sinha,Leila Khalatbari, Maria Ryskina, Rita Frieske, RyanCotterell, and Zhijing Jin. 2023. A taxonomy andreview of generalization research in nlp. Nature Ma-chine Intelligence, 5(10):11611174. Hamish Ivison, Yizhong Wang, Valentina Pyatkin,Nathan Lambert, Matthew E. Peters, Pradeep Dasigi,Joel Jang, David Wadden, Noah A. Smith, Iz Beltagy,and Hanna Hajishirzi. 2023. Camels in a changingclimate: Enhancing lm adaptation with tulu 2. ArXiv,abs/2311.10702.",
  "Stefano Leone. 2020. Rotten tomatoes movies and criticreviews dataset": "Weixin Liang, Zachary Izzo, Yaohui Zhang, Haley Lepp,Hancheng Cao, Xuandong Zhao, Lingjiao Chen, Hao-tian Ye, Sheng Liu, Zhi Huang, et al. 2024a. Moni-toring ai-modified content at scale: A case study onthe impact of chatgpt on ai conference peer reviews.arXiv preprint arXiv:2403.07183. Weixin Liang, Yaohui Zhang, Zhengxuan Wu, HaleyLepp, Wenlong Ji, Xuandong Zhao, Hancheng Cao,Sheng Liu, Siyu He, Zhi Huang, et al. 2024b. Map-ping the increasing use of llms in scientific papers.arXiv preprint arXiv:2404.01268. R. Thomas McCoy, Paul Smolensky, Tal Linzen, Jian-feng Gao, and Asli Celikyilmaz. 2023. How MuchDo Language Models Copy From Their TrainingData? Evaluating Linguistic Novelty in Text Genera-tion Using RAVEN. Transactions of the Associationfor Computational Linguistics, 11:652670.",
  "Ariel Rosenfeld and Teddy Lazebnik. 2024. Whosellm is it anyway? linguistic comparison and llm at-tribution for gpt-3.5, gpt-4 and bard. arXiv preprintarXiv:2402.14533": "Nikita Salkar, Thomas Trikalinos, Byron Wallace, andAni Nenkova. 2022. Self-repetition in abstractiveneural summarizers. In Proceedings of the 2nd Con-ference of the Asia-Pacific Chapter of the Associationfor Computational Linguistics and the 12th Interna-tional Joint Conference on Natural Language Pro-cessing (Volume 2: Short Papers), pages 341350,Online only. Association for Computational Linguis-tics. Chantal Shaib, Joe Barrow, Jiuding Sun, Alexa F Siu,Byron C Wallace, and Ani Nenkova. 2024. Stan-dardizing the measurement of text diversity: A tooland a comparative analysis of scores. arXiv preprintarXiv:2403.00553. Luca Soldaini, Rodney Kinney, Akshita Bhagia, DustinSchwenk, David Atkinson, Russell Authur, Ben Bo-gin, Khyathi Chandu, Jennifer Dumas, Yanai Elazar,et al. 2024. Dolma: An open corpus of three tril-lion tokens for language model pretraining research.arXiv preprint arXiv:2402.00159. Juan Soler-Company and Leo Wanner. 2017. On therelevance of syntactic and discourse features for au-thor profiling and identification. In Proceedings ofthe 15th Conference of the European Chapter of theAssociation for Computational Linguistics: Volume2, Short Papers, pages 681687, Valencia, Spain. As-sociation for Computational Linguistics.",
  "and efficient foundation language models. ArXiv,abs/2302.13971": "Hugo Touvron, Louis Martin, Kevin R. Stone, PeterAlbert, Amjad Almahairi, Yasmine Babaei, Niko-lay Bashlykov, Soumya Batra, Prajjwal Bhargava,Shruti Bhosale, Daniel M. Bikel, Lukas Blecher, Cris-tian Cantn Ferrer, Moya Chen, Guillem Cucurull,David Esiobu, Jude Fernandes, Jeremy Fu, WenyinFu, Brian Fuller, Cynthia Gao, Vedanuj Goswami,Naman Goyal, Anthony S. Hartshorn, Saghar Hos-seini, Rui Hou, Hakan Inan, Marcin Kardas, ViktorKerkez, Madian Khabsa, Isabel M. Kloumann, A. V.Korenev, Punit Singh Koura, Marie-Anne Lachaux,Thibaut Lavril, Jenya Lee, Diana Liskovich, YinghaiLu, Yuning Mao, Xavier Martinet, Todor Mihaylov,Pushkar Mishra, Igor Molybog, Yixin Nie, AndrewPoulton, Jeremy Reizenstein, Rashi Rungta, KalyanSaladi, Alan Schelten, Ruan Silva, Eric MichaelSmith, R. Subramanian, Xia Tan, Binh Tang, RossTaylor, Adina Williams, Jian Xiang Kuan, PuxinXu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang, An-gela Fan, Melanie Kambadur, Sharan Narang, Aure-lien Rodriguez, Robert Stojnic, Sergey Edunov, andThomas Scialom. 2023b. Llama 2: Open foundationand fine-tuned chat models. ArXiv, abs/2307.09288. Byron C. Wallace, Sayantani Saha, Frank Soboczen-ski, and Iain James Marshall. 2020.Generating(factual?) narrative summaries of rcts: Experimentswith neural multi-document summarization. AMIA ...Annual Symposium proceedings. AMIA Symposium,2021:605614. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, AlisaLiu, Noah A. Smith, Daniel Khashabi, and HannanehHajishirzi. 2022. Self-instruct: Aligning languagemodels with self-generated instructions. In AnnualMeeting of the Association for Computational Lin-guistics.",
  "Template (Constituents)FrequencyMatched Text": "(VP (VB ) (NP (NP (DT )(JJ ) (NN )) (PP (IN ) (NP)458Trace the intellectual history of ancientExamine the early history of automobilesguarantee a seamless ascent into anotherreach a broad audience of buyers(PP (IN ) (NP (NP (DT ) (JJ )(NN )) (PP (IN ) (NP)948as a key component of yourby a high abundance of freeacross a global range of culturesfor the comprehensive study of the(DT ) (JJ ) (NN ))(PP (IN ) (NP)1680a strong grasp of variousa solid understanding ofa radical change in",
  "There is no evidence from good quality randomized trials or non-randomized studies of the effectiveness of lens extraction for chronic primary angle-closure glaucoma": "There was not enough evidence to judge whether or not the included drugs cured bedwetting when used alone. [...] There was also evidence to suggest that combination therapy with anticholinergic therapy increased the efficacy of other established therapies such as imipramine, desmopressin and enuresis alarms by [...]. Future studies should evaluate the role of combination therapy against established treatments in rigorous and adequately powered trials. There is some evidence for use of botulinum toxin injections to salivary glands for the treatment of sialorrhea in MND. Further research is required on this important symptom. Data are needed on the problem of sialorrhea in MND and its measurement, both by patient self report measures and objective tests. These will allow the development of better randomized controlled trials. There is significant evidence to suggest that topical application of chlorhexidine to umbilical cord reduces neonatal mortality and omphalitis in community and primary care settings in developing countries. It may increase cord separation time however, there is no evidence that it increases risk of subsequent morbidity or infection.There is insufficient evidence to support the application of an antiseptic to umbilical cord in hospital settings compared with dry cord care in developed countries.We found insufficient evidence to determine if overground physical therapy gait training benefits gait function in patients with chronic stroke, though limited evidence suggests small benefits for variables such as gait speed or 6MWT. These findings must be replicated by large, high quality studies using varied outcome measures.",
  ": Percentage of generated summaries with atleast 1 template of length n = 6 under different instruc-tion prompts. Some instruction prompts result is moretemplates outputs for certain models": "result in lower performance. It is possible that withthe shorter and more generic instructions instruc-tions, there may be a higher overlap in templatetypes across models.The choice of prompt can affect the rate of tem-plates. Appendix shows the rate of tem-plates with different prompts while the choice ofprompt impacts the rate of templates, the incidenceremains on average higher than 90%.",
  "Reference5.3125.146.4 (0.040)5.6373.883.3 (0.049)5.3357.736.0 (0.013)Input Documents5.82668.229.3 (0.001)5.961555.398.5 (0.021)5.54514.798.4 (0.020)": "OLMo-7B6.45194.497.0 (0.041)6.53158.174.0 (0.030)5.83177.191.2 (0.025)Mistral-7B6.29185.699.6 (0.043)6.10177.299.5 (0.043)5.70153.089.9 (0.029)Llama-2-7B6.87126.593.0 (0.047)6.43151.088.4 (0.042)5.71153.990.4 (0.028)Llama-2-13B6.70117.099.0 (0.060)6.65157.795.1 (0.052)5.91143.597.4 (0.042)Llama-2-70B6.36114.299.3 (0.123)6.51324.799.7 (0.042)5.69138.387.4 (0.027)Llama-3-70B6.39106.199.2 (0.151)6.50387.599.5 (0.030)5.66132.783.2 (0.024)Alpaca-7B6.6599.492.4 (0.070)7.8298.175.9 (0.051)6.65145.290.0 (0.027)Alpaca-13B6.2893.089.2 (0.053)6.2669.767.0 (0.043)5.59138.185.4 (0.028)GPT-4o6.11203.598.2 (0.041)6.12560.795.7 (0.011)5.71167.691.0 (0.026) : Compression ratio with POS (CR-POS) reported for each model-generated output over a random sample(n=500) of the Rotten Tomatoes, Cochrane, and CNN/DM datasets using greedy decoding, and the prompt Writea short summary\". For Cochrane, we use the prompt Write a meta-analysis\" to match the task. Largervalues in CR-POS indicate less diversity in the sequences. We report the percentage of generated outputs with atleast 1 template of size n = 6, and the rate of templates-per-token in parentheses (avg. num. templates per summarynormalized by avg. length). Models producing higher templates-per-token than the human-written references aremarked in bold."
}