{
  "Abstract": "Caregiver strategy classification in pediatric re-habilitation contexts is strongly motivated byreal-world clinical constraints but highly under-resourced and seldom studied in natural lan-guage processing settings. We introduce a largedataset of 3,062 caregiver strategies in this set-ting, a five-fold increase over the nearest con-temporary dataset. These strategies are manu-ally categorized into clinically established con-structs with high agreement (=0.68-0.89). Wealso propose two techniques to further addressidentified data constraints. First, we manuallysupplement target task data with relevant publicdata from online child health forums. Next, wepropose a novel data augmentation techniqueto generate synthetic caregiver strategies withhigh downstream task utility. Extensive experi-ments showcase the quality of our dataset. Theyalso establish evidence that both the publiclyavailable data and the synthetic strategies re-sult in large performance gains, with relativeF1 increases of 22.6% and 50.9%, respectively.",
  "Introduction": "Globally, over 50 million children aged 0-5 yearsexperience disability (Olusanya et al., 2018). Theseyoung children and their families benefit fromtimely access to quality pediatric rehabilitation ser-vices in diverse contexts, ranging from hospitalto home and community (Olusanya et al., 2024).When rehabilitation providers create conditions forfamilies to share their expertise about their childsattendance and involvement in valued activities,perceived supports and strategies, and prioritiesfor change, they can engage families in shareddecision-making to design and monitor a meaning-ful service plan (Crawford et al., 2022). Providersbenefit from gathering this information from fam-ilies to direct equitable care (Pinto et al., 2022;Jarvis and Fink, 2021; Magnusson and Khetani,",
  "*Work completed at University of Illinois Chicago": "2022). However, parent-generated data is often col-lected and documented as free text narratives, ne-cessitating efforts to extract and standardize contentfor clinical and research applications (Newman-Griffis et al., 2022a; Kaelin et al., 2024, 2022b).Development of web-based tools (e.g., the Par-ticipation and Environment Measure (Coster andKhetani, 2008), also known as PEM) can diver-sify the capture and use of structured and narrativeinformation from families to drive pediatric reha-bilitation service design and improvement. Recentwork established benchmarks for the detection andclassification of caregiver strategies collected usingtwo available versions of a PEM tool (Kaelin et al.,2023; Valizadeh et al., 2024). However, modelperformance was constrained by a limited avail-ability of caregiver strategy data involving children,across a subset of relevant age ranges and rehabil-itation care contexts. A larger, more diverse datasource is needed to strengthen applicability acrossthe broader pediatric rehabilitation care continuum.We respond to that need in this work, makingthree primary contributions. First, we establishinclusion and exclusion criteria for data sourcesfitting one or more classes of caregiver strategies.We define primary class characteristics, identifyrelevant and irrelevant external sources, and con-struct or select prototypical samples. Next, weidentify and prepare a subset of strategies datafrom (a) three datasets from prior related research(n=185 families (Jarvis et al., 2019; Khetani et al.,2015, 2023)) matching these criteria, and (b) pub-licly available data instances that also match es-tablished guidelines. Data are preprocessed andstored in a format compatible with existing care-giver strategies data (Valizadeh et al., 2024), andlabeled according to strategy class with high relia-bility (=0.68-0.89). Finally, we propose a noveldata augmentation technique to generate and filtercaregiver strategies. We perform quality checks andperformance comparisons to assess augmentation feasibility within this task domain. Ultimately, wefind that our manually and synthetically augmenteddata improves strategy classification performanceby a wide margin, establishing a new performanceceiling for this task (F1=0.80).",
  "Caregiver Strategy Data": "Minimal existing data is suitable for caregiver strat-egy classification in pediatric rehabilitation set-tings. Previously, Newman-Griffis et al. (2021)created a dataset of 289 clinical documents associ-ated with claims for federal disability benefits fromthe U.S. Social Security Administration, and Cho-rianopoulou et al. (2017) created a dataset with apediatric focus, collecting video-recorded sessionsof children with autism spectrum disorder and typ-ically developing children. However, these datadid not relate to caregiver strategies for improvingchild participation in daily activities.The closest relevant dataset is the recently re-leased CareCorpus (Valizadeh et al., 2024), whichcontains 780 caregiver strategies organized into cat-egories based on known drivers of child and youthparticipation (Imms et al., 2017). CareCorpus isdrawn from a subset of data collected during a sin-gle pilot implementation trial of PEM in an earlyintervention program targeting children 0-3 yearsold (Kaelin et al., 2022a), which limits the gener-alizability of information that can be drawn fromthe corpus, in terms of both child demographicsand service context. We (1) add data from morediverse pediatric rehabilitation care contexts (hos-pital, home, and community) as accessed by chil-dren across a broader age range (0-5 years); (2)introduce non-strategies from stylistically relevantsources; and (3) incorporate a synthetic data aug-mentation approach to further diversify our trainingstrategies. This addresses limitations of CareCor-pus, including data scarcity, homogeneity, and classimbalances.",
  "granularities. Valizadeh et al. (2024) experimentedwith both feature-based models and popular pre-trained language models (PLMs), finding competi-tive performance using a fine-tuned BERT model": "Valizadeh et al. (2024)s study raised questionsabout whether general-domain pretraining data isstill preferable to more health-focused data fordiversified pediatric rehabilitation contexts as ac-cessed by children across a broader age range.Moreover, replicating their study on a larger datasetenables assessment of the reproducibility and gen-eralizability of their findings. Our work creates asandbox extending from this for the study of dataaugmentation in specialized healthcare settings.",
  "Data Augmentation": "Data augmentation (DA) tackles data scarcity inlow-resource NLP tasks by employing techniquesto generate additional similar samples that varyalong some dimension from the original source. Apopular DA approach is rewriting or paraphrasing,by replacing words with synonyms and varyingsentence structure while preserving overall mean-ing (Wei and Zou, 2019; Kobayashi, 2018; Guptaet al., 2017; Okur et al., 2022). Other common ap-proaches include backtranslation, which involvestranslating data to and from one or more interme-diate languages (Edunov et al., 2018; Yu et al.,2018), and data noising, which involves maskingsome words with random unigrams or placeholdertokens (Xie et al., 2017). These rule-based DAtechniques may struggle with semantic diversity.In contrast, conditional generation involves fine-tuning a PLM to produce text conditioned on thetarget label (Bowman et al., 2016; Anaby-Tavoret al., 2020; Yang et al., 2020; Lee et al., 2021).However, it has traditionally required costly humanlabels (Sahu et al., 2022; Papangelis et al., 2021).Large language models (LLMs) have emerged asa promising avenue for generating synthetic data,demonstrating remarkable rewriting capabilities(Radford et al., 2021). Their use addresses nu-merous limitations of prior DA approaches, prior-itizing effectiveness and accessibility. However,LLM-generated data may be of dubious quality(Guerreiro et al., 2023). To preserve the qualityand diversity of data augmented using LLMs, Yeet al. (2024) proposed LLM-DA, evaluating it in anamed entity recognition setting and augmentingdata at both the context and entity levels to alignwith characteristics inherent to the task. Ghorbaniand Zou (2019) proposed DATA SHAPLEY in the biomedical text and image classification domains,generating data and evaluating its training utilityfor the target task. Likewise, Lin et al. (2023) in-troduced selective in-context data augmentation,evaluating synthetic examples before training anintent detection model. We adopt the selective dataaugmentation strategy for our work, leveraging thegenerative power of LLMs to address data scarcitywhile evaluating and selecting the most valuableexamples to augment the training data to ensure sus-tained data quality. In contrast to Lin et al. (2023)swork, we frame data augmentation as a paraphras-ing task with various prompts, described in 4.1.",
  "Data Collection": "We identified and combined common data elementsacross three diverse datasets from prior studies. Par-ticipant demographics for each data source are pro-vided in Appendix A. We also sourced stylistically-relevant non-strategies to aid in classification. Wecomplied with existing institutional review board(IRB) protocols in accessing all data, and ensuredthat our acquisition of non-strategies data was con-sistent with platform-specific terms and conditions. Strategies Dataset A.These data come from across-sectional study establishing the Young Chil-drens PEM (YC-PEM) psychometric properties(Khetani et al., 2015). Eligible caregivers (n=395):1) could read and write English; 2) resided in theUnited States or Canada; 3) identified as parentsor legal guardians 18+ years old; 4) had a child be-tween 0-5 years old; and 5) had Internet access. Atotal of 93 caregivers of children with developmen-tal disabilities and delays and accessing rehabilita-tion services (in the hospital, home, and/or commu-nity) are represented in the combined dataset. Strategies Dataset B.These data come from atrial testing the preliminary effectiveness and im-plementation of the YC-PEM when paired witha program-specific decision support tool (Kaelinet al., 2022a; Khetani et al., 2023; Rizk et al., 2023).Eligible caregivers (n=76): 1) were at least 18 yearsof age; 2) identified as the parent or legal guardianof the child already enrolled in early intervention(EI) services at home and in the community; 3)had oral and written proficiency in English; 4) hadInternet and phone access; 5) cared for a child 0-3years old who had received EI for at least 3 months.A total of 39 caregivers assigned to the intervention",
  "group are included in the combined dataset": "Strategies Dataset C.These data come from aprospective cohort study of children surviving criti-cal illness (Choong et al., 2018; Jarvis et al., 2019;Khetani et al., 2018). Eligible caregivers (n=180)had children that were: 1) between ages 1-17 yearsold, and 2) had been admitted to the pediatric in-tensive care unit for at least 48 hours. A total of53 caregivers with children aged 0-4 years old whothus completed the YC-PEM at study enrollmentand 3 and 6 months post-discharge are included inthe combined dataset. Non-Strategies Data.These data come fromfour public health forums (Patient.Info,1 Mother-ing,2 DC Urban Moms and Dads,3 and Netmums4).Eligible caregivers (n=1002): 1) had a child be-tween 0-5 years old, and 2) had a child with adiagnosis or health issue. Data entries includeddescriptions of the childs behavior (e.g., eats andplays well like his normal self), questions (e.g.,Anyone else had this experience with a child?),and caregiver-reported feelings about the childshealth (e.g., I am concerned).",
  "Data Annotation": "The diversified dataset includes 3,062 caregiverstrategies. Two research team members (one maleand one female undergraduate at a large, diverseuniversity in an urban environment) independentlyannotated 50-250 strategies per week, using thesame pediatric rehabilitation categories adopted by Valizadeh et al. (2024), from March-August2023.Annotators were paid $15.20 per hour.They met with a third annotator and research teammember (a PhD-holding occupational therapist andre/habilitation scientist) to settle discrepancies bymajority rule, seeking feedback from other key in-formants (project leads who direct rehabilitationscience and natural language processing researchlabs) as needed. Data instances not meeting labelcriteria were categorized as non-strategies.We calculated inter-annotator agreement usingpercent agreement and Cohens kappa (Cohen,1960), and report per-class agreement statistics aswell as inter-annotator agreement across broadercategorizations of the data in . In AppendixB, we present examples of strategies from eachclass, with the Pediatric Habilitation Context cor-responding to samples from the data sources A andB, and the Pediatric Rehabilitation Context corre-sponding to examples from data source C.",
  "Unique Qualities of the Dataset": "The combined dataset5 (n=3,062) is much largerthan the original CareCorpus (n=780), with strate-gies spanning: 1) more diverse rehabilitation ser-vice contexts; and 2) the full early childhood period.We sourced our strategies from caregivers whosechildren were accessing pediatric rehabilitation ser-vices across the clinic to community care contin-uum, whereas prior work targeted children solelyaccessing community-based early intervention ser-vices. This more diverse range of service contextsaffords for assessing performance in ways that canguide more varied downstream applications.Similarly, since young children benefit frompersonalized rehabilitation service design throughtheir preschool and kindergarten years, the ex-panded age range (0-5 years versus the previ-ous 0-3 years) lends itself to application acrossa more comprehensive early childhood period. Fi-nally, the non-strategies data responds to limita-tions in CareCorpuss class balance (Valizadehet al., 2024). We visualize the semantic diversity ofthe extended dataset in , comparing vectorspace representations of strategies from the originalCareCorpus (CC), our new extended CareCorpus(CC+), CareCorpus+ with additional non-strategies(CC+NS), and CareCorpus+ with synthetically aug-mented data (described further in 4). In all cases,",
  "Prompt-Based Strategy Generation": "To investigate the feasibility of synthetic datasetexpansion for this task domain, we leveragedthe open-source Flan-t5-xl (Chung et al., 2022),a 3B-parameter autoregressive encoderdecoderLLM. This model is lightweight and has previ-ously proven reliable for zero- or few-shot textgeneration tasks (Chung et al., 2022; Sterner et al.,2024), as well as for query reformulation tasks (Moet al., 2023).6 Its lightweight nature makes it well-suited for environments that are not expected tohave substantial compute resources, such as occu-pational therapy settings. We did not fine-tune themodel for the rephrasing task, but rather focusedon prompting methods that rely on the models ex- 6We use the encoder-decoder based model only to generatesynthetic data, and then use the augmented dataset is used totrain downstream classification models, allowing us to lever-age the power of PLMs while preserving the independence ofthe strategy classification model design.",
  "Please generate rewrite of the abovestrategy keeping the style similar.Find out whats going on when it comes tofamily activities and restaurants thatare kid friendly": ": Examples of the prompts used to generatesynthetic examples. The strategy class is in black boldtext, whereas the broader activity type and environmentsettings related to the strategy are in violet and orangebold text in prompt templates (b) and (c), respectively.Completions by the language model are in green. isting knowledge and understanding to produce de-sired outputs. Likewise, rather than fine-tuning fornoise reduction, we leveraged a filtering technique(described further in 4.2) to mitigate the impact ofnonsense strategies generated by the model. Thesechoices also felt more computationally viable foran occupational therapy setting. We framed strategy augmentation as a paraphras-ing task. For each strategy class, we created threeversions of a natural language prompt, with dif-ferent versions including (a) the class name, (b)the class name and broader activity context, and(c) the class name and setting. The broader ac-tivity context and setting were additional meta-data values stored in our CC+ dataset. Broaderactivity contexts were drawn from {chore, social-izing, outing, classes and groups, basic care rou-tine, recreational, educational, play}, and settingswere one of three environments: {community, day- care/preschool, home}.Each of these versions was followed by an exam-ple from the training set, and then an instruction torewrite the given example. We show the three dif-ferent prompt versions for the strategy class Envi-ronment/Context in . For each input strategy,we generated nine synthetic outputs using theseprompt templates with varying temperature valuesof {0.8, 0.9, 1.0}. We adopted random samplingwith the repetition penalty set to 1.1 (Keskar et al.,2019). We also set the maximum output sequencelength to 276, which was the maximum length ofany strategy in the training set.",
  "PVI Filtering": "Given the diversity of our samples coupled with adiversity-oriented stochastic sampling generationstrategy, we expected that some generated strate-gies would not match the desired strategy class.To filter for synthetic strategies anticipated to havehigh downstream task utility, we adopted the In-Context Data Augmentation with PVI Filtering al-gorithm (Lin et al., 2023). We retained syntheticstrategies deemed relevant based on their PointwiseV-Information (PVI) (Ethayarajh et al., 2022). ThePVI of an input x with label y is calculated usingpredictive V-entropy g = HV(Y ) and conditionalV-entropy g = HV(Y |X), with X and Y beingrandom variables and V a predictive model family:",
  "(1)": "PVI was originally proposed as a mechanism forunderstanding dataset difficulty: it measures theamount of information that x provides to the clas-sification model for learning y, compared to theabsence of that input. High PVI suggests high in-formation content, whereas low PVI suggests thatthe information gain is unlikely to be useful forlearning the target class (Ethayarajh et al., 2022).Following Lin et al. (2023), we set a PVI threshold for each strategy class, where was the averagePVI for the given strategy class in the validationset. Using these thresholds, our PVI filtering stepdiscarded 11, 397 of the 15, 873 synthetically gen-erated strategies.",
  "(2024): logistic regression (Lee et al., 2006), naveBayes (Joyce, 2003), BERT (Devlin et al., 2019),and Bio-ClinicalBERT (Alsentzer et al., 2019).7": "We represented strategies in statistical models usingTF-IDF vectors with a vocabulary size of the 5000most-frequent words in our dataset (Zhang et al.,2011). For BERT and Bio-ClinicalBERT, we usedembeddings generated by the models input layer.We classified caregiver strategies across our fullfive-class data distribution, and set a baseline per-formance floor by predicting the most frequentclass from the training set for each instance. Fol-lowing precedent from earlier work, we also usedour best-performing model to assess performancefor the pipelined strategy/non-strategy (S/NS) andextrinsic/intrinsic strategy (ES/IS) classificationtasks introduced by Valizadeh et al. (2024). Thesetasks predict broader categorizations of the data,with S/NS classification being a useful filteringstep for some downstream applications and ES/ISclassification reframing the strategy divisions alongmore general rehabilitation constructs. In motivat-ing inclusion of these additional dataset divisions,we note that extracting and standardizing contentfrom free text for clinical use is important on amore (i.e., in the finer-grained classes EC, SOS, P,and AC) as well as less (i.e., the more simplifiedclasses ES and IS) level. Automated distinction atthe ES/IS level may empower clinicians to start dif-ferentiating between more specific strategy types,facilitating decision-making without the need forfiner-grained precision Valizadeh et al. (2024).",
  "Experimental Setup": "We split the CC+ corpus into 90:10 train:testsets. For experiments with statistical models, weoptimized model parameters via 10-fold cross-validation on the training set (Refaeilzadeh et al.,2009). For experiments with pre-trained languagemodels (BERT and Bio-ClinicalBERT) we furthersubdivided the training set into a training and vali-dation set, resulting in an 80% training, 10% val-idation, and 10% test split. In these cases, thevalidation set was used during fine-tuning for hy-perparameter optimization. The held-out test setremained consistent across all conditions. 7We note that while it is likely that higher performance mayhave been achieved with more targeted focus on classificationmodel design and selection, our emphasis in this work was oninvestigating the impact of manual and synthetic expansionof data in this highly specialized setting; maintaining modelconsistency with contemporary relevant work allowed us tocontrol more fully for our variables of interest. In the CC+NS and CC+Aug conditions, the train-ing data was augmented with the non-strategy datadescribed earlier (CC+NS), as well as with syn-thetically generated data (CC+Aug).However,the validation and test data was never augmented,meaning that we used the same CC+ test set (withno augmented data present) for all conditions. Toavoid potential training biases, we kept all strate-gies authored by the same caregiver in the samedata split for all models. We trained BERT andBio-ClinicalBERT using a learning rate of 2e-6 andbatch size of 16, for 10 epochs. All models weretrained and evaluated using one NVIDIA TeslaV100 GPU with 32 GB of memory.We compared strategy classification perfor-mance when training models on the originalCareCorpus (CC), our manually expanded datasetwithout additional non-strategies (CC+), our manu-ally expanded dataset with non-strategies sourcedfrom online forums (CC+NS), and our manuallyexpanded dataset with synthetically augmenteddata (CC+Aug). For CC+NS, we under-sampledthe non-strategy class (retaining 30% of non-strategies from online forums) due to its compara-tively high frequency. We also used class weightsto penalize minority class misclassification.",
  "Results": "We report our results in . Results using CCare reported directly from Valizadeh et al. (2024)spaper. Results for BERT and Bio-ClinicalBERTmodels are averaged across three runs with dif-ferent random seeds, with standard deviations in-cluded in parentheses. We observe a trend of in-creased performance with added non-strategy datafrom online forums (CC+NS), as well as with aug-mented data (CC+Aug). Performance improve-ments for CC+ over CC are inconsistent, withimprovements observed using logistic regression(F1=0.57 versus F1=0.46) and Bio-ClinicalBERT(F1=0.44 versus F1=0.39) but not for nave Bayesor BERT. This is unsurprising, given the intentionalincreased diversity of strategy samples in CC+. Wenearly uniformly observe the highest performanceusing a fine-tuned BERT model, successfully repli-cating findings from Valizadeh et al. (2024). Ouroverall highest-performing model is BERT fine-tuned using CC+Aug, achieving F1=0.80.We also report five-class strategy classificationperformance with varying numbers of training in-stances from the CC+Aug dataset in . Weobserve the best performance in both accuracy and",
  ": Performance in a five-class setting. Acc. = accu-racy (%), P = precision, R = recall, LR = logistic regres-sion, NB = nave Bayes, and Bio = Bio-ClinicalBERT": "F1 with a training set size of n = 6799; as men-tioned earlier, the PVI filtering threshold was op-timized for each strategy class using the valida-tion set (see for example PVI values cor-responding to different synthetic samples). Opti-mized thresholds thus varied with varying trainingset sizes. When we selected the training instancesbased on threshold set to the average PVI value(across the strategy class) on the validation set,which increases the training set size to n = 9773,the performance dropped. This presents additionalevidence supporting the efficacy of per class PVIfiltering of synthetically generated instances in thedownstream strategy classification task.In , we report results under these sameconditions for the pipelined S/NS and ES/IS clas-sification settings. We compare these conditionsonly using BERT, following our findings from Ta-ble 3. We do not report ES/IS classification re-",
  ": Five-class strategy classification performancewith the varying number of training instances (n) fromthe CC+Aug dataset using the fine-tuned BERT model": "sults for CC+NS, since ES/IS classification pre-dicts divisions only between strategy data (lead-ing to unchanged training conditions from CC+).We observe similar trends to those observed in theall-class setting for the S/NS setting, with equiva-lent performance when training on CC+ versus CCand increased performance when training on bothCC+NS (F1=0.93) and CC+Aug (F1=0.89). We ob-serve a dramatic performance increase in the ES/ISclassification setting when training on CC+ versusCC (F1=0.83 versus F1=0.53), and greater perfor-mance still when training on CC+Aug (F1=0.91).",
  "Error Analyses": "We systematically analyzed errors to identify ar-eas for improvement. We (a) studied syntheticexamples in the context of their PVI, calculated asdescribed in 4.2; and (b) examined misclassifica-tions from our best-performing model in .We provide prototypical samples from each analy-sis in Tables 5 and 6. shows manually authored strategies andcorresponding strategies that were generated whenthese manual strategies were used as demonstra-",
  ": Model comparison for pipelined classificationtasks, using the same metrics as in . All condi-tions use a fine-tuned BERT model": "tions during data augmentation, paired with thecalculated PVI for the generated strategy. We show-case both high-PVI and low-PVI examples, withlow PVIs emphasized in red.8 Broadly speaking,we observed that high-PVI samples tended to varythe writing style while adhering closely to the con-tent conveyed in the demonstration; often this wasbecause the demonstration was straightforward toprocess (e.g., Encourage to help tidy and put awayprior to moving to another activity Encouragethem to help with the chores ahead of time). Low-PVI examples typically demonstrated a lack of un-derstanding of the source content, either for un-known reasons (e.g., Save money to hire a babysit-ter for parent night out Kidnappers are better atstaying up late) or due to noise or other complex-ities in the demonstration (e.g., It takes 2 to talk-??? Program for speech therapy Talking is avery relaxing way to relax). shows mispredictions with their actualand predicted labels. We find that non-strategies us-ing caregiving language are often misclassified asbelonging to strategy classes. Although these cases(e.g., Teachers are knowledgeable about my childsneeds + abilities) do not include specific strategycontent, their style is close to that observed in ac-tual strategies. Non-strategies using caregiving lan-guage are a minority; more common non-strategiesin CC and CC+ are N/A and None. Future classifica-",
  "Maximum PVI among our synthetic examples is 1.701,and minimum PVI is -2.417": "tion approaches that more closely target underlyingintent or actionable language may be able to ad-dress challenging non-strategies. This could alsoallow for better capture of atypically worded actualstrategies, which are sometimes missed with ourcurrent models (e.g., If it is a sequence of events wewill try and go back to where a step was missed).",
  "Discussion": "Our findings broadly support the premise that di-verse data can be leveraged for specialized pediatricrehabilitation contexts, justifying our manual datacuration and our investigation of synthetic data ex-pansion within this domain. It also replicates find-ings from Valizadeh et al. (2024) across a broaderage range and rehabilitation care continuum; giventhe heterogeneity of pediatric rehabilitation, thesefindings encourage the application of automatedstrategy classification for this use case. Perfor-mance continues to improve with the addition ofnon-strategy data harvested from publicly availableonline forums pertaining to child health, suggestingan accessible avenue for increasing performance.Useful applications of this may include initiatingcaregiver education when detecting non-strategyresponses during PEM completion (Villegas et al.,2023), enabling skilled engagement for familieson waitlists to access rehabilitation services (Mc-Manus et al., 2019).Importantly, we also find that prompt-based syn-thetic data expansion improves model performance.As LLMs are nascent in rehabilitation (Bonnechre,2024), this establishes evidence that LLMs arecapable of adequately replicating user-generatedcontent in this domain, to an extent that it im-proves model performance when used as a trainingsource. It also raises intriguing questions for fu-ture work, such as whether LLMs could be usedto consolidate strategies of the same type. Thiscould address known barriers to family-centeredgoal-setting practice (Crawford et al., 2022). Itcould also decrease caregiver burden when search-ing through a large bank of user-generated strate-gies, such as that in the PEM-Plus goal settingapplication, sustaining longer-term feasibility ofuser-driven strategy exchange. Despite promisingtechnical merit and potential clinical utility, thereare ethical considerations to synthetic data expan-sion, such as its potential to compromise familyvoice (Newman-Griffis et al., 2022b). This presentsa ripe opportunity for further study.",
  "Conclusion": "In this work, we introduced an expanded dataset(n=3,062, an approximately five-fold increase overprior work) of caregiver strategies in diverse pedi-atric rehabilitation contexts. The strategies wereidentified from prior pediatric rehabilitation stud-ies and manually assigned to clinically-establishedconstructs by trained researchers spanning a rig-orous five-month annotation process, resulting instrong agreement (=0.680.89). We also identi-fied non-strategies from publicly available online child health forums to supplement the data andaddress previously-identified class balance issues(Valizadeh et al., 2024).Additionally, we proposed a new technique forsynthetic data augmentation in this domain, guidedby three diverse prompts leveraging task-relevantcontextual information while filtering for syntheticstrategies with high anticipated task utility. Wedemonstrated the value of the additional manuallycurated strategies, publicly available task-relevantnon-strategies, and our novel data augmentationapproach for the downstream task of caregiverstrategy classification. Our results establish evi-dence that both publicly available non-strategies(F1=0.65, a 22.6% relative increase over the use ofCC+ alone) and prompting-based synthetic strate-gies (F1=0.80, a 50.9% relative increase) can sup-port impressive performance gains in this highlyspecialized and under-resourced domain.",
  "This work is limited by two factors. First, we cu-rated a larger, more diverse, and more balanceddataset relative to prior work, but implementa-tion of PEM as a candidate common data ele-": "ment into data capture systems across diverse pe-diatric rehabilitation contexts is both possible andneeded (Schiariti et al., 2018; Pinto et al., 2022)to further overcome data scarcity and homogene-ity when examining generalizability in the longer-term. Second, our dataset is limited to English-language strategies. It remains unclear whetherthe results can be reproduced in less-resourced lan-guages. Culturally adapted versions of PEM doexist (Krieger et al., 2020; Tomas et al., 2022), al-though they have been the subject of less researchto date. We are committed to extending this workto additional data sources derived from use of cul-turally adapted PEM version(s) as permitted.",
  "Ethical Considerations": "A guiding motivation of our work is to enable moreequitable support for caregivers of children withdiverse rehabilitation needs. In pursuing this goal,we have been cognizant of the intersectional biasespresent in the contemporary pediatric rehabilita-tion community, along dimensions including race,ethnicity, and socioeconomic status. We report de-mographic items pertaining to these factors for ourdata sources in , to the extent that they areavailable and recognizing that education level is animperfect proxy for socioeconomic status.We intend for our caregiver strategy classifi-cation and strategy augmentation approaches tobe deployed for the specific uses outlined in 6.Specifically, classification of caregiver strategiescan reduce burden for caregivers searching throughpublic strategy banks and enable educational oppor-tunities regarding strategy development. Strategyaugmentation can foster improved strategy classifi-cation, as established in Tables 3 and 4. A risk ofstrategy augmentation is that it holds potential todiminish family voice, although we note that in ourwork generated strategies are not provided to usersnor used in any way to recommend strategy quality.We urge future research studying strategy augmen-tation in other pediatric rehabilitation contexts toexamine this ethical consideration further.Our dataset will be distributed under the licens-ing terms of the source datasets and in ways thatare consistent with our prior work. CareCorpus(Valizadeh et al., 2024) was made available in theInter-university Consortium for Political and So-cial Research (ICPSR) portal (Kaelin et al., 2023b).ICPSR requests IRB approval for researchers toaccess this additional linked dataset to ensure re- search done with this dataset aligns with ethicalregulations and principles.Similarly, the CareCorpus+ dataset is comprisedof deidentified strategies data from sources A(Khetani et al., 2015), B (Kaelin et al., 2022a;Khetani et al., 2023; Rizk et al., 2023), and C(Choong et al., 2018; Jarvis et al., 2019; Khetaniet al., 2018), and ethics approval was obtainedprior to participant recruitment, each participantprovided consent for study participation and wasinformed about their rights to withdraw their par-ticipation at any time, and in most cases were com-pensated with a gift card. Our use of these existingartifacts was consistent with their intended use,as specified in those source publications. Dataare anonymized and available upon author re-quest, provided that existing institutional reviewboard approval is provided and protocol is fol-lowed. Manually-curated non-strategy data is pub-licly available following the terms and conditionsof the web sources from which it was downloaded.We provide a link to a publicly available repos-itory to facilitate straightforward acquisition ofdata, as well as source code to replicate our ex-periments, under a Creative Commons Attribution-NonCommercial 4.0 International license. Deriva-tives of our work accessed for research purposesshould not be deployed for purposes other than asa research prototype. To foster reproducibility, wereport our experimental setup, relevant statisticsfor running, and hyperparameters in 5. We reportmeans and standard deviations in Tables 3 and 4for BERT and Bio-ClinicalBERT, averaging resultsacross three runs with different random seeds.",
  "Acknowledgements": "Data for this study were collected with fund-ing from the National Institutes of Health (NIHgrant number 1K12 HD055931; PI: M. Khetani),Academic Health Sciences AFP Innovation Fund(PI: K. Choong, Collaborator: M. Khetani), andthe American Occupational Therapy Foundation(AOTF grant number AOTFIR20KHETANI; PI: M.Khetani). Analyses of these data were supported bythe National Science Foundation (award #2125411;PIs: N. Parde, M. Khetani, J. Dooling-Litfin). Thecontent is the responsibility of the authors and doesnot necessarily represent the official views of thesefunding agencies. We thank Shayan Rasheed atUniversity of Illinois Chicago for assisting withdata annotation. Emily Alsentzer, John Murphy, William Boag, Wei-Hung Weng, Di Jindi, Tristan Naumann, andMatthew McDermott. 2019. Publicly available clin-ical BERT embeddings. In Proceedings of the 2ndClinical Natural Language Processing Workshop,pages 7278, Minneapolis, Minnesota, USA. Associ-ation for Computational Linguistics. Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich,Amir Kantor, George Kour, Segev Shlomov, NaamaTepper, and Naama Zwerdling. 2020. Do not haveenough data? deep learning to the rescue! Proceed-ings of the AAAI Conference on Artificial Intelligence,34(05):73837390.",
  "Bruno Bonnechre. 2024. Unlocking the black box? acomprehensive exploration of large language mod-els in rehabilitation. American Journal of PhysicalMedicine & Rehabilitation, pages 101097": "Samuel R. Bowman, Luke Vilnis, Oriol Vinyals, An-drew Dai, Rafal Jozefowicz, and Samy Bengio. 2016.Generating sentences from a continuous space. InProceedings of the 20th SIGNLL Conference on Com-putational Natural Language Learning, pages 1021,Berlin, Germany. Association for Computational Lin-guistics. Karen Choong, Samah Al-Harbi, Asm Borham, JillCameron, Saoirse Cameron, Ji (Emmy) Cheng,Heather Clark, Tim Doherty, Nora Fayed, Jan WillemGorter, Margaret Herridge, Mary Khetani, KusumMenon, Jamie Seabrook, Racquel Simpson, andLehana Thabane. 2018. Functional recovery in criti-cally ill children, the \"weecover\" multicenter study.Pediatric Critical Care Medicine, 19:145154. Arodami Chorianopoulou, Efthymios Tzinis, Elias Iosif,Asimenia Papoulidi, Christina Papailiou, and Alexan-dros Potamianos. 2017. Engagement detection forchildren with autism spectrum disorder.In 2017IEEE International Conference on Acoustics, Speechand Signal Processing (ICASSP), pages 50555059,New Orleans, USA. IEEE. Hyung Won Chung, Le Hou, Shayne Longpre, BarretZoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang,Mostafa Dehghani, Siddhartha Brahma, Albert Web-son, Shixiang Shane Gu, Zhuyun Dai, Mirac Suz-gun, Xinyun Chen, Aakanksha Chowdhery, SharanNarang, Gaurav Mishra, Adams Yu, Vincent Zhao,Yanping Huang, Andrew Dai, Hongkun Yu, SlavPetrov, Ed H. Chi, Jeff Dean, Jacob Devlin, AdamRoberts, Denny Zhou, Quoc V. Le, and Jason Wei.2022. Scaling instruction-finetuned language models.arXiv preprint.",
  "Wendy Coster and Mary Alunkal Khetani. 2008. Mea-suring participation of children with disabilities: Is-sues and challenges. Disability and rehabilitation,30(8):639648": "L Crawford, J Maxwell, H Colquhoun, S Kingsnorth,D Fehlings, S Zarshenas, S McFarland, and NoraFayed. 2022.Facilitators and barriers to patient-centred goal-setting in rehabilitation: a scoping re-view. Clinical Rehabilitation, 36(12):16941704. Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. BERT: Pre-training ofdeep bidirectional transformers for language under-standing. In Proceedings of the 2019 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, Volume 1 (Long and Short Papers), pages41714186, Minneapolis, Minnesota. Association forComputational Linguistics. Sergey Edunov, Myle Ott, Michael Auli, and DavidGrangier. 2018. Understanding back-translation atscale. In Proceedings of the 2018 Conference onEmpirical Methods in Natural Language Processing,pages 489500, Brussels, Belgium. Association forComputational Linguistics. KawinEthayarajh,YejinChoi,andSwabhaSwayamdipta.2022.Understandingdatasetdifficulty with V-usable information. In Proceedingsof the 39th International Conference on MachineLearning, volume 162 of Proceedings of MachineLearning Research, pages 59886008. PMLR.",
  "James Joyce. 2003. Bayes theorem. In The StanfordEncyclopedia of Philosophy (Fall 2021 Edition). TheMetaphysics Research Lab, Philosophy Department,Stanford University": "Vera Kaelin, Vivian Villegas, Yi-Fan Chen, NatalieMurphy, Elizabeth Papautsky, Jodi Litfin, NatalieLeland, Varun Maheshwari, Beth McManus, andMary Khetani. 2022a.Effectiveness and scala-bility of an electronic patient-reported outcomemeasure and decision support tool for family-centred and participation-focused early intervention:PROSPECT hybrid type 1 trial protocol. BMJ open,12(1):e051582. Vera C. Kaelin, Dianna L. Bosak, Shivani Saluja, De-nis Newman-Griffis, Andrew D. Boyd, and Mary A.Khetani. 2024. Representation of child and youthparticipation within the unified medical language sys-tem (umls). Disability and Rehabilitation, 0(0):16.PMID: 38596871. Vera C. Kaelin, Andrew D. Boyd, Martha M. Werler,Natalie Parde, and Mary A. Khetani. 2023. Naturallanguage processing to classify caregiver strategiessupporting participation among children and youthwith craniofacial microsomia and other childhood-onset disabilities. Journal of Healthcare InformaticsResearch, 7(4):480500. Vera C. Kaelin, Mina Valizadeh, Zurisadai Salgado,Julia G. Sim, Dana Anaby, Andrew D. Boyd, Na-talie Parde, and Mary A. Khetani. 2022b. Captur-ing and operationalizing participation in pediatricre/habilitation research using artificial intelligence:A scoping review. Frontiers in Rehabilitation Sci-ences, 3.",
  "Nitish Shirish Keskar, Bryan McCann, Lav Varsh-ney, Caiming Xiong, and Richard Socher. 2019.CTRL - A Conditional Transformer LanguageModel for Controllable Generation. arXiv preprintarXiv:1909.05858": "M.A. Khetani, V. Kaelin, S. Rizk, M. Angulo, Z. Sal-gado, Y.F. Chen, V. Villegas, J. Dooling-Litfin, N. Le-land, E. Lerner Papautsky, N. Murphy, B. McManus,and High Value Early Intervention Research Group.2023.Preliminary effectiveness of an electronicpatient-reported outcome measure and decision sup-port tool on early intervention service quality. Devel-opmental Medicine & Child Neurology, 65(S3):587. Mary Khetani, Erin Albrecht, Jessica Jarvis, DavidPogorzelski, Ji (Emmy) Cheng, and Karen Choong.2018. Determinants of change in home participa-tion among critically ill children. DevelopmentalMedicine & Child Neurology, 60. Mary A. Khetani, James E. Graham, Patricia L. Davies,Mary C. Law, and Rune J. Simeonsson. 2015. Psy-chometric properties of the young childrens partici-pation and environment measure. Archives of Physi-cal Medicine and Rehabilitation, 96(2):307316. Sosuke Kobayashi. 2018. Contextual augmentation:Data augmentation by words with paradigmatic re-lations. In Proceedings of the 2018 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, Volume 2 (Short Papers), pages 452457,New Orleans, Louisiana. Association for Computa-tional Linguistics. Beate Krieger, Christina Schulze, Jillian Boyd, RuthAmann, Barbara Pikur, Anna Beurskens, RachelTeplicky, and Albine Moser. 2020. Cross-culturaladaptation of the participation and environment mea-sure for children and youth (pem-cy) into german: aqualitative study in three countries. BMC Pediatrics,20(1):492.",
  "Su-In Lee, Honglak Lee, Pieter Abbeel, and Andrew Y.Ng. 2006. Efficient l 1 regularized logistic regres-sion. In AAAI, volume 6, pages 401408, Boston,USA": "Yen-Ting Lin, Alexandros Papangelis, Seokhwan Kim,Sungjin Lee, Devamanyu Hazarika, Mahdi Namazi-far, Di Jin, Yang Liu, and Dilek Hakkani-Tur. 2023.Selective in-context data augmentation for intent de-tection using pointwise V-information. In Proceed-ings of the 17th Conference of the European Chap-ter of the Association for Computational Linguistics,pages 14631476, Dubrovnik, Croatia. Associationfor Computational Linguistics. D. Magnusson and M.A. Khetani. 2022. Early interven-tion. In Heidi M Feldman, Ellen Roy Elias, Nathan JBlum, Manuel Jimenez, and Terry Stancin, editors,Developmental and Behavioral Pediatrics. Elsevier. Beth M. McManus, Zachary Richardson, MargaretSchenkman, Natalie Murphy, and Elaine H. Mor-rato. 2019. Timing and Intensity of Early Interven-tion Service Use and Outcomes Among a Safety-Net Population of Children. JAMA Network Open,2(1):e187529e187529. Fengran Mo, Kelong Mao, Yutao Zhu, Yihong Wu,Kaiyu Huang, and Jian-Yun Nie. 2023. ConvGQR:Generative query reformulation for conversationalsearch. In Proceedings of the 61st Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 1: Long Papers), pages 49985012, Toronto,Canada. Association for Computational Linguistics.",
  "free text documentation of functioning and disabilityto the icf with natural language processing. Frontiersin Rehabilitation Sciences, 2:117": "Denis R. Newman-Griffis, Max B. Hurwitz, Gina P.McKernan, Amy J. Houtrow, and Brad E. Dicianno.2022a. A roadmap to reduce information inequitiesin disability with digital health and natural languageprocessing. PLOS Digital Health, 1(11):119. Denis R Newman-Griffis, Max B Hurwitz, Gina P McK-ernan, Amy J Houtrow, and Brad E Dicianno. 2022b.A roadmap to reduce information inequities in dis-ability with digital health and natural language pro-cessing. PLOS Digital Health, 1(11):e0000135.",
  "Eda Okur, Saurav Sahay, and Lama Nachman. 2022": "Data augmentation with paraphrase generation andentity extraction for multimodal dialogue system. InProceedings of the Thirteenth Language Resourcesand Evaluation Conference, pages 41144125, Mar-seille, France. European Language Resources Asso-ciation. Bolajoko O Olusanya, Adrian C Davis, Donald Wertlieb,Nem-Yun Boo, MKC Nair, Ricardo Halpern, HannahKuper, Cecilia Breinbauer, Petrus J De Vries, MelissaGladstone, et al. 2018. Developmental disabilitiesamong children younger than 5 years in 195 countriesand territories, 19902016: a systematic analysis forthe global burden of disease study 2016. The LancetGlobal Health, 6(10):e1100e1121. Bolajoko O Olusanya,Scott M Wright,TraceySmythe, Mary A Khetani, MARISOL MORENO-ANGARITA, Sheffali Gulati, Sally A Brinkman, Ni-had A Almasri, Marta Figueiredo, Lidia B Giudici,et al. 2024. Early childhood development strategyfor the worlds children with disabilities. Frontiersin Public Health, 12:1390107. Alexandros Papangelis, Karthik Gopalakrishnan, Aish-warya Padmakumar, Seokhwan Kim, Gokhan Tur,and Dilek Hakkani-Tur. 2021. Generative conversa-tional networks. In Proceedings of the 22nd AnnualMeeting of the Special Interest Group on Discourseand Dialogue, pages 111120, Singapore and Online.Association for Computational Linguistics. Neethi P Pinto, Aline B Maddux, Leslie A Dervan,Alan G Woodruff, Jessica M Jarvis, Sholeen Nett,Elizabeth Y Killien, Robert J Graham, Karen Choong,Peter M Luckett, et al. 2022. A core outcome mea-surement set for pediatric critical care. PediatricCritical Care Medicine, 23(11):893907. Alec Radford, Jong Wook Kim, Chris Hallacy, AdityaRamesh, Gabriel Goh, Sandhini Agarwal, Girish Sas-try, Amanda Askell, Pamela Mishkin, Jack Clark,Gretchen Krueger, and Ilya Sutskever. 2021. Learn-ing transferable visual models from natural languagesupervision. In Proceedings of the 38th InternationalConference on Machine Learning, volume 139 ofProceedings of Machine Learning Research, pages87488763. PMLR.",
  "Payam Refaeilzadeh, Lei Tang, and Huan Liu. 2009.Cross-validation. Encyclopedia of Database Systems,5:532538": "Sabrin Rizk, Vera C Kaelin, Julia Gabrielle C Sim, Na-talie J Murphy, Beth M McManus, Natalie E Leland,Ashley Stoffel, Lesly James, Kris Barnekow, Eliza-beth Lerner Papautsky, and Mary A Khetani. 2023.Implementing an electronic patient-reported outcomeand decision support tool in early intervention. Ap-plied clinical informatics, 14(1):91107. Gaurav Sahu, Pau Rodriguez, Issam Laradji, ParmidaAtighehchian, David Vazquez, and Dzmitry Bah-danau. 2022. Data augmentation for intent classi-fication with off-the-shelf large language models. InProceedings of the 4th Workshop on NLP for Conver-sational AI, pages 4757, Dublin, Ireland. Associa-tion for Computational Linguistics. Vernica Schiariti, Eileen Fowler, Joline E Brandenburg,Eric Levey, Sarah Mcintyre, Theresa Sukal-Moulton,Sharon L Ramey, Jessica Rose, Susan Sienko, ElaineStashinko, Laura Vogtle, Robin S Feldman, andJames I Koenig. 2018. A common data language forclinical research studies: the national institute of neu-rological disorders and stroke and american academyfor cerebral palsy and developmental medicine cere-bral palsy common data elements version 1.0 rec-ommendations. Developmental Medicine & ChildNeurology, 60(10):976986.",
  "Igor Sterner, Weizhe Lin, Jinghong Chen, and BillByrne. 2024. Few-shot VQA with frozen llms: Atale of two approaches. CoRR, abs/2403.11317": "Vanessa Tomas, Roopa Srinivasan, Vrushali Kulkarni,Rachel Teplicky, Dana Anaby, and Mary Khetani.2022.A guiding process to culturally adapt as-sessments for participation-focused pediatric prac-tice: the case of the participation and environmentmeasures (pem).Disability and Rehabilitation,44(21):64976509. Mina Valizadeh, Vera Kaelin, Mary Khetani, and Na-talie Parde. 2024. Carecorpus: A corpus of real-world solution-focused caregiver strategies for per-sonalized pediatric rehabilitation service design. InProceedings of the 2024 Joint International Confer-ence on Computational Linguistics, Language Re-sources and Evaluation, Turin, Italy. European Lan-guage Resources Association. Vivian C Villegas, Dianna L Bosak, Zurisadai Salgado,Michelle Phoenix, Natalie Parde, Rachel Teplicky,Mary A Khetani, and High Value Early Interven-tion Research Group Kuznicki L. Pedrow A. HowellA. 2023. Diversified caregiver input to upgrade theyoung childrens participation and environment mea-sure for equitable pediatric re/habilitation practice.Journal of Patient-Reported Outcomes, 7(1):87. Jason Wei and Kai Zou. 2019. EDA: Easy data augmen-tation techniques for boosting performance on textclassification tasks. In Proceedings of the 2019 Con-ference on Empirical Methods in Natural Language",
  "AChild and Caregiver Characteristics": "We report relevant demographic characteristics ofthe children and caregivers represented in datasources A, B, and C in . Characteristicsinclude child age, sex, and disability status, as wellas caregiver race, ethnicity, and education level.Mean child age is reported with interquartile rangein parentheses; all other characteristics are reportedas frequencies with percentage in parentheses.",
  "BSample Caregiver Strategies": "We include sample caregiver strategies in . Samples from the Pediatric Habilitation Con-text correspond to data sources A and B. Samplesfrom the Pediatric Rehabilitation Context are fromsource C. We abbreviate strategy types as EC (En-vironment/Context), SOS (Sense of Self), AC (Ac-tivity Competence), and P (Preferences). Whilepediatric rehabilitation focuses on helping childrenredevelop skills they have lost, pediatric habilita-tion focuses on helping them develop new skills.",
  "CharacteristicSource A(n=39)Source B(n=53)Source C(n=93)": "Child Age, M(IQR)2.4 (1.9, 2.6)-3.2 (1.3, 4.6)Child Sex, n (%)Female12 (30.8)25 (44.6)30 (32.3)Male27 (69.2)31 (55.4)63 (67.7)Child Disability Status, n (%)Developmental Delay/At Risk27 (69.2)0 (0.0)41 (44.0)Diagnosed Condition12 (30.8)52 (98.1)52 (55.9) Caregiver Race, n (%)American Indian/Alaskan Native1 (2.6)-0 (0.0)Asian2 (5.13)-7 (7.5)Black or African American6 (15.4)-9 (9.7)White29 (74.4)-77 (82.8)Caregiver Ethnicity, n (%)Latinx9 (24.3)-12 (12.9)Non-Latinx27 (73.0)-81 (87.1)Caregiver Education, n (%)High School Graduate10 (25.6)-7 (0.1)Some College/Technical Training--15 (16.2)Associates Degree2 (5.13)-13 (14.0)College/University Degree10 (25.6)-29 (31.2)Some Graduate Coursework3 (7.69)-6 (0.1)Graduate Degree14 (35.9)-29 (31.2) : Characteristics of the participants in data sources A, B, and C. Developmental Delay/At Risk indicates thatthe child has a developmental delay or is at risk for a developmental delay. Caregiver race, ethnicity, and educationwere not collected for Source 2 since those demographic items are not part of the Canadian standard."
}