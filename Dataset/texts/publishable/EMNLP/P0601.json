{
  "Abstract": "Retrieval-augmented generation (RAG) meth-ods encounter difficulties when addressingcomplex questions like multi-hop queries.While iterative retrieval methods improve per-formance by gathering additional information,current approaches often rely on multiple callsof large language models (LLMs). In this pa-per, we introduce EfficientRAG, an efficientretriever for multi-hop question answering. Ef-ficientRAG iteratively generates new querieswithout the need for LLM calls at each iterationand filters out irrelevant information. Experi-mental results demonstrate that EfficientRAGsurpasses existing RAG methods on three open-domain multi-hop question-answering datasets.The code is available in aka.ms/efficientrag.",
  "Introduction": "Large-language models (LLMs) have shown re-markable performance in numerous applicationsand tasks (OpenAI, 2023; Jiang et al., 2023a; Tou-vron et al., 2023b). However, LLMs lack knowl-edge underrepresented in their training data, es-pecially in domain-specific settings, and still facethe issues of hallucinations (Zhang et al., 2023;Huang et al., 2023; Yang et al., 2023). Retrieval-augmented generation (RAG) techniques (Lewiset al., 2020; Gao et al., 2023) have been widelyadapted to retrieve knowledge from external re-sources to ground the generated responses. Previ-ous RAG methods often adapt one-round retrieval,e.g., only use the user query or question as the inputto retrieve knowledge (Guu et al., 2020; Borgeaudet al., 2022; Izacard et al., 2023; Shi et al., 2023).Such one-round RAG is capable of answering ques-tions which clearly state all the needed informationin the input query (Thorne et al., 2018; Trischleret al., 2017; Rajpurkar et al., 2016), such as one-hop question, e.g., what is Newtons third law",
  "*Equal ContributionWork is done during an internship at MicrosoftCorresponding author": "of motion?. However, one-round RAG methodscould fail in complex questions where more infor-mation is required beyond the first-round retrievedinformation, e.g., multi-hop questions (Yang et al.,2018a; Trivedi et al., 2022a; Ho et al., 2020b). Inorder to deal with complex multi-hop questions, re-cent works propose to obtain required informationthrough multi-round retrievals or reasonings, suchas rewriting or generating queries for the followingmulti-round retrievals (Khattab et al., 2022; Maet al., 2023; Shao et al., 2023; Jiang et al., 2023b),discriminating and correcting internal reasoningprocedures (Gao et al., 2024), interleaving mul-tiple retrieval and reasoning steps (Trivedi et al.,2023), multi-rounds of self-asking (Press et al.,2023). However, such iterative retrieval approacheshave the following limitations: (1) they require mul-tiple LLM calls concerning rewriting or generatingnew queries for the next round of retrieval, thusincreasing the latency and cost. (2) they requirededicated prompting and few-shot examples thatmight need updating across different scenarios.In this paper, we are inspired by the intuitionthat the types of relations in multi-hop questionsare limited, or significantly fewer compared to thenumber of entities. As proved in Zhu et al. (2023)that small models have a certain ability of reason-ing, we propose that identifying relations and theirassociated entities from retrieved information canbe effectively managed by small models instead ofLLMs. Thus, we propose EfficientRAG consists ofa Labeler and a Filter to iteratively generate newqueries for retrieval and in the meanwhile keepthe most relevant retrieved information, enhancingefficiency compared to other RAG methods.",
  "In this section, we conducted an empirical studyto assess how well an LLM-based generator per-": "forms with different levels of retrieved informa-tion. We test on three settings: direct prompt (noretrieved chunks), oracle chunks (oracle chunksas the context), and mixed chunks (both oracleand irrelevant chunks as the context) on threedatasets, i.e., HotpotQA (Yang et al., 2018b),2Wiki-multihop (2WikiMQA) (Ho et al., 2020a)and MuSiQue (Trivedi et al., 2022b). The genera-tor model includes GPT-3.5 (OpenAI, 2022), GPT-4 (OpenAI, 2023) with 1106-preview version, andLlama-3-8B1 (Touvron et al., 2023a). We evaluatethe model answer with accuracy metric by GPT-3.5,the prompt can be found in Appendix B.1. As illus-trated in , retrieval proves beneficial, withboth oracle and mixture settings outperforming thedirect answering approach. Nonetheless, the pres-ence of irrelevant chunks continues to challengethe LLM generator, underscoring the need for moreprecise information retrieval. DirectOracle ChunksMixed Chunks 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0",
  "Retrieve with Query Decomposition": "It is a common practice to use LLMs for query de-composition when facing complex multi-hop ques-tions (Gao et al., 2023). We conduct another em-pirical study to check how query decompositionapproaches impact the retrieval stage. As shownin , the number of oracle chunks retrievedby one-time decomposition (LLM Decompose, de-tailed in ) outperforms the Direct retrievalfor the original query. At a similar number ofchunks, iterative decomposition (EfficientRAG De-compose) achieves higher recall. When retrievingapproximately 20 chunks, the Recall achieved byEfficientRAG Decompose has comparable perfor-mance with the LLM Decompose when retrievingaround 200 chunks, thus demonstrating the effi-ciency of EfficientRAG Decompose. All retriev-ers used the contriever-msmarco (Izacard et al.,2022) setup, with chunk retrievals configured as",
  "EfficientRAG Framework": "In this section, we introduce EfficientRAG , a plug-and-play approach designed to efficiently retrieverelevant information with multiple retrieval roundsto enrich the retrieved information and reduce ir-relevant information, then help improve the qualityand accuracy of answers.EfficientRAG consists of two lightweight com-ponents: the Labeler & Tagger and the Filter. Thesecomponents share the same model structure, withthe Labeler & Tagger2 producing outputs from sep-arate heads within the same model and the filtersoutput comes from another model. Both the La-beler and the Filter function as token-level clas-sifiers, classifying tokens as either true or false. shows that how EfficientRAG fits intotraditional RAG systems. Given a query, the re-triever obtains relevant chunks from the database.Then the labeler module annotates a sequence oftokens in this document representing the useful in-formation that could (partially) answer the query.The tagger module then tags the chunk, indicatingwhether the retrieved chunk is helpful or irrelevant.If the tag indicates there needs more informationto answer the query, i.e., tagged as <Continue>,we will add this chunk to a candidate pool, whichwill be fed to the LLM-based generator to have thefinal answer. Otherwise, if the document is labeleduseless or irrelevant, we stop searching for the suc-cessor branches from this query. The filter moduletakes both the labeled tokens and the current queryto construct a new query for the next round of re-trieval. It is done by replacing the unknown part of",
  "Retriever": "How large is the shoppingmall where KGOT radiostation has its studios? KGOT: KGOT (101.3 FM) is a commercial Top 40 (CHR) radio station in Anchorage, Alaska. The station is owned by iHeartMedia, Inc. and broadcasts (along with its sister stations) from studios in the Dimond Center. <Continue> Chunk #1KGLK: KGLK (107.5 FM) and KHPT (106.9 FM, \\\"Houston's Eagle\\\") is a pair of simulcast classic rock formatted radio stations licensed to serve the communities of Lake Jackson, Texas, and Conroe, Texas, United States, respectively. <Terminate>",
  "Answer": "How large is the shoppingmallwhereKGOTradio station has its studios? : EfficientRAG framework operates within the iterative RAG system. Initially, EfficientRAG retrievesrelevant chunks from the knowledge base, tagging each as either <Terminate> or <Continue>, and annotatespreserved tokens \"KGOT in the Dimond Center\" from the <Continue> chunks. The Filter then processes theconcatenation of the original question and the previously annotated tokens, \"Q: How large is the shopping mallwhere KGOT radio station has its studios? Info: KGOT, in the Dimond Center\", and annotates the next-hop querytokens \"How large is Dimond Center?\". This iterative process continues until all chunks are tagged <Terminate> orthe maximum number of iterations is reached. the query with labeled tokens (useful information).Our approach efficiently generates new queriesfor subsequent retrieval rounds, aiming to retrieveinformation beyond the scope of the initial query.Once our approach gets enough information to an-swer the initial question, it stops and passes allthis information to the final generator to get thefinal response. Leveraging our efficient RAG ap-proach eliminates the need for multiple LLM callsfor query generation, resulting in improved perfor-mance when tackling complex queries.",
  "Synthetic Data Construction": "We utilize LLM to synthesize training data for theLabeler and Filter. The process consists of multi-hop question decomposition, token labeling, next-hop question filtering, and negative sampling. Syn-thetic data is detailed in .Multi-hop question decomposition. Given a multi-hop question and relevant chunks, we first promptthe LLM to decompose the original question intoseveral single-hop questions. Each single-hop ques-tion corresponds to a chunk. Then, we ask the LLMto parse the dependency for the sub-questions.Token Labeling. For each sub-question and cor-responding chunk, we prompt the LLM to labelimportant words in the chunk pertinent to the sub- question answering. We annotate each word in thechunk with a binary label to determine if it is im-portant and should be preserved by EfficientRAGLabeler. We use the SpaCy toolkit3 following Panet al. (2024). Next-hop question filtering. Given a single-hopquestion and the labeled tokens from its dependentquestions, we prompt the LLM to generate a next-hop question, which is ideally the next query forretrieval. We extract the next-hop question tokenssame as the Token Labeling procedure. Negative Sampling. With each filtered next-hopquestion, we retrieve the most similar but not rel-evant chunk as the hard negative chunk. Thesenegative chunks will be tagged <Terminate> whileother relevant chunks are tagged <Continue>.",
  "Training": "We train EfficientRAG Labeler for two tasks, tokenlabeling and chunk filtering, as they both take inthe same input. We use an auto-encoder languagemodel as an encoder to derive embeddings for eachtoken of concatenated sequence query, chunk. Sub-sequently, we use one fully connected layer toproject the token embedding into a 2-dimensionalspace, indicating \"useful token\" and \"useless to-ken\". Another fully connected layer is adapted toproject the average pooling of the sequence em-bedding into a 2-dimensional space, representingthe chunk tag <Continue> and <Terminate>. Wetrain EfficientRAGFilter similarly, while its inputsequence is the concatenation of query and labeledtokens. The Filter extracts words and concatenatesthem to formulate the next-hop query.",
  "End2end QA performance": "We conduct evaluations of our EfficientRAG andmultiple baselines on three multi-hop question-answering datasets same as 2.1. We select thefollowing models as our baselines.First is di-rect answering without retrieval, including LMswith proprietary data. We include direct promptingand Chain-of-Thought prompting (Touvron et al., 2023a) and question decomposition prompting inthis setting. Secondly, we include baselines withnaive RAG with top-10 retrieve chunks as its knowl-edge. Third, we include advanced iterative RAGmethods like Iter-RetGen (Shao et al., 2023) andSelfAsk (Press et al., 2023). The implementationprompts are in Appendix B.3.Implementation Details. EfficientRAG Labelerand Filter are fine-tuned based on DeBERTa-v3-large (He et al., 2021) with 24 layers and 304Mparameters. We adopt Llama-3-8B-Instruct for thequestion-answering stage and all other baselines.We utilize Contriever-MSMARCO (Izacard et al.,2022) as the retriever for both data synthesis andinference stages.We constructed the training data following Sec-tion 3.2 with Llama-3-70B-Instruct (Prompts aredetailed in Appendix B.2). We trained our modelon 4 Nvidia A100 GPUs for about 10 GPU-hoursseparately, with AdamW (Loshchilov and Hutter,2019) optimizer and a learning rate of 5e-6.",
  "The models performance was assessed using theRecall@K metric across three distinct datasets.As presented in , EfficientRAG achieves": "notably high recall scores on HotpotQA and2WikiMQA datasets, with recall values of 81.84and 84.08, respectively.These results are im-pressive considering the minimal number ofchunks retrieved 6.41 for HotpotQA and 3.69 for2WikiMQA. However, the performance of Efficien-tRAG on the MuSiQue dataset was less satisfac-tory. This suboptimal result may be attributed tothe smaller number of chunks retrieved and theincreased complexity of the dataset.We further evaluate the QnA performance on thethree datasets. As is illustrated in , our Effi-cientRAG framework achieves the second-highestaccuracy on both HotpotQA and 2WikiMQA, andit also performs well on MuSiQue even with lowrecall.Those LLM-based systems perform unsatisfyingsince they require LLMs to generate partial answerswith noisy knowledge inputs, but they always fail inthe intermediate steps. We posit that more helpfulknowledge and fewer irrelevant chunks are the keypoints to the RAG system, even a simple model canbeat LLMs with the correct RAG paradigm.",
  "Transferability": "EfficientRAG demonstrates the flexibility to adaptto a variety of task scenarios without the need foradditional downstream training. To evaluate itstransferability, we conduct an experiment acrossthe HotpotQA and 2WikiMQA datasets, trainingthe model on one dataset and testing it on the other.As shown in , our model successfully gener-alizes across datasets and, in some instances, evenoutperforms models trained on the original dataset.These results highlight that EfficientRAG does notdepend heavily on domain-specific knowledge, ex-hibiting robust adaptability across diverse tasks.",
  "Conclusion": "In this study, we introduce the EfficientRAG re-triever, a novel approach for multi-hop question re-trieval that iteratively generates new queries whilecircumventing the need for large language mod-els. Evaluations across three benchmark datasetsdemonstrate that EfficientRAG not only achieveshigh recall with a minimal number of retrievedchunks but also delivers promising outcomes insubsequent question-answering tasks. These find-ings indicate that EfficientRAG outperforms tra-ditional retrieval-augmented generation methods,particularly in the context of complex, multi-hopquestion-answering scenarios.",
  "The authors declare no competing interests. Thedatasets used in the training and evaluation comefrom publicly available sources and do not containsensitive content such as personal information": "Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann,Trevor Cai, Eliza Rutherford, Katie Millican, Georgevan den Driessche, Jean-Baptiste Lespiau, BogdanDamoc, Aidan Clark, Diego de Las Casas, AureliaGuy, Jacob Menick, Roman Ring, Tom Hennigan,Saffron Huang, Loren Maggiore, Chris Jones, AlbinCassirer, Andy Brock, Michela Paganini, GeoffreyIrving, Oriol Vinyals, Simon Osindero, Karen Si-monyan, Jack W. Rae, Erich Elsen, and Laurent Sifre.2022. Improving language models by retrieving fromtrillions of tokens. In International Conference onMachine Learning, ICML 2022, 17-23 July 2022, Bal-timore, Maryland, USA, volume 162 of Proceedingsof Machine Learning Research, pages 22062240.PMLR. Yuan Gao, Yiheng Zhu, Yuanbin Cao, Yinzhi Zhou,Zhen Wu, Yujie Chen, Shenglan Wu, Haoyuan Hu,and Xinyu Dai. 2024. Dr3: Ask large language mod-els not to give off-topic answers in open domainmulti-hop question answering. In Proceedings ofthe 2024 Joint International Conference on Computa-tional Linguistics, Language Resources and Evalua-tion, LREC/COLING 2024, 20-25 May, 2024, Torino,Italy, pages 53505364. ELRA and ICCL. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo,Meng Wang, and Haofen Wang. 2023. Retrieval-augmented generation for large language models: Asurvey. CoRR, abs/2312.10997. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,and Ming-Wei Chang. 2020. Retrieval augmentedlanguage model pre-training. In Proceedings of the37th International Conference on Machine Learning,ICML 2020, 13-18 July 2020, Virtual Event, volume119 of Proceedings of Machine Learning Research,pages 39293938. PMLR.",
  "bert with disentangled attention. In 9th InternationalConference on Learning Representations, ICLR 2021,Virtual Event, Austria, May 3-7, 2021. OpenRe-view.net": "Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara,and Akiko Aizawa. 2020a. Constructing a multi-hop QA dataset for comprehensive evaluation ofreasoning steps. In Proceedings of the 28th Inter-national Conference on Computational Linguistics,pages 66096625, Barcelona, Spain (Online). Inter-national Committee on Computational Linguistics. Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara,and Akiko Aizawa. 2020b. Constructing A multi-hopQA dataset for comprehensive evaluation of reason-ing steps. In Proceedings of the 28th InternationalConference on Computational Linguistics, COLING2020, Barcelona, Spain (Online), December 8-13,2020, pages 66096625. International Committee onComputational Linguistics. Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong,Zhangyin Feng, Haotian Wang, Qianglong Chen,Weihua Peng, Xiaocheng Feng, Bing Qin, and TingLiu. 2023. A survey on hallucination in large lan-guage models: Principles, taxonomy, challenges, andopen questions. CoRR, abs/2311.05232. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Se-bastian Riedel, Piotr Bojanowski, Armand Joulin,and Edouard Grave. 2022. Unsupervised dense in-formation retrieval with contrastive learning. Trans.Mach. Learn. Res., 2022. Gautier Izacard, Patrick S. H. Lewis, Maria Lomeli,Lucas Hosseini, Fabio Petroni, Timo Schick, JaneDwivedi-Yu, Armand Joulin, Sebastian Riedel, andEdouard Grave. 2023.Atlas: Few-shot learningwith retrieval augmented language models. J. Mach.Learn. Res., 24:251:1251:43. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode Las Casas, Florian Bressand, Gianna Lengyel,Guillaume Lample, Lucile Saulnier, Llio Re-nard Lavaud, Marie-Anne Lachaux, Pierre Stock,Teven Le Scao, Thibaut Lavril, Thomas Wang, Timo-the Lacroix, and William El Sayed. 2023a. Mistral7b. CoRR, abs/2310.06825. Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun,Qian Liu, Jane Dwivedi-Yu, Yiming Yang, JamieCallan, and Graham Neubig. 2023b. Active retrievalaugmented generation. In Proceedings of the 2023Conference on Empirical Methods in Natural Lan-guage Processing, EMNLP 2023, Singapore, Decem-ber 6-10, 2023, pages 79697992. Association forComputational Linguistics. Omar Khattab, Keshav Santhanam, Xiang Lisa Li,David Hall, Percy Liang, Christopher Potts, andMatei Zaharia. 2022. Demonstrate-search-predict:Composing retrieval and language models forknowledge-intensive NLP. CoRR, abs/2212.14024. Patrick S. H. Lewis, Ethan Perez, Aleksandra Pik-tus, Fabio Petroni, Vladimir Karpukhin, NamanGoyal, Heinrich Kttler, Mike Lewis, Wen-tau Yih,Tim Rocktschel, Sebastian Riedel, and DouweKiela. 2020.Retrieval-augmented generation forknowledge-intensive NLP tasks. In Advances in Neu-ral Information Processing Systems 33: Annual Con-ference on Neural Information Processing Systems2020, NeurIPS 2020, December 6-12, 2020, virtual. Ilya Loshchilov and Frank Hutter. 2019. Decoupledweight decay regularization. In 7th InternationalConference on Learning Representations, ICLR 2019,New Orleans, LA, USA, May 6-9, 2019. OpenRe-view.net.",
  "OpenAI. 2023.GPT-4 technical report.CoRR,abs/2303.08774": "Zhuoshi Pan, Qianhui Wu, Huiqiang Jiang, Menglin Xia,Xufang Luo, Jue Zhang, Qingwei Lin, Victor Rhle,Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu,and Dongmei Zhang. 2024. Llmlingua-2: Data distil-lation for efficient and faithful task-agnostic promptcompression. CoRR, abs/2403.12968. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt,Noah A. Smith, and Mike Lewis. 2023. Measuringand narrowing the compositionality gap in languagemodels. In Findings of the Association for Compu-tational Linguistics: EMNLP 2023, Singapore, De-cember 6-10, 2023, pages 56875711. Associationfor Computational Linguistics. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, andPercy Liang. 2016.Squad: 100, 000+ questionsfor machine comprehension of text. In Proceedingsof the 2016 Conference on Empirical Methods inNatural Language Processing, EMNLP 2016, Austin,Texas, USA, November 1-4, 2016, pages 23832392.The Association for Computational Linguistics. Zhihong Shao, Yeyun Gong, Yelong Shen, MinlieHuang, Nan Duan, and Weizhu Chen. 2023. En-hancing retrieval-augmented large language modelswith iterative retrieval-generation synergy. In Find-ings of the Association for Computational Linguis-tics: EMNLP 2023, Singapore, December 6-10, 2023,pages 92489274. Association for ComputationalLinguistics.",
  "FEVER: a large-scale dataset for fact extraction": "and verification.In Proceedings of the 2018Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, NAACL-HLT 2018, NewOrleans, Louisiana, USA, June 1-6, 2018, Volume1 (Long Papers), pages 809819. Association forComputational Linguistics. Hugo Touvron, Thibaut Lavril, Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, Aurlien Rodriguez, Armand Joulin, EdouardGrave, and Guillaume Lample. 2023a. Llama: Openand efficient foundation language models. CoRR,abs/2302.13971. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Aurlien Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. 2023b. Llama 2: Open foundation andfine-tuned chat models. CoRR, abs/2307.09288. Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris,Alessandro Sordoni, Philip Bachman, and KaheerSuleman. 2017. Newsqa: A machine comprehensiondataset.In Proceedings of the 2nd Workshop onRepresentation Learning for NLP, Rep4NLP@ACL2017, Vancouver, Canada, August 3, 2017, pages191200. Association for Computational Linguistics.",
  "Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,and Ashish Sabharwal. 2022a.Musique: Multi-hop questions via single-hop question composition.Trans. Assoc. Comput. Linguistics, 10:539554": "Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,and Ashish Sabharwal. 2022b. MuSiQue: Multi-hop questions via single-hop question composition.Transactions of the Association for ComputationalLinguistics. Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,and Ashish Sabharwal. 2023. Interleaving retrievalwith chain-of-thought reasoning for knowledge-intensive multi-step questions. In Proceedings ofthe 61st Annual Meeting of the Association for Com-putational Linguistics (Volume 1: Long Papers),",
  "ACL 2023, Toronto, Canada, July 9-14, 2023, pages1001410037. Association for Computational Lin-guistics": "Fangkai Yang, Pu Zhao, Zezhong Wang, Lu Wang,Bo Qiao, Jue Zhang, Mohit Garg, Qingwei Lin, Sara-van Rajmohan, and Dongmei Zhang. 2023. Empowerlarge language model to perform better on industrialdomain-specific question answering. In Proceedingsof the 2023 Conference on Empirical Methods inNatural Language Processing: EMNLP 2023 - Indus-try Track, Singapore, December 6-10, 2023, pages294312. Association for Computational Linguistics. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-gio, William W. Cohen, Ruslan Salakhutdinov, andChristopher D. Manning. 2018a. Hotpotqa: A datasetfor diverse, explainable multi-hop question answer-ing. In Proceedings of the 2018 Conference on Em-pirical Methods in Natural Language Processing,Brussels, Belgium, October 31 - November 4, 2018,pages 23692380. Association for ComputationalLinguistics. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-gio, William W. Cohen, Ruslan Salakhutdinov, andChristopher D. Manning. 2018b.HotpotQA: Adataset for diverse, explainable multi-hop questionanswering. In Conference on Empirical Methods inNatural Language Processing (EMNLP). Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,Yulong Chen, Longyue Wang, Anh Tuan Luu, WeiBi, Freda Shi, and Shuming Shi. 2023. Sirens songin the AI ocean: A survey on hallucination in largelanguage models. CoRR, abs/2309.01219. Tong Zhu, Junfei Ren, Zijian Yu, Mengsong Wu, Guo-liang Zhang, Xiaoye Qu, Wenliang Chen, ZhefengWang, Baoxing Huai, and Min Zhang. 2023. Mir-ror: A universal framework for various informationextraction tasks. ArXiv:2311.05419 [cs].",
  "B.1Accuracy Evaluation Prompt": "You are an experienced linguist who is responsible forevaluating the correctness of the generated responses.You are provided with question, the generated responsesand the corresponding ground truth answer. Your taskis to compare the generated responses with the groundtruth responses and evaluate the correctness of the gen-erated responses. Response in JSON format with key\"response\" and value \"yes\" or \"no\".Question: {question}Prediction: {prediction}Ground-truth Answer: {answer}Your response:",
  "B.2Data Synthesize Prompt": "Question Decomposition PromptYou are assigned a multi-hop question decomposition task.Your mission is to decompose the original multi-hop question into a list of single-hop sub_questions, based on supportingdocuments for each sub_question, and such that you can answer each sub_question independently from each document.Each document infers a sub_question id which starts with #. The evidence in the document indicates the relation of twoentities, in the form of entity1 - relation - entity2.The JSON output must contain the following keys:- \"question\": a string, the original multi-hop question.- \"decomposed_questions\": a dict of sub_questions and answers. The key should be the sub_question number(stringformat), and each value should be a dict containing:- \"sub_question\": a string, the decomposed single-hop sub_question. It MUST NOT contain information more than theoriginal question and its dependencies. NEVER introduce information from documents.- \"answer\": a string, the answer of the sub_question.- \"dependency\": a list of sub_question number(string format). If the sub_question relies on the answer of othersub_questions, you should list the sub_question number here. Leave it empty for now because the questions now are allcomparison type.- \"document\": a string, the document id that supports the sub_question.Notice that you dont need to come out the compare question, just the sub_questions and answers. Token Labeling PromptYou have been assigned an information extraction task.Your mission is to extract the words from a given paragraph so that others can answer a question using only yourextracted words.Your extracted words should cover information from both the question and the answer, including entities (e.g. people,location, film) and core relations.Your response should be in JSON format and include the following key:- \"extracted_words\": a string composed of a list of words extracted from the paragraph, separated by a space.Please adhere to the following guidelines:- Do not reorder, change, miss, or add words. Keep it the same as the original paragraph.- Identify and extract ONLY the words explicitly mentioned in either the question or its answer, and strongly related tothe question or its answer.- NEVER label any words that do not contribute meaningful information to the question or answer.- Only extract words that occurred in the paragraph. Query Filtering PromptYou are assigned a multi-hop question refactoring task.Given a complex question along with a set of related known information, you are required to refactor the question byapplying the principle of retraining difference and removing redundancies. Specifically, you should eliminate the contentthat is duplicated between the question and the known information, leaving only the parts of the question that havenot been answered, and the new knowledge points in the known information. The ultimate goal is to reorganize theseretrained parts to form a new question.You can only generate the question by picking words from the question and known information. You should first pickup words from the question, and then from each known info, and concatenate them finally. You are not allowed to add,change, or reorder words. The given known information starts with the word \"Info: \".You response should be in JSON format and include the following key:- \"filtered_query\": a string representing the concatenation of the words from both the question and newly addedinformation, separated by a space.Please adhere to the following guidelines:- Do not reorder, change, or add words. Keep it the same as the original question.- Identify and remove ONLY the words that are already known, keep the unknown information from both the questionand information.",
  "All prompts can be found in this section, and are given in the order of Direct, CoT, Decompose, Direct-R,Iter-RetGen, and Self-ask, as shown in Tables 9 to 22": "Direct Prompting for HotpotQAAs an assistant, your task is to answer the question directly after <Question>. Your answer should be after <Answer> inJSON format with key \"answer\" and its value should be string.There are some examples for you to refer to:<Question>: What is the name of this American musician, singer, actor, comedian, and songwriter, who worked withModern Records and born in December 5, 1932?<Answer>: json{{\"answer\": \"Little Richard\"}}<Question>: Between Chinua Achebe and Rachel Carson, who had more diverse jobs?<Answer>: json{{\"answer\": \"Chinua Achebe\"}}<Question>: Remember Me Ballin is a CD single by Indo G that features an American rapper born in what year?<Answer>: json{{\"answer\": \"1979\"}}Now your Question is<Question>: {question}<Answer>: Direct Prompting for MuSiQueAs an assistant, your task is to answer the question directly after <Question>. Your answer should be after <Answer> inJSON format with key \"answer\" and its value should be string.There are some examples for you to refer to:<Question>: In which year did the publisher of In Cold Blood form?<Answer>:json{{\"answer\": \"2001\"}}<Question>: Who was in charge of the city where The Killing of a Sacred Deer was filmed?<Answer>: json{{\"answer\": \"John Cranley\"}}<Question>: Where on the Avalon Peninsula is the city that Signal Hill overlooks?<Answer>:json{{\"answer\": \"eastern tip\"}}Now your Question is<Question>: {question}<Answer>: Direct Prompting for 2Wiki-MultihopQAAs an assistant, your task is to answer the question directly after <Question>. Your answer should be after <Answer> inJSON format with key \"answer\" and its value should be string.There are some examples for you to refer to:<Question>: Which film came out first, Blind Shaft or The Mask Of Fu Manchu?<Answer>:json{{\"answer\": \"The Mask Of Fu Manchu\"}}<Question>: When did John V, Prince Of Anhalt-Zerbsts father die?<Answer>:json{{\"answer\": \"12 June 1516\"}}<Question>: Which film has the director who was born later, El Extrano Viaje or Love In Pawn?<Answer>:json{{\"answer\": \"El Extrano Viaje\"}}Now your Question is<Question>: {question}<Answer>:",
  ": Detailed prompts for Direct Question Answering with Llama-3 8B": "CoT Prompting for HotpotQAAs an assistant, your task is to answer the question after <Question>. You should first think step by step about thequestion and give your thought and then answer the <Question>. Your answer should be after <Answer> in JSON formatwith key \"thought\" and \"answer\" and their values should be string.There are some examples for you to refer to:<Question>: What is the name of this American musician, singer, actor, comedian, and songwriter, who worked withModern Records and born in December 5, 1932?<Answer>: json{{\"thought\":\"Modern Record is a big R&B label with artists including Etta James, Joe Houston, Little Richard, Ike,Tina Turner and John Lee Hooker in the 1950s and 1960s. Little Richard is an American musician, signer actor andsongwriter, born in December 5 1932. So the answer is Little Richard.\",\"answer\": \"Little Richard\"}}<Question>: Between Chinua Achebe and Rachel Carson, who had more diverse jobs?<Answer>: json{{\"thought\":\"Chinua Achebe was a Nigerian novelist, poet, professor, and critic. Rachel Carson was an Americanmarine biologist, author, and conservationist. Chinua Achebe has 4 jobs while Rachel Carson has 3 jobs. So the answeris Chinua Achebe.\",\"answer\": \"Chinua Achebe\"}}<Question>: Remember Me Ballin is a CD single by Indo G that features an American rapper born in what year?<Answer>: json{{\"thought\":\"Remember Me Ballin is the CD singer by Indo G that features Gangsta Boo, who is named Lola Mitchell,an American rapper born in 1979. So the answer is 1979.\",\"answer\": \"1979\"}}Now your Question is<Question>: {question}<Answer>:",
  ": Detailed prompts for Chain-of-Thought Question Answering with Llama-3 8B On hotpotQA": "Question Decomposition Prompt You are assigned a multi-hop question decomposition task.You should decompose the given multi-hop question into multiple single-hop questions, and such that you can answereach single-hop question independently.Your response must be wrapped with json and .You should answer in JSON format, your answer must contain the following keys:- \"decomposed_questions\": a list of strings, each string is a single-hop question.Here are some examples for your reference:## Examples<Multi-hop question>: Which film came out first, The Love Route or Engal Aasan?Your response:json{{ \"decomposed_questions\": [ \"When does the film The Love Route come out?\", \"When does the film Engal Aasancome out?\" ] }}<Multi-hop question>: Where did the spouse of Moderens composer die?Your response:json{{ \"decomposed_questions\": [ \"Who is Moderns composer?\", \"Who is the spouse of Carl Nielsen?\", \"In what place didAnne Marie Carl-Nielsen die?\" ] }}<Multi-hop question>: Where was the director of film The Fascist born?Your response:json{{ \"decomposed_questions\": [ \"Who is the director of film The Fascist?\", \"Where was Luciano Salce born?\" ] }}",
  ": Detailed prompts for multi-hop question decomposition, applicable to all datasets": "CoT Prompting for MuSiQueAs an assistant, your task is to answer the question after <Question>. You should first think step by step about thequestion and give your thought and then answer the <Question>. Your answer should be after <Answer> in JSON formatwith key \"thought\" and \"answer\" and their values should be string.There are some examples for you to refer to:<Question>: In which year did the publisher of In Cold Blood form?<Answer>: json{{\"thought\": \"The publisher of In Cold Blood is Random house, which was formed in 2001. So the answer is 2001.\",\"answer\": \"2001\"}}<Question>: Who was in charge of the city where The Killing of a Sacred Deer was filmed?<Answer>: json{{\"thought\": \"The killing of a Scared Deer was filmed in Cincinnati, Ohio, where John Cranley is the mayor. So theanswer is John Cranley.\", \"answer\": \"John Cranley\"}}<Question>: Where on the Avalon Peninsula is the city that Signal Hill overlooks?<Answer>: json{{\"thought\": \"Signal Hill overlooks the city St. Johns, which is located on the eastern tip of the Avalon Peninsula. Sothe answer is eastern tip.\", \"answer\": \"eastern tip\"}}Now your Question is<Question>: {question}<Answer>:",
  ": Detailed prompts for Chain-of-Thought Question Answering with Llama-3 8B on MuSiQue": "CoT Prompting for 2Wiki-MultihopQAAs an assistant, your task is to answer the question after <Question>. You should first think step by step about thequestion and give your thought and then answer the <Question>. Your answer should be after <Answer> in JSON formatwith key \"thought\" and \"answer\" and their values should be string.There are some examples for you to refer to:<Question>: Which film came out first, Blind Shaft or The Mask Of Fu Manchu?<Answer>: json{{\"thought\": \"Blind Shaft is a 2003 Chinese film, and The Mask Of Fu Manchu is a 1932 American pre-Code adventurefilm. The Mask Of Fu Manchu came out first. So the answer is The Mask Of Fu Manchu.\", \"answer\": \"The Mask Of FuManchu\"}}<Question>: When did John V, Prince Of Anhalt-Zerbsts father die?<Answer>: json{{\"thought\": \"The father of John V, Prince Of Anhalt-Zerbst is Ernest I, Prince of Anhalt-Dessau. He died on 12 June1516. So the answer is 12 June 1516.\", \"answer\": \"12 June 1516\"}}<Question>: Which film has the director who was born later, El Extrano Viaje or Love In Pawn?<Answer>: json{{\"thought\": \"The director of El Extrano Viaje is Fernando Fernan Gomez, he was born on 29 August 1921. The directorof Love In Pawn is Charles Saunders, he was born on 8 April 1904. Fernando Fernan Gomez was born later, so film ElExtrano Viaje has the director who was born later. So the answer is El Extrano Viaje.\", \"answer\": \"El Extrano Viaje\"}}Now your Question is<Question>: {question}<Answer>:",
  ": Detailed prompts for Chain-of-Thought Question Answering with Llama-3 8B on 2Wiki-MultihopQA": "Retrieval Prompting for HotpotQAAnswer the given question in JSON format, you can refer to the document provided.As an assistant, your task is to answer the question based on the given knowledge. Your answer should be after <Answer>in JSON format with key \"answer\" and its value should be string.The given knowledge will be embraced by <doc> and </doc> tags. You can refer to the knowledge to answer the question.If the knowledge does not contain the answer, answer the question directly.There are some examples for you to refer to:<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: What is the name of this American musician, singer, actor, comedian, and songwriter, who worked withModern Records and born in December 5, 1932?<Answer>: json{{\"answer\": \"Little Richard\"}}<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: Between Chinua Achebe and Rachel Carson, who had more diverse jobs?<Answer>: json{{\"answer\": \"Chinua Achebe\"}}<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: Remember Me Ballin is a CD single by Indo G that features an American rapper born in what year?<Answer>: json{{\"answer\": \"1979\"}}Now your question and reference knowledge are as follows.<doc>{knowledge}</doc><Question>: {question}<Answer>:",
  ": Detailed prompt for retrieval on HotpotQA": "Retrieval Prompting for MuSiQueAs an assistant, your task is to answer the question based on the given knowledge. Your answer should be after <Answer>in JSON format with key \"answer\" and its value should be string.The given knowledge will be embraced by <doc> and </doc> tags. You can refer to the knowledge to answer the question.If the knowledge does not contain the answer, answer the question directly.There are some examples for you to refer to:<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: In which year did the publisher of In Cold Blood form?<Answer>: json{{\"answer\": \"2001\"}}<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: Who was in charge of the city where The Killing of a Sacred Deer was filmed?<Answer>: json{{\"answer\": \"John Cranley\"}}<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: Where on the Avalon Peninsula is the city that Signal Hill overlooks?<Answer>: json{{\"answer\": \"eastern tip\"}}Now your question and reference knowledge are as follows.<doc>{knowledge}</doc><Question>: {question}<Answer>:",
  ": Detailed prompt for retrieval on MuSiQue": "Retrieval Prompting for 2Wiki-MultihopQAAs an assistant, your task is to answer the question based on the given knowledge. Your answer should be after <Answer>in JSON format with key \"answer\" and its value should be string.The given knowledge will be embraced by <doc> and </doc> tags. You can refer to the knowledge to answer the question.If the knowledge does not contain the answer, answer the question directly.There are some examples for you to refer to:<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: Which film came out first, Blind Shaft or The Mask Of Fu Manchu?<Answer>: json{{\"answer\": \"The Mask Of Fu Manchu\"}}<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: When did John V, Prince Of Anhalt-Zerbsts father die?<Answer>: json{{\"answer\": \"12 June 1516\"}}<doc>{{KNOWLEDGE FOR YOUR REFERENCE}}</doc><Question>: Which film has the director who was born later, El Extrano Viaje or Love In Pawn?<Answer>: json{{\"answer\": \"El Extrano Viaje\"}}Now your question and reference knowledge are as follows.<doc>{knowledge}</doc><Question>: {question}<Answer>:",
  ": Detailed prompt for retrieval on 2Wiki-MultihopQA": "Iter-RetGen Prompting for HotpotQAYou should think step by step and answer the question after <Question> based on given knowledge embraced with <doc>and </doc>. Your answer should be after <Answer> in JSON format with key \"thought\" and \"answer\", their value shouldbe string.Here are some examples for you to refer to:<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: What is the name of this American musician, singer, actor, comedian, and songwriter, who worked withModern Records and born in December 5, 1932?Lets think step by step.<Answer>: json{{ \"thought\": \"Artists who worked with Modern Records include Etta James, Joe Houston, Little Richard, Ike andTina Turner and John Lee Hooker in the 1950s and 1960s. Of these Little Richard, born in December 5, 1932, was anAmerican musician, singer, actor, comedian, and songwriter.\", \"answer\": \"Little Richard\" }}<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: Between Chinua Achebe and Rachel Carson, who had more diverse jobs?<Answer>: json{{ \"thought\": \"Chinua Achebe was a Nigerian novelist, poet, professor, and critic. Rachel Carson was an Americanmarine biologist, author, and conservationist. So Chinua Achebe had 4 jobs, while Rachel Carson had 3 jobs. ChinuaAchebe had more diverse jobs than Rachel Carson.\", \"answer\": \"Chinua Achebe\" }}<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: Remember Me Ballin is a CD single by Indo G that features an American rapper born in what year?<Answer>: json{{ \"thought\": \"Remember Me Ballin is the CD single by Indo G featuring Gangsta Boo. Gangsta Boo is Lola Mitchellsstage name, who was born in August 7, 1979, and is an American rapper.\", \"answer\": \"1979\" }}Now based on the given doc, answer the question after <Question>.<doc>{documents}</doc><Question>: {question}Lets think step by step.<Answer>:",
  ": Detailed prompt for Iter-RetGen on HotpotQA": "Iter-RetGen Prompting for MuSiQueYou should think step by step and answer the question after <Question> based on given knowledge embraced with <doc>and </doc>. Your answer should be after <Answer> in JSON format with key \"thought\" and \"answer\", their value shouldbe string.Here are some examples for you to refer to:<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: In which year did the publisher of In Cold Blood form?Lets think step by step.<Answer>: json{{ \"thought\": \"In Cold Blood was first published in book form by Random House. Random House was form in 2001.\",\"answer\": \"2011\" }}<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: Who was in charge of the city where The Killing of a Sacred Deer was filmed?Lets think step by step.<Answer>: json{{ \"thought\": \"The Killing of a Sacred Deer was filmed in Cincinnati. The present Mayor of Cincinnati is John Cranley.Therefore, John Cranley is in charge of the city.\", \"answer\": \"John Cranley\" }}<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: Where on the Avalon Peninsula is the city that Signal Hill overlooks?Lets think step by step.<Answer>: json{{ \"thought\": \"Signal Hill is a hill which overlooks the city of St. Johns. St. Johns is located on the eastern tip of theAvalon Peninsula.\", \"answer\": \"eastern tip\" }}Now based on the given doc, answer the question after <Question>.<doc>{documents}</doc><Question>: {question}Lets think step by step.<Answer>:",
  ": Detailed prompt for Iter-RetGen on MuSiQue": "Iter-RetGen Prompting for 2Wiki-MultihopQAYou should think step by step and answer the question after <Question> based on given knowledge embraced with <doc>and </doc>. Your answer should be after <Answer> in JSON format with key \"thought\" and \"answer\", their value shouldbe string.Here are some examples for you to refer to:<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: Which film came out first, Blind Shaft or The Mask Of Fu Manchu?Lets think step by step.<Answer>: json{{ \"thought\": \"Blind Shaft is a 2003 film, while The Mask Of Fu Manchu opened in New York on December 2, 1932.2003 comes after 1932. Therefore, The Mask Of Fu Manchu came out earlier than Blind Shaft.\", \"answer\": \"The MaskOf Fu Manchu\" }}<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: When did John V, Prince Of Anhalt-Zerbsts father die?Lets think step by step.<Answer>: json{{ \"thought\": \"John V, Prince Of Anhalt-Zerbst was the son of Ernest I, Prince of Anhalt-Dessau. Ernest I, Prince ofAnhalt-Dessau died on 12 June 1516.\", \"answer\": \"12 June 1516\" }}<doc>{{KNOWLEDGE FOR THE QUESTION}}</doc><Question>: Which film has the director who was born later, El Extrano Viaje or Love In Pawn?Lets think step by step.<Answer>: json{{ \"thought\": \"The director of El Extrano Viaje is Fernando Fernan Gomez, who was born on 28 August 1921. Thedirector of Love In Pawn is Charles Saunders, who was born on 8 April 1904. 28 August 1921 comes after 8 April 1904.Therefore, Fernando Fernan Gomez was born later than Charles Saunders.\", \"answer\": \"El Extrano Viaje\" }}Now based on the given doc, answer the question after <Question><doc>{documents}</doc><Question>: {question}Lets think step by step.<Answer>:",
  ": Detailed prompt for Iter-RetGen on 2Wiki-MultihopQA": "Self-ask Prompting for HotpotQASolve the question with the given knowledge.Each line should start with either \"Intermediate answer:\", \"Follow up:\", \"So the final answer is:\", or \"Are follow upquestions needed here:\".#Question: What is the name of this American musician, singer, actor, comedian, and songwriter, who worked withModern Records and born in December 5, 1932?Are follow up questions needed here: Yes.Follow up: Who worked with Modern Records?Intermediate answer: Artists worked with Modern Records include Etta James, Little Richard, Joe Houston, Ike and TinaTurner and John Lee Hooker.Follow up: Is Etta James an American musician, singer, actor, comedian, and songwriter, and was born in December 5,1932?Intermediate answer: Etta James was born in January 25, 1938, not December 5, 1932, so the answer is no.Follow up: Is Little Richard an American musician, singer, actor, comedian, and songwriter, and was born in December5, 1932?Intermediate answer: Yes, Little Richard, born in December 5, 1932, is an American musician, singer, actor, comedianand songwriter.So the final answer is: Little Richard#Question: Between Chinua Achebe and Rachel Carson, who had more diverse jobs?Are follow up questions needed here: Yes.Follow up: What jobs did Chinua Achebe have?Intermediate answer: Chinua Achebe was a Nigerian (1) novelist, (2) poet, (3) professor, and (4) critic, so Chinua Achebehad 4 jobs.Follow up: What jobs did Rachel Carson have?Intermediate answer: Rachel Carson was an American (1) marine biologist, (2) author, and (3) conservationist, so RachelCarson had 3 jobs.Follow up: Did Chinua Achebe have more jobs than Rachel Carson?Intermediate answer: Chinua Achebe had 4 jobs, while Rachel Carson had 3 jobs. 4 is greater than 3, so yes, ChinuaAchebe had more jobs.So the final answer is: Chinua Achebe#Question: Remember Me Ballin is a CD single by Indo G that features an American rapper born in what year?Are follow up questions needed here: Yes.Follow up: Which American rapper is featured by Remember Me Ballin, a CD single by Indo G?Intermediate answer: Gangsta BooFollow up: In which year was Gangsta Boo born?Intermediate answer: Gangsta Boo was born in August 7, 1979, so the answer is 1979.So the final answer is: 1979#Question: {question}Are follow up questions needed here:",
  ": Detailed prompt for self-ask on HotpotQA": "Self-ask Prompting for MuSiQueSolve the question with the given knowledge.Each line should start with either \"Intermediate answer:\", \"Follow up:\", \"So the final answer is:\", or \"Are follow upquestions needed here:\".#Question: In which year did the publisher of In Cold Blood form?Are follow up questions needed here: Yes.Follow up: What business published In Cold Blood?Intermediate answer: In Cold Blood was published in book form by Random House.Follow up: Which year witnessed the formation of Random House?Intermediate answer: Random House was form in 2001.So the final answer is: 2001#Question: Who was in charge of the city where The Killing of a Sacred Deer was filmed?Are follow up questions needed here: Yes.Follow up: In which city was The Killing of a Sacred Deer filmedIntermediate answer: The Killing of a Sacred Deer was filmed in Cincinnati.Follow up: Who was in charge of Cincinnati?Intermediate answer: The present Mayor of Cincinnati is John Cranley, so John Cranley is in charge.So the final answer is: John Cranley#Question: Where on the Avalon Peninsula is the city that Signal Hill overlooks?Are follow up questions needed here: Yes.Follow up: What city does Signal Hill overlook?Intermediate answer: Signal Hill is a hill which overlooks the city of St. Johns.Follow up: Where on the Avalon Peninsula is St. Johns located?Intermediate answer: St. Johns is located on the eastern tip of the Avalon Peninsula.So the final answer is: eastern tip#Question: {question}Are follow up questions needed here:",
  ": Detailed prompt for self-ask on MuSiQue": "Self-ask Prompting for 2Wiki-MultihopQASolve the question with the given knowledge.Each line should start with either \"Intermediate answer:\", \"Follow up:\", \"So the final answer is:\", or \"Are follow upquestions needed here:\".Follow the examples below to answer the questions with natural language.#Question: Which film came out first, Blind Shaft or The Mask Of Fu Manchu?Are follow up questions needed here: Yes.Follow up: When did Blind Shaft come out?Intermediate answer: Blind Shaft came out in 2003.Follow up: When did The Mask Of Fu Manchu come out?Intermediate answer: The Mask Of Fu Manchu came out in 1932.So the final answer is: The Mask Of Fu Manchu#Question: When did John V, Prince Of Anhalt-Zerbsts father die?Are follow up questions needed here: Yes.Follow up: Who is the father of John V, Prince Of Anhalt-Zerbst?Intermediate answer: The father of John V, Prince Of Anhalt-Zerbst is Ernest I, Prince of Anhalt-Dessau.Follow up: When did Ernest I, Prince of Anhalt-Dessau die?Intermediate answer: Ernest I, Prince of Anhalt-Dessau died on 12 June 1516.So the final answer is: 12 June 1516#Question: Which film has the director who was born later, El Extrano Viaje or Love In Pawn?Are follow up questions needed here: Yes.Follow up: Who is the director of El Extrano Viaje?Intermediate answer: The director of El Extrano Viaje is Fernando Fernan Gomez.Follow up: Who is the director of Love in Pawn?Intermediate answer: The director of Love in Pawn is Charles Saunders.Follow up: When was Fernando Fernan Gomez born?Intermediate answer: Fernando Fernan Gomez was born on 28 August 1921.Follow up: When was Charles Saunders (director) born?Intermediate answer: Charles Saunders was born on 8 April 1904.So the final answer is: El Extrano Viaje#Question: {question}Are follow up questions needed here:"
}