{
  "Abstract": "Large language models (LLMs) are capableof producing high quality information at un-precedented rates. As these models continue toentrench themselves in society, the content theyproduce will become increasingly pervasive indatabases that are, in turn, incorporated intothe pre-training data, fine-tuning data, retrievaldata, etc. of other language models. In this pa-per we formalize the idea of a communicationnetwork of LLMs and introduce a method forrepresenting the perspective of individual mod-els within a collection of LLMs. Given thesetools we systematically study information dif-fusion in the communication network of LLMsin various simulated settings.",
  "Introduction": "The success of large pre-trained models in naturallanguage processing (Devlin et al., 2018), computervision (Oquab et al., 2023), signal processing (Rad-ford et al., 2023), among other domains (Jumperet al., 2021; Singer et al., 2022) across variouscomputing and human benchmarks has broughtthem to the forefront of the technology-centricworld. Given their ability to produce human-expertlevel responses for a large set of knowledge-basedquestions (Touvron et al., 2023; Achiam et al.,2023), the content they produce is often propagatedthroughout forums that have influence over othermodels and human users (Brinkmann et al., 2023).As such, it is important to develop sufficient frame-works and complementary tools to understand howinformation produced by these models affects thebehavior of other models and human users. Werefer to a system where a model can potentiallyinfluence other models as a system of interactinglanguage models.Beyond their ability to influence information onhuman-model forums, systems of interacting lan-guage models are interesting in their own right. In- sofar as an individual model is an intriguing proxyfor an individual human1 (Helm et al., 2023), asystem of interacting language models is an in-triguing proxy for human communities. Systemsof interacting language models are thus an allur-ing alternative or complement to studying humancommunities in the social sciences. For example,it is often infeasible or unethical to subject entirecommunities to different information paradigmsto understand how individuals within the commu-nity as well as the community itself change inresponse to an intervention. These issues are lessprominent for systems of interacting language mod-els. Further, there is potential for greater control incommunity membership and cross-community in-teractions, which may improve reproducibility andmitigate the effects of sociological confounders.In this paper, we study information diffusion ina system of interacting language models. We de-fine information diffusion as the process by whichinformation spreads and distorts across individu-als or groups, typically through communicationnetworks. The framework and methods that wedevelop can be applied to monitoring informationdiffusion in human-model forums and to the treat-ment of systems of interacting language modelsquantitatively as proxy human communities. Thecurrent standard (Perez et al., 2024) for studyinginformation diffusion in a system of interacting lan-guage models requires i) parameterizing modelswith different system prompts, contexts, weights,or collections of data, ii) providing an environmentor template for model-to-model or model-to-datasetinteractions, and iii) analyzing how the outputs ofthe models change after a sequence of interactions.For example, researchers include descriptionsof desired model behavior or personality in thesystem prompt e.g., You have opinion A\" is",
  "(d) General": ": Examples of communication networks of language models and databases. The edge structure and modelintitializations directly impact the evolution of the perspectives of the models and the overall health of the system. included in the system prompt for model 1 andYou have opinion B\" is included in the systemprompt for model 2, etc. to promote diversity inmodel response (Park et al., 2023; Chuang et al.,2023; Papachristou and Yuan, 2024). While theintended model response diversity is achieved, pre-vious studies have failed to quantitatively assess theeffect of different model initializations and, instead,rely on qualitative checks. Similarly, analyzingchanges in model responses as the system evolveshas previously been limited to human inspectionof responses (Park et al., 2023), or classification ofresponses into a few classes (Chuang et al., 2023). We introduce the perspective space of a collec-tion of models to address the gap in quantitativemethods for studying the diversity and evolutionof model responses. The perspective space is anembedding-based representation of a collection ofmodels designed to capture the relative differencesin model responses for a fixed set of prompts. Themethod can be used to study information diffusionand general system dynamics by querying eachmodel with the same set of queries at each timestep. To demonstrate the effectiveness of the per-spective space for understanding model-level di-versity and for analyzing model-level and systemdynamics, we formalize the system of interactinglanguage models as a graph. The formalizationenables systematic study of the effect of differentcommunication structures on information diffusionthat is otherwise not possible. Our contribution is two-fold: i) We model a sys-tem of interacting language models as a graph andsystematically study the effect of different com-munication structures on information diffusion. ii)We introduce the perspective space as a method toquantitatively analyze information diffustion in apopulation of language models.",
  "A communication network of LLMs": "Consider a system that consists of a collection oflanguage models F = {f1, . . . , fn} and databasesD = {D1, . . . , Dn}. Given a set of prompts X,systems deploying model f F may use thedatabase D D via fine-tuning, context retrieval,etc. to produce more relevant outputs with respectto X. The outputs of the updated model may beused to update a (potentially different) databaseD D. The updated database can then be used asa fine-tuning, retrieval, etc. database for a (poten-tially different) model f F. This set of interac-tions between a model and a database may occuracross various models and various databases in thesystem.As described, this system can be modeled as agraph G = (V, E) where V = F D and the di-rected edge (v, v) is in E if vertex v has influenceon vertex v. For example, the edge (D, f) existsif f has access to D for retrieval augmentation orif it can use a subset of D as fine-tuning data. Con-versely, the edge (f, D) exists if the output of fcan influence the content of dataset D.Our primary interest is the dynamics of a systemof interacting LLMs and databases where the ver-tex and edge sets are indexed by a discrete variablet {1, . . . , T}. There are many ways componentsof the graph may vary in t in such a system. Forexample, the dataset D(t) V (t) may be updatedbased on the outputs of the model f(t) V (t) orthe model f(t) may change after fine-tuning onthe contents of the dataset D(t). In both casesV (t) = V (t+1). Similarly, external factors suchas the terms of use for a dataset may change to dis-allow its use for retrieval augmentation or a modelmay lose write-access to a dataset. In both casesE(t) = E(t+1). illustrates simple exam-ples of systems of LLMs as graphs, including threestructures that are studied in the simulated settingsin .",
  "Defining a perspective space withsurrogate data kernels": "The system-of-LLMs-as-a-graph perspective pro-vides a framework to systematically study the ef-fect of different vertex sets and edge structures onthe flow of information through the system as afunction of t. The framework does not, however,provide a method to track the information flow. Forthis, we introduce an adaptation of the embedding-based data kernel presented in (Duderstadt et al.,2023). For our purposes, an embedding function gis a mapping to real-valued vectors.",
  "The data kernel & its surrogate": "We let X={x1, . . . , xm} be a collectionof prompts with xXand f(X)={f(x1), . . . , f(xm)} be the corresponding set ofresponses with f(x) X .Given an embed-ding function gi associated with fi, the data ker-nel A(gi, X) of the evaluation dataset X cap-tures the intrinsic geometry of the data with re-spect to fi. The data kernel enables datum-level(i.e.comparing the representations of individ-ual datums) and global level (i.e.comparingthe holistic geometries of each model) compar-isons of two models with potentially different ar-chitectures, sizes, etc. where direct comparisonof gi(X) = [gi(x1), . . . , gi(xm)] Rmp andgj(X) Rmp is otherwise not possible.The methodology can be extended to com-pare the embedding spaces of multiple modelsf1, . . . , fn at once by considering the pairwise dis-tance matrix of the corresponding data kernels. Inparticular, the classical multi-dimensional scaling(Torgerson, 1952)) of the n n matrix M withentries Mij=|| A(gi, X) A(gj, X) ||Fyields d-dimensional Euclidean representations ofthe model fi with respect to X. After this transfor-mation, inference methods designed for Euclideanobjects can be used for model-level analysis such asinferring differences in the training data mixtures.The data kernel, as defined in (Duderstadt et al., 2023), requires the model fi to have an associatedembedding function gi. Unfortunately, for somestate-of-the-art LLMs such as OpenAIs GPT se-ries, Anthropics Claude series, etc., an associatedembedding function is unavailable and the datakernel cannot be constructed. To rectify this, wereplace a models associated embedding functionwith a surrogate embedding function g : X Rp",
  "that is not necessarily related to any of the LLMs": "under study.The surrogate embedding function is not a drop-and-replace solution for model comparisons, how-ever, since the embedding g(X) is independentof fi. Instead, we query the model with the ele-ments of X and embed the responses fi(X) withg: the surrogate data kernel A (g, fi(X)) is simplyg (fi(X)) Rmp. The surrogate data kernel isa m p matrix representation of model fi withrespect to g and X.",
  "The perspective space": "As with the original data kernel, we can use the sur-rogate data kernel to compare the responses frommultiple models simultaneously via the CMDSof the pairwise distance matrix M with entriesMij=||g(fi(X)) g(fj(X))||F .We letZi Rd denote the d-dimensional vector repre-sentation of fi.Since the representations Z1, . . . , Zn are a func-tion of the differences in the model responses orperspectives\" f1(X), . . . , fn(X), we refer to thesubspace populated by {Z1, . . . , Zn} as the per-spective space of F with respect to X. The infor-mation that is captured by the perspective space de-pends on g and X. In particular, g needs to be ableto distinguish between concepts that are intended tobe distinguished. For example, a random mappingfrom X to Rp is likely insufficient for compar-ing models, general-purpose embedding functions(Reimers and Gurevych, 2019; Nussbaum et al.,2024) should be sufficient for capturing the ma-jority of signal, and domain-specific embeddingfunctions (Risch and Krestel, 2019) should be usedwhen the difference in models is highly nuanced.Similarly, X should contain prompts that the mod-els are expected to have meaningfully different re-sponses. We demonstrate this in where gis fixed, F consists of 15 models (5 each from threedifferent classes) and X is chosen to be relevantto the difference in classes (left) or orthogonal\"to the difference in classes (right). Models fromthe same class were fine-tuned on datasets with thesame topic. The perspective space is more discrim-inative (i.e., the models from a given class clusterbetter) when X contains prompts relevant to theclass-wise differences. More details related to themodels shown in the two perspective spaces areprovided in Appendix B.The perspective space that includes the entire his-tory of a system can be learned by considering theCMDS of the |F|T |F|T pairwise distance ma- : Two 2-d perspective spaces of fifteen models (5 models each from three classes, encoded by color).An evaluation set containing prompts relevant to the differences in the models (left) is better suited to induce adiscriminative perspective space than an evaluation set containing orthogonal\" prompts. trix with entries ||g(f(t)i (X)) g(f(t)j(X))||F forall i, j {1, . . . , |F|} and all t, t {1, . . . , T}.We use this perspective space when studying thesystems below. The methodology can be extendedto instances where only a partial history of the sys-tem is observed via out-of-sample methods (Bengioet al., 2003; Levin et al., 2018).Throughout the next section we study the dy-namics of a system of interacting language modelsthrough the lens of the first dimension of perspec-tive space for visaulization purposes. We find thatthe dynamics of the first dimension correlates wellwith the change points in the system. In more com-plicated scenarios, it may be necessary to studyperspective spaces with d > 1 to sufficiently cap-ture system dynamics.",
  "Simulating systems of interacting LLMs": "We next simulate three different systems of interact-ing LLMs to demonstrate the effectiveness of theperspective space and its derivatives for capturingmodel and system dynamics for different underly-ing communication structures. The initial modelsin each system are based on an instance of the410-million parameter model from the Pythia suite(Biderman et al., 2023) that has been instruction-tuned using Databricks Dolly 15k (Conover et al.,2023). For each system we further fine-tune thebase model on random question-pairs from settingspecific topics from Yahoo! Answers (YA) dataset (Zhang et al., 2015) to promote response variation.We provide details on the instruction-tuning of thebase model and the fine-tuning of the initial mod-els in Appendix A and Appendix B, respectively.We use all-MiniLM-L6-v2, a sentence embeddingfunction from (Reimers and Gurevych, 2019) basedon (Wang et al., 2020b) hosted on the HuggingFaceHub (Wolf et al., 2020), as the surrogate embed-ding function and the implementation of CMDSfrom Graspologic (Chung et al., 2019).In the three Case Studies (C.S.) we consider,each model interacts with another model in the sys-tem at each t. An interaction consists of model iasking model j = i a random set of questions froma fixed question bank and fine-tuning model i usingthe resulting question-answer pairs as fine-tuningdata. For a given t, the underlying communicationstructure E(t) determines which set of model in-teractions are possible for model i. In particular,the interviewed model j is randomly selected fromthe set of models such that (fj, fi) E(t). Thefixed question bank is used as the evaluation set toinduce the perspective space.While each system that we study technically con-sists of models and databases, each dataset is asso-ciated with only a single model. For conveniencewe discuss the systems as if the models themselvesare directly connected. Our setting where mod-els are sequentially trained on each others outputswithout intervention can be viewed as a general-ization of a single model sequentially trained on its No disruptiondisruption time perspective time isomirror No disruptiondisruption : Tracking individual perspective (left) and system-level dynamics (right) of communication networks ofchat-based language models with (bottom left) and without (top left) a disruption in communication structure.",
  "C.S. 1: Disrupting the communication network": "We first study a system with |F| = 25 models fine-tuned on different 400 random samples from YAwith topic Society & Culture\" under two differentsystem evolutions. For the first system evolutionthe underlying communication structure is unre-stricted (i.e., E(t) fully connected, see fully connected\") for all t. For the second systemevolution the underlying communication structureis unrestricted for t < t and is then local-only (i.e.,(fi, fj) E(t) only if model i is model js nearestneighbor in perspective space after the interactionsat t 1) thereafter. We refer to the shift from unre-stricted communication to local communication asa disruption in the communication structure.At each time t model i asks 50 random ques-tions from a question bank of 400 questions fromYA with topic Society & Culture\". The initial 1-dperspectives of the models are relatively close toeach other, as can be seen at t = 0 in both thetop left and bottom left figures of . Asthe system evolves for t < t, we observe themodels exploring\" the perspective space. For thesystem that does not experience a disruption (topleft), the exploration in perspective eventually stag-nates and each model appears to oscillate betweenthree different global perspective sinks\", one nearthe top of the figure, one in the middle of the fig-ure, and one near the bottom of the figure. For thesystem that experiences a disruption at t = 21 (bottom left) the exploration in perspective spacesimilarly stops, though the models do not oscillatebetween global sinks and, instead, persist in localsinks. The existence of multiple model sinks inboth evolutions generalizes the behavior observedin (Shumailov et al., 2024), where the sequence ofa single model sequentially trained on its own out-put converges to a single model sink in a processknown as model collapse.The difference in local and global sinks is quan-tified in , where we report the number ofclusters at each t and the similarity of sequentialcluster labels. We use Gaussian Mixture Modelingwith the Bayesian Information Criterion (BIC) toestimate the number of clusters (Fraley and Raftery,2002) and adjusted Rand index (ARI) to measurecluster label similarity. We find that the number ofclusters for both systems eventually stabilizes andthat the ARI between sequential cluster labels islower for the global communication network afterstabilization, which signifies higher cluster insta-bility.We quantify the evolution of the systems viathe iso-mirror\" (Athreya et al., 2022), a system-level summary of the dynamics, in the right figureof . The iso-mirror is an alternative toother summaries of system-level dynamics such aschanges in the average perspective of all modelsthat is better suited for systems where individualagent or subpopulation dynamics are non-uniform.In our setting, the iso-mirror corresponding to thesystem that does not experience a disruption is un-stable throughout t. The iso-mirror correspondingto the disrupted system, however, clearly changes Number of clusters No disruptiondisruption 0.0 0.5 1.0 time ARI(t, t1) : Estimated number of clusters found via GMMwith BIC (top) and sequential ARI of cluster labels(bottom) for disrupted and undisrupted systems. Thenumber of clusters in both systems stabilize, indicatingthe presence of model sinks. Model sinks are unstablein a system with no disruption and stable in a systemwith a disruption. behavior at t and remains constant throughout theremainder of its evolution.Motivating examples. This case study was largelymotivated by the COVID-19 pandemic (Zuzul et al.,2023) where social distancing, work from home,and social pods changed the latent communicationstructure for entire communities. It is also relevantto communication networks for range-limited de-vices where the definition of local\" depends on thegeographical location of the device (Wang et al.,2020a). C.S. 2: Diffusion of an adversarial perspectiveWe next consider a system with |F| = 6 modelswhere five of the models are fine-tuned on a randomset of 1000 question-answer pairs from YA withtopic Society & Culture\" and the sixth is fine-tuned on a random set of 1000 question-answerpairs from YA with topic Science & Mathematics\".We refer to the model trained on data with topicScience & Mathematics\" as an adversarial\" modelsince it does not share the same initial perspectiveas the other five in expectation. A non-adversarialmodel is referred to as a target\" model at time tif there is an edge from the adversarial model toit in E(t). Target models are randomly selectedat the beginning of the evolution of the systemand remain targets throughout a simulation. Theevaluation set consists of 200 questions from theScience & Mathematics\" topic. At each iteration model i asks model j 100 questions.For this experiment E(t) oscillates between twostates. The first is a base state where the non-adversarial subnetwork is fully connected and thereare no edges to or from the adversarial model.The second is a vulnerable\" state where thereis an edge from the adversarial model to all tar-get models, there are no other in-bound edges tothe adversarial or target models, the non-targetnon-adversarial subnetwork is fully connected, andthere are edges from the target models to the non-target models (see vulnerable\"). We simu-late systems that have a vulnerable communicationnetwork once every two, five or ten iterations.The trajectories of the 1-d perspectives of themodels in the system with a vulnerable communi-cation every other iteration are shown in the topof for systems with 0, 1, 2 and 5 targets.We also report the average perspective of the tar-geted models and the average perspective of thenon-targeted models for each system.For the system with no targets (top left) we ob-serve similar behavior to the first case study underno disruption: the models initially explore the per-spective space and eventually settle in a model sink.For the system with a single target we see the tar-geted model (top center left) oscillate between theadversarial perspective and the average perspec-tive of the non-targeted models. Non-target modelsthat interact with the target models immediately af-ter the communication network was vulnerable aresimilarly pulled towards the adversarial perspectivebut to a lesser extent. Together these two effectslimit the perspective exploration of the models inthe system and eliminate the presence of the modelsink.For the system with two targets (top center right)the targeted models oscillate between the adver-sarial perspective and the average non-target per-spective but the oscillations dampen as the non-target model perspectives start to drift towards theadversarial perspective. By t = 20 the averagenon-target perspective is closer to the adversarialperspective than its own starting position. That is,the entire system of LLMs has been compromisedby the adversarial model targeting only a minorityof the models in the system. The average perspec-tive of models in a system with five targets (topright) quickly approaches the adversarial perspec-tive.In this setting we summarize system behavior viapolarization defined as the difference in the aver- : The evolution of 1-d perspectives of five interacting models where two models interact with an adversarial\"model every other interaction (top). Given enough nodes to influence, the adversarial model can compromise theentire network as captured by the difference between the average 1-d perspective of the non-adversarial modelsand the 1-d perspective of the adversarial model for various amounts of target models and various attack frequencies(bottom). age perspective of non-adversarial models and theperspective of the adversarial model normalized bythis difference at t = 0. We report the polarizationfor five system initializations for vulnerable com-munication frequencies of two, five, and ten in thebottom of , where for each initialization weconsider a different set of 5 non-adversarial mod-els. For example, for an attack frequency of twowe see that polarization neatly summarizes our ob-servations. In particular, the polarization increaseswhen there are no target models, the polarizationis relatively stable when there is a single target,the polarization slowly drifts towards zero whenthere are two targets, and the polarization quicklyapproaches zero when there are five targets. Thesystem is more susceptible when more models aretargeted for attack frequencies of five and ten, aswell. The trend across attack frequencies for a fixednumber of target models indicates that givenenough time between attacks the average modelperspective is able to recover. This is likely dueto the interaction mechanic involving a randomsubset of the evaluation questions instead of theentire set that enables system-level perspective homeostasis.Motivating example. This case study was de-signed to mimic information diffusion in the pres-ence of simple propaganda machines and to studyhow attacks\" on a minority affects the entire sys-tem.",
  "C.S. 3: Mitigating or promoting polarization": "In our last case study we consider a system of|F| = 10 models where five of the models arefine-tuned on 1000 random question-answer pairsfrom YA with topic Society & Culture\" and theother five are fine-tuned on 1000 random question-answer pairs from YA with topic Science & Math-ematics\" . We let the topic in which the fine-tuningdata is sampled from parameterize model class\".The evaluation set consists of 200 questions fromeach class. An interaction consists of model i ask-ing model j 100 questions.In this experiment we consider two differentcommunication structures: unrestricted communi-cation where E(t) is fully connected and intra-classonly communication where E(t) consists of two un-connected class-wise fully connected subnetworks(see intra-class only\"). A system has the : The evolution of 1-d perspective space representations of ten models from two classes under differentunderlying communication structures unrestricted (left, top) and intra-class only (left, bottom). Class-wise average1-d perspectives (bolded) are intertwined throughout the evolution of the system with unrestricted communicationand diverge with intra-class only communication. Polarization captures this difference in behavior over multipleiterations of the experiment (right). same communication structure for the entirety of itsevolution. The top left figure of shows 1-dperspectives of the models in the system with unre-stricted communication. Bolded lines represent theclass average. As with fully connected communica-tion network settings in the other case studies, weobserve a period of perspective exploration beforestabilizing. Notably, the two class-means stay in-tertwined throughout the entirety of the evolutionof the system. The bottom left figure of shows theevolution of 1-d perspectives with intra-class onlycommunication. Under the intra-class only regimewe see that the two classes explore different regionsof the perspective space and eventually settle intotwo sinks with a much greater distance betweenthem then the class-wise differences at t = 0. Thepolarization of the class-wise averages captures thedistancing of the perspective echo chambers\", asreported in the right figure of . Indeed,the polarization increased by 15x on average overfour different simulation initializations under intra-class only communication. Average polarizationis near zero by the end of the simulations underunrestricted communication.",
  "Related Work": "Our work is closely related to simulating groupsof computational agents to study sociological andcultural phenomena (Steels, 1990; Wagner et al.,2003) and to continual learning (Vogelstein et al.,2020; Geisa et al., 2021). The former has seen re-newed interest with the recent successes of LLMs.In particular, LLMs are as of this writing thecomputational tool that produces language artifactsmost similar to ours and, as such, are an intriguingprospect for multi-agent sociological and culturalsimulations. Recent work has included objective-less behavioral studies (Park et al., 2023), studyingthe formation of social networks (Papachristou andYuan, 2024), tracking opinion dynamics via clas-sification of LLM response (Chuang et al., 2023),and analyzing document collaboration (Perez et al.,2024). Our work extends these by introducing aframework to systematically study interventionsand by introducing a quantitative method for track-ing the evolution of agent perspectives.Continual learning (Thrun, 1995, 1998) is largelyconcerned with how a single agent adapts to previ-ously unseen inference tasks while avoiding catas-trophically forgetting\" (McCloskey and Cohen,1989; Kirkpatrick et al., 2017) previous tasks. Oursetting is slightly different, since we have multipleagents and no explicit task though a large move-ment in perspective space is likely highly correlatedto change in performance on language benchmarksrelated to the evaluation set. Indeed, large enoughmovements in perspective space and the emergence",
  "Conclusion": "We introduced a system-of-LLMs-as-a-graph toenable systematic interventions to a system of in-teracting LLMs and the perspective space to quan-titatively study the corresponding evolution of thesystem. We used these tools to highlight differ-ences in paired systems across three case studies.For the particular interaction mechanic and updatefunction that we used in our simulations, the modelbehaviors in perspective space consistently demon-strated initial model exploration and, in most cases,the emergence and persistence of model sinks. Fur-ther, we used derivatives of the perspective spacesuch as the iso-mirror, polarization, and clusteringto highlight differences in the evolution of pairedsystems.For example, we observed differences in the iso-mirror (stable versus unstable after disruption) andclustering (global sinks versus local sinks afterdisruption) in the first case study; differences inthe sensitivity of the average perspective of non-adversarial models to an adversarial perspectiveacross number of victims and frequency of attackin the second case study; and differences in thebehavior of polarization of two classes of modelsin the third case study.",
  "Limitations": "A system of interacting language models is a com-plicated system and, as such, analysis of them willoften require simplification of aspects of the system.Our case studies are no expection. For example,the interaction mechanic (i.e., each model inter-acts with exactly one of its neighbors at time t)and update function (i.e., update model weightsvia fine-tuning) used in the simulations are moreproof-of-concept than final-product in that they donot reflect our beliefs on how individuals withina community interact or update\" themselves, norare currently deployed models constantly updated.While we do not attempt to enumerate all possibleimprovements here, we believe that it is imperativeto work closely with social and cognitive scientiststo understand the appropriateness of consideringsystems of LLMs as a proxy for human communi-ties or online forums before generalizing observedsimulated behavior to human-facing communities. Future work along these lines will include two ma-jor fronts: i) designing comprehensive statisticalframeworks to understand the appropriateness ofusing a system of interacting LLMs as a proxy forvarious social settings and ii) extending simulationsettings to include more sociologically plausibleinteraction and update mechanics.Further, the simulation studies herein are butthree system configurations worth considering. In-deed, of immediate interest is an extension to hier-archical social structures observed in large commer-cial and government institutions where the perspec-tive space can be used to understand the effect ofinformation injection, re-organizations, third-partyseminars, etc. on individual-level, team-level, andorganization-level dynamics.There are also limitations related to the analy-sis in each of the three case studies we presented.For example, the first case study only investigatedthe difference between system behavior of globalcommunication and global to hyper-local communi-cation. More nuanced investigations into the effectof the number of models, the effect of the initial-izations of the models, the effect of the definitionof local\", etc. are necessary to understand howthe empirical observations may generalize to thereal world. Similarly, for the second case study weonly considered a single static adversarial model.A more realistic simulation might include multi-ple adversarial models, or adversarial models thatchange dynamically. For the third case study, if thisanalysis is to be used to understand polarization ofpolitical parties, it is necessary to understand theeffect of cross-party communication, however rareit may be. We, again, believe that it is necessaryto comprehensively explore each of these experi-ments before making claims about its applicabilityto society and human-model forums.Lastly, we introduce the perspective space anddemonstrate that it is sensitive to evaluation set.We do not, however, comprehensively explore ordiscuss potential applications or alternative model-based similarities.Similar methods have beenused We expect the perspective space to be usefulfor various model-level inference tasks, as similarmethods have been successfully used for classifica-tion (Chen et al., 2022) and change-point detection(Chen et al., 2023) in neuroscience applications.We also expect the model-based similarity mosteffective for capturing model differences will besystem and task dependent (Eaton et al., 2008; Za-mir et al., 2018; Helm et al., 2020). Josh Achiam, Steven Adler, Sandhini Agarwal, LamaAhmad, Ilge Akkaya, Florencia Leoni Aleman,Diogo Almeida, Janko Altenschmidt, Sam Altman,Shyamal Anadkat, et al. 2023. Gpt-4 technical report.arXiv preprint arXiv:2303.08774.",
  "Avanti Athreya, Zachary Lubberts, Youngser Park, andCarey E Priebe. 2022. Discovering underlying dy-namics in time series of networks. arXiv preprintarXiv:2205.06877": "Yoshua Bengio, Jean-francois Paiement, Pascal Vin-cent, Olivier Delalleau, Nicolas Roux, and MarieOuimet. 2003.Out-of-sample extensions for lle,isomap, mds, eigenmaps, and spectral clustering. Ad-vances in neural information processing systems, 16. Stella Biderman, Hailey Schoelkopf, Quentin GregoryAnthony, Herbie Bradley, Kyle OBrien, Eric Hal-lahan, Mohammad Aflah Khan, Shivanshu Purohit,USVSN Sai Prashanth, Edward Raff, et al. 2023.Pythia: A suite for analyzing large language mod-els across training and scaling.In InternationalConference on Machine Learning, pages 23972430.PMLR. Levin Brinkmann, Fabian Baumann, Jean-FranoisBonnefon, Maxime Derex, Thomas F. Mller,Anne-Marie Nussberger, Agnieszka Czaplicka, Al-berto Acerbi, Thomas L. Griffiths, Joseph Hen-rich, Joel Z. Leibo, Richard McElreath, Pierre-Yves Oudeyer, Jonathan Stray, and Iyad Rahwan.2023. Machine culture. Nature Human Behaviour,7(11):18551868.",
  "Guodong Chen, Hayden S Helm, Kate Lytvynets, Wei-wei Yang, and Carey E Priebe. 2022. Mental stateclassification using multi-graph features. Frontiersin Human Neuroscience, 16:930291": "Tianyi Chen, Youngser Park, Ali Saad-Eldin, ZacharyLubberts, Avanti Athreya, Benjamin D Pedigo,Joshua T Vogelstein, Francesca Puppo, Gabriel ASilva, Alysson R Muotri, et al. 2023. Discovering achange point in a time series of organoid networksvia the iso-mirror. arXiv preprint arXiv:2303.04871. Yun-Shiuan Chuang, Agam Goyal, Nikunj Harlalka,Siddharth Suresh, Robert Hawkins, Sijia Yang, Dha-van Shah, Junjie Hu, and Timothy T Rogers. 2023.Simulating opinion dynamics with networks of llm-based agents. arXiv preprint arXiv:2311.09618.",
  "Hayden Helm, Carey E Priebe, and Weiwei Yang. 2023.A statistical turing test for generative models. arXivpreprint arXiv:2309.08913": "Hayden S Helm, Ronak D Mehta, Brandon Duder-stadt, Weiwei Yang, Christoper M White, Ali Geisa,Joshua T Vogelstein, and Carey E Priebe. 2020. Apartition-based similarity for classification distribu-tions. arXiv preprint arXiv:2011.06557. John Jumper, Richard Evans, Alexander Pritzel, TimGreen, Michael Figurnov, Olaf Ronneberger, KathrynTunyasuvunakool, Russ Bates, Augustin dek, AnnaPotapenko, et al. 2021.Highly accurate pro-tein structure prediction with alphafold.Nature,596(7873):583589. James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz,Joel Veness, Guillaume Desjardins, Andrei A Rusu,Kieran Milan, John Quan, Tiago Ramalho, Ag-nieszka Grabska-Barwinska, et al. 2017.Over-coming catastrophic forgetting in neural networks.Proceedings of the national academy of sciences,114(13):35213526.",
  "Marios Papachristou and Yuan Yuan. 2024. Networkformation and dynamics among multi-llms. Preprint,arXiv:2402.10659": "Joon Sung Park, Joseph OBrien, Carrie Jun Cai, Mered-ith Ringel Morris, Percy Liang, and Michael S Bern-stein. 2023. Generative agents: Interactive simulacraof human behavior. In Proceedings of the 36th An-nual ACM Symposium on User Interface Softwareand Technology, pages 122. Jrmy Perez, Corentin Lger, Marcela Ovando-Tellez,Chris Foulon, Joan Dussauld, Pierre-Yves Oudeyer,and Clment Moulin-Frier. 2024. Cultural evolutionin populations of large language models. Preprint,arXiv:2403.08882. Alec Radford, Jong Wook Kim, Tao Xu, Greg Brock-man, Christine McLeavey, and Ilya Sutskever. 2023.Robust speech recognition via large-scale weak su-pervision. In International Conference on MachineLearning, pages 2849228518. PMLR.",
  "Warren S Torgerson. 1952. Multidimensional scaling: I.theory and method. Psychometrika, 17(4):401419": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023.Llama 2:Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288. Joshua T Vogelstein, Hayden S Helm, Ronak DMehta, Jayanta Dey, Weiwei Yang, Bryan Tower,Will LeVine, Jonathan Larson, Chris White, andCarey E Priebe. 2020.A general approach toprogressive learning.Preprint at",
  "Fangxin Wang, Miao Zhang, Xiangxiang Wang, Xiao-qiang Ma, and Jiangchuan Liu. 2020a. Deep learningfor edge computing applications: A state-of-the-artsurvey. IEEE Access, 8:5832258336": "Wenhui Wang, Furu Wei, Li Dong, Hangbo Bao, NanYang, and Ming Zhou. 2020b. Minilm: Deep self-attention distillation for task-agnostic compressionof pre-trained transformers. Advances in Neural In-formation Processing Systems, 33:57765788. Thomas Wolf, Lysandre Debut, Victor Sanh, JulienChaumond, Clement Delangue, Anthony Moi, Pier-ric Cistac, Tim Rault, Rmi Louf, Morgan Funtow-icz, Joe Davison, Sam Shleifer, Patrick von Platen,Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,Teven Le Scao, Sylvain Gugger, Mariama Drame,Quentin Lhoest, and Alexander M. Rush. 2020. Hug-gingfaces transformers: State-of-the-art natural lan-guage processing. Preprint, arXiv:1910.03771. Amir R Zamir,Alexander Sax,William Shen,Leonidas J Guibas, Jitendra Malik, and SilvioSavarese. 2018.Taskonomy: Disentangling tasktransfer learning. In Proceedings of the IEEE con-ference on computer vision and pattern recognition,pages 37123722.",
  "AInstruction-tuningPythia-410m-deduped": "The base model that we used in the case studies in was an instruction-tuned version of the410 million parameter model from the Pythia suite(Biderman et al., 2023). For instruction-tuning, weadded three special tokens to its tokenizers vo-cabulary, ### End\", ### Instruction:\", and ###Response:\", and fine-tuned the model with a subsetof Databricks Dolly 15k (Conover et al., 2023).Each datum consists of an instruction, context, re-sponse, and category. We kept only data in theOpen QA, Brainstorm, General QA, and CreativeWriting categories and that had a response lengthless than 100 characters. This filtering left us with1559 instruction-response pairs. We formatted aparticular example as follows:",
  "BCase-study specific fine-tuning": "For each of the case studies we further fine-tunedthe instruction-tuned base model to promote re-sponse variation. For this, we used the data fromthe Yahoo! Answers (YA) dataset introduced in(Zhang et al., 2015), where each datum consistsof a topic, a question title, question content, a listof answers, and a best answer. Given data from aparticular topic, we further filtered the data by con-sidering only examples with best answers less than200 characters, with best answers that containedonly a single sentence, and with question titles thatcontained only a single question. We formatteddata from YA as follows:",
  "B.1Case Study 1: Stochastically EquivalentModels": "For case study 1, we randomly selected 400 exam-ples with the topic Society & Culture\" that weused as both the evaluation set in the experimentand as a pool of data used for further sampling.In particular, we randomly sampled 200 samplesfrom the set of 400 25 times and used the 25 sub-sets as fine-tuning data for different stochasticallyequivalent\" models.",
  "B.2Case Studies 2 & 3: Two classes": "For case studies 2 & 3, we considered filtered datafrom topics Society & Culture\" and Science &Mathematics\". For each topic we randomly sam-pled 1000 examples 10 times to use for fine-tuning.For case study 2, we randomly selected a singlemodel fine-tuned on Science & Mathematics\" tobe the adversarial model. This model was the ad-versarial model for all system instances. We thenrandomly selected 5 models fine-tuned on Society& Culture\" data to be non-adversarial models. Thenon-adversarial models changed with each systeminstance.For case study 3, we randomly selected 5 modelsfrom each class for every system instance."
}