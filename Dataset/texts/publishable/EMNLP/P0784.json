{
  "Abstract": "This study explores the effectiveness of LargeLanguage Models (LLMs) in creating person-alized mirror stories that reflect and resonatewith individual readers identities, addressingthe significant lack of diversity in literature. Wepresent MIRRORSTORIES, a corpus of 1,500personalized short stories generated by inte-grating elements such as name, gender, age,ethnicity, reader interest, and story moral. Wedemonstrate that LLMs can effectively incor-porate diverse identity elements into narratives,with human evaluators identifying personal-ized elements in the stories with high accuracy.Through a comprehensive evaluation involving26 diverse human judges, we compare the effec-tiveness of MIRRORSTORIES against genericnarratives. We find that personalized LLM-generated stories not only outscore generichuman-written and LLM-generated ones acrossall metrics of engagement (with average ratingsof 4.22 versus 3.37 on a 5-point scale), butalso achieve higher textual diversity while pre-serving the intended moral. We also provideanalyses that include bias assessments and astudy on the potential for integrating imagesinto personalized stories.1",
  "There is no greater agony than bearing an un-told story inside you. Maya Angelou": "Mirror books are stories that reflect the readersidentity, culture, and experiences, serving to en-gage, validate, and empower individuals (Bishop,1990).Such books are crucial in educationalsettings, fostering a sense of belonging and self-understanding through diverse narratives (Fleminget al., 2016), while also improving engagement andcomprehension (Walkington and Bernacki, 2014;Heineke et al., 2022). Beyond education, person-alized narratives have shown potential in various",
  "Interactive web application and corpus are publicly avail-able at mirrorstories.me": "fields, including health communication and market-ing, where they enhance patient understanding andadherence, and strengthen emotional connectionsbetween brands and consumers (Galitsky, 2024;Babatunde et al., 2024).Despite the profound need for these personalizednarratives, there is a noticeable underrepresentationof non-white minority groups in literature (CCBC,2021) relative to their population size, detailed inAppendix . The gap in cultural represen-tation highlights the need for more inclusive narra-tives that reflect diverse reader identities, enhanceempathy, and promote cultural awareness (Hoyttet al., 2022). Diversity in literature can lead to im-proved innovation and a broader consideration ofideas, ultimately enriching the reading experiencefor all (Phillips, 2014).Advancements in natural language processing,particularly through the development of LLMs likeGPT-4, PaLM, and LLaMA have introduced thepotential to address these gaps on a large scale(OpenAI, 2023; Chowdhery et al., 2022; Touvronet al., 2023). LLMs excel in generating human-like text and adapting content to various contextualneeds (Brown et al., 2020; Zhao et al., 2023).Recent studies have investigated LLMs capa-bilities in expressing personality within generatedcontent (Li et al., 2024; Jiang et al., 2024) and de-veloping methods to induce and edit personalityexpressions in LLM outputs (Jiang et al., 2023; Liet al., 2024; Mao et al., 2024). New benchmarkshave also been released to assess personality traitsin LLM outputs (Jiang et al., 2023; Wang et al.,2024). However, there remains a gap in researchconcerning whether LLMs can generate contentthat incorporates identity traits and faithfully mir-rors the diverse identities of a global readership.Our study addresses this gap by exploring the po-tential of LLMs to create mirror storiesnarrativesthat genuinely reflect and resonate with the identi-ties of individual readers. We present a framework",
  ": Generation and evaluation process for human-written generic, LLM-generated generic, and LLM-generatedpersonalized narratives": "that evaluates the effectiveness of LLM-generatedmirror stories in comparison to traditional narra-tives, assessing their impact on engagement, satis-faction, and the perception of personal relevance(see ). Our contributions are three-fold: 1. We release MIRRORSTORIES, a corpus of1,500 personalized short stories generated byintegrating elements such as name, gender,age, ethnicity, reader interest, and moral ofthe story. We demonstrate that LLMs can ef-fectively incorporate identity elements intonarratives, with human evaluators identifyingthem in the stories with high accuracy. 2. Through a comprehensive evaluation involv-ing 26 diverse human judges, personalizedLLM-generated stories consistently outper-form both generic human-written and LLM-generated stories across all engagement met-rics, with a significantly higher average rating. 3. We present analyses that assess text diversity,coherence, and moral comprehension acrosseach story type, and examine biases exhibitedby LLMs when evaluating personalized narra-tives. We also explore the potential of integrat-ing images and incorporate MIRRORSTORIESinto an interactive web application whereusers can browse and generate stories.",
  "MIRRORSTORIES is a corpus designed to evalu-ate the ability of LLMs to generate both generic": "and personalized short narratives based on prede-fined morals and identity elements. Each datasetinstance consists of a moral (e.g., Kindness isnever wasted) guiding the narratives tone and aset of identity elements (name, age, gender, ethnic-ity, and personal interest) to personalize the story.Specifically, the dataset includes a human-writtenand an LLM-generated generic story, both of whichdo not incorporate specific identity elements, andan LLM-generated personalized story that includesthese elements to enhance relevance and engage-ment. Appendix A.5 provides a detailed exampleof the dataset structure.",
  "Human-writtenStories&MoralsMIR-": "RORSTORIES incorporates human-written storiesderived from Aesops fables (Wier et al., 1890)2,a well-known collection famous for its clearnarrative structure and explicit moral conclusions.The morals serve as guides for generating bothgeneric and personalized stories. The complete listof morals is provided in Appendix A.5 . IdentitiesIdentity traits such as name, age, gen-der, ethnic background, and interests are includedto personalize the narratives. We drew from 123unique ethnic backgrounds, 124 diverse interests,and 28 distinct morals. The complete set of identi-ties is provided in Appendix A.5 .",
  ": Illustration demonstrating the personalization validation and impact processes": "on the moral, while personalized stories addition-ally integrate the specified identity elements. Forthe specific prompts, refer to . GPT-4 (ver.0613), Claude-3 Sonnet3, and Gemini 1.5 Flash(Reid et al., 2024) were used, each responsible forgenerating one-third of the narratives.MIRRORSTORIES comprises 1,500 narrativeswith an almost even split between male and femalecharacters. The dataset spans a broad age rangefrom 10 to 60 years. Detailed illustrations of thedistributions are in Appendix A.1 Figures 9 and 10.",
  "Experiments": "We conducted two experiments to assess the ef-fectiveness of personalization in LLM-generatedstories: Personalization Validation, which validatesthe integration of identity elements within the nar-ratives, and Personalization Impact, which assessesthe impact of these narratives on user engagement,comprehension, satisfaction, and personalness. PromptsIn both experiments,personalizedprompts incorporating identity elements were usedto generate personalized stories. For Personaliza-tion Validation, these elements were specificallyasked not to be stated explicitly, to test their seam-less integration into the narrative. In the Personal-ization Impact experiment, personal elements werealigned with those of 26 human evaluators, en-suring that each story was tailored to evaluators. and 2 provide detailed structures of theprompts for both generation and evaluation. Human EvaluationIn both experiments, thesame 26 human evaluatorsall students from di-verse disciplineswere tasked with evaluating thenarratives (for demographic details, see Appendix). For the Personalization Validation, theyanswered a structured questionnaire for a randomsample of 30 stories to identify the personalized elements. In the Personalization Impact test, eachevaluator reviewed a human-written, generic LLM-generated, and personalized LLM-generated story,with the personalized LLM-generated story specifi-cally tailored to reflect their personal identity. Theyprovided feedback on all three story types, ratingthem on satisfaction, quality, engagement, and per-sonalness. The detailed questionnaire is providedin Appendix A.2. ModelsGPT-4 (ver. 0613, temperature 0.4) wasused as an evaluator in both experiments. Initially,it assessed the integration of personalized elements.Later, it was used to evaluate the stories for satisfac-tion, quality, engagement, and personalness, witha sample of the evaluation process and promptsprovided in Appendix . GPT-4 was chosenfor its increasing adoption as an evaluator acrossdomains (Gilardi et al., 2023; Tarkka et al., 2024;Malik et al., 2024), with potential advantages suchas scalability, cost-efficiency, and consistency.",
  "Results": "Are MIRRORSTORIES personalized?The ef-fectiveness of personalization in MIRRORSTORIESis evident from the high accuracy rates in identi-fying identity elements by both human and LLMevaluators. As shown in , human evalua-tors were particularly adept at identifying genderand ethnicity with accuracies at 100% and 94%,respectively. Similarly, GPT-4 showed robust per-formance, matching or exceeding human accuracyin all categories, which confirms the high level ofpersonalization achieved in the narratives.Personalized LLM-generated stories also effec-tively incorporate both the provided moral and thereaders interests, with a stronger emphasis on themoral. To demonstrate this, we used BERTopic(Grootendorst, 2022) for topic modeling to iden-tify the top five terms for each story. We then",
  ": Number of correctly identified morals for eachstory type, excluding N/A responses": "calculated cosine similarity using Word2Vec em-beddings4 (Mikolov et al., 2013) between these topterms and the provided interest and moral. Theaverage cosine similarity was 0.12 for the providedinterest and 0.27 for the moral, demonstrating abalance between incorporating the readers interestand maintaining the intended moral.5 A detailedsample of the top terms identified for each story isprovided in Appendix .",
  ": The Shannon Diversity Index (SDI) values forall story types. Values are statistically significant (p <0.01), as determined by a one-way ANOVA": "type of story, or provide N/A if they could not.We manually assessed the evaluators responses tothe intended morals. Excluding N/A responses,the correctly identified morals are detailed in . The results indicate that differences in moralidentification across story types are not statisticallysignificant, demonstrating that adding personaliza-tion did not negatively affect the models ability toconvey the intended moral. A sample of evaluatorresponses is shown in Appendix . What is the impact of personalization on textualdiversity?We analyzed how personalization ele-ments impact textual diversity using the ShannonDiversity Index (SDI). shows that person-alized stories achieve the highest SDI among allstory types. Including a single personalization ele-ment, such as the interest element, also increasesSDI compared to generic and human-written sto-ries with the same moral. Additionally, we ob-served that increasing GPT-4s temperature nega-tively affects the diversity and coherence of genericLLM-generated stories. At a temperature of 1.2,the stories showed increased diversity but began tolose coherence. Further increasing the temperatureto 1.5 resulted in nonsensical outputs.",
  ": Average ratings by GPT-4 across gender": "Are there biases in LLM evaluations of person-alized stories?We found several preferential bi-ases in GPT-4s evaluation results. showsan instance of gender-based bias, with stories fea-turing non-binary characters receiving the highestpersonalness ratings, while those with male char-acters rated lower in quality and engagement. Eth-nic background also influences evaluations, withNorwegian and Japanese characters rated higheracross all metrics (Appendix ). We alsoobserved inter-model preferential biases across thethree models used for generating personalized sto-ries, with Claude-3 consistently receiving higherratings compared to GPT-4 and Gemini-1.5. Anoverview of all bias results is provided in AppendixA.3.1.",
  "Extended Analyses": "Qualitative comparison of human and LLMevaluationsWe examine cases where human andLLM evaluators either contradict or agree on thescores assigned to stories, providing insights intothe differences in evaluations and preferences forvarious types of stories. Examples of these cases,highlighting instances of both agreement and dis-agreement between human and LLM evaluators,are presented in Appendix . Image generation for personalized storiesWeexplored the potential of incorporating images intostories to enhance engagement and representation.The image generation and evaluation processesare detailed in Appendix . Notably, hu-man evaluators show a high accuracy in identifyingpersonalized elements in the images generated byDALLE 2 (Ramesh et al., 2022), with gender andinterest being recognized with 100% and 95% ac-curacy, respectively (Appendix ). Correlation between human and LLM evalua-torsCorrelation analysis revealed a low to moder-ate alignment between human evaluators and GPT-4 in story evaluation metrics. GPT-4 aligned moreclosely with human evaluators on quality across allstory types (correlations 0.22-0.47), but showed theweakest correlation in assessing personalness, par-ticularly for personalized stories (as low as 0.08).This suggests that while GPT-4 is increasingly usedfor various evaluation tasks, its effectiveness in as-sessing subjective aspects of creative tasks is lim-ited. A detailed analysis of these correlations andtemperature variations is presented in AppendixA.4.2, and .",
  "Related Work": "Our study builds on research on the effectivenessof personalized narratives in engaging readers andimproving learning outcomes (Zhang et al., 2024;Pennebaker and Graybeal, 2001; Hirsh and Peter-son, 2009). We extend this work by examining howLLMs can generate personalized narratives to in-crease reader engagement and satisfaction. Whilepromising, the accuracy of personal traits in gen-erated content remains challenging, with studiesshowing mixed results (Jiang et al., 2024; Bhan-dari and Brennan, 2023). Concurrently, LLM ex-ploration in narrative generation has focused onimproving coherence and depth (Andreas, 2022;Shen and Elhoseiny, 2023; El-Refai et al., 2024;Gmez-Rodrguez and Williams, 2023). To assessthese advancements, recent evaluative techniquesfor narrative systems emphasize user interactionsand alignment metrics between visual content andnarratives (El-Refai et al., 2024; Ning et al., 2023).",
  "Conclusion": "Our study demonstrates the potential of LLMs ingenerating personalized narratives that effectivelyincorporate diverse identity elements and enhancereader engagement compared to generic stories.MIRRORSTORIES consists of 1,500 personalizedstories that consistently outperform generic ones onkey metrics. By making MIRRORSTORIES publiclyavailable and integrating it into an interactive webapplication, we aim to encourage further researchon personalized narrative generation, contributingto more engaging and inclusive content. Futurework could explore out-group perceptions of thesenarratives, broadening our understanding of person-alizations impact across diverse audiences.",
  "Limitations": "Story Constraints:To maintain consistency andfeasibility within the scope of our study, we im-posed certain constraints on the stories generated,such as limiting the length to 250-300 words andfocusing on a specific set of morals. While theseconstraints allowed for a controlled comparison be-tween personalized and generic stories, they maynot fully capture the potential of LLMs in generat-ing longer, more complex narratives or exploring awider range of themes and morals. Future researchcould investigate the impact of personalization onstories of varying lengths and themes to gain a morecomprehensive understanding of how these factorsinfluence reader engagement and satisfaction. Demographic Diversity:While our study aimedto include a diverse range of identities and back-grounds, the demographic diversity of our humanevaluators was by no means the perfect sample ofglobal readership. The majority of our evaluatorswere university students, which may not be repre-sentative of the broader population. Future researchshould include a more diverse pool of evaluatorsacross age, education, and cultural backgrounds toensure the generalizability of the findings and tocapture a wider range of perspectives on personal-ized storytelling. Scope of Personalization:Our study primarilyexamined personalization factors like age, gender,interests, and ethnic background. However, aspectssuch as personality traits, emotional resonance, andnarrative preferences were not extensively investi-gated but could notably enhance engagement andnarrative impact. For example, aligning story el-ements with reader emotional responses or tailor-ing narratives to specific preferences like mystery,romance, or adventure could significantly boostsatisfaction and engagement. Subjectivity of Evaluation:Another limitationof our study is the inherent subjectivity involvedin evaluating the impact of personalized stories.Despite our attempts to standardize evaluation cri-teria and maintain consistency among evaluators,individual preferences, biases, and interpretationscan still significantly influence the outcomes. Thissubjectivity can lead to variability in how differ-ent evaluators perceive and rate the same narrativeelements.",
  "Model Selection and Variety:Our study utilizedGPT-4, Claude3, Gemini-1.5, and DALLE 2 for": "generating and evaluating narratives and images.This limited selection may affect the generalizabil-ity of our findings, as different models might pro-duce or assess stories differently based on theirtraining data and algorithms. Expanding future re-search to include a variety of models, includingopen-source ones, could provide a more compre-hensive understanding of how different languagemodels handle personalization in storytelling andevaluate narrative elements.",
  "Ethical Considerations": "We followed strict ethical standards throughout ourresearch to ensure validity and fairness. Consentand transparency were central to our approach, withall participants fully informed and providing ex-plicit consent. We also ensured compliance withintellectual property rights by using Aesops fables,which are in the public domain. Data Privacy and Security:Ensuring the pri-vacy and security of participants personal infor-mation was a top priority. We collected and usedpersonal details such as age, gender, interests, andethnic background to generate personalized sto-ries. Robust data protection measures were imple-mented, including secure storage, anonymization,and restricted access to sensitive information. Par-ticipants were informed about how their data wouldbe used, stored, and protected. Potential Misuse and Unintended Consequences:While personalized storytelling has the potential toenhance engagement and representation, we care-fully considered the potential for misuse or unin-tended consequences. To mitigate risks such asthe manipulation of individuals emotions or thereinforcement of stereotypes, we implemented safe-guards against harmful content and regularly au-dited the generated stories for potential biases orinappropriate themes. Inclusivity and Representation:When generat-ing personalized stories, we strived to ensure thatthe stories were inclusive and representative of di-verse identities and experiences. This includedconsidering factors such as race, ethnicity, genderidentity, sexual orientation, disability, and socioe-conomic status. We aimed to create stories thatwere respectful, authentic, and empowering for allindividuals, avoiding stereotypes and promotingpositive representation.Accountability and integrity were paramount in reporting our results, including limitations and im-plications. Additionally, every narrative generatedby LLMs underwent a thorough review to maintainquality and appropriateness, enhancing the reliabil-ity of our findings and participant well-being.",
  "Prabin Bhandari and Hannah Marie Brennan. 2023.Trustworthiness of children stories generated by largelanguage models. arXiv preprint arXiv:2308.00073": "Rudine Sims Bishop. 1990. Mirrors, windows, and slid-ing glass doors. perspectives: Choosing and usingbooks for the classroom, 6 (3). Perspectives: Choos-ing and using books for the classroom, 6(3):ixxi. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shotlearners. Advances in neural information processingsystems, 33:18771901.",
  "Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal,Deb Roy, and Jad Kabbara. 2024. Personallm: In-vestigating the ability of large language models toexpress personality traits": "Tianlong Li, Shihan Dou, Changze Lv, Wenhao Liu,Jianhan Xu, Muling Wu, Zixuan Ling, XiaoqingZheng, and Xuanjing Huang. 2024.Tailoringpersonality traits in large language models viaunsupervisedly-built personalized lexicons. Usman Malik, Simon Bernard, Alexandre Pauchet, Cl-ment Chatelain, Romain Picot-Clmente, and JrmeCortinovis. 2024. Pseudo-labeling with large lan-guage models for multi-label emotion classificationof french tweets. IEEE Access, 12:1590215916.",
  "Shengyu Mao, Xiaohan Wang, Mengru Wang, YongJiang, Pengjun Xie, Fei Huang, and Ningyu Zhang.2024. Editing personality for large language models": "Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-rado, and Jeff Dean. 2013. Distributed representa-tions of words and phrases and their compositionality.In Advances in Neural Information Processing Sys-tems, volume 26. Curran Associates, Inc. Munan Ning, Yujia Xie, Dongdong Chen, Zeyin Song,Lu Yuan, Yonghong Tian, and Qixiang Ye. 2023.Album storytelling with iterative story-aware cap-tioning and large language models. arXiv preprintarXiv:2305.12943.",
  "XiaoqianShenandMohamedElhoseiny.2023.Storygpt-v: Large language models as consistentstory visualizers. arXiv preprint arXiv:2402.03483": "Otto Tarkka, Jaakko Koljonen, Markus Korhonen, Ju-uso Laine, Kristian Martiskainen, Kimmo Elo, andVeronika Laippala. 2024. Automated emotion an-notation of Finnish parliamentary speeches usingGPT-4. In Proceedings of the IV Workshop on Creat-ing, Analysing, and Increasing Accessibility of Parlia-mentary Corpora (ParlaCLARIN) @ LREC-COLING2024, pages 7076, Torino, Italia. ELRA and ICCL. Hugo Touvron, Thibaut Lavril, Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Rozire, Naman Goyal, Eric Hambro,Faisal Azhar, et al. 2023. Llama: Open and effi-cient foundation language models. arXiv preprintarXiv:2302.13971.",
  "H. Wier, J. Tenniel, and E.H. Griset. 1890. Aesops Fa-bles: A New Revised Version from Original Sources.Worthington, Company": "Chao Zhang, Xuechen Liu, Katherine Ziska, SoobinJeon, Chi-Lin Yu, and Ying Xu. 2024. Mathemyths:Leveraging large language models to teach mathe-matical language through child-ai co-creative story-telling. In Proceedings of the CHI Conference onHuman Factors in Computing Systems, pages 123,New York, NY, USA. ACM. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,Xiaolei Wang, Yupeng Hou, Yingqian Min, BeichenZhang, Junjie Zhang, Zican Dong, Yifan Du, ChenYang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu,Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. Asurvey of large language models.",
  "GPT-4 as an Evaluator": "Sample GPT-4 INPUT:You are ANDRII, a MALE character, aged 25, of RUSSIAN ethnicity, with an interest in WRESTLING. As an evaluator,evaluate the story based on the following metrics:METRICS:SATISFACTION: How would you rate your overall satisfaction with the story?1 (BAD): The story did not meet any expectations, had significant flaws in plot, character development, or other keyareas, and provided little to no enjoyment or value.5 (GOOD): The story exceeded all expectations, was exceptional in most if not all aspects.QUALITY: How would you rate the quality of the story? ... STORY:In the heart of Moscow lived Andrii, a 25-year-old whose heart and soul were intertwined with the art of wrestling.Every morning, before the first ray of sunlight kissed the domes of Saint Basils Cathedral ... Sample GPT-4 OUTPUT:I would rate my overall satisfaction with the story a 5. The unexpected turn in the plot, well-developed character, and theconsistent twists kept me engaged, and the story exceeded all my expectations.I would rate the quality of content of the story a 4. The intertwining of fiction and reality, the character ...",
  "Behzad 23MaleBoxingIndianLearnfromyourmistakes": "Behzad, a sturdy 23-year-old Indian man,was far more attached to his boxing glovesthan his engineering textbooks. Son of amechanic, his life was perched comfort-ably on the rusty edges of Mumbai, lit upby the lambent moon by night and the in-truding sun by day. Unlike his peers, Be-hzad wasnt fascinated by the jingling callof corporate ladders; instead, he ...",
  "GenderMale, Female, Non-binary": "EthnicityAlbanian, Arab, Arab-Amazigh, Armenian, Australian, Austrian, Akan, An-dorran, Azerbaijani, Bambara, Belarusian, Bengali, Baganda, Bosnian, PardoBrazilian, Bosniak, British, Bulgarian, Canadian, Chechen, Chinese, Congolese,Croat, Czech, Dane, Dutch, Egyptian, Emirati, Estonian, Fijian, Finn, Geor-gian, German, Greek, Hawaiian, Hungarian, Indian, Indonesian (Javanese), IraqiArab, Irish, Italian, Japanese, Jewish, Jordanian, Kazakh, Korean, Kikuyu, Kur-dish, Kuwaiti, Kyrgyz, Latvian, Lithuanian, Luxembourger, Malay, Maldivian,Maltese, Maori, Mestizo, Moldovan, Norwegian, Punjabi, Palestinian, Persian,Polish, Portuguese, Romanian, Russian, Hutu, Salvadoran, Scottish, Serb, Slo-vak, Slovene, Somali, Spanish, Sudanese, Swede, Swiss, Syrian, Tajik, Thai,Turk, Turkmen Ukrainian, Uzbek, Vietnamese (Viet), Welsh, Wolof. InterestActing, Archery, Arts, Astronomy, Badminton, Bagpiping, Baking, Ballet, Base-ball, Basketball, Beadwork, Beekeeping, Biology, Biking, Blogging, Board,Bonsai, Boxing, Calligraphy, Camping, Canoeing, Carpentry, Chess, Coding,Community Service, Cooking, Crafting, Cricket, Culinary, Cycling, Dancing,Digital, Drawing, Drumming, Embroidery, Falconry, Farming, Fashion, Fenc-ing, Filmmaking, Fishing, Football, Foraging, Gardening, Geography, Graphicdesign, Guitar, Gymnastics, Hiking, History, Hockey, Horseback, Ice, Ikebana,Judo, K-Pop, Kayaking, Kendo, Kickboxing, Kite Flying, Knitting, Literature,Jewelry Making, Martial Arts, Massage, Meditation, Mountaineering, Music,Painting, Papercraft, Parkour, Photography, Piano, Pilates, Poetry, Politics,;Pottery, Quilting, Reading, Respect, Riding, Robotics, Rock Climbing, Rowing,Rugby, Running, Sailing, Sculpting, Science, Sewing, Skateboarding, Skydiv-ing, Skiing, Singing, Social Activities, Soccer, Sprinting, Storytelling, Surfing,Swimming, Taekwondo, Table, Tango, Teaching, ennis, Traveling, Trekking,Video Games, Violin, Volleyball, Volunteering, Weaving, Weightlifting, Wine-making, Woodworking, Wrestling, Writing, Yoga. MoralMaintain humility, Learn from your mistakes, Be optimistic, Show empathy,Be loyal, Work hard and stay humble, Live with purpose, Take responsibilityfor your actions, Always tell the truth, Cherish your family, Be generous, Keepyour promises, Treat others as you want to be treated, Be a good listener, Be fairand just, Live with integrity, Protect the weak and vulnerable, Seek justice, Becurious and keep learning, Be grateful, Have courage, Help those in need, Strivefor excellence, Have respect for yourself and others, Practice good manners,Embrace diversity, The race is not always to the swift, A kindness is neverwasted, Liars are not believed even when they speak the truth."
}