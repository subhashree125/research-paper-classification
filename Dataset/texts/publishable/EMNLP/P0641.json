{
  "Abstract": "Multilingual large language models (LLMs)often have knowledge disparities across lan-guages, with larger gaps in under-resourced lan-guages. Teaching LLMs to abstain in the faceof knowledge gaps is thus a promising strat-egy to mitigate hallucinations in multilingualsettings. However, previous studies on LLMabstention primarily focus on English; we findthat directly applying these solutions beyondEnglish results in up to 20.5% performancegaps between high and low-resource languages,potentially due to LLMs drop in calibrationand reasoning beyond a few resource-rich lan-guages. To this end, we propose strategies toenhance LLM abstention by learning from mul-tilingual feedback, where LLMs self-reflect onproposed answers in one language by gener-ating multiple feedback items in related lan-guages: we show that this helps identify theknowledge gaps across diverse languages, cul-tures, and communities. Extensive experimentsdemonstrate that our multilingual feedback ap-proach outperforms various strong baselines,achieving up to 9.2% improvement for low-resource languages across three black-box andopen models on three datasets, featuring open-book, closed-book, and commonsense QA. Fur-ther analysis reveals that multilingual feedbackis both an effective and a more equitable abstainstrategy to serve diverse language speakers, andcultural factors have great impact on languageselection and LLM abstention behavior, high-lighting future directions for multilingual andmulti-cultural reliable language modeling.1",
  ": Average accuracy of abstention baselines inlow- and high-resource languages with AYA-13B. Ex-isting abstain strategies drop by 8.4% on averagewhen applied to QA in low-resource languages": "that compromises LLM reliability (Lazaridou et al.,2021; Ji et al., 2023; Kumar et al., 2023; Mishraet al., 2024). A growing body of work seeks to en-hance LLM reliability by teaching them to abstain,i.e., avoiding wrong answers in low-confidencescenarios to mitigate hallucinations and factual in-accuracies. While these studies put forward vi-able solutions, they are evaluated on English only(Gu and Hopkins, 2023; Varshney and Baral, 2023;Yang et al., 2023; Feng et al., 2024). However, thefactuality of multilingual LLMs in low-resourcelanguages is often worse (Zhang et al., 2023b; Laiet al., 2023; Kang et al., 2024), underserving di-verse language speakers and communities. As such,there is an urgent need for robust abstaining strate-gies that work with the long tail of languages.Developed and evaluated in English, are exist-ing abstain approaches viable for low-resource lan-guages? Drawing from Feng et al. (2024), we firstevaluate seven existing abstain methods, spanningcalibration (Jiang et al., 2021; Tian et al., 2023),prompting (Edunov et al., 2018; Kadavath et al.,2022; Feng et al., 2023), and training (Ouyanget al., 2022), on multilingual MMLU and Hel- laswag datasets (Lai et al., 2023) featuring 8 high-resource and 7 low-resource languages. demonstrates that performance degrades by up to12.8% and 20.5% for both datasets: while existingapproaches perform well in English, they are lim-ited by LLMs diminishing utility and calibrationaccuracy in low-resource languages, struggling toidentify knowledge gaps and abstain accordingly.As a result, we ask: how to identify knowledge gapsin LLMs and reliably abstain beyond English? To this end, we present the first study on mul-tilingual LLM abstention and propose to teachLLMs to abstain by generating and learning frommultilingual feedback in related languages (Fig-ure 2). While the concept of generated feedbackwas previously demonstrated to improve reasoningand alignment in English-only scenarios (Du et al.,2023; Madaan et al., 2024), sampling diverse andhigh-quality feedback in low-resource languagesis challenging due to LLMs diminishing utility inlong-tail languages (Lai et al., 2023). MultilingualLLMs can leverage related languages to improveperformance via transfer learning (Lin et al., 2019a;Pires et al., 2019; Asai et al., 2023; Tanwar et al.,2023), so we expect that generating feedback fromrelated languages would help identify knowledgegaps across diverse domains and cultures. There-fore, we probe multilingual LLMs to provide feed-back, on its proposed answer, in several relatedlanguages, where language relatedness is definedby linguistic typology, geography, or culture (Lit-tell et al., 2017; Lin et al., 2019b; Sun et al., 2021).Together with the proposed answer and generatedfeedback from the most related languages, LLMsreason and self-reflect to make abstain decisions. We evaluate baselines and our multilingual feed-back approach using three open-source and pro-prietary LLMs (GPT-4, Aya-13B, and ChatGPT)on three datasets in open-domain, closed-book,and commonsense QA. Extensive experimentsdemonstrate that multilingual feedback consistentlyoutperforms strong baselines across models anddatasets, achieving up to 9.2% improvements of ab-stain accuracy for low-resource languages. Furtheranalysis reveals that multilingual feedback presentsa more equitable abstain strategy, highlighting cul-ture as a driving factor in multilingual abstention.It impacts the optimal languages for feedback andLLMs performance gaps across diverse informa-tion domains.",
  "Methodology": "BackgroundWe focus on teaching LLMs to Ab-stain in Question Answering (AbstainQA) (Fenget al., 2024):given a query q and an LLM,we aim to develop robust abstention strategiesf(q, LLM) {true, false}. Ideally, the LLM ab-stains (f = true) when it would provide an in-correct answer and should not abstain (f = false)when it is capable of generating a correct answer(Feng et al., 2024). f should work for diverse lan-guages of varying language families, resourcenesslevels, and speaker communities.Since existing approaches to LLM abstention arelimited by LLMs diminishing utility and calibra-tion beyond English (, 1), we propose toteach LLMs to abstain via multilingual feedback,hypothesizing that self-feedback about its proposedanswer from related languages could help identifythe blind spots across cultures, perspectives, andcontexts. We present an overview in .",
  "Please review the proposed answer and provide aparagraph of feedback on its correctness. Feed-back should be in i. to elicit f i": "Finally, the LLM employs the multilingualfeedback to reason and make an abstain decision:LLM(q, a, {f 1, f 2, , f k}) {true, false}.We specifically use the prompt Based on thefeedback, is the proposed answer True or False?and abstain if the answer a is deemed false. Language SelectionContrary to English-onlyscenarios, it is often challenging to sample diverseand high-quality feedback in one low-resource lan-guage. We hypothesize that by generating feedbackin related languages to the language of the question, LLMs could better identify internal knowledgegaps and patch the blind spots with informationacross varying cultures, perspectives, and more.We experiment with four modes of selecting feed-back languages {1, , k}. monolingual, native (MONO-NATIVE): all feed-back are sampled in the native language of thequestion: 1 = = k = . This resembles theprevious English-only setting where questionsand feedback are in the same language (English). monolingual, English (MONO-ENGLISH):re-gardless of the language of the question, all feed-back are sampled in English: 1 = = k =English. This is because English is the highest-resource language and is often used as the sourcelanguage in cross-lingual transfer (Conneau et al.,2018; Conneau and Lample, 2019; Hu et al.,2020; Wang et al., 2020b). multilingual, random (MULTI-RANDOM): thisis a control setting where we employ multiplelanguages for feedback generation, but the lan-guages are randomly selected from a languagepool L: i = random_choice(L). multilingual, related (MULTI-RELATED):wepropose to employ languages related to the lan-guage of the question for feedback generation.Concretely, we employ Lang2vec (Littell et al.,2017) to obtain the vector representation of a lan-guage va in a linguistic attribute a A.2 Wedefine the distance between a pair of languages",
  "Experiment Settings": "ModelsWe evaluate existing approaches and thefour proposed monolingual/multilingual feedbackstrategies with three LLMs: Aya-13B, a specificallymultilingual instruction-tuned model, ChatGPTand GPT-4, two general-purpose black-box LLMs.We employ greedy decoding for QA and making anabstain decision, and employ a temperature of 0.7when sampling repeatedly (e.g., consistency-basedbaselines and feedback generation). DatasetsWe evaluate with the MultilingualMMLU(M-MMLU)andHellaswag(M-Hellaswag) datasets (Lai et al., 2023), featuringencyclopedicandcommonsenseknowledge.Originally in English, these QA problems weretranslated into 26 other languages through machinetranslation.These languages are characterizedas 8 high-resource languages, 11 mid-resourcelanguages, and 7 low-resource languages basedon their proportion in pretraining data.3 We alsopresent evaluation with Belebele (Bandarkar et al.,2023) in Appendix A, a multilingual readingcomprehension dataset.For the three datasets,we create random splits with 200 instances forvalidation and 800 for test, with minor variationacross languages due to data availability. BaselinesWe compare with nine abstain base-lines that could be adapted in multilingual set-tings: calibration-based PROBS (token probabil-ities), TEMP (Jiang et al., 2021), ASK CALI. (Tianet al., 2023); training-based INSTRUCT (Ouyanget al., 2022); prompting-based REFLECT (Ka-davath et al., 2022), MOREINFO (Feng et al.,2023), BACKTRANS (Edunov et al., 2018); andconsistency-based approaches SCTHRES. (Wanget al., 2022), CONFLICT (Feng et al., 2024). Moredetails about the baselines are in Appendix B.",
  "MULTI-RELATED .785 .752 .659 .730 .638 .674 .636 .659 .678.722 .532 .543 .706 .647 .610 .531 .572 .592": ": Performance of calibration, training, prompting, consistency, and our proposed feedback-based approacheson two LLMs and two multilingual datasets. We employ the Abstain Accuracy metric, Avg-H and Avg-L denoteaverage performance for high and low-resource languages, while we additionally present performance for the sevenlow-resource languages (Bengali, Tamil, Nepali, Malayalam, Marathi, Telugu, and Kannada). Best performance inbold and second-best in underline. Baselines that rely on token probabilities (e.g., Probs) are not compatible withGPT-4. MULTI-RELATED achieves the best average performance in low-resource languages across all modelsand datasets, improving over baselines by up to 9.2%. Evaluation MetricsWe use the Abstain Ac-curacy metric (A-Acc) proposed in Feng et al.(2024): LLMs should abstain when it would pro-vide an incorrect answer and should not abstainwhen it would provide a correct answer, concretelyA-Acc =TP+TN",
  "We present the abstain accuracy results with twoLLMs on two multilingual datasets in": "MULTI-RELATED achieves state-of-the-art per-formance.MULTI-RELATED achieves the high-est average performance on low-resource languages(Avg-L) across all four model and dataset set-tings, improving over the strongest baseline by4.9% on average. Out of the 7 low-resource lan- guages, MULTI-RELATED achieves the best and top-2 performance in 3.25 and 4.75 languages on aver-age. This improvement in low-resource languagescomes with on-par performance in high-resourcelanguages (Avg-H), outperforming baselines in81% of the times across four (model, dataset) set-tings. This indicates that by generating and re-flecting on multilingual feedback from related lan-guages, LLMs greatly improve in identifying inher-ent knowledge gaps across languages. Existing approaches greatly drop beyond high-resource languages.Ask for Calibration (Tianet al., 2023), an approach to solicit LLM confi-dence scores verbally, witness a 12.7% drop fromhigh to low-resource languages (0.613 0.486) onMMLU using AYA-13B. While it could generatemeaningful confidence scores between 0 and 1 forhigh-resource languages, it collapses and repeat-edly generate the same number (e.g., 0.8) for al- most all questions in low-resource languages. Sim-ilar performance gaps and failure modes could beobserved for previously strong approaches in En-glish such as Instruction Tuning (35.3% drop, onaverage), Self-Reflect (33.3%), and SCthreshold(12.2%). In comparison, MULT-RELATED has asmaller drop of 8.5%: we further quantify the fair-ness of abstain strategies in . Abstaining is a language-specific problem.Outof the seven low-resource languages, we observethat Tamil (ta) and Malayalam (ml) are consistentlythe most challenging languages across models,datasets, and approaches: an average performanceof 0.484 and 0.492 is achieved on the two lan-guages, while the global average for low-resourcelanguages is 0.520. This could be attributed to theirlow representation in LLM pretraining data (Laiet al., 2023) and thus lower utility, meaning thatthere is no one-size-fits-all solution for abstainingacross multilingual contexts and robust strategiesshould be language-specific.MULTI-RELATEDtakes linguistic knowledge into account by employ-ing related languages for feedback generation, suc-cessfully achieving the best Avg-L performanceacross all models and datasets. We further studythe utility of language relatedness in . AYA-13B shows smaller gaps than GPT-4.While the performance of MULTI-RELATED ishigher on GPT-4, the gap between low and high-resource languages is smaller with AYA-13B (1.7%vs. 16.9%). Since MULTI-RELATED specificallyrelies on generating and reasoning in multilin-gual contexts, the explicitly multilingual AYA-13Bwould be better than the general-purpose GPT-4 tothis end. This motivates a potential collaborationbetween models: using a stronger general-purposeLLM for QA and a smaller but explicitly multi-lingual LLM for feedback generation. We furtherexplore this in .",
  "Ld u,d =nL n": "where u denotes the utility/performance on lan-guage , n denotes the number of native speak-ers, the exponential = 1 indicates demographicweighted utility and = 0 indicates lingusticweighted utility where all languages are treatedas equals. For equity, performance on various lan-guages are sorted in non-decreasing order (ui ui+1) and the Gini coefficient is calculated:",
  "| L | +1 2|L|i=1(| L | +1 i)ui|L|i=1 ui": "where | L | indicates the total number of languages.The range of G is 0 to 1 and more equitable abstainstrategies should have lower G values.We present the demographic utility, linguisticutility, and equity metrics in .MULTI- RELATED outperforms baselines on both utilitymodes, while being more equitable across lan-guages, evident in the 12.9% reduction in Gini Co-efficient. On the contrary, MONO-ENGLISH haveon-par demographic utility but worse linguistic util-ity and equity, indicating that generated feedbackin English is unevenly helpful to other languages,whereas low-resource languages distant from En-glish benefit much less.",
  "Abstain Accuracy": "29.031.1 36.5 29.932.630.2 34.1 39.341.5 47.344.941.7 49.6 45.0 50.3 56.354.1 40.9 54.955.0 47.3 52.8 59.658.0 52.5 58.6 53.451.9 probabilityreflectmonolingual (ours)multilingual (ours) : Abstain accuracy in the cross-lingual retrieval setting, where English Wikipedia is employed for retrievalto aid QA in low-resource languages. Multilingual feedback consistently produces more accurate abstain decisionsin six of the seven low-resource languages.",
  ": GPT-4 evaluation of feedback pairs to thesame question, comparing MULTI-RELATED againstother feedback settings to evaluate which produces morerelevant and informative feedback": "parison, MULTI-RELATED produces 24.7% moreconflicting scenarios where feedback disagree incontent or conclusion: the abstain accuracy on con-flicting scenarios are also the highest, indicatingthat LLMs face more knowledge conflicts (Xieet al., 2023; Wang et al., 2023b) by generating mul-tiple feedback from related but different languages,which in turn aids self-reflection and making better-informed abstain decisions (Feng et al., 2024). Wefurther present a qualitative analysis in AppendixA in addition to the automatic GPT-4 evaluation. Culture is a driving factor in multilingual ab-stention.For MULTI-RELATED, we by defaultdefine language relatedness as the average of thesix linguistic attributes in Lang2vec (Littell et al.,2017). (2) We further investigate what aspectsof language relatedness are most helpful for ab-staining across multilingual contexts. Specifically,we additionally select related languages only byone of the six categories (e.g., syntactic or phono-logical relatedness). We introduce two additionalsettings: 1) LLMs are prompted to propose threerelated languages by themselves; 2) related lan-guages in the same culture cluster according to theWorld Value Survey.4 We present the performanceof various language relatedness settings in . We observe that geography and phonology arethe most helpful linguistic attributes, while culture-informed language selection yields the best utilityand equity results. This indicates that multilingualfeedback from languages of related socio-culturalbackgrounds is most helpful for low-resource lan-guages and overall fairness.To further investigate the impact of culture, we",
  "GENETIC0.64760.60240.49440.0839INVENTORY0.63710.58270.43560.0950FEATURAL0.64120.61160.44170.0916LLM-GENERATED0.63160.59290.43620.0981CULTURE0.64250.62020.53220.0438": ": Performance averages for high, mid, and low-resource languages, as well as the equity metric G forvarious language relatedness settings. Best performancein bold and second-best in underline. Culturally in-formed language selection is best for mid and low-resource languages and also more equitable. present the performance breakdown of variousMMLU domains in . We illustrate the10 domains with the largest gaps between low- andhigh-resource languages and 10 domains with theleast gaps. The largest gaps often come from west-centric topics such as US history, European his-tory, and US foreign policy, while the smallestgaps are often on STEM domains that transcendsocio-cultural contexts such as logical fallacies,high school physics, and electrical engineering.This again indicates that culture is a driving factorin multilingual abstention: improving LLM abstaincapabilities is not only a technical problem butalso a social-oriented one, where the existing West-centric LLMs (Naous et al., 2023) should betterincorporate other cultures and perspectives for eq-uitable improvements in factuality and reliability. Abstain decisions are less transferable acrossunrelated and low-resource languages.One so-lution to multilingual abstain is to take the highest-resource language (e.g., English), make abstain de-cisions, and use that decision to abstain/generate inlow-resource languages. However, to what extentdo abstain decisions overlap across languages andthus transferable remains underexplored, whichcould not be taken for granted given the factual-ity variation across languages (Lai et al., 2023;Kang et al., 2024). To this end, we visualize theabstain overlap of parallel questions across variousthree-language groups in , where overlap-ping parts indicate that MULTI-RELATED for 2 or3 languages decided to abstain. For control group#1, the group of three related languages sees muchgreater overlap (74.5% 2+ overlap) than the threeunrelated languages (48.1%). For control group",
  "SELF.752.659.730.638.674.636.659/.678OTHER.788.722.735.656.669.735.697/.715": ": Performance when using GPT-4 itself or theother AYA-13B multilingual LLM for feedback genera-tion. The collaboration between a general-purpose LLMfor QA and a smaller but more multilingual model forfeedback generation benefits low-resource languages. : Overlap of abstain decisions made in differ-ent languages, where the overlap indicates that LLMsabstain in both/all three of the languages. We find thatabstain decisions are only somewhat transferrablebetween relevant and high-resource language clus-ters. #2, a group of three high-resource languages seesgreater overlap (70.5%) than three low-resourcelanguages (48.4%). These two findings togetherindicate that abstain decisions are only somewhattransferable in the case of high-resource closelyrelated languages: however, many languages onthe long tail are neither close to English nor well-represented in LLM training data, thus English-only abstain methods are not one-size-fit-all solu-tions and abstaining is a language-specific problem.",
  "General-purpose LLMs could be supervised bya smaller but more multilingual model.Moti-vated by the finding that GPT-4 has higher absoluteperformance but Aya-13B witnesses smaller gaps": ": Abstain accuracy on various MMLU domains with high and low-resource languages: on the left we showthe 10 domains with the least performance gaps and on the right we show the 10 with the most gaps. hs indicateshigh school. While domains with the least gaps often feature STEM topics that are more objective, domainswith the largest gaps are often driven by culture, especially West-centric social knowledge. with MULTI-RELATED (4), we explore the collab-oration between the two models: using GPT-4 forquestion answering and Aya-13B for multilingualfeedback generation. demonstrates thatwhile for high-resource languages this might becounterproductive, for low-resource languages it re-sults in a 5.4% improvement on average. This indi-cates that when user queries come in low-resourceand underrepresented languages, a smaller but ex-plicitly multilingual model could be employed tosupervise general-purpose black-box LLMs to im-prove abstaining and mitigate hallucinations.",
  "Related Work": "Teaching LLMs to AbstainExisting works fo-cus on various types of approaches: Calibration-based approaches focus on eliciting the confidencelevels of LLMs with token probabilities (Sun et al.,2022; Zhou et al., 2023a; Liu et al., 2023a) or se-mantic markers of uncertainty (Kuhn et al., 2022;Zhou et al., 2023b, 2024), where previous researchevaluate (Radford et al., 2019; Ahuja et al., 2022;Liang et al., 2023; Tao et al., 2023; He et al.,2023) and improve (Kamath et al., 2020; Desaiand Durrett, 2020; Jagannatha and Yu, 2020; Konget al., 2020; Jiang et al., 2021; Lin et al., 2022a;Mielke et al., 2022) calibration for various tasks(Wang et al., 2020a; Stengel-Eskin and Van Durme,2023; Kalai and Vempala, 2023; Zablotskaia et al.,2023). Prompting-based approaches induce self-reflection by including none-of-the-above options(Kadavath et al., 2022), prompt to self-correct rea-soning (Kim et al., 2024; Shinn et al., 2023; Huanget al., 2023a; Chen et al., 2023), ask for addi-tional information (Feng et al., 2023), and more(Wang et al., 2023a; Si et al., 2023). Training- based approaches aim to adapt LLMs for absten-tion with linear probing (Slobodkin et al., 2023;Azaria and Mitchell, 2023), training an extra mod-ule (Cobbe et al., 2021), or alignment objectives(Zhang et al., 2023a; Yang et al., 2023; Sun et al.,2023; Bashlovkina et al., 2023; Huang et al., 2023b;Liu et al., 2023b). Consistency-based (Wang et al.,2022; Cole et al., 2023) and collaboration-basedapproaches (Feng et al., 2024) are also exploredto gauge LLM confidence through output varia-tion from a single model or knowledge variationacross multiple models. However, most existing ap-proaches were proposed and evaluated with Englishonly, while shows that multilingual absten-tion poses new challenges to existing solutions andleads to performance gaps based on language re-sourcesness. To mitigate this gap, we propose toteach LLMs to abstain by learning from multilin-gual feedback, where diverse feedback are gener-ated in related languages to enhance reliability andmake trustworthy abstain decisions. Multilingual FactualityWhile early factualitystudies were mostly conducted in English (Huanget al., 2023b; Zhang et al., 2023c; Ji et al., 2023),understanding and mitigating hallucinations be-yond English is increasingly important for LLMsto equitably serve diverse populations (Liu et al.,2022; Lai et al., 2023; Xu et al., 2023a,b; Qiet al., 2023; Schott et al., 2023; Kang et al., 2024;Gao et al., 2024). In multilingual summarization,metrics and evaluations are proposed to quantifyfactual errors and utility (Aharoni et al., 2022;Qiu et al., 2023; Clark et al., 2023). In machinetranslation, faithfulness across diverse languagesis also a critical concern (Lee et al., 2018; Rau-nak et al., 2021; Xu et al., 2023c; Dale et al., 2023a,b). A diverse range of models (Lin et al.,2022b; Muennighoff et al., 2023; Lai et al., 2023;stn et al., 2024), datasets (Artetxe et al., 2020;Clark et al., 2020; Longpre et al., 2021; Chalkidiset al., 2022; Gehrmann et al., 2022; Ebrahimi et al.,2022; Li et al., 2022; Asai et al., 2023; Ogundepoet al., 2023; Ahuja et al., 2023; Wang et al., 2024),and studies on multilingual transfer (Lin et al.,2019a; Pires et al., 2019; Wu and Dredze, 2019;Karthikeyan et al., 2019; Wu et al., 2022; Fujinumaet al., 2022; stn et al., 2022; Schmidt et al., 2022;Asai et al., 2023; Philippy et al., 2023; Tanwar et al.,2023; Reusens et al., 2023; Li et al., 2024b; Gaoet al., 2024) also contribute to the improvement ofLLM factuality and utility beyond English. In thiswork, we present the first study on LLM abstain-ing in multilingual contexts and make an importantstep toward improving the reliability of multilin-gual LLMs and mitigating hallucinations.",
  "Conclusion": "We propose to improve the reliability of multilin-gual LLMs by abstaining via multilingual feedback,where LLMs generate feedback to their proposedanswer in related languages for self-reflection. Ex-tensive experiments demonstrate that multilingualfeedback achieves up to 9.2% improvement againstbaselines across models and datasets, while pre-senting a more equitable solution to multilingualabstention. Further analysis reveals that abstentionis a language-specific problem, that multilingualfeedback in related languages both improves theaccuracy of abstention and calibrates the fairnessacross higher- and lower-resource languages, andthat cultural relatedness is an important factor inthe utility and equity of abstention, highlightingthat multilingual modeling is not only a technicalproblem but also a social-oriented one.",
  "Limitations": "Our study of teaching LLMs to abstain focuseson the knowledge perspective, i.e., LLMs shouldabstain when their parametric knowledge is insuffi-cient to provide a correct answer. However, the ab-stain problem also has implications from the safetyperspective (Huang et al., 2023b; Liu et al., 2023b).We envision future methodologies and evaluationsthat tackle both directions of the abstain problemacross diverse language contexts.Our approach, teaching LLMs to abstain viamultilingual feedback, involves sampling multiple feedback from related languages to promote self-reflection. This sampling introduces minor random-ness in LLMs abstain decisions (Appendix A). Inaddition, it would incur greater inference costs thanthe most simple prompting approaches, but is alsonot the most expensive (Feng et al., 2024). Whena black-box LLM with hundreds of billions of pa-rameters is served behind an API call, our approachenables the incorporation of one extra multilingual7B model for stronger reliability () and doesnot add much to the overall cost.",
  "Ethics Statement": "While abstaining in multilingual contexts is a tech-nical problem, we discover the role of culture inAbstainQA and that west-centric LLMs (Naouset al., 2023; Li et al., 2024a; Rao et al., 2024) arehindering progress on equitable LLM abstention(5). This encourages research at the intersection ofmultilingualism and culture (Choenni et al., 2024).We envision future work on not only proposingtechnical solutions to the abstain problem, but alsoimproving the representation of diverse values, per-spectives, and cultures in LLMs.",
  "Acknowledgements": "We gratefully acknowledge support from the Na-tional Science Foundation under CAREER GrantNo. IIS2142739, and NSF grants No. IIS2125201and IIS2203097. This work was also supported inpart by gift funding from Google and MSR. Roee Aharoni, Shashi Narayan, Joshua Maynez,Jonathan Herzig, Elizabeth Clark, and Mirella La-pata. 2022.mface: Multilingual summarizationwith factual consistency evaluation. arXiv preprintarXiv:2212.10622. Kabir Ahuja, Harshita Diddee, Rishav Hada, Milli-cent Ochieng, Krithika Ramesh, Prachi Jain, Ak-shay Nambi, Tanuja Ganu, Sameer Segal, MohamedAhmed, Kalika Bali, and Sunayana Sitaram. 2023.MEGA: Multilingual evaluation of generative AI. InProceedings of the 2023 Conference on EmpiricalMethods in Natural Language Processing. Kabir Ahuja, Sunayana Sitaram, Sandipan Dandapat,and Monojit Choudhury. 2022. On the calibration ofmassively multilingual language models. In Proceed-ings of the 2022 Conference on Empirical Methodsin Natural Language Processing. Mikel Artetxe, Sebastian Ruder, and Dani Yogatama.2020. On the cross-lingual transferability of mono-lingual representations. In Proceedings of the 58thAnnual Meeting of the Association for ComputationalLinguistics, pages 46234637. Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu,Terra Blevins, Hila Gonen, Machel Reid, YuliaTsvetkov, Sebastian Ruder, and Hannaneh Hajishirzi.2023. Buffet: Benchmarking large language modelsfor few-shot cross-lingual transfer. arXiv preprintarXiv:2305.14857. Akari Asai, Xinyan Yu, Jungo Kasai, and Hanna Ha-jishirzi. 2021. One question answering model formany languages with cross-lingual dense passage re-trieval. Advances in Neural Information ProcessingSystems, 34:75477560.",
  "Amos Azaria and Tom Mitchell. 2023. The internalstate of an llm knows when its lying. In Findingsof the Association for Computational Linguistics:EMNLP 2023, pages 967976": "Lucas Bandarkar, Davis Liang, Benjamin Muller, MikelArtetxe, Satya Narayan Shukla, Donald Husa, NamanGoyal, Abhinandan Krishnan, Luke Zettlemoyer, andMadian Khabsa. 2023. The belebele benchmark: aparallel reading comprehension dataset in 122 lan-guage variants. arXiv preprint arXiv:2308.16884. Vasilisa Bashlovkina, Zhaobin Kuang, Riley Matthews,Edward Clifford, Yennie Jun, William W Cohen, andSimon Baumgartner. 2023.Trusted source align-ment in large language models.arXiv preprintarXiv:2311.06697. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020.Language models are few-shot learners. In Advancesin Neural Information Processing Systems. Ilias Chalkidis, Tommaso Pasini, Sheng Zhang, LetiziaTomada, Sebastian Schwemer, and Anders Sgaard.2022. FairLex: A multilingual benchmark for evalu-ating fairness in legal text processing. In Proceedingsof the 60th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers). Jiefeng Chen, Jinsung Yoon, Sayna Ebrahimi, SercanArik, Tomas Pfister, and Somesh Jha. 2023. Adap-tation with self-evaluation to improve selective pre-diction in LLMs. In Findings of the Association forComputational Linguistics: EMNLP 2023.",
  "Rochelle Choenni, Anne Lauscher, and EkaterinaShutova. 2024. The echoes of multilinguality: Trac-ing cultural value shifts during lm fine-tuning. arXivpreprint arXiv:2405.12744": "Elizabeth Clark, Shruti Rijhwani, Sebastian Gehrmann,Joshua Maynez, Roee Aharoni, Vitaly Nikolaev,Thibault Sellam, Aditya Siddhant, Dipanjan Das, andAnkur Parikh. 2023. SEAHORSE: A multilingual,multifaceted dataset for summarization evaluation.In Proceedings of the 2023 Conference on EmpiricalMethods in Natural Language Processing. Jonathan H Clark, Eunsol Choi, Michael Collins, DanGarrette, Tom Kwiatkowski, Vitaly Nikolaev, andJennimaria Palomaki. 2020. Tydi qa: A benchmarkfor information-seeking question answering in ty po-logically di verse languages. Transactions of the As-sociation for Computational Linguistics, 8:454470. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,Mark Chen, Heewoo Jun, Lukasz Kaiser, MatthiasPlappert, Jerry Tworek, Jacob Hilton, ReiichiroNakano, Christopher Hesse, and John Schulman.2021. Training verifiers to solve math word prob-lems. arXiv preprint arXiv:2110.14168. Jeremy Cole, Michael Zhang, Daniel Gillick, JulianEisenschlos, Bhuwan Dhingra, and Jacob Eisenstein.2023. Selectively answering ambiguous questions.In Proceedings of the 2023 Conference on EmpiricalMethods in Natural Language Processing.",
  "Alexis Conneau and Guillaume Lample. 2019. Cross-lingual language model pretraining. Advances inneural information processing systems, 32": "Alexis Conneau, Ruty Rinott, Guillaume Lample, Ad-ina Williams, Samuel Bowman, Holger Schwenk,and Veselin Stoyanov. 2018. Xnli: Evaluating cross-lingual sentence representations. In Proceedings ofthe 2018 Conference on Empirical Methods in Natu-ral Language Processing, pages 24752485. David Dale, Elena Voita, Loc Barrault, and Marta RCosta-juss. 2023a. Detecting and mitigating hal-lucinations in machine translation: Model internalworkings alone do well, sentence similarity even bet-ter. In Proceedings of the 61st Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 3650. David Dale, Elena Voita, Janice Lam, PrangthipHansanti, Christophe Ropers, Elahe Kalbassi, Cyn-thia Gao, Loic Barrault, and Marta Costa-juss.2023b. HalOmi: A manually annotated benchmarkfor multilingual hallucination and omission detec-tion in machine translation. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing. Shrey Desai and Greg Durrett. 2020. Calibration ofpre-trained transformers. In Proceedings of the 2020Conference on Empirical Methods in Natural Lan-guage Processing (EMNLP), pages 295302, Online.Association for Computational Linguistics. Yilun Du, Shuang Li, Antonio Torralba, Joshua B Tenen-baum, and Igor Mordatch. 2023. Improving factual-ity and reasoning in language models through multia-gent debate. arXiv preprint arXiv:2305.14325. Abteen Ebrahimi, Manuel Mager, Arturo Oncevay,Vishrav Chaudhary, Luis Chiruzzo, Angela Fan, JohnOrtega, Ricardo Ramos, Annette Rios, Ivan VladimirMeza Ruiz, Gustavo Gimnez-Lugo, ElisabethMager, Graham Neubig, Alexis Palmer, RolandoCoto-Solano, Thang Vu, and Katharina Kann. 2022.AmericasNLI: Evaluating zero-shot natural languageunderstanding of pretrained multilingual models intruly low-resource languages. In Proceedings of the60th Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers). Sergey Edunov, Myle Ott, Michael Auli, and DavidGrangier. 2018. Understanding back-translation atscale. In Proceedings of the 2018 Conference onEmpirical Methods in Natural Language Processing,pages 489500. Shangbin Feng, Weijia Shi, Yuyang Bai, Vidhisha Bal-achandran, Tianxing He, and Yulia Tsvetkov. 2023.Knowledge card: Filling llms knowledge gaps withplug-in specialized language models. In The TwelfthInternational Conference on Learning Representa-tions. Shangbin Feng, Weijia Shi, Yike Wang, Wenxuan Ding,Vidhisha Balachandran, and Yulia Tsvetkov. 2024.Dont hallucinate, abstain: Identifying llm knowl-edge gaps via multi-llm collaboration. arXiv preprintarXiv:2402.00367. Yoshinari Fujinuma, Jordan Boyd-Graber, and Katha-rina Kann. 2022. Match the script, adapt if multilin-gual: Analyzing the effect of multilingual pretrainingon cross-lingual transferability. In Proceedings of the60th Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers). Changjiang Gao, Hongda Hu, Peng Hu, Jiajun Chen,Jixing Li, and Shujian Huang. 2024. Multilingual pre-training and instruction tuning improve cross-lingualknowledge alignment, but only shallowly. In Pro-ceedings of the 2024 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics: Human Language Technologies (Volume1: Long Papers). Sebastian Gehrmann, Abhik Bhattacharjee, AbinayaMahendiran, Alex Wang, Alexandros Papangelis,Aman Madaan, Angelina Mcmillan-major, AnnaShvets, Ashish Upadhyay, Bernd Bohnet, BingshengYao, Bryan Wilie, Chandra Bhagavatula, ChaobinYou, Craig Thomson, Cristina Garbacea, DakuoWang, Daniel Deutsch, Deyi Xiong, Di Jin, Dimi-tra Gkatzia, Dragomir Radev, Elizabeth Clark, EsinDurmus, Faisal Ladhak, Filip Ginter, Genta IndraWinata, Hendrik Strobelt, Hiroaki Hayashi, Jekate-rina Novikova, Jenna Kanerva, Jenny Chim, JiaweiZhou, Jordan Clive, Joshua Maynez, Joo Sedoc,Juraj Juraska, Kaustubh Dhole, Khyathi RaghaviChandu, Laura Perez Beltrachini, Leonardo F . R.Ribeiro, Lewis Tunstall, Li Zhang, Mahim Pushkarna,Mathias Creutz, Michael White, Mihir Sanjay Kale,Moussa Kamal Eddine, Nico Daheim, Nishant Subra-mani, Ondrej Dusek, Paul Pu Liang, Pawan Sasanka Ammanamanchi, Qi Zhu, Ratish Puduppully, RenoKriz, Rifat Shahriyar, Ronald Cardenas, Saad Ma-hamood, Salomey Osei, Samuel Cahyawijaya, Sanjatajner, Sebastien Montella, Shailza Jolly, SimonMille, Tahmid Hasan, Tianhao Shen, Tosin Adewumi,Vikas Raunak, Vipul Raheja, Vitaly Nikolaev, VivianTsai, Yacine Jernite, Ying Xu, Yisi Sang, Yixin Liu,and Yufang Hou. 2022. GEMv2: Multilingual NLGbenchmarking in a single line of code. In Proceed-ings of the 2022 Conference on Empirical Methodsin Natural Language Processing: System Demonstra-tions. Zhengyao Gu and Mark Hopkins. 2023. On the evalua-tion of neural selective prediction methods for naturallanguage processing. In Proceedings of the 61st An-nual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers).",
  "Guande He, Peng Cui, Jianfei Chen, Wenbo Hu, and JunZhu. 2023. Investigating uncertainty calibration ofaligned language models under the multiple-choicesetting. arXiv preprint arXiv:2310.11732": "Junjie Hu, Sebastian Ruder, Aditya Siddhant, Gra-ham Neubig, Orhan Firat, and Melvin Johnson.2020. Xtreme: A massively multilingual multi-taskbenchmark for evaluating cross-lingual generalisa-tion. In International Conference on Machine Learn-ing, pages 44114421. PMLR. JieHuang,XinyunChen,SwaroopMishra,Huaixiu Steven Zheng, Adams Wei Yu, Xiny-ing Song, and Denny Zhou. 2023a. Large languagemodels cannot self-correct reasoning yet. In TheTwelfth International Conference on LearningRepresentations. Xiaowei Huang, Wenjie Ruan, Wei Huang, Gao Jin,Yizhen Dong, Changshun Wu, Saddek Bensalem,Ronghui Mu, Yi Qi, Xingyu Zhao, Kaiwen Cai, Yang-hao Zhang, Sihao Wu, Peipei Xu, Dengyu Wu, AndrFreitas, and Mustafa A. Mustafa. 2023b. A survey ofsafety and trustworthiness of large language modelsthrough the lens of verification and validation. ArXiv,abs/2305.11391. Zhiqi Huang, Puxuan Yu, and James Allan. 2023c. Im-proving cross-lingual information retrieval on low-resource languages via optimal transport distillation.In Proceedings of the Sixteenth ACM InternationalConference on Web Search and Data Mining, pages10481056. Abhyuday Jagannatha and Hong Yu. 2020. Calibratingstructured output predictors for natural language pro-cessing. In Proceedings of the 58th Annual Meetingof the Association for Computational Linguistics. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, DanSu, Yan Xu, Etsuko Ishii, Ye Jin Bang, AndreaMadotto, and Pascale Fung. 2023. Survey of halluci-nation in natural language generation. ACM Comput-ing Surveys, 55(12):138. Zhengbao Jiang, Jun Araki, Haibo Ding, and GrahamNeubig. 2021. How can we know when languagemodels know? on the calibration of language modelsfor question answering. Transactions of the Associa-tion for Computational Linguistics, 9:962977. Saurav Kadavath, Tom Conerly, Amanda Askell, T. J.Henighan, Dawn Drain, Ethan Perez, NicholasSchiefer, Zachary Dodds, Nova DasSarma, Eli Tran-Johnson, Scott Johnston, Sheer El-Showk, AndyJones, Nelson Elhage, Tristan Hume, Anna Chen,Yuntao Bai, Sam Bowman, Stanislav Fort, DeepGanguli, Danny Hernandez, Josh Jacobson, JohnKernion, Shauna Kravec, Liane Lovitt, KamalNdousse, Catherine Olsson, Sam Ringer, DarioAmodei, Tom B. Brown, Jack Clark, Nicholas Joseph,Benjamin Mann, Sam McCandlish, Christopher Olah,and Jared Kaplan. 2022. Language models (mostly)know what they know. ArXiv, abs/2207.05221.",
  "Geunwoo Kim, Pierre Baldi, and Stephen McAleer.2024. Language models can solve computer tasks.Advances in Neural Information Processing Systems,36": "Lingkai Kong, Haoming Jiang, Yuchen Zhuang, JieLyu, Tuo Zhao, and Chao Zhang. 2020.Cali-brated language model fine-tuning for in- and out-of-distribution data. In Proceedings of the 2020 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), pages 13261340, Online. As-sociation for Computational Linguistics. Lorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2022.Semantic uncertainty: Linguistic invariances for un-certainty estimation in natural language generation.In The Eleventh International Conference on Learn-ing Representations. Sachin Kumar, Vidhisha Balachandran, Lucille Njoo,Antonios Anastasopoulos, and Yulia Tsvetkov. 2023.Language generation models can cause harm: Sowhat can we do about it? an actionable survey. InProceedings of the 17th Conference of the EuropeanChapter of the Association for Computational Lin-guistics, pages 32993321. Viet Lai, Chien Nguyen, Nghia Ngo, Thuat Nguyen,Franck Dernoncourt, Ryan Rossi, and Thien Nguyen.2023. Okapi: Instruction-tuned large language mod-els in multiple languages with reinforcement learningfrom human feedback. In Proceedings of the 2023Conference on Empirical Methods in Natural Lan-guage Processing: System Demonstrations, pages318327. Angeliki Lazaridou, Adhi Kuncoro, Elena Gribovskaya,Devang Agrawal, Adam Liska, Tayfun Terzi, MaiGimenez, Cyprien de Masson dAutume, Tomas Ko-cisky, Sebastian Ruder, et al. 2021. Mind the gap:Assessing temporal generalization in neural languagemodels. Advances in Neural Information ProcessingSystems, 34:2934829363.",
  "Cheng Li, Damien Teney, Linyi Yang, Qingsong Wen,Xing Xie, and Jindong Wang. 2024a. Culturepark:Boosting cross-cultural understanding in large lan-guage models. arXiv preprint arXiv:2405.15145": "Chong Li, Shaonan Wang, Jiajun Zhang, and ChengqingZong. 2024b.Improving in-context learning ofmultilingual generative language models with cross-lingual alignment. In Proceedings of the 2024 Con-ference of the North American Chapter of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies (Volume 1: Long Papers). Mingqi Li, Fei Ding, Dan Zhang, Long Cheng, HongxinHu, and Feng Luo. 2022. Multi-level distillation ofsemantic knowledge for pre-training multilingual lan-guage model. In Proceedings of the 2022 Conferenceon Empirical Methods in Natural Language Process-ing. Percy Liang, Rishi Bommasani, Tony Lee, DimitrisTsipras, Dilara Soylu, Michihiro Yasunaga, YianZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-mar, et al. 2023. Holistic evaluation of language mod-els. Transactions on Machine Learning Research. Sheng-Chieh Lin, Amin Ahmad, and Jimmy Lin. 2023.mAggretriever: A simple yet effective approach tozero-shot multilingual dense retrieval. In Proceed-ings of the 2023 Conference on Empirical Methodsin Natural Language Processing.",
  "Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, TianluWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-man Goyal, Shruti Bhosale, Jingfei Du, Ramakanth": "Pasunuru, Sam Shleifer, Punit Singh Koura, VishravChaudhary, Brian OHoro, Jeff Wang, Luke Zettle-moyer, Zornitsa Kozareva, Mona Diab, Veselin Stoy-anov, and Xian Li. 2022b. Few-shot learning withmultilingual generative language models. In Proceed-ings of the 2022 Conference on Empirical Methodsin Natural Language Processing. Yu-Hsiang Lin, Chian-Yu Chen, Jean Lee, Zirui Li,Yuyan Zhang, Mengzhou Xia, Shruti Rijhwani, Junx-ian He, Zhisong Zhang, Xuezhe Ma, Antonios Anas-tasopoulos, Patrick Littell, and Graham Neubig.2019a. Choosing transfer languages for cross-linguallearning. In Proceedings of the 57th Annual Meetingof the Association for Computational Linguistics. Yu-Hsiang Lin, Chian-Yu Chen, Jean Lee, Zirui Li,Yuyan Zhang, Mengzhou Xia, Shruti Rijhwani, Junx-ian He, Zhisong Zhang, Xuezhe Ma, et al. 2019b.Choosing transfer languages for cross-lingual learn-ing. In Proceedings of the 57th Annual Meeting ofthe Association for Computational Linguistics, pages31253135. Patrick Littell, David R Mortensen, Ke Lin, KatherineKairis, Carlisle Turner, and Lori Levin. 2017. Urieland lang2vec: Representing languages as typological,geographical, and phylogenetic vectors. In Proceed-ings of the 15th Conference of the European Chap-ter of the Association for Computational Linguistics:Volume 2, Short Papers, pages 814. Linlin Liu, Xin Li, Ruidan He, Lidong Bing, Shafiq Joty,and Luo Si. 2022. Enhancing multilingual languagemodel with massive multilingual knowledge triples.In Proceedings of the 2022 Conference on EmpiricalMethods in Natural Language Processing.",
  "Xin Liu, Muhammad Khalifa, and Lu Wang. 2023a.Litcab: Lightweight calibration of language mod-els on outputs of varied lengths.arXiv preprintarXiv:2310.19208": "Yang Liu, Yuanshun Yao, Jean-Francois Ton, XiaoyingZhang, Ruocheng Guo, Hao Cheng, Yegor Klochkov,Muhammad Faaiz Taufiq, and Hang Li. 2023b. Trust-worthy llms: a survey and guideline for evaluatinglarge language models alignment. In Socially Re-sponsible Language Modelling Research. Shayne Longpre, Yi Lu, and Joachim Daiber. 2021.Mkqa: A linguistically diverse benchmark for mul-tilingual open domain question answering. Transac-tions of the Association for Computational Linguis-tics, 9:13891406. Aman Madaan, Niket Tandon, Prakhar Gupta, SkylerHallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,et al. 2024. Self-refine: Iterative refinement withself-feedback. Advances in Neural Information Pro-cessing Systems, 36.",
  "overconfidence through linguistic calibration. Trans-actions of the Association for Computational Linguis-tics, 10:857872": "Abhika Mishra, Akari Asai, Vidhisha Balachandran,Yizhong Wang, Graham Neubig, Yulia Tsvetkov, andHannaneh Hajishirzi. 2024. Fine-grained hallucina-tion detection and editing for language models. arXivpreprint arXiv:2401.06855. Niklas Muennighoff, Thomas Wang, Lintang Sutawika,Adam Roberts, Stella Biderman, Teven Le Scao,M Saiful Bari, Sheng Shen, Zheng Xin Yong, HaileySchoelkopf, et al. 2023. Crosslingual generalizationthrough multitask finetuning. In Proceedings of the61st Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages1599116111.",
  "Tarek Naous, Michael J Ryan, Alan Ritter, and WeiXu. 2023.Having beer after prayer? measuringcultural bias in large language models. arXiv preprintarXiv:2305.14456": "Odunayo Ogundepo, Tajuddeen Gwadabe, Clara Rivera,Jonathan H Clark, Sebastian Ruder, David Adelani,Bonaventure Dossou, Abdou Diop, Claytone Sika-sote, Gilles Hacheme, et al. 2023.Cross-lingualopen-retrieval question answering for african lan-guages.In Findings of the Association for Com-putational Linguistics: EMNLP 2023, pages 1495714972. Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,Carroll Wainwright, Pamela Mishkin, Chong Zhang,Sandhini Agarwal, Katarina Slama, Alex Ray, et al.2022. Training language models to follow instruc-tions with human feedback.Advances in NeuralInformation Processing Systems, 35:2773027744. Fabio Petroni, Tim Rocktschel, Sebastian Riedel,Patrick Lewis, Anton Bakhtin, Yuxiang Wu, andAlexander Miller. 2019. Language models as knowl-edge bases?In Proceedings of the 2019 Confer-ence on Empirical Methods in Natural Language Pro-cessing and the 9th International Joint Conferenceon Natural Language Processing (EMNLP-IJCNLP),pages 24632473. Fred Philippy, Siwen Guo, and Shohreh Haddadan.2023. Towards a common understanding of contribut-ing factors for cross-lingual transfer in multilinguallanguage models: A review. In Proceedings of the61st Annual Meeting of the Association for Computa-tional Linguistics (Volume 1: Long Papers).",
  "Telmo Pires, Eva Schlinger, and Dan Garrette. 2019.How multilingual is multilingual BERT? In Proceed-ings of the 57th Annual Meeting of the Associationfor Computational Linguistics": "Jirui Qi, Raquel Fernndez, and Arianna Bisazza. 2023.Cross-lingual consistency of factual knowledge inmultilingual language models. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing. Yifu Qiu, Yftah Ziser, Anna Korhonen, Edoardo Ponti,and Shay B Cohen. 2023. Detecting and mitigatinghallucinations in multilingual summarisation. In Pro-ceedings of the 2023 Conference on Empirical Meth-ods in Natural Language Processing, pages 89148932.",
  "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,Dario Amodei, Ilya Sutskever, et al. 2019. Languagemodels are unsupervised multitask learners. OpenAIblog, 1(8):9": "Abhinav Rao, Akhila Yerukola, Vishwa Shah, KatharinaReinecke, and Maarten Sap. 2024. Normad: A bench-mark for measuring the cultural adaptability of largelanguage models. arXiv preprint arXiv:2404.12464. Vikas Raunak, Arul Menezes, and Marcin Junczys-Dowmunt. 2021. The curious case of hallucinationsin neural machine translation. In Proceedings of the2021 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 11721183. Manon Reusens, Philipp Borchert, Margot Mieskes,Jochen De Weerdt, and Bart Baesens. 2023. Investi-gating bias in multilingual language models: Cross-lingual transfer of debiasing techniques. In Proceed-ings of the 2023 Conference on Empirical Methodsin Natural Language Processing. Fabian David Schmidt, Ivan Vulic, and Goran Glava.2022. Dont stop fine-tuning: On training regimesfor few-shot cross-lingual transfer with multilinguallanguage models. In Proceedings of the 2022 Con-ference on Empirical Methods in Natural LanguageProcessing. Tim Schott, Daniel Furman, and Shreshta Bhat. 2023.Polyglot or not? measuring multilingual encyclope-dic knowledge in foundation models. In Proceedingsof the 2023 Conference on Empirical Methods inNatural Language Processing. Tianhao Shen, Mingtong Liu, Ming Zhou, and DeyiXiong. 2022. Recovering gold from black sand: Mul-tilingual dense passage retrieval with hard and falsenegative samples. In Proceedings of the 2022 Con-ference on Empirical Methods in Natural LanguageProcessing. Weijia Shi, Sewon Min, Michihiro Yasunaga, Min-joon Seo, Richard James, Mike Lewis, Luke Zettle-moyer, and Wen-tau Yih. 2024. REPLUG: Retrieval-augmented black-box language models. In Proceed-ings of the 2024 Conference of the North AmericanChapter of the Association for Computational Lin-guistics: Human Language Technologies (Volume 1:Long Papers). Noah Shinn, Federico Cassano, Ashwin Gopinath,Karthik R Narasimhan, and Shunyu Yao. 2023. Re-flexion: Language agents with verbal reinforcementlearning. In Thirty-seventh Conference on NeuralInformation Processing Systems. Chenglei Si, Weijia Shi, Chen Zhao, Luke Zettlemoyer,and Jordan Boyd-Graber. 2023. Getting more outof mixture of language model reasoning experts. InFindings of the Association for Computational Lin-guistics: EMNLP 2023, pages 82348249. Aviv Slobodkin, Omer Goldman, Avi Caciularu, IdoDagan, and Shauli Ravfogel. 2023. The curious caseof hallucinatory (un) answerability: Finding truthsin the hidden states of over-confident large languagemodels. In Proceedings of the 2023 Conference onEmpirical Methods in Natural Language Processing,pages 36073625. Yueqi Song, Simran Khanuja, Pengfei Liu, Fahim Faisal,Alissa Ostapenko, Genta Winata, Alham Aji, SamuelCahyawijaya, Yulia Tsvetkov, Antonios Anastasopou-los, et al. 2023.Globalbench: A benchmark forglobal progress in natural language processing. InProceedings of the 2023 Conference on EmpiricalMethods in Natural Language Processing, pages1415714171.",
  "Meiqi Sun, Wilson Yan, Pieter Abbeel, and Igor Mor-datch. 2022. Quantifying uncertainty in foundationmodels via ensembles. In NeurIPS 2022 Workshopon Robustness in Sequence Modeling": "Zhiqing Sun, Sheng Shen, Shengcao Cao, Haotian Liu,Chunyuan Li, Yikang Shen, Chuang Gan, Liang-Yan Gui, Yu-Xiong Wang, Yiming Yang, et al. 2023.Aligning large multimodal models with factually aug-mented rlhf. arXiv preprint arXiv:2309.14525. Eshaan Tanwar, Subhabrata Dutta, Manish Borthakur,and Tanmoy Chakraborty. 2023. Multilingual LLMsare better cross-lingual in-context learners with align-ment. In Proceedings of the 61st Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 1: Long Papers).",
  "Linwei Tao, Younan Zhu, Haolan Guo, Minjing Dong,and Chang Xu. 2023. A benchmark study on cali-bration. In The Twelfth International Conference onLearning Representations": "Nandan Thakur, Jianmo Ni, Gustavo Hernandez Abrego,John Wieting, Jimmy Lin, and Daniel Cer. 2024.Leveraging LLMs for synthesizing training dataacross many languages in multilingual dense retrieval.In Proceedings of the 2024 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies(Volume 1: Long Papers). Katherine Tian, Eric Mitchell, Allan Zhou, ArchitSharma, Rafael Rafailov, Huaxiu Yao, Chelsea Finn,and Christopher Manning. 2023. Just ask for cali-bration: Strategies for eliciting calibrated confidencescores from language models fine-tuned with humanfeedback. In Proceedings of the 2023 Conferenceon Empirical Methods in Natural Language Process-ing, pages 54335442, Singapore. Association forComputational Linguistics. Ahmet stn, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel Dsouza, Gbemileke Onilude, NeelBhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid,et al. 2024. Aya model: An instruction finetunedopen-access multilingual language model.arXivpreprint arXiv:2402.07827. Ahmet stn, Arianna Bisazza, Gosse Bouma, Gertjanvan Noord, and Sebastian Ruder. 2022. Hyper-X:A unified hypernetwork for multi-task multilingualtransfer. In Proceedings of the 2022 Conference onEmpirical Methods in Natural Language Processing. Neeraj Varshney and Chitta Baral. 2023.Post-abstention: Towards reliably re-attempting the ab-stained instances in QA. In Proceedings of the 61stAnnual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers). Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao,Yang Ding, AiTi Aw, and Nancy Chen. 2024. SeaE-val for multilingual foundation models: From cross-lingual alignment to cultural reasoning. In Proceed-ings of the 2024 Conference of the North AmericanChapter of the Association for Computational Lin-guistics: Human Language Technologies (Volume 1:Long Papers). Boshi Wang, Xiang Yue, and Huan Sun. 2023a. CanChatGPT defend its belief in truth? evaluating LLMreasoning via debate. In Findings of the Associationfor Computational Linguistics: EMNLP 2023, pages1186511881, Singapore. Association for Computa-tional Linguistics. Shuo Wang, Zhaopeng Tu, Shuming Shi, and Yang Liu.2020a. On the inference calibration of neural ma-chine translation. In Proceedings of the 58th AnnualMeeting of the Association for Computational Lin-guistics, pages 30703079, Online. Association forComputational Linguistics. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le,Ed H Chi, Sharan Narang, Aakanksha Chowdhery,and Denny Zhou. 2022. Self-consistency improveschain of thought reasoning in language models. InThe Eleventh International Conference on LearningRepresentations.",
  "Yike Wang, Shangbin Feng, Heng Wang, WeijiaShi, Vidhisha Balachandran, Tianxing He, and Yu-lia Tsvetkov. 2023b.Resolving knowledge con-flicts in large language models.arXiv preprintarXiv:2310.00935": "Zirui Wang, Zachary C. Lipton, and Yulia Tsvetkov.2020b. On negative interference in multilingual mod-els: Findings and a meta-learning treatment.InProceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 44384450. Association for ComputationalLinguistics. Spencer Whitehead, Suzanne Petryk, Vedaad Shakib,Joseph Gonzalez, Trevor Darrell, Anna Rohrbach,and Marcus Rohrbach. 2022. Reliable visual ques-tion answering: Abstain rather than answer incor-rectly. In European Conference on Computer Vision,pages 148166. Springer. John Wieting, Jonathan Clark, William Cohen, GrahamNeubig, and Taylor Berg-Kirkpatrick. 2023. Beyondcontrastive learning: A variational generative modelfor multilingual retrieval. In Proceedings of the 61stAnnual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers). Linjuan Wu, Shaojuan Wu, Xiaowang Zhang, DeyiXiong, Shizhan Chen, Zhiqiang Zhuang, and Zhiy-ong Feng. 2022. Learning disentangled semanticrepresentations for zero-shot cross-lingual transferin multilingual machine reading comprehension. InProceedings of the 60th Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers). Shijie Wu and Mark Dredze. 2019. Beto, bentz, becas:The surprising cross-lingual effectiveness of BERT.In Proceedings of the 2019 Conference on EmpiricalMethods in Natural Language Processing and the 9thInternational Joint Conference on Natural LanguageProcessing (EMNLP-IJCNLP). Jian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, andYu Su. 2023. Adaptive chameleon or stubborn sloth:Revealing the behavior of large language models inknowledge conflicts. In The Twelfth InternationalConference on Learning Representations. Fangyuan Xu, Weijia Shi, and Eunsol Choi. 2024. RE-COMP: Improving retrieval-augmented LMs withcontext compression and selective augmentation. InThe Twelfth International Conference on LearningRepresentations. Haoran Xu, Weiting Tan, Shuyue Li, Yunmo Chen, Ben-jamin Van Durme, Philipp Koehn, and Kenton Mur-ray. 2023a. Condensing multilingual knowledge withlightweight language-specific modules. In Proceed-ings of the 2023 Conference on Empirical Methodsin Natural Language Processing. Shaoyang Xu, Junzhuo Li, and Deyi Xiong. 2023b.Language representation projection: Can we transferfactual knowledge across languages in multilinguallanguage models? In Proceedings of the 2023 Con-ference on Empirical Methods in Natural LanguageProcessing. Weijia Xu, Sweta Agrawal, Eleftheria Briakou, Mari-anna J Martindale, and Marine Carpuat. 2023c. Un-derstanding and detecting hallucinations in neuralmachine translation via model introspection. Trans-actions of the Association for Computational Linguis-tics, 11:546564.",
  "Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi,Richard James, Jure Leskovec, Percy Liang, MikeLewis, Luke Zettlemoyer, and Wen-tau Yih. 2023.Retrieval-augmented multimodal language modeling": "Jifan Yu, Xiaozhi Wang, Shangqing Tu, Shulin Cao,Daniel Zhang-Li, Xin Lv, Hao Peng, Zijun Yao, Xiao-han Zhang, Hanming Li, et al. 2023. Kola: Carefullybenchmarking world knowledge of large languagemodels. In The Twelfth International Conference onLearning Representations. Polina Zablotskaia, Du Phan, Joshua Maynez, ShashiNarayan, Jie Ren, and Jeremiah Liu. 2023. On un-certainty calibration and selective generation in prob-abilistic neural summarization: A benchmark study.In Findings of the Association for ComputationalLinguistics: EMNLP 2023. Hanning Zhang, Shizhe Diao, Yong Lin, Yi R Fung,Qing Lian, Xingyao Wang, Yangyi Chen, Heng Ji,and Tong Zhang. 2023a. R-tuning: Teaching largelanguage models to refuse unknown questions. arXivpreprint arXiv:2311.09677. Xiang Zhang, Senyu Li, Bradley Hauer, Ning Shi, andGrzegorz Kondrak. 2023b.Dont trust ChatGPTwhen your question is not in English: A study ofmultilingual abilities and types of LLMs. In Proceed-ings of the 2023 Conference on Empirical Methodsin Natural Language Processing. Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,Yulong Chen, et al. 2023c. Sirens song in the aiocean: a survey on hallucination in large languagemodels. arXiv preprint arXiv:2309.01219. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, SiyuanZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.Judging llm-as-a-judge with mt-bench and chatbotarena. Advances in Neural Information ProcessingSystems, 36. Han Zhou, Xingchen Wan, Lev Proleev, Diana Mincu,Jilin Chen, Katherine Heller, and Subhrajit Roy.2023a. Batch calibration: Rethinking calibration forin-context learning and prompt engineering. arXivpreprint arXiv:2309.17249.",
  "AAnalysis (cont.)": "MULTI-RELATED helps abstaining in cross-lingual retrieval.When retrieval corpora are notreadily available in low-resource languages, cross-lingual retrieval (Asai et al., 2021; Shen et al., 2022;Huang et al., 2023c; Wieting et al., 2023; Lin et al.,2023; Thakur et al., 2024) is often necessary forretrieval-augmented LLMs (Lewis et al., 2020; Shiet al., 2024; Yasunaga et al., 2023; Xu et al., 2024),where user queries are translated to high-resourcelanguages and retrieval is performed with that lan-guage. We investigate whether our multilingualfeedback approach works in this setting: we useEnglish Wikipedia for retrieval 5 and prepend back-translated paragraphs before the query from theseven low-resource languages. We evaluate variousabstain approaches with CHATGPT and presentperformance in . Our proposed multilin-gual feedback approach outperforms baselines forsix of the seven low-resource languages, by 6.9%on average. This indicates that our Multi-relatedapproach could also improve multilingual LLMreliability in retrieval-augmented settings. FP and FNFalse positives refer to cases wherethe LLM should be able to provide the correct an-swer but abstained, while false negatives are caseswhere the LLM did not abstain but generated anincorrect answer. We present the false positive andfalse negative rates of MULTI-RELATED in : we find that on high-resource languages, LLMstend to be more confident and the FN is usuallyhigher; for low-resource languages, LLMs tend tobe more conservative and the FP is usually higher.We argue that having a high FP for low-resourcelanguages is desirable since LLM has diminishingfactuality on the long tail of languages, thus LLMsshould be more cautious and abstain more. Correlation between QA Performance and Ab-stain PerformanceWe present the question an-swering accuracy as well as the abstain accuracyacross various languages in . We find thatthere is no lock-step synchronization between thetwo metrics, indicating that abstaining is an inde-pendent problem to question answering that needsfurther studies.",
  "Working ExamplesWe conduct qualitative anal-ysis to validate the generated feedback and abstaindecisions. We specifically present several workingexamples in Tables 14, 15, and 16": "Standard DeviationSince MULTI-RELATEDsamples feedback from multiple languages, thissampling introduces randomness in the feedbackcontent and potentially different abstain decisions.We re-run MULTI-RELATED three times with tem-perature = 0.7, and we find that the standarddeviation across runs is 0.0227, 0.0198, and 0.0086for high, mid, and low-resource languages, indicat-ing that the abstain performance is largely stable. AbstainECEAside from a binary decision ofabstaining or answering, the probabilities of theabstain decision token (True/False) could be em-ployed as an indicator for probabilistic abstention.We present the AbstainECE metric (Feng et al.,2024) in , which demonstrates that MONO-ENGLISH and MULTI-RELATED are stronger whilethe latter is best for low-resource languages. Weenvision improving LLM calibration with multilin-gual contexts could also help.",
  ": Other AbstainQA metrics with AYA-13B and MMLU": "the question is also employed to generate feedback;3) lang var., where the feedback content stays thesame but translated to different related languages. demonstrates that the default setting oftenworks best, while including the original languagefor feedback generation could be beneficial for cer-tain cases. Another Interpretation of Abstain OverlapFor , another way is to compare the propor-tion of consensus, where LLMs abstain for zero orall three of languages. In this definition, the sameconclusion still holds: the first control group has23.1% vs. 20.9%, while the second control grouphas 32.1% vs. 16.2%. Randomness in Sampling FeedbackWe ran-domly sample feedback sets with temperature of 1and repeat for 3 runs. If the LLM abstains/answersin all 3 runs, then it is deemed consistent; 1:2 and2:1 scenarios are then deemed as inconsistent. Wepresent results in , showing that learningto abstain from multilingual feedback is largelyconsistent.",
  "BExperiment Details": "Dataset DetailsWe employ M-MMLU, M-Hellaswag (Lai et al., 2023), and Belebele (Ban-darkar et al., 2023) as evaluations of multilingualAbstainQA. Specifically, we adopt 26 languagesbeyond English: 8 high-resource (Russian, ru; Ger-man, de; Chinese, zh; French, fr; Spanish, es; Ital-ian, it; Dutch, nl; Vietnamese, vi), 11 mid-resourcelanguages (Indonesian, id; Arabic, ar; Hungar-ian, hu; Romanian, ro; Danish, da; Slovak, sk;Ukrainian, uk; Catalan, ca; Serbian, sr; Croatian,hr; Hindi, hi), and 7 low-resource languages (Ben-gali, bn; Tamil, ta; Nepali, ne; Malayalam, ml;Marathi, Mr; Telugu, te; Kannada, kn). We followthe definition of language resourceness based onpretraining data frequency in Lai et al. (2023). Werandomly sample 200 questions for validation and800 questions for test from each language, withminor variation across languages based on dataavailability. ModelDetailsWeemploytheCohereForAI/aya-101modelcheckpointon Huggingface for AYA-13B, and the AzureOpenAI API checkpoint of gpt4 for GPT-4,and the GPT-3.5-TURBO-INSTRUCT modelcheckpoint on OpenAI API for CHATGPT.",
  "Baseline DetailsWe refer readers to Feng et al": "(2024) for a complete description of baselines. Forthe additional BACKTRANSLATION baseline, wetranslate the question to English and make an ab-stain decision in English, then use that abstain de-cision for other languages. GPT-4 Evaluation DetailsFor quality evalua-tion, we employ Question: <question> ProposedAnswer: <answer> Feedback 1: <feedback> Feed-back 2: <feedback> Which feedback is more rele-vant to the question? and Question: <question>Proposed Answer: <answer> Feedback 1: <feed-back> Feedback 2: <feedback> Which feedbackis more informative?. For role evaluation, weemploy Question: <question> Proposed Answer:<answer> Feedback 1: <feedback> Feedback 2:<feedback> Feedback 3: <feedback >What is therelationship among the three feedbacks? A. simi-lar B. complementary C. conflicting D. unrelatedRelationship:.",
  "Implementation DetailsWe present the relatedlanguages employed for feedback generation in theLanguage Relatedness study (5) in Tables 11, 12,and 13": "default:{ \"en\": [\"German\", \"Dutch\", \"French\"], \"ru\": [\"Ukrainian\", \"Romanian\", \"Catalan\"], \"de\":[\"Dutch\", \"English\", \"French\"], \"zh\": [\"Arabic\", \"Slovak\", \"Danish\"], \"fr\": [\"Catalan\", \"German\",\"Spanish\"], \"es\": [\"Catalan\", \"Romanian\", \"French\"], \"it\": [\"Catalan\", \"Romanian\", \"Ukrainian\"], \"nl\":[\"German\", \"Italian\", \"Ukrainian\"], \"vi\": [\"Indonesian\", \"English\", \"Bengali\"], \"id\": [\"Vietnamese\",\"Catalan\", \"Russian\"], \"ar\": [\"Chinese\", \"Slovak\", \"Danish\"], \"hu\": [\"Romanian\", \"German\", \"French\"],\"ro\": [\"Catalan\", \"Italian\", \"Spanish\"], \"da\": [\"Slovak\", \"Dutch\", \"Ukrainian\"], \"sk\": [\"Chinese\", \"Ara-bic\", \"Danish\"], \"uk\": [\"Russian\", \"Italian\", \"Croatian\"], \"ca\": [\"Romanian\", \"Spanish\", \"Italian\"], \"sr\":[\"Slovak\", \"Danish\", \"Croatian\"], \"hr\": [\"Ukrainian\", \"Italian\", \"Dutch\"], \"hi\": [\"Bengali\", \"Talugu\",\"Marathi\"], \"bn\": [\"Hindi\", \"Telugu\", \"Nepali\"], \"ta\": [\"Malayalam\", \"Marathi\", \"Kannada\"], \"ne\":[\"Kanaada\", \"Telugu\", \"Hindi\"], \"ml\": [\"Tamil\", \"Marathi\", \"Kannada\"], \"mr\": [\"Tamil\", \"Malayalam\",\"Hindi\"], \"te\": [\"Kannada\", \"Tamil\", \"Nepali\"], \"kn\": [\"Telugu\", \"Malaayalam\", \"Tamil\"] } syntactic: \"en\": [\"Spanish\", \"German\", \"French\"], \"ru\": [\"Ukrainian\", \"German\", \"Spanish\"], \"de\":[\"Dutch\", \"English\", \"Russian\"], \"zh\": [\"Arabic\", \"Slovak\", \"Hungarian\"], \"fr\": [\"Spanish\", \"English\",\"German\"], \"es\": [\"English\", \"French\", \"Russian\"], \"it\": [\"Catalan\", \"Romanian\", \"Dutch\"], \"nl\": [\"Ger-man\", \"Italian\", \"Danish\"], \"vi\": [\"Indonesian\", \"English\", \"French\"], \"id\": [\"Vietnamese\", \"English\",\"Italian\"], \"ar\": [\"Chinese\", \"Slovak\", \"Hungarian\"], \"hu\": [\"Russian\", \"Italian\", \"Romanian\"], \"ro\":[\"Italian\", \"Ukrainian\", \"Spanish\"], \"da\": [\"Dutch\", \"German\", \"French\"], \"sk\": [\"Chinese\", \"Arabic\",\"Hungarian\"], \"uk\": [\"Russian\", \"Italian\", \"Romanian\"], \"ca\": [\"Italian\", \"Dutch\", \"Romanian\"], \"sr\":[\"Catalan\", \"Ukrainian\", \"German\"], \"hr\": [\"Serbian\", \"Vietnamese\", \"Danish\"], \"hi\": [\"Kannada\",\"Russian\", \"Ukrainian\"], \"bn\": [\"Marathi\", \"Hindi\", \"Tamil\"], \"ta\": [\"Telugu\", \"Kannada\", \"Marathi\"],\"ne\": [\"Kannada\", \"Telugu\", \"Hindi\"], \"ml\": [\"Telugu\", \"Kannada\", \"Tamil\"], \"mr\": [\"Tamil\", \"Ben-gali\", \"Telugu\"], \"te\": [\"Tamil\", \"Nepali\", \"Kannada\"], \"kn\": [\"Tamil\", \"Nepali\", \"Hindi\"], featural: \"en\": [\"German\", \"Russian\", \"French\"], \"ru\": [\"Romanian\", \"Ukrainian\", \"English\"], \"de\":[\"English\", \"French\", \"Dutch\"], \"zh\": [\"Arabic\", \"Slovak\", \"English\"], \"fr\": [\"German\", \"English\",\"Russian\"], \"es\": [\"English\", \"Russian\", \"French\"], \"it\": [\"Dutch\", \"Romanian\", \"Ukrainian\"], \"nl\":[\"German\", \"Italian\", \"English\"], \"vi\": [\"Indonesian\", \"English\", \"French\"], \"id\": [\"Vietnamese\",\"Catalan\", \"English\"], \"ar\": [\"Chinese\", \"Slovak\", \"English\"], \"hu\": [\"Rominian\", \"English\", \"Russian\"],\"ro\": [\"Russian\", \"Italian\", \"Hungarian\"], \"da\": [\"Serbian\", \"English\", \"Russian\"], \"sk\": [\"Chinese\",\"Arabic\", \"English\"], \"uk\": [\"Russian\", \"Italian\", \"Romanian\"], \"ca\": [\"Italian\", \"Dutch\", \"Romanian\"],\"sr\": [\"Danish\", \"Russian\", \"Spanish\"], \"hr\": [\"Catalan\", \"English\", \"Russian\"], \"hi\": [\"Bengali\",\"Nepali\", \"Telugu\"], \"bn\": [\"Hindi\", \"Nepali\", \"Telugu\"], \"ta\": [\"Malayalam\", \"Marathi\", \"Telugu\"],\"ne\": [\"Hindi\", \"Bengali\", \"Marathi\"], \"ml\": [\"Tamil\", \"Marathi\", \"Kannada\"], \"mr\": [\"Tamil\", \"Nepali\",\"Malayalam\"], \"te\": [\"Hindi\", \"Bengali\", \"Tamil\"], \"kn\": [\"Hindi\", \"Tamil\", \"Nepali\"], genetic: \"en\": [\"German\", \"Dutch\", \"Danish\"], \"ru\": [\"Ukrainian\", \"Slovak\", \"Serbian\"], \"de\": [\"Dutch\",\"English\", \"Danish\"], \"zh\": [\"English\", \"Russian\", \"German\"], \"fr\": [\"Spanish\", \"Catalan\", \"Italian\"],\"es\": [\"Catalan\", \"Romanian\", \"French\"], \"it\": [\"Romanian\", \"Catalan\", \"Spanish\"], \"nl\": [\"German\",\"English\", \"Danish\"], \"vi\": [\"English\", \"Russian\", \"German\"], \"id\": [\"English\", \"Russian\", \"German\"],\"ar\": [\"English\", \"Russian\", \"German\"], \"hu\": [\"English\", \"Russian\", \"German\"], \"ro\": [\"Spanish\", \"Ital-ian\", \"Catalan\"], \"da\": [\"German\", \"English\", \"Dutch\"], \"sk\": [\"Russian\", \"Ukrainian\", \"Serbian\"], \"uk\":[\"Russian\", \"Slovak\", \"Serbian\"], \"ca\": [\"Spanish\", \"Romanian\", \"Italian\"], \"sr\": [\"Croatian\", \"Rus-sian\", \"Ukrainian\"], \"hr\": [\"Serbian\", \"Russian\", \"Slovak\"], \"hi\": [\"Bengali\", \"Marathi\", \"German\"],\"bn\": [\"Hindi\", \"Marathi\", \"English\"], \"ta\": [\"Malayalam\", \"Kannada\", \"Telugu\"], \"ne\": [\"English\",\"Russian\", \"German\"], \"ml\": [\"Tamil\", \"Kannada\", \"Telugu\"], \"mr\": [\"Hindi\", \"Bengali\", \"Russian\"],\"te\": [\"Tamil\", \"Malayalam\", \"Kannada\"], \"kn\": [\"Malayalam\", \"Tamil\", \"Telugu\"],",
  ": Related languages across different method settings, part 1": "geographic: \"en\": [\"French\", \"Dutch\", \"Danish\"], \"ru\": [\"English\", \"German\", \"French\"], \"de\":[\"French\", \"Italian\", \"Dutch\"], \"zh\": [\"English\", \"Russian\", \"German\"], \"fr\": [\"English\", \"German\",\"Spanish\"], \"es\": [\"French\", \"Catalan\", \"English\"], \"it\": [\"German\", \"French\", \"Hungarian\"], \"nl\":[\"English\", \"German\", \"French\"], \"vi\": [\"Indonesian\", \"Bengali\", \"Nepali\"], \"id\": [\"Vietnamese\",\"Bengali\", \"Tamil\"], \"ar\": [\"English\", \"Russian\", \"German\"], \"hu\": [\"German\", \"Italian\", \"Roma-nian\"], \"ro\": [\"German\", \"Italian\", \"Hungarian\"], \"da\": [\"English\", \"German\", \"French\"], \"sk\": [\"Ger-man\", \"Italian\", \"Hungarian\"], \"uk\": [\"German\", \"Hungarian\", \"Romanian\"], \"ca\": [\"French\", \"Span-ish\", \"Italian\"], \"sr\": [\"German\", \"Italian\", \"Hungarian\"], \"hr\": [\"German\", \"Italian\", \"Hungarian\"],\"hi\": [\"Nepali\", \"Marathi\", \"Telugu\"], \"bn\": [\"Nepali\", \"Vietnamese\", \"Hindi\"], \"ta\": [\"Malayalam\",\"Marathi\", \"Telugu\"], \"ne\": [\"Hindi\", \"Bengali\", \"Vietnamese\"], \"ml\": [\"Tamil\", \"Marathi\", \"Tel-ugu\"], \"mr\": [\"Hindi\", \"Tamil\", \"Malayalam\"], \"te\": [\"Hindi\", \"Tamil\", \"Malayalam\"], \"kn\": [\"Tamil\",\"Malayalam\", \"Marathi\"], inventory: \"en\": [\"German\", \"Marathi\", \"Telugu\"], \"ru\": [\"Ukrainian\", \"Croatian\", \"Romanian\"], \"de\":[\"Dutch\", \"French\", \"English\"], \"zh\": [\"Arabic\", \"Danish\", \"Slovak\"], \"fr\": [\"Hungarian\", \"Dutch\",\"German\"], \"es\": [\"Hungarian\", \"German\", \"Indonesian\"], \"it\": [\"Catalan\", \"Romanian\", \"Ukrainian\"],\"nl\": [\"German\", \"French\", \"Hungarian\"], \"vi\": [\"English\", \"Dutch\", \"German\"], \"id\": [\"Catalan\",\"Croatian\", \"Romanian\"], \"ar\": [\"Chinese\", \"Danish\", \"Slovak\"], \"hu\": [\"French\", \"Romanian\", \"Ital-ian\"], \"ro\": [\"Ukranian\", \"Catalan\", \"Italian\"], \"da\": [\"Chinese\", \"Arabic\", \"Slovak\"], \"sk\": [\"Chinese\",\"Arabic\", \"Danish\"], \"uk\": [\"Romanian\", \"Russian\", \"Italian\"], \"ca\": [\"Indonesian\", \"Italian\", \"Ro-manian\"], \"sr\": [\"Chinese\", \"Arabic\", \"Danish\"], \"hr\": [\"Catalan\", \"Indonesian\", \"Hungarian\"], \"hi\":[\"Telugu\", \"Bengali\", \"Nepali\"], \"bn\": [\"Telugu\", \"Nepali\", \"Hindi\"], \"ta\": [\"Kannada\", \"Malay-alam\", \"Marathi\"], \"ne\": [\"Marathi\", \"Bengali\", \"Kannada\"], \"ml\": [\"Kannada\", \"Marathi\", \"Tamil\"],\"mr\": [\"Kannada\", \"Malayalam\", \"Nepali\"], \"te\": [\"Hindi\", \"Bengali\", \"Nepali\"], \"kn\": [\"Malayalam\",\"Marathi\", \"Tamil\"], phonological: \"en\": [\"Indonesian\", \"Russian\", \"Catalan\"], \"ru\": [\"Catalan\", \"Hungarian\", \"Hindi\"], \"de\":[\"French\", \"Hungarian\", \"English\"], \"zh\": [\"Italian\", \"Dutch\", \"Arabic\"], \"fr\": [\"German\", \"Hungarian\",\"Hindi\"], \"es\": [\"English\", \"Russian\", \"Catalan\"], \"it\": [\"Chinese\", \"Dutch\", \"Arabic\"], \"nl\": [\"Chinese\",\"Italian\", \"Arabic\"], \"vi\": [\"Indonesian\", \"English\", \"Russian\"], \"id\": [\"English\", \"Russian\", \"Catalan\"],\"ar\": [\"Chinese\", \"Italian\", \"Dutch\"], \"hu\": [\"Russian\", \"Catalan\", \"German\"], \"ro\": [\"Russian\",\"Catalan\", \"German\"], \"da\": [\"Chinese\", \"Italian\", \"Dutch\"], \"sk\": [\"Chinese\", \"Italian\", \"Dutch\"],\"uk\": [\"Chinese\", \"Italian\", \"Dutch\"], \"ca\": [\"Russian\", \"Hungarian\", \"Hindi\"], \"sr\": [\"Spanish\",\"Chinese\", \"Italian\"], \"hr\": [\"Chinese\", \"Italian\", \"Dutch\"], \"hi\": [\"Russian\", \"Catalan\", \"French\"],\"bn\": [\"Telugu\", \"Kannada\", \"Russian\"], \"ta\": [\"Chinese\", \"Italian\", \"Dutch\"], \"ne\": [\"Romanian\",\"Telugu\", \"Kannada\"], \"ml\": [\"Chinese\", \"Italian\", \"Dutch\"], \"mr\": [\"Chinese\", \"Italian\", \"Dutch\"],\"te\": [\"Kannada\", \"Russian\", \"Catalan\"], \"kn\": [\"Kannada\", \"Russian\", \"Catalan\"],",
  ": Related languages across different method settings, part 2": "WVS: \"en\": [\"English\", \"English\", \"English\"], \"ru\": [\"Ukrainian\", \"Romanian\", \"Russian\"], \"de\":[\"German\", \"Dutch\", \"Danish\"], \"zh\": [\"Chinese\", \"Chinese\", \"Chinese\"], \"fr\": [\"French\", \"Slovak\",\"Hungarian\"], \"es\": [\"French\", \"Slovak\", \"Hungarian\"], \"it\": [\"French\", \"Slovak\", \"Hungarian\"], \"nl\":[\"German\", \"Dutch\", \"Danish\"], \"vi\": [\"Vietnamese\", \"Vietnamese\", \"Vietnamese\"], \"id\": [\"Indone-sian\", \"Indonesian\", \"Indonesian\"], \"ar\": [\"Arabic\", \"Hindi\", \"Bengali\"], \"hu\": [\"French\", \"Slovak\",\"Hungarian\"], \"ro\": [\"Ukrainian\", \"Romanian\", \"Russian\"], \"da\": [\"German\", \"Dutch\", \"Danish\"], \"sk\":[\"French\", \"Slovak\", \"Hungarian\"], \"uk\": [\"Ukrainian\", \"Romanian\", \"Russian\"], \"ca\": [\"Catalan\",\"Catalan\", \"Catalan\"], \"sr\": [\"Serbian\", \"Serbian\", \"Serbian\"], \"hr\": [\"French\", \"Slovak\", \"Hungarian\"],\"hi\": [\"Arabic\", \"Hindi\", \"Bengali\"], \"bn\": [\"Arabic\", \"Hindi\", \"Bengali\"], \"ta\": [\"Arabic\", \"Hindi\",\"Bengali\"], \"ne\": [\"Arabic\", \"Hindi\", \"Bengali\"], \"ml\": [\"Arabic\", \"Hindi\", \"Bengali\"], \"mr\": [\"Arabic\",\"Hindi\", \"Bengali\"], \"te\": [\"Arabic\", \"Hindi\", \"Bengali\"], \"kn\": [\"Arabic\", \"Hindi\", \"Bengali\"], LLM-generated: \"en\": [\"Frisian\", \"Dutch\", \"German\"], \"ru\": [\"Belarusian\", \"Ukrainian\", \"Rusyn\"],\"de\": [\"Dutch\", \"Luxembourgish\", \"Yiddish\"], \"zh\": [\"Cantonese\", \"Shanghainese\", \"Hokkien\"], \"fr\":[\"Italian\", \"Spanish\", \"Catalan\"], \"es\": [\"Portuguese\", \"Catalan\", \"Italian\"], \"it\": [\"Sicilian\", \"Neapoli-tan\", \"Tuscan\"], \"nl\": [\"Afrikaans\", \"Frisian\", \"German\"], \"vi\": [\"Muong\", \"Khmer\", \"Mon\"], \"id\":[\"Malay\", \"Minangkabau\", \"Javanese\"], \"ar\": [\"Hebrew\", \"Aramaic\", \"Amharic\"], \"hu\": [\"Finnish\", \"Es-tonian\", \"Udmurt\"], \"ro\": [\"Italian\", \"Spanish\", \"French\"], \"da\": [\"Swedish\", \"Norwegian\", \"Icelandic\"],\"sk\": [\"Czech\", \"Polish\", \"Slovene\"], \"uk\": [\"Russian\", \"Belarusian\", \"Rusyn\"], \"ca\": [\"Occitan\",\"Spanish\", \"French\"], \"sr\": [\"Croatian\", \"Bosnian\", \"Montenegrin\"], \"hr\": [\"Serbian\", \"Bosnian\",\"Montenegrin\"], \"hi\": [\"Urdu\", \"Punjabi\", \"Bengali\"], \"bn\": [\"Assamese\", \"Odia\", \"Maithili\"], \"ta\":[\"Kannada\", \"Telugu\", \"Malayalam\"], \"ne\": [\"Maithili\", \"Bhojpuri\", \"Awadhi\"], \"ml\": [\"Tamil\", \"Tulu\",\"Kannada\"], \"mr\": [\"Konkani\", \"Sanskrit\", \"Gujarati\"], \"te\": [\"Kannada\", \"Tamil\", \"Malayalam\"], \"kn\":[\"Telugu\", \"Tamil\", \"Tulu\"],",
  "Feedback 1:": "(translated: Ordinary people are complex and differ in their feelings and moods. They also have a lotof negative thinking and are less politically motivated. In contrast, this type of people resort to votingpersonally and endorse candidates to hold some seats as a minority in the presidential candidate. Thestudy shows that the majority of individuals participating in the electoral process find this situationinteresting in terms of empathy and embrace. It differs in terms of negative thinking. People usuallybelieve that this situation was not due to their feelings towards politics, but due to their lack ofparticipation.) Feedback 2:Zvycajne je obycajn clovek, ktor podporuje kandidtov z celho ttu, zvycajne ludom plneneznmym. Umonuj volicom hlasovat za svojho kandidta a predstavuj ho podla svojho nzoru.Kede na zvolenie kandidta je potrebn nejak druh spolocnho zvolenia, zskali dal hlas clenoviazvolitelskej delegcie a tto s usilujci o cast na zvolovan. O takto psobenie sa postar delegtzvolitelskej delegcie, ktor je ludom plne neznmy.(translated: Usually, an ordinary person who supports candidates from all over the state, usually topeople completely unknown. They allow voters to vote for their candidate and represent him accordingto their opinion. Since some kind of common election is needed to elect a candidate, additional voteswere obtained by members of the electors delegation, who are seeking to participate in the election. Adelegate of the electors delegation, who is completely unknown to people, will take care of this action.) Feedback 3:Delegaterne fra staten har ofte mere viden om politik end de fleste almindelige mennesker.(translated: The states delegates often have more knowledge about politics than most ordinary people.)",
  ": Working example one, where the three pieces of feedback unanimously point out the error in the answer": "Question: A: B: C: D: (translated: Which of the following provides most of the information about the structure of the Earthscore, mantle, and lower crust? A: Measuring the strength and fluctuations of the Earths magnetic fieldB: Detecting plumes of molten rock C: Collecting samples from deep drilling D: Studying the speedand paths of seismic waves passing through the Earth)",
  ": Working example two, where there is a conflict among the three feedback": "Question: A: B: C: D: (translated: Which statement is correct about delegates to the presidential nominating convention? A:Delegates are more likely to register as third-party voters at some point. B: Most ordinary people havea higher level of education than delegates. C: Delegates generally have less interest in politics. D:Typically, ordinary people have less ideology than delegates.)"
}