{
  "Abstract": "Event Causality Identification (ECI) aims atdetermining the existence of a causal relationbetween two events. Although recent promptlearning-based approaches have shown promis-ing improvements on the ECI task, their per-formance are often subject to the delicate de-sign of multiple prompts and the positive cor-relations between the main task and derivatetasks. The in-context learning paradigm pro-vides explicit guidance for label prediction inthe prompt learning paradigm, alleviating its re-liance on complex prompts and derivative tasks.However, it does not distinguish between pos-itive and negative demonstrations for analogylearning. Motivated from such considerations,this paper proposes an In-Context ContrastiveLearning (ICCL) model that utilizes contrastivelearning to enhance the effectiveness of bothpositive and negative demonstrations. Addi-tionally, we apply contrastive learning to eventpairs to better facilitate event causality identi-fication. Our ICCL is evaluated on the widelyused corpora, including the EventStoryLineand Causal-TimeBank, and results show sig-nificant performance improvements over thestate-of-the-art algorithms. 1",
  "Introduction": "Event Causality Identification (ECI) is to detectwhether there exists a causal relation between twoevent mentions in a document. It is of great impor-tance for many Natural Language Processing (NLP)applications, such as question answer (Breja andJain, 2020), machine reading comprehension (Be-rant et al., 2014), and etc. Furthermore, It also hasmany practical applications in real-world scenarios,such as event prediction (Preethi et al., 2015; Radin-sky et al., 2012) and strategy optimization (Balgiet al., 2022). illustrates an event causality",
  ": Illustration of our motivation. The event pairsare highlighted in different colors": "example from the Event StoryLine Corpus (ESC).We concatenated two causal demonstrations andtwo non-causal demonstrations before the query tobe predicted, and enhanced the analogy betweenthe query and demonstrations through contrastive.Ultimately, our ICCL model determined the causal-ity between the two events, \"died\" and \"shield\", inthe query.Some graph-based methods have been proposedfor the ECI task (Zhao et al., 2021; Phu andNguyen, 2021; Pu et al., 2023), which apply agraph structure to represent events and their poten-tial relations. For example, Zhao et al. (2021) ini-tialize event nodes embeddings using a document-level encoder and employ a graph inference mech-anism to update their embeddings. Pu et al. (2023)incorporate causal label information and event pairinteraction information to enhance the representa-tion learning for event nodes in the graph. Thesemethods follow the traditional representation learn-ing for classification yet on a graph structure.Recently the prompt learning paradigm (Liu et al., 2023) has shown its great successes in manyNLP tasks, as it can well leverage the potentialsof a pre-trained language model (PLM). Some re-searchers have applied the prompt learning for theECI task (Liu et al., 2021b; Shen et al., 2022). Forexample, the DPJL model (Shen et al., 2022) de-signs a main cloze task but also designs two deriva-tive prompt tasks. Although the DPJL has achievednew state-of-the-art performance, it involves thedelicate design of multiple prompts and relies onthe positive correlations between the main task andderivative tasks.The in-context learning paradigm (Dong et al., 2022) includes some demonstrations with theirground-truth labels into the query prompt to learnsome patterns hidden in demostrations when mak-ing its prediction. However, it does not distin-guish between positive and negative demonstra-tions for analogy. Motivated from such considera-tions, we propose to use contrastive learning on thein-context demonstrations to enhance the effective-ness of analogy, as illustrated in . Besides, wealso argue that the semantic of event mentions arethe most important for the causal relation identifi-cation between them. As such we apply contrastivelearning to the representation of event mentions inin-context demonstrations, so as to distinguishingthe semantic between causal and non-causal eventpairs and facilitating event causality predictions.In this paper,we propose an In-ContextContrastive Learning (ICCL) model for the ECItask. The ICCL model contains three modules.The prompt learning module reformulates an in-put event pair and some retrieved demonstrationsinto a prompt template, as the input for PLM en-coding. The in-context contrastive module opti-mizes the representation of event mention by si-multaneously maximizing its agreement with posi-tive demonstrations and minimizing with negativeones, via a contrastive loss. The causality pre-diction module predicts answer word to identifycausal relations. Experiments are conducted on thewidely used EventStoryLine and Causal-TimeBankcorpora, and results have shown that our ICCLachieves the new state-of-the-art performance forthe ECI task.",
  "Event Causality Identification (ECI) is an essen-tial task in information extraction, attracting sig-": "nificant attention due to its wide range of poten-tial applications.Early methods mainly reliedon designing task-oriented neural network models(Liu et al., 2021b; Zuo et al., 2021a). For exam-ple, Liu et al. (2021b) improve the capability oftheir neural model to identify previously unseencausal relations by incorporating event-agnosticand context-specific patterns derived from the Con-ceptNet (Speer et al., 2017). With further explo-ration of graph structures and the emergence oflarge-scale PLMs, recent studies have increasinglyadopted graph-based and prompt-based learningapproaches to address the ECI task.Graph-based approaches usually model the ECItask as a node classification problem, employ-ing graph neural networks to learn event noderepresentations based on contextual semantics atthe document level (Phu and Nguyen, 2021; Caoet al., 2021; Fan et al., 2022). For example, Fanet al. (2022) establish explicit connections betweenevents, mentions and contexts to construct a co-occurrence graph for node representation learn-ing and causal relation identification. In additionto node classification, some studies approach theECI task as a graph-based edge prediction problem(Zhao et al., 2021; Chen et al., 2022). For example,Zhao et al. (2021) initialize event node embeddingsusing a document-level encoder based on a PLMand employ a graph inference mechanism to predictcausal edges through graph updating.",
  "Prompt-based Causality Identification": "Recently, with the help of large-scale PLMs, suchas the BERT (Devlin et al., 2018), RoBERTa (Liuet al., 2019) and etc, prompt learning has emergedas a new paradigm for various NLP tasks (Xi-ang et al., 2022; Ding et al., 2021). It convertsdownstream tasks into the similar form as pre-training task, which aligns objectives between thetwo stages. This alignment helps bridging the gapbetween PLM and task and can directly enhance theperformance of a downstream task. Moreover, re-searchers have also devised appropriate prompts toreframe ECI task as a cloze task (Shen et al., 2022;Liu et al., 2021b). For example, Shen et al. (2022)propose a derivative prompt joint learning modelthat leverages potential causal knowledge withinPLMs based on the causal cue words detection. Liuet al. (2021b) use an event mention masking gener-alization mechanism to encode some event causal-ity patterns for causal relation reasoning. Althoughprompt-based methods are constrained by complex",
  "Task Formulation": "We apply the prompt learning paradigm to trans-form the ECI task into a causal relation cloze task,utilizing a PLM to predict answer words for causalrelation identification. As the event mentions areannotated by a few words in a sentence, we usethe event mentions E1 and E2 of an event pair aswell as their raw sentences S1 and S2, as the in-put x = {E1, E2, S1, S2}, where E1 S1 andE2 S2. The virtual answer words <causal>and <none> indicating whether there is a causalrelation between the input event pair, are used asthe output y {<causal>, <none>}. We notethat in cases where E1 and E2 originate from thesame sentence, S1 and S2 refer to the same sen-tence.",
  "As illustrated in the bottom of , we first refor-mulate each input instance x = {E1, E2, S1, S2}into a kind of in-context prompt template T(x),": "as the input of a PLM for encoding.The in-context prompt input contains a query instanceand K retrieved demonstrations. The query in-stance is the input event instance, denoted as q ={Eq1, Eq2, Sq1, Sq2}, with the causal relation betweentwo events to be identified. The demonstrations areretrieved from the training dataset, consisting ofan event mention pair and their raw sentences, aswell as the relation label between them, denoted asdk = {Ek1, Ek2, Sk1, Sk2, yk}. We randomly selectM demonstrations labeled with <causal> rela-tion and N demonstrations labeled with <none>relation, denoted as d+m and dn , respectively.We design a prediction prompt template Tp(q)for the query instance q and an analogy prompttemplate Ta(dk) for its retrieved demonstrations dk,respectively. Both of them are constructed by con-catenating the raw sentences with a simple clozetemplate, as follows:",
  "[start] + Ek1 + yk + Ek2 + [end]": "where Eq1, Eq2, Sq1, Sq1 are the two event mentionsand their raw sentences, and the PLM-specific to-ken [start] and [end] are used to indicate the be-ginning and ending of the cloze template. For pre-diction prompt template Tp(q), a PLM-specific to- ken [MASK] is inserted between two event mentionsfor relation prediction; For analogy prompt tem-plate Ta(dk), it is replaced by the virtual word ofthe relation label yk for each demostrations, i.e.<causal> or <none>.The in-context prompt template T(x) is con-structed by concatenating the prediction prompttempalte Tp(q) and some analogy prompt templatesTa(dk) of its retrieved demonstrations, as follows:",
  "+ Ta(d1 ) [SEP] . . . Ta(dN) [SEP] + Tp(q) [SEP]": "where the PLM-specific token [CLS] and [SEP] areused to indicate the beginning and ending of aninput, and some [SEP] tokens are used as separatorsbetween the query and those demonstrations. Notethat, the causal demonstrations d+m are positionedbefore the none causal demonstrations dn . Weprovide a specific example of in-context prompttemplate input in Appendix C.After the PLM encoding, we obtain a hiddenstate h Rd for each input tokens, where d is thedimension of hidden states. We denote the hiddenstate of input [MASK] token as hmask for causal-ity prediction. The hidden states of input eventpair in query instance, retrieved causal and none-causal demonstrations are denoted as [hqe1, hqe2],[hm+e1 , hm+e2 ] and [hne1 , hne2 ], respectively, whichare next used for in-context contrastive learning.",
  "In-context Contrastive Module": "The in-context contrastive module optimizes therepresentation of event mention by simultaneouslymaximizing its agreement with positive demonstra-tion samples and minimizing with negative ones,via a contrastive loss. In the training phase, we usethe input query instance as an anchor. The retrieveddemonstrations with the same relation label as thequery are positive samples, while those with differ-ent relation label are negative samples. We assumethat the querys label is <causal>, so the causaldemonstrations d+m being treated as positives, andnon-causal ones dn as negatives.Motivated by the fact that the offsets of pre-trained word embeddings can model the relation-ship between them (Mikolov et al., 2013; Pen-nington et al., 2014; Chen et al., 2016), such ashking hman hqueen hwoman. We use theoffsets between event mentions hidden states torepresent their relation for contrastive learning, as",
  "zn = hne1 hne2 ,(3)": "where zq, z+m, zn are the relation vector of eventpair in query instance, positive and negative demon-strations, respectively.We adpot supervised constrastive learning on therelation vector of event pair for its representationoptimization (Khosla et al., 2020). Specifically, itpulls together the anchor towards positive samplesin embedding space, while simultaneously pushingit apart from negative samples. The supervisedcontrastive loss is computed as follows:",
  "Datasets": "Our experiments are conducted on two widelyused datasets for the ECI task: EventStory-Line0.9 Corpus (ESC) (Caselli and Vossen, 2017)and Causal-TimeBank Corpus (CTB) (Mirza andTonelli, 2014).EventStoryLine contains 22 topics and 258 doc-uments collected from various news websites. Intotal, there are 5,334 event mentions in ECS dataset.Among them, 5,625 event pairs are annotated withcausal relations. Specifically, 1,770 causal relationsare intra-sentence causalities, while 3,855 ones arecross-sentence causalities. Following the standarddata splitting Gao et al. (2019), we use the last twotopics as the development set, and conduct 5-foldcross-validation on the remaining 20 topics. Theaverage results of precision (P), recall (R), and F1score are adopted as performance metrics.Causal-TimeBank comprises 184 documentssourced from English news articles, with a totalof 7,608 annotated event pairs. Among them, 318are annotated with causal relations. Specifically,300 causal relations are intra-sentence causalities,while only 18 ones are cross-sentence causalities.Following the standard data splitting (Liu et al.,2021a), we employ a 10-fold cross-validation andthe average results of precision (P), recall (R), andF1 score are adopted as performance metrics. Fol-lowing Phu and Nguyen (2021), we only conductintra-sentence event causality identification exper-",
  "Parameter Setting": "We use the pre-trained RoBERTa (Liu et al., 2019)model with 768-dimension base version providedby the HuggingFace transformers2 (Wolf et al.,2020). Our implementation is based on PyTorchframework3, running on NVIDIA GTX 3090 GPUs.The training process costs approximately 5 GPUhours on average. We set the learning rate to 1e-5,batch size to 16. The contrastive loss ratio isset to 0.5, the temperature parameter is set to1.0, and the number of demonstrations is set to 4,viz. (M, N) = (2, 2). All trainable parameters arerandomly initialized from normal distributions.",
  "Competitors": "We compare our ICCL with the following com-petitors: ILP (Gao et al., 2019), KnowMMR (Liuet al., 2021b), RichGCN (Phu and Nguyen, 2021),CauSeRL (Zuo et al., 2021a), LSIN (Cao et al.,2021), LearnDA (Zuo et al., 2021b), GESI (Fanet al., 2022), ERGO (Chen et al., 2022), DPJL(Shen et al., 2022), SemSln (Hu et al., 2023). Thedetailed introduction of competitors can be foundin Appendix B.",
  "Overall Result": "compares the overall performance betweenour ICCL and the competitors on the ESC and CTBcorpus. We can observe that the ILP cannot outper-form other competitors, including the RichGCN,GESI, ERGO, and SemSln. This can be attributedto their utilization of some graph neural networksfor document structure encoding, enabling themto learn global contextual semantic for causalityprediction. We can also observe that the DPJLadopting a kind of derivative prompt learning cansignificantly outperform the other competitors inintra-sentence causality identification. The out-standing performance can be attributed to its apply-ing the prompt learning paradigm that transformsthe ECI task to directly predict a PLM vocabularyword, other than fine-tuning a task-specific neuralmodel upon a PLM. Although some other competi-tors have used external knowledge bases for rela-",
  ": Comparison of overall results on the ESC and CTB corpus": "tion identification, the prompt learning paradigmcan better leverages potential causal knowledge inPLMs.Finally, our ICCL with different PLMs hasachieved significant performance improvementsoverall competitors in terms of much higher F1score with all intra-sentence, inter-sentence, andoverall event causality identification on both ESCand CTB corpus. We attribute its outstanding per-formance to applying contrastive learning on in-context demonstrations, by which our ICCL canbetter distinguish the semantic of causal and non-causal event pairs for causality prediction. Fur-thermore, we can also observe that using differentPLMs do result in some performance variations,which are further discussed in Appendix A. Finallythe ICCL based on RoBERTa has achieved the bestperformance, as such we implement the remainingablation experiments with RoBERTa.",
  "Ablation Study": "To examine the effectiveness of contrastive learningand in-context learning, we design the followingablation study. compares their perfomance. Prompt is prompt learning model, withoutdemonstrations or contrastive module. In-context is in-context learning model, in-cluding retrieved demonstrations but without con-trastive module. ProCon w/o Demos is prompt based con-trastive model, but without demonstrations. Weselect positive and negative samples within batchinsted of demonstrations, and use hidden state of[MASK] as input to contrastive module. ProCon w/ Demos is in-context based con-trastive model with retrieved demonstrations, butstill use the hidden state of [MASK] as input to con-trastive module.",
  "EvtCon is event based prompt contrastivemodel, the only difference with ProCon w/o De-mos is using hidden states of event pairs as con-trastive module inputs": "In-context learning: The first observationis that models incorporating in-context learningperform better. For example, the three models,In-context, ProCon w/ Demos and ICCL out-perform Prompt, ProCon w/o Demos and Evt-Con, respectively. This indicates the inclusion ofdemonstrations to explicitly guide the label predic-tion is highly effective in improving model perfor-mance. Furthermore, models with in-context learn-ing show notable performance gains in challegingcross-sentence causality identification. Thats be-cause randomly selected demonstrations are pre-dominantly composed of cross-sentence samples,which are more abundant in datasets. Therefore,PLMs develop a more comprehensive understand-ing of cross-sentence causality. Contrastive learning: We can observe thatmodels with a contrastive module exhibit betterperformance. For example, both ProCon w/ De-mos and EvtCon preform bette than Prompt. Ad-ditionally, both ProCon w/o Demos and ICCLpreform bette than In-context. This can be at-tributed to the utilization of the contrastive learningparadigm, which enables the PLM to concentrateon event pairs or [MASK] and enhances PLMs abil-ity to model them. Furthermore, it also helps dis-criminatively model positive and negative demon-strations, strengthening analogy between the queryand all demonstrations. Additionally, we also ob-serve that EvtCon usually outperformes ProConw/o Demos. Thats because hidden state of [MASK]serves as input for both contrastive and predictionmodule in the case of ProCon w/o Demos, yetthe optimization directions of two modules do not",
  "Numbers of demonstrations": "To further investigate the impact of demonstrations,we conducted an experiment that compared theperformance of In-context and ICCL with varyingnumbers of causal and non-causal demonstrations.The results are showcased in .With more demonstrations, F1-score of bothmodels initially exhibited improved performance,further validating the effectiveness of using demon-strations as explicit guidance. However, as theinput length becomes too long, performance of In-context declines, while the performance of ICCLcontinues to improve. This can be attributed to theeffectiveness of contrastive module used in ICCL,which aids the PLM in better focusing on eventpairs, even with longer input. Additionally, thecausal/non-causal ratio of 2/1 performs better com-pared to that of 1/2. Thats because the datasetcontains a limited number of causal samples. In-creasing the number of causal demonstrations helpsthe model better learn the features of causal exam-ples, mitigating the data imbalance issue.We can also observe that performance metricsof In-context model, particularly precision, exhibitminimal changes when the number of demonstra-tions varies. While as for our ICCL model, the pre-cision and recall vary based on the ratio of causaland non-causal demonstrations. More non-causaldemonstrations results in higher recall, while theopposite scenario leads to higher precision. Thesefindings emphasize that the critical role of the con-trastive module in enhancing analogy and enablingthe PLM to effectively utilize positive and negativedemonstrations.",
  ": Comparision of ICCL and In-context modelwhen using differenr numbers of causal and non-causaldemonstrations on ESC corpus": "our ICCL also employs a prompt-based methodto predict the label, we examine its performancein low-resource scenarios and replicate the perfor-mance of ERGO as a benchmark for comparison. shows the performance comparison betweenERGO and our ICCL on ESC corpus.As expected, the performance of ICCL graduallydecreases as the amount of training data decreases.However, the decrease in performance is relativelyslow, with an F1 score decrease of about 10% whentraining data is reduced by 80%, whereas the perfor-mance of ERGO declined by nearly 25%. Notably,even with only 20% of the training data, ICCL(F1: 51.9%) outperformes ERGO (F1: 50.9%)and many other competitors with full training data.These results confirm the effectiveness of ICCLeven with fewer training data.We also showcase the intra-sentence causalityidentification performance among different PLMs 100%80%60%40%20% Training data Percentage F1 score +6 +19+20+22 +24 +14 +22+23 +25 +26 (%) ERGO overallICCL overall ERGO intraERGO crossICCL intraICCL cross",
  ": Intra-sentence causality identification results ofdifferent PLMs and LLMs on the ESC and CTB corpus": "and several zero-shot models in the . Wecan not only find that our fine-tuned generativemodel, T5 (Our implementation), perform signifi-cantly worse than autoencoder models like BERT-base (Gao et al., 2023) and RoBERTa-base (Gaoet al., 2023), which confirms the conclusion drawnby Gao et al. (2023) that generative models may notbe well-suited for causal reasoning tasks like ECI.We can also observe that although the ChatGPTmodels, such as gpt-3.5-turbo and gpt-4, havemore comprehensive pre-training and larger modelscales, these zero-shot models exhibit a significantperformance gap compared to fine-tuned modelslike T5-base and et al. This demonstrates the impor-tance of fine-tune, indicating that it is challengingto address causal reasoning tasks like ECI in a zero-shot scenario. For more detailed analysis, pleaserefer to Appendix A.",
  "Embedding Visualization": "In order to verify the impact of contrastive mod-ule with event pairs as input, we compare thelearned event pairs embeddings (he1 he2) of dif-ferent models on ESC test dataset by t-distributedstochastic neighbor embedding (t-SNE) (Hintonand Roweis, 2002). In , we color-coded thepoints to represent True Nagetive (TN), False Pos- F1 score: 61.7%",
  ": Visualization of the event pairs embeddingencoded by different models on ESC corpus": "itive (FP), False Nagetive (FN) and True Positive(TP) samples.We can ovserve that models incorporating thecontrastive module with event pairs as input exhibita clear phenomenon of event pairs representationsclustering together based on labels in the embed-ding space, which demonstrates the effective of thecontrastive module. Additionally, representationsof samples predicted to have the same label tendedto cluster together, highlighting the crucial role ofevent pairs in identifying causality.",
  "Concluding Remarks": "In this paper, we propose an ICCL model and applyit on the ECI task. We leverage the causality knowl-edge of PLM by introducing explicit guidancethrough the inclusion of demonstrations, ratherthan relying on the design of complex prompts.Meanwhile, we employ contrastive learning withevent pairs as input to enhance the PLMs attentionto event pairs and strengthen the analogy betweenquery and demonstrations. Experiments on theESC and CTB corpus have validated that our ICCLcan significantly outperform the state-of-the-art al-gorithms.In future, we will try to undertake experiments toapply our proposed framework to other NLP tasksin order to explore whether it can exhibit favorableadaptability when applied to different tasks.",
  "Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan,Lawrence Carin, and Weizhu Chen. 2021a. Whatmakes good in-context examples for gpt-3? arXivpreprint arXiv:2101.06804": "Jian Liu, Yubo Chen, and Jun Zhao. 2021b. Knowl-edge enhanced event causality identification withmention masking generalizations. In Proceedings ofthe Twenty-Ninth International Conference on Inter-national Joint Conferences on Artificial Intelligence,pages 36083614. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,Hiroaki Hayashi, and Graham Neubig. 2023. Pre-train, prompt, and predict: A systematic survey ofprompting methods in natural language processing.ACM Computing Surveys, 55(9):135. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,Luke Zettlemoyer, and Veselin Stoyanov. 2019.Roberta: A robustly optimized bert pretraining ap-proach. arXiv preprint arXiv:1907.11692.",
  "Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-frey Dean. 2013.Efficient estimation of wordrepresentations in vector space.arXiv preprintarXiv:1301.3781": "Paramita Mirza and Sara Tonelli. 2014. An analysis ofcausality between events and its relation to tempo-ral information. In Proceedings of COLING 2014,the 25th International Conference on ComputationalLinguistics: Technical Papers, pages 20972106. Jeffrey Pennington, Richard Socher, and Christopher DManning. 2014. Glove: Global vectors for word rep-resentation. In Proceedings of the 2014 conferenceon empirical methods in natural language processing(EMNLP), pages 15321543. Minh Tran Phu and Thien Huu Nguyen. 2021. Graphconvolutional networks for event causality identifi-cation with rich document-level structures. In Pro-ceedings of the 2021 conference of the North Amer-ican chapter of the association for computationallinguistics: Human language technologies, pages34803490.",
  "KiraRadinsky,SagieDavidovich,andShaulMarkovitch. 2012.Learning causality for newsevents prediction.In Proceedings of the 21stinternational conference on World Wide Web, pages909918": "Colin Raffel, Noam Shazeer, Adam Roberts, KatherineLee, Sharan Narang, Michael Matena, Yanqi Zhou,Wei Li, and Peter J Liu. 2020. Exploring the limitsof transfer learning with a unified text-to-text trans-former. The Journal of Machine Learning Research,21(1):54855551. Shirong Shen, Heng Zhou, Tongtong Wu, and Guilin Qi.2022. Event causality identification via derivativeprompt joint learning. In Proceedings of the 29thInternational Conference on Computational Linguis-tics, pages 22882299.",
  "Robyn Speer, Joshua Chin, and Catherine Havasi. 2017.Conceptnet 5.5: An open multilingual graph of gen-eral knowledge. In Proceedings of the AAAI confer-ence on artificial intelligence, volume 31": "Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, XuyiChen, Han Zhang, Xin Tian, Danxiang Zhu, HaoTian, and Hua Wu. 2019. Ernie: Enhanced represen-tation through knowledge integration. arXiv preprintarXiv:1904.09223. Chengyu Wang, Jianing Wang, Minghui Qiu, JunHuang, and Ming Gao. 2021. Transprompt: Towardsan automatic transferable prompting framework forfew-shot text classification. In Proceedings of the2021 conference on empirical methods in naturallanguage processing, pages 27922802. Thomas Wolf, Lysandre Debut, Victor Sanh, JulienChaumond, Clement Delangue, Anthony Moi, Pier-ric Cistac, Tim Rault, Rmi Louf, Morgan Funtowicz,et al. 2020. Transformers: State-of-the-art naturallanguage processing. In Proceedings of the 2020 con-ference on empirical methods in natural languageprocessing: system demonstrations, pages 3845. Wei Xiang, Zhenglin Wang, Lu Dai, and Bang Wang.2022. Connprompt: Connective-cloze prompt learn-ing for implicit discourse relation recognition. InProceedings of the 29th International Conference onComputational Linguistics, pages 902911.",
  "Kun Zhao, Donghong Ji, Fazhi He, Yijiang Liu, andYafeng Ren. 2021. Document-level event causalityidentification via graph inference mechanism. Infor-mation Sciences, 561:115129": "Xinyu Zuo, Pengfei Cao, Yubo Chen, Kang Liu, JunZhao, Weihua Peng, and Yuguang Chen. 2021a.Improving event causality identification via self-supervised representation learning on external causalstatement. arXiv preprint arXiv:2106.01654. Xinyu Zuo, Pengfei Cao, Yubo Chen, Kang Liu, JunZhao, Weihua Peng, and Yuguang Chen. 2021b.Learnda: Learnable knowledge-guided data aug-mentation for event causality identification. arXivpreprint arXiv:2106.01649.",
  "AStudy of PLMs": "The ICCL model we proposed is a PLM-sensitivemodel. In order to investigate the performanceof our model using different PLMs and select themost suitable one, we conducted PLM ablation ex-periment to test performance of our model withdifferenr PLMs. Furthermore, we also cited perfor-mance of some baseline methods based on PLMsfinetuned on full training datasets from the workof Gao et al. (2023) to evaluate various PLMs andsummarized the results in . The introduc-tions of main PLMs we considered are as follows: BERT (Devlin et al., 2018): The most repre-sentive PLM proposed by Google4, which is pre-trained using a cloze task and a next sentence pre-diction task. RoBERTa (Liu et al., 2019): A BERT en-hanced PLM proposed by Facebook5, which re-moves the next sentence prediction objective andis pre-trained on a much larger dataset with somemodified key hyper-parameters. ERNIE (Sun et al., 2019): A knowledge en-haced PLM proposed by Baidu6, which uses someknowledgeable masking strategies in pre-training. DeBERTa (He et al., 2020): The latest maskedPLM proposed by Microsoft7, which improvesBERT and RoBERTa models using a disentangledattention mechanism and an enhanced mask de-coder. T5 (Raffel et al., 2020): A generative languagemodel proposed by Google8 in 2020, which is pre-trained on large-scale unsupervised datasets usingan autoregressive approach and fine-tuned on task-specific annotated data. It has achieved state-of-the-art performance on multiple NLP tasks such astext generation, summarization, and translation.As shown in , according to the researchby Gao et al. (2023), it can be observed that,ourfine-tuned generative model, T5-base, performssignificantly worse than autoencoder models likeBERT-base (Gao et al., 2023) and RoBERTa-base(Gao et al., 2023). Moreover, the performance ofIn-context-T5 is also far inferior to the model In-context-RoBERTa. This confirms the conclusion drawn by Gao et al. (2023) that generative mod-els may not be well-suited for causal reasoningtasks like ECI. Additionally, although the ChatGPTmodels, such as gpt-3.5-turbo) and gpt-4, havemore comprehensive pre-training and larger modelscales, these zero-shot models exhibit a significantperformance gap compared to fine-tuned modelslike T5-base and et al. This demonstrates the impor-tance of fine-tune, indicating that it is challengingto address causal reasoning tasks like ECI in a zero-shot scenario.Besides, we can observe that our ICCL with allfour PLMs has achieved better performance thanmost of competitors on both ESC and CTB cor-pus. Even our ICCL-BERT outperformed manycompetitors with advanced PLMs, such as ERGObased on Longformer(Beltagy et al., 2020). Thisfurther demonstrates the effectiveness of our pro-posed method. Compared to approaches involvingcomplex prompts or joint training across multipletasks, our approach of utilizing simple explicit guid-ance and leveraging it for contextual contrastivelearning better harnesses the semantic knowledgeembedded in PLMs and guides their understandingof causal relationships.We can also observe that using different PLMsdo result in some performance variations. This isnot unexpected. It can be attributed to that whileall the four PLMs employ a kind of Transformer-based model in pre-training on large-scale cor-pus, their training strategies or training corpusare not entirely identical.Compared to ICCL-BERT, our ICCL model using ERNIE, DeBERTa,or RoBERTa achieved better performance. This isattributed to the fact that these three PLMs havemade some optimizations based on BERT. For ex-ample, ERNIE utilizes a strategy of continuouslearning in the pre-training stage. Finally, ICCL-RoBERTa achieved the best performance, whichremoves the next sentence prediction objective andis pre-trained on a much larger dataset with somemodified key hyper-parameters. Therefore, we im-plement the remaining ablation experiments withRoBERTa.",
  "In-context-T563.362.662.753.746.649.357.051.553.79.250.414.8In-context-RoBERTa66.072.468.957.760.959.160.464.562.260.358.058.7": "ILP (Gao et al., 2019)38.852.444.635.148.240.636.249.541.9---KnowMMR (Liu et al., 2021b)41.962.550.1------36.655.644.1RichGCN (Phu and Nguyen, 2021)49.263.055.239.245.742.242.651.346.639.756.546.7CauSeRL (Zuo et al., 2021a)41.969.052.1------43.668.153.2LSIN (Cao et al., 2021)47.958.152.5------51.556.253.7LearnDA (Zuo et al., 2021b)42.269.852.6------41.968.051.9GESI (Fan et al., 2022)--50.3--49.3--49.4---ERGO (Chen et al., 2022)57.572.063.951.643.347.148.653.450.962.161.361.7DPJL (Shen et al., 2022)65.370.867.9------63.666.764.6SemSln (Hu et al., 2023)64.265.764.9------52.365.858.3 ICCL-BERT64.969.667.156.358.457.259.061.960.460.558.459.1ICCL-ERNIE66.868.567.563.756.259.564.860.062.164.866.064.7ICCL-DeBERTa67.673.770.461.858.459.961.763.263.366.764.464.9ICCL-RoBERTa67.573.770.460.362.761.362.666.164.263.768.865.4 : Comparison of overall results on the ESC and CTB corpus. Performance of models marked with \"\" afterthe name are cited from the research of Gao et al. (2023). We name our models in the format of Model-PLM, forexample, ICCL-BERT is the version of ICCL model based on BERT. corporating causal constraints at document level. KnowMMR (Liu et al., 2021b) utilizes externalknowledge to extract event causality patterns. RichGCN (Phu and Nguyen, 2021) usesa graph convolutional network to learn context-enriched representations for event pairs based ondocument-level information. CauSeRL (Zuo et al., 2021a) employs a con-trastive approach to transfer externally learnedcausal statements. LSIN (Cao et al., 2021) employs graph induc-tion to acquire external structural and relationalknowledge. LearnDA (Zuo et al., 2021b) utilizes knowl-edge bases to interactively generate training data. GESI (Fan et al., 2022) designs a graph con-volutional network on an event co-reference graphto model causality. ERGO (Chen et al., 2022) constructs a rela-tional graph where event pairs serve as nodes, cap-turing causal transitivity through a transformer-likenetwork. DPJL (Shen et al., 2022) leverages two deriva-tive prompt tasks to identify causality. SemSln (Hu et al., 2023) uses a Graph NeuralNetwork (GNN) to learn from event-centric struc-",
  "CIn-context input": "To help readers gain a better understanding of thein-context input generated by our Prompt module,we provide a specific example in .As depicted in , we randomly chose twocausal demonstrations and two non-causal demon-strations from the training dataset for the query.Each segment in represents either a prompteddemonstration or a prompted query. The initialtwo segments, highlighted in green font, representsdemonstrations labeled as < causal >. The fol-lowing two segments, highlighted in orange font,represents demonstrations labeled as < none >.Lastly, the final segment, highlighted in purple font,represents the query to predict.Besides, we have annotated some specific to-kens we used with special colors. We utilized threePLM-special tokens: [CLS] to indicate the begin-ning of the input, [SEP] as a sentence separator,and [MASK] as a placeholder for the label to pre-dict. Furthermore, we have also devised some ad-ditional special tokens: [start] and [end] are usedto indicate the beginning and end of the cloze tem-",
  ": Comparision of ICCL model with differentvalue of on the ESC corpus": "plate respectively, [event1], [event1/], [event2],[event2/] are used to highlight the events in thequery, while < causal > and < none > respecti-valy represent the causal and uncausal labels forthe demonstrations. Additionally, although the contrastive moduleonly works during the training phase, we selectappropriate demonstrations for the query in bothtraining and testing phases. Specifically, we ran-domly select M samples labeled as < causal >and N samples labeled as < none > from train-ing dataset to be demonstrations. And on the con-trastive learning process, positive demonstrationsare those with the same label as the query, whilenegative demonstrations have different labels. Fur-thermore, during training phase, different demon-strations are retrieved for the same query in differ-ent epochs to introduce variability and enhance themodels ability to handle diverse instances of thesame query. However, during validation and testingstate, demonstrations retrieved for the same query,as well as the permutation order, remain consistentacross epochs which ensures fair evaluation.",
  "DStudy of": "To further explore how to balance the importance ofcontrastive loss and prediction loss, we investigatedthe performance of the ICCL model with differentvalues of the hyperparameter on the ESC corpus.As shown in , we can observe that as increases from 0, the performance of the modelinitially improves and then starts to decline. Theoptimal performance on both intra-sentence causal-ity and cross-sentence causality is achieved when = 0.5 . This indicates that the introduction of con-trastive learning loss does indeed help the modelbetter focus on event pairs of the query and demon-strations, understand causalities, and achieve betterperformance. However, it is important to strike abalance between the contrastive learning loss andthe prediction loss. Excessive emphasis on the for-mer should be avoided as it may cause the modelto overly prioritize modeling event pairs and over-look the semantic relevance of the context, whichcan ultimately lead to a decrease in the modelsperformance."
}