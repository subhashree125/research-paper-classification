{
  "Abstract": "Collecting diverse human opinions is costlyand challenging. This leads to a recent trend inexploiting large language models (LLMs) forgenerating diverse data for potential scalableand efficient solutions. However, the extentto which LLMs can generate diverse perspec-tives on subjective topics is still unclear. Inthis study, we explore LLMs capacity of gen-erating diverse perspectives and rationales onsubjective topics such as social norms and ar-gumentative texts. We introduce the problemof extracting maximum diversity from LLMs.Motivated by how humans form opinions basedon values, we propose a criteria-based prompt-ing technique to ground diverse opinions. Tosee how far we can extract diverse perspectivesfrom LLMs, or called diversity coverage, weemploy a step-by-step recall prompting to gen-erate more outputs from the model iteratively.Our methods, applied to various tasks, showthat LLMs can indeed produce diverse opinionsaccording to the degree of task subjectivity. Wealso find that LLMs performance of extractingmaximum diversity is on par with human.1",
  "Introduction": "Using NLP for tasks that require social reason-ing or involve human subjectivity like argumenta-tion (Hidey et al., 2017) or toxicity detection (Sapet al., 2019) often calls for diverse perspectives. In-stead of providing a single viewpoint, an ideal NLPmodel should accommodate various perspectivesto avoid any bias towards a dominant one. Priorworks emphasize the importance of modeling mul-tiple viewpoints (Plank, 2022; Abercrombie et al.,2022). Some studies have addressed this challengeby gathering responses from multiple human an-notators with diverse backgrounds (Rottger et al.,",
  "Human": ": LLMs are trained on texts written by differentpeople who may have distinct perspectives. Our studyexamines whether LLMs can do reverse modeling ofhumans perspectives from the training data and howmuch diversity coverage LLMs can generate. (A checkmark = Agree and a cross mark =Disagree) 2022; Santy et al., 2023). However, this approachis costly in time and resources. Recent advance-ments of LLMs have gained much interest fromresearchers to exploit their capability of creativegeneration for data augmentation with less cost andhigher diversity (Cegin et al., 2023; Chung et al.,2023; Bubeck et al., 2023).LLM is known as a compressed parametricknowledge (e.g., blurry JPEG) of the training cor-pus (Chiang, 2023), and our work study how peo-ples pluralistic diverse opinions are compressedin the parameter and how far we can reversely ex-tract them from an LLM. illustrates thesignificance of understanding the extent of diver-sity achievable by LLMs. During training, LLMs",
  "creativityinnovationrisk-taking": ": People can have different opinions given asubjective statement. Given a statement, humans canagree or disagree with the statement with their owncriteria (e.g., teamwork, risk-taking) in deciding theirstances. have access to various writings from humans withdistinct values. Yet, can LLMs reflect this diversitywhen generating text, or do they tend to favor ma-jority opinions? How do LLM-generated opinionsoverlap with human viewpoints? If the purple circlein hypothetically represents the maximumdiversity achievable by humans, we aim to exploremethods for LLMs to approach this diversity.In real-world scenarios, humans may take dif-ferent stances on a subjective statement (). For instance, those valuing teamwork and goalachievements may agree with the statement, whileothers valuing creativity and innovation could op-pose it. Then the key question is: How many andwhat diverse perspectives do LLMs model?We introduce a novel problem called maximumdiversity extraction from LLMs. Formally, our taskinvolves (1) asking LLMs to generate as many dif-ferent stances as possible, (2) providing reasons foreach stance, and (3) producing important criteriawords that guide their reasoning process. We ap-ply this diversity prompting across four subjectivetasks: social norms, argumentation, hate speechlabeling, and story continuation.",
  "ContributionsFirst, we propose perspective di-versity as a new focus for generative LLMs, dis-tinct from lexical, syntactical, and semantic diver-": "sity mainly explored in previous studies. Throughvarious experiments, we assess LLMs capacityto achieve maximum perspective diversity. Sec-ond, we introduce criteria-based diversity prompt-ing to extract and ground diverse perspectives fromLLMs. Finally, we suggest a step-by-step recall ap-proach to measure the extent of diversity coverageof LLMs, comparing the coverage between LLM-generated opinions with human-authored opinions.Our study reveals a saturation point in the diver-sity that LLMs can achieve, depending on the sub-jectivity of a task. Also, LLMs generally producemore diverse opinions than an individual human,but two or more humans achieve greater diversity.Regarding the quality of LLMs generation, LLMis able to generate opinions which are semanticallysimilar to human opinions. However, some fre-quent criteria words by LLM are different fromwhat humans consider as important.",
  "Motivation": "First, we present the motivation behind our ap-proach. Imagine engaging in a debate with some-one over a controversial topic. Effective debatersoften employ overarching framing to shape theirarguments persuasively and coherently. For exam-ple, framing arguments around power dynamicsor creativity can effectively challenge the givenstatement as shown in the disagree examples in. We refer to these framing keywords ascriteria. Opinions guided by these criteria couldbe more diverse as they are grounded in the combi-nation of various criteria words.",
  "Criteria-Based vs. Free-formWe then comparemodels diversity performance on two prompting": "settings: with criteria vs. without criteria (free-form). From our experiments (.1), wefound that the criteria-based prompting methodenables the model to generate important criteria forframing high-level decisions and providing well-grounded reasons. The criteria list can also be seenas reflecting the models values. This approachfollows human reasoning, where personal valuesoften guide opinions and behavior (Rokeach, 1973;Kesberg and Keller, 2018).Motivated by recent advancements in few-shotlearning that have enhanced model performance onchallenging tasks, we utilize in-context promptingto explore the models capacity to generate diverseopinions.2 (Perez et al., 2021; Min et al., 2022b,a;Lu et al., 2022). The output format is structured asa Python dictionary to be parsed for diversity evalu-ation. Each few-shot example contains ten opinions- five agreeing with the statement and five disagree-ing. This setting does not influence the number ofgenerated opinions and the content of each opinion,as we found cases when the model produces animbalanced number of stances or opinions fewerthan 10 (details in Appendix A.9). We also test thebest-performing model with a zero-shot approach. Human Evaluation on Model-Generated Opin-ionsTo ensure the quality of model-generatedopinions, we conduct human inspections to verifyif each opinion entails its corresponding statementand stance. Over 99% of opinions in randomly sam-pled opinion-statement pairs were found to alignaccurately. We also examine whether the gener-ated criteria words entail the free-form reasons theysupport; 96% of opinions in randomly sampledopinion-criteria pairs demonstrated this entailment.Further details about this process are described inthe Appendix A.11 and A.12.",
  "Step 2: Step-by-Step Recall Prompting toMaximize Diversity Incrementally": "Once we identify the best setups, we expand ourdiversity prompting approach to include step-by-step recall prompting to assess the LLMs diver-sity coverage. In this experiment, no examples areprovided in the prompt. Instead, we only extractone opinion for a given statement and prompt themodel to generate additional opinions iterativelyuntil reaching a specified number, N ().Without 1-shot demonstration, weaker LLMs of-ten struggle to produce structured outputs. The",
  "+": ": Step-by-step recall prompting. The statementand first generated opinion become the demonstrationfor prompting the LLM to generate N opinions. Theblue-colored parts (Steps 1 and 2) are done incremen-tally with step size = 3. purpose of this recall prompting experiment is toidentify the saturation point of the models di-versity, which is the maximum number of uniquediverse opinions an LLM can generate.Acrosstheexperiment,wesetN{2, 5, 8, 11, 14, 17, 20}.Thefirstopiniongenerated by the LLM guides the structured outputformat since few-shot prompting is not employedin this experiment.",
  "Models and Prompting": "We experiment primarily with four GPT variants:GPT-4o3, GPT-4, GPT-3.5 (OpenAI, 2023), andGPT-3 (text-davinci-002) (Brown et al., 2020),along with Llama3-70b-chat4 and Mixtral 8x7B(Jiang et al., 2024). Our baseline involves free-formprompting, where the model generates its stanceand reasoning without generating criteria words.Our primary prompting setup uses in-context learn-ing with one example of ten opinions per statement.We also compare with five-shot prompting acrossall LLMs and zero-shot prompting only for thestrongest model, GPT-4, as weaker models maystruggle to generate structured outputs without ex-amples. In step-by-step recall prompting experi-ments, we vary the number of opinions generated.",
  "Model Input (one-shot example below)": "Statement: Its okay to have privacyTell me opinions about the statement as many as possible from different people with, Agree or Disagree, one-word orone-phrase criteria that is important for their opinions, and explain how they have different opinionsOutput:{1:{Stance :Agree,Criteria: [personal boundaries, autonomy],Reason: Having privacy allows individuals to establish personal boundaries and maintain.their autonomy.\"},2: {Stance: Disagree\",Criteria: [transparency, trust],Reason: Lack of privacy can promote transparency and build trust in relationships....10: {Stance: ...\", Criteria: [...], Reason: ...\"}}...Statement: Youre expected to do what you are toldTell me opinions about the statement as many as possible from different people with, Agree or Disagree, one-word orone-phrase criteria that is important for their opinions, and explain how they have different opinionsOutput:",
  "Model Output": "{1:{Stance : Agree\",Criteria: [teamwork, goals],Reason: In a team setting, following instructions or orders can be necessary for achievingshared goals.},...10: {Stance: ...\", Criteria: [...], Reason: ...\"}} : Example prompt for criteria-based diversity prompting. Prompt for the free-form prompting is all the sameexcept for not having the Criteria. Full prompts for free-form prompting and criteria prompting are shown in A.2. Since social norms depend on many factors suchas the groups beliefs and cultures (Ajzen, 1991;Shweder, 1990), this dataset is suitable for our taskof maximizing LLMs diversity capability. Forour study, we randomly sampled 500 texts for thecriteria-based vs. free-form prompting experimentand 200 texts for the step-by-step recall prompting. CHANGE MY VIEW (CMV)consists of de-bates from online forum threads of the subredditChange My View collected by Hidey et al. (2017).We only take the title of each discussion since itis usually the claim of the argument, resulting ina total of 67 unique claims. We use this dataset toexamine if LLMs can produce diverse opinions ona highly subjective task because an argumentationtask could be highly controversial (van Eemerenet al., 2015). HATE SPEECHdataset contains texts catego-rized as either hate or not hate speech. (Vid-gen et al., 2021). From this dataset, we randomlysample 200 instances, focusing only on implicithate speech texts which are harder to detect. Hatespeech detection is a subjective task because an-notators background may affect how they rate thehate speech label of a text (Sap et al., 2019; Ghoshet al., 2021). We add this task for the step-by-steprecall prompting experiment to show how criteria-",
  "based prompting can be applied to subjective label-ing problems": "MORAL STORIESis a crowd-sourced narrativestory dataset (Emelin et al., 2021). For this study,the LLM needs to continue the story with the sit-uation part as. We also randomly sample 200 in-stances from this dataset and use this dataset forthe step-by-step recall prompting experiment toshow how our prompting method can be applied toopen-ended generation problems.",
  "Evaluation Metric": "Semantic diversityTo examine the semantic di-versity of the models reasons using both criteria-based and free-form prompting, we convert theLLM-generated reasons for each statementinto sentence embeddings using SentenceBERT(Reimers and Gurevych, 2019) with DistilRoberta(Sanh et al., 2019). Next, we compute the cosinedistance between every pair of reasons and calcu-late the average cosine distance across all pairs tomeasure the statements semantic diversity score.We average these scores across all statements toobtain the overall semantic diversity.",
  "(b) CMV": ": Semantic diversity score for different LLMs and prompting methods for SOCIAL-CHEM-101 (left) andCMV (right) datasets. Criteria-based prompting is the best diversity extraction method for across LLMvariants, datasets, and various shots. We also found that too many examples may hurt diversity (5-shot results).The results on SOCIAL-CHEM-101 are statistically significant with p < 0.05 (GPT-4) and p < 0.01 (the rest of themodels) and p < 0.01 for GPT-3 and Mixtral for CMV. with similar meanings can be conveyed in differ-ent ways. For instance, given a statement It isexpected that friends will enjoy being around eachother, the model could generate two opinions; anopinion may contain joy as one of the criteriawhile the other opinion contains happiness. Weprompt GPT-4 with 3 examples to cluster criteriawords with similar meanings into groups (detailsin A.4). Two human annotators manually inspect1,159 clusters of criteria words from 100 randomlysampled statements across SOCIAL-CHEM-101,CMV, HATE SPEECH, and MORAL STORIES (25statements per dataset). From this study, the anno-tators agree that an average of 80.95% of those clus-ters of criteria words have similar meanings withinter-annotator percentage agreement of 88.85%.To measure perspective diversity, we count the num-",
  "Semantically Diverse Opinions aboutSocial Norms and Argumentation": "presents our experiment findings regardingsemantic diversity. One-shot prompting on GPT-4 produces notably more semantically diversereasons compared to other models. Interestingly,weaker models like Mixtral and GPT-3 benefit mostfrom having criteria to guide them toward generat-ing semantically diverse opinions.When we prompt GPT-4 without examples andask for structured outputs only, it tends to gener-",
  "(d) Moral Stories": ": X-axis = the number of generated opinions for our diversity coverage experiment. Y-axis = the averagenumber of unique criteria clusters for all statements. Moral Stories do not have stances, so the line is only for allgenerated continued stories. The more subjective a task is, the more LLM can generate unique criteria clusters. ate more diverse reasons with free-form prompting.This aligns with our pilot study where asking cri-teria without examples proved challenging for themodel. Notably, GPT-4 generates an average of 6.8opinions with zero-shot prompting, fewer than allmodels with one-shot prompting (GPT-4: 9.9 opin-ions, Llama3: 10.0, Mixtral: 9.0, GPT-4o: 10.1). shows that criteria-based prompt-ing consistently outperforms free-form prompt-ing across datasets. One-shot prompting particu-larly outputs higher diversity scores than five-shotprompting. This indicates that in five-shot prompt-ing, models tend to adhere more closely to givenexamples, resulting in less diverse outputs com-pared to the one-shot setting. Interestingly, in thezero-shot setting, free-form prompting on GPT-4generates more semantically diverse perspectivesthan criteria-based prompting. We hypothesize thatthis occurs because introducing criteria in theprompt without concrete examples may confusethe model. As a result, the model produces fewerdiverse diverse perspectives compared to the sim-pler free-form prompting.",
  "Diversity Coverage by Step-by-Step RecallPrompting": "shows an increase in the number of uniquecriteria clusters as the step size increases for the re-call step-by-step experiment. For SOCIAL-CHEM-101 and CMV, the model on average generates 8unique criteria clusters for agreeing and 7 for dis-agreeing opinions. For HATE SPEECH, the averagenumber of unique criteria clusters is lower (4 forhate and 5 for not hate). This demonstrates thatlabeling hate speech is less subjective compared tosocial norms (SOCIAL-CHEM-101) or argumenta-tion (CMV). On the other hand, MORAL STORIESshows a different trend, with the model generatingan average of 20 unique criteria clusters. In , we can see examples of opinions generated per",
  ": Different task types with the maximum and themedian of the number of unique criteria clusters. Moredetails are in": "statement for the recall prompting experiment.Since we limit the maximum number of gener-ated opinions (N = 20), the lines on the graphin may seem not to have converged yet.However, increasing N does not necessarily leadto a higher number of unique clusters as this is task-dependent (see ). For instance, in the hatespeech labeling task, although we set a maximumN = 20, the highest number of unique clustersis 14 for both hate and not hate,\" with averagenumber of unique clusters is 4 and 5, respectively.For open-ended problems such as story continua-tion (MORAL STORIES), increasing N would leadto a greater number of unique clusters.",
  "Human vs. LLMs: Diverse OpinionGeneration": "To assess human capabilities of generating diverseopinions, we hire crowd-workers from AmazonMechanical Turk to generate as many opinions asthey can ( 3) for each stance (agree, disagree)on 100 statements from SOCIAL-CHEM-101 and67 statements from CMV. These statements are asubset of the dataset used in our recall promptingexperiments. Each worker writes opinions for five",
  "statements per HIT, compensated at $2 per HIT": "For each human-written opinion, we query GPT-4 to extract criteria words and cluster them usingthe same method employed for computing perspec-tive diversity of model-generated opinions. shows that humans tend to produce slightly morediverse opinions than LLMs, with approximately1 or 2 more criteria for SOCIAL-CHEM-101 and 3more criteria for CMV. illustrates two statements alongsidetheir respective opinions by humans and GPT-4in T-SNE plot. The statements and opinions areembedded with the same approach for semanticdiversity experiment. We observe that LLMs cangenerate agreeing and disagreeing opinions thatalign with human perspectives, despite LLMsproducing slightly fewer opinions.The failurecases of LLMs occur when human opinions di-verge semantically from the statement (e.g., thelower right under purple circles).",
  ": T-SNE for opinions written by human andgenerated by GPT-4. LLM can mostly generate bothagree and disagree opinions that align with humanwhen they are semantically close to the statement": "Criteria Words by Different LLMs and HumansWe analyze the frequent criteria words generated byGPT-4, Llama3, Mixtral, and humans using T-SNEembeddings in for agreeing and disagree-ing opinions in SOCIAL-CHEM-101. From eachmodel and humans, we select the top 5 frequentcriteria words across all statements and visualizetheir embeddings on a T-SNE plot.For agreeing opinions, in general the three LLMsquite align with humans. GPT-4 and Llama3 haverespect as the most frequent criterion, and allthree LLMs regard responsibility, safety, andemapthy as important criteria. Meanwhile, hu-mans value trust the most, and only Llama3aligns with human for this value.For the dis-agreeing opinions, we can see that humans valuepersonal growth the most and then followed bycultural norms, communication, privacy, and",
  "self-care": ": T-SNE plots of five most frequent criteria words by humans and three LLMs: GPT-4, Llama3, and Mixtral.The size of a point represents the frequency. Black font refers to the label of all points next to the text. Purple fontfor humans criteria words, green for GPT-4, blue for Llama3, and orange for Mistral. LLMs generally mimichuman values, although at times they tend to regard rule-following notions as important (e.g., responsibilityor safety) for agree opinions and extreme freedom (e.g., independence, boundaries, individuality)for disagreeing opinions more than humans do. honesty. However, only Llama3 also considerspersonal growth as important. In general, allLLMs consider that freedom and autonomyare the most important which sounds more extremecompared to human values.We also examine how much the criteria wordsgenerated by LLMs agree with human responsesusing top-p sampling (p=10%). For both agree-ing and disagreeing opinions, we found that GPT-4 agrees the most with humans (agree: 45.63%,disagree: 39.53%), followed by Llama3 (30.00%and 28.14%), and Mixtral (29.38% and 26.35%).Since the criteria words by humans are extractedby GPT-4, there may be a lexical bias toward wordsthat GPT-4 frequently uses. However, the T-SNEplot displays the semantic closeness of the criteriawords by these different LLMs and humans. Allthree LLMs align well with humans with a ten-dency of favoring rule-following criteria words foragreeing opinions and extreme independence fordisagreeing opinions. When Will Human Reach LLMs Diversity Gen-eration Capability?To examine how many hu-mans are needed to match the diversity generationcapability of LLMs, we compute the difference ofthe number of unique clusters of criteria in humanopinions vs. GPT-4s generation. visual-izes the distribution of these differences betweenhumans and GPT-4. Our analysis indicates that aperson tends to generate fewer unique perspectivescompared to GPT-4. However, a pair of humans 1 (Individual)2 (Pair)3 (All) Number of Humans Difference of # Unique Criteria (humans - GPT-4)",
  "Related Work": "Diversity in NLPDiversity in NLP has been ex-tensively explored across various dimensions: (1)lexical variability (Duek and Kasner, 2020; Tevetand Berant, 2021; Li et al., 2016); (2) syntactical di-versity (Giulianelli et al., 2023; Huang et al., 2023);(3) semantic diversity (Stasaski and Hearst, 2022;Reimers and Gurevych, 2019; Zhang et al., 2020);and (4) perspective diversity (Plank, 2022; Hayatiet al., 2021; Santy et al., 2023). Some studies focuson annotator diversity (Rottger et al., 2022; Wichet al., 2021), while others examine diversity in gen-erated language (Hashimoto et al., 2019; Liu et al.,2023). Our work aligns closely with prior studieson perspective diversity, specifically in examiningstances and rationales generated by LLMs. How-ever, unlike previous research primarily focusingon classification tasks, our investigation encom-passes sentence-level reasoning diversity, offeringa more nuanced perspective. Joshi et al. (2020)argue that NLP research is biased toward Westernperspectives. Thus, diverse perspectives from mi-nority populations are relatively overlooked. Ourwork is important to uncover the extent to whichperspective diversity can be extracted from LLMs. Diversity Generation by LLMsLLMs havebeen utilized extensively to produce diverse syn-thetic datasets, such as paraphrasing (Cegin et al.,2023), structured wiki-like bios for notable figures(Yuan et al., 2022), and instruction datasets (Wanget al., 2023b; Taori et al., 2023; Honovich et al.,2023). Unlike diverse large-scale data generation,Lahoti et al. (2023); Giulianelli et al. (2023) specifi-cally examine variability in model responses. Theypropose novel prompting techniques to enhance di-versity in LLM outputs, particularly concerninggender and cultural prompts.Our work alignsclosely with Lahoti et al. (2023) by advocatingfor fairness in LLM outputs through perspectivediversity, which goes beyond semantic variability.Additionally, our approach is similar to Giu-lianelli et al. (2023) in generating multiple re-sponses per prompt. To promote opinion diversityin LLMs, Aroyo et al. (2023) introduce a dataset la-beled by human raters from different demographicpopulations, focusing on safety such as bias, misin- formation, and harmful content. Despite the previ-ous claim that LLMs can produce diverse content,some studies suggest that co-writing with LLMsmay affect human writers opinions (Jakesch et al.,2023) and reduce writing diversity (Padmakumarand He, 2024). Our research addresses this gap byproposing a method to generate diverse perspec-tives rather than a single dominant opinion.",
  "Conclusion and Future Work": "To the best of our knowledge, this is the first workthat tackles extracting maximum perspective di-versity from LLMs.To do this, we propose acriteria-based prompting method and probe LLMscapacity to generate as many diverse perspectivesas possible and explain their reasons for choos-ing their corresponding stances on subjective state-ments. Through our step-by-step recall prompting,we characterize the subjectivity of various tasks andreach the maximum diversity of LLMs generation.LLMs can generate comparable number of diverseoutputs with humans and similar values as humansresponses. As we compare LLMs opinion gener-ations with humans, they are quite precise asthey are semantically similar to human opinions,bur their recall is slightly lower than humans.While the number of criteria clusters does notprecisely mean the ideal maximum diversity, it in-dicates that we could use LLMs to push further per-spective diversity to include more diverse opinions.Our work opens up a wider range of possibilitiesfor examining more advanced diversity quantifica-tion and maximization methods. There are alsomany application possibilities for extending thiswork in the future. In this study, we have not as-sessed how much the extracted diverse opinions aresimilar with the real worlds diverse opinions yet.Instead, we focus on the diversity coverage. Futurework could evaluate this by comparing the distri-bution of extracted opinions with a distribution ofpeoples opinions collected from real world surveyor poll data. We recommend further exploration ofcultural aspects, persona, or human values on diver-sity extraction. Moreover, our method could be ap-plied for curating diverse data for open-ended tasks,such as generating diverse outputs for instruction-tuning tasks or subjective task labeling. Findingsthat it takes two humans to equalize LLMs diversegeneration capacity suggest that communicationsbetween multiple humans or LLMs can be a futurework to introduce more diverse perspectives.",
  "Limitations and Ethical Considerations": "While our prompting approach does not generatean exhaustive, complete list of diverse opinions,our study serves as a comparative study that exam-ines the capability of various language models forgenerating diverse opinions given various numbersof examples and input datasets. Moreover, for now,we only experimented with our proposed criteria-based prompting technique for subjective tasks. Itwould be interesting future work to try the sametechnique on non-subjective tasks. Currently, werely on LLMs (GPT-4) to generate criteria wordsfrom non-criteria prompting outputs. Future workscould deal with in-depth variations of these criteriaword extraction methods and analyses on the wordsthemselves. We noticed that the demographics of crowd-workers who participate in the opinion writing areskewed toward white with bachelor degree as theirhighest education level. Demographic factors, in-cluding culture, may impact how these opinionsare written. For future work, it would be interest-ing to compare more opinions written by partici-pants from other cultures with the models gener-ated opinions. We also have not explored all different combi-nations of setups of decoding parameters besidescomparing different temperatures and top_p sam-pling during the initial experiments. However, wewould like to highlight that our work is not simplyprobing LLMs ability to generate diverse tokensthat may convey similar meaning, but rather if theLLM has the capability for generating diverse per-spectives. Examining various decoding methodscould be a potential future work for this study. Potential risks could be a situation where ourcriteria-based prompting attempts to generate di-verse opinions on certain topics that are sociallyunacceptable and/or contain harmful content. Tomitigate any concern regarding this issue, we sug-gest that researchers carefully review the content ofsubjects before applying our prompting approachto their work. For the human study, our institution determinedour study as exempt from IRB review. Since thetopic of some statements could trigger human work-ers, we added warnings before the worker couldproceed to work on our task.",
  "Icek Ajzen. 1991. The theory of planned behavior. Or-ganizational behavior and human decision processes,50(2):179211": "Lora Aroyo, Alex S. Taylor, Mark Diaz, Christopher M.Homan, Alicia Parrish, Greg Serapio-Garcia, Vinod-kumar Prabhakaran, and Ding Wang. 2023. Dicesdataset: Diversity in conversational ai evaluation forsafety. Preprint, arXiv:2306.11247. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shotlearners. Advances in neural information processingsystems, 33:18771901. Sbastien Bubeck, Varun Chandrasekaran, Ronen El-dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-berg, et al. 2023. Sparks of artificial general intelli-gence: Early experiments with gpt-4. arXiv preprintarXiv:2303.12712. Jan Cegin, Jakub Simko, and Peter Brusilovsky. 2023.Chatgpt to replace crowdsourcing of paraphrases forintent classification: Higher diversity and comparablemodel robustness. arXiv preprint arXiv:2305.12947.",
  "John Chung, Ece Kamar, and Saleema Amershi. 2023": "Increasing diversity while maintaining accuracy:Text data generation with large language models andhuman interventions. In Proceedings of the 61st An-nual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers), pages 575593,Toronto, Canada. Association for Computational Lin-guistics. Ondrej Duek and Zdenek Kasner. 2020. Evaluatingsemantic accuracy of data-to-text generation with nat-ural language inference. In Proceedings of the 13thInternational Conference on Natural Language Gen-eration, pages 131137, Dublin, Ireland. Associationfor Computational Linguistics.",
  "Denis Emelin, Ronan Le Bras, Jena D. Hwang, MaxwellForbes, and Yejin Choi. 2021. Moral stories: Situ-ated reasoning about norms, intents, actions, and": "their consequences. In Proceedings of the 2021 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 698718, Online and Punta Cana,Dominican Republic. Association for ComputationalLinguistics. Maxwell Forbes, Jena D. Hwang, Vered Shwartz,Maarten Sap, and Yejin Choi. 2020. Social chem-istry 101: Learning to reason about social and moralnorms. In Proceedings of the 2020 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 653670, Online. Association forComputational Linguistics. Sayan Ghosh, Dylan Baker, David Jurgens, and Vin-odkumar Prabhakaran. 2021.Detecting cross-geographic biases in toxicity modeling on social me-dia. In Proceedings of the Seventh Workshop onNoisy User-generated Text (W-NUT 2021), pages313328, Online. Association for Computational Lin-guistics. Mario Giulianelli, Joris Baan, Wilker Aziz, RaquelFernndez, and Barbara Plank. 2023. What comesnext? evaluating uncertainty in neural text generatorsagainst human production variability. In Proceed-ings of the 2023 Conference on Empirical Methods inNatural Language Processing, pages 1434914371,Singapore. Association for Computational Linguis-tics. Tatsunori B. Hashimoto, Hugh Zhang, and Percy Liang.2019. Unifying human and statistical evaluation fornatural language generation. In Proceedings of the2019 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, Volume 1 (Long andShort Papers), pages 16891701, Minneapolis, Min-nesota. Association for Computational Linguistics. Shirley Anugrah Hayati, Dongyeop Kang, and Lyle Un-gar. 2021. Does BERT learn as humans perceive?understanding linguistic styles through lexica. In Pro-ceedings of the 2021 Conference on Empirical Meth-ods in Natural Language Processing, pages 63236331, Online and Punta Cana, Dominican Republic.Association for Computational Linguistics. Christopher Hidey,Elena Musi,Alyssa Hwang,Smaranda Muresan, and Kathy McKeown. 2017. An-alyzing the semantic types of claims and premisesin an online persuasive forum. In Proceedings ofthe 4th Workshop on Argument Mining, pages 1121,Copenhagen, Denmark. Association for Computa-tional Linguistics. Or Honovich, Thomas Scialom, Omer Levy, and TimoSchick. 2023. Unnatural instructions: Tuning lan-guage models with (almost) no human labor.InProceedings of the 61st Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 1440914428, Toronto, Canada.Association for Computational Linguistics.",
  "Kuan-Hao Huang, Varun Iyer, I-Hung Hsu, AnoopKumar, Kai-Wei Chang, and Aram Galstyan. 2023": "ParaAMR: A large-scale syntactically diverse para-phrase dataset by AMR back-translation. In Proceed-ings of the 61st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 80478061, Toronto, Canada. Association forComputational Linguistics. Maurice Jakesch, Advait Bhat, Daniel Buschek, LiorZalmanson, and Mor Naaman. 2023. Co-writing withopinionated language models affects users views. InProceedings of the 2023 CHI Conference on HumanFactors in Computing Systems, CHI 23. ACM. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, Llio Renard Lavaud,Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,Thibaut Lavril, Thomas Wang, Timothe Lacroix,and William El Sayed. 2023. Mistral 7b. Preprint,arXiv:2310.06825. Albert Q Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, Chris Bam-ford, Devendra Singh Chaplot, Diego de las Casas,Emma Bou Hanna, Florian Bressand, et al. 2024.Mixtral of experts. arXiv preprint arXiv:2401.04088. Pratik Joshi, Sebastin Santy, Amar Budhiraja, KalikaBali, and Monojit Choudhury. 2020. The state andfate of linguistic diversity and inclusion in the NLPworld. In Proceedings of the 58th Annual Meeting ofthe Association for Computational Linguistics, pages62826293, Online. Association for ComputationalLinguistics. Rebekka Kesberg and Johannes Keller. 2018. The rela-tion between human values and perceived situationcharacteristics in everyday life. Frontiers in Psy-chology, 9. Place: Switzerland Publisher: FrontiersMedia S.A. Preethi Lahoti, Nicholas Blumm, Xiao Ma, Raghaven-dra Kotikalapudi, Sahitya Potluri, Qijun Tan, HansaSrinivasan, Ben Packer, Ahmad Beirami, Alex Beu-tel, and Jilin Chen. 2023. Improving diversity ofdemographic representation in large language mod-els via collective-critiques and self-voting. Preprint,arXiv:2310.16523. Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,and Bill Dolan. 2016. A diversity-promoting ob-jective function for neural conversation models. InProceedings of the 2016 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 110119, San Diego, California. Associationfor Computational Linguistics.",
  "Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,and Pontus Stenetorp. 2022. Fantastically ordered": "prompts and where to find them: Overcoming few-shot prompt order sensitivity. In Proceedings of the60th Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages80868098, Dublin, Ireland. Association for Compu-tational Linguistics. Sewon Min, Mike Lewis, Luke Zettlemoyer, and Han-naneh Hajishirzi. 2022a. Metaicl: Learning to learnin context. In Proceedings of the 2022 Conferenceof the North American Chapter of the Associationfor Computational Linguistics: Human LanguageTechnologies, pages 27912809. Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,Mike Lewis, Hannaneh Hajishirzi, and Luke Zettle-moyer. 2022b. Rethinking the role of demonstrations:What makes in-context learning work? In Proceed-ings of the 2022 Conference on Empirical Methods inNatural Language Processing, pages 1104811064,Abu Dhabi, United Arab Emirates. Association forComputational Linguistics.",
  "Ethan Perez, Douwe Kiela, and Kyunghyun Cho. 2021.True few-shot learning with language models. Ad-vances in neural information processing systems,34:1105411070": "Barbara Plank. 2022. The problem of human labelvariation: On ground truth in data, modeling andevaluation. In Proceedings of the 2022 Conferenceon Empirical Methods in Natural Language Process-ing, pages 1067110682, Abu Dhabi, United ArabEmirates. Association for Computational Linguistics. Nils Reimers and Iryna Gurevych. 2019.Sentence-BERT: Sentence embeddings using Siamese BERT-networks. In Proceedings of the 2019 Conference onEmpirical Methods in Natural Language Processingand the 9th International Joint Conference on Natu-ral Language Processing (EMNLP-IJCNLP), pages39823992, Hong Kong, China. Association for Com-putational Linguistics.",
  "of bert: smaller, faster, cheaper and lighter. arXivpreprint arXiv:1910.01108": "Sebastin Santy, Jenny Liang, Ronan Le Bras, KatharinaReinecke, and Maarten Sap. 2023. NLPositionality:Characterizing design biases of datasets and models.In Proceedings of the 61st Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 90809102, Toronto, Canada.Association for Computational Linguistics. Maarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi,and Noah A. Smith. 2019. The risk of racial biasin hate speech detection. In Proceedings of the 57thAnnual Meeting of the Association for ComputationalLinguistics, pages 16681678, Florence, Italy. Asso-ciation for Computational Linguistics.",
  "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, YannDubois, Xuechen Li, Carlos Guestrin, Percy Liang,and Tatsunori B. Hashimoto. 2023. Stanford alpaca:An instruction-following llama model": "Guy Tevet and Jonathan Berant. 2021. Evaluating theevaluation of diversity in natural language generation.In Proceedings of the 16th Conference of the Euro-pean Chapter of the Association for ComputationalLinguistics: Main Volume, pages 326346, Online.Association for Computational Linguistics. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian CantonFerrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. 2023. Llama 2: Open foundation and fine-tuned chat models. Preprint, arXiv:2307.09288. Frans H. van Eemeren, Sally Jackson, and Scott Jacobs.2015. Argumentation, pages 325. ArgumentationLibrary. Springer, Germany. Publisher Copyright: 2015, Springer International Publishing Switzerland. Bertie Vidgen, Tristan Thrush, Zeerak Waseem, andDouwe Kiela. 2021. Learning from the worst: Dy-namically generated datasets to improve online hatedetection. In Proceedings of the 59th Annual Meet-ing of the Association for Computational Linguisticsand the 11th International Joint Conference on Natu-ral Language Processing (Volume 1: Long Papers),pages 16671682, Online. Association for Computa-tional Linguistics. Xuezhi Wang, Jason Wei, Dale Schuurmans, QuocLe, Ed Chi, Sharan Narang, Aakanksha Chowdh-ery, and Denny Zhou. 2023a. Self-consistency im-proves chain of thought reasoning in language mod-els. Preprint, arXiv:2203.11171. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, AlisaLiu, Noah A. Smith, Daniel Khashabi, and HannanehHajishirzi. 2023b. Self-instruct: Aligning languagemodels with self-generated instructions. In Proceed-ings of the 61st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 1348413508, Toronto, Canada. Associationfor Computational Linguistics. Jason Wei, Xuezhi Wang, Dale Schuurmans, MaartenBosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, andDenny Zhou. 2023. Chain-of-thought prompting elic-its reasoning in large language models. Preprint,arXiv:2201.11903. Maximilian Wich, Christian Widmer, Gerhard Hagerer,and Georg Groh. 2021. Investigating annotator biasin abusive language datasets. In Proceedings of theInternational Conference on Recent Advances in Nat-ural Language Processing (RANLP 2021), pages15151525, Held Online. INCOMA Ltd. Ann Yuan, Daphne Ippolito, Vitaly Nikolaev, ChrisCallison-Burch,Andy Coenen,and SebastianGehrmann. 2022. Synthbio: A case study in human-ai collaborative curation of text datasets. Preprint,arXiv:2111.06467.",
  "During our pilot study with a smaller number ofsubjective statements, we tried various prompting": "methods, such as (1) zero-shot vs. few-shot prompt-ing; (2) the number of opinions (10, 15, 20) in thefew-shot examples; (3) prompts to generate struc-tured output vs. unstructured output; and (4) vary-ing N greater than 20 (e.g., 30, 50, 100) for ourstep-by-step recall prompting. However, it wouldbe too costly in terms of budget and time to run allthe combinations of set-ups, so we chose the cur-rent setup since it produces enough diverse outputto examine the saturation point and the structuredoutputs are easy to process. We are aware of otherprompting techniques such as Chain-of-Thought(CoT) prompting (Wei et al., 2023), least-to-mostprompting (Zhou et al., 2023), and self-consistencyprompting (Wang et al., 2023a). However, none ofthem handle the task of asking LLM to generatethe maximum diversity. On the other hand, ourdiversity prompting can complement these otherprompting approaches for extracting diversity.",
  "Tell me opinions about the statementas many as possible from differentpeoplewith\"Agree\"or\"Disagree\"and explain how they have differentopinions": "Output: {1:{\"Stance\":\"Agree\",\"Reason\":\"Iwasbroughtupinafamilyandculturewhereusingprofanitywasconsideredimpoliteanddisrespectful,andIhavecontinuedtoholdthatbeliefinmyadultlife.\",2:{\"Stance\":\"Disagree\",\"Reason\":\"Profanitycanbeaformofself-expression,andtherearesituationswhereitmaybeappropriateorevennecessarytouseittoconveystrong emotions or opinions.\"},3:{\"Stance\": \"Agree\", \"Reason\": \"Usingprofanity goes against accepted normsofetiquetteandsocialbehavior,anditisconsideredimpoliteand rudeinmostsocialsettings.\"},4: {\"Stance\": \"Disagree\", \"Reason\":\"Theappropriatenessofprofanitydependsonthecontextandtheindividuals perception, as what maybe acceptable in one situation maynot be in another.\"}, 5: {\"Stance\":\"Agree\",\"Reason\":\"Usingprofanitycandisruptsocialharmonyandrespectfulcommunication,anditis important to maintain a certainlevel of decorum in interactions.\"},6: {\"Stance\": \"Disagree\", \"Reason\":\"Individuals should have the freedomtochoosetheirlanguage,andusingprofanitycanbeawaytoexpress themselves authentically.\"},7: {\"Stance\": \"Disagree\", \"Reason\":\"Incertainculturesorsocieties,theuseofprofanitymaybemoreaccepted or even a normal part ofeveryday language.\"}, 8:{\"Stance\":\"Agree\", \"Reason\": \"In a professionalenvironment, the use of profanity canbeseenasunprofessionalandcannegativelyimpactonesreputationand relationships with colleagues.\"},9:{\"Stance\":\"Disagree\",\"Reason\":\"Profanitycanbeusedinartandcreativeexpressiontoevokeemotions, challenge societal norms,orconveyaspecificmessage.\"},10:{\"Stance\": \"Agree\", \"Reason\": \"Iwas taught from a young age that usingprofanity is rude and disrespectful,and I continue to adhere to thosevalues.\"}}",
  "Statement: Its okay to have privacy.Tell me opinions about the statementas many as possible from differentpeoplewith\"Agree\"or\"Disagree\"and explain how they have differentopinions": "Output:{1:{\"Stance\":\"Agree\",\"Reason\":\"Havingprivacyallowsindividualstoestablishpersonalboundariesandmaintaintheirautonomy.\"},2:{\"Stance\":\"Disagree\",\"Reason\":\"Lackofprivacycanpromotetransparencyand build trust in relationships.\"}, 3:{\"Stance\":\"Agree\",\"Reason\":\"Privacyprovidesasenseofsecurity and protection, especiallyin personal and sensitive matters.\"},4:{\"Stance\":\"Disagree\",\"Reason\":\"Reduced privacy enablesaccountabilityandfacilitatessupervision,ensuringresponsiblebehavior.\"}, 5: {\"Stance\": \"Agree\",\"Reason\":\"Privacycontributestopersonalwell-beingandmentalhealthbyallowingindividualstohavespaceforself-reflectionandrelaxation.\"},6:{\"Stance\":\"Disagree\",\"Reason\":\"Limitedprivacy fosters social connectednessandasenseofcommunity,asindividualssharetheirlivesmoreopenly.\"},7:{\"Stance\":\"Agree\", \"Reason\": \"Privacy fostersintimacyandallowsindividualstobevulnerableinpersonalrelationships.\"},8:{\"Stance\":\"Disagree\",\"Reason\":\"Reducedprivacypromotesopennessandhonesty,asindividualsaremoretransparent about their actions andintentions.\"}, 9: {\"Stance\": \"Agree\",\"Reason\":\"Privacyfacilitatespersonal growth and self-discovery,providingaspaceforindividualstoexploretheirinterestsandidentities.\"},10:{\"Stance\":\"Disagree\",\"Reason\":\"Limitedprivacy enhances safety and securityby allowing for greater surveillanceand monitoring of individuals.\"}} Statement:Its good to confide inyour parents the things that yourestrugglingwith.Tellmeopinionsaboutthestatementasmanyaspossible from different people with\"Agree\" or \"Disagree\" and explain howthey have different opinions.",
  "{1:{\"Stance\":\"Agree\",\"Reason\":\"Confidinginparentscanprovideemotionalsupport,strengthentheparent-childbond,andallowparents to provide guidance in timesofstruggle.\"},2:{\"Stance\":": "\"Disagree\",\"Reason\":\"Someindividualsmayfearjudgmentfromtheirparentsorvaluetheirprivacy,leadingthemtohesitateinconfidingtheirstruggles.\"},3:{\"Stance\":\"Agree\",\"Reason\":\"Sharing struggles with parents canbuild trust and create opportunitiesfor collaborative problem-solving andfinding solutions.\"}, 4:{\"Stance\":\"Disagree\",\"Reason\":\"Someindividualsbelieveinresolvingtheirstrugglesindependently,promotingself-relianceandindependence.\"},5:{\"Stance\":\"Agree\",\"Reason\":\"Confidinginparentsallowsthemtoprovideempathy,understanding,andemotional support during challengingtimes.\"}, 6: {\"Stance\": \"Disagree\",\"Reason\":\"Communicationbarriersoragenerationgapmayhindereffectiveunderstandingandmakeindividuals less likely to confidein their parents.\"}, 7:{\"Stance\":\"Agree\", \"Reason\": \"Parents, havinggonethroughsimilarexperiences,canofferwisdomandadvicebasedontheirownlifelessons.\"},8:{\"Stance\":\"Disagree\",\"Reason\":\"Someindividualsmayhaveexperiencedneglectorunhelpfuladvicefromtheirparentsinthepast, making them hesitant to confidein them.\"}, 9:{\"Stance\":\"Agree\",\"Reason\":\"Sharingstruggleswithparentscanprovideasenseofcatharsisandemotionalreliefbyexpressing emotions and thoughts.\"},10: {\"Stance\": \"Disagree\", \"Reason\":\"Some individuals find more comfortinconfidingtheirstrugglestofriends or other trusted individuals,seeking peer support.\"}}",
  "Output:": "{1:{\"Stance\":\"Agree\", \"Criteria\":[\"empathy\",\"compassion\",\"kindness\"],\"Reason\":\"Helpingothers in tough situations is an actof empathy, compassion, and kindness,and it can make a positive impactontheirlives.\"},2:{\"Stance\":\"Disagree\", \"Criteria\":[\"safety\"],\"Reason\":\"Helping others in toughsituationscanputonespersonalsafetyatriskandmayviolatepersonal boundaries.\"}, 3: {\"Stance\":\"Agree\",\"Criteria\":[\"moralobligation\",\"responsibility\"],\"Reason\":\"Asmembersofsociety,wehaveamoralobligationandresponsibility to help those in need, especially in tough situations.\"}, 4:{\"Stance\":\"Disagree\",\"Criteria\":[\"self-preservation\", \"priorities\"],\"Reason\":\"Insomesituations,prioritizingself-preservationandpersonalprioritiesmaybemoreimportantthanhelpingothersintough situations.\"},5:{\"Stance\":\"Agree\",\"Criteria\":[\"community\",\"solidarity\"],\"Reason\":\"Helpingothers in tough situations fostersa sense of community and solidarity,and it can strengthen social bonds.\"},6: {\"Stance\": \"Disagree\", \"Criteria\":[\"enabling\", \"dependency\"], \"Reason\":\"Helping others in tough situationscanenabledependencyandmaynotaddresstherootcausesoftheirproblems.\"},7:{\"Stance\":\"Agree\",\"Criteria\":[\"altruism\",\"generosity\"],\"Reason\":\"Helpingothersintoughsituationsisanactofaltruismandgenerosity,anditcanbringasenseoffulfillmentandpurpose.\"},8:{\"Stance\":\"Disagree\",\"Criteria\":[\"personalboundaries\",\"consent\"],\"Reason\":\"Helping others in toughsituationsshouldrespectpersonalboundaries and require consent, asforcinghelponsomeonecanbeharmful.\"}, 9:{\"Stance\":\"Agree\",\"Criteria\":[\"humanitarianism\",\"globalresponsibility\"],\"Reason\":\"Helping others in tough situationsisapartofhumanitarianismandglobalresponsibility,anditcancontributetoamorejustandequitable world.\"},10:{\"Stance\":\"Disagree\",\"Criteria\":[\"culturalsensitivity\",\"respect\"],\"Reason\":\"Helping others in tough situationsshouldbedonewithculturalsensitivity and respect, as imposingonesvaluesandbeliefsthroughhelpingotherscanbeharmfulanddisrespectful.\"}}",
  "Statement:Itsrudetouseprofanity": "Tell me opinions about the statementas many as possible from differentpeoplewith\"Agree\"or\"Disagree\",one-word or one-phrase criteria thatisimportantfortheiropinions,and explain how they have differentopinions. Output:{1:{\"Stance\":\"Agree\",\"Criteria\":[\"impolite\",\"disrespectful\",\"culture\",\"family\"], \"Reason\": \"I was broughtup in a family and culture where usingprofanity was considered impolite anddisrespectful, and I have continuedtoholdthatbeliefinmyadultlife.\",2:\"Stance\":\"Disagree\",\"Criteria\":[\"self-expression\",situation],\"Reason\":\"Profanitycanbeaformofself-expression,andtherearesituationswhereitmaybeappropriateorevennecessary to use it to convey strongemotions or opinions.\", 3: {\"Stance\":\"Agree\",\"Criteria\":[\"etiquette\",\"social norms\", \"impolite\", \"rude\"],\"Reason\":\"Usingprofanitygoesagainst accepted norms of etiquetteandsocialbehavior,anditisconsidered impolite and rude in mostsocialsettings.\"},4:{\"Stance\":\"Disagree\", \"Criteria\": [\"contextualappropriateness\",\"individualperception\"],\"Reason\":\"Theappropriateness of profanity dependson the context and the individualsperception, as what may be acceptableinonesituationmaynotbeinanother.\"}, 5:{\"Stance\":\"Agree\",\"Criteria\": [\"harmony\", \"responsiblecommunication\"],\"Reason\":\"Usingprofanity can disrupt social harmonyand respectful communication, and itis important to maintain a certainlevel of decorum in interactions.\"},6:{\"Stance\": \"Disagree\", \"Criteria\":[\"individuality\",\"choice\"], \"Reason\":\"Individualsshouldhavethefreedomtochoosetheirlanguage,andusingprofanitycanbeawaytoexpressthemselvesauthentically.\"},7:{\"Stance\":\"Disagree\", \"Criteria\":[\"culture\",\"society\"],\"Reason\":\"Incertaincultures or societies,the use ofprofanitymaybemoreacceptedorevenanormalpartofeverydaylanguage.\"},8:{\"Stance\":\"Agree\",\"Criteria\":[\"professionalism\",\"workplace\"],\"Reason\":\"Inaprofessionalenvironment,theuseofprofanitycanbeseenasunprofessionalandcannegativelyimpactonesreputationandrelationshipswithcolleagues.\"},9:{\"Stance\":\"Disagree\",\"Criteria\":[\"artisticexpression\",\"creativity\"],\"Reason\":\"Profanitycanbeusedinartandcreativeexpressiontoevokeemotions,challengesocietalnorms,orconveyaspecificmessage.\"},10:{\"Stance\":\"Agree\",\"Criteria\":[\"education\",\"upbringing\"],\"Reason\":\"Iwastaught from a young age that usingprofanity is rude and disrespectful,and I continue to adhere to thosevalues.\"}}",
  "peoplewith\"Agree\"or\"Disagree\",one-word or one-phrase criteria thatisimportantfortheiropinions,and explain how they have differentopinions": "Output:{1:{\"Stance\":\"Agree\",\"Criteria\":[\"cleanliness\",\"respect\"],\"Reason\":\"Allowingpeopletoeatinyourcarcanleadtomessinessanddisrespect for your property.\"}, 2:{\"Stance\":\"Disagree\",\"Criteria\":[\"hospitality\", \"comfort\"], \"Reason\":\"Allowing people to eat in your carcan be a hospitable gesture and makethemfeelmorecomfortable.\"},3:{\"Stance\":\"Agree\",\"Criteria\":[\"odor\",\"stains\"],\"Reason\":\"Allowingpeopletoeatinyourcarcanleaveunpleasantodorsandstainsthataredifficulttoremove.\"}, 4: {\"Stance\": \"Disagree\",\"Criteria\": [\"convenience\", \"time\"],\"Reason\": \"Allowing people to eat inyour car can be convenient and savetime, especially when on the go.\"},5:{\"Stance\":\"Agree\",\"Criteria\":[\"hygiene\",\"health\"],\"Reason\":\"Allowingpeopletoeatinyourcar can compromise hygiene and posehealthrisks,especiallyifthefoodisnotproperlyhandledorstored.\"}, 6: {\"Stance\": \"Disagree\",\"Criteria\":[\"personalchoice\",\"relationship\"], \"Reason\": \"Allowingpeopletoeatinyourcarisapersonalchoiceandcandependonthe relationship with the person andthe circumstances.\"}, 7:{\"Stance\":\"Agree\", \"Criteria\": [\"distraction\",\"safety\"],\"Reason\":\"Allowingpeople to eat in your car can be adistractionandcompromisesafety,especiallyifthedriverisalsoeating.\"}, 8: {\"Stance\": \"Disagree\",\"Criteria\":[\"flexibility\",\"adaptability\", \"social\"], \"Reason\":\"Allowingpeopletoeatinyourcarcandemonstrateflexibilityandadaptability,especiallyinsocial situations.\"}, 9:{\"Stance\": \"Agree\", \"Criteria\": [\"resale value\",\"maintenance\"], \"Reason\":\"Allowingpeople to eat in your car can decreaseitsresalevalueandrequiremoremaintenanceandcleaning.\"},10:{\"Stance\":\"Disagree\",\"Criteria\":[\"culturalnorms\",\"etiquette\"],\"Reason\":\"Allowingpeopletoeatinyourcarcanbeacceptableincertain cultural norms and etiquette,and it depends on the context andsituation.\"}}",
  "A.7Recall Results": "shows how many statements generate thatmany unique criteria clusters. The minimum num-ber could be 0 because GPT-4 clustering is not100% covering all the words. During our robust-ness check on the CMV dataset, 0.4% of the crite-ria words are not grouped (5 out of 1276 in criteriawords). summarizes how task subjectivity im-pacts the diversity coverage by LLMs.",
  "A.9Imbalanced Number of GeneratedOpinions in HATE SPEECH": "We observed that GPT-4 generated an imbalancednumber of opinions between Hate Speech andNot Hate Speech when choosing the labels dur-ing the step-by-step recall prompting experiments(N = 20) for 37.5% of the total 200 statements.This occurrence is substantially higher compared toother datasets, where SOCIAL-CHEM-101 createdan imbalanced number of opinions between stancesfor only 0.5% of the total 200 statements.",
  "A.10Regarding Lexical Diversity": "Following Giulianelli et al. (2023), we computedthe lexical diversity of opinions generated by GPT-4 using n-grams (n {1, 2, 3}), where highern-gram score is interpreted as higher uniqueness(and thus higher diversity as well). We observedthat across all n, the lexical diversity scores of both stances/generated stories for all four datasetsare almost greater than 0.98, which indicates al-most unique words in the LLM-generated opinionswithin the same stance. Thus, in this case, lexicaldiversity metric does not inform us of the differentdegrees of diversity we expected for different tasktypes.",
  "A.11GPT-3.5s Capability on InstructionAlignment": "We analyzed if each opinion generated by GPT-3.5 with a one-shot setting not only entails thecorresponding statement but also aligns with theappropriate stance.In our approach, we usedstratified sampling to validate the quality of opin-ions by criteria-based and free-form promptingmethods, thus obtaining a total of 100 opinionsfrom each dataset: 50 were generated by criteria-based prompting, and 50 by free-form prompting.From these, we randomly selected 25 opinions thatagreed with a given statement and 25 that were indisagreement. Then, we examined the followingtwo criteria for each pair of statement and opinion:(1) if an opinion entails the statement and (2) if thestance of an opinion aligns with the reason in theopinion. We recruited two undergraduate studentswho are proficient in English and currently enrolledin a university in the United States as annotators.The computed percent agreement between the twoannotators was 93% and 85% for the settings (1)and (2), respectively.We observed that all 100 and 99 opinions fromSOCIAL-CHEM-101 and CMV respectively werefound to entail their corresponding statements, indi-cating that the GPT-3.5-generated opinions tend tocorrectly understand the context of each given state-ment and follow the instructions of the prompts.In addition, more than 98% of the samples ineach of the two datasets have their opinions regard-ing a given statement aligned with the generatedstance. We found a misalignment mostly fromthe opinions generated by GPT-3.5 that disagreewith their statement. For example, in the SOCIAL-CHEM-101 dataset, for a statement Its okay towant your partner to do more chores. GPT-3.5generated with criteria-based prompting the fol-lowing opinion that disagrees: Its important torecognize that everyone has different strengths andweaknesses, and its okay if one partner is betterat certain chores than the other. The reason for theopinion itself is contrary to its stance, as it in factsupports the attitude of people making their partner",
  "Model Input (Step-by-step recall prompting, N=2)": "Statement: Its okay to have privacyTell me opinions about the statement as many as possible from 2 different people with, Agree or Disagree, one-word orone-phrase criteria that is important for their opinions, and explain how they have different opinionsOutput:{1:{Stance :Agree,Criteria: [personal boundaries, autonomy],Reason: Having privacy allows individuals to establish personal boundaries and maintain.their autonomy.\"},2: {Stance:",
  "Disagree\",Criteria: [transparency, trust],Reason: Lack of privacy can promote transparency and build trust in relationships": ": Example criteria-based step-by-step recall prompting for investigating LLMs diversity coverage where N= the number of opinions we ask LLMs to generate. The number of opinions in the model input is incrementedstep-by-step. do more chores.We also found another type of logical contradic-tion in a sample of CMV that shows misalignmentbetween the stance and the reason for its generatedopinions. In the statement The EGG came firstbefore the chicken, GPT-3.5 generates with free-from prompting the following disagreeing opinion:The genetic mutation that led to the first chickenwould have occurred in the chickens parents, sothe chicken came first. The opinion sounds seem-ingly reasonable that supports chicken before egg;however, the paradox inside it (i.e., the worlds firstchickens parents are chickens.) does not supportits stance. As a result, we determined this exam-ple is the only sample that shows a contradictionbetween opinion and statement as well.",
  "A.12Evaluation of Generated Criteria Words": "We examined whether the criteria words generatedby GPT-3.5 deliver the main message of the corre-sponding opinion. We recruited two undergraduatestudents who are proficient in English and currentlyenrolled in a university in the United States as an-notators. The percent agreement between the twoannotators was greater than or equal to 95% for allLLM variants for both datasets. We found that atleast 96% of 100 opinions generated by all LLMvariants entailed its corresponding criteria words,for both SOCIAL-CHEM-101 and CMV datasets().Although most generated criteria words directlymatch their corresponding opinions (denoted as ex-plicit), we observed that LLMs can also generateimplicit criteria words, subtly conveying the rea- soning behind opinions. For instance, the opinionSome people are just more irritable by nature, andtheres nothing wrong with that. implicitly con-tains criteria personality and temperament, whichresonate with the core idea of being irritable bynature.While most of the generated criteria wordsseemed to entail their corresponding opinions, wealso found some samples whose criteria wordscould be added by different words in the opinionsfor better representation. For example, for a state-ment If you dont want to be somewhere anymore,you should leave GPT-3.5 in one-shot setting gen-erated the following opinion with bolded criteriawords: Leaving a situation that goes against onespersonal values and integrity is an act of self-respect and authenticity. However, we agreedto consider self-respect and authenticity as the ad-ditional criteria words, since these words also em-phasize an individuals ability to determine theirstance in such a situation.Also, there are some samples of criteria wordsthat entail their corresponding opinion but do notcover the main value of the opinion. For a statementIf youre a nudist, you should go to a nudist beach,the criteria words generated by GPT-3 in a one-shot setting are nudist and beach in the followingopinion: If youre a nudist, you should go to anudist beach so you can be around like-mindedpeople and feel comfortable. However, these wordsare just the repetition of the exact words in thestatement and do not deliver the main reason behindthe opinion; that is, forming a community with thesame perspective and value. We agreed to decide 0.02.55.07.510.012.515.017.5 #unique clusters Agree Max: 17, Median: 8.0, Min: 1 Disagree Max: 16, Median: 7.0, Min: 0 0.0 5.0 10.0 15.0 20.0 25.0 30.0 35.0 #statements AgreeDisagree",
  "A.13Evaluation of Clustered Criteria Words": "In 3.3, we prompted GPT-4 to generate clustersof criteria words that are semantically similar andrandomly sampled 25 clusters from each of thefour datasets, totaling up to 100 clusters. Then,we recruited two volunteers who currently attend a4-year university in the U.S. and are proficient inEnglish. After a 1-hour training session, we askedthem to annotate whether all words in each clusterhave similar meanings.We identified three distinct patterns of GPT-4sfallacies from those 91 clusters (5.8% of the to-tal) of criteria words that both annotators disagreedwith labeling as the ones of all semantically simi-lar words. First, some criteria words are partiallyrepetitive. For example, the clusters (value ap-preciation, sacrifice, appreciation, recogni-tion) and (concern, parental anxiety, personalopinion, personal belief, concerned viewpoint)have repetitive words that do not entirely match the theme of other words in the clusters. Second,some clusters have words of entirely opposing orcause-and-effect themes. For instance, we observethat the cluster (internet addiction, social isola-tion) and (sacrifice, duty) have words that areconsequences for each other. Also, the clusters(distractions, concentration) and (polarization,bias, generalization) show opposing values. Lastly, clusters of which annotators agreed asnot semantically similar present different aspectswithin a broader theme. One cluster (unnecessarylegal battles, parental conflict), for example, isrelated to a theme of conflict, but they occur in dif-ferent contexts (e.g., legal vs family). Another ex-ample is (mental health, physical health, long-term healing), which cover different subtopics of abroader theme of human health. Also, we observethat the cluster (personal integrity, respect forothers property, personal reputation) addressesdifferent aspects of ethical behaviors or social con-duct.",
  "Agree": "1. Individual differences: Children are born with diverse learning styles, talents, and interests.Some may grasp certain subjects easily, while others genuinely struggle.This can be due to natural variations in cognitive abilities, not a lack of parental effort.2. External factors: Socioeconomic realities like poverty, limited access to resources, or even unstablehome environments can have a profound impact on a childs ability to focus and learn.Blaming parents for these external challenges adds an unnecessary layer of guiltand doesnt address the root cause.3. Learning differences and mental health: Undiagnosed learning disabilities like dyslexia or ADHD,or even unseen mental health concerns like anxiety or depression, can significantly hindera childs academic progress. Parents may not be aware of these issues or may be strugglingto get the proper support for their child.",
  "Disagree": "1. Guilt and shame: Parents who are already likely worried about their childs strugglesare burdened with unfair blame, leading to feelings of guilt, shame, and inadequacy.This hinders their ability to effectively support their child.2. Erosion of trust: Blaming parents can create a wall between them and the school,hindering open communication and collaboration, which are essential for finding solutions.3. Overlooking other factors: The focus solely on parental fault distracts from identifyingand addressing the actual root causes of the childs difficulties, ultimately delayingor even preventing progress.",
  "A.14Human Preference on Criteria-basedPrompting": "With three recruited workers via Amazon Mechani-cal Turk (AMT), we examined whether humans pre-fer opinions generated by criteria-based promptingvs. free-form prompting, in terms of perspectivediversity. Fleisss Kappa among three annotatorswas on average 0.46 for both SOCIAL-CHEM-101and CMV datasets, signifying a moderate agree-ment among the workers for both datasets.We computed the proportion of statements wherecriteria-based prompting wins, out of the 50 ran-domly selected statements from SOCIAL-CHEM-101 and 30 from CMV datasets (denoted as winrate of criteria-based prompting). showsthe win rate of criteria-based prompting on eachstance session of both datasets. In general, the opin-ions generated by criteria-based prompting were preferred by humans in more than half of the to-tal statements, except for the agree session ofCMV. This indicates that in more than half of thetotal samples, a majority of crowd-workers con-sider the set of opinions about a statement gener-ated by criteria-based prompting as one presentingmore diverse reasons that support the stance of theopinions.",
  "Hate Speech": "1. They discern this as an attempt to exclude and belittle individuals who chooses to wear burqini,therefore promoting inequality.Criteria: exclusion, belittlement2. They see this as a lack of acceptance towards other cultures and promoting a specific dress codeby discriminating certain types of wear.Criteria: lack of acceptance, discrimination3.They categorize the statement as hateful because it manifests intolerance and bigotry againstindividuals who choose to wear burqini.Criteria: intolerance, bigotry",
  "Not Hate Speech": "1.They believe the statement expresses personal views about swimwear which is part ofthe freedom of expression.Criteria: personal views, freedom of expression2. They perceive the statement as hyperbolic or exaggerated, not intended to cause harm or incite hate.Criteria: hyperbole, exaggeration3. They may interpret this statement as a joke or a misunderstanding, rather than a deliberate attackon a specific group.Criteria: joke, misunderstanding",
  ": Examples of GPT-4 generated opinions for a statement from HATE SPEECH (Top) and another fromMORAL STORIES (Bottom)": "form prompting in a one-shot setting, respectively,were not able to follow the instructions to correctlygenerate the output. Similarly, 67% and 49% ofLLaMA2 with criteria-based and free-form prompt-ing in a one-shot setting, respectively, generatednoisy-structured outputs that did not correctly fol-low the given instructions. Thus, we cannot con-duct comprehensive analyses of these generatedoutputs. For example, given the following statement - Ithink the Paris shooting makes a good case for cul-ture of responsible gun ownership any carrying.,Mistral responded as follows: * Culture of re-sponsible gun ownership + Respect for the powerof firearms + Personal safety + Community security+ Public safety Disagree: * Culture of responsible gun owner-ship + Risk of misuse + Lack of common-sense gunlaws + Strict enforcement of gun laws + Unhealthyfear of criminals + Safety concerns + Danger ofpublic health + Moral values + Culture of gun vio-",
  "A.16More About Human Opinions": "When participants from are asked to pro-vide opinions more than 3 about statements fromSOCIAL-CHEM-101 and CMV, they tend to pro-vide more opinions to the stance that they support,as shown in . This may indicate that hu-mans are likely to be more conservative towardthe stance against their preference. We suggestthat humans interaction with LLMs powered byour criteria-based prompting can also maximizediversity within the human perspectives, creatingmore inclusive environments within a society. Fea-sible future work could also be the evaluation ofcriteria-based prompting on human perspectives inan interactive setting.",
  "-shot1006832988216": ": Number of generated opinions with criteria-based prompting in four different LLM variants. We haverandomly sampled 100 opinions for each LLM variant and counted the number of opinions under that category. Forexample, 96 (%) out of 100 opinions generated by criteria-prompting with GPT-3.5 1-shot setting were entailed byits respective criteria words.",
  "A.17Details about AMT Experiment Setups": "For ,we engaged three workers fromthe Amazon Mechanical Turk (AMT) platform,each of whom (1) lives in one of the five English-speaking countries (U.S., Canada, Australia, NewZealand, and the United Kingdom), (2) achieveda Human Intelligence Task (HIT) approval rateof 99% or higher, as well as (3) the number ofHITs approved greater than 10000 on the platform.Each HIT consists of five statements, and per state-ment each worker was supposed to provide at least3 opinions that both agree and disagree with thestatement, regardless of their personal stance onthe statement.To acquire a pool of workers with better-qualityresponses, we manually reviewed every responsefrom HITs once provided, filtering out the re-sponses that fell short into the following types: (1)irrelevant to our statements; (2) not explaining yourrationales behind your stance; or (3) saying that youjust dont want to provide reasons to any stance.For example, if a participant answers like N/A,Nothing, I dont agree/disagree, Good, Hello,etc. all of which are nonsense, these responses werenot accepted. We compensated those participantswith $2 USD payment for their participation.Tables 11, 12, and 13 presents the demographicdetails of the participants of , for both",
  ": Demographic statistics of the participants of - (2) Race Group. Almost all of the partici-pants identified themselves as White": "For Section A.14We recruited three workersfrom the Amazon Mechanical Turk (AMT) plat-form, each of whom (1) lives in one of the fiveEnglish-speaking countries (U.S., Canada, Aus-tralia, New Zealand, and the United Kingdom),(2) achieved a Human Intelligence Task (HIT) ap-proval rate of 98% or higher, as well as (3) thenumber of HITs approved greater than 10000 onthe platform. Each HIT consists of five statements 3456+ Number of Human-generated Opinions 0.0 20.0 40.0 60.0 80.0 100.0 120.0 140.0 160.0 Number of People Stance (Agree) - Opinion (Agree)Stance (Agree) - Opinion (Disagree)",
  "(d) Human Stance: Disagree": ": The distribution of human-written opinions, separated by the human stance on given statements, inSOCIAL-CHEM-101 (top) and CMV (bottom). Paler-colored bars represent instances where participants were askedto write opinions that opposed their personal stances on a statement. Each bar indicates the count of participantswho provided the number of opinions corresponding to the bars position on the x-axis.",
  ": Demographic statistics of the participantsof - (3) Highest Education Attainment. Weobserved most of the participants obtained bachelorsdegrees": "and a pairwise comparison set of A and B, whereA and B are either criteria-prompting or free-formprompting outputs under anonymity.For each statement, workers were then askedto provide their own stance on that statement andchoose between A and B in terms of which setpossesses a more diverse perspective toward thestatement. To acquire a pool of workers with better- quality responses, we ran a training session beforethe real task, where we also filtered out the work-ers whose responses did not make sense. Onlythe workers who showed above a threshold of ourown were able to proceed to the real tasks. Fortheir efforts, each participant received at least $0.5USD payment for completing the HIT regardlessof the quality of their responses, considering thesimplicity of the task and an anticipated time ofcompletion to be less than 15 minutes. For thosewho showed a well-done performance that passedour threshold, we remunerated each of them with abonus of at least $2 (USD). First, we randomly sampled 50 statements froma dataset.For each statement, we created twoseparate evaluation sessions, one for the agreestance and the other for disagree. In each session,we present the two sets of opinions that have thatstance and are generated by GPT-3.5 in an one-shotsetting: (1) Set A, generated with criteria-basedprompting, and (2) Set B with free-form prompting. The workers were first asked to choose their ownstance on the statement. Then, for each session,they select either set A or B, which they think in-cludes a greater diversity of perspectives that showthe same stance.After the response collection, we aggregated themajority of workers preferences per statement un-der each stance session, and if the majority prefer-ence is the set generated by criteria-based prompt-ing, we considered that criteria-prompting winsover the free-form prompting for the statement.Lastly, we computed the proportion of statementswhere criteria-based prompting wins, out of the 50statements (denoted as win rate of criteria-basedprompting)."
}