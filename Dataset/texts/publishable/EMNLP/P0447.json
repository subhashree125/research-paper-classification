{
  "Abstract": "Learned Sparse Retrieval (LSR) models usevocabularies from pre-trained transformers,which often split entities into nonsensical frag-ments. Splitting entities can reduce retrievalaccuracy and limits the models ability to in-corporate up-to-date world knowledge not in-cluded in the training data. In this work, weenhance the LSR vocabulary with Wikipediaconcepts and entities, enabling the model toresolve ambiguities more effectively and staycurrent with evolving knowledge. Central toour approach is a Dynamic Vocabulary (DyVo)head, which leverages existing entity embed-dings and an entity retrieval component thatidentifies entities relevant to a query or doc-ument. We use the DyVo head to generateentity weights, which are then merged withword piece weights to create joint representa-tions for efficient indexing and retrieval usingan inverted index. In experiments across threeentity-rich document ranking datasets, the re-sulting DyVo model substantially outperformsstate-of-the-art baselines.1",
  "Introduction": "Neural IR methods typically operate in two stages.Initially, a set of candidate documents is retrievedusing a fast, computationally-efficient first-stageretrieval method that considers sparse or densevector representations. These candidates are thenre-ranked using more computationally-intensivescoring functions, such as those involving cross-encoders (Nogueira and Cho, 2019; MacAvaneyet al., 2019; Nogueira et al., 2020; Sun et al., 2023).Learned Sparse Retrieval (LSR) (Nguyen et al., 2023b; Formal et al., 2021, 2022) is a prominentneural method for first-stage retrieval. LSR en-codes queries and documents into sparse, lexically-aligned representations that can be stored in aninverted index for fast retrieval. LSR offers sev-eral advantages over Dense Retrieval (DR), another",
  "w/ bag of word pieces and entities": ": DyVo augments BERTs word piece vocabu-lary with an entity vocabulary to help disambiguate aquery (or document). Word pieces are in blue and enti-ties are in orange. Darker terms have a higher weight inthe sparse representation. common approach for first-stage retrieval (Linet al., 2020). LSRs lexically grounded represen-tations are more transparent, making it easier forusers to understand the model and inspect repre-sentations for biases (Abolghasemi et al., 2024).Furthermore, LSRs compatibility with an invertedindex enables efficient and exact retrieval (Dingand Suel, 2011), while also simplifying the tran-sition from existing lexical search infrastructuresupporting methods like BM25. LSR not only per-forms competitively with DR in terms of perfor-mance within the same domain, but it also tendsto generalize better across different domains andtasks (Formal et al., 2021). However, LSR models lack explicit representa-tions for entities and concepts in their vocabulary.This can pose challenges due to the tokenizationprocess, where words are segmented into subwordsor wordpieces. For instance, a word like BioN-Tech might be tokenized into [bio, ##nte, ##ch].Such fragmentation can lead to ambiguity, compli-cating the retrieval process by obscuring the fullmeaning and context of the original word, whichin turn may affect the accuracy and relevance ofsearch results. Additionally, the bag of word piecesrepresentation employed by LSR methods strug- gles with homonyms, where different meanings orentities, such as WHO (World Health Organiza-tion) and US (United States), could be conflatedwhen represented merely as word pieces in a querylike Is the US a member of WHO? Hence, while LSR provides a framework for ef-ficient first-stage document retrieval, its current de-sign particularly in handling entities and complexvocabulary poses significant challenges. We hy-pothesize that integrating explicit entities into theLSR vocabulary could significantly enhance its per-formance. This integration is especially pertinentas a large proportion of queries pertain to specificentities or are closely related to them (Kumar andTomkins, 2010; Guo et al., 2009). Previous workindicates that hybrid models combining word andentity representations have improved both sparseretrieval (Dalton et al., 2014; Shehata et al., 2022;Mackie et al., 2024) and dense retrieval (Xionget al., 2017a; Tran and Yates, 2022; Chatterjee et al.,2024). To address the above limitations, we incorporateentities from Wikipedia into the vocabulary of anLSR model. The English Wikipedia contains en-tities spanning a diverse range of categories anddisciplines, including named entities like people,organizations, and locations, as well as generalconcepts such as eudaimonia, hot dog, and net in-come. Integrating these Wikipedia entities into aLSR model significantly enhances its ability to han-dle complex semantic phrases and entities that arecurrently fragmented into nonsensical word pieces.By enriching query and document representationswith relevant entities, we reduce ambiguity andimprove the representational power of LSR. Thisapproach is illustrated in . Moreover, lever-aging Wikipedia a rich and continually updatedknowledge base allows the LSR model to refreshits internal knowledge, aligning it with evolvingglobal information. As of April 2024, the English Wikipedia hostsnearly 7 million entities and concepts, which ismore than 200 times larger than the word piecevocabulary used in current state-of-the-art LSRmethods. To identify relevant entities from amongmillions of them, we propose adding a Dynamic Vo-cabulary (DyVo) head with an entity candidate re-trieval component. Specifically, we leverage entityretrieval techniques and Large Language Models(LLMs) to dynamically generate relevant entities.These methods aim to refine the set of highly rel- evant entities, which are then passed to the LSRencoder for scoring. The encoder outputs a smallbag of weighted entities, ignoring those that werenot retrieved. The entity representation is thenconcatenated with the word-piece representation,forming a joint representation used for indexingand retrieval processes. Our contributions are: We propose the DyVo model to address the limi-tations of the word piece vocabulary commonlyemployed in LSR, which uses a Dynamic Vo-cabulary (DyVo) head to extend LSR to a largevocabulary (e.g., millions of Wikipedia entitiesand concepts) by leveraging existing entity em-beddings and a candidate retrieval componentthat identifies a small set of entities to score. We introduce a few-shot generative entity re-trieval approach capable of generating highlyrelevant entity candidates, which leads to supe-rior performance when integrated into our DyVoframework. Furthermore, we find that documentretrieval effectiveness using candidates generatedby Mixtral or GPT4 is competitive with using en-tities identified by human annotators. We demonstrate that incorporating entities intoLSR through a dynamic vocabulary consistentlyenhances the effectiveness of LSR across threeentity-rich benchmark datasets (i.e., TREC Ro-bust04, TREC Core 2018, and CODEC). De-spite its simplicity, Wikipedia2Vec is a surpris-ingly effective source of entity embeddings. Weachieve further performance gains by utilizingtransformer-based dense entity encoders to en-code entity descriptions into embeddings.",
  "Related Work": "Learned sparse retrieval.LSR encodes queriesand documents into sparse lexical vectors, whichare bag of words representations that are indexedand retrieved using an inverted index, akin totraditional lexical retrieval methods like BM25.One of the early works in this area proposed us-ing neural networks to learn sparse representa-tions that are compatible with an inverted indexand demonstrated promising performance (Zamaniet al., 2018). With the advent of the transformer ar-chitecture (Vaswani et al., 2017), subsequent workhas successfully utilized pretrained transformersto enhance the effectiveness and efficiency of LSRmodels (Formal et al., 2021; Lassance and Clin-chant, 2022; Formal et al., 2022; MacAvaney et al., 2020; Zhao et al., 2020; Zhuang and Zuccon, 2021).Among these, SPLADE (Formal et al., 2021, 2022)stands out as a state-of-the-art LSR method. WhileSPLADE uses a word piece vocabulary, prior workhas demonstrated that its vocabulary can be re-placed by performing additional masked languagemodeling (MLM) pretraining and then exhaustivelyscoring all terms in the new vocabulary (Dudeket al., 2023). In this work, we dynamically augmenta word piece vocabulary using pre-existing embed-dings rather than performing additional pretraining.SPLADE typically employs a shared MLM encoderfor both queries and documents, enabling term ex-pansion and weighting on both sides. However,previous work (Nguyen et al., 2023b; MacAvaneyet al., 2020) has shown that removing query expan-sion by replacing the MLM query encoder with anMLP encoder can simplify training and improveefficiency by reducing the number of query termsinvolved. While most LSR research has focused onad-hoc paragraph retrieval tasks, recent efforts haveexplored extending LSR to other settings, such asconversational search (Hai Le et al., 2023), longdocuments (Nguyen et al., 2023a), and text-imagesearch (Zhao et al., 2023; Chen et al., 2023; Nguyenet al., 2024). Entity-oriented search.Early work in entity-oriented search primarily utilized entities for queryexpansion. A significant advancement in this do-main was made by Meij et al. (2010), who intro-duced a double translation process where a querywas first translated into relevant entities, and thenthe terms associated with these entities were usedto expand the query. Dalton et al. (2014) furtherdeveloped this concept with Entity Query FeatureExpansion, which enhanced document retrieval byenriching the query context with entity features.The field then recognized the more integral roleof entities in search applications, transitioningfrom merely using entities for query expansionto treating them as a latent layer while maintain-ing the original document and query representa-tions. Among these methods, Explicit SemanticAnalysis (Gabrilovich and Markovitch, 2009) usedconcept vectors from knowledge repositories likeWikipedia to generate vector-based semantic repre-sentations. The Latent Entity Space model (Liuand Fang, 2015) utilized entities to assess rele-vance between documents and queries based ontheir alignments in the entity-informed dimensions.EsdRank (Xiong and Callan, 2015) leveraged semi- structured data such as controlled vocabularies andknowledge bases to connect queries and documents,pioneering a novel approach to document represen-tation and ranking based on interrelated entities.This progression in research inspired a shift to-wards methodologies that treated entities not justas a latent layer but as explicit, integral elementsof the retrieval model. For example, the creationof entity-based language models marked a signif-icant development. Raviv et al. (2016) exploredthe impact of explicit entity markup within queriesand documents, balancing term-based and entity-based information for document ranking. Ensanand Bagheri (2017) developed the Semantic En-abled Language Model, which ranks documentsbased on semantic relatedness to the query.Xiong et al.s line of work (Xiong et al., 2017b,a, 2018, 2017c) exemplifies a dual-layered approachthat pairs a traditional bag of terms representationwith a separate bag of entities representation, en-hancing the document retrieval process by incorpo-rating both term and entity-based semantics. Forexample, Explicit Semantic Ranking used a knowl-edge graph to create \"soft matches\" in the entityspace, and the Word-Entity Duet Model capturedmultiple interactions between queries and docu-ments using a mixture of term and entity vectors.The Entity-Duet Ranking Model (EDRM) (Liuet al., 2018) represents a pioneering effort in neu-ral entity-based search, merging the word-entityduet framework with the capabilities of neural net-works and knowledge graphs (KGs). Tran andYates (2022) advanced this area by introducing amethod that clusters entities within documents toproduce multiple entity views or perspectives,enhancing the understanding and interpretation ofvarious facets of a document. Recently, Chatter-jee et al. (2024) proposed to learn query-specificweights for entities within candidate documents tore-rank them. Entity ranking.The task of entity ranking in-volves retrieving and ordering entities from aknowledge graph based on their relevance to agiven query. Traditionally, this process has utilizedterm-based representations or descriptions derivedfrom unstructured sources or structured knowledgebases like DBpedia (Lehmann et al., 2015). Rank-ing was commonly performed using models suchas BM25 (Robertson and Zaragoza, 2009). Ad-ditionally, Markov Randon Fields-based modelslike the Sequential Dependence Model (Metzler and Croft, 2005) and its variants (Zhiltsov et al.,2015; Nikolaev et al., 2016; Hasibi et al., 2016;Raviv et al., 2012) addressed the joint distributionof entity terms from semi-structured data.As the availability of large-scale knowledgegraphs increased, semantically enriched modelswere developed. These models leverage aspectssuch as entity types (Kaptein et al., 2010; Baloget al., 2011; Garigliotti and Balog, 2017) and therelationships between entities (Tonon et al., 2012;Ciglan et al., 2012) to enhance ranking accuracy.More recently, the focus has shifted towardsLearning-To-Rank (LTR) methods (Schuhmacheret al., 2015; Graus et al., 2016; Dietz, 2019; Chat-terjee and Dietz, 2021), which utilize a variety offeatures, particularly textual information and neigh-boring relationships, to re-rank entities. The in-troduction of graph embedding-based models likeGEEER (Gerritse et al., 2020) and KEWER (Niko-laev and Kotov, 2020) has further enriched the fieldby incorporating Wikipedia2Vec (Yamada et al.,2020) embeddings, allowing entities and words tobe jointly embedded in the same vector space.The latest advancements in this domain havebeen driven by transformer-based neural modelssuch as GENRE (Cao et al., 2021), BERT-ER++(Chatterjee and Dietz, 2022), and EM-BERT (Ger-ritse et al., 2022). These models introduce sophis-ticated techniques including autoregressive entityranking, blending BERT-based entity rankings withadditional features, and augmenting BERT (Devlinet al., 2019) with Wikipedia2Vec embeddings.",
  "Sparse Encoders": "Given a query q and a document d as input, an LSRsystem uses a query encoder fq and a documentencoder fd to convert the inputs into respectivesparse representations sq and sd. The dimensionsare aligned with a vocabulary V and only a smallnumber of dimensions have non-zero values. Eachdimension siq or sid encodes the weight of the ith",
  "i=0siqsid(1)": "Various types of sparse encoders have been previ-ously defined in the literature and summarized byNguyen et al. (2023b). SPLADE (Formal et al.,2021, 2022; Lassance and Clinchant, 2022) isa state-of-the-art LSR method that employs theMLM architecture for both the query and documentencoders. The strength of the MLM architecture isits ability to do term weighting and expansion inan end-to-end fashion, meaning that the model canitself learn from data to expand the input to seman-tically relevant terms and to weight the importanceof individual terms. With an MLM encoder, thesparse representation of a query or document aregenerated as follows:",
  "where s(.)i and ei are the output weight and theembedding (from the embedding layer) of the ith": "vocabulary item respectively, L is the length ofthe input query or document, and hj is the the lasthidden state of the jth query or document inputtoken produced by a transformer backbone, suchas BERT (Devlin et al., 2019). A recent study(Nguyen et al., 2023b) found that it is not neces-sary to have both query and document expansion.Disabling query expansion,by replacing the MLMquery encoder by an MLP encoder can improvemodel efficiency while keeping the models effec-tiveness. The MLP encoder weights each queryinput token as follows:",
  "0j<L1vi=qj(W hTj + b)(3)": "where W and b are parameters of a linear layerprojecting a hidden state hj to a scalar weight.In this work, we employ this model variantwith a MLP query encoder and a MLM documentencoder as the baseline, and try to improve themodels expressiveness by expanding the outputvocabulary to Wikipedia entities. This model vari-ant is similar to EPIC (MacAvaney et al., 2020)and SPLADE-v3-Lexical (Lassance et al., 2024),though it does not exactly correspond to eithermodel. We call this model LSR-w to emphasize itsuse of the word piece vocabulary.",
  "Entity Vocabulary": "In this section, we describe our methodology toenrich the LSR vocabulary with Wikipedia entities.We build upon the MLM architecture for entityscoring in order to expand the input to any relevantitems in the vocabulary, including entities whichare not part of the encoder input. In the MLM head,the weight of the i-th entity with regard to an inputquery or document is calculated as follows:",
  "sient = ent max0j<L log(1 + ReLU(eentityi hj))(4)": "We calculate the dot product between the entity em-bedding eentityiand every hidden state hj, and thenselect the maximum score. Via a ReLU gate, onlypositive weights are retained and then log scaled.For each query or document, only a small numberof relevant entities have non-zero weights, forminga small bag of weighted entities (i.e., a sparse entityrepresentation). This resulting entity representationis merged with the bag of words representation inthe previous section to form a joint word-entitysparse representation. We add ent (initialized as0.05) as a trainable scaling factor to adjust the entityweights. This scaling factor is important to preventtraining collapse as discussed in Appendix A.2",
  "Dynamic Vocabulary Head": "It is not practical to add every entity to the existingMLM head, because the MLM head exhaustivelyscores every term in its vocabulary for each inputvector. We propose a Dynamic Vocabulary (DyVo)head that augments an existing vocabulary usingtwo ingredients: (1) embeddings of the new vocab-ulary terms (e.g., entity embeddings obtained froman external source) and (2) a candidate retrievalmethod that takes a query or document as input andidentifies a small subset of the new vocabulary thatmay be present in the input (e.g., entities identi-fied by an entity linker). We use a DyVo head toexpand the sparse encoders vocabulary to includemillions of Wikipedia entities, without the need toexhaustively score them as in Equation 4. Entity embeddings. To produce a score for an en-tity in the vocabulary, the DyVo head needs to com-pute the dot product between the entity embeddingand the hidden state of each input token. This op-eration requires both the entity embedding and thehidden states in the transformer backbone to havethe same size and live in the same latent space. Inthis work, we chose DistilBERT (Sanh et al., 2019),which has proven its effectiveness in previous re-search, as the transformer backbone with an embed-ding size of 768. For our default entity embeddings,we utilize the LaQue pretrained dense entity en-coder (Arabzadeh et al., 2024) to encode entitydescriptions from KILT (Petroni et al., 2021) intoentity embeddings. We choose LaQue for its con-sistent performance in yielding good entity weightsand retrieval effectiveness in pilot experiments. Welater provide detailed results comparing differenttypes of entity embeddings. Entity candidate retrieval. Instead of computingthe weights for millions of entities in the vocabu-lary, we propose to add an entity candidate retrievalcomponent () that aims to narrow downthe search space to a small set of relevant entities,which are then scored by the LSR encoder usingEquation 4. Offloading the entity retrieval task toa separate specialized component would allow theLSR model to focus entirely on the scoring task tomaximize the document retrieval objective. Whileusing linked entities is a popular option in priorresearch, this approach may overlook important en-tities that are not directly mentioned in the text. In- stead, we introduce a few-shot generative approachthat leverages the power of LLMs to generate highquality candidates, including both linked entitiesand relevant entities. For each query, we show twoexamples and prompt LLMs (Mixtral, GPT4) togenerate a list of Wikipedia entities that are helpfulto retrieve relevant documents. The prompt tem-plate is shown in Prompt A.2. We later compareour generative approach to various baselines. Practical considerations. The DyVo head ismemory-efficient when handling a large vocabu-lary, such as Wikipedia entities. At both trainingtime and inference time, DyVo avoids instantiatingsparse vectors with millions of dimensions, whichwould require a substantial amount of memory com-pared to the raw text (e.g., 10MB to store a singlefloat16 vector with 5 million dimensions). Duringtraining, DyVo leverages the fact that the vast ma-jority of entities do not appear in any given query(or document) to create a compact subset of the vo-cabulary for each batch. To do so, DyVo maintainsa per-batch tensor of entity candidate IDs alongwith the corresponding entity weights, which areused to match entities between the query and thedocument. The weights of the matching entitiesare multiplied together and summed to produce thefinal relevance score. This allows DyVo to instan-tiate relatively small sparse vectors that containenough dimensions to hold the entity candidates,rather than instantiating vectors that correspond tothe entire vocabulary. Sparse representations arestored in an inverted index that is queried at infer-ence time, so vocabulary-size vectors do not needto be instantiated at retrieval time.",
  "Experimental setup": "Datasets. Given our need for entity-rich queriesand documents, we evaluate our approach usingdatasets containing a mix of news documents andcomplex information needs (i.e., TREC Robust04,TREC Core 2018, CODEC), which have also beencommonly used in prior work, e.g. (Dalton et al.,2014; Chatterjee et al., 2024; Tan et al., 2023;MacAvaney et al., 2019; Nogueira et al., 2020; Liet al., 2023). Robust04 (Voorhees et al., 2003)has 528k documents and 250 query topics wheredocuments are news articles. All topics are deeplyannotated with 1246 judged documents per topicon average. Core 2018 contains 595k news articlesor blog posts from The Washington Post with about50 topics and 524 relevant judgements per topic. CODEC (Mackie et al., 2022) provides 729k webdocuments crawled from various sources and 42complex query topics, covering recent themes (e.g.,bitcoins, NFT) from diverse domains, such as his-tory, economics, politics. Furthermore, each topiccomes with approximately 147 document judge-ments and 269 entity annotations.We use all provided topics (description field onTREC datasets and query field on CODEC) forevaluation. To train models, we used synthesizeddataset provided by InParsV2 (Jeronymo et al.,2023). Because CODEC is not available on In-ParsV2, we generate 10k queries ourselves usingMixtral-8x7B-Instruct-v0.1 (Jiang et al., 2024). Knowledge base and entity candidates. We usethe KILT (Petroni et al., 2021) knowledge reposi-tory with 5.9 millions entities and only keep entitiesappearing in Wikipedia2Vec (Yamada et al., 2020),resulting in ~5.3 millions entities. To obtain linkedentity candidates for queries, we use the REL (vanHulst et al., 2020) entity linker with n-gram NERtagger. For the entity retrieval approach, we ex-perimented with different aproaches, including tra-ditional sparse retrieval (BM25), dense retrieval(LaQue), and generative retrievers (Mixtral andGPT4). For BM25, we index the entitys descrip-tion and retrieve the top 20 entities per query usingPyserini (Lin et al., 2021) with the default param-eters. With LaQue, we encode both queries andentity descriptions using the LaQue (DistilBERT)dense encoder, and select the top 20 entities thathave the highest dot product with the querys densevector. With generative approaches, we promptMixtral and GPT4 to generate relevant entities andremove out-of-vocabulary entities. For simplicity,we re-use the linked entities from Chatterjee et al.(2024) on the document side for all experiments. Training configuration. Starting from a LSRcheckpoint without entities trained on MSMARCO,we further fine-tune them on the three datasets us-ing the synthesized queries, MonoT5-3b scoresfor distillation, KL loss (Formal et al., 2022) andBM25 negatives. To regularize vector sparsity, weapply a L1 penalty on the output sparse represen-tations, which has previously been shown to beeffective (Nguyen et al., 2023b). We experimentwith different L1 weights, including [1e-3, 1e-4,1e-5]. For each setting, we train two LSR versions:LSR-w that produces word piece representationsonly, and DyVo that produces joint word-entity rep- resentations. On each dataset, we train the modelsfor 100k steps with a batch size of 16, learning rateof 5e-7, and 16-bit precision on a single A100 GPU.Entity embeddings are pre-computed and frozenduring training; only a projection layer is trainedwhere the word and entity embedding sizes differ.",
  "Experimental results": "We first consider whether incorporating linked enti-ties in sparse representations increases effective-ness over representations containing only wordpieces, finding that doing so yields consistent im-provements on our entity-rich benchmarks. Wethen consider the impact of the entity selectioncomponent and the entity embeddings used, findingthat performing entity retrieval rather than entitylinking can further improve performance and thatDyVo performs well with a range of entity embed-ding techniques.",
  "RQ1: Does incorporating linked entitiesimprove the effectiveness of LSR?": "In this RQ, we seek to evaluate the effectivenessof LSR with linked entities. We train three dif-ferent LSR versions with different sparse regular-ization weights (1e-3, 1e-4, 1e-5). For each LSRversion, we trained two models (LSR-w and DyVo)with and without entities, respectively, using ex-actly the same training configuration. Although weare mainly interested in the comparison betweenDyVo and LSR-w, other baselines (e.g., BM25,BM25+RM3, and zero-shot single-vector denseretrieval methods) are provided in to helpreaders position LSR with regard to other first-stageretrieval families.Our first observation is that our model withlinked entities (DyVo) outperforms the model with-out entities (LSR-w) consistently on all metrics(nDCG@10, nDCG@20, R@1000) across threedifferent datasets and three different sparsity con-straints. The difference between the two modelsis more pronounced when the document represen-tations become more sparse. With the largest reg-ularization weight (reg=1e-3), the documents arethe most sparse and have the fewest terms. In thisscenario, enriching the word representation withlinked entities typically results in a significant gain, notably with an increase ranging from 1.15 to 3.57points in nDCG@10 across all datasets. When werelax the sparsity regularization to 1e-4 and 1e-5,we observe an improvement in the performance ofLSR-w baseline models. However, we still con-sistently observe the usefulness of linked entities,albeit to a lesser degree. In the most relaxed setup(reg=1e-5), we often gain from 1 to 2 nDCG pointson all three datasets. The R@1000 improvement issimilar, except we only observe a minimal increaseon Core 2018.Compared to other families, both LSR andDyVo demonstrate better performance than un-supervised lexical retrieval methods (BM25,BM25+RM3) and Dense Retrieval (DR) mod-els, including DistilBERT-dot-v5 (Reimers andGurevych, 2019a), GTR-T5-base (Ni et al., 2022b),and Sentence-T5-base (Ni et al., 2022a). Despiteusing models three times larger (T5-base vs. Distil-BERT), both GTR-T5-base and Sentence-T5-basestill show lower effectiveness than LSR models.This is due to the generalization difficulties ofdense retrieval methods.DyVo also outperforms BM25 + RM3, a tra-ditional query expansion method using pseudo-relevance feedback. Compared to GRF, a LLM-based query expansion approach by Mackie et al.(2023), DyVo achieves a significantly highernDCG@10 score (e.g., 53.40 with DyVo using theREL linker versus 40.50 with GRF on CODEC).It is important to note that the LLMs used in GRFwere not fine-tuned, and doing so would presentsubstantial computational challenges.",
  "RQ2: Can LSR be more effective withretrieval-oriented entity candidates?": "In the previous RQ, we explored how incorporat-ing linked entities enhances LSRs representations.However, relying solely on linked entities over-looks other relevant entities crucial for documentretrieval. For instance, with the CODEC queryWhy are many commentators arguing NFTs are thenext big investment category?, entities like Cryp-tocurrency, Bitcoin, and Digital asset can bevaluable despite not being explicitly mentioned.In this RQ, we aim to evaluate our few-shot gen-erative entity retrieval approach based on Mixtralor GPT4 and compare it with other entity retrievalapproaches, including entity linking (as explored inthe previous RQ), sparse methods (BM25), denseentity retrieval methods (LaQue), and human anno-tations. The results are shown in .",
  "LSR-w1e-549.1346.3466.8640.9938.7363.2252.6149.2269.07DyVo (REL)51.1947.6568.5643.7240.5663.5653.4051.1570.60": ": Results with linked entities. All LSR models use a DistilBERT backbone. DyVo uses entities found by theREL entity linker and LaQue entity embeddings. All documents are truncated to the first 512 tokens. Observing the table, we note that DyVo (BM25)and DyVo (LaQue) show modest performancegains compared to the DyVo (REL) model, whichincorporates linked entities, and the LSR modelwithout entities. Employing LaQue-retrieved can-didates to DyVo increases LSR-ws R@1000 by+1.39 points (66.86 68.25), +1.61 points (63.22 64.83), and +1.8 points (from 69.07 70.87)on the Robust04, Core18, and CODEC datasets,respectively. This recall improvement is compara-ble to the gain achieved by using the REL entitylinker. However, we generally observe no benefitsin terms of nDCG when using the BM25 or LaQueretriever. This could be because BM25 and LaQuetend to prioritize recall, resulting in the retrieval ofnot only relevant entities but also noisy entities. Our generative approach utilizing Mixtral andGPT4 represents a significant step forward in entityretrieval for document ranking. Compared to linkedentities provided by REL, our approach showcasesnotable improvements, enhancing nDCG@10 andnDCG@20 scores by approximately +1.3 to +1.78points across all datasets, with the exception ofnDCG@10 on Core 2018. Mixtrals effectivenessis further highlighted by its impact on R@1000scores, with increases observed across the Ro-bust04, Core 2018, and CODEC datasets. Additionally, when we replace Mixtral withGPT4, we see further improvements that result inDyVo achieving the highest performance on nearlyevery metric and dataset. Notably, retrieval usingGPT-4 generated entities is competitive with re- trieval using human-annotated entities on CODEC,underlining the significance of enriching query rep-resentations with relevant entities beyond linkedones. We attach examples in in the Ap-pendix to illustrate the candidates retrieved by dif-ferent systems.",
  "RQ3: How does changing entity embeddingsaffect the models ranking performance?": "Previously, we utilized the same entity encoder,LaQue (Arabzadeh et al., 2024), to generate en-tity embeddings. Here, our objective is to evaluatevarious approaches to obtain entity embeddingsincluding Token Aggregation (i.e., splitting an en-titys surface form into word pieces and averagingtheir static embeddings), Wikipedia2Vec (Yamadaet al., 2020), general dense passage encoders likeJDS and DPR (Pouran Ben Veyseh et al., 2021)and specialized dense entity encoders like LaQueand BLINK (Arabzadeh et al., 2024; Laskar et al.,2022). JDS is a joint dense ([CLS] vector) andsparse model with a shared DistilBERT backbone.We train our JDS model on MSMARCO datasetwith a dual dense-sparse loss, using it to encodeentity descriptions into dense embeddings. Theresults is shown in .First, we observe that simply tokenizing theentity name into word pieces and averaging thetransformers static token embeddings proves tobe a viable method for creating entity embed-dings. This approach typically yields a +1 pointimprovement over LSR-w across various metrics",
  "and datasets. We hypothesize that this improve-ment mainly stems from phrase matching throughentity name matching, as we believe the token staticembeddings do not encode much entity knowledge": "Interestingly, in terms of nDCG scores, this sim-ple method outperforms the DPR and JDS meth-ods, which rely on generic dense passage encoderstrained for ad-hoc passage retrieval tasks to en-code entity descriptions. DPR and JDS, however,demonstrate strong recall, suggesting that theseencoders may prioritize encoding abstract entityinformation, which enables them to pull relevantdocuments within the top 1000 results. However,they may lack fine-grained entity knowledge nec-essary for more nuanced weighting. Wikipedia2Vec (Wiki2Vec, dim=300), LaQue,and BLINK are specialized for entity representa-tion learning or entity ranking tasks. As indicatedin the last three rows of , using them togenerate entity embeddings enhances document re-trieval performance across all metrics and datasets.Despite being trained using a simple skip-grammodel, Wikipedia2Vec effectively supports LSR indocument retrieval, outperforming models utilizingaggregated token embeddings and dense passageencoders. The robustness of Wikipedia2Vec hasbeen documented in prior research (Oza and Di-etz, 2023). Substituting Wikipedia2Vec with moreadvanced transformer-based entity encoders such as LaQue and BLINK results in the strongest over-all performance. LaQue, based on the lightweightDistilBERT backbone, shows a slight improvementover Wikipedia2Vec. Using a larger transformermodel (BERT-large), BLINK usually achieves a +1nDCG point increase compared to LaQue, toppingall datasets in terms of nDCG@10 and nDCG@20.",
  "Conclusion": "LSR has emerged as a competitive method for first-stage retrieval. In this work, we observed that rely-ing on only word pieces for lexical grounding cancreate ambiguity in sparse representations espe-cially when entities are split into subwords. We ex-plored whether learned sparse representations caninclude entity dimensions in addition to word piecedimensions. In order to facilitate modeling millionsof potential entities, we proposed a Dynamic Vo-cabulary (DyVo) head that leverages entity retrievalto identify potential entity candidates and entityembeddings to represent them. We find that whileboth linked entities and LLM-generated entities areeffective, LLM-generated entities ultimately yieldhigher LSR effectiveness. The approach is largelyrobust to the choice of entity embedding. Our worksets the stage for other LSR models that go beyondword piece vocabularies.",
  "Limitations": "While our approach is highly effective on the doc-ument retrieval benchmarks considered, it is im-portant to note that its reliance on large languagemodels (LLMs) like Mixtral and GPT4 can posecomputational and cost inefficiencies. This chal-lenge is not unique to our methodology; rather, itis a common concern across various research pur-suits employing LLMs for retrieval purposes. Onepotential avenue for mitigating these costs involvesleveraging LLMs to generate synthetic datasets anddistill their internal knowledge into a more stream-lined entity ranker or re-ranker. Addressing thisissue extends beyond the scope of our current work.",
  "Ethics Statement": "We constructed our LSR encoder using a pretrainedDistilBERT and employed Large Language Modelssuch as Mixtral and GPT4 to generate entity candi-dates. Consequently, our models may inherit biases(e.g., preferences towards certain entities) encodedwithin these language models. Our evaluation en-compasses both open-source models (Mixtral, Dis-tilBERT, LaQue, BLINK, REL, Wikipedia2Vec)and proprietary ones (GPT4), which do not alwaysdisclose their training data.",
  "Acknowledgements": "This research was supported by the Hybrid In-telligence Center, a 10-year program fundedby the Dutch Ministry of Education,Cul-ture and Science through the Netherlands Or-ganisation for Scientific Research, and projectVI.Vidi.223.166 of the NWO Talent Programmewhich is (partly) financed by the Dutch ResearchCouncil (NWO). Amin Abolghasemi, Leif Azzopardi, Arian Askari,Maarten de Rijke, and Suzan Verberne. 2024. Mea-suring bias in a ranked list using term-based repre-sentations. In European Conference on InformationRetrieval, pages 319. Springer.",
  "Nicola De Cao, Gautier Izacard, Sebastian Riedel, andFabio Petroni. 2021. Autoregressive entity retrieval.In International Conference on Learning Representa-tions": "Shubham Chatterjee and Laura Dietz. 2021.EntityRetrieval Using Fine-Grained Entity Aspects. In Pro-ceedings of the 44th International ACM SIGIR Con-ference on Research and Development in InformationRetrieval, SIGIR 21, page 16621666, New York,NY, USA. Association for Computing Machinery. Shubham Chatterjee and Laura Dietz. 2022. Bert-er:Query-specific bert entity representations for entityranking. In Proceedings of the 45th InternationalACM SIGIR Conference on Research and Devel-opment in Information Retrieval, SIGIR 22, page14661477, New York, NY, USA. Association forComputing Machinery.",
  "Shubham Chatterjee, Iain Mackie, and Jeff Dalton. 2024.Dreq: Document re-ranking using entity-based queryunderstanding. arXiv preprint arXiv:2401.05939": "Chen Chen, Bowen Zhang, Liangliang Cao, JiguangShen, Tom Gunter, Albin Madappally Jose, Alexan-der Toshev, Jonathon Shlens, Ruoming Pang, and Yin-fei Yang. 2023. Stair: Learning sparse text and imagerepresentation in grounded tokens. arXiv preprintarXiv:2301.13081. Marek Ciglan, Kjetil Nrvg, and Ladislav Hluch.2012. The semsets model for ad-hoc semantic listsearch.In Proceedings of the 21st InternationalConference on World Wide Web, WWW 12, page131140, New York, NY, USA. Association for Com-puting Machinery. Jeffrey Dalton, Laura Dietz, and James Allan. 2014.Entity query feature expansion using knowledge baselinks. In Proceedings of the 37th international ACMSIGIR conference on Research & development ininformation retrieval, SIGIR 14, pages 365374. Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. Bert: Pre-training of deepbidirectional transformers for language understand-ing. In North American Chapter of the Associationfor Computational Linguistics. Laura Dietz. 2019. ENT Rank: Retrieving Entities forTopical Information Needs through Entity-Neighbor-Text Relations. In Proceedings of the 42nd Interna-tional ACM SIGIR Conference on Research and De-velopment in Information Retrieval, SIGIR19, page215224, New York, NY, USA. Association for Com-puting Machinery. Shuai Ding and Torsten Suel. 2011. Faster top-k doc-ument retrieval using block-max indexes. In Pro-ceeding of the 34th International ACM SIGIR Confer-ence on Research and Development in InformationRetrieval, SIGIR 2011, Beijing, China, July 25-29,2011, pages 9931002. ACM. Jeffrey M Dudek, Weize Kong, Cheng Li, MingyangZhang, and Michael Bendersky. 2023.Learningsparse lexical representations over specified vocabu-laries for retrieval. In Proceedings of the 32nd ACMInternational Conference on Information and Knowl-edge Management, CIKM 23, pages 38653869. Faezeh Ensan and Ebrahim Bagheri. 2017. Documentretrieval model through semantic linking. In Pro-ceedings of the 10th ACM International Conferenceon Web Search and Data Mining, WSDM 17, page181190, New York, NY, USA. Association for Com-puting Machinery. Thibault Formal, Carlos Lassance, Benjamin Pi-wowarski, and Stphane Clinchant. 2022. From dis-tillation to hard negative sampling: Making sparseneural ir models more effective. In Proceedings ofthe 45th International ACM SIGIR Conference onResearch and Development in Information Retrieval,pages 23532359. Thibault Formal, Benjamin Piwowarski, and StphaneClinchant. 2021. Splade: Sparse lexical and expan-sion model for first stage ranking. In Proceedingsof the 44th International ACM SIGIR Conference onResearch and Development in Information Retrieval,pages 22882292.",
  "Evgeniy Gabrilovich and Shaul Markovitch. 2009.Wikipedia-based semantic interpretation for naturallanguage processing. Journal of Artificial Intelli-gence Research, 34:443498": "Daro Garigliotti and Krisztian Balog. 2017. On type-aware entity retrieval. In Proceedings of the ACMSIGIR International Conference on Theory of Infor-mation Retrieval, ICTIR 17, page 2734, New York,NY, USA. Association for Computing Machinery. Emma J Gerritse, Faegheh Hasibi, and Arjen P de Vries.2020.Graph-Embedding Empowered Entity Re-trieval. In Advances in Information Retrieval, Pro-ceedings of the 42nd European Conference on In-formation Retrieval (ECIR 2020), Lecture Notes inComputer Science, pages 97110, Cham. Springer. Emma J. Gerritse, Faegheh Hasibi, and Arjen P. de Vries.2022. Entity-aware transformers for entity search. InProceedings of the 45th International ACM SIGIRConference on Research and Development in Infor-mation Retrieval, SIGIR 22, page 14551465, NewYork, NY, USA. Association for Computing Machin-ery. David Graus, Manos Tsagkias, Wouter Weerkamp,Edgar Meij, and Maarten de Rijke. 2016. Dynamiccollective entity representations for entity ranking. InProceedings of the Ninth ACM International Confer-ence on Web Search and Data Mining, WSDM 16,page 595604, New York, NY, USA. Association forComputing Machinery.",
  "of the 32nd international ACM SIGIR conference onResearch and development in information retrieval,SIGIR 09, pages 267274": "Nam Hai Le, Thomas Gerald, Thibault Formal, Jian-YunNie, Benjamin Piwowarski, and Laure Soulier. 2023.Cosplade: Contextualizing splade for conversationalinformation retrieval. In European Conference onInformation Retrieval, pages 537552. Springer. Faegheh Hasibi, Krisztian Balog, and Svein Erik Brats-berg. 2016. Exploiting entity linking in queries forentity retrieval. In Proceedings of the 2016 ACM In-ternational Conference on the Theory of InformationRetrieval, ICTIR 16, page 209218, New York, NY,USA. Association for Computing Machinery. Vitor Jeronymo, Luiz Bonifacio, Hugo Abonizio,Marzieh Fadaee, Roberto Lotufo, Jakub Zavrel, andRodrigo Nogueira. 2023. InPars-v2: Large languagemodels as efficient dataset generators for informationretrieval. Albert Q Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, Chris Bam-ford, Devendra Singh Chaplot, Diego de las Casas,Emma Bou Hanna, Florian Bressand, et al. 2024.Mixtral of experts. arXiv preprint arXiv:2401.04088. Rianne Kaptein, Pavel Serdyukov, Arjen De Vries, andJaap Kamps. 2010. Entity ranking using wikipediaas a pivot. In Proceedings of the 19th ACM Inter-national Conference on Information and KnowledgeManagement, CIKM 10, page 6978, New York, NY,USA. Association for Computing Machinery.",
  "Ravi Kumar and Andrew Tomkins. 2010. A characteri-zation of online browsing behavior. In Proceedingsof the 19th International Conference on World WideWeb, pages 561570": "Md Tahmid Rahman Laskar, Cheng Chen, AliaksandrMartsinovich, Jonathan Johnston, Xue-Yong Fu,Shashi Bhushan Tn, and Simon Corston-Oliver. 2022.BLINK with Elasticsearch for efficient entity link-ing in business conversations. In Proceedings of the2022 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies: Industry Track, pages344352, Hybrid: Seattle, Washington + Online. As-sociation for Computational Linguistics. Carlos Lassance and Stphane Clinchant. 2022. Anefficiency study for splade models. In Proceedingsof the 45th International ACM SIGIR Conference onResearch and Development in Information Retrieval,pages 22202226.",
  "Canjia Li, Andrew Yates, Sean MacAvaney, Ben He, andYingfei Sun. 2023. Parade: Passage representationaggregation fordocument reranking. ACM Transac-tions on Information Systems, 42(2):126": "Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-Hong Yang, Ronak Pradeep, and Rodrigo Nogueira.2021. Pyserini: A python toolkit for reproducibleinformation retrieval research with sparse and denserepresentations. In Proceedings of the 44th Inter-national ACM SIGIR Conference on Research andDevelopment in Information Retrieval, SIGIR 21,page 23562362, New York, NY, USA. Associationfor Computing Machinery.",
  "Sean MacAvaney, Craig Macdonald, and Iadh Ounis.2022.Streamlining evaluation with ir-measures.In European Conference on Information Retrieval,pages 305310. Springer": "Sean MacAvaney, Franco Maria Nardini, RaffaelePerego, Nicola Tonellotto, Nazli Goharian, and OphirFrieder. 2020. Expansion via prediction of impor-tance with contextualization. In Proceedings of the43rd International ACM SIGIR conference on re-search and development in Information Retrieval,pages 15731576. Sean MacAvaney, Andrew Yates, Arman Cohan, andNazli Goharian. 2019. Cedr: Contextualized em-beddings for document ranking. In Proceedings ofthe 42nd international ACM SIGIR conference onresearch and development in information retrieval,pages 11011104. Iain Mackie, Shubham Chatterjee, and Jeffrey Dalton.2023. Generative relevance feedback with large lan-guage models.In Proceedings of the 46th Inter-national ACM SIGIR Conference on Research andDevelopment in Information Retrieval, pages 20262031. Iain Mackie, Shubham Chatterjee, Sean MacAvaney,and Jeff Dalton. 2024. Adaptive latent entity ex-pansion for document retrieval.The First Work-shop on Knowledge-Enhanced Information Retrieval(ECIR24). Iain Mackie, Paul Owoicho, Carlos Gemmell, SophieFischer, Sean MacAvaney, and Jeffrey Dalton. 2022.Codec: Complex document and entity collection. InProceedings of the 45th International ACM SIGIRConference on Research and Development in Infor-mation Retrieval, SIGIR 22, page 30673077, NewYork, NY, USA. Association for Computing Machin-ery.",
  "Edgar Meij, Dolf Trieschnigg, Maarten de Rijke, andWessel Kraaij. 2010. Conceptual language modelsfor domain-specific retrieval. Inf. Process. Manage.,46(4):448469": "Donald Metzler and W. Bruce Croft. 2005. A markovrandom field model for term dependencies. In Pro-ceedings of the 28th Annual International ACM SI-GIR Conference on Research and Development inInformation Retrieval, SIGIR 05, page 472479,New York, NY, USA. Association for ComputingMachinery. Thong Nguyen, Mariya Hendriksen, Andrew Yates, andMaarten De Rijke. 2024. Multimodal learned sparseretrieval with probabilistic expansion control.InAdvances in Information Retrieval: 46th EuropeanConference on Information Retrieval, ECIR 2024,Glasgow, UK. Springer. Thong Nguyen, Sean MacAvaney, and Andrew Yates.2023a. Adapting learned sparse retrieval for longdocuments. In Proceedings of the 46th InternationalACM SIGIR Conference on Research and Develop-ment in Information Retrieval, pages 17811785.",
  "Thong Nguyen, Sean MacAvaney, and Andrew Yates.2023b. A unified framework for learned sparse re-trieval. In European Conference on Information Re-trieval, pages 101116": "Jianmo Ni, Gustavo Hernandez Abrego, Noah Con-stant, Ji Ma, Keith Hall, Daniel Cer, and Yinfei Yang.2022a.Sentence-t5: Scalable sentence encodersfrom pre-trained text-to-text models. In Findings ofthe Association for Computational Linguistics: ACL2022, pages 18641874, Dublin, Ireland. Associationfor Computational Linguistics. Jianmo Ni, Chen Qu, Jing Lu, Zhuyun Dai, Gustavo Her-nandez Abrego, Ji Ma, Vincent Zhao, Yi Luan, KeithHall, Ming-Wei Chang, and Yinfei Yang. 2022b.Large dual encoders are generalizable retrievers. InProceedings of the 2022 Conference on EmpiricalMethods in Natural Language Processing, pages98449855, Abu Dhabi, United Arab Emirates. As-sociation for Computational Linguistics.",
  "Fedor Nikolaev and Alexander Kotov. 2020. Joint wordand entity embeddings for entity retrieval from a": "knowledge graph. In Advances in Information Re-trieval: 42nd European Conference on IR Research,ECIR 2020, Lisbon, Portugal, April 1417, 2020, Pro-ceedings, Part I, page 141155, Berlin, Heidelberg.Springer-Verlag. Fedor Nikolaev, Alexander Kotov, and Nikita Zhiltsov.2016. Parameterized fielded term dependence mod-els for ad-hoc entity retrieval from knowledge graph.In Proceedings of the 39th International ACM SIGIRConference on Research and Development in Infor-mation Retrieval, SIGIR 16, page 435444, NewYork, NY, USA. Association for Computing Machin-ery. Rodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, andJimmy Lin. 2020. Document ranking with a pre-trained sequence-to-sequence model. In Findingsof the Association for Computational Linguistics:EMNLP 2020, pages 708718, Online. Associationfor Computational Linguistics.",
  "Pooja Oza and Laura Dietz. 2023. Entity embeddingsfor entity ranking: A replicability study. In EuropeanConference on Information Retrieval, pages 117131.Springer": "Fabio Petroni, Aleksandra Piktus, Angela Fan, PatrickLewis, Majid Yazdani, Nicola De Cao, James Thorne,Yacine Jernite, Vladimir Karpukhin, Jean Maillard,Vassilis Plachouras, Tim Rocktschel, and SebastianRiedel. 2021. KILT: a benchmark for knowledgeintensive language tasks. In Proceedings of the 2021Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 25232544, Online.Association for Computational Linguistics. Amir Pouran Ben Veyseh, Franck Dernoncourt, andThien Huu Nguyen. 2021. DPR at SemEval-2021task 8: Dynamic path reasoning for measurement re-lation extraction. In Proceedings of the 15th Interna-tional Workshop on Semantic Evaluation (SemEval-2021), pages 397403, Online. Association for Com-putational Linguistics.",
  "Victor Sanh, Lysandre Debut, Julien Chaumond, andThomas Wolf. 2019. Distilbert, a distilled versionof bert: smaller, faster, cheaper and lighter. arXivpreprint arXiv:1910.01108": "Michael Schuhmacher, Laura Dietz, and SimonePaolo Ponzetto. 2015.Ranking Entities for WebQueries Through Text and Knowledge. In Proceed-ings of the 24th ACM International on Conferenceon Information and Knowledge Management, CIKM15, page 14611470, New York, NY, USA. Associa-tion for Computing Machinery. Dahlia Shehata, Negar Arabzadeh, and Charles LAClarke. 2022. Early stage sparse retrieval with en-tity linking. In Proceedings of the 31st ACM Inter-national Conference on Information & KnowledgeManagement, pages 44644469. Weiwei Sun, Lingyong Yan, Xinyu Ma, ShuaiqiangWang, Pengjie Ren, Zhumin Chen, Dawei Yin, andZhaochun Ren. 2023. Is ChatGPT good at search?investigating large language models as re-rankingagents. In Proceedings of the 2023 Conference onEmpirical Methods in Natural Language Process-ing, pages 1491814937, Singapore. Association forComputational Linguistics.",
  "Chenyan Xiong, Jamie Callan, and Tie-Yan Liu. 2017a": "Word-entity duet representations for document rank-ing. In Proceedings of the 40th International ACMSIGIR Conference on Research and Developmentin Information Retrieval, SIGIR 17, page 763772,New York, NY, USA. Association for ComputingMachinery. Chenyan Xiong, Zhengzhong Liu, Jamie Callan, andEduard Hovy. 2017b. Jointsem: Combining queryentity linking and entity based document ranking.In Proceedings of the 2017 ACM SIGIR Conferenceon Information and Knowledge Management, CIKM17, page 23912394, New York, NY, USA. Associa-tion for Computing Machinery. Chenyan Xiong, Zhengzhong Liu, Jamie Callan, andTie-Yan Liu. 2018. Towards better text understandingand retrieval through kernel entity salience modeling.In The 41st International ACM SIGIR Conference onResearch and Development in Information Retrieval,SIGIR 18, page 575584, New York, NY, USA. As-sociation for Computing Machinery. Chenyan Xiong, Russell Power, and Jamie Callan.2017c.Explicit semantic ranking for academicsearch via knowledge graph embedding. In Proceed-ings of the 26th International Conference on WorldWide Web, WWW 17, page 12711279, Republicand Canton of Geneva, CHE. International WorldWide Web Conferences Steering Committee. Ikuya Yamada, Akari Asai, Jin Sakuma, HiroyukiShindo, Hideaki Takeda, Yoshiyasu Takefuji, andYuji Matsumoto. 2020. Wikipedia2Vec: An efficienttoolkit for learning and visualizing the embeddings ofwords and entities from Wikipedia. In Proceedingsof the 2020 Conference on Empirical Methods in Nat-ural Language Processing: System Demonstrations,pages 2330, Online. Association for ComputationalLinguistics. Hamed Zamani, Mostafa Dehghani, W Bruce Croft,Erik Learned-Miller, and Jaap Kamps. 2018. Fromneural re-ranking to neural ranking: Learning asparse representation for inverted indexing. In Pro-ceedings of the 27th ACM international conference",
  "Tiancheng Zhao, Xiaopeng Lu, and Kyusong Lee. 2020.Sparta: Efficient open-domain question answeringvia sparse transformer matching retrieval.arXivpreprint arXiv:2009.13013": "Nikita Zhiltsov, Alexander Kotov, and Fedor Nikolaev.2015. Fielded sequential dependence model for ad-hoc entity retrieval in the web of data. In Proceedingsof the 38th International ACM SIGIR Conference onResearch and Development in Information Retrieval,SIGIR 15, page 253262, New York, NY, USA. As-sociation for Computing Machinery. Shengyao Zhuang and Guido Zuccon. 2021.Tilde:Term independent likelihood model for passage re-ranking. In Proceedings of the 44th InternationalACM SIGIR Conference on Research and Develop-ment in Information Retrieval, pages 14831492.",
  "A.1Detailed training configuration": "We train our DyVo methods using two-step dis-tillation. In the first step, we train a base LSRmodel on MSMARCO without entities using stan-dard LSR training techniques. We employ KL lossto distill knowledge from a cross-encoder with dataobtained from sentence-transformers (Reimers andGurevych, 2019b)2. This model is trained with abatch size of 64 triplets (query, positive passage,negative passage) for 300k steps with 16-bit preci-sion. In the second step, we start from the modelpretrained on MSMARCO and further fine-tune iton the target datasets using distillation training onsynthesized queries, BM25 negatives, and cross-encoder scores from MonoT5-3B (Nogueira et al.,2020). The documents in Robust04, Core 2018,and CODEC are longer than MSMARCO, so weuse a smaller batch size of 16. All models aretrained on one single A100 for for 100k steps.For query generation, we re-use generatedqueries from InParsv2 (Jeronymo et al., 2023) avail-able for TREC Robust04 and Core 2018.ForCODEC, we generate the queries ourselves us-ing the prompting Mixtral model. We re-use theprompt template in InParsv2 and add a small in-struction at the beginning (Prompt A.1). For sparse regularization, we apply L1 with vary-ing regularization strengths. Entity representationsare sparse themselves since we constrain the outputto a small set of entity candidates and ignore otherentities. Therefore, we do not apply L1 to entities. 0.0 0.5 1.0 # entities log step # words",
  "A.2Entity representation collapse": "When integrating entity embeddings into DyVo,we observe that the model produces entity weightswith magnitudes significantly higher than those ofword piece weights. This discrepancy may arisefrom the lack of alignment between entity embed-dings, generated by a separate model, and wordpiece embeddings. Initially, the model attempts tomitigate the dominance of entity weights by scal-ing them down. However, after a certain number oftraining epochs, the model overcompensates, result-ing in the collapse of entity representations. Thiscollapse is illustrated in , where all entityweights become negative and are subsequently fil-tered out by the ReLU gate. Once this collapseoccurs, it cannot be rectified, as there is no gradientflowing through the ReLU gate. To address thisissue, we introduce a learnable scaling factor, asdepicted in Equation 4, initializing it to a smallvalue. This scaling factor is helpful to alleviateentity dominance at the beginning of training andtemper the models aggressiveness in scaling downentity weights during training.",
  "In , we provide a qualitative comparison ofthe entity candidates retrieved by different systems.Within the two query samples presented, we ob-serve that the generative approaches (i.e., Mixtral": "and GPT4) consistently produce highly relevant en-tities. Notably, Mixtral tends to generate fewer andshorter entities compared to both GPT-4 and hu-man annotations. Conversely, GPT4 retrieves moreentities, and sometimes more entities than human-produced candidates. This discrepancy suggestsan explanation for why Mixtrals performance ingenerating entities to support document retrievalfalls short of that achieved by GPT4.In contrast to the consistent performance of gen-erative entity retrieval, we observe divergent be-haviors among other approaches (i.e., REL, BM25,and LaQue) across the two queries. The first query,which is less ambiguous with clearly expressed en-tities, allows these systems to retrieve/link simple,direct entities such as American RevolutionaryWar and France in the American RevolutionaryWar. However, they also introduce a significantamount of noise with irrelevant entities.Conversely, the second query poses greater dif-ficulty, with the entity Non-fungible token men-tioned via its abbreviation NFTs which is furtherfragmented by the DistilBERT tokenizer into mean-ingless sub-word units. In this scenario, REL andBM25 fail entirely, while LaQue manages to re-trieve only generic and distantly relevant entities.None of these systems successfully resolves NFTsto Non-fungible token as the generative approachdoes.",
  "RetrieverQ: How vital was French support during the American Revolutionary War?WP : [how, vital, was, french, support, during, the, american, revolutionary, war, ?]": "REL[Vitalism, French people, Military logistics, American Revolutionary War]BM25[Richard Howe, 1st Earl Howe, HMS Childers (1778), Robert Howe (Continental Army officer), JamesCoutts Crawford, Glorious First of June, George Eyre, Jacques-Antoine de Chambarlhac de Laubespin,Anthony James Pye Molloy, Nantucket during the American Revolutionary War era, Friedrich Joseph, Countof Nauendorf, Jonathan Faulknor the elder, Joseph Spear, HMS Romney (1762), HMS Roebuck (1774),France in the American Revolutionary War, Invasion of Corsica (1794), List of British fencible regiments,Northern theater of the American Revolutionary War after Saratoga, Robert Linzee, Guilin Laurent Bizanet]LaQue[France in the American Revolutionary War, List of French units in the American Revolutionary War,Support our troops, List of wars involving France, List of American Revolutionary War battles, AmericanVolunteers, Colonial American military history, List of battles involving France in modern history, Militaryhistory of France, List of the lengths of United States participation in wars, 1776, France and the AmericanCivil War, USS Confederacy (1778), Financial costs of the American Revolutionary War, List of warsinvolving the United States, List of American Civil War generals (Union), United States assistance toVietnam, French Revolutionary Wars, American Revolutionary War, List of battles involving France]Mixtral[American Revolutionary War, France, United States, Military history, Diplomacy, Military alliance]GPT4[France in the American Revolutionary War, French Army, American Revolutionary War, Benjamin Franklin,Kingdom of France, Treaty of Alliance (1778), George Washington, John Adams, Treaty of Paris (1783),Continental Congress, Continental Army, Naval battles of the American Revolutionary War, Siege ofSavannah, Capture of Fort Ticond]Human[American Revolution, France in the American Revolutionary War, Kingdom of Great Britain, United States,George Washington, Roderigue Hortalez and Company, British Empire, France, George Washington in theAmerican Revolution, Gilbert du Motier, Marquis de Lafayette, Spain and the American RevolutionaryWar, American Revolutionary War, Diplomacy in the American Revolutionary War, Treaty of Paris (1783),Franco-American alliance, Naval battles of the American Revolutionary War, Treaty of Alliance (1778),Battles of Saratoga]",
  "Q: Why are many commentators arguing NFTs are the next big investment category?WP: [why, are, many, commentators, arguing, n, ##ft, ##s, are, the, next, big, investment, category]": "REL[Sports commentator, National Film and Television School, Next plc, Toronto, Investment banking, Catego-rization]BM25[Kuznets swing, The Green Bubble, Why We Get Fat, Big mama, Types of nationalism, Not for Tourists,Mark Roeder, Ernie Awards, Dramatistic pentad, Pagan Theology, RJ Balaji, Leslie Hardcastle, Why didntyou invest in Eastern Poland?, Big Data Maturity Model, Celebrity Big Brother racism controversy, TheBottom Billion, National Film and Television School, Canopy Group, The Wallypug of Why]LaQue[List of bond market indices, National Futures Association, NB Global, Companies listed on the New YorkStock Exchange (N), Companies listed on the New York Stock Exchange (G), Companies listed on theNew York Stock Exchange (F), List of exchange-traded funds, Companies listed on the New York StockExchange (T), Emerging and growth-leading economies, List of private equity firms, List of wealthiestorganizations, Pension investment in private equity, Group of Ten (economics), Companies listed on theNew York Stock Exchange (P), List of stock market indices, Lists of corporate assets, Companies listed onthe New York Stock Exchange (U), List of public corporations by market capitalization, Net capital outflow,National best bid and offer]Mixtral[Non-fungible token, Blockchain, Cryptocurrency, Digital art, Ethereum, Value proposition, Art market,CryptoKitties, Investment strategy]GPT4[Non-fungible token, Cryptocurrency, Bitcoin, Ethereum, Digital art, Blockchain, CryptoKitties, Digitalasset, Cryptocurrency bubble, Cryptocurrency exchange, Initial coin offering, Cryptocurrency wallet, Smartcontract, Decentralized application, Digital currency]Human[Cryptocurrency, Public key certificate, Blockchain, Virtual economy, Bitcoin, Speculation, Non-fungibletoken, Ethereum]",
  "Prompt. A.1: Prompt template for query generation with LLMs": "Given an input document, your task is to generate a short and self-contained question that couldbe answered by the document. Three examples are given, please finish generating the query for thelast example. Please generate only one short and self-contained question without numbering in asingle line, and do not generate an explanation.Example 1:Document: We dont know a lot about the effects of caffeine during pregnancy on you and yourbaby. So its best to limit the amount you get each day. If you are pregnant, limit caffeine to 200milligrams each day. This is about the amount in 1 8-ounce cups of coffee or one 12-ounce cupof coffee.Relevant Query: Is a little caffeine ok during pregnancy?Example 2:Document: Passiflora herbertiana. A rare passion fruit native to Australia. Fruits are green-skinned, white fleshed, with an unknown edible rating. Some sources list the fruit as edible, sweetand tasty, while others list the fruits as being bitter and inedible.assiflora herbertiana. A rarepassion fruit native to Australia. Fruits are green-skinned, white fleshed, with an unknown ediblerating. Some sources list the fruit as edible, sweet and tasty, while others list the fruits as beingbitter and inedible.Relevant Query: What fruit is native to Australia?Example 3:Document: The Canadian Armed Forces. 1 The first large-scale Canadian peacekeeping missionstarted in Egypt on November 24, 1956. 2 There are approximately 65,000 Regular Force and25,000 reservist members in the Canadian military. 3 In Canada, August 9 is designated as NationalPeacekeepers Day.Relevant Query: How large is the canadian military?Example 4:Document: {input document}Relevant Query:;",
  "Prompt. A.2: Prompt template for few-shot generative entity retrieval": "Identify Wikipedia entities that are helpful to retrieve documents relevant to a web search query.Please return a list of entity names only:Example 1:Query: How is the push towards electric cars impacting the demand for raw materials?Entities: [\"Cobalt\", \"Automotive battery\", \"China\", \"Electric car\", \"Electric battery\", \"Gigafactory1\", \"Demand\", \"Fossil fuel\", \"Electric vehicle industry in China\", \"Electric vehicle battery\",\"Electric vehicle conversion\", \"Electric vehicle\", \"Supply and demand\", \"Mining industry of theDemocratic Republic of the Congo\", \"Raw material\", \"Lithium iron phosphate\", \"Lithium-ionbattery\", \"Mining\", \"Lithium\", \"Petroleum\"]Example 2:Query: Why do many economists argue against fixed exchange rates?Entities: [\"Argentine peso\", \"Currency crisis\", \"Inflation\", \"Hong Kong dollar\", \"Exchangerate\", \"Gold standard\", \"European Exchange Rate Mechanism\", \"1998 Russian financial crisis\",\"Black Saturday (1983)\", \"Black Wednesday\", \"Optimum currency area\", \"Mexican peso crisis\",\"Milton Friedman\", \"Euro\", \"Recession\", \"Currency intervention\", \"1997 Asian financial crisis\",\"Devaluation\", \"Original sin (economics)\", \"Exchange-rate regime\"]Please find relevant entities for this new example:Query: {input query}Entities:"
}