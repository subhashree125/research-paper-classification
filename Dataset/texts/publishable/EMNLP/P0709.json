{
  "Abstract": "Answering reasoning-based complex questionsover text and hybrid sources, including tables,is a challenging task.Recent advances inlarge language models (LLMs) have enabledin-context learning (ICL), allowing LLMs toacquire proficiency in a specific task using onlya few demonstration samples (exemplars). Acritical challenge in ICL is the selection ofoptimal exemplars, which can be either task-specific (static) or test-example-specific (dy-namic). Static exemplars provide faster infer-ence times and increased robustness across adistribution of test examples. In this paper, wepropose an algorithm for static exemplar subsetselection for complex reasoning tasks. We in-troduce EXPLORA, a novel exploration methoddesigned to estimate the parameters of the scor-ing function, which evaluates exemplar sub-sets without incorporating confidence informa-tion. EXPLORA significantly reduces the num-ber of LLM calls to 11% of those requiredby state-of-the-art methods and achieves a sub-stantial performance improvement of 12.24%.We open-source our code and data1.",
  "Introduction": "Answering complex questions that require multi-step reasoning (Chen et al., 2022b; Lu et al., 2023a;Ling et al., 2017; Roy and Roth, 2016; Roy andAnand, 2022; Venktesh et al., 2024) over structuredand unstructured sources is an active research areawith applications in finance, law, fact-checking andhealthcare (Wang et al., 2023a; Zhang et al., 2021).Unlike fine-tuning task-specific models (Chiangand Chen, 2019; Amini et al., 2019; Ling et al.,2017; Roy and Roth, 2016; Geva et al., 2020;Cobbe et al., 2021), recent advances in Large Lan-guage Models (LLMs) have paved the way for newapproaches that employ in-context learning (ICL) (Wei et al., 2023) to solve complex reasoning prob-lems. This approach focuses on choosing a smallnumber of demonstration examples to be used asinput prompts to LLMs.An effective way to tackle complex reasoningproblems is to use chain-of-thought (COT) prompt-ing, which adds hand-crafted natural languagerationales as stepwise solutions to the prompts,resulting in the triplet (input, rationale,output) (Wei et al., 2023). In this work, we re-fer to this triplet as an exemplar. A limitation ofthe COT-based method for reasoning tasks is thetedious and non-scalable manual effort requiredin selecting the rationales or exemplars (Lu et al.,2022; Zhao et al., 2021; Chang and Jia, 2023). Toaddress these limitations, both static and dynamicapproaches for automatic exemplar selection havebeen proposed (Ye et al., 2023a; Lu et al., 2022;Rubin et al., 2022; Fu et al., 2023). Some ap-proaches require annotated data and training ofmultiple models for exemplar selection (Lu et al.,2023b; Ye et al., 2023a). Dynamic exemplar se-lection methods often involve additional computa-tional costs because they select exemplars duringquery time, necessitating extensive query encod-ing and dynamic exploration of the search space.In contrast, static exemplar selection pre-selects asmall subset of exemplars, which are used duringLLM inference. Prior exemplar selection methodsdo not capture interactions between the exemplarsin the selected set (Li and Qiu, 2023). Addition-ally, current static selection approaches (Li and Qiu,2023) are characterized by a large number of LLMcalls, which are computationally expensive. In this work, we propose EXPLORA, a novelstatic exemplar subset selection method that se-lects multiple low-loss exemplar subsets (overviewin ). Our method is designed based on twohypotheses: (1) An effective exemplar selectionalgorithm for ICL should model the end-to-endICL process, and (2) Prompt generators (refer Sec- tion 3.1), which generate prompts using multipleexemplar subsets can be used to enhance the ef-fectiveness of static ICL predictors for complexreasoning tasks. Following these hypotheses, wemodel the problem of static exemplar selection forIn-context Complex Reasoning (ICCR) tasks as anovel top-l exemplar subset-selection problem. Weuse a linear model of similarity with validationexamples for modeling the loss incurred by exem-plar subsets. We propose a novel sampling-basedbandit algorithm for simultaneously estimating theparameters of the loss model and identifying thetop-l exemplar subsets, while incurring a low num-ber of calls to the LLM (which corresponds to alow sample complexity of the bandit algorithm).Our approach implicitly captures the interactionsbetween the exemplars in the subset by scoringsubsets. We conduct extensive experiments acrossmultiple reasoning-based QA tasks. Our resultsindicate that EXPLORA outperform both static anddynamic exemplar selection baselines by 12.24%and 45.45% respectively (), while reducingthe number of LLM calls to 11% of the state-of-the-art (Li and Qiu, 2023) ().Contributions. The contributions of our work are:(1) We propose a novel top-l exemplar-subsetselection approach, EXPLORA, for end-to-end in-context learning of complex reasoning tasks byapproximating the loss for a given exemplar subsetusing a scoring function.(2) We introduce a novel sampling-based banditalgorithm for efficiently learning the parametersof the scoring function and estimating the top-lexemplar subsets.(3) We demonstrate that the exemplars selectedby EXPLORA on smaller LLMs can be well trans-ferred to larger LLMs (), reducing the costincurred by larger LLMs for exemplar selection.(4) We show that exemplars selected by EX-",
  "Related Work": "While many existing techniques for complex rea-soning tasks involve fine-tuning of specialized mod-els (Chiang and Chen, 2019; Amini et al., 2019;Chen et al., 2020), these approaches require accessto the model parameters. Recent developments inlanguage models have introduced few-shot prompt-ing approaches (Brown et al., 2020a; Wei et al.,2022) through ICL (Wei et al., 2023; Wang et al., 2023b; Kojima et al., 2023; Chen et al., 2022a) andCOT in complex reasoning tasks (Ling et al., 2017;Cobbe et al., 2021; Brown et al., 2020b; Shin et al.,2020; V et al., 2023). However, a major drawbackof these approaches is the need for manual selectionof exemplars, which is tedious and non-scalable.Moreover, ICL is sensitive to the sample order (Luet al., 2022), dataset, task, and models (Zhao et al.,2021) (Su et al., 2022), making optimal exemplarselection essential for stable task performance.Exemplar-Selection for ICL: Several automatedexemplar selection methods have been proposedto eliminate the need for manual selection. Theseinclude reinforcement learning-based approaches(Zhang et al., 2022; Lu et al., 2023b), Determinan-tal Point Processes (Ye et al., 2023a), Low Rankapproximation (DQ-LoRe) (Xiong et al., 2023)and constrained optimization (Tonglet et al., 2023),which are effective for reasoning tasks. Addition-ally, alternative learning-free methods for diverseexemplar selection, such as similarity-based (Rubinet al., 2022), complexity-based (Fu et al., 2023) andMMR (Ye et al., 2023b) have also been proposed.However, existing dynamic exemplar selectionmethods incur additional computational costs dur-ing inference. To address this, a small, representa-tive set of exemplars can be selected for ICL. Un-like coreset selection methods (Guo et al., 2022),which rely on gradient-based model updates fortraditional deep learning, ICL performs the targettasks without any parameter updates.To the best of our knowledge, there has beenvery little research in this area, with the closestwork being LENS (Li and Qiu, 2023). However,LENS relies on LLMs output probabilities andthus cannot be extended to black-box LLMs. Inthis work, we propose a novel and robust approachfor static exemplar selection that is applicable toblack-box and also other open language models.",
  "EXPLORA: Model-based Explorationfor Exemplar Subset Selection": "In black-box models, we cannot access the param-eters of the LLMs or compute the gradient of theloss with respect to these parameters. Additionally,intermediate representations or generative probabil-ity scores from LLMs cannot be utilized for scoringexemplar subsets. To overcome these challenges,we introduce a novel approach to effectively selectexemplar subsets without relying on the parametersof the LLMs. .1 formally describes the scorer : Overview of EXPLORA: Initially, set U is randomly selected from set U. In each iteration, parameters ofthe scoring function (, .) are computed by minimizing a loss function. guides the selection of the subset fromU \\ U with the lowest loss, which is then used to update U. This iterative updating process ensures U maintainslow-loss subsets, leading to a more accurate estimation of in subsequent iterations.",
  "ICL for Complex Reasoning": "In-context learning (ICL) leverages LLMs to ac-quire proficiency in a specific task using only a fewexemplars, without updating the models parameter.During this process, the LLM is provided with aprompt that includes input-rationale-output triplet,referred to as exemplars, which demonstrate thetask to the LLM. Due to the financial and perfor-mance costs associated with large contexts, provid-ing all n training examples is impractical. Hence,exemplar selection methods curate a few exem-plars that maximize overall accuracy. Formally, letX = {xi, zi, yi}ni=1 denote the set of all n trainingexamples (potential exemplars), and let xtest be atest input. The goal is to predict the test output ytest.Let S X denote a subset of k exemplars used forpredicting xtest. The prompt P is constructed as:P = [S, xtest] = [(xi1, zi1, yi1), ..., (xik, zi1, yik),xtest], The end-to-end ICL process can be de-scribed as a composition of two steps: (1) re-sponse generator f, and (2) post-processing (de-coding) . The response generator f generatesmultiple responses, r from the probability distribu-tion PLLM. The post-processing step is appliedto the LLM-generated response f(P) to extract thetask-specific output ytest.",
  "Reasoning problems (Ho et al., 2020; Ling et al.,": "2017) are especially challenging due to the com-plex relationship between the exemplars and theLLMs ability to perform multi-step reasoningtasks. It has been demonstrated that providing ra-tionales elucidating the reasoning steps improvesLLM performance compared to state-of-the-art ap-proaches (Wei et al., 2023; Fu et al., 2023). There-fore, selecting exemplars with appropriate ratio-nales tailored to the complex reasoning task is cru-cial (Xiong et al., 2023; Tonglet et al., 2023). How-ever, generic exemplar selection approaches forICL do not explicitly model this role of the ratio-nales and interactions between exemplars. End-to-end modeling of the entire ICL process (Eq 1) isessential for capturing the complex role of the ratio-nales. In this work, we propose implicitly modelingthe relationship between exemplars and explicitlymodeling their relation to the LLMs performanceby scoring subsets of exemplars (see section 3.2).This leads to formulation for the In-context Com-plex Reasoning (ICCR) problem as an exemplar-subset selection problem. A disadvantage of using a single subset of exem-plars is that the prompt may not capture all diverseaspects of a given task. This can be addressed us-ing a prompt generator (S1, ..., Sl, xtest), whichuses multiple subsets of exemplars, S1, ..., Sl anda test input xtest to create a prompt P, improvingoverall performance and robustness compared to using a single exemplar subset. For example, onecan use a similarity-based prompt generator KNN,which selects semantically nearest neighbor subset,or a diversity-based prompt generator MMR (thedetails are described in section 4). In this revisedframework, the entire output generation processcan be described as:",
  "ytest = (f(P)); P = (S1, ..., Sl, xtest)(2)": "In this setup, we are interested in finding a set U ={S1, ...., Sl} of subsets such that the correspondingprompt P generated by the prompt generator minimizes the total validation loss. Let V be theset of m validation examples {ui, vi}mi=1, where uiand vi represents the input and the output of theith validation example respectively. We define thevalidation loss for a prompt generator (U) with aset of exemplar subsets U as:",
  "Loss model for top-l Exemplar SubsetSelection": "There are two main challenges in efficiently solv-ing the exemplar subset selection problem (Eq 4):(1) the set of all exemplar subsets S can be verylarge leading to prohibitive time-complexity. For in-stance, n = 5000 training examples, and a promptsize of k = 5 examples lead to C55000 (approxi-mately 2.5 1016) exemplar subsets. (2) a naivecalculation of loss (Eq 3) for each exemplar subsetS involves m calls (m 1000) to the LLM, whichcan be expensive (both computationally and finan-cially). We address the first issue in section 3.3.We propose to address the second issue by buildinga scoring function () for the subsets S S, whichcan be used to calculate the top-l subsets withoutmaking calls to the LLM. Intuitively, given a subset S, the scoring func-tion (S) should model the validation loss of anexemplar subset, L(, {S}, V), since they are ex-pected to generate identical rankings. Hence, wepropose that should incorporate the relationshipbetween the exemplars question xi and the vali-dation examples question uj V. In this work,we capture the relationship using a similarity score,Eij =(xi)T (uj)",
  "i=1i1(xi S)Eij(5)": "Here, i denotes the i-th exemplars contribution tothe scoring function. We dynamically estimate ito fit the top-l (lowest loss) exemplar subsets in S..3 describes the details of the algorithm.Note that since is can be negative, they canbe learned to implicitly estimate both positiveand negative correlations between training exem-plars xi and xj, according to signs of i and j.Also, note the above equation can be written asni=1 i1(xi S)ei, where ei =1mmj=1 Eij,which indicates that only aggregate effect of ex-emplars in validation set is modeled by . Finally,training exemplars in ICL can be thought of asrepresenting different distinguishable\" solutionconcepts of tasks (see e.g. (Xie et al., 2021)). Forinstance, consider the exemplars selected by EX- PLORA for the AQUARAT dataset () canbe identified with concepts like Proportionality,Series, Kinematics, and Interest. Since the finalscoring function is trained to fit the top-l exemplarsubsets resulting in low loss, the resultant is canbe thought of as implicitly representing the impor-tant concepts needed for effectively predicting thecorrect label (hence resulting in low loss). Unfortu-nately, since is can be both positive and negative,their magnitudes are not directly interpretable asimportance scores for the concepts. Unlike exist-ing works e.g. (Li and Qiu, 2023; Xu and Zhang,2024), we do not use probability scores for tokensprovided by LLMs in our scoring function, as thesescores are not directly related to the predictive task.",
  "Output: UT ;Set of l subsets from U which have thelowest validation loss": "two objectives: (1) learning the parameters of theloss model () for the top-l exemplar subsets, and(2) calculating a set of low-loss exemplar sub-sets, U. This problem can be posed as the top-l arm selection problem in stochastic linear ban-dits (Kalyanakrishnan et al., 2012; Chaudhuri andKalyanakrishnan, 2019). In the current setting, thearms correspond to the exemplar subsets S, andfeature vectors for the linear bandit are given byEij where xi S. The reward in our setting canbe thought of as the negative of loss of a subset:L(, {S}, V). LUCB (Kalyanakrishnan et al.,2012; Chaudhuri and Kalyanakrishnan, 2019) andlater generalized variants of GIFA (Rda et al.,2021) are widely used for top-l arm selection instochastic linear bandits. LUCB maintains two sets:(1) l high-reward arms (called U here), and (2) theother low-reward arms. In each round, one arm ispulled from each of the sets, leading to a revisedestimate of the rewards of all the arms. However,these algorithms are impractical for our setting,since they require at least linear time in the numberof arms, in each round.Algorithm 1 describesEXPLORA, a novelsampling-based bandit algorithm, inspired byLUCB, for estimating i and identifying a set ofl low-loss (corresponding to high reward) exem-plar subsets U. For practicality, we start with amanageable set U S of exemplar subsets aftereliminating the obvious ones (see ). Weinitialize U0 as l random subsets from U. Ut inround t denotes the set of l subsets with the lowestloss. Vt denotes the set of other subsets (note thatwe do not exhaustively enumerate Vt). EXPLORA has two broad steps: (1) calculation of i basedon losses computed using subsets from Ut and Vt,and (2) updating Ut based on the modified scorefunction (due to updation of i). i is updatedby minimizing the following loss function:",
  "SVt(L(S, V) (, S))2 (6)": "Here the first term denotes the approximation errorof the loss model for the low-loss set Ut, and thesecond term denotes the loss on negative samplesfrom high-loss set Vt. The negative samples facili-tate exploration over the set Vt by allowing the ivalues corresponding to unexplored and potentiallylow-loss subsets to be estimated correctly.The key motivation behind this formulation isto be able to frugally compute i while makingminimal calls to the LLM. A naive computationof the first term requires l m calls to the LLM.However, since Ut+1 differs from Ut by only oneexemplar subset, a caching mechanism can imple-ment this step in m calls to the LLM, where mis the validation set size. The second term can becomputed using l m LLM calls, where l is thenumber of negative samples. Ut is updated in lines8 12 in Algorithm 1. Ut+1 differs from Ut byonly one exemplar subset. This leads to a smootherconvergence of i over the iterations since the lossfunction L depends mainly on Ut. Line 11 removesthe exemplar subset St from Ut, which is the high-est estimated loss subset in Ut, and line 12 addsSt to Ut, which is the exemplar subset with thelowest estimated loss in Vt. While a formal conver-gence guarantee for the proposed algorithm will beexplored elsewhere, the updates is designed to de-crease the total validation loss of Ut, provided thatthe estimation of loss (, S), S Ut becomesmore accurate over the iterations. This can beachieved by reducing l over the rounds. Also, notethat the step in line 8 can be expensive to imple-ment in many settings, due to the size of Vt. Hereone can perform an approximate search that finds agood enough St such that (, St ) < (, St).",
  "GPT-3.5-turbo": "DynamicKNN (Rubin et al., 2022)53.4551.9678.3351.5281.83KNN (S-BERT) (Rubin et al., 2022)53.0752.7577.9552.6581.83MMR (Ye et al., 2023b)54.3651.1877.3249.8782.86KNN+SC (Wang et al., 2023c)80.2162.5983.0854.4983.88MMR+SC (Wang et al., 2023c)78.0159.4581.3650.7483.88PromptPG (Lu et al., 2023b)--68.2353.56- StaticZero-Shot COT (Kojima et al., 2023)67.0249.6057.1047.5159.75Manual Few-Shot COT (Wei et al., 2023)73.4644.8871.2252.2273.06Random67.7949.8055.8953.7081.02PS+ (Wang et al., 2023b)59.3046.00---Auto-COT (Zhang et al., 2023b)57.1041.70--71.20GraphCut (Iyer and Bilmes, 2013)66.1947.2460.4552.3180.00FacilityLocation (Iyer and Bilmes, 2013)68.6148.4367.6636.7981.63LENS (Li and Qiu, 2023)69.3748.8277.2754.7579.79LENS+SC (Li and Qiu, 2023)79.3757.8780.6860.0682.24 Our ApproachEXPLORA77.86(12.24%) 53.54(9.67%)83.07(7.51%) 59.46(8.60%) 85.71(5.63%) EXPLORA+SC86.35(24.48%) 63.39(29.84%) 85.52(10.68%) 64.52(17.84%) 87.14 (9.21%)EXPLORA+KNN+SC85.14 (22.73%)62.20(27.41%)86.29(12.39%) 65.12(18.94%) 88.37(10.75%)EXPLORA+MMR+SC86.13(24.16%) 63.78(30.64%) 86.96(12.54%)64.60(17.99%) 87.55(9.73%)",
  "LENS (Li and Qiu, 2023)76.1964.5686.3469.3192.85EXPLORA93.6369.2990.1272.7195.10": ": Results across datasets (we use 5-shot for all methods). Percentage improvements are reported over LENS(Li and Qiu, 2023). indicates statistical significance using t-test over LENS at 0.05 level and at 0.01 level. RQ II. Can we transfer the exemplars selectedwith respect to smaller language models directly toLarger Language Models?RQ III. Can we minimize the number of calls tothe language models during exemplar selection?",
  "Experimental setting": "Datasets, Metrics: We conduct extensive experi-ments over a range of complex reasoning datasets(GSM8K, AquaRat, TabMWP, FinQA and Strate-gyQA). We use official metrics of the datasets, i.e.,exact match (EM), cover-EM (Press et al., 2023;Rosset et al., 2021). More details about the datasetsand prompts can be found in Appendix A and C.Hyperparameters: For all experiments, we set thetemperature to 0.3 to mitigate randomness, withfrequency and presence penalty set to 0.8 and 0.6to avoid repetition. We set the max_token_lengthto 900 for generation. For efficiency reasons, wecarry our experiments in a transfer setting, wherewe select exemplars using EXPLORA or other staticexemplar selection methods for smaller models likeMistral-7b and Llama2-7b and then transfer themto a larger model like gpt-3.5-turbo to perform in-ference owing to its superior capabilities. We reportperformance on smaller LLMs in Appendix B.Subset selection hyperparameters:For EX-",
  "PLORA, we set k as 5, the desired number of clus-ters to be formed from the training set. We set the": "number of validation examples V to 20. We con-struct a set U, of 40 subsets, each containing 5 ex-emplars, by randomly selecting one exemplar fromeach cluster with replacement. While we experi-mented with larger values for size of U (100..etc.)we observe that at U=40, we achieve optimal perfor-mance on validation set. Initially, set U consists of10 random subsets from set U, while V comprisesthe remaining subsets not included in U. In eachround, we randomly sample 5 subsets from V . Weupdate U by removing the worst subset and add thebest subset from V to it. This process repeats for10 iterations, with the stopping criterion of approx-imation error being unchanged between iterations,resulting in U having 10 low-loss subsets. EXPLORA Variants: We posit that static and dy-namic approaches can complement each other andapply dynamic methods like MMR and KNN overthe l subsets selected by EXPLORA, thereby reduc-ing the search space. This makes EXPLORA+KNNand EXPLORA+MMR a hybrid approach.",
  ": Results for transfer (T) of exemplars selectedusing EXPLORA (EXP) on smaller LLMs (Llama2-7b(L) and Mistral-7b (M)) to larger LLM (gpt-3.5-turbo)": "be the optimal value. For KNN (S-BERT), weemploy sentence transformer paraphrase-MiniLM-L6-v2. We also compare with the chain of thoughtmethods like Manual Few-Shot COT (Wei et al.,2023), Zero-Shot COT (Kojima et al., 2023), ran-dom , coreset selection methods (Facility Locationand Graph Cut (Iyer and Bilmes, 2013)) and task-specific approaches like Plan and Solve\" (Wanget al., 2023b) and Auto-COT (Zhang et al., 2023b).LENS (Li and Qiu, 2023): We compare witha closely related static exemplar selection methodwhere the training data is filtered in two stages toextract informative examples.",
  "Performance Comparison": "To answer RQ1, we compare EXPLORA and itsvariants with state-of-the-art static and dynamic ex-emplar selection methods. We observe in that EXPLORA outperforms the random baseline,which highlights the non-triviality of the proposedtask of selecting task-level representative exem-plars. We also observe that EXPLORA outperformsmanual Few-Shot COT (Wei et al., 2023).We also compare EXPLORA with LENS (Li andQiu, 2023) a static exemplar selection method forICL. We observe that EXPLORA and its variantssignificantly outperform LENS. For instance, onGSM8K EXPLORA outperforms LENS by 12.24%.LENS scores each exemplar independently with-out considering any interactions between the exem-plars, and also assumes access to LLM logits. How-ever, in EXPLORA, scores are assigned to subsets,allowing for the implicit capture of the interplaybetween the exemplars within each subset. This isparticularly important for reasoning tasks, as theexemplars need to contain sufficient informationfor solving diverse reasoning based questions. Weperform a qualitative analysis of exemplars chosenby LENS vs EXPLORA in Appendix D.",
  ": Comparison of robustness of EXPLORA to otherapproaches. We report standard deviation (lower isbetter) with scores from different splits of eval. set": "We also observe that existing coreset selectionmethods like Graph Cut and Facility Location per-form worse than or are similar in performance tothe random exemplar selection. This indicates theimportance of designing methods specific to ICLfor exemplar selection.We also observe that EXPLORA outperformsdynamic exemplar selection methods like KNN,PromptPG and MMR. A significant limitation,apart from additional inference time computationalcosts, is that dynamic exemplar selection methodsdo not consider interactions between the exemplars.",
  "Transferability of exemplars from smallerLLMs to larger LLMs": "To answer RQ2, we report the performance ontest set in transfer setting across tasks using gpt-3.5-turbo with exemplars selected from Llama2-7band Mistral-7b as shown in . In we report the EXPLORA results from this transfersetup with exemplars selected from Mistral-7b. Weobserve that the exemplars selected by EXPLORAusing smaller LLMs transfer well to larger LLMs,as indicated by their superior performance com-pared to baselines through evaluation in the trans-fer setting. This shows the strong transferability ofour selected exemplars and the effectiveness of EX-",
  ": (Top) Frugal exemplar selection by EXPLORA:LLM calls LENS vs EXPLORA (y-axis) with corre-sponding EM scores indicated on top of bars. (Bottom)Runtime comparison LENS vs EXPLORA": "different subsets of the evaluation set when com-pared to other static exemplar selection methods.We also observe that in 3 out of 4 datasets, exem-plars chosen by EXPLORA has less variance in taskperformance when compared to dynamic exemplarselection methods like KNN and MMR. Exemplarsselected through dynamic approaches are not opti-mized for the task but rather on a per-test-examplebasis. Consequently, this leads to greater variancein final task performance. In TabMWP, we observethat the variance in results is low for all exemplarselection methods. Hence, EXPLORA helps selectexemplars for the task which are more robust thanother static methods or dynamic selection methods.",
  "Exemplar selection efficiency based onnumber of LLM evaluations": "To answer RQ3, we compare the number of callsmade to the LLMs during the exemplar selectionstep. We compare the number of such calls andalso running times for the LENS approach and ourproposed approach EXPLORA as shown in . We observe that LENS has significantly moreLLM calls than EXPLORA (about 10x). This isbecause LENS relies on confidence estimates fromthe LLM for each training example and computesan informativeness score for all examples in the",
  ": Ablation studies: exhaustive evaluation, w/oexploration vs proposed exploration (EXPLORA)": "dataset, incurring expensive LLM calls for eachexample. Whereas, EXPLORA computes scores forwhole exemplar subsets and employs a explorationbased approach, resulting in LLM calls only forsmall number of subsets. In summary, EXPLORAdrastically reduces the number of LLM calls (to 11% of calls made by LENS) and also reducesrunning time as shown in during exemplarselection step with significant performance gains.",
  "Ablation Studies": "We conduct an exhaustive evaluation to compareour exploration method and demonstrate its effec-tiveness, as shown in . Evaluating all possi-ble subsets is infeasible, so we exhaustively eval-uated a downsampled set of 40 subsets (U from EXPLORA) on the validation set. We then selectedthe subset with the minimum validation loss forsubsequent inference on the test set. Our superiorperformance compared to the exhaustive evaluationis due to modeling the top-l subsets in each round.Additionally, we perform an ablation studywhere we fit the linear model once on the entiredownsampled set of 40 subsets (shown in ). Then we select the subset with the minimumapproximation error (loss) for subsequent inferenceon the test set. Note that in this ablation, the linearmodel is fit once for all subsets, whereas in EX-",
  "Conclusion": "In this work, we propose an efficient and robusttask level exemplar subset selection method thatidentifies highly informative exemplar subsets. Theproposed method saves resources by reducing thenumber of LLM calls, in contrast to the currentstate-of-the-art. We also observe that the exemplarsobtained using smaller LLMs can be well trans-ferred to larger LLMs. EXPLORA outperforms ex-isting static and dynamic exemplar selection meth-ods. In future, we plan to further explore hybridexemplar selection and the impact of exemplars fortasks involving complex reasoning.",
  "Limitations": "Our method deals with selecting top-l exemplarsubsets that are best suited to improve the overallperformance through In-Context Learning (ICL).We identify certain limitations that could be ad-dressed in future works.Our method is significantly efficient and com-putationally less resource intensive compared tostate-of-the-art exemplar selection methods. How-ever, one of the limitations of our approach is thatif the space of the subsets U is large in some scenar-ios, then the computational time of the step (Algo1, line 8) that calculates the lowest loss subset fromV would increase. However, it would not increasethe number of LLM calls and would still be compu-tationally less resource intensive than the existingapproaches. We would also need more efficientways to sample negative examples (Eq 6) with in-crease in size of U. While currently we propose arandom sampling mechanism to sample negativeexamples from V , in future we plan to further ana-lyze the impact of sampling negative examples forlarger U sizes. We defer this for future work, as itis beyond the scope of the current work.While EXPLORA converges as observed from ourexperiments, the current work does not provide ananalysis or provable guarantees for convergence ofthe parameter . In future, we plan to provide ananalysis for convergence of parameter .",
  "Ethical Considerations": "The intended use of the proposed approach is ex-emplar selection for reasoning problems that canbe used to build QA systems for finance or educa-tion. Since our approach uses LLM for complexreasoning-based QA, the risks of hallucination (Jiet al., 2023) must be taken into consideration beforedeploying the approach. Since users may trust thehallucinated answers from the QA system, this mayresult in the spread of misinformation (Zhang et al.,2023a; Albrecht et al., 2022). We observe that EXPLORA is more robust across test instances com-pared to baselines due to the transfer of informativeexemplars with rationales. Although hallucinationis still a possibility when employing EXPLORA andthe resulting QA systems are not infallible.Additionally, we do not use any private infor-mation for the proposed approach. Though LLMsmay have been pre-trained on sensitive information,our prompts do not elicit any sensitive informationdirectly or indirectly.",
  "Joshua Albrecht, Ellie Kitanidis, and Abraham J. Fet-terman. 2022. Despite \"super-human\" performance,current llms are unsuited for decisions about ethicsand safety": "Aida Amini, Saadia Gabriel, Shanchuan Lin, RikKoncel-Kedziorski, Yejin Choi, and Hannaneh Ha-jishirzi. 2019. MathQA: Towards interpretable mathword problem solving with operation-based for-malisms. In Proceedings of the 2019 Conferenceof the North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, Volume 1 (Long and Short Papers), pages23572367, Minneapolis, Minnesota. Association forComputational Linguistics. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020a.Language models are few-shot learners.In Ad-vances in Neural Information Processing Systems,volume 33, pages 18771901. Curran Associates,Inc.",
  "Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, Amanda": "Askell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020b.Language models are few-shot learners.In Ad-vances in Neural Information Processing Systems,volume 33, pages 18771901. Curran Associates,Inc.",
  "Wenhu Chen, Xueguang Ma, Xinyi Wang, andWilliam W. Cohen. 2022a.Program of thoughtsprompting: Disentangling computation from reason-ing for numerical reasoning tasks": "Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong,Hong Wang, and William Yang Wang. 2020. Hy-bridQA: A dataset of multi-hop question answeringover tabular and textual data. In Findings of the Asso-ciation for Computational Linguistics: EMNLP 2020,pages 10261036, Online. Association for Computa-tional Linguistics. Zhiyu Chen, Wenhu Chen, Charese Smiley, SameenaShah, Iana Borova, Dylan Langdon, Reema Moussa,Matt Beane, Ting-Hao Huang, Bryan Routledge, andWilliam Yang Wang. 2022b. Finqa: A dataset ofnumerical reasoning over financial data.",
  "Ting-RuiChiangandYun-NungChen.2019": "Semantically-alignedequationgenerationforsolving and reasoning math word problems.InProceedings of the 2019 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,Volume 1 (Long and Short Papers), pages 26562668, Minneapolis, Minnesota. Association forComputational Linguistics. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,Mark Chen, Heewoo Jun, Lukasz Kaiser, MatthiasPlappert, Jerry Tworek, Jacob Hilton, ReiichiroNakano, Christopher Hesse, and John Schulman.2021. Training verifiers to solve math word prob-lems.",
  "Xiaonan Li and Xipeng Qiu. 2023. Finding supportexamples for in-context learning. In The 2023 Con-ference on Empirical Methods in Natural LanguageProcessing": "Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-som. 2017. Program induction by rationale genera-tion: Learning to solve and explain algebraic wordproblems. In Proceedings of the 55th Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long Papers), pages 158167, Vancouver,Canada. Association for Computational Linguistics. Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu,Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark,and Ashwin Kalyan. 2023a. Dynamic prompt learn-ing via policy gradient for semi-structured mathemat-ical reasoning. Pan Lu, Liang Qiu, Kai-Wei Chang, Ying Nian Wu,Song-Chun Zhu, Tanmay Rajpurohit, Peter Clark,and Ashwin Kalyan. 2023b. Dynamic prompt learn-ing via policy gradient for semi-structured mathemat-ical reasoning. Yao Lu, Max Bartolo, Alastair Moore, Sebastian Riedel,and Pontus Stenetorp. 2022. Fantastically orderedprompts and where to find them: Overcoming few-shot prompt order sensitivity. In Proceedings of the60th Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages80868098, Dublin, Ireland. Association for Compu-tational Linguistics.",
  "Subhro Roy and Dan Roth. 2016. Solving general arith-metic word problems": "Ohad Rubin, Jonathan Herzig, and Jonathan Berant.2022. Learning to retrieve prompts for in-contextlearning. In Proceedings of the 2022 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, pages 26552671, Seattle, United States.Association for Computational Linguistics. Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, EricWallace, and Sameer Singh. 2020. AutoPrompt: Elic-iting Knowledge from Language Models with Auto-matically Generated Prompts. In Proceedings of the2020 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 42224235,Online. Association for Computational Linguistics. Hongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi,Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf,Luke Zettlemoyer, Noah A. Smith, and Tao Yu. 2022.Selective annotation makes language models betterfew-shot learners.",
  "Dingzirui Wang, Longxu Dou, and Wanxiang Che.2023a. A survey on table-and-text hybridqa: Con-cepts, methods, challenges and future directions": "Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu,Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim.2023b. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large languagemodels. In Proceedings of the 61st Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long Papers), pages 26092634, Toronto,Canada. Association for Computational Linguistics. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V Le,Ed H Chi, Sharan Narang, Aakanksha Chowdhery,and Denny Zhou. 2023c. Self-consistency improveschain of thought reasoning in language models. InThe Eleventh International Conference on LearningRepresentations. Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,Barret Zoph, Sebastian Borgeaud, Dani Yogatama,Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.Chi, Tatsunori Hashimoto, Oriol Vinyals, PercyLiang, Jeff Dean, and William Fedus. 2022. Emer-gent abilities of large language models.",
  "Jiacheng Ye, Zhiyong Wu, Jiangtao Feng, Tao Yu, andLingpeng Kong. 2023a. Compositional exemplarsfor in-context learning": "Xi Ye, Srinivasan Iyer, Asli Celikyilmaz, Veselin Stoy-anov, Greg Durrett, and Ramakanth Pasunuru. 2023b.Complementary explanations for effective in-contextlearning. In Findings of the Association for Compu-tational Linguistics: ACL 2023, pages 44694484,Toronto, Canada. Association for Computational Lin-guistics. Jianyi Zhang, Xu Ji, Zhangchi Zhao, Xiali Hei, andKim-Kwang Raymond Choo. 2023a. Ethical consid-erations and policy implications for large languagemodels: Guiding responsible development and de-ployment. Yiming Zhang, Shi Feng, and Chenhao Tan. 2022. Ac-tive example selection for in-context learning. In Pro-ceedings of the 2022 Conference on Empirical Meth-ods in Natural Language Processing, pages 91349148, Abu Dhabi, United Arab Emirates. Associationfor Computational Linguistics.",
  "An overview of the dataset statistics and examplesare shown in": "FinQA: Comprises financial questions over fi-nancial reports that require numerical reasoningwith structured and unstructured evidence. Here,23.42% of the questions only require the informa-tion in the text to answer; 62.43% of the questionsonly require the information in the table to answer;and 14.15% need both the text and table to answer.Meanwhile, 46.30% of the examples have one sen-tence or one table row as the fact; 42.63% has twopieces of facts; and 11.07% has more than twopieces of facts. This dataset has 1147 questions inthe evaluation set. AquaRat: This dataset comprises 100,000 al-gebraic word problems in the train set with devand test set each comprising 254 problems. theproblems are provided along with answers and nat-ural language rationales providing the step-by-stepsolution to the problem. An examples problem isshown in . TabMWP: It is a tabular-based math wordproblem-solving dataset with 38,431 questions.TabMWP is rich in diversity, where 74.7% of thequestions in TabMWP belong to free-text ques-tions, while 25.3% are multi-choice. We treat allquestions as free-form type and do not provide anyoptions to the LLM for consistent evaluation. Weevaluate on the test set with 7686 problems.",
  "GSM8K: This dataset consists of linguisticallydiverse math problems that require multi-step rea-soning. The dataset consists of 8.5K problems andwe evaluate on the test set of 1319 questions": "StrategyQA: To prove the generality of our ap-proach for reasoning tasks, we evaluate on Strate-gyQA (Geva et al., 2021b), a dataset with implicitand commonsense reasoning questions. Since thereis no public test set with ground truth answers, weperform stratified sampling done on 2290 full trainset to split into 1800 train and 490 test. Metrics: For TabMWP and StrategyQA we em-ploy cover-EM (Rosset et al., 2021; Press et al.,2023), a relaxation of Exact Match metric whichchecks whether the ground truth answer is con-tained in the generated answer. This helps handlescenarios where LLM generates \"4 hours\" and theground truth is \"4\". For other numerical reasoningdatasets, we employ Exact match.",
  "BResults using Alternate Open SourceLLMs": "We also report the performance of the proposedexemplar selection approach EXPLORA on open-source models like Mistral-7b and LLama2-7b. Theresults are shown in . We observe thatthe absolute performance across baselines and EX- PLORA is lower than when employing gpt-3.5-turboas backbone for the same exemplars. We primarilyobserve that this is due to the scale of the Languagemodels as Mistral and LLAMA2 models have 7billion parameters while gpt-3.5-turbo is of muchlarger scale and the emergent capabilities like In-Context Learning are proportional to scale of thelanguage models (Wei et al., 2022).However, we still observe that EXPLORA leads toreasonable performance gains over other static ex-emplar selection methods across the smaller open-source LLMs. We also observe that EXPLORA andits variants are competitive with dynamic exemplarselection methods.Our main experiments are carried out in a trans-fer setting where exemplar selection is done usingsmall open source LLMs and transferred to largerLLMs. This is done for reducing the cost of LLMinference during exemplar selection, and also toleverage superior performance of LLMs with largerscale during inference. This setting is inspired fromthe work P (Yang et al., 2022) where the languagemodel hyperparameters are tuned on a smaller LMand transferred to a larger language model.",
  "DExemplar Qualitative Analysis": "We provide a qualitative analysis of exemplars andcompare the exemplars selected using EXPLORAwith exemplars selected using LENS (Li and Qiu,2023), the recent state-of-the-art approach.The final set of exemplars chosen by LENS vs EXPLORA for the AquaRat dataset is shown in Ta-ble 7. We observe that Question 4 and Question5 in the set of exemplars chosen by LENS are re-dundant in that they are very similar problems thatrequire similar reasoning steps and are also similarthematically. Both the questions are centered onthe theme of work and time and are phrased in asimilar manner. Hence, they do not add any addi-tional information to solve diverse problems theLLM may encounter during inference. However,we observe that the exemplars chosen by EXPLORAare problems that require diverse reasoning capa-bilities and are also different thematically.We also compare the exemplars chosen by EX- PLORA with LENS for the FinQA dataset ( ) and make similar observations. We observe thatthe exemplars chosen by EXPLORA comprises di-verse set of problems with diverse reasoning. Wealso observe that EXPLORA also contains exem-plars that require composite numerical operationswith multi-step reasoning rationales to arrive at thesolutions, whereas LENS mostly has exemplarswith single-step solutions.The exemplars chosen by LENS compared to EXPLORA for TabMWP are shown in . Weobserve that exemplar 1 and exemplar 3 chosen byLENS are redundant, as they represent the samereasoning concept of computing median for a listof numbers. However, we observe that EXPLORAselects diverse exemplars with each exemplar rep-resenting a different reasoning concept.We also demonstrate the exemplars for GSM8Kand StrategyQA in and respec-tively.",
  "EAnalysis of Accuracy (Exact Match) vsnumber of LLM calls": "We analyze the change in accuracy in proportionto number of calls to the LLM (EXPLORA Algo1 iterations) as shown in . We observethat the performance increases with number ofLLM calls/iterations (Algorithm 1) of EXPLORAalgorithm. We also observe that for GSM8K andTabMWP EXPLORA converges and obtains opti-mal validation set performance quickly with lessnumber of LLM calls, as observed in .",
  "AQUA Prompt": "Instruction:You are a helpful, respectful and honest assistant helping to solvemath word problems or tasks requiring reasoning or math.Follow givenexamples and solve the problems in step by step manner.Exemplars:[Question]: The average age of three boys is 45 years and their ages are in proportion 3:5:7. What is the age in yearsof the youngest boy?[Options]: A) 9, B) 10, C) 11, D) 12, E) 13[Explanation]: 3x + 5x + 7x = 45,x = 3,3x = 9[Answer]: The option is A. ... ..Test Input: Question: Options:Explanation: [INS] Answer: [INS]",
  "FinQA Prompt": "Instruction:You are a helpful, respectful and honest assistant helping to solvemath word problems or tasks requiring reasoning or math, using the informationfrom given table and text.Exemplars:Read the following table, and then answer the question:[Table]: Year | 2016 | 2015 | 2014 |share-based compensation expense | 30809 | 21056 | 29793 |income tax benefit | 9879 | 6907 | 7126 |[Question]: how much percent did the income tax benefit increase from 2014 to 2016?[Explanation]: x0 = (9879 7126 ),ans=( x0/7126 )[Answer]: The answer is increased 38.6%. ... ..Test Input: Read the following table, and then answer the question: Table: Question:Explanation: [INS] Answer: [INS]",
  "GSM8K Prompt": "Instruction:You are a helpful, respectful and honest assistant helping to solvemath word problems or tasks requiring reasoning or math.Follow givenexamples and solve the problems in step by step manner.Exemplars:[Question]: Samir just turned half the age Hania was 10 years ago. If in five years Hania will be 45 years old, what willSamirs age be five years from now?[Explanation]: If in five years, Hania will be 45 years old, currently she is 45 5 = 40 years old.Samir just turned half the age Hania was 10 years ago, which means she is 30/2 = 15 years old.In five years, Samir will be 15 + 5 = 20 years old.[Answer]: 20 years old. ... ..Test Input: Question:Explanation: [INS] Answer: [INS]",
  "TabMWP Prompt": "Instruction:You are a helpful, respectful and honest assistant helping to solvemath word problems or tasks requiring reasoning or math, using the informationfrom the given table.Solve the given problem step by step providing anexplanation for your answer.Exemplars:[Table]: Table: Day | Number of ticketsMonday | 36Tuesday | 43Wednesday | 46Thursday | 59Friday | 37Saturday | 46Sunday | 51[Question]: The transportation company tracked the number of train tickets sold in the past 7 days. What is the range ofthe numbers?[Explanation]: Read the numbers from the table. 36, 43, 46, 59, 37, 46, 51First, find the greatest number. The greatest number is 59.Next, find the least number. The least number is 36.Subtract the least number from the greatest number: 59 - 36 = 23[Answer]: The range is 23. ... ..Test Input: Table: Question:Explanation: [INS] Answer: [INS]",
  "StrategyQA Prompt": "Instruction:You are a helpful, respectful and honest assistant helping to solvecommonsense problems requiring reasoning.Follow the given examples that usethe facts to answer a question by decomposing into sub-questions first andthen predicting the final answer as \"Yes\" or \"No\" only.Exemplars:[Facts]: Snowden scored above 145 on two separate IQ tests. The minimum accepted IQ score for MENSA on theStanfordBinet is 132, while for the Cattell it is 148.[Question]: Could Edward Snowden join MENSA?[Sub-question 1]: What is the minimum accepted IQ score to be admitted to MENSA?[Sub-question 2]: What is Edward Snowdens IQ?[Sub-question 3]: Is #2 greater than or equal to #1?[Answer]: Yes. ... ..Test Input: Facts: Question:Sub-question: [INS] Answer: [INS]",
  "MethodExemplars": "LENSFacts: Penguins are native to deep, cold parts of southern hemisphere. Miami is locatedin the northern hemisphere and has a warm climate. Question: Would it be common tofind a penguin in Miami? Rationale: Where is a typical penguins natural habitat? Whatconditions make #1 suitable for penguins? Are all of #2 present in Miami? Answer: NoFacts: Shirley Bassey recorded the song Diamonds are Forever in 1971. Over time,diamonds degrade and turn into graphite. Graphite is the same chemical compositionfound in pencils. Question: Is the title of Shirley Basseys 1971 diamond song a truestatement? Rationale: What is the title to Shirley Basseys 1971 diamond song? Dodiamonds last for the period in #1? Answer: NoFacts: The first six numbers in Fibonacci sequence are 1,1,2,3,5,8. Since 1 is doubled,there are only five different single digit numbers. Question: Are there five different single-digit Fibonacci numbers? Rationale: What are the single-digit numbers in Fibonaccisequence? How many unique numbers are in #1? Does #2 equal 5? Answer: YesFacts: Katy Perrys gospel album sold about 200 copies. Katy Perrys most recent popalbums sold over 800,000 copies. Question: Do most fans follow Katy Perry for gospelmusic? Rationale: What type of music is Katy Perry known for? Is Gospel music thesame as #1? Answer: NoFacts: The Italian Renaissance was a period of history from the 13th century to 1600.A theocracy is a type of rule in which religious leaders have power. Friar GirolamoSavonarola was the ruler of Florence, after driving out the Medici family, from November1494 C 23 May 1498. Question: Was Florence a Theocracy during Italian Renaissance?Rationale: When was the Italian Renaissance?When did Friar Girolamo Savonarolarule Florence? Is #2 within the span of #1? Did Friar Girolamo Savonarola belong to areligious order during #3? Answer: Yes EXPLORAFacts: The average cost of a US Boeing 737 plane is 1.6 million dollars. Wonder Woman(2017 film) grossed over 800 million dollars at the box office. Question: Is a Boeing 737cost covered by Wonder Woman (2017 film) box office receipts? Rationale: How muchdoes a Boeing 737 cost?. How much did the 2017 movie Wonder Woman gross? Is #2greater than #1? Answer: YesFacts: Big Show is a professional wrestler that weighs 383 pounds. Force is equal to masstimes acceleration. An adult Cheetah weighs around 160 pounds. An adult Cheetah canrun up to 58 MPH. Question: Can a cheetah generate enough force to topple Big Show?Rationale: How much does Big Show weigh? How much does a cheetah weigh? Howfast can a cheetah run? Is the force produced by a mass of #2 and a speed of #3 enough toknock over something that weighs #1? Answer: YesFacts: Spaghetti and meatballs are a staple on Italian pizzeria menus in US. The OliveGarden, an Italian family restaurant, has several dishes with meatballs. Meatballs origi-nated in the Chinese Qin dynasty (221 BC to 207 BC). Question: Do restaurants associatemeatballs with the wrong country of origin? Rationale: In what country is the oldestevidence of people eating meatballs found? ...Are #3 and #1 different? Answer: YesFacts: Torah scrolls must be duplicated precisely by a trained scribe. The Torah has atotal of 8,674 words. The population of Bunkie Louisiana is 3,939 people according to a2018 census. Question: Can you give at least one word from the Torah to all residents ofBunkie Louisiana? Rationale: How many words are in the Torah? How many residentsdoes Bunkie, Louisiana have? Is #1 greater than #2? Answer: YesFacts: Wrestlemania X took place in 1994. The Toyota Prius was first manufactured in1997. Question: Could someone have arrived at Wrestlemania X in a Toyota Prius? Ra-tionale: When did Wrestlemania X hold? When was the Toyota Prius first manufactured?Is #2 before #1? Answer: No : Qualitative analysis of exemplars for StrategyQA dataset selected by LENS vs EXPLORA. Rationale isnot completely shown for some questions to conserve space. However, in our experiments all exemplars includerationales.",
  "= 45 days. This is 5 days behind Schedule Answer: A": "Question: A can do a job in 9 days and B can do it in 27 days. A and B working togetherwill finish twice the amount of work in - days?Options: A)22 days, B)18 days, C)22 6/2 days, D)27 days, E)9 days Rationale:1/9 + 1/27= 3/27 = 1/9 9/1 = 9*2 =18 day Answer: B EXPLORAQuestion: The average age of three boys is 15 years and their ages are in proportion 3:5:7.What is the age in years of the youngest boy? Options: [A)9, B)10, C)11, D)12,E)13] Rationale: 3x + 5x + 7x = 45, x =3, 3x = 9 Answer: AQuestion: Can you deduce the pattern and find the next number in the series? 6, 14, 26, 98?Options: [A)276, B)277, C)278, D)279, E)None of these]Rationale: 6 = 11 + 21 + 31, 14 = 12 + 22 + 32, 36 = 13 + 23 + 33, 98 = 14 + 24 + 34 Thus the next number Answer: AQuestion:In covering a distance of 42 km, A takes 2 hours more than B. If A doubles hisspeed, then he would take 1 hour less than B. As speed is:?Options: A)5 km/h, B)7 km/h, C)10 km/h, D)15 km/h, E)25 km/h Rationale:Let As speed be X km/hr. Then, 42/x - 42/2x = 3 6x = 42 x = 7 km/hr Answer: BQuestion:Find the number which when multiplied by 15 is increased by 196.Options: A)14, B)20, C)26, D)28, E)30 Rationale: Solution Let the number be x. Then, 15x - x = 196 =14x = 196 x = 14 Answer: AQuestion: A certain sum of money at simple interest amounted Rs.980 in 3 years at5% per annum, find the sum? Options: A)867, B)855, C)299, D)852, E)903Rationale: 980 = P [1 + (3*5)/100] P = 852 Answer: D : Qualitative analysis of exemplars for AquaRat dataset selected by LENS vs EXPLORA. Rationale isnot completely shown for some questions to conserve space. However, in our experiments all exemplars includerationales."
}