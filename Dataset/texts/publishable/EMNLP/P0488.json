{
  "Abstract": "The Matthew effect is a big challenge in Rec-ommender Systems (RSs), where popular itemstend to receive increasing attention, while lesspopular ones are often overlooked, perpetuatingexisting disparities. Although many existingmethods attempt to mitigate Matthew effect inthe static or quasi-static recommendation sce-narios, such issue will be more pronouncedas users engage with the system over time.To this end, we propose a novel framework,Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning for Conversational Rec-ommendation (HiCore), aiming to addressMatthew effect in the Conversational Recom-mender System (CRS) involving the dynamicuser-system feedback loop. It devotes to learnmulti-level user interests by building a set ofhypergraphs (i.e., item-, entity-, word-orientedmultiple-channel hypergraphs) to alleviate theMatthew effec. Extensive experiments on fourCRS-based datasets showcase that HiCore at-tains a new state-of-the-art performance, un-derscoring its superiority in mitigating theMatthew effect effectively. Our code is avail-able at",
  "Introduction": "Engaging users in ongoing conversations forpersonalized recommendations, ConversationalRecommendation Systems (CRSs) (Qin et al.,2023; Mishra et al., 2023) have become a prevalentstrategy utilized in diverse fields (Liu et al., 2023;Epure and Hennequin, 2023).However, CRSsoften face a big challenge known as Matthew effect(Liu and Huang, 2021), captured by the adage \"theprivileged gain more privilege, while the under-privileged fall further behind.\" This observationunderscores that well-received items or categoriesin past records garner heightened visibility infuture suggestions, whereas less preferred onesfrequently face neglect or marginalization.",
  "Corresponding author": "Lately, a multitude of studies have focusedon investigating the Matthew effect in relativelyunchanging offline recommendation scenarios(Liu and Huang, 2021; Anderson et al., 2020),identifying two root causes for its occurrence. Onecause (Liang et al., 2021; Zheng et al., 2021a;Hansen et al., 2021; Anderson et al., 2020) isthe heightened vulnerability of individuals withnarrower and uniform preferences or intereststo succumb to the pervasive influence of theMatthew effect. This susceptibility often stemsfrom a tendency towards familiarity and comfort,leading to a reinforcement of existing patternsand a limited exploration of diverse alternatives.Another cause (Zheng et al., 2021b) arises fromthe pervasive favoritism towards mainstream items,resulting in a perpetual reinforcement of theirprominence, while lesser-known alternatives lingerin the shadows. This bias towards popular choicesnot only perpetuates existing trends but also limitsthe discoverability of niche or underappreciatedoptions. Thus, the amplification of visibility forwidely favored items can overshadow the potentialvalue and diversity offered by less popular butequally deserving alternatives.Despite their effectiveness,most existingmethods still suffer from two major limitations. 1)Interactive Strategy. While many methods haveoffered valuable insights into the Matthew effect,they often overlook the adverse effects originatingfrom the dynamic user-system feedback loop(Zhang et al., 2021), as they primarily focus onmitigating the Matthew effect in relatively stableoffline recommendation settings.In fact, theMatthew effect can intensify as users interact moreactively with the system over time, potentiallyexacerbating concerns such as echo chambers(Ge et al., 2020) and filter bubbles (Steck, 2018).Hence, it is important to address the Matthew effectin the CRS. 2) Interest Exploration. Consideringthat the root cause of the Matthew effect lies in the confinement of user interests (Zheng et al.,2021a; Liang et al., 2021; Hansen et al., 2021;Anderson et al., 2020), most existing methodsfocus on leveraging hypergraphs to unveil complexhigh-order user relationship patterns for exploringuser interests. However, these hypergraphs oftenremain single-channel, constraining their capacityto capture diverse user relation patterns since eachhypergraph can only represent a specific type ofuser patterns.Moreover, these single-channelhypergraphs may risk evolving into traditionalKnowledge Graphs (KGs) due to the scarcity ofuser-item interaction data. Thus, the constructionof multi-channel hypergraphs is paramount forexploring multi-level user interests.To address these limitations, we propose thenovel framework,Multi-Hypergraph BoostedMulti-InterestSelf-SupervisedLearningforConversational Recommendation (HiCore), whichaims to mitigate the negative impact of Mattheweffect when users engage with the system over timein the CRS. It is comprised of Multi-HypergraphBoosted Multi-Interest Self-Supervised Learningand Interest-Boosted CRS. The former devotesto construct multi-hypergraph (i.e., item-oriented,entity-oriented, and word-oriented triple-channelhypergraphs) to learn multi-level user interests (i.e.,item-level, entity-level, word-level triple-channelinterests), where triple channels contain the group,joint, and purchase channels. The latter aims toutilize the multi-level interests to enhance bothconversation and recommendation tasks whenusers chat with system over time.Concretely,multi-level user interests are used to effectivelygenerate next utterances in the conversational task,and accurately predict users interested items inthe recommendation task. Extensive experimentalresults on four benchmarks show that HiCoreachieves a new state-of-the-art performancecompared all the baselines, and the effectivenessof mitigating Matthew effect in the CRS.Overall, our main contributions are included:",
  "Matthew Effect in Recommendation": "The Matthew effect poses a formidable challengein recommendation systems. To combat this issue,there are two primary research lines. One line of re-search focuses on understanding a diverse range ofuser interests to enhance recommendation diversifi-cation (Anderson et al., 2020; Hansen et al., 2021;Liang et al., 2021; Zheng et al., 2021a). The otherline of research (Zheng et al., 2021b) is dedicatedto mitigating popularity bias to ensure a balancedexposure of items across various categories. For ex-ample, Wang et al. (Wang et al., 2019) conducteda meticulous quantitative analysis, providing valu-able insights into the quantitative characteristicsof the Matthew effect in collaborative-based rec-ommender systems. Liu et al. (Liu and Huang,2021) have confirmed the presence and impact ofthe Matthew effect within the intricate algorithmsof YouTubes recommendation system. However,these methods primarily concentrate on exploringthe Matthew effect in static recommendation envi-ronments, overlooking the crucial interplay of theuser-system feedback loop.",
  "Conversational Recommender System": "Conversational Recommendation System aims touncover users genuine intentions and intereststhrough natural language dialogues, thereby offer-ing top-notch recommendations to users. Currently,CRS-based methods can be categorized into twomain groups. 1) Attribute-based CRS (Deng et al.,2021a; Lei et al., 2020a,b; Ren et al., 2021; Xuet al., 2021), which seeks to delve into user in-terests by posing queries about items or their at-tributes. However, this approach primarily relieson predefined templates for response generation,often falling short in producing fluent, human-likenatural language expressions. 2) Generated-basedCRS (Chen et al., 2019; Deng et al., 2023; Li et al.,2022; Zhou et al., 2020a, 2022; Shang et al., 2023),which can address the shortcomings of attribute-centric CRS by utilizing the Seq2Seq architecture(Vaswani et al., 2017a) to integrate a conversa-tion component and a recommendation component,resulting in the creation of smooth and coherenthuman-like responses. Despite their effectiveness,they face challenges in grasping the varied inter-ests of users because of the restricted and scarcecharacter of user-item interaction data. : Overview of our HiCore framework. It consists of Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning and Interested-Boosted CRS. The former aims to learn multi-level user interests, while thelatter devotes to generate responses in the conversation module and predict items in the recommendation module.",
  "HiCore": "Most existing methods (Hussein et al., 2020; Liuet al., 2021a; Nguyen et al., 2014) have consistentlyrevealed that individuals with constrained interestsare greatly impacted by Matthew effect. Thus,we propose a novel framework, HiCore, whichis comprised of Multi-Hypergraph Boosted Multi-Interest Self-Supervised Learning and Interest-Boosted CRS. The overall pipeline of the proposedHiCore is illustrated in .",
  "In this section, we will establish multi-hypergraphto learn multi-level user interests to mitigateMatthew effect in the CRS": "3.1.1Multi-Hypergraph Boosts Multi-InterestInstead of linking only two nodes per edge as intraditional KGs, hypergraphs extend the notion ofedges to connect more than two nodes. By utiliz-ing diverse hypergraphs to encode various high-order user relation patterns, we construct multipleknowledge-oriented triple-channel hypergraphs.Item-oriented triple-channel Hypergraphs. Wefirst build item-oriented hypergraphs from triplechannels, i.e., Group Channel (g), Joint Chan-nel (j) , and Purchase Channel (p) via the Motif",
  ": Triangle motifs used in our proposed HiCore": "(Milo et al., 2002; Yu et al., 2021), a commonlyutilized tool for capturing complex local structuresinvolving multiple nodes, as illustrated in .Group-channel hypergraph. Group-channelhypergraphs aim to analyze users social relationsto unveil the dynamics among individuals basedon their shared interests, preferences, and char-acteristics. Understanding group preferences notonly consolidates individual tastes but also facil-itates collective decisions that benefit the entiregroup. Formally, we utilize a set of triangular mo-tifs (Milo et al., 2002; Yu et al., 2021) to build theitem-oriented group-channel hypergraphs G(i)g as:",
  "G(i)g= (V(i)g , N (i)g , A(i)Mgk ).(1)": "Here V(i)grepresents the set of items derivedfrom the historical conversations, while N (i)g={M gk|1 k 7} denotes the collection of hy-peredges, with each hyperedge representing anoccurrence of the specified motif M gk in .A(i)Mgk |V(i)g | |N (i)g | is the group-motif-inducedadjacency matrices. Firstly, we need to define thematrix computation of each type of motif. Let H(i)kbe the matrix computation of the motif M gk, thenwe can obtain:",
  "If (A(i)Mgk )n,r=1, it signifies that the noden and the node r co-occur in a single in-stance of M gk.When two nodes appear inmultiple instances, it turns to be (A(i)Mgk )n,r =": "#(n, r occur in the same instance of M gk).Joint-channel hypergraph. The joint channelreflects the scenario of shared behaviors amongfriends in a social network. When friends purchasethe same items, it not only suggests similarities intastes and interests but also hints at deeper levels ofinteraction and trust. This phenomenon of \"friends purchasing the same item\" may facilitate informa-tion dissemination and interaction within the socialnetwork, strengthening social relationships, and tosome extent, reflecting influence and collective be-havior within the social network. Therefore, byidentifying and analyzing the joint motifs, the item-oriented joint-channel hypergraph G(i)jis:",
  "(4)": "where V(i)j , and N (i)j= {Mjk|8 k 9} denotethe item set, and the hyperedge set, respectively.Each hyperedge is induced from each type of jointmotif, depicted in . R is a binary matrix thatrecords user-item interactions, and A(i)Mjk denotes the joint-motif-induced adjacency matrices.Purchase-channel hypergraph. Additionally,we should also take into account users who do nothave explicit social connections. Therefore, theanalysis is non-exclusive and delineates the im-plicit higher-order social relationships among userswho lack direct social ties but still purchase thesame items. By considering these users withoutovert social links, we can uncover hidden patternsof social influence and affiliation that transcend tra-ditional network structures. Thus, the item-orientedpurchase-channel hypergraph G(i)p can be inducedfrom the purchase motif M p10 as follows:",
  "A(i)Mpk = H(i)10 = RRT ,ifM p10,(5)": "here V(i)pand N (i)p= {Mpk|k = 10} are the itemset and hyperedge set, respectively. Specifically,the hyperedge set, depicted in . A(i)Mpk is thepurchase-motif-induced adjacency matrices.Entity-oriented triple-channel hypergraphs. Totackle the sparsity and constraints inherent in his-torical user-item interaction data, we leverage therich DBpedia KG (Auer et al., 2007) to build anentity-oriented hypergraph. More precisely, weidentify individual items referenced in historicalconversations as entities and their k-hop neighbors to construct each hyperedge. This method enablesus to capture shared semantic nuances among thebroader network of neighbors. Similar to item-oriented triple-channel hypergraphs, we build theentity-oriented hypergraphs from triple channel set-ting. Formally, the entity-oriented hypergraphsG(e)cfrom triple-channel c can be given as:",
  "G(e)c= (V(e)c , N (e)c, A(e)Mck).(6)": "Here c {g, j, p} represents triple channels (i.e.,group, joint, and purchase channel). V(e)cdenotesthe entities from triple-channel setting. These enti-ties are k-hop neighbors extracted from the histor-ical conversations. N (e)cmeans the hyperedge setinduced from different motifs. Each hyperedge isan instance of the Motif. A(e)Mck represents the group-channel, joint-channel, and purchase-channel adja-cency matrices, they are defined as Eq.(3), Eq.(4),and Eq.(5), respectively.Word-oriented triple-channel hypergraphs. Thesignificance of keywords exchanged during con-versations is paramount in grasping users require-ments. By scrutinizing notable words, we can pin-point specific inclinations, a critical aspect in mod-eling an array of user tastes. To realize this ob-jective, we construct a lexeme-centric hypergraphutilizing the lexicon-focused ConceptNet (Speeret al., 2017) KG to unveil semantic associationssuch as synonymy, antonyms, and co-occurrence.Based on these analysis, the word-oriented hyper-graphs from group-, joint-, and purchase-channelcan be expressed as:",
  "G(w)c= (V(w)c, N (w)c, A(w)Mck),(7)": "where V(w)cis the words from k-hop neighbors.N (w)cdenotes the hyperedge set from different mo-tifs, including group, joint, purchase motifs. A(w)Mckare the word-oriented adjacency matrices inducedfrom triple channels, illustrated in Eq.(3) Eq.(5). 3.1.2Multi-Interest Self-Supervised LearningAfter constructing a series of hypergraphs fromtriple-channel setting, we will construct multi-leveluser interests via the hypergraph convolution net-work (Yu et al., 2021), which can be written as:",
  "P (l+1)c= D1c KcL1c KTc P (l)c= D1c A(i)c P (l)c ,(8)where P (l)cand P (l+1)crepresent the output of thel-th and (l + 1)-th layers, respectively. Specifically,": "the base user embedding is P (0)c= fcgate(P (0)),and fcgate() is self-gating units (SGUs) to controlthe information flow to different channel from thebase user embedding P (0). Dc is the degree matrixof Ac, which is the summation of the motifs with-out considering self-connections (Yu et al., 2021).In terms of the group motifs, it can be definedas A(i)c= 7k=1 A(i)Mk, in terms of joint motifs,",
  "uUlog(f(zhu, kh) f(zhu, kh)": "(11)Here zhu = fhgate(fs(Xh; phu), fs() is the sum op-eration, zhu is the negative example by shufflingboth rows and columns of zhu, and h is defined asEq.(9). f() Rdd serves as the discriminator,evaluating the alignment between two input vectors.Specifically, kh = fout(Zh), where Zh and Xmare ground truths for each other, and fout() aimsto perform permutation invariant (Yu et al., 2021).",
  "Challenges Discussion": "Throughout the developmental journey of hyper-graphs, we surmounted several significant chal-lenges, elaborated upon below:1) Hypergraph Construction Challenge: Duringthe projects initial stages, the real-time construc-tion of hypergraphs presented a bottleneck, result-ing in delays. Through the strategic repositioningof this operation to the data preprocessing phase,we adeptly extracted essential subgraphs, leadingto a noteworthy reduction in training time. Thisadjustment enhanced efficiency, streamlined pro-cesses, and improved performance.2) Graph Storage Challenge: The transition tosparse graph storage mechanisms is pivotal in en-hancing efficiency, streamlining computation time,and optimizing memory utilization. Embracing thisshift not only boosts the systems performance butalso establishes a robust foundation for scalableand resource-efficient operations.3) Model Training Challenge: With the emer-gence of a series of hypergraphs, optimizing theefficiency of model training becomes paramount.Consequently, we redefined our strategy by dispers-ing hypergraphs across multiple computing cards,enabling parallel computation and achieving a sig-nificant boost in the models runtime speed.",
  "Experimental Protocol": "Datasets. We assess the effectiveness of our pro-posed HiCore through comprehensive evaluationson four CRS-based benchmarks: REDIAL (Liet al., 2018b), TG-REDIAL (Zhou et al., 2020b),OpenDialKG (Moon et al., 2019), and DuRecDial(Liu et al., 2021b). The REDIAL dataset com-prises 11,348 dialogues involving 956 users and6,924 items, while the TG-REDIAL dataset en-compasses 10,000 dialogues with 1,482 users and",
  "ModelREDIALTG-REDIAL": "R@10R@50 M@10 M@50 N@10 N@50R@10R@50 M@10 M@50 N@10 0.1821 0.0235 0.0285 0.0328 0.05800.0097 0.0208 0.0040 0.0045 0.0053 0.0077SASRec0.1117 0.2329 0.0540 0.0593 0.0674 0.09360.0043 0.0178 0.0011 0.0017 0.0019 0.0047BERT4Rec0.1285 0.3032 0.0475 0.0555 0.0663 0.10450.0043 0.0226 0.0013 0.0020 0.0020 0.0058KGSF0.1785 0.3690 0.0705 0.0796 0.0956 0.13790.0215 0.0643 0.0069 0.0087 0.0103 0.0194TG-ReDial0.1679 0.3327 0.0694 0.0771 0.0924 0.12860.0110 0.0174 0.0048 0.0050 0.0062 0.0076ReDial0.1705 0.3077 0.0677 0.0738 0.0925 0.12220.0038 0.0165 0.0012 0.0017 0.0018 0.0045KBRD0.1796 0.3421 0.0722 0.0800 0.0972 0.13330.0201 0.0501 0.0077 0.0090 0.0106 0.0171BART0.1693 0.3783 0.0646 0.0744 0.0888 0.13500.0047 0.0187 0.0012 0.0017 0.0020 0.0048BERT0.1608 0.3525 0.0597 0.0688 0.0831 0.12550.0040 0.0194 0.0011 0.0017 0.0018 0.0050XLNet0.1569 0.3590 0.0583 0.0677 0.0811 0.12550.0040 0.0187 0.0011 0.0017 0.0017 0.0048KGConvRec0.1819 0.3587 0.0711 0.0794 0.0969 0.13580.0220 0.0524 0.0088 0.0102 0.0119 0.0185MHIM0.1966 0.3832 0.0742 0.0830 0.1027 0.14400.0300 0.0783 0.0108 0.0129 0.0152 0.0256HiCore*0.2192 0.4163 0.0775 0.0874 0.1107 0.15580.0270 0.0769 0.0880 0.1074 0.0152 0.0225",
  ": Recommendation results on REDIAL and TG-REDIAL datasets. * indicates statistically significantimprovement (p < 0.05) over all baselines": "33,834 items.To provide a holistic evaluationof our proposed methodology, we integrate twocross-domain datasets, OpenDialKG and DuRec-Dial, which cover a wide array of domains includ-ing movies, music, books, sports, restaurants, news,and culinary experiences.Baselines. We compared our HiCore with the fol-lowing state-of-the-art methods TextCNN (Kim,2014), SASRec (Kang and McAuley, 2018),BERT4Rec (Sun et al., 2019), KBRD (Chen et al.,2019), Trans. (Vaswani et al., 2017b), ReDial (Liet al., 2018a), KGSF (Zhou et al., 2020a), KG-ConvRec (Sarkar et al., 2020), XLNet (Yang et al.,2019), BART (Lewis et al., 2020), BERT (Devlinet al., 2019), DialoGPT (Zhang et al., 2020), Uni-CRS (Deng et al., 2021b), GPT-3 (Brown et al.,2020), C2-CRS (Zhou et al., 2022), LOT-CRS(Zhao et al., 2023), MHIM (Shang et al., 2023),and HyCoRec (Zheng et al., 2024).",
  "Recommendation Performance (RQ1)": "In accordance with (Shang et al., 2023), we uti-lize Recall@K (R@K), MRR@K (M@K), andNDCG@K (N@K) (K=1, 10, 50) to assess the rec-ommendation task. Analyzing the results presentedin and , it is evident that our pro-posed method, HiCore, consistently outperformsall the comparison baselines.There exist multiple crucial facets contribut-ing to the advancement of our proposed HiCoremethod: (a) Diversification of hypergraphs: weintroduced a diverse set of hypergraphs, includingitem-oriented, entity-oriented, and word-orientedhypergraphs. This expansion aims to go beyondthe traditional pairwise interactions, broadening",
  "KBRD0.31921.76600.51801.5500KGSF0.16870.53870.13890.3862ReDial0.15790.58080.10950.3981TGReDial0.48362.14300.54532.0030HyCoRec2.81904.77101.08202.4440HiCore*2.84304.81201.09402.4280": ": Results on both recommendation and conver-sation tasks on OpenDialKG and DuRecDial datasetsinvolving various domains. * indicates statistically sig-nificant improvement (p < 0.05) over all baselines. the scope of user interest modeling by incorpo-rating interactions among multiple nodes.(b)Exploration of hypergraph configurations: mov-ing beyond the conventional triple-channel model,we delved into various hypergraph configurationslike group-channel, joint-channel, and purchase-channel. These configurations were designed tocater not only to social connections but also indi-vidual preferences, enhancing the systems adapt-ability. (c) Integration of multi-level user interests:transitioning from the triple-channel structure, weintegrated these hypergraphs to capture multi-leveluser interests. This strategic shift helps alleviate theMatthew effect in the CRS involving the dynamicuser-system feedback loop. This comprehensiveapproach highlights the innovation and adaptabil-",
  "Conversational Performance (RQ2)": "For the conversation task, we use Distinct n-gram(Dist-n) (Shang et al., 2023) (n=2,3,4) to estimatethe conversation task. and indicatea significant performance superiority of our HiCore.For example, HiCore gains 123.83%, 138.27%,77.26%, 65.75%, 62.90%, and 79.10% improve-ments on Dist-2 against the strong baselines in-cluding, C2-CRS, UniCRS, LOT-CRS, DialoGPT,GPT-3, and MHIM on the REDIAL dataset, respec-tively. It also gains 446.51%, 357.61%, 208.07%,140.80%, 133.46%, and 157.75% improvementson Dist-2 against the strong baselines including,C2-CRS, UniCRS, LOT-CRS, DialoGPT, GPT-3,and MHIM on the REDIAL dataset, respectively.The improvement in HiCore can be attributed tothe following reasons: (a) Our HiCore focuses onconstructing a diverse set of hypergraphs, encom-passing item-oriented, entity-oriented, and word-oriented triple-channel hypergraphs. These struc-tures effectively capture intricate local patternsthrough motif analysis, enabling the explorationof high-order user behaviors. This proves invalu-able in generating informative and high-quality re-sponse utterances. (b) HiCore is dedicated to miti-gating the Matthew effect that may occur as usersengage with the system over time. By learningmulti-level user interests from the hypergraphs, thesystem can adapt to users evolving preferences.This strategic approach enables the CRS to pro-vide a varied array of responses that align with thediverse interests of the users.",
  "Study on Matthew Effect (RQ3)": "Given our goal of mitigating the Matthew effectthat may arise as users interact with the systemover time, we engage in a series of experimentscomparing the proposed method with the mostrobust baselines. This investigation seeks to de-termine the efficacy of HiCore in effectively alle-viating the Matthew effect. Considering the keystrategy to mitigate Matthew effect is to improvethe recommendation diversification, and thus weuse the diversify-based evaluation metrics Cover-age@k (C@k), Average Popularity (A@K) of Rec-ommended Items and Long Tail RecommendationRatio (L@K) to comprehensively evaluate the ef-ficacy of our proposed method in mitigating theMatthew Effect. illustrates the experimental outcomes,showcasing the consistent superiority of HiCorein achieving the highest levels of Coverage acrossall datasets in comparison to the most robust base-lines. The heightened coverage metric highlightsits exceptional ability to encompass a broad spec-trum of the recommendation space by incorporat-ing items from diverse categories. Additionally, as",
  ": Impact of different hyperparameteres": "outlined in , our proposed method demon-strates the lowest values for Average Popularity andLong Tail Ratio. This evidence suggests that ourmethod effectively mitigates the adverse effects ofitem popularity on recommendation outcomes andsuccessfully addresses the long tail distribution ofitems. These results validate the effectiveness ofour proposed approach in combating the Mattheweffect in the CRS as users interact with the systemover time, attributed to its capability to learn multi-level user interests through a series of hypergraphsfrom triple-channel setting, including group, joint,and purchase channels.",
  "Hyperparameters Analysis (RQ4)": "Hyperparameters are parameters in a machinelearning algorithm that need to be manually setand tuned to optimize model performance, distinctfrom the parameters that the model learns duringtraining. Next, we will delve into the research onhow various hyperparameters influence the perfor-mance of recommendations, including the embed-ding dimension d, comparative learning weight ,hypergraph convolution layers N, and the hyper-edge threshold P. From , we can obtain: (1)Elevating the feature dimensionality enhances out-comes, as higher dimensions can encapsulate moreintricate features effectively; (2) Having too few hy-peredges may hinder the capture of intricate localpatterns, whereas an excess of hyperedges couldimpede the models convergence; (3) A lower betavalue signifies a reduced weight for the comparisonterm, which show that the recommendation termexerts a more significant influence on the results;(4) A two-layer hyperconv network is sufficient to",
  "Ablation Studies (RQ5)": "To assess the efficacy of each component within theproposed method, we perform ablation experimentsusing various iterations of Hicore, including: 1)w/o Gig, w/o Gij, w/o Gip: removing item-orientedgroup-channel, joint-channel, purchase-channelhypergraph, respectively; 2) w/o Geg, w/o Gej,w/o Gip: removing entity-oriented group-channel,joint-channel, purchase-channel hypergraph, re-spectively; 3) w/o Gwg , w/o Gwj , w/o Gwp : remov-ing word-oriented group-channel, joint-channel,purchase-channel hypergraph, respectively. outlines the experimental findings, in-dicating that the removal of any hypergraph typeresults in a performance decrease. This highlightsthe effectiveness of each hypergraph type and un-derscores the superiority of HiCore in learningmulti-level user interests through a collection ofhypergraphs to mitigate Matthew effect in the CRS.",
  "Conclusion": "The Matthew effect poses a significant challenge inthe CRS due to the dynamic user-system feedbackloop, which tends to escalate over time as usersengage with the system. In response to these chal-lenges, we proposed a novel framework, HiCore,aimed at mitigating the Matthew effect by capturingmulti-level user interests through a variety of hy-pergraphs, including item-oriented, entity-oriented,and word-oriented triple-channel hypergraphs. Ex-tensive experiments validate that HiCore outper-forms all baselines, demonstrating the effectivenessof HiCore in addressing the Matthew effect as userschat with the system over time in the CRS.",
  "Limitations": "While our HiCore has achieved a remarkable state-of-the-art performance, it does come with certainlimitations. Firstly, triple-channel hypergraphs maypresent challenges due to their computational com-plexity, interpretational intricacies, and potentialissues with sparse data. Secondly, scaling thesehypergraphs to larger datasets could introduce scal-ability hurdles, with a risk of overfitting when themodel becomes excessively fine-tuned to the train-ing data. Furthermore, ensuring generalizabilityand handling resource-intensive computations arecrucial factors to consider when leveraging multi-channel hypergraphs.",
  "Acknowledgements": "This research / project is supported by the NationalResearch Foundation, Singapore and InfocommMedia Development Authority under its Trust TechFunding Initiative. Any opinions, findings and con-clusions or recommendations expressed in this ma-terial are those of the author(s) and do not reflectthe views of National Research Foundation, Singa-pore and Infocomm Media Development Authority.",
  "Ashton Anderson, Lucas Maystre, Ian Anderson,Rishabh Mehrotra, and Mounia Lalmas. 2020. Al-gorithmic effects on the diversity of consumption onspotify. In The Web Conference, pages 21552165": "Sren Auer, Christian Bizer, Georgi Kobilarov, JensLehmann, Richard Cyganiak, and Zachary G. Ives.2007. Dbpedia: A nucleus for a web of open data.In International Semantic Web Conference/Asian Se-mantic Web Conference, volume 4825, pages 722735. Tom B. Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,Clemens Winter, Christopher Hesse, Mark Chen, EricSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,Jack Clark, Christopher Berner, Sam McCandlish,Alec Radford, Ilya Sutskever, and Dario Amodei.",
  "Qibin Chen, Junyang Lin, Yichang Zhang, Ming Ding,Yukuo Cen, Hongxia Yang, and Jie Tang. 2019. To-wards knowledge-based recommender dialog system.arXiv preprint arXiv:1908.05391": "Yang Deng, Yaliang Li, Fei Sun, Bolin Ding, and WaiLam. 2021a. Unified conversational recommenda-tion policy learning via graph-based reinforcementlearning. In Conference on Research and Develop-ment in Information Retrieval, pages 14311441. Yang Deng, Yaliang Li, Fei Sun, Bolin Ding, and WaiLam. 2021b. Unified conversational recommenda-tion policy learning via graph-based reinforcementlearning. In Conference on Research and Develop-ment in Information Retrieval, pages 14311441. Yang Deng, Wenxuan Zhang, Weiwen Xu, WenqiangLei, Tat-Seng Chua, and Wai Lam. 2023. A unifiedmulti-task learning framework for multi-goal conver-sational recommender systems. ACM Transactionson Information Systems, 41(3):125. Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. BERT: pre-training ofdeep bidirectional transformers for language under-standing. In the North American Chapter of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies, pages 41714186. Associationfor Computational Linguistics. Elena V. Epure and Romain Hennequin. 2023. A humansubject study of named entity recognition in conversa-tional music recommendation queries. In EuropeanChapter of the Association for Computational Lin-guistics, pages 12731288. Yingqiang Ge, Shuya Zhao, Honglu Zhou, ChanghuaPei, Fei Sun, Wenwu Ou, and Yongfeng Zhang. 2020.Understanding echo chambers in e-commerce rec-ommender systems. In Conference on Research andDevelopment in Information Retrieval, pages 22612270. ACM. Christian Hansen, Rishabh Mehrotra, Casper Hansen,Brian Brost, Lucas Maystre, and Mounia Lalmas.2021. Shifting consumption towards diverse contenton music streaming platforms. In Conference on WebSearch and Data Mining, pages 238246. ACM.",
  "Yoon Kim. 2014. Convolutional neural networks forsentence classification. In Empirical Methods in Nat-ural Language Processing (Demonstrations), pages17461751": "Wenqiang Lei, Xiangnan He, Yisong Miao, QingyunWu, Richang Hong, Min-Yen Kan, and Tat-SengChua. 2020a. Estimation-action-reflection: Towardsdeep interaction between conversational and recom-mender systems. In Web Search and Data Mining,pages 304312. Wenqiang Lei, Gangyi Zhang, Xiangnan He, YisongMiao, Xiang Wang, Liang Chen, and Tat-Seng Chua.2020b. Interactive path reasoning on graph for con-versational recommendation. In International Con-ference on Knowledge Discovery and Data Mining,pages 20732083. Mike Lewis, Yinhan Liu, Naman Goyal, MarjanGhazvininejad, Abdelrahman Mohamed, Omer Levy,Veselin Stoyanov, and Luke Zettlemoyer. 2020.BART: denoising sequence-to-sequence pre-trainingfor natural language generation, translation, and com-prehension. In the Association for ComputationalLinguistics, pages 78717880. Association for Com-putational Linguistics. Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz,Vincent Michalski, Laurent Charlin, and Chris Pal.2018a. Towards deep conversational recommenda-tions. Advances in Neural Information ProcessingSystems, 31. Raymond Li, Samira Ebrahimi Kahou, Hannes Schulz,Vincent Michalski, Laurent Charlin, and Chris Pal.2018b. Towards deep conversational recommenda-tions. In Advances in Neural Information ProcessingSystems, pages 97489758. Shuokai Li, Ruobing Xie, Yongchun Zhu, Xiang Ao,Fuzhen Zhuang, and Qing He. 2022. User-centricconversational recommendation with multi-aspectuser modeling. In Conference on Research and De-velopment in Information Retrieval, pages 223233. Yile Liang, Tieyun Qian, Qing Li, and Hongzhi Yin.2021. Enhancing domain-level and user-level adap-tivity in diversified recommendation. In Conferenceon Research and Development in Information Re-trieval, pages 747756. ACM. Ping Liu, Karthik Shivaram, Aron Culotta, Matthew A.Shapiro, and Mustafa Bilgic. 2021a. The interactionbetween political typology and filter bubbles in newsrecommendation algorithms. In The Web Conference,pages 37913801.",
  "R. Milo, S. Shen-Orr, S. Itzkovitz, N. Kashtan,D. Chklovskii, and U. Alon. 2002. Network mo-tifs: Simple building blocks of complex networks.Science, 298(5594):824827": "Kshitij Mishra, Priyanshu Priya, and Asif Ekbal. 2023.Help me heal: A reinforced polite and empatheticmental health and legal counseling dialogue systemfor crime victims. In Association for the Advance-ment of Artificial Intelligence, pages 1440814416. Seungwhan Moon, Pararth Shah, Anuj Kumar, and Ra-jen Subba. 2019. Opendialkg: Explainable conver-sational reasoning with attention-based walks overknowledge graphs. In Conference of the Associationfor Computational Linguistics ACL, pages 845854.Association for Computational Linguistics. Tien T. Nguyen, Pik-Mai Hui, F. Maxwell Harper,Loren G. Terveen, and Joseph A. Konstan. 2014. Ex-ploring the filter bubble: the effect of using recom-mender systems on content diversity. In The WebConference, pages 677686. ACM. Libo Qin, Zhouyang Li, Qiying Yu, Lehan Wang, andWanxiang Che. 2023. Towards complex scenarios:Building end-to-end task-oriented dialogue systemacross multiple knowledge bases. In Associationfor the Advancement of Artificial Intelligence, pages1348313491. Xuhui Ren, Hongzhi Yin, Tong Chen, Hao Wang,Zi Huang, and Kai Zheng. 2021. Learning to askappropriate questions in conversational recommenda-tion. In Conference on Research and Developmentin Information Retrieval, pages 808817. Rajdeep Sarkar, Koustava Goswami, Mihael Arcan, andJohn Philip McCrae. 2020. Suggest me a movie fortonight: Leveraging knowledge graphs for conversa-tional recommendation. In Conference on Computa-tional Linguistics, pages 41794189.",
  "Harald Steck. 2018. Calibrated recommendations. InConference on Recommender Systems, pages 154162": "Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin,Wenwu Ou, and Peng Jiang. 2019. Bert4rec: Se-quential recommendation with bidirectional encoderrepresentations from transformer. In InternationalConference on Information and Knowledge Manage-ment, pages 14411450. ACM. Ashish Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoreit, Llion Jones, Aidan N Gomez, ukaszKaiser, and Illia Polosukhin. 2017a. Attention is allyou need. Advances in neural information processingsystems, 30. Ashish Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoreit, Llion Jones, Aidan N. Gomez, LukaszKaiser, and Illia Polosukhin. 2017b. Attention isall you need. In Advances in Neural InformationProcessing Systems, pages 59986008.",
  "Kerui Xu, Jingxuan Yang, Jun Xu, Sheng Gao, Jun Guo,and Ji-Rong Wen. 2021. Adapting user preference toonline feedback in conversational recommendation.In Web Search and Data Mining, pages 364372": "Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G. Car-bonell, Ruslan Salakhutdinov, and Quoc V. Le. 2019.Xlnet: Generalized autoregressive pretraining for lan-guage understanding. In Advances in Neural Infor-mation Processing Systems, pages 57545764. Junliang Yu, Hongzhi Yin, Jundong Li, Qinyong Wang,Nguyen Quoc Viet Hung, and Xiangliang Zhang.2021.Self-supervised multi-channel hypergraphconvolutional network for social recommendation.In World Wide Web WWW, pages 413424. ACM /IW3C2. Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei,Chonggang Song, Guohui Ling, and YongdongZhang. 2021. Causal intervention for leveraging pop-ularity bias in recommendation. In Conference onResearch and Development in Information Retrieval,pages 1120. ACM. Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,Chris Brockett, Xiang Gao, Jianfeng Gao, JingjingLiu, and Bill Dolan. 2020. DIALOGPT : Large-scalegenerative pre-training for conversational responsegeneration. In the Association for ComputationalLinguistics, pages 270278. Association for Compu-tational Linguistics. Zhipeng Zhao, Kun Zhou, Xiaolei Wang, Wayne XinZhao, Fan Pan, Zhao Cao, and Ji-Rong Wen. 2023.Alleviating the long-tail problem in conversationalrecommender systems. In ACM Conference on Rec-ommender Systems, pages 374385. ACM. Yongsen Zheng, Ruilin Xu, Ziliang Chen, GuohuaWang, Mingjie Qian, Jinghui Qin, and LiangLin. 2024. Hycorec: Hypergraph-enhanced multi-preference learning for alleviating matthew effectin conversational recommendation. In the Associa-tion for Computational Linguistics ACL, pages 25262537. Association for Computational Linguistics.",
  "Yu Zheng, Chen Gao, Xiang Li, Xiangnan He, Yong Li,and Depeng Jin. 2021b. Disentangling user interestand conformity for recommendation with causal em-bedding. In The Web Conference, pages 29802991": "Kun Zhou, Wayne Xin Zhao, Shuqing Bian, YuanhangZhou, Ji-Rong Wen, and Jingsong Yu. 2020a. Im-proving conversational recommender systems viaknowledge graph based semantic fusion. In Inter-national Conference on Knowledge Discovery andData Mining, pages 10061014. Kun Zhou, Yuanhang Zhou, Wayne Xin Zhao, XiaokeWang, and Ji-Rong Wen. 2020b.Towards topic-guided conversational recommender system. In Inter-national Conference on Computational Linguistics,pages 41284139. Yuanhang Zhou, Kun Zhou, Wayne Xin Zhao, ChengWang, Peng Jiang, and He Hu. 2022. C2-crs: Coarse-to-fine contrastive learning for conversational recom-mender system. In Web Search and Data Mining,pages 14881496. ACM."
}