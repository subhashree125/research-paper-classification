{
  "Abstract": "The advent of large language models (LLMs)like GPT-4 has catalyzed the exploration ofmulti-task learning (MTL), in which a singlemodel demonstrates proficiency across diversetasks. Task arithmetic has emerged as a cost-effective approach for MTL. It enables perfor-mance enhancement across multiple tasks byadding their corresponding task vectors to apre-trained model. However, the current lackof a method that can achieve optimal perfor-mance with low computational cost and pro-tecting the data privacy, which limits their ap-plication to LLMs. In this paper, we proposeModel Exclusive Task Arithmetic for merg-ing GPT-scale models (MetaGPT), which for-malizes the objective of model merging intoa multi-task learning framework, aiming tominimize the average loss difference betweenthe merged model and each individual taskmodel. Since data privacy limits the use ofmulti-task training data, we leverage LLMs lo-cal linearity and task vectors orthogonality toseparate the data term and scaling coefficientsterm and derive a model-exclusive task arith-metic method. Our proposed MetaGPT is data-agnostic and bypasses the heavy search process,making it cost-effective and easy to implementfor LLMs. Extensive experiments demonstratethat MetaGPT leads to improvements in taskarithmetic and achieves state-of-the-art perfor-mance on multiple tasks.",
  "Arithmetic": ": Existing methods face the trilemma of per-formance, data privacy, and computational costs, whichhinders its application to LLMs. Our MetaGPT can solvethese problems under careful approximation and thuscan scale to GPT3-scale LLMs. 2020). However, for each new application, a sep-arate model has to be fine-tuned and deployed,which is computationally expensive and resource-intensive (Fifty et al., 2021; Zhang and Yang, 2021).Thus, Multi-Task Learning (MTL) methods havebeen proposed and developed to enable a singlemodel to solve multiple tasks concurrently. Conventional MTL approaches typically involvecollecting raw data across multiple tasks and thenjointly training a single model (Caruana, 1997;Yang et al., 2023a). However, the fine-tuning pro-cess becomes extremely computationally intensivewith the development of large language models(LLMs) that may comprise billions or even tril-lions of parameters. Therefore, researchers haveexplored merging various task-specific models withthe expectation that the merged model can handlemultiple tasks simultaneously.One of the outstanding merging methods is taskarithmetic (Ilharco et al., 2023). For a given task,the element-wise difference between the weights of the pre-trained model and the fine-tuned model isreferred to as the task vector. Recent studies haveshown that linearly adding multiple scaled task vec-tors to the pre-trained model can improve perfor-mance across those tasks (Ilharco et al., 2023; Yanget al., 2023b). Nevertheless, previous task arith-metic methods face a trilemma in practice. 1) Thebest-performing task arithmetic methods requireextra training to obtain optimal hyper-parameters,but the high computational costs hinder their appli-cation to GPT3-scale LLMs. 2) Some training-freemethods heuristically set the scaling coefficient toa constant (e.g., 0.3), which is efficient but leadsto sub-optimal performance. 3) Some methodsconduct grid search on the training/validation set,which is sometimes impractical and faces the riskof data privacy concerns. In summary, as illustratedin , there is essentially no task arithmeticmethod suitable for billion-scale models that per-form satisfactorily in practice.To address the aforementioned problems, in thispaper, we propose MetaGPT: an optimal and effi-cient task arithmetic method for MTL without anydata (model exclusive task arithmetic). We beginby providing a detailed theoretical analysis of thetask loss difference and average loss difference in-troduced by the task arithmetic algorithm. Sincewe aim to choose parameters that minimize the av-erage loss difference, we first separate the data termand scaling coefficients, which also establishes aperformance upper bound for task arithmetic. Afterseparating the scaling coefficients, the final resultis quadratic for each scaling coefficient, leading toa closed-form solution that is simple and effectiveto implement.The experimental results on the LLaMA-2 (Tou-vron et al., 2023) and Mistral (Jiang et al., 2023)series demonstrate that the MetaGPT approach issuperior to previous merging methods on severaltasks. MetaGPT provides an efficient avenue to op-timally implement task arithmetic for large-scalemulti-task learning (MTL) and push the frontiersof language model merging. To sum up, our contri-butions include:",
  "Related Work": "Model Merging. Currently, model merging hasbeen developed for multiple uses such as improv-ing performance on a single target task (Izmailovet al., 2018; Wortsman et al., 2022), improving out-of-domain generalization (Ram et al., 2023; Chaet al., 2021; Arpit et al., 2022), and improving theperformance of multi-task learning (Ilharco et al.,2023; Yadav et al., 2024; Yu et al., 2023), which isthe core focus of our research. The range of appli-cations has led to a proliferation of methods to im-prove beyond simple parameter averaging. Fishermerging (Matena and Raffel, 2022) tries to weightthe importance of individual models using FisherInformation Matrix and uses it to merge differentmodels. RegMean (Jin et al., 2022) formulate themerging problem as a regression problem and leadsto an optimal solution for linear models. Task Arith-metic (Ilharco et al., 2023) presents a method formerging models by adding task vectors to the pre-trained model to improve multi-task performance.Ties Merging (Yadav et al., 2024) and DARE (Yuet al., 2023) propose to refine the task vectors byresolving the interference and removing extremelyredundant components. Ortiz-Jimenez et al. (2024)propose that fine-tuning the models in their tangentspace can amplify weight disentanglement and leadto substantial performance improvements.Multi-Task Learning. Multi-task learning is apowerful method for solving multiple correlatedtasks simultaneously (Caruana, 1997). CurrentMTL works mainly focus on learning the sharedrepresentations from designing specific architec-ture (Misra et al., 2016; Sun et al., 2020) or usingspecific optimization methods (Sener and Koltun,2018; Liu et al., 2021). The former focuses onlearning the shared representation using differentmethods such as designing specific representationsharing module (Liu et al., 2019; Ding et al., 2021), learning to branch (Lu et al., 2017; Guo et al.,2020), and based selection criteria (Ma et al., 2018;Hazimeh et al., 2021). And the latter focuses onbalancing multiple tasks from the perspectives oftask training weights (Sener and Koltun, 2018; Liuet al., 2019), gradient dominance (Chen et al., 2018;He et al., 2022; Yang et al., 2023a), and solving gra-dient conflicts (Yu et al., 2020; Chen et al., 2020;Liu et al., 2021). However, the conventional MTLapproaches for collecting raw data across multipletasks for joint training are not suitable for LLMs.The factors contributing to this issue are twofold:first, computational inefficiency due to the substan-tial computational costs associated with updatingpre-trained models; second, a significant number ofdata proprietors are reluctant to disclose valuableor privacy-sensitive raw data.",
  "Notation": "Let : X Y be a neural network tak-ing inputs X and parameterized by a set ofweights . We assume X R, R andY R. We consider fine-tuning a pre-trainedmodel (, 0) on different tasks, with eachtask consisting of a triplet (D, L, ) , whereD = (Dtrain, Dval , Dtest) is the training, valida-tion and test data of task , L is the loss functionof task , and is the model parameters fine-tunedon task based on the pre-trained weight 0.",
  "=1(2)": "where is the scaling coefficient of task vector. As illustrated in Eq. 2, the task arithmetic intro-duces hyper-parameters {| = 1, ,} andthe choice of these scaling coefficients has a signif-icant influence on the performance of the mergedmodel. Thus, selecting the appropriate scaling co-efficients for different task vectors remains a chal-lenging problem.",
  "Existing Methods": "Earlier task arithmetic (Ilharco et al., 2023; Yadavet al., 2024) propose to perform a grid search (G-Task Arithmetic) on the validation set to choosethe optimal scaling coefficients. However, as thenumber of tasks increases, exploring all the scalingcoefficient combinations faces the curse of dimen-sionality. Therefore, to simplify the problem, theyuse the same value for multiple scaling coefficients,thereby reducing the computational complexity. Inthe absence of the training/validation data, they set = 0.3 as the default setting for dataless arith-metic. Moreover, Adamerging (Yang et al., 2023b)aims to autonomously learn the coefficients fromunlabeled test samples using entropy minimization.",
  "Scalability Challenges for LLMs": "The methods mentioned above are not suitable forscaling to LLMs: The grid search method requiresextra validation/training data, which faces the riskof data privacy concerns and the curse of dimen-sionality when the number of tasks increases. Forinstance, conducting a grid search for three hyper-parameters, each with a discretization interval of0.01, would require 106 forward passes across theentire dataset. Setting a fixed value such as 0.3 forall the is time-efficient and can be applied toLLMs, but it leads to sub-optimal performance. Us-ing test data input to unsupervised optimize thesehyper-parameters can lead to an optimal solutionbut requires extra data and necessitates loading mul-tiple models for training. This process is both timeand memory consuming, making it challenging toapply to LLMs. For example, merging three LLMsrequires loading three LLMs simultaneously to op-timize, which is extremely costly. The statementabove suggests that scaling up existing optimal taskarithmetic to LLMs remains a challenging problem.",
  "Overview": "To solve the problems above, we propose a new al-gorithm MetaGPT, based on careful approximationsto a closed-form solution, which easily scales togiant models both in terms of runtime as well asperformance while protecting data privacy. In thissection, we state the motivation and optimizationproblem and solve it step by step. All proofs oflemmas and theorems are provided in the appendix.",
  "= L (final, ) L (, )": "It is obvious that smaller TLD suggests thatthe loss of the merged model is close or even lowerthan the fine-tuned model on task , which indicatesa better task arithmetic performance.However, for task arithmetic, it aims to improvethe average performance of the final model on allthe tasks. Thus, we define the average of all thetask loss differences as Average Loss Difference(ALD), which can be formulated as follows:Definition 2 (Average Task Loss Difference). Forthe fine-tuned models {| = 1, ,} and taskarithmetic merged model final. The average lossdifference for all tasks is defined as:",
  "( 0) (1 )( 0).(7)": "Single TLD is associated with the data, models,and scaling coefficients. As we can see in Eq. 6, wehave transformed the data term to the Hessian,the coefficients = and models term to . As our method tends to achievemodel-exclusive task arithmetic, the final resultshould not correlate with the data term. Thus, wefirst provide a property, which will be used latterin our theorem proofs to separate the data term andscaling coefficients and models term. In general, ifa pre-trained network (; 0) demonstrates kernelbehavior during fine-tuning, i.e., fine-tuning occursin the linear regime, the following property mustbe satisfied (Jacot et al., 2018):Property 5 (NTK linearization). Around the ini-tialization weights 0, a neural network can beapproximated with a linear approximation:",
  "where = ( 0) (, 0) is a data andmodel dependent constant": "It is worth noting that, as the network width ap-proaches infinity, Eq. 8 becomes exact and remainsvalid throughout training (Jacot et al., 2018; Aroraet al., 2019; Lee et al., 2019), which is specificallysuitable for the LLMs arithmetic scenario.The second property is observed by (Ilharcoet al., 2023), which states that the different taskvectors are orthogonal:",
  "NTK Linearization": "Jacot et al. (2018) have proved that when thewidth of the neural network approaches infin-ity, it demonstrates kernel behavior and the op-timization proceeds in the linear regime.Wetest Llama-2-7b-chat-hf (Touvron et al., 2023) onAGIEval (Zhong et al., 2023) dataset to verify its linearity. We have randomly sampled three outputsof the Llama-2-7b-chat-hf when in Eq. 8 getsvalue of [0, 0.1, , 1]. For better visualization,we also subtract all the outputs using max{},ensuring they have the same endpoint. From the re-sults in , we can see that all the outputs arealmost linear with , which indicates that LLMsdo exhibit a kernel behavior during finetuning.",
  "Task Vector Orthogonality": "Ilharco et al. (2023); Yang et al. (2023b) have per-formed experiments to verify this property for vi-sion models. For LLMs, we also observe similarresults: these task vectors are almost orthogonal toeach other. The result has been shown in .We can see that different task vectors are almostorthogonal, and their cosine similarity is nearly 0as Eq.9 expected, which verifies the property wehave used for our proof.",
  "Experiments": "In this section, we conduct experiments to demon-strate the effectiveness of our MetaGPT. In the firstsection, we demonstrate that our MetaGPT consis-tently achieves optimal average performance acrossdiverse datasets and is robust for model series withvarying parameter sizes and architectures. DAREand Ties-Merging are task vector-improving meth-ods that resolve conflicts and redundant parametersbetween task vectors. We conduct experimentsto demonstrate that our method is orthogonal totheirs and can be integrated to improve the aver-age performance further. Finally, we show that the",
  "Merging Models Using MetaGPT": "Dataset and Models.To test the effectiveness ofour method, we use Llama-2-7b-chat-hf (Touvronet al., 2023), MAmmoTH-7B (Yue et al., 2023) andllama-2-coder-7b (Manuel Romero, 2023) as mod-els fine-tuned on general knowledge, math, andcode datasets using the pre-trained model Llama-2-7B-hf (Touvron et al., 2023). Moreover, we use adifferent model architecture: Mistral-7B-Instruct-v0.2 (AI), MAmmoTH2-7B-Plus (Yue et al., 2024)and Mistral-7B-codealpaca-lora (Nondzu) as mod-els fine-tuned on general knowledge, math, andcode datasets using pre-trained model Mistral7B (Jiang et al., 2023). We also provide experi-ments using models with larger sizes: Llama-2-13b-chat-hf (Touvron et al., 2023), MAmmoTH-13B (Yue et al., 2023), and llama-2-13b-code-chat (TASAR, 2023) as models fine-tuned on gen-eral knowledge, math, and code datasets usingthe pre-trained model Llama-2-13B-hf (Touvronet al., 2023). We use WinoGrande (Sakaguchiet al., 2021) and AGIEval (Zhong et al., 2023)for evaluating general knowledge performance,GSM8K (Cobbe et al., 2021) and MATH (Saxtonand Hill, 2019) for testing mathematical reason-ing ability, HumanEval (Chen et al., 2021) andMBPP (Austin et al., 2021) for estimating code-generation capacity. Evaluation Metrics.We use common evalua-tion settings for a single task: 5-shot accuracy forAGIEval, 4-shot accuracy for GSM8K and MATH,3-shot accuracy for MBPP, and zero-shot accuracyfor HumanEval and WinoGrande. We employ twokey metrics in evaluating different merging meth-ods: absolute average performance and normalizedaverage accuracy. Quantitative Evaluation for LLaMA-2-7B.Weuse the metrics and datasets we introduced above toevaluate the performance of different methods. Weuse Weight Average (Wortsman et al., 2022), TaskArithmetic (Ilharco et al., 2023), Ties-Merging (Ya-dav et al., 2024) and DARE (Yu et al., 2023),which are also model exclusive and computation-ally efficient methods, to compare with our methodby merging LLaMA-2-7B. The scores in show that for WinoGrande, AGIEval, GSM8k, andMATH dataset, our method scores 64.25, 32.71,45.41, and 7.80, which outperforms other meth-",
  ": Performance comparison of merging different Mistral-7B fine-tuned models on different datasets": "ods. For the HumanEval dataset, DARE performsbest, and for the MBPP dataset, the Weight Av-erage method achieves the highest score. Sinceour method aims to achieve the average best per-formance, we use absolute average performancescore and normalized average performance scoreto compare the five methods. We can see that ourMetaGPT achieves the rank-1 score 31.51, 1.31 inboth absolute average performance and normalizedaverage performance. Using Different Model Architecture.We alsouse a different model architecture, Mistral-7B, forevaluation, and the result has been shown in .The scores have shown similar results to LLaMA-2-7B: For WinoGrande, AGIEval, GSM8k, andMATH dataset, our MetaGPT scores 41.86, 68.35,66.03, 20.8, which outperforms existing meth-ods, for HumanEval dataset Weight Average, TaskArithmetic, and Ties Merging performs best and forMBPP dataset, DARE method achieves the highestscore.",
  "Using Larger Model Size.We also test ourmethod using a larger model LLaMA-2-13B (Tou-": "vron et al., 2023). The scores in demon-strate that for AGIEval, Math, and MBPP datasets,our method outperforms other methods. For Wino-Grand, GSM8K, and HumanEval dataset, DARE,Weight Average and Ties-Merging achieves thehighest score. Similarly, under the average mea-sure absolute average performance and normalizedaverage performance, our method also outperformsthe other five methods. Integrate with Ties/DAREAs there are conflictsand redundant parameters between task vectors,DARE (Yu et al., 2023) and Ties-Merging (Yadavet al., 2024) are two methods trying to solve theinterfaces, reducing the redundancy and thereby im-proving the performance of task arithmetic. Sinceour method is also based on the framework of taskarithmetic, Ties-merging and DARE are expectedto improve the performance of our MetaGPT fur-ther. As we can see in , under the baselineof Ties-Merging and DARE methods, our methodis orthogonal to Ties-Merging and DARE and canintegrate them into our MetaGPT, thus leading tofurther improvement. For example, the averageabsolute performance of DARE has been improved",
  ": MetaGPT can be integrated with DARE and Ties-Merging, thereby leading to further improvment": "by our MetaGPT from 30.72 to 31.57. And the nor-malized absolute performance of DARE has beenimproved by our MetaGPT from 1.26 to 1.3. Ties-merging also leads to a similar conclusion: the av-erage absolute performance of DARE has been im-proved by our MetaGPT from 30.20 to 31.57. Andthe normalized absolute performance of DARE hasbeen improved by our MetaGPT from 1.26 to 1.33.",
  "Out of Distribution Generalization": "Following (Yang et al., 2023b; Jin et al., 2022), wealso compare the out-of-distribution generalizationability of different merging methods. We evalu-ate different methods using JEC-QA (Zhong et al.,2020), FinanceIQ (DI, 2023), and MedQA (Jinet al., 2021) dataset. All three datasets use 5-shotaccuracy as the evaluation metric. sum-marizes out-of-distribution generalization perfor-mance when merging all domain specific mod-els using different methods.As we can see,MetaGPT outperforms current methods on these un-seen datasets, which demonstrates that MetaGPT ismore robust to the test data distribution shifts.",
  ": Out of Distribution Generalization": "formance. The time complexity for forward andbackward processes is denoted as FW and BP. ForRegMean, it requires the inner product data matri-ces for layer input to calculate the updated parame-ters. It only requires a forward process, but loadingall the inner products of the layer input matrix re-quires O() memory. For Fisher merge, it also re-quires the data to calculate the Fisher Matrix, whichrequires the forward process to calculate the Fishermatrix and O() memory to store the approximateddiagonal Fisher matrix. Grid-search Task Arith-metic (G-Task Arithmetic) requires O(T TFW)forward process to evaluate, where G is the gridnumber (G = 100 means 100 girds from 0 to 1) andT is the number of tasks. The space complexity isalso equal to the memory requirement of the for-",
  "RegMeanO(TFW)O()Fisher MergeO(TFW)O()G-Task ArithmeticO(T TFW)O(SFW)AdaMergingO(TBP)O(SBP )Task ArithmeticO(1)O()Weight AverageO(1)O()MetaGPTO(1)O()": ": Extra data information requirement, time and space complexity, and optimally of current methods. The timecomplexity for forward process and back propagation are denote by TFW, TBP. The space complexity for forwardprocess and back propagation are denote by SFW, SBP. T is the number of task, is the number of parameters and Gis the grid number (G = 100 means 100 girds from 0 to 1). ward process. For Adamerging, it simultaneouslyloads T LLMs to optimize, whose time complexityis O(TBP) and space complexity is: O(SBP ).For weight average, task arithmetic, and MetaGPT,they all do not need extra data information, which ismodel exclusive. Their time and space complexityis O(1) and O(), but only our MetaGPT achievesoptimal performance.",
  "Conclusion": "In this paper, we have provided a novel modelmerging method named MetaGPT, an optimal taskarithmetic algorithm under the setting of efficientand protecting data privacy, which is specificallydesigned for LLMs. We provide the mathemati-cal formulation of task arithmetics optimizationobjective and the theoretical analysis of the taskarithmetic performance bound. By separating thedata and scaling coefficient term under careful ap-proximation, the closed-form solution provides anavenue for optimally achieving task arithmetic un-der the setting of applicable to LLMs and withoutusing any data. Extensive experiment results showthat our MetaGPT outperforms the existing state-of-the-art model-exclusive merging method and canbe integrated with task vector-improving methodssuch as Ties-Merging and DARE to achieve betterperformance.",
  "Mistral AI. Mistral-7b-instruct-v0.2": "Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, Rus-lan Salakhutdinov, and Ruosong Wang. 2019. Onexact computation with an infinitely wide neural net.In Advances in Neural Information Processing Sys-tems (NeurIPS). Devansh Arpit, Huan Wang, Yingbo Zhou, and Caim-ing Xiong. 2022. Ensemble of averages: Improvingmodel selection and boosting performance in domaingeneralization. Advances in Neural Information Pro-cessing Systems, 35:82658277. Jacob Austin, Augustus Odena, Maxwell Nye, MaartenBosma, Henryk Michalewski, David Dohan, EllenJiang, Carrie Cai, Michael Terry, Quoc Le, et al. 2021.Program synthesis with large language models. arXivpreprint arXiv:2108.07732.",
  "Rich Caruana. 1997.Multitask learning.Machinelearning, 28:4175": "Junbum Cha, Sanghyuk Chun, Kyungjae Lee, Han-Cheol Cho, Seunghyun Park, Yunsung Lee, and Sun-grae Park. 2021. Swad: Domain generalization byseeking flat minima. Advances in Neural InformationProcessing Systems, 34:2240522418. Mark Chen, Jerry Tworek, Heewoo Jun, QimingYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-plan, Harri Edwards, Yuri Burda, Nicholas Joseph,Greg Brockman, Alex Ray, Raul Puri, GretchenKrueger, Michael Petrov, Heidy Khlaaf, Girish Sas-try, Pamela Mishkin, Brooke Chan, Scott Gray,Nick Ryder, Mikhail Pavlov, Alethea Power, LukaszKaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cum-mings, Matthias Plappert, Fotios Chantzis, Eliza-beth Barnes, Ariel Herbert-Voss, William HebgenGuss, Alex Nichol, Alex Paino, Nikolas Tezak, JieTang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,William Saunders, Christopher Hesse, Andrew N.Carr, Jan Leike, Josh Achiam, Vedant Misra, EvanMorikawa, Alec Radford, Matthew Knight, MilesBrundage, Mira Murati, Katie Mayer, Peter Welinder,Bob McGrew, Dario Amodei, Sam McCandlish, IlyaSutskever, and Wojciech Zaremba. 2021. Evaluat-ing large language models trained on code. Preprint,arXiv:2107.03374.",
  "Zhao Chen, Vijay Badrinarayanan, Chen-Yu Lee, andAndrew Rabinovich. 2018. Gradnorm: Gradient nor-malization for adaptive loss balancing in deep multi-task networks. In ICML, pages 794803. PMLR": "Zhao Chen, Jiquan Ngiam, Yanping Huang, ThangLuong, Henrik Kretzschmar, Yuning Chai, andDragomir Anguelov. 2020. Just pick a sign: Op-timizing deep multitask models with gradient signdropout. In NeurIPS. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,Mark Chen, Heewoo Jun, Lukasz Kaiser, MatthiasPlappert, Jerry Tworek, Jacob Hilton, ReiichiroNakano, Christopher Hesse, and John Schulman.2021. Training verifiers to solve math word prob-lems. arXiv preprint arXiv:2110.14168.",
  "Duxiaoman DI. 2023. Financeiq": "Ke Ding, Xin Dong, Yong He, Lei Cheng, Chilin Fu,Zhaoxin Huan, Hai Li, Tan Yan, Liang Zhang, XiaoluZhang, et al. 2021. Mssm: a multiple-level sparsesharing model for efficient multi-task learning. InSIGIR, pages 22372241. Jesse Dodge, Gabriel Ilharco, Roy Schwartz, AliFarhadi, Hannaneh Hajishirzi, and Noah Smith. 2020.Fine-tuning pretrained language models: Weight ini-tializations, data orders, and early stopping. arXivpreprint arXiv:2002.06305. Chris Fifty, Ehsan Amid, Zhe Zhao, Tianhe Yu, RohanAnil, and Chelsea Finn. 2021. Efficiently identifyingtask groupings for multi-task learning. Advances inNeural Information Processing Systems, 34:2750327516.",
  "Pengsheng Guo, Chen-Yu Lee, and Daniel Ulbricht.2020. Learning to branch for multi-task learning. InICML, pages 38543863. PMLR": "Hussein Hazimeh, Zhe Zhao, Aakanksha Chowdh-ery, Maheswaran Sathiamoorthy, Yihua Chen, RahulMazumder, Lichan Hong, and Ed Chi. 2021. Dselect-k: Differentiable selection in the mixture of expertswith applications to multi-task learning. NeurIPS,34:2933529347. Yun He, Xue Feng, Cheng Cheng, Geng Ji, YunsongGuo, and James Caverlee. 2022. Metabalance: Im-proving multi-task recommendations via adaptinggradient magnitudes of auxiliary tasks. WWW, pages22052215. Gabriel Ilharco, Marco Tulio Ribeiro, Mitchell Worts-man, Suchin Gururangan, Ludwig Schmidt, Han-naneh Hajishirzi, and Ali Farhadi. 2023. Editingmodels with task arithmetic. The Twelfth Interna-tional Conference on Learning Representations.",
  "Arthur Jacot, Franck Gabriel, and Clment Hongler.2018. Neural tangent kernel: Convergence and gen-eralization in neural networks. Advances in neuralinformation processing systems, 31": "Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, et al. 2023. Mistral7b. arXiv preprint arXiv:2310.06825. Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,Hanyi Fang, and Peter Szolovits. 2021. What diseasedoes this patient have? a large-scale open domainquestion answering dataset from medical exams. Ap-plied Sciences, 11(14):6421.",
  "OpenAI. 2023.GPT-4 technical report.Preprint,arXiv:2303.08774": "Guillermo Ortiz-Jimenez, Alessandro Favero, and Pas-cal Frossard. 2024. Task arithmetic in the tangentspace: Improved editing of pre-trained models. Ad-vances in Neural Information Processing Systems,36. Alexandre Ram, Kartik Ahuja, Jianyu Zhang, MatthieuCord, Lon Bottou, and David Lopez-Paz. 2023.Model ratatouille: Recycling diverse models for out-of-distribution generalization. In International Con-ference on Machine Learning, pages 2865628679.PMLR.",
  "Davut Emre TASAR. 2023. llama-2-13b-code-chat": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023.Llama 2:Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288. Mitchell Wortsman, Gabriel Ilharco, Samir Ya Gadre,Rebecca Roelofs, Raphael Gontijo-Lopes, Ari S Mor-cos, Hongseok Namkoong, Ali Farhadi, Yair Carmon,Simon Kornblith, et al. 2022. Model soups: averag-ing weights of multiple fine-tuned models improvesaccuracy without increasing inference time. In In-ternational conference on machine learning, pages2396523998. PMLR.",
  "Prateek Yadav, Derek Tam, Leshem Choshen, Colin ARaffel, and Mohit Bansal. 2024. Ties-merging: Re-solving interference when merging models.Ad-vances in Neural Information Processing Systems,36": "Enneng Yang, Junwei Pan, Ximei Wang, Haibin Yu,Li Shen, Xihua Chen, Lei Xiao, Jie Jiang, and Guib-ing Guo. 2023a. Adatask: A task-aware adaptivelearning rate approach to multi-task learning.InAAAI, volume 37, pages 1074510753. Enneng Yang, Zhenyi Wang, Li Shen, Shiwei Liu, Guib-ing Guo, Xingwei Wang, and Dacheng Tao. 2023b.Adamerging: Adaptive model merging for multi-tasklearning. In The Twelfth International Conference onLearning Representations.",
  "Yu Zhang and Qiang Yang. 2021. A survey on multi-task learning. IEEE Transactions on Knowledge andData Engineering, 34(12):55865609": "Haoxi Zhong, Chaojun Xiao, Cunchao Tu, TianyangZhang, Zhiyuan Liu, and Maosong Sun. 2020. Jec-qa: a legal-domain question answering dataset. InProceedings of the AAAI conference on artificial in-telligence, volume 34, pages 97019708. Wanjun Zhong, Ruixiang Cui, Yiduo Guo, Yaobo Liang,Shuai Lu, Yanlin Wang, Amin Saied, Weizhu Chen,and Nan Duan. 2023. Agieval: A human-centricbenchmark for evaluating foundation models. arXivpreprint arXiv:2304.06364."
}