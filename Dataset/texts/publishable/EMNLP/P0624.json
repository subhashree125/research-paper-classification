{
  "Abstract": "The reasoning abilities of large language mod-els (LLMs) are the topic of a growing body ofresearch in AI and cognitive science. In this pa-per, we probe the extent to which twenty-nineLLMs are able to distinguish logically correctinferences from logically fallacious ones. Wefocus on inference patterns involving condi-tionals (e.g., If Ann has a queen, then Bobhas a jack) and epistemic modals (e.g., Annmight have an ace, Bob must have a king).These inferences have been of special interestto logicians, philosophers, and linguists, sincethey play a central role in the fundamental hu-man ability to reason about distal possibilities.Assessing LLMs on these inferences is thushighly relevant to the question of how muchthe reasoning abilities of LLMs match those ofhumans. All the LLMs we tested make somebasic mistakes with conditionals or modals,though zero-shot chain-of-thought promptinghelps them make fewer mistakes. Even thebest performing LLMs make basic errors inmodal reasoning, display logically inconsistentjudgments across inference patterns involvingepistemic modals and conditionals, and giveanswers about complex conditional inferencesthat do not match reported human judgments.These results highlight gaps in basic logicalreasoning in todays LLMs.",
  "Introduction": "One of the most distinctive human cognitive abil-ities is the ability to think about what follows ifsomething is the caseconditional thinkingandabout what might or must be the casemodal think-ing (Evans and Over, 2004; Portner, 2009). Suchreasoning about distal possibilities is crucial to thehuman capacity for planning (we try to choose theaction that would bring about the best effects if wewere to take it (Gibbard and Harper, 1981)), causalreasoning (C causes E if E wouldnt have happenedif C hadnt (Lewis, 1973a; Beller and Gerstenberg,2023)), retroactive evaluation, and more. 0%25%50%75%100% Average correct answer frequency Llama 3.1 Instruct 405B GPT-4 Turbo (2024-04-09) Claude 3.5 SonnetGPT-4 Turbo (1106) GPT-4 (0613) Llama 3.1 Instruct 70B Gemini 1.5 Pro GPT-4 (0314) GPT-4o (2024-05-13) GPT-4o mini Claude 3 Opus Gemini 1.5 Flash Mistral Large 2 Mixtral 8x7B Llama 3 Instruct 70B Claude 3 Sonnet Claude 3 Haiku Mixtral 8x22BGemma 2 27B Llama 3 Instruct 8B Code Llama 34B GPT-3.5 Turbo (0125) Llama 2 Chat 7B GPT-3.5 Turbo (1106)Llama 3.1 Instruct 8B Code Llama 7B Llama 2 Chat 13B Mistral 7B Code Llama 13B Temperature: 0, Condition: zero-shot 89% 87% 85% 84% 83% 81% 81% 80% 79% 75% 74% 72% 72% 71% 70% 68% 65% 65% 64% 63% 58% 57% 55% 54% 53% 50% 49% 49% 45% Summary of performance on some simple inferences : Summary of performance on the uncontrover-sial logical inference patterns discussed in 4. Guessingaccuracy is 50%. Larger models generally perform bet-ter, and most models show clear weakness at this task. Conditional and modal language has thus been acentral focus of philosophers (e.g., Stalnaker, 1968;Lewis, 1973b; Khoo, 2022), linguists (e.g., Kratzer,2012; Portner, 2009), and logicians (e.g., Kripke,1963; Stalnaker and Thomason, 1970; van Ben-them, 2023), as well as an interest of computerscientists (e.g., Friedman and Halpern, 1994; Faginet al., 1995), leading to a variety of sophisticatedmodels of conditional and modal reasoning (Egrand Rott, 2021; Garson, 2024). With the rapid recent development of large lan-guage models (LLMs) that at least superficiallyresemble human speakers and reasoners in manyrespects (Huang and Chang, 2022; Wei et al., 2022;Bubeck et al., 2023; Zhao et al., 2023), a natu-ral question to ask is to what extent LLMs havemastered conditional and modal reasoning. In thispaper, we begin to tackle this problem from the per-spective of philosophers and logicians, probing thedegree to which different LLMs have mastered the logical inference patterns characteristic of condi-tional and modal reasoning. For example, considerthe pattern known as Modus Tollens (MT): If p,then q. Not q. Therefore, not p. We tested whetherLLMs draw inferences in accord with this patternby prompting them with many instances of the pat-tern, as in: User prompt: From If Alex finishedthe race, then Chris finished the racetogether with Chris did not finish therace, can we infer Alex did not finishthe race? (System prompt: Answeronly with yes or no and nothing else.)",
  "GPT-4: yes. Mistral 7B: no. Etc": "We then gave other instances of the pattern to eachLLM, asssessing their performance in terms of ac-curacy on the pattern of inference. summa-rizes performance across several inference patternsto be discussed. We also compared performance onthe zero-shot condition shown above with few-shotand chain-of-thought conditions ().After providing some background in 2 and de-tailing our experimental setup in 3, we discussresults for a number of inference patterns in 4.We find that among the LLMs tested, all modelscommit basic fallacies in reasoning with modalsand conditionals. Even the best performing modelsdisplay logically inconsistent judgments across cer-tain inference patterns involving modals and con-ditionals. And almost all models give answers tocertain complex conditional inferences that do notmatch reported human judgments. We also showthat models performance on our reasoning tasksis highly correlated with that of Chatbot Arena Eloratings (Chiang et al., 2024), MMLU (Hendryckset al., 2020), and GSM8K (Cobbe et al., 2021),supporting the hypothesis that logical reasoningabilities are predictive of general model capabili-ties and performance on downstream tasks. In sum,our main contributions in this paper are:",
  "Logical inference": "First and most generally, we draw on a philosoph-ical understanding of what a logical inference is.Logical inferences are those inferences that arevalid just in virtue of the meaning of logical wordslike and, or, not, if, must, might, and soon. That is, a logically valid inference is one whoseconclusion is always true when its premises are, nomatter how the non-logical words in the premisesand conclusion are understood (Tarski, 1936).This contrasts with more colloquial uses of log-ical reasoning that are current in the literature onLLMs, where logical reasoning is often used forreasoning in general, involving inferential leaps ofvarious kinds that go beyond deductive inferenceproper (this holds for many of the tasks studied inXu et al. (2023); Chen et al. (2023); Huang andChang (2023); Liu et al. (2021) and nearly all theBigBench tasks (BIG-bench authors, 2023) catego-rized under the keyword logical reasoning). Forinstance, in the logicians sense, the inference A isto the left of B, hence B is to the right of A is notlogically valid, since its correctness depends on themeaning of the non-logical words left and right.By contrast, A is to the left of B, hence somethingis to the left of B is logically valid, since its cor-rectness relies only on the meaning of the logicalword something. While studying content-basedreasoning in LLMs is obviously of great interest,we believe it is also of fundamental interest to studypurely logical reasoning in LLMs, since such rea-soning is plausibly part of the backbone of humaninference and knowledge of meanings.Regarding purely logical reasoning, a seriesof benchmarks have been created in recent years(Tafjord et al., 2020; Tian et al., 2021; Han et al.,2022; Saparov and He, 2023; Saparov et al., 2023),and various strategies have been proposed to solvesome of them (Creswell et al., 2023; Kazemi et al.,2023; Olausson et al., 2023; Pan et al., 2023; Poe-sia et al., 2023; Ye et al., 2023). Those studies(with the exceptions of Tafjord et al. 2020; Creswellet al. 2023) primarily focus on multi-step reason- ing, where a proof is required from premises to thehypothesis. Here we target single-step inferencepatterns, which we treat as more fundamental. In-deed, the inability to recognize the basic inferencepatterns we study here could provide further expla-nations of failures on multi-step reasoning prob-lems. Most importantly, none of the work abovestudies modal operators, conditional operators, andtheir interactions, our novel focus in this paper.",
  "Modals and conditionals": "Here we draw specifically on the logical and philo-sophical literature on modals and conditionals.Enormous progress has been made in the last halfcentury on both topics. First, modal operators (likemust and might) have been successfully mod-eled as quantifiers over possible worlds (Kripke,1963; Kratzer, 1981). That is, just as Every boyis sitting quantifies universally over all boys (ina given domain), It must be raining quantifiesover all possible worlds (in a given domaininthis case, an epistemic domain) and says that it israining in all of them; and just as Some boy issitting quantifies existentially over boys, It mightbe raining says that it is raining in some epistem-ically possible world. Similarly, a deontic modallike may can be interpreted as quantifying overa domain of deontically possible worlds, so thatYou may eat a cookie is true just in case you eata cookie in some deontically possible world, i.e.,one where all the actual deontic requirements aresatisfied. Likewise, must, on its deontic interpre-tation (as in You must eat this cookie) quantifiesuniversally over deontically possible worlds, andsays that you eat cookies in all of them.This interpretation of modals yields correspond-ing logics of modal language, with the details de-pending on how the domain of possible worlds isobtained (and the interpretation of the other con-nectives and operators with which modals interact).Conditional operators have likewise been ana-lyzed with possible worlds semantics. In classicallogic, if p, then q is treated as the material con-ditional, which is true whenever p is false or q istrue. However, it is almost universally acceptedby philosophers, linguists, and logicians that thistreatment is a very poor approximation to the actualmeaning of if in natural language. For instance,on the material analysis of if, No student willfail if she studies hard would entail Every stu-dent will study hard, which obviously does notfollow. Likewise, if the material analysis were cor- rect, then the probability of if p, then q would goup as the probability of p goes down, but this iswrong. Consider a fair coin. The probability thatthe coin will land heads if it is flipped is intuitively.5, and it is intuitively probabilistically independentof whether the coin is flipped. That is, finding outthat the coin probably will not be flipped does notmake it any more likely that if it is flipped, it willland heads (Douven and Verbrugge, 2013). Edging-ton (1995) provides a battery of widely acceptedfurther arguments against the material analysis.These points are worth emphasizing, since al-though the material analysis is almost universallyrejected by theorists of the conditional, it is stillassumed in much existing work testing the logicalcapacities of humans and LLMs, in both cognitivescience and artificial intelligence (e.g., in the recentWan et al. 2024, which treats the material analysisas one of the benchmarks of correct reasoning withconditionals). This is a serious blindspot, sincefailing to reason in accord with the material con-ditional may be logically correct; and, conversely,reasoning in accord with the material conditionalmay be a serious logical mistake.The most popular alternative treats if p, then qas a restricted modal operator, which says that qis true in all p-worlds (in a given domain). Just asfor modals, this yields corresponding logics, withthe details again depending on assumptions aboutwhich p-worlds are in the domain, together withthe interpretation of other connectives (Stalnaker,1968; Lewis, 1973b; Egr and Rott, 2021).Although the material analysis is almost univer-sally rejected, there is ongoing controversy aboutthe correct logic of conditionals and modals. Wehave chosen a wide range of inference patterns totest: in many of these cases there is (near) universalagreement about whether the inference pattern isvalid. In other cases, there is less agreement aboutwhether the pattern is truly valid, but even in thosecases, there is for the most part agreement aboutwhether typical human reasoners are inclined todraw the inference, and the remaining controversyis about how to model those patterns (as genuine(in)validities or the result of systematic shifts ininterpretation). We do not aim to take a position inthese complex debates here but rather to comparethe behavior of LLMs to widely reported humaninferential dispositions. In future work, we plan tocompare the behavior of LLMs with human sub-jects (compare the methodology of Pavlick andKwiatkowski, 2019; Dasgupta et al., 2022; Web-",
  "Natural language inference": "Our task format and evaluation method is similarto the one used in the natural language inference(NLI) paradigm (Bowman et al., 2015; Williamset al., 2018; Nie et al., 2019), which has a richand long tradition (Katz, 1972; Condoravdi et al.,2003; van Benthem, 2008; MacCartney and Man-ning, 2009; Dagan et al., 2010). There, a problemcomes with a premise P and a hypothesis H, andthe goal is to decide whether the premise entails,contradicts, or is neutral with respect to H. Thenotion of entailment is typically based on commonsense, whereas in this work we exclusively studylogical entailment in the sense specified above.In sum, our approach differs from previous workon LLMs in two central ways: (i) we focus on one-step logical inference, in the austere philosophicalsense, rather than common-sense reasoning in gen-eral, differing from most extant benchmarks; (ii)we bring sophisticated approaches to the logic ofconditionals and modals from philosophy, linguis-tics, and logic, yielding new ways to assess howclosely LLMs match human reasoning in this keydomain. In particular, in contrast to the work onlogical reasoning cited above, we go beyond propo-sitional/predicate logic to incorporate more realisticapproaches to the logic of conditionals and modals,which to our knowledge has not been explored.",
  "Models": "0% 20% 40% 60% 80% 100% Frequency of Consistency for each of six different question orders Frequencies of consistency on DSmi, DSMu, and MiN ConditionZero-shotChain-of-thought : Percentage of responses that were jointly con-sistent when we asked leading models about DSmu,MiN, and DSmi in the same context window, in oneof the six possible orders. Each dot represents such anorder. The results show strong sensitivity to questionorder, which is highly undesirable. 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot CMP example: Suppose that the Lakers, Warriors, and Celticshave the best odds to win the NBA championship. Based on expert projections, it is most likely the Lakers will win,followed closely by the Warriors, with the Celtics having much lower odds. These are the only top contenders, so if the Warriors don t win, then if the Lakers don t win, the Celtics will win. Moreover, it is most likely the Lakerswill win and hence that the Warriors won t win. Does itfollow that it is likely that, if the Lakers don t win, the Celtics will? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: chain_of_thought CMP example: Suppose that the Lakers, Warriors, and Celticshave the best odds to win the NBA championship. Based on expert projections, it is most likely the Lakers will win,followed closely by the Warriors, with the Celtics having much lower odds. These are the only top contenders, so if the Warriors don t win, then if the Lakers don t win, the Celtics will win. Moreover, it is most likely the Lakerswill win and hence that the Warriors won t win. Does itfollow that it is likely that, if the Lakers don t win, the Celtics will?",
  "For our experiments, we created a bank of ques-tions for dozens of inference patterns, allowing usto individually probe LLMs inferential capacities": "with respect to each inference pattern. For eachof these, we began by handcrafting a paradigm in-stance. E.g., for Modus Tollens (MT) (see ),our paradigm instance was: From If Mary was atthe wedding, then Sue was at the wedding togetherwith Sue was not at the wedding, can we inferMary was not at the wedding? With the helpother other LLMs (mostly Claude 2, supplementedby GitHub Copilot and Devin), we created 19 addi-tional instances of the pattern, e.g., From If thealien visited Mars, then the robot visited Jupitertogether with The robot did not visit Jupiter, canwe infer The alien did not visit Mars? To guardagainst an LLM judging an inference based onworld knowledge rather than the inferences logicalform, we also created 20 instances with nonsensepredicates, e.g., From If the flugel was blimmed,then the flugel was zargled together with Theflugel was not zargled, can we infer The flugelwas not blimmed? We denote the version of aninference with nonsense predicates with an x atthe end of its name, e.g., MTx. We also tested or-der effects for all inferences with two premises byswitching the order of premises in an o version.Using nonsense predicates and switched premiseorder yields an ox version that we also tested.We reviewed all LLM-generated stimuli and madenecessary adjustments by hand.",
  "Evaluation": "For each of the 20 instances of an inference pat-tern question and each LLM, we posed the instanceto the LLM with temperature 0 and then 1, alongwith a prompt for either zero-shot, few-shot, orzero-shot chain-of-thought (Kojima et al., 2022)conditions (see Appendix B). For temperature = 1,we asked the question repeatedly to get an empiri-cal frequency for yes and for no.1 To assess the sufficiency of using 20 instancesof each inference pattern, we looked at the Pearsoncorrelation coefficients between the yes-frequencyof model responses to the 20 instances of an infer-ence with nonsensical predicates (like MTx) andthe yes-frequency of model responses to the 20instances with sensical predicates (like MT). The 1We used the following stopping rule: if for a particularquestion the LLM answered yes 10 times in a row or no10 times in a row, then we proceeded to the next question;otherwise we posed the same question a total of 20 timesto the model. For the models with the higher costs per to-ken, we reduced 10 to 5 to reduce cost. For OpenAI models,the empirical frequencies obtained closely agree with the logprobabilities, but log probs were not available for all models.",
  "DS:Either Fido is inside or Fido is in the garden. Fido is not in the garden.CT:If its raining, then its not raining hard.p q, q p Fido is inside.p q q p If its raining hard, then its not raining": "MP:If Mary was at the wedding, then Sue was at the wedding.AS:If the match is struck, then it will light.p q, p qMary was at the wedding.p q (p r) q If the match is struck and has been soaked in water, Sue was at the wedding.then it will light. MT:If Mary was at the wedding, then Sue was at the wedding.CMP:If the Warriors dont win, thenp q, q pSue was not at the wedding. Mary was not at the wedding.p (q r), pif the Lakers dont win, the Celtics will.",
  "Invalid InferencesControv. Modal": "AC:If Mary was at the wedding, then Sue was at the wedding.DSmu:Either Fido is inside or Fido must be in the garden.p q, q pSue was at the wedding.p 2q, 2q pIts not the case that Fido must be in the garden. Mary was at the wedding Fido is inside. CONV:If Mary was at the wedding, then Sue was at the wedding.DSmi:Either Fido is inside or Fido must be in the garden.p q q p If Sue was at the wedding, then Mary was at the wedding.p 2q, q pFido might not be in the garden. Fido is inside. DA:If Mary was at the wedding, then Sue was at the wedding.MTmi:If Mary was at the wedding, then Sue must have been there.p q, p qMary was not at the wedding.p 2q, p pSue might not have been there. Sue was not at the wedding. Mary was not at the wedding. INV:If Mary was at the wedding, then Sue was at the wedding.MTmu:If Mary was at the wedding, then Sue must have been there.p q pq If Mary was not at the wedding, then Sue was not at the wedding.p 2q, 2q pIts not the case that Sue must have been at the wedding. Mary was not at the wedding. MuDistOr:The envelope must have been upstairs or under a bed.WSFC:John might clean his room or he might go to the lecture.2(pq)2p2q The envelope must have been upstairs or it must have been under a bed.p q p q John might clean his room and he might go to the lecture. MiAg:The envelope might be upstairs and the envelope might be under a bed.NSFC:John might clean his room or go to the lecture.pq (pq) The envelope might be upstairs under a bed.(p q) p q John might clean his room and John might go to the lecture. : Key inferences tested; p, q stand for modal/conditional-free propositions, for not, for or, for if. . . then, for might, and 2 for must. 1, . . . , n is the inference from the list of premises 1, . . . , n to the conclusion .Controv. stands for controversial inferences. summarizes success on all and only the uncontroversial inferences. overall correlation for all inferences in is.85. While we could run more instances for all in-ference patterns, limited only by time and cost, thehigh correlations between responses to sensical andnonsensical instances suggest that we already haveenough instances to see how an LLM responds tothe logical form in question, not just to contingentfeatures of particular instances of that form.We also tested to what extent our results aresensitive to the choice of the word infer in ourprompts, as opposed to other phrases we considerequivalent in this context: deduce, conclude,logically infer, logically deduce, and logicallyconclude. Could it be, e.g., that models mightcommit fewer conditional fallacies if we promptthem with one of these other phrases? We ranthe instances of the AC inference (see ) us-ing each of the mentioned substitutes for infer.The results are qualitatively the same as for in-fer, and the correlation coefficients between theyes-frequencies for infer and for each of the sub-stitutes are over .9. Thus, which of the phrasesabove we use apparently makes little difference.2 2By contrast, there was a bigger difference when we explic-itly asked LLMs, Is this form of argument logically valid?(we call this the v variant of each question). This decreasedthe rate at which some LLMs accepted fallacious inferences,perhaps due to the presence of texts on formal logic in the",
  "Results": "Key inferences we tested are summarized in Ta-ble 1. To establish a baseline for performance, wetested a variety of inferences whose (in)validity isuncontroversial (as labeled in the left-hand side ofthe table): DS, MP, MT, AC, DA, and x, o, andox variants thereof, as well as INV, CONV, MiN,NMu, MuDistOr, MiAg, and x variants thereof.The aggregate performance of our models on theseinferences is reported in for the temperature0 settings, in addition to at the beginningof the paper. We see that the results significantlyvary across models, and performance roughly cor-relates with model size. No model achieves above90% accuracy on this set of tasks. Moreover, Llama3.1 405B and 70B are the only open-weights mod-els that achieve 80%+ accuracy, with the formerbeing the best performer overall. The GPT-4 modelfamily show generally strong performance.We observe that the models perform similarly inthe few-shot setting compared to the zero-shot set-ting (paired t-test not statistically significant). Thisis presumably because the few-shot examples we training data. However, it also decreased the rate at whichsome LLMs accepted valid inferences (see the GitHub reposi-tory). In any case, the qualitative observations we make stillapply with this alternative formulation of the questions.",
  "Model0-shotFew-shot0-shot Cot(T = 0)Accuracy %DeltaDelta": "Llama 3.1 Instruct 405B89.500.171.00GPT-4 Turbo (2024-04-09)87.172.004.33Claude 3.5 Sonnet85.332.832.33GPT-4 Turbo (1106)84.671.331.67GPT-4 (0613)83.502.505.17Llama 3.1 Instruct 70B81.333.335.50Gemini 1.5 Pro81.17-4.837.67GPT-4 (0314)80.335.337.50GPT-4o (2024-05-13)79.670.509.00GPT-4o mini75.338.1713.50Claude 3 Opus74.006.0015.83Gemini 1.5 Flash72.83-2.3313.50Mistral Large 272.1710.6712.50Mixtral 8x7B71.17-7.830.17Llama 3 Instruct 70B70.335.3311.00Claude 3 Sonnet68.172.1712.00Claude 3 Haiku65.50-3.6711.00Mixtral 8x22B65.1712.5021.50Gemma 2 27B64.671.3316.50Llama 3 Instruct 8B63.83-4.008.17Code Llama 34B58.67-7.832.67GPT-3.5 Turbo (0125)57.332.3317.00Llama 2 Chat 7B55.00-1.003.50GPT-3.5 Turbo (1106)54.331.1714.67Llama 3.1 Instruct 8B53.678.0019.50Code Llama 7B50.334.5012.67Llama 2 Chat 13B49.677.839.00Mistral 7B49.170.1721.17Code Llama 13B45.33-8.008.17",
  ": Model performance on uncontroversial infer-ences with different prompting setups": "use (see Appendix B) are about conjunctions anddisjunctions, not directly about conditionals andmodals. The motivation of the few-shot setting isto make the logical reasoning task clear in context.The results suggest that models understand the taskin the zero-shot setting, yet they are not capableof consistently recognizing valid and invalid infer-ence patterns. On the other hand, zero-shot chain-of-thought (CoT) prompting does dramatically im-prove performance (paired t-test statistically signif-icant): the best models all achieve accuracy near90%, while still systematically making some mis-takes with modal or conditionals. These results con-tribute to the cumulative evidence that CoT elicitsand improves reasoning in LLMs (Wei et al., 2022;Kojima et al., 2022; Suzgun et al., 2022), whilepointing to lacunae that persist even with CoT. Theperformance trends of the temperature 1 settingsare similar, and we include figures for those, andfor CoT prompting, in Appendix C. Next, we sum-marize some noteworthy findings based on specificinferences from .",
  "Divergences from the material analysis": "Under the material analysis of conditionals dis-cussed in , CT would be valid. However,CT is not valid according to the modal analysis ofconditionals mentioned in , and indeed,there are well-known intuitive counterexamples to CT (Stalnaker, 1968): for instance, the inferencefrom If its raining, its not raining hard to Ifits raining hard, its not raining, is obviously notvalid, but this inference would be valid if CT were(given very weak background assumptions).Another inference pattern that is valid accordingto the material analysis is AS. But there are againwell-known counterexamples to AS: from If thematch is struck, it will light, we cannot infer Ifthe match is struck and it has been soaked in water,it will light (Stalnaker, 1968).The LLMs we tested largely agree with humanjudgment in rejecting CT and AS (see AppendicesC.1.10-C.1.11). This underscores the importanceof not assuming the material analysis when eval-uating LLMs, since if we did, we would wronglyascribe mistakes to them in this case. And it showsthat LLMs, like ordinary human speakers, do not in-terpret the natural language conditional if. . . thenas a material conditional.",
  "Inconsistency and overgeneralization": "We tested a number of inference patterns that in-volve the interaction of modals with conditionalsor disjunction. This is an especially interestingdomain, since work in philosophy and logic hasshown that substituting a modal sentence for a non-modal one can change a pattern from being appar-ently valid to apparently invalid.For instance, p q, q uncontroversially entailsp (DS) provided p and q are Boolean (that is, do notthemselves contain modals or conditionals). But itis not clear that p2q, together with 2q, entails p(DSmu; see Klinedinst and Rothschild (2012)). Forinstance, if we know that Fido is either inside oroutside, but dont know where he is, then it seemswe know (i) Fido is either inside or else must beoutside; and (ii) its not true that Fido must beoutside (since he might be inside). But we need notconclude that Fido is inside, contrary to DSmu.Similarly, we can uncontroversially concludep from p q together with q, when p and qare Boolean (MT). But it is not so clear that theinference from p 2q and 2q to p (MTmu) isvalid (Yalcin, 2012). It seems that we can know (i)if Fido is not inside, he must be outside and (ii) itsnot true that Fido must be outside (since he mightbe inside), without being compelled to concludethat Fido is inside, contrary to MTmu.For a final case, McGee (1985) pointed out that,while the inference from p q, p to q is obviouslyvalid when p, q are Boolean (MP), the inference from p (q r), p to q r (CMP) appearsinvalid. Suppose that the Lakers, Warriors, andCeltics are the only finalists in a tournament, soits certain that (i) if the Warriors dont win, thenif the Lakers dont win, the Celtics will. Supposemoreover that (ii) the Warriors are very likely notto win, because the Lakers are way ahead. But nowsuppose further that the Celtics are heavy under-dogs, so that if the Lakers dont win, the Warriorsprobably will. We then cant conclude from (i) and(ii) that its likely that, if the Lakers dont win, theCeltics will. But this would follow if CMP werevalid, since valid inference preserves probability.These cases are of special interest to test onLLMs since human subjects can immediately rec-ognize that while DS, MT, and MP are valid forBoolean sentences, they apparently fail for modal/-conditional substitution instances of these patternslike DSmu, MTmu, and CMP. That is, humans donot overgeneralize from the simple (Boolean) caseto the general case. It is thus interesting to ex-plore whether LLMs are human-like in this respector rather overgeneralize from simple to complexcasesespecially since these complex cases haveonly been discussed in a relatively small numberof philosophy and logic papers and are presumablysomewhat rare in naturalistic settings and hencepresumably not very frequent in training data.We found that, indeed, many LLMs do overgen-eralize: they do not agree with human judgmentsabout the invalidity of MTmu, DSmu, and CMP.Intriguingly, some models exhibit human-like judg-ments in rejecting MTmi, but at the same time theyaccept MTmu (). This is logically incon-sistent, since those models also accept that mightnot is logically equivalent to not must (MiN andNMu), 3 and MTmi and MTmu differ only by sub-stituting these equivalent phrases. This intriguingpattern suggests that LLMs may indeed overgener-alize from the validity of MT to judging MTmu tobe valid, while recognizing that MTmi (which isnot syntactically an instance of MT) is invalid.4",
  "We found similar patterns for DS, as shown in, where many models accepted DSmu but": "3In fact, the inconsistenty arises just using MiN. For givenMiN, the premises of MTmi entail the premises of MTmu, soone cannot reject the former and accept the latter.4Our examples were designed to elicit an epistemic readingof the modals in question. However, this is immaterial to ourlogical points, since even if the target LLM instead accessed adeontic reading, the judgments we report would remain jointlyinconsistent, as long as the LLMs interpretation does notchange across different instances of the modal in question. 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot MTmu example: From 'If Mary was at the wedding, then Suemust have been at the wedding' together with 'It's not thecase that Sue must have been at the wedding', can we infer 'Mary was not at the wedding'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot MTmi example: From 'If Mary was at the wedding, then Sue must have been at the wedding' together with 'Sue might nothave been at the wedding', can we infer 'Mary was not at the wedding'?",
  ": Zero-shot responses for MTmu (above) andMTmi (below) show inconsistency for many models.All error bars, including in subsequent figures, represent95% confidence intervals": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot DSmu example: From 'Either Fido is inside or Fido must be in the garden' together with 'It's not the case that Fido must be in the garden', can we infer 'Fido is inside'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot DSmi example: From 'Either Fido is inside or Fido must be inthe garden' together with 'Fido might not be in the garden', can we infer 'Fido is inside'?",
  ": Responses for CMP, zero-shot (above) andchain-of-thought (below); LLMs were asked whetherthe inference preserved likelihood, i.e., if q r mustbe likely when p (q r) is certain and p is likely": "this area, accepting DSmu and MiN while reject-ing DSmi. This inconsistency was displayed forboth zero-shot and chain-of-thought prompts. Wewondered whether this incoherence could be dueto the fact that the inconsistent triad of responseswas given in response to different prompts in dif-ferent context windows, so we probed more deeply,asking the leading models about each of the three inference patterns within the same context window,but their responses remained logically inconsistentmuch of the time; see for a summary.Also strikingly, the models that performed bestoverall on other inferences uniformly judge CMP tobe valid with zero-shot prompts, contrary to humanjudgment.Performance improved substantiallywith CoT prompts, but most of the best-performingmodels still accept CMP at surprisingly high rates(), pointing to a stark contrast between re-flective human judgment and state of the art LLMperformance. Along with our findings about MTand DS, this supports the hypothesis that LLMsmay overgeneralize from the validity of inferencepatterns for Boolean sentences to the unrestrictedvalidity of those patterns for all substitutions.",
  "Modal fallacies and free choice": "We also found intriguing patterns involving LLMsbehavior with purely modal inferences, shown inAppendix C.1.17-C.1.20. While, as noted, the mod-els were generally able to correctly reason aboutduality (inferring not must from might not, andvice versa), they systematically made basic errorsin modal reasoning in other cases. Strikingly, al-most all models, including those that performedbest overall, accepted both MuDistOr and MiAgas valid, despite these being clearly invalid. (ForMuDistOr, asssume the keys must be upstairs ordownstairs; it doesnt follow that either they mustbe upstairs or they must be downstairs. After all,they might not be upstairs, and they might not bedownstairs. For MiAg, assume the keys might beupstairs and might be downstairs; it doesnt followthat they might be both upstairs and downstairs.)The situation with WSFC and NSFC is also inter-esting. There is controversy in the semantics litera-ture about the status of these patterns, which strikemany speakers as valid but are not valid on stan-dard modal semantics (Kamp, 1973). Intriguingly,many models accepted NSFC but rejected WSFC.In fact, this conforms to one position in the litera-ture which maintains that, indeed, NSFC but notWSFC is valid (Simons, 2005; Meyer and Sauer-land, 2017; Fusco, 2019). However, this threatensinconsistency, since most models also accept the(standardly valid) equivalence of (p q) withp q (see the GitHub repository).",
  "Correct Response Percentage": "GSM8K score Temperature: 0, Condition: zero-shotPerformance vs. GSM8K scoreModel Claude 3 HaikuClaude 3 OpusClaude 3 SonnetClaude 3.5 SonnetCode Llama 34BGPT-4 (0613)GPT-4 Turbo (1106)GPT-4 Turbo (2024-04-09)GPT-4o (2024-05-13)Gemini 1.5 FlashGemini 1.5 ProGemma 2 27BLlama 2 Chat 13BLlama 2 Chat 7BLlama 3 Instruct 70BLlama 3 Instruct 8BLlama 3.1 Instruct 405BLlama 3.1 Instruct 70BLlama 3.1 Instruct 8BMistral 7BMistral Large 2Mixtral 8x22BMixtral 8x7B",
  ": Correlations of our evaluation results (zero-shot) vs. LMSYS Elo ratings, MMLU scores, and GSM8kscores. The correlations are 0.81, 0.85, and 0.75, respectively. All p-values are less than 0.01": "compare the models performance on our bench-mark (uncontroversial inferences) to that of Chat-bot Arena (general assistance, Chiang et al., 2024),MMLU (domain knowledge, Hendrycks et al.,2020), and GSM8K (math reasoning, Cobbe et al.,2021), all of which are popular benchmarks to as-sess LLM capabilities. We show that our resultsare highly correlated with the results of each of thethree in . The Arena Elo ratings come fromLMSYS directly.5 The MMLU and GSM8k scoresare obtained from the HELM leaderboard (Lianget al., 2022).6 The high correlations support the hy-pothesis that logical reasoning abilities are relatedto and predictive of not only mathematical reason-ing abilities but also domain-general capabilities. Itwould be interesting to investigate the causal con-nections: whether improving logical reasoning alsoimproves some general reasoning abilities.",
  "Discussion": "On the one hand, our results mirror what we havelearned in the field over the past few years: largermodels are likely to perform better at reasoning,and chain-of-thought prompting often but does notalways help. On the other hand, we have iden-tified inconsistent and counterintuitive reasoningbehaviors from even the best models with and with-out chain-of-thought. The inference patterns thatgive rise to those behaviors reflect state-of-the-artresearch in philosophy and logic, which by their na-ture means they are less present in the training andfine-tuning data of LLMs (though most likely notabsent). This is suggestive of sources from whichwe can acquire more out-of-distribution evaluationdata to test LLMs, and it illustrates that LLMsjudgments may not be reliable when they encounter novel inference patterns, even if those are naturaland intuitive for humans. Lastly, we note that aneurosymbolic, semantic-parsing approach to logi-cal reasoning, as in Olausson et al. 2023, will notautomatically handle the tasks we present here. Toour knowledge, theorem provers do not natively im-plement the nuanced meaning representations wediscussed in this paper, and in some cases it is stillcontroversial what the correct semantics for certainmodal operators are. Thus, working towards anautomated natural language reasoning system thatsensibly solves our tasks is a challenge regardlessof the models and approaches.",
  "Conclusion": "We have drawn on philosophical, logical, and lin-guistic analyses of inference to explore the extent towhich current LLMs are accurate logical reasonersabout conditionals and modals. We hope this willbe the start of a new strand of research on LLMs.There are many natural follow-ups. First, it wouldbe interesting to compare the behavior of LLMswith experimental human subjects on all the infer-ences we tested. We have reported expert humanjudgments from the literature, but the judgments ofexperimental subjects might exhibit mistakes inter-estingly similar to or different from those we find inLLMs. Second, there are many more inference pat-terns to explore, involving modals, conditionals, aswell as many other logical constructions, like quan-tifiers, attitude predicates, and degree constructions.Third, modal and conditional reasoning is also con-nected to probabilistic reasoning, causal models,and mental simulations, and hence could provideanother perspective for studying these in LLMs andhumans. More generally, we hope that there willbe more work studying LLMs using philosophi-cal, linguistic, and logical insights into the buildingblocks of reasoning and meaning.",
  "Limitations": "In this paper, we have focused on studying to whatextent LLMs understand logical inferences withconditionals and modals. The conditional connec-tive and must and might operators are the target,while we do not systematically study other impor-tant logical operators such as and and or, orquantifiers such as some and all. Even in themodal domain, operators like probably and cer-tainly also deserve careful analysis. In particular,the interactions of many of these different kinds ofoperators could lead to interesting inference pat-terns, which would be worthy of future study. Ad-ditionally, we employ simple syntactical construc-tions to create the evaluation data. While this isnatural for testing logical inference, the modelsperformance on an inference pattern may not gen-eralize when it is made of more complex phrases.Lastly, our dataset is in English, and the modelslogical inference abilities may differ by language.We hope future work could study the multilingualaspect of logical inference as well.",
  "Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind": "Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020.Language models are few-shot learners.In Ad-vances in Neural Information Processing Systems,volume 33, pages 18771901. Curran Associates,Inc. Sbastien Bubeck, Varun Chandrasekaran, Ronen El-dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-berg, et al. 2023. Sparks of Artificial General In-telligence: Early experiments with GPT-4. arXivpreprint arXiv:2303.12712.",
  "Meiqi Chen, Yubo Ma, Kaitao Song, Yixin Cao, YanZhang, and Dongsheng Li. 2023. Learning to teachlarge language models logical reasoning.arXivpreprint arXiv:2310.09158": "Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anasta-sios Nikolas Angelopoulos, Tianle Li, Dacheng Li,Hao Zhang, Banghua Zhu, Michael Jordan, Joseph EGonzalez, et al. 2024. Chatbot arena: An open plat-form for evaluating llms by human preference. arXivpreprint arXiv:2403.04132. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,Mark Chen, Heewoo Jun, Lukasz Kaiser, MatthiasPlappert, Jerry Tworek, Jacob Hilton, ReiichiroNakano, et al. 2021. Training verifiers to solve mathword problems. arXiv preprint arXiv:2110.14168. Cleo Condoravdi, Dick Crouch, Valeria de Paiva, Rein-hard Stolle, and Daniel G Bobrow. 2003. Entailment,intensionality and text understanding. In Proceedingsof the HLT-NAACL 2003 Workshop on Text Meaning,pages 3845. Antonia Creswell, Murray Shanahan, and Irina Higgins.2023. Selection-inference: Exploiting large languagemodels for interpretable logical reasoning. In TheEleventh International Conference on Learning Rep-resentations.",
  "Gemma Team. 2024. Gemma 2: Improving open lan-guage models at a practical size": "Allan Gibbard and William L Harper. 1981. Counterfac-tuals and two kinds of expected utility. In William L.Harper, Robert Stalnaker, and Glenn Pearce, editors,Ifs: Conditionals, Beliefs, Decision, Chance, andTime, pages 153192. D. Reidel Publishing Com-pany. Simeng Han, Hailey Schoelkopf, Yilun Zhao, ZhentingQi, Martin Riddell, Luke Benson, Lucy Sun, Eka-terina Zubova, Yujie Qiao, Matthew Burtell, et al.2022. Folio: Natural language reasoning with first-order logic. arXiv preprint arXiv:2209.00840.",
  "Jie Huang and Kevin Chen-Chuan Chang. 2022. To-wards reasoning in large language models: A survey.arXiv preprint arXiv:2212.10403": "Jie Huang and Kevin Chen-Chuan Chang. 2023. To-wards reasoning in large language models: A survey.In Findings of the Association for ComputationalLinguistics: ACL 2023, pages 10491065, Toronto,Canada. Association for Computational Linguistics. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, et al. 2023. Mistral7b. arXiv preprint arXiv:2310.06825. Albert Q Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, Chris Bam-ford, Devendra Singh Chaplot, Diego de las Casas,Emma Bou Hanna, Florian Bressand, et al. 2024.Mixtral of experts. arXiv preprint arXiv:2401.04088.",
  "David Lewis. 1973b. Counterfactuals. Basil Blackwell,Oxford": "Percy Liang, Rishi Bommasani, Tony Lee, DimitrisTsipras, Dilara Soylu, Michihiro Yasunaga, YianZhang, Deepak Narayanan, Yuhuai Wu, Ananya Ku-mar, et al. 2022. Holistic evaluation of languagemodels. arXiv preprint arXiv:2211.09110. Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang,Yile Wang, and Yue Zhang. 2021. Logiqa: a chal-lenge dataset for machine reading comprehensionwith logical reasoning. In Proceedings of the Twenty-Ninth International Joint Conference on ArtificialIntelligence, IJCAI20.",
  "Alfred Tarski. 1936. ber den Begriff der logischen Fol-gerung. Aces du Congrs International de Philoso-phie Scientifique, fasc. 7:111": "Jidong Tian, Yitian Li, Wenqing Chen, Liqiang Xiao,Hao He, and Yaohui Jin. 2021. Diagnosing the first-order logical reasoning ability through LogicNLI.In Proceedings of the 2021 Conference on Empiri-cal Methods in Natural Language Processing, pages37383747, Online and Punta Cana, Dominican Re-public. Association for Computational Linguistics. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023.Llama 2:Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288. Yuxuan Wan, Wenxuan Wang, Yiliu Yang, YouliangYuan, Jen-tse Huang, Pinjia He, Wenxiang Jiao, andMichael R Lyu. 2024. A & b== b & a: Triggeringlogical reasoning failures in large language models.arXiv preprint arXiv:2401.00757.",
  "Albert Webson, Alyssa Marie Loo, Qinan Yu, and ElliePavlick. 2023. Are language models worse than hu-mans at following prompts? its complicated. arXivpreprint arXiv:2301.07085": "Jason Wei, Xuezhi Wang, Dale Schuurmans, MaartenBosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,and Denny Zhou. 2022. Chain-of-thought prompt-ing elicits reasoning in large language models. InAdvances in Neural Information Processing Systems,volume 35, pages 2482424837. Curran Associates,Inc. Adina Williams, Nikita Nangia, and Samuel Bowman.2018. A broad-coverage challenge corpus for sen-tence understanding through inference. In Proceed-ings of the 2018 Conference of the North AmericanChapter of the Association for Computational Lin-guistics: Human Language Technologies, Volume1 (Long Papers), pages 11121122, New Orleans,Louisiana. Association for Computational Linguis-tics. Fangzhi Xu, Qika Lin, Jiawei Han, Tianzhe Zhao, JunLiu, and Erik Cambria. 2023. Are large languagemodels really good logical reasoners? a comprehen-sive evaluation from deductive, inductive and abduc-tive views. arXiv preprint arXiv:2306.09841.",
  "Seth Yalcin. 2012. A counterexample to modus tollens.Journal of Philosophical Logic, 41:10011024": "Xi Ye, Qiaochu Chen, Isil Dillig, and Greg Durrett.2023. Satlm: Satisfiability-aided language modelsusing declarative prompting. In Advances in NeuralInformation Processing Systems, volume 36, pages4554845580. Curran Associates, Inc. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,Xiaolei Wang, Yupeng Hou, Yingqian Min, BeichenZhang, Junjie Zhang, Zican Dong, et al. 2023. Asurvey of large language models.arXiv preprintarXiv:2303.18223.",
  "ALanguage models used": "In this section, we cite all the LLMs used to con-duct our experiments: the GPT-4 model family(OpenAI, 2023); the GPT-3.5 model family (Brownet al., 2020);7 the Claude 3 model family8 andClaude 3.5 Sonnet;9 Gemini 1.5 Pro and Flash(Reid et al., 2024); Gemma 2 27B (Gemma Team,2024); the Llama 3 model family (Dubey et al.,2024); Mistral Large 2;10 Mixtral 8x7B (Jiang et al.,2024) and Mistral 7B (Jiang et al., 2023); Llama2 Chat 7B and 13B (Touvron et al., 2023); CodeLlama 7B, 13B, and 34B (Roziere et al., 2023).",
  "BPrompts used in the experiments": "We use the following prompts to run the experi-ments reported in this work. The prompts are thesame for all models, except that for some smallmodels (e.g., Llama 2 7B and Code Llama 7B), wehad to modify the chain-of-thought prompt withextra reminders to answer only after first thinkingstep by step. Each prompt is shown with a concreteexample of an inference pattern.",
  "C.1.1Disjunctive Syllogism (DS)": "0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot DS example: From 'Either Fido is inside or Fido is inthe garden' together with 'Fido is not in the garden', can we infer 'Fido is inside'? 0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot DS example: From 'Either Fido is inside or Fido is inthe garden' together with 'Fido is not in the garden', can we infer 'Fido is inside'?",
  "C.1.2Modus Ponens (MP)": "0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot MP example: From 'If Mary was at the wedding, then Sue was at the wedding' together with 'Mary was at the wedding', can we infer 'Sue was at the wedding'? 0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot MP example: From 'If Mary was at the wedding, then Sue was at the wedding' together with 'Mary was at the wedding', can we infer 'Sue was at the wedding'?",
  "C.1.3Modus Tollens (MT)": "0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot MT example: From 'If Mary was at the wedding, then Sue was at the wedding' together with 'Sue was not at thewedding', can we infer 'Mary was not at the wedding'? 0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot MT example: From 'If Mary was at the wedding, then Sue was at the wedding' together with 'Sue was not at thewedding', can we infer 'Mary was not at the wedding'?",
  "C.1.4Affirming the Consequent (AC)": "0%25%50%75%100% Correct answer ('no') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot AC example: From 'If Mary was at the wedding, then Sue was at the wedding' together with 'Sue was at thewedding', can we infer 'Mary was at the wedding'? 0%25%50%75%100% Correct answer ('no') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot AC example: From 'If Mary was at the wedding, then Sue was at the wedding' together with 'Sue was at thewedding', can we infer 'Mary was at the wedding'?",
  "C.1.5Conversion CONV)": "0%25%50%75%100% Correct answer ('no') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot CONV example: From 'If Mary was at the wedding, then Sue was at the wedding', can we infer 'If Sue was at the wedding, then Mary was at the wedding'? 0%25%50%75%100% Correct answer ('no') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot CONV example: From 'If Mary was at the wedding, then Sue was at the wedding', can we infer 'If Sue was at the wedding, then Mary was at the wedding'?",
  "C.1.6Denying the Antecedent (DA)": "0%25%50%75%100% Correct answer ('no') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot DA example: From 'If Mary was at the wedding, then Suewas at the wedding' together with 'Mary was not at the wedding', can we infer 'Sue was not at the wedding'? 0%25%50%75%100% Correct answer ('no') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot DA example: From 'If Mary was at the wedding, then Suewas at the wedding' together with 'Mary was not at the wedding', can we infer 'Sue was not at the wedding'?",
  "C.1.7Inversion (INV)": "0%25%50%75%100% Correct answer ('no') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot INV example: From 'If Mary was at the wedding, then Sue was at the wedding', can we infer 'If Mary was not at the wedding, then Sue was not at the wedding'? 0%25%50%75%100% Correct answer ('no') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot INV example: From 'If Mary was at the wedding, then Sue was at the wedding', can we infer 'If Mary was not at the wedding, then Sue was not at the wedding'?",
  "C.1.8Might Not (MiN)": "0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot MiN example: From 'Mary might not have been at the wedding', can we infer 'It's not the case that Mary must have been at the wedding'? 0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot MiN example: From 'Mary might not have been at the wedding', can we infer 'It's not the case that Mary must have been at the wedding'?",
  "C.1.9Not Must (NMu)": "0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 0, Condition: zero-shot NMu example: From 'It's not the case that Mary must have been at the wedding', can we infer 'Mary might not have been at the wedding'? 0%25%50%75%100% Correct answer ('yes') frequency Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B Temperature: 1, Condition: zero-shot NMu example: From 'It's not the case that Mary must have been at the wedding', can we infer 'Mary might not have been at the wedding'?",
  "C.1.10Antecedent Strengthening (AS)In the graphs below, the d in ASd indicates de-viant instances, designed to bring out the invalidityof antecedent strengthening as in Stalnaker 1968": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot ASd example: From 'If the match is struck, then it will light', can we infer 'If the match is struck and it has been soaked in water, then it will light'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot ASd example: From 'If the match is struck, then it will light', can we infer 'If the match is struck and it has been soaked in water, then it will light'? C.1.11Contraposition (CT)In the graphs below, the n in CTnd indicates thatwe use a version of contraposition with negationin the premise (p q q p), while the dagain indicates deviant instances, designed to bringout the invalidity of CT as in Stalnaker 1968. 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot CTnd example: From 'If it's raining, then it's not raining hard', can we infer 'If it's raining hard, then it's not raining'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot CTnd example: From 'If it's raining, then it's not raining hard', can we infer 'If it's raining hard, then it's not raining'?",
  "C.1.12DS with must (DSmu)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot DSmu example: From 'Either Fido is inside or Fido must be in the garden' together with 'It's not the case that Fido must be in the garden', can we infer 'Fido is inside'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot DSmu example: From 'Either Fido is inside or Fido must be in the garden' together with 'It's not the case that Fido must be in the garden', can we infer 'Fido is inside'?",
  "C.1.13DS with might (DSmi)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot DSmi example: From 'Either Fido is inside or Fido must be inthe garden' together with 'Fido might not be in the garden', can we infer 'Fido is inside'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot DSmi example: From 'Either Fido is inside or Fido must be inthe garden' together with 'Fido might not be in the garden', can we infer 'Fido is inside'?",
  "C.1.14MT with must (MTmu)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot MTmu example: From 'If Mary was at the wedding, then Suemust have been at the wedding' together with 'It's not thecase that Sue must have been at the wedding', can we infer 'Mary was not at the wedding'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot MTmu example: From 'If Mary was at the wedding, then Suemust have been at the wedding' together with 'It's not thecase that Sue must have been at the wedding', can we infer 'Mary was not at the wedding'?",
  "C.1.15MT with might (MTmi)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot MTmi example: From 'If Mary was at the wedding, then Sue must have been at the wedding' together with 'Sue might nothave been at the wedding', can we infer 'Mary was not at the wedding'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot MTmi example: From 'If Mary was at the wedding, then Sue must have been at the wedding' together with 'Sue might nothave been at the wedding', can we infer 'Mary was not at the wedding'?",
  "C.1.16Complex Modus Ponens (CMP)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot CMP example: Suppose that the Lakers, Warriors, and Celticshave the best odds to win the NBA championship. Based on expert projections, it is most likely the Lakers will win,followed closely by the Warriors, with the Celtics having much lower odds. These are the only top contenders, so if the Warriors don t win, then if the Lakers don t win, the Celtics will win. Moreover, it is most likely the Lakerswill win and hence that the Warriors won t win. Does itfollow that it is likely that, if the Lakers don t win, the Celtics will? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot CMP example: Suppose that the Lakers, Warriors, and Celticshave the best odds to win the NBA championship. Based on expert projections, it is most likely the Lakers will win,followed closely by the Warriors, with the Celtics having much lower odds. These are the only top contenders, so if the Warriors don t win, then if the Lakers don t win, the Celtics will win. Moreover, it is most likely the Lakerswill win and hence that the Warriors won t win. Does itfollow that it is likely that, if the Lakers don t win, the Celtics will?",
  "C.1.17Must distribution over or(MuDistOr)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot MuDistOr example: From 'The envelope must have been upstairs or under a bed', can we infer 'The envelope must have been upstairs or it must have been under a bed'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot MuDistOr example: From 'The envelope must have been upstairs or under a bed', can we infer 'The envelope must have been upstairs or it must have been under a bed'?",
  "C.1.18Might agglomeration (MiAg)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot MiAg example: From 'The envelope might be upstairs and theenvelope might be under a bed', can we infer 'The envelope might be upstairs under a bed'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot MiAg example: From 'The envelope might be upstairs and theenvelope might be under a bed', can we infer 'The envelope might be upstairs under a bed'?",
  "C.1.19Narrow-scope free choice (NSFC)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot NSFC example: From 'John might clean his room or go to the lecture', can we infer 'John might clean his room and John might go to the lecture'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot NSFC example: From 'John might clean his room or go to the lecture', can we infer 'John might clean his room and John might go to the lecture'?",
  "C.1.20Wide-scope free choice (WSFC)": "100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 0, Condition: zero-shot WSFC example: From 'John might clean his room or he might go to the lecture', can we infer 'John might clean his room and he might go to the lecture'? 100%50%050%100% Claude 3 HaikuClaude 3 Opus Claude 3 Sonnet Claude 3.5 Sonnet Code Llama 13BCode Llama 34B Code Llama 7B GPT-3.5 Turbo (0125) GPT-4 (0613) GPT-4 Turbo (2024-04-09) GPT-4o (2024-05-13) GPT-4o mini Gemini 1.5 Flash Gemini 1.5 ProGemma 2 27B Llama 2 Chat 13B Llama 2 Chat 7B Mistral 7B Llama 3 Instruct 70B Llama 3 Instruct 8B Llama 3.1 Instruct 405B Llama 3.1 Instruct 70B Llama 3.1 Instruct 8B Mistral Large 2 Mixtral 8x22B Mixtral 8x7B 'Yes' Frequency'No' Frequency Temperature: 1, Condition: zero-shot WSFC example: From 'John might clean his room or he might go to the lecture', can we infer 'John might clean his room and he might go to the lecture'?",
  "C.2Performance summaries": "0%25%50%75%100% Average correct answer frequency Llama 3.1 Instruct 405B GPT-4 Turbo (2024-04-09) Claude 3.5 SonnetGPT-4 Turbo (1106) GPT-4 (0613) Llama 3.1 Instruct 70B Gemini 1.5 Pro GPT-4 (0314) GPT-4o (2024-05-13) GPT-4o mini Claude 3 Opus Gemini 1.5 Flash Mistral Large 2 Mixtral 8x7B Llama 3 Instruct 70B Claude 3 Sonnet Claude 3 Haiku Mixtral 8x22BGemma 2 27B Llama 3 Instruct 8B Code Llama 34B GPT-3.5 Turbo (0125) Llama 2 Chat 7B GPT-3.5 Turbo (1106)Llama 3.1 Instruct 8B Code Llama 7B Llama 2 Chat 13B Mistral 7B Code Llama 13B Temperature: 0, Condition: zero-shot 89% 87% 85% 84% 83% 81% 81% 80% 79% 75% 74% 72% 72% 71% 70% 68% 65% 65% 64% 63% 58% 57% 55% 54% 53% 50% 49% 49% 45% Summary of performance on some simple inferences 0%25%50%75%100% Average correct answer frequency Llama 3.1 Instruct 405B GPT-4 Turbo (2024-04-09) Claude 3.5 Sonnet GPT-4 (0613) GPT-4 Turbo (1106) GPT-4 (0314) Llama 3.1 Instruct 70B GPT-4o mini Mistral Large 2 GPT-4o (2024-05-13) Claude 3 OpusMixtral 8x22BGemini 1.5 Pro Llama 3 Instruct 70B Gemini 1.5 FlashClaude 3 Sonnet Gemma 2 27B Mixtral 8x7B Claude 3 Haiku Llama 3.1 Instruct 8B Llama 3 Instruct 8B GPT-3.5 Turbo (0125) Llama 2 Chat 13B GPT-3.5 Turbo (1106) Code Llama 7B Llama 2 Chat 7BCode Llama 34B Mistral 7B Code Llama 13B Temperature: 0, Condition: few-shot 89% 89% 88% 86% 86% 85% 84% 83% 82% 80% 80% 77% 76% 75% 70% 70% 66% 63% 61% 61% 59% 59% 57% 55% 54% 54% 50% 49% 37% Summary of performance on some simple inferences 0%25%50%75%100% Average correct answer frequency GPT-4 Turbo (2024-04-09) Llama 3.1 Instruct 405B Claude 3 Opus GPT-4o mini Gemini 1.5 Pro GPT-4 (0613) GPT-4o (2024-05-13) GPT-4 (0314) Claude 3.5 Sonnet Llama 3.1 Instruct 70B Mixtral 8x22B GPT-4 Turbo (1106) Gemini 1.5 Flash Mistral Large 2 Llama 3 Instruct 70B Gemma 2 27B Claude 3 Sonnet Claude 3 Haiku GPT-3.5 Turbo (0125)Llama 3.1 Instruct 8B Llama 3 Instruct 8B Mixtral 8x7B Mistral 7B GPT-3.5 Turbo (1106) Code Llama 7B Code Llama 34B Llama 2 Chat 13B Llama 2 Chat 7BCode Llama 13B Temperature: 0, Condition: chain_of_thought 91% 90% 89% 88% 88% 88% 88% 87% 87% 86% 86% 86% 86% 84% 81% 81% 80% 76% 74% 73% 72% 71% 70% 69% 63% 61% 58% 58% 53% Summary of performance on some simple inferences",
  ": Summary of performance on the uncontrover-sial logical inference patterns under different conditionsand temperature 0": "0%25%50%75%100% Average correct answer frequency Llama 3.1 Instruct 405B GPT-4 Turbo (2024-04-09) Claude 3.5 SonnetGPT-4 Turbo (1106) GPT-4 (0613) Gemini 1.5 Pro GPT-4 (0314) Llama 3.1 Instruct 70B GPT-4o (2024-05-13) GPT-4o mini Claude 3 OpusMistral Large 2 Gemini 1.5 Flash Mixtral 8x7B Llama 3 Instruct 70B Claude 3 Sonnet Claude 3 HaikuGemma 2 27B Llama 3 Instruct 8B GPT-3.5 Turbo (0125)Llama 3.1 Instruct 8B Mixtral 8x22B Llama 2 Chat 7BCode Llama 34B GPT-3.5 Turbo (1106) Code Llama 7B Llama 2 Chat 13B Mistral 7B Code Llama 13B Temperature: 1, Condition: zero-shot 89% 86% 85% 84% 83% 81% 80% 80% 79% 74% 74% 73% 72% 71% 70% 67% 65% 64% 63% 57% 57% 55% 54% 54% 54% 50% 50% 49% 46% Summary of performance on some simple inferences 0%25%50%75%100% Average correct answer frequency Llama 3.1 Instruct 405B GPT-4 Turbo (2024-04-09) Claude 3.5 SonnetGPT-4 Turbo (1106) GPT-4 (0613)GPT-4 (0314) Llama 3.1 Instruct 70B Mistral Large 2 GPT-4o mini Claude 3 Opus GPT-4o (2024-05-13) Mixtral 8x22BGemini 1.5 Pro Llama 3 Instruct 70B Gemini 1.5 FlashClaude 3 Sonnet Gemma 2 27BClaude 3 Haiku Mixtral 8x7B Llama 3 Instruct 8B GPT-3.5 Turbo (0125)Llama 3.1 Instruct 8BGPT-3.5 Turbo (1106) Llama 2 Chat 13B Llama 2 Chat 7B Code Llama 7B Code Llama 34B Mistral 7B Code Llama 13B Temperature: 1, Condition: few-shot 89% 88% 88% 86% 86% 85% 83% 83% 83% 80% 80% 77% 76% 75% 70% 70% 65% 63% 63% 59% 58% 57% 56% 55% 52% 51% 51% 49% 45% Summary of performance on some simple inferences"
}