{
  "Abstract": "Amidst the rapid advancements in generativelanguage models, the investigation of howtraining data shapes the performance of GPTmodels is still emerging. This paper presentsGPTfluence, a novel approach that leveragesa featurized simulation to assess the impactof training examples on the training dynam-ics of GPT models. Our approach not onlytraces the influence of individual training in-stances on performance trajectories, such asloss and other key metrics, on targeted testpoints but also enables a comprehensive com-parison with existing methods across varioustraining scenarios in GPT models, ranging from14 million to 2.8 billion parameters, across arange of downstream tasks. Contrary to earliermethods that struggle with generalization tonew data, GPTfluence introduces a parameter-ized simulation of training dynamics, demon-strating robust generalization capabilities to un-seen training data. This adaptability is evidentacross both fine-tuning and instruction-tuningscenarios, spanning tasks in natural languageunderstanding and generation. We make ourcode and data publicly available at",
  "Introduction": "The advent of generative language models, par-ticularly the GPT series (Radford et al., 2019;Brown et al., 2020; Zhang et al., 2022), has markeda paradigm shift in natural language processing(NLP) (Touvron et al., 2023; Jiang et al., 2023),code generation (Lozhkov et al., 2024; Chai et al.,2023), visual and language understanding (Achiamet al., 2023; Team et al., 2023). These models haveredefined performance standards across an exten-sive range of tasks, igniting detailed investigationsinto the process of training dynamics and the in-tricate nature of learned representations. Despitethese strides, the specific influence of individual",
  "*Work done during QLs internship at Baidu": "training examples on the performance of GPT mod-els remains a significantly underexplored area. Thisoversight presents a critical challenge in optimiz-ing training processes, a challenge that grows intandem with the increasing complexity and scaleof these models.Current research has yet to focus comprehen-sively on the influence of training data on autore-gressive language models. Prior studies, such asthose utilizing the BERT (Park et al., 2023) or T5architecture (Guu et al., 2023), have predominantlyconcentrated on natural language understandingtasks, leaving a considerable void in the explorationof generative language models.Furthermore,themajorityofthisre-search (Pruthi et al., 2020; Guu et al., 2023;K and Sgaard, 2021; Koh and Liang, 2017;Yeh et al., 2018) has focused on test loss asthe primary metric of interest, neglecting othervital performance indicators.Metrics such asBLEU (Papineni et al., 2002) and ROUGE (Lin,2004) scores are crucial for a thorough evaluationof a models capabilities, particularly in the contextof generative language models where downstreamtask performance is paramount. Additionally, thechallenge of generalizabilityextending method-ologies to accommodate unseen datapersistsas a significant barrier (Guu et al., 2023). This isparticularly critical for models expected to adapt tothe dynamic and evolving trajectory of NLP tasks.In response to these gaps,we introduceGPTfluence, a novel framework designed to ex-tend the analysis of training data influence be-yond the limitations of existing methodologies andacross a broader spectrum of tasks. Employing afeaturized simulation approach, GPTfluence esti-mates the impact of individual training examples onthe performance of GPT models, covering both nat-ural language understanding and generation tasks.This expanded focus facilitates a comprehensiveunderstanding of model training dynamics, provid- ing insights into a wide array of evaluation metricsbeyond mere test loss.Extensive experiments on selected subsets fromFLAN datasets (Wei et al., 2022), across a varietyof tasks and GPT model variants (Biderman et al.,2023), ranging in size from 14 million to 2.8 billionparameters, validate the effectiveness and superi-ority of our approach. Notably, our method notonly sheds light on the training dynamics of GPTmodels but also demonstrates remarkable general-ization capabilities to unseen data. ContributionTo summarize, our contributionsare as follows: We introduce GPTfluence, a featurized simula-tion approach that significantly advances the anal-ysis of training data influence on GPT models.This approach not only enables a comprehensivecomparison with existing methodologies but alsomarks the first extensive foray into the extensiveinvestigation of training datas impact on the per-formance of GPT models across various scales.",
  "Task Definition": "Considering the data space Z, such as datasets uti-lized for instruction-tuning, we denote a trainingexample by z and a test example by z in Z. We em-ploy a model, specifically a GPT variant in our ex-periments, parameterized by weights Rp. Ourobjective is to forecast the models performanceon a target metric (, z) : Rp Z R, with amain focus in existing literature on predicting testset loss (Pruthi et al., 2020; Guu et al., 2023).Practically, this involves working with a se-quence of training batches c = (c1, c2, . . . , cT ),delineating a training curriculum. Here, ct symbol-izes the batch of training examples utilized at step t. The crux of our task is to ascertain the influence oftraining examples z on a test example of interest z,specifically in terms of a test metric score (, z),given the training curriculum c. This involves track-ing changes in performance trajectory as a functionof the curriculum c, with prior research predomi-nantly focused on test loss prediction, rather than abroader spectrum of performance metrics.",
  "Lt+1(z) Lt(z) tLt(zi), Lt(z) (1)": "where t represents the learning rate at step t, andLt() signifies the gradient of the loss functionwith respect to the model weights .It adopts an influence measurement that utilizescheckpoint ensembling, dubbed TracInCP. Thisapproach aggregates the influences calculated atpredefined intervals throughout the training, pro-viding a comprehensive view of the training datasimpact over time.",
  "Lt(z) = (ct)Lt1(z) + (ct)(3)": "Here, (ct) and (ct), the multiplicative and ad-ditive factors respectively, are determined using alinear model, with ct indicating the batch of ex-amples consumed at training step t. Although itoffers a data-driven simulator derived from trainingdynamics trajectories, its mapping from trainingdata indices to test data points constrains generaliz-ability to new, unseen data. While TracIn leverages the neural models first-order gradients and Simfluence employs a data-driven simulation approach, both primarily focuson predicting test loss. Our proposed method alignswith Simfluences direction but seeks to overcomeits limitations, extending our focus to encompass awider array of performance metrics beyond meretest loss prediction.",
  "Overview": "We present GPTfluence, a novel approach fortracking the impact of training examples on thetraining dynamics of GPT models using a featur-ized simulator. depicts the process ofGPTfluence, encompassing the collection of train-ing dynamics, the training of the simulator, andthe execution of the final simulation. Similar toGuu et al. (2023), our initial step involves gather-ing a comprehensive dataset of training dynamics,which captures both the training curriculum andvarious target metrics for test examples, extendingbeyond traditional loss metrics to include perfor-mance measures like BLEU and ROUGE scores.GPTfluence models these dynamics via an n-thorder Markov process, incorporating both multi-plicative and additive factors to reflect the influenceof training examples. At its core, the simulator usesa pre-trained encoder to attain the general repre-sentation of training and test examples, ensuringadaptability to new, unseen data. This is achievedby modeling the intricate interplay between exam-ples through the interactions within their condensedhidden vector representations. In its application, itcan autoregressively forecast the complete perfor-mance trajectory of a test example, starting fromits initial performance metrics and following thespecified training curriculum.The collection of training dynamics is pivotal forpredicting a test samples performance trajectorythroughout the training process. As outlined in2.1, a T time steps training run is characterized bya sequence of training batches c, each contributingto the models evolving parameters, t, throughgradient descent.To monitor the performance evolution of a par-ticular test example z, we record its metric scoresyt = (t, z) at every training step t, employinga variety of evaluation metrics beyond mere loss,such as BLEU and ROUGE. This comprehensive record, denoted as y = 1:T , tracks the test exam-ples performance across all T steps of training.From a broader dataset D, we sample K sub-sets D D for GPT model training, resulting inK distinct training runs. These runs yield a richdataset of training dynamics Drun, encapsulatingboth the training curricula and the sequential targetmetric scores for each test point z. This datasetis represented as Drun = {ck, yk}Kk=1.",
  "Featurized Simulation Approach": "In this work, we introduce a featurized simulationmethodology designed to capture the effects oftraining examples on GPT model training dynam-ics. This method is predicated on conceptualizingthe training process as a sequential, time-evolvingMarkov process, thereby enabling the simulation ofmetric trajectories across training iterations. Build-ing upon the foundational insights of Guu et al.(2023), our model extends the conventional first-order Markov assumption to an n-th order Markovprocess. This allows for the consideration of a testsample z, where its performance metric () atany given timestep t is influenced by its perfor-mance across the preceding n steps, encapsulatedas {t1, t2, , tn}.Our approach integrates both multiplicative andadditive components within the simulation. Theperformance trajectory of a test sample z is thusdelineated by a combination of these factors, for-mulated as follows:",
  "Predict the test metric of the next step": ": Overview of GPTfluence. Step 1: We sample training data to create curricula for training GPT modelsand compute the test metrics of test examples at each training step. All the training curricula and the ground-truthmetrics are referred to as GPTDynamics. Step 2: We train our featurized simulator on GPTDynamics, taking intoaccount training examples at current and previous steps with the test example as input and predicts the ground-truthmetric. Step 3: Given a new curriculum with the test example of interest, start from the test metric at the first step,the simulator simulates the test metric in the future training steps in an autoregressive manner.",
  "hzi = (zi),hz = (z),(6)": "where hzi and hz are the low-dimensional embed-dings of the training and test examples, respectively.To preserve the encoders semantic generalizability,we keep it frozen during the simulators training.The multiplicative and additive influence fac-tors are then derived by passing the embed-dings through the corresponding linear projections,which are subsequently integrated using a Frobe-nius product as follows:",
  "Bi = Whzij , UhzF(8)": "where W(j), U(j), W, U are learnable weights,, F represents the Frobenius inner product be-tween the hidden representations of the trainingand test examples, yielding a refined estimation ofthe multiplicative influence exerted by each train-ing example zi on the test examples performancetrajectory. Our approach offers a granular and com-prehensive analysis of training dynamics throughthis intricate data-driven simulation.To learn our featurized simulator , we optimize",
  "Connection to Previous Approaches": "Our approach offers a flexible framework that, un-der specific conditions, aligns with establishedmodels in the TDA literature. Specifically, whenthe focus narrows down to the overall influenceof per-step dynamics, our approach converges tothe datamodels (Ilyas et al., 2022; Engstrom et al.,2024). Moreover, in scenarios where the Markovorder n is set to 1 and the input encoder is config-ured to process sample indices, our method reducesto Simfluence (Guu et al., 2023).",
  ": Results of test loss estimation for instruction tuning. Results are averaged over 5 held-out test runs": "FLAN datasets along with task-specific instruc-tions as instruction tuning. Conversely, the termfine-tuning is reserved to describe the process ofindividually optimizing models on separate taskswithout the use of instructional prompts. Both in-struction tuning and fine-tuning processes are en-capsulated within our GPTDynamics dataset. Werefer to Appendix A.1 for detailed information. GPT BackboneWe employed Pythia (Bidermanet al., 2023), a model suite recently made avail-able to the public, as our foundational architecture.Within this suite, we selected five distinct mod-els based on their sizes, encompassing 14M, 70M,160M, 410M, 1B, and 2.8B, to ensure a broad rangeof computational capacities were represented.",
  "Test Loss Estimation": "Instruction Tuning presents a com-parison between our approach and traditionalTDA methods for instruction tuning. GPTfluencedemonstrated a distinct edge over Simfluence andother gradient-based TDA techniques across a setof five natural language understanding (NLU) andnatural language generation (NLG) tasks, as evi-denced by the MSE and MAE metrics for the entiretrajectory, alongside the Spearman correlation co-efficients at the final time step across various testsamples. Examples are shown in (a) and 2(b).Additionally, we observed that while the effective-ness of all evaluated TDA methods in predictingloss trajectories varied with changes in GPT sizes,GPTfluence maintained optimal performance, in-dependent of the GPT scale. Fine-tuningIn , it is evident that our ap-proach consistently outperforms Simfluence whenit comes to fine-tuning GPT models. On average,our method reduces the MSE and MAE across alltraining steps by 42% and 28%, respectively, whencompared to Simfluence. This implies that ourmethod is more robust and adaptable in simulatingtraining dynamics.",
  "Generalizing to Test Metric Estimation": "We have expanded the evaluation of our model be-yond the mere prediction of test loss, now includingvital measures such as ROUGE and BLEU scores.We have not reported the performance of TracInand Grad-Dot baselines due to its inability on suchmetric predictions. Instruction TuningAs for instruction tuning,our findings, displayed in , demonstratea superior performance of our method over Sim-fluence in predicting both BLEU and ROUGE-Lscores and for GPTs of varying sizes. Intuitively,We draw some qualitative examples in the (c)and 2(d). Notably, for BLEU simulation on theWMT-16 DE/EN task, as the size of GPT increases,all steps MSE of Simfluence increases, whereasour method maintains a more stable performance,even exhibiting slight improvements from 0.92 to0.93 in loss prediction accuracy at the final step.This suggests that our model is better equipped tomanage more challenging tasks and larger modelsizes, leveraging the pre-trained representationsand instance interactions. Fine-tuningOur methods superiority remainsevident in the fine-tuning scenario, as depicted in, underscoring the robustness of our feature-based simulation approach. Its worth noting thatthe margin by which GPTfluence outperforms Sim-fluence in BLEU metric simulation is not as pro-nounced in fine-tuning contexts as it is in instruc-tion tuning settings. This discrepancy is likely dueto the richer and more diverse data available in in-struction tuning, which accentuates Simfluencesrelative inefficiency, given its independent parame-ter learning for each training instance and a distinctsimulator for each test instance.",
  ": Results of test metric estimation on NLGdatasets for fine-tuning": "when dealing with large-sized GPTs. Therefore,we conduct experiments to choose training check-points at specific intervals to approximate the re-ality of the neighboring points with the trainingstate of that particular point. Then, we trained oursimulator on the approximate training dynamicsto find the balance between the cost of collectingtraining dynamics and the simulator performance. Results are shown in . Unless otherwisespecified, we instruction tuning the Pythia-410Mfor further analysis. In general, the performance ofour simulator deteriorates as the number of check-point intervals increases. This is manifested by arise in MSE and MAE at all steps and a drop inSpearmans when the checkpoint interval is large.However, even when the number of checkpoint in-tervals is equal to 10, which means that we willuse the training state of one point to approximatethe training state of the previous ten points and thetraining dynamics collection time will be shortenedby almost 90%, our method still has comparableprediction error at all steps and better Spearmancoefficient than Simfluence.",
  ": Illustration of loss and metric simulation on NLU and NLG tasks with different TDA methods forinstruction tuning. See the D for more examples": "Empirical Analysis of Markov Order Depen-dencyUsing the first-order Markov process topredict future states based on the prior step, poten-tially oversimplifies GPT training dynamics. There-fore, we consider the training dynamics as an n-thorder Markov process (n = 2, 3, 5, 10) and exper-iment on both language understanding (RTE) andgenerative (WebNLG) tasks. The result can be seen in . Overall, whenconsidering more preceding training information,the simulation error initially increases and de-creases for both datasets, as indicated by the all-steps MSE metric. It suggests that a high ordern might introduce noise, leading to a degradedsimulators performance. Moreover, the final-stepSpearmans shows a significant increase from0.746 to 0.785 for RTE with the increase of ordern, but not the same for WebNLG. We guess consid-ering more past training information could improvethe prediction accuracy for NLU tasks.",
  "types of pre-trained encoders: BERT 1 and Pythia 2": "with different sizes. Results are shown in . Ingeneral, BERTs feature representations producebetter simulation results than the Pythia encoder.This could be due to its ability to encode context in-formation in both directions. Interestingly, we alsofound that increasing the parameters of the Pythiaencoder does not always lead to better performanceof the performance simulator.",
  "Analysis": "Robustness across Varying Model SizesWeconducted experiments to validate how our sim-ulator handles the complexity of GPTs of differentsizes, ranging from 14M to 2.8B, specifically fo-cusing on instruction tuning scenarios. Results arepresented in . Our loss simulation experi-ments revealed that despite the inconsistent simula-tion performance trend with increasing GPT size,our featurized model consistently surpassed Sim-fluence. These findings demonstrate the superiorityof our model in effectively capturing and managingmodel complexity.",
  ": Analysis on the impact of n-th order Markovprocess on language understanding (RTE) and genera-tion (WebNLG) tasks, varying n from 1 to 10": "Unseen Data GeneralizationUnlike Simflu-ence, which restricts the parameters only in-dexed by seen samples of past training runs, ourGPTfluence can handle unseen samples via sam-ple parameterization. We conducted experimentson RTE and WebNLG tasks in fine-tuning scenar-ios to further verify the unseen data generalization.For a future training run, we experiment in threedifferent unseen data scenarios: 1) Examples inthe training curriculum are unseen; 2) Test exam-ples are unseen; 3) Both examples in training thecurriculum and test examples are unseen.We defer the results in in Appendix. BERTPythia0.160 0.165 0.170 0.175 0.180 0.185 0.190 0.195 0.200 All-steps MAE BERTPythia-160MPythia-410MPythia-1B BERTPythia0.60 0.65 0.70 0.75 0.80 0.85 0.90 Final-step Spearman's",
  ":Comparison of the loss simulation be-tween GPTfluence and Simfluence on instruction tun-ing Pythia model series, ranging from 14M to 2.8B": "Overall, GPTfluence can generalize to unseen data,which includes simulating loss and performancemetrics. Whats more, we find that GPTfluenceis better at generalizing to unseen training data tosimulate the impact of test samples that have beenseen in the past. To illustrate this more visually, weshow the effect of GPTfluences simulation of theunseen training data setting with loss and perfor-mance metrics, respectively. As shown in ,the generalization performance of GPTfluence ismostly satisfactory.",
  "Following previous studies (Yeh et al., 2018; Pruthiet al., 2020), we present a mislabeled data identifi-cation use case to evaluate our TDA-based method": "Experimental SetupWe employ the Pythia-410M model as our classifier and utilize a subsetof the SST-2 dataset. The methods compared in-clude the following: Random, where we bypassinfluence calculation and apply random shuffling3.TracIn-CP, which uses self-influence as the metricby computing the gradient dot-product between asample and itself. Similarly, GPTfluence calcu-lates the influence by simulating the multiplicativefactor on the sample itself. ResultsThe results are depicted in . Whenexamining the fraction of mislabelled data iden-tified, GPTfluence demonstrates comparable per-formance to random selection, albeit slightly un-derperforming compared to TracIn-CP. However,the marginal difference in mislabel detection is off-set by the notable improvement in test accuracyachieved with GPTfluence. Our method outper-forms both TracIn-CP and random selection, par-ticularly excelling in the early stages of mislabel",
  ": SST-2 Mislabelled Data Identification withGPTfluence, TracIn-CP and Random Selection": "detection, which is crucial when reviewing a smallfraction of data. In scenarios where precision is key,especially with limited data available for review,GPTfluence proves its efficacy.To simulate mislabeled data, we corrupted 40%of the training set by flipping the labels, resultingin an initial classification accuracy of 0.53. Wethen sequentially corrected mislabelled samples byinspecting fractions of the dataset ranked by ourinfluence metric, computed via the TDA method.After correcting the mislabels, we retrained the clas-sifier and reported the test accuracy on the cleaneddataset.",
  "Related Work": "Our methodology extends the frontier of TDA tech-niques, which are instrumental in understandingthe influence of individual training instances onmodel predictions. This body of work bifurcatesinto two main strands: gradient-based approxima-tion methods and simulation-based approaches. Gradient-Based Approximation MethodsThisstrand of research capitalizes on gradient informa-tion to infer the influence of training instances onmodel predictions, providing a quantifiable mea-sure of individual data points contributions (Kohand Liang, 2017; Yeh et al., 2018; K and Sgaard,2021). Influence Functions, a pioneering methodin this domain, leverages the mathematical frame-work of influence functions for estimating the im-pact of dataset perturbations on model predictions.Complementing this, TracIn (Pruthi et al., 2020)employs gradient-based approximations to tracethe influence of training data on test predictions.Similarly, Grad-Dot (Charpiat et al., 2019) usesgradient dot products to approximate the influenceof training examples. A contemporary work (Xiaet al., 2024) that adapts the TracIn frameworkfor models optimized with Adam. LESS incor-porates LoRA (Hu et al., 2021) and random projec- tion (Park et al., 2023) techniques to enhance dataselection processes. These methods primarily relyon gradients to quantify data influence, offeringtractable solutions with varying degrees of approx-imation accuracy. Simulation-Based ApproachesAn alternativeresearch vein adopts model-based simulations torepresent training dynamics (Ilyas et al., 2022; Guuet al., 2023). Simfluence (Guu et al., 2023) pio-neers the simulation-based category by learning alinear model that predicts the influence of trainingexamples through multiplicative and additive fac-tors, as detailed in 2. Recent efforts (Engstromet al., 2024) have focused on simulating the overallinfluence of training examples, aiming at predict-ing the cumulative influence of training data forrefined data selection.Ourcontributiondistinctlyadvancesthesimulation-based direction by forecasting theend-point influence and modeling the entiretrajectory of training dynamics using featurizedrepresentations. This approach provides a morein-depth understanding of training data influence,facilitating dynamic adjustments and insights intothe model training curricula.",
  "Conclusion and Future Work": "In this paper, we explore the data attribution analy-sis for GPT models through GPTfluence, a novelfeaturized simulator approach. This methodologynot only surpasses the predictive capabilities oftraditional test loss metrics but forecasts essentialtask performance metrics across a broad spectrumof GPT model sizes, ranging from 14M to 2.8Bparameters. Our comprehensive evaluations acrossdiverse downstream tasks and fine-tuning scenariossubstantiate the superior efficacy of our approach.In the future, extending this approach to other tasksand training regime presents a promising avenuefor future research.",
  "Ethical Consideration": "While our study focuses on predicting the influenceof training data on GPT models, we recognize thebroader ethical implications that our research mayentail, especially as it contributes to the advance-ment of large language models (LLMs) that areincreasingly integrated into societal functions. Data Use and PrivacyOur research utilizes pub-licly available datasets and respects privacy con-cerns by anonymizing any potentially identifiableinformation. We ensure that our data handling prac-tices comply with all relevant data protection regu-lations and ethical guidelines, safeguarding againstmisuse. Potential MisuseWe are cognizant of the poten-tial misuse of predictive models in manipulating orunfairly influencing AI systems. Our research aimsto contribute to the understanding and mitigationof such risks by providing tools to analyze and ad-just the influence of training data. We encouragethe application of our findings in ethical ways thatpromote fairness and transparency in AI. Broader ImpactThis study advances under-standing of data influence on LLMs, offering amethodological approach for detailed impact anal-ysis. This work not only enhances the interpretabil-ity and transparency of LLMs but also lays thegroundwork for more informed and ethical deci-sions in data curation and model training.",
  "Limitations": "This work introduces a novel feature-based ap-proach within the simulation-based framework forpredicting the influence of training data on GPTmodels. While our methodology represents a sig-nificant advancement in the field, it is not withoutits limitations, which we discuss below: Dependence on Extensive Training DynamicsA fundamental constraint of our approach is its re-liance on a comprehensive set of training dynamicsto train the simulator effectively. This requirement,while crucial for the accuracy of our predictions,necessitates considerable computational resourcesand time. The efficiency of data influence simu-lators remains an area ripe for further exploration,with the aim of reducing the computational over-head without compromising on performance. Limited Dataset ScopeOur experimental valida-tion is confined to a subset of the FLAN datasets,constrained by the logistical and computationalcosts associated with collecting a large-scale train-ing dynamics dataset. Despite this limitation, wehave conducted over 352 training experimentsacross six different GPT model sizes (ranging from14M to 2.8B parameters) to amass the GPTDynam-ics dataset. This dataset, which we are makingpublicly available, is a step towards mitigating thedata scarcity in this research area, yet the need formore expansive datasets encompassing a broaderrange of tasks and languages remains. Model Size ConstraintsThe high computationalcosts involved in executing multiple runs on largerlanguage models, such as those with 13B or even72B parameters, have limited the scale of the mod-els we could feasibly include in our study. Whileour findings are robust across the examined modelsizes, extending our analysis to larger models withhundreds of billions of parameters would likelyyield additional insights into the scalability andgeneralizability of our approach. Generalization to Other DomainsWhile ourstudy focuses on GPT models and a specific subsetof datasets, the generalizability of our approach toother model architectures and domains is not fullyexplored. Future work could extend our method-ology to different types of language models andbeyond, including vision and multimodal systems,to assess the applicability and adaptability of ourfeaturized simulation-based approach. Josh Achiam, Steven Adler, Sandhini Agarwal, LamaAhmad, Ilge Akkaya, Florencia Leoni Aleman,Diogo Almeida, Janko Altenschmidt, Sam Altman,Shyamal Anadkat, et al. 2023. Gpt-4 technical report.arXiv preprint arXiv:2303.08774. Stella Biderman, Hailey Schoelkopf, Quentin Anthony,Herbie Bradley, Kyle OBrien, Eric Hallahan, Mo-hammad Aflah Khan, Shivanshu Purohit, USVSN SaiPrashanth, Edward Raff, Aviya Skowron, LintangSutawika, and Oskar van der Wal. 2023.Pythia:A suite for analyzing large language models acrosstraining and scaling. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shotlearners. Advances in neural information processingsystems, 33:18771901. Yekun Chai, Shuohuan Wang, Chao Pang, Yu Sun,Hao Tian, and Hua Wu. 2023.Ernie-code: Be-yond english-centric cross-lingual pretraining for pro-gramming languages. In Findings of the Associationfor Computational Linguistics: ACL 2023, Toronto,Canada, July 9-14, 2023, pages 1062810650. Asso-ciation for Computational Linguistics.",
  "Chin-Yew Lin. 2004. Rouge: A package for automaticevaluation of summaries.In Text summarizationbranches out, pages 7481": "Anton Lozhkov, Raymond Li, Loubna Ben Allal, Fed-erico Cassano, Joel Lamy-Poirier, Nouamane Tazi,Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei,et al. 2024. Starcoder 2 and the stack v2: The nextgeneration. arXiv preprint arXiv:2402.19173. Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evalu-ation of machine translation. In Proceedings of the40th annual meeting of the Association for Computa-tional Linguistics, pages 311318.",
  "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,Dario Amodei, Ilya Sutskever, et al. 2019. Languagemodels are unsupervised multitask learners. OpenAIblog, 1(8):9": "Gemini Team, Rohan Anil, Sebastian Borgeaud,Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,Radu Soricut, Johan Schalkwyk, Andrew M Dai,Anja Hauth, et al. 2023.Gemini: a family ofhighly capable multimodal models. arXiv preprintarXiv:2312.11805. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023.Llama 2:Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288.",
  "A.1Tasks and Datasets for GPTDynamics": "We conduct experiments on a subset of FLAN (Weiet al., 2022), a diverse array of datasets for instruc-tion tuning, to conduct a thorough evaluation ofTDA methods. Our dataset selection spans bothNLU and NLG tasks, thereby offering a broad spec-trum of challenges for TDA methods to tackle.The NLU tasks selected include RTE (NaturalLanguage Inference), SST-2 (Sentiment Classifica-tion), and BoolQ (Reading Comprehension). ForNLG, we delve into WebNLG (Struct-to-Text) andWMT-16 DE/EN (Machine Translation) tasks.To exploit the superior generalization benefitsthat instruction tuning brings to language mod-els, we have assembled a specialized subset forinstruction fine-tuning. This subset amalgamatesthe previously mentioned five tasks with CNN-DM(Summarization), crafting an extensive testing en-vironment of FLAN data. We sourced task-specificinstructions directly from the original FLAN paper.",
  "TracIn (Pruthi et al., 2020) is a gradient-basedused to calculate the influence through a first-ordergradient approximation. It considers the influenceof the training example z on the test example z": "as a loss change in z, which is provided by eachgradient step of the training example z. In practice,TracInCP was proposed as an alternative approxi-mation that considers specific checkpoints duringtraining. TracInCP calculates the gradient dot prod-uct of z and z at these checkpoints. In our experi-ments, we used TracInCP with 10 checkpoints andall steps checkpoints to estimate the influence.Grad-Dot (Charpiat et al., 2019) is a heuristicgradient-based TDA method. They also computethe effect of a training sample on a test sample bythe dot product of the gradients but computed ontop of the final trained model.Simfluence (Guu et al., 2023) is a novel frame-work for TDA. It characterizes the loss variationof test samples during training by modeling it asa Markov process. Then, it learns a unique multi-plicative and additive influence parameter for eachtraining example. It is worth noting that in theoriginal paper, the framework that considers bothmultiplicative and additive influences is referred toas Simfluence-linear. However, for simplicity inthis paper, we use the term Simfluence to refer tothe same model.",
  "A.3Implementation Details of InstructionTuning": "GPTDynamics Collection for Instruction Tun-ingWe instruction tuned Pythia from 14M to2.8B (i.e., 14M, 70M, 160M, 410M, 1B, and 2.8B)on the instruction tuning dataset referenced in Ap-pendix A.1. We collect a total of randomly sam-pled 768 instances from aforementioned five tasks,with each samples 128 of 200 data points in onetraining run for instruction tuning. The data di-vision followed the same protocol as in the fine-tuning scenarios. All Pythia models underwentcomprehensive fine-tuning, with the exception ofthe Pythia-2.8B model, which was fine-tuned usingthe parameter-efficient LoRA technique (Hu et al.,2021). The LoRA module was implemented withinthe query, key, and value projection matrices ofthe self-attention module, with a LoRA rank of 8,alpha set to 4, and a dropout probability of 0.05.We evaluated the Pythia models using the identi-cal datasets as those in the fine-tuning experiments.For the WebNLG and WMT16 DE/EN datasets, weevaluated BLEU and ROUGE-L scores in additionto test loss, employing a top-p sampling strategyfor generation with a temperature of 0.2 and top-p probability of 0.95. Detailed instruction-tuninghyperparameters are reported in . GPTfluence Training SetupThe architecture ofour simulator is a pre-trained sentence encoder fol-lowed by parallel weight-sharing fully-connectedlayers for predicting influence factors. The train-able model size of the simulator is 11.4M excludingpre-trained embeddings (frozen). Unless specified,we use the sentence transformer4 as our pre-trainedencoder. For the simulator training, we combineall five FLAN datasets and train our simulator ina multi-task manner, each dataset has 27 trainingruns. All reported results are averaged over 5 held-out runs. We set the order n of Markov processassumptions equal to 1 for instruction tuning. De-tailed training hyperparameters of GPTfluence areshown in .",
  "HyperparametersPythia-14MPythia-70MPythia-160MPythia-410MPythia-1BPythia-2.8B": "L2 regularizaiton 1e-5OptimizerAdamWAdams (0.9, 0.999)Adams 1e-8Learning rate1e-61e-61e-61e-51e-51e-5Learning rate scheduleLinear decayWarmup steps200Batch size128Max training epochs505050505050Pre-trained encoderMiniLM-L6-v2Max sequence length512512512512512512Early stoppingPrecisionfp32Seed42 : Hyperparameters of training our featurized simulator for instruction tuning on Pythia models of size from14M to 2.8B. We use the same training hyperparameters as in the loss simulation for the BLEU and ROUGE-Lscore simulation on WebNLG and WMT16 DE/EN datasets. we perform a total of 32 training runs, with eachsample 128 of 200 data points from the originaltraining set for GPT training. The split of trainingruns is divided into 25 for training, 2 for validation,and 5 for test. All reported results are averagedover 5 held-out runs. For NLG datasets, we mea-sure BLEU, ROUGE-L scores besides the test loss,using a top-p sampling strategy for generation witha temperature setting of 0.2 and a top-p probabilityof 0.95. Note that we collect ROUGE-L scores on ascale from 0 to 1. The fine-tuning hyperparametersare shown in . GPTfluence Training SetupWe train a singlefeaturized simulator on training runs for eachdataset with the L2-regularized regression objectiveas defined in section 3.2. We freeze the parametersof the pre-trained encoder during training for bet-ter generalization. We set the order n of Markovprocess assumptions equal to 1 for fine-tuning. De-tailed training hyperparameters are shown in Ta-ble 8.",
  "A.5Implementing GPTfluence": "GPTfluence TrainingTo elucidate the intri-cate process of collecting training data dynamicsand the training of the featurized simulator withGPTfluence, we present the pseudo-code in Algo-rithm 1. The execution of this algorithm yields aGPTfluence simulator, which is adept at simulat-ing the target performance trajectory and assessingthe impact of training examples on a given testpoint. GPTfluence EvaluationFor evaluation, Thesimulator autoregressively forecasts upcoming test-set metrics, based on the previous n observations.Specifically, it commences with the initial test met-ric recorded at the starting step, thereafter predict-ing the subsequent performance metrics across thetraining curriculum.",
  "HyperparametersSST-2RTEBoolQWebNLGWMT16 DE/EN": "L2-regularizaitons 1e-5OptimizerAdamWAdams (0.9, 0.999)Adams 1e-8Learning rate1e-41e-41e-41e-41e-4Learning rate scheduleLinear decayWarmup steps200Batch size128Max training epochs300300300300300Pre-trained encoderMiniLM-L6-v2MiniLM-L6-v2MiniLM-L6-v2MiniLM-L6-v2MiniLM-L6-v2Max sequence length512512512512512Early stoppingPrecisionfp32Seed42 : Hyperparameters of training our featurized simulator for each dataset for fine-tuning. We use the sametraining hyperparameters as in the loss simulation for the BLEU and ROUGE-L score simulation on WebNLG andWMT16 DE/EN datasets.",
  ": return": "ious TDA methods. Results are presented in Ta-ble 13. TracIn-CP, a representative of gradient-based methods, exhibited the highest inference la-tency and FLOPs. This is attributable to the need todo forward and backward operations directly on theGPTs. Conversely, GPTfluence solely depends ona considerably smaller simulator during inference.Furthermore, we analyzed the convergence andvalidation performance of our GPTfluence in com-parison with Simfluence.As shown in ,GPTfluence exhibits a better convergence effi-ciency and also has lower validation all-steps MSE.This underscores the better training efficiency andmodel capacity of our featurized simulator."
}