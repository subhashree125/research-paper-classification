{
  "Abstract": "We discover that many natural-languageprompts can be replaced by correspondingprompts that are unintelligible to humans butthat provably elicit similar behavior in languagemodels. We call these prompts evil twins be-cause they are obfuscated and uninterpretable(evil), but at the same time mimic the function-ality of the original natural-language prompts(twins). Remarkably, evil twins transfer be-tween models. We find these prompts by solv-ing a maximum-likelihood problem which hasapplications of independent interest.1.",
  "Introduction": "Large Language Models (LLMs) are rapidly im-proving across a wide range of tasks (Ope-nAI, 2023; Touvron et al., 2023a,b; Jiang et al.,2023; Bubeck et al., 2023). LLMs are typicallyinstruction-tuned (Ouyang et al., 2022) to acceptuser queries as prompts, and these prompts havebecome the primary interface for interacting withthese models. Nevertheless, many basic questionson how models parse prompts remain largely open.In this paper, we examine the question:",
  "Our code and data is available at": "show that natural-language prompts can often be re-placed by prompts that are unintelligible to humans,but that cause the model to behave functionally sim-ilarly to the original natural-language prompt. Inmore detail: Functional similarity between promptsFirst,we propose a quantitative measure of functionalsimilarity between two prompts p and p, by view-ing them as inducing distributions PLLM(|p) andPLLM(|p) over outputs when fed into a languagemodel. The two prompts are functionally similar ifthese distributions are similar, which we measurethrough the Kullback-Leibler divergence (KL):",
  "The KL divergence is an information-theoretic mea-sure of the distance between two distributions,which is zero if and only if the two distributionsare identical (Cover et al., 1991)": "Finding prompts with similar functionalityGiven a ground-truth prompt p, we seek to find afunctionally similar prompt p. To do so, we drawa set of outputs from the model, d1, . . . , dn PLLM(|p) and solve the maximum-likelihoodproblem where the objective is to find the promptp under which the example outputs are most likelyto have been drawn.",
  "GPT-4 reconstructionHow can I aerate soil in my garden?19.40.5optimizationacter aerate soil kar kt waysierno3.70.4": ": Five examples of ground truth prompts p and corresponding evil twins p. Each evil twin is found bysolving the maximum-likelihood problem (2) on 100 documents generated from the ground truth prompt. Wecompare the evil twins to a baseline created by asking GPT-4 to generate a prompt that could have created the 100documents. Surprisingly, the optimized prompts, although incoherent, are more functionally similar to the groundtruth prompt (lower KL divergence) than the GPT-4 reconstruction. Details are in . in theappendix contains a full table of results.",
  "Transferability. Remarkably, these evil twinprompts transfer between a variety of open-source and proprietary language models; see": "Robustness. We investigate the robustness ofevil twin prompts to changes in their token-order and to replacements of their tokens. Wefind that whether evil twins are robust to ran-domly permuting their tokens depends on theLLM family. On the other hand, across LLMfamilies, evil twins are more impacted by ran-domly replacing their tokens than ground truthprompts. This suggests that even the uncom-mon, non-English tokens in the optimized",
  "Related work": "This paper fits into a quickly growing literaturestudying how language models parse prompts. Fur-thermore, the techniques used in this paper buildoff of a body of work on prompt optimization. Wesurvey relevant work below. How models parse promptsThere is rapidlymounting evidence that LLMs interpret natural-language prompts in counterintuitive ways. Forinstance, models struggle with prompts that arenegated, such as prompts that ask to Give an in-correct example instead of to Give a correct ex- ample (Jang et al., 2023). Additionally, natural-language instructions in prompts in few-shot set-tings can often be replaced by irrelevant strings oftext, with no drop in performance (Webson andPavlick, 2022). Moreover, in few-shot settings thein-context examples labels can be replaced by ran-dom labels with little drop in performance (Minet al., 2022). These experiments indicate that LLMsfollow instructions in prompts differently than hu-mans do, which agrees in spirit with our finding ofevil twin prompts.There is also existing evidence that LLMs areable to parse some non-natural language prompts.Daras and Dimakis, 2022 finds that garbled text ap-pearing in DALLE-2 images can be repurposed inprompts to the image generation model, and yieldsnatural images. Millire, 2022 suggests that thismay be an artifact of the models byte pair encod-ing, pointing out that the example prompt Apoploevesrreaitais, which generates bird images, is rem-iniscent of the real Latin bird families Apodidaeand Ploceidae. Furthermore, adversarial exampleprompts that jailbreak models sometimes containuninterpretable suffixes (e.g., (Cherepanova andZou, 2024; Zou et al., 2023; Liu et al., 2023)).Our results in this paper demonstrate that the phe-nomenon of language models parsing non-naturallanguage prompts is more widespread than previ-ously known, since many natural language promptshave non-natural language analogues. A full under-standing of how models parse prompts will requirecontending with the existence of evil twin prompts. Prompt optimizationThe techniques in thiswork draw from the prompt optimization litera-ture. This literature primarily includes optimizationmethods for hard prompts (which are text strings,i.e., sequences of tokens), and soft prompts (i.e.,sequences of embedding vectors that are not con-strained to correspond to a textual string). Hardprompts are more desirable because they are moreeasily inspected by humans, and can be inputtedacross different models.Foundational work for soft prompt optimizationincludes prefix tuning (Li and Liang, 2021; Lesteret al., 2021), which trains a soft prompt with gradi-ent descent. This soft prompt is then prepended toa hard prompt for improved conditional generationon a range of tasks. We include experiments onsoft prompts in Appendix D, but the focus of thispaper is on hard prompts.Hard prompt optimization operates in the models discrete token space, meaning that theoptimization is not directly differentiable. Hardprompt optimization is most frequently describedin the context of adversarial attacks or finding jail-breaks (prompts) that generate malicious output,or induce model misclassification. Several meth-ods such as HotFlip (Ebrahimi et al., 2018), Auto-Prompt (Shin et al., 2020), Greedy Coordinate Gra-dient (GCG) (Zou et al., 2023), and AutoDAN (Liuet al., 2023) have been developed to optimize overhard prompts. These methods work by startingwith an arbitrary prompt and iteratively modifyingtokens towards the goal of obtaining the adversar-ial attack behavior. In our work, we apply GCG(plus extra warm starts, pruning, and fluency penal-ties) to our optimization framework, demonstratingthat it can be used in settings beyond adversarialattacks.The closest work to ours is PEZ (Wen et al., 2023), which proposes a method that takes inputimages and finds matching prompts in CLIP embed-ding space. This bears similarity to the maximum-likelihood problem in (2), but our setting differssignificantly from PEZ in that our optimizationproblem does not rely on a multimodal model witha shared embedding space all that we require isthe ability to compute the log-likelihood of a docu-ment given a prompt. In particular, our formulationof prompt optimization means that our method isapplicable even when the documents outputted bythe model do not have the same meaning as theprompt (i.e., the twin prompt does not have to beclose to the documents in some embedding space).This is the setting in all conversational languagemodels, where the models responses are not para-phrases of the prompt.",
  "Autoregressive language models": "In our work, we focus on transformers (Vaswaniet al., 2017) with a decoder-only architecture, as themajority of recent language models have adoptedthis architecture. We define a transformer languagemodel h, with a vocabulary size of V tokens, whereeach token maps to a d dimensional embedding.The input to the model is a length-k sequence repre-sented as a matrix X RkV by stacking one-hotencodings x1, . . . , xk RV of tokens.Given a sequence X1:i RiV , the modeloutputs logits for the (i + 1) token probabilitiesh(X1:i) RV .",
  "Optimization problem": "We seek a prompt p that minimizes the empiricalestimate of the KL divergence between p and pgiven in (4). However, (4) involves additive termsthat depend on p, which we cannot compute un-less we know p. Fortunately, these terms do notdepend on p, so in the optimization we can dropthese terms and define the loss function",
  "We consider various methods to optimize (5)": "Asking GPT-4.Since this optimization isequivalent to the maximum-likelihood prob-lem, we benchmark our methods against theoptimization ability of commercial LLMs.Namely, we provide GPT-4 with our trainingcorpus, containing the n documents which areused for optimization, and ask it to provide anexample prompt that could have generated thecorpus; see Appendix E for more details andthe GPT-4 prompt template. GCG with cold start. We optimize (5) withthe Greedy Coordinate Gradient (GCG) al-gorithm (Zou et al., 2023), which computesper-token gradients for each position in theprompt, and iteratively flips tokens in order tominimize the loss. The full GCG algorithm isreproduced in Appendix A. In the cold startversion, we initialize a prompt p0 RkpV",
  "We compare these methods on 100 randomlysampled prompts from the Alpaca instruction tun-ing dataset (Taori et al., 2023), where Vicuna-7b-": ": Win rate between various methods acrossoptimizations of 100 ground truth prompts with 100documents each. Given two prompts to compare, wecompute the KL divergence for both prompts withrespect to the ground truth, and the method with lowerKL wins. Darker shades indicate ROW method is betterthan COLUMN method. Full optimization results areshown in Appendix E. In the case of ties, the win isshared by both methods. The most effective method isGCG with warm starts. v1.5 is the instruction-tuned model. Additional ex-periments on various model families and datasetsare presented in Appendix C. For each method andprompt, we compute the KL divergence of the opti-mized prompt with respect to the original prompt.We compare pairs of methods based on which onefinds the closer prompt to the ground truth; see. GPT-4 suggestions perform roughly onpar with those from cold-start GCG. On the otherhand, GCG with a warm start provides a strong im-provement over both cold-start GCG and the GPT-4prompt suggestions. Enforcing interpretability byadding a fluency penalty or pruning the vocabu-lary does not improve the optimized prompt (see). All results are reported in .",
  "Transferability to open source andproprietary models": "Although the optimized evil twin prompts aregenerally unintelligible to humans, we surprisinglyfind that they transfer to a number of open sourceand closed industrial LLMs. We use 100 optimized(from a GPT-4 warm start) prompts from Vicunaand run them through a variety of open source andclosed models. We use GPT-4 as a judge to deter-mine if the induced responses from the optimizedprompt are faithful to the original prompt on a scaleof 1 to 3.Specifically, the prompt that we use for GPT-4is:",
  "ModelScore = 1Score = 2Score = 3 (best)": "Gemini Pro17875GPT-3.5-turbo31663GPT-431762Claude 3 Haiku59536Claude 3 Sonnet38854mistral-medium163054mistral-small211267mistral-tiny242253OpenHermes-2.552471OpenHermes-13B281953Llama2-7b-chat72864Llama2-13b-chat82764Vicuna-7B72271Vicuna-13B82764 : Transferability results to open source andproprietary models. Using 100 optimized prompts fromVicuna, we directly input these prompts to various opensource and closed models. The ratings are given byGPT-4, based on the scale described in the prompt in.1. family while varying the size. The Pythia (Bider-man et al., 2023) suite includes models rangingfrom 70M to 12B parameters. Each model is iden-tical apart from the number of parameters, whichmakes it ideal for investigating how the distance be-tween prompts changes with model size. Addition-ally, each model is trained with the same data seenin the same order. Our results are shown in .We find that prompts optimized on smaller modelshave worse transferability to larger ones. However,prompts optimized on larger models transfer verywell to smaller ones.",
  "Token order sensitivity": "Natural language is sensitive to token order, in thatthe meaning of a sequence can be affected by re-arrangement of its constituent tokens. Ishibashiet al., 2023 finds that prompts learned by Auto-Prompt are more sensitive to token rearrangementthan prompts written manually, as measured by per-formance on natural language inference tasks. Weexamine whether this is also true of our optimizedprompts, invoking a KL-based assessment:",
  "Pa,b(dKL(a||a) > dKL(b||b)) > 0.5": ": Transferability between model sizes. Foreach model size in the Pythia suite (excluding 12B),and each of 100 prompt sentences from the HellaSwagdataset (Zellers et al., 2019), we run GCG with coldstart to generate an optimized prompt based on 100documents from the original prompt. For eachoptimized prompt at each model size, we compute theKL divergence for the optimized prompt at all othermodel sizes. The measured ratio isdKL,dest(ppsource)dKL,source(ppsource) averaged over all 100 prompts,where psource represents the optimized prompt from thesource model, dKL,source represents the KL divergenceas measured on the source model, and dKL,destrepresents the KL divergence as measured on thedestination model. Full results are shown in . We wish to compare the token-order-sensitivityof optimized prompts to that of the natural-language ground truth prompts. We evaluate thisusing Algorithm 1, which calculates a token-order-sensitivity win rate w between p and p, compar-ing how much the prompts change under randomtoken reordering.",
  "We find that token order sensitivity appears to bedependent on the model family; see . ForPythia, Phi-2 and Gemma, the optimized promptsare significantly less order sensitive than the ground": ": Individual token importance in optimized and original prompts for various models. For each of the 100prompts from the Alpaca (Taori et al., 2023) and OpenHermes-2.5 datasets, and for each of the first 6 positionsi {1, . . . , 6} of the prompt, we compute the KL divergence dKL(p ri(p)) when we replace position i with the[UNK] token. Each histogram is over all positions and prompts (either the original prompts or optimized prompts)for a given model. The optimized prompts appear to be generally more sensitive.",
  "ModelUw": "pythia-70m1.00 (0.95, 1.00)0.93 (0.85, 0.96)pythia-160m1.00 (0.95, 1.00)0.97 (0.92, 0.99)pythia-410m1.00 (0.96, 1.00)0.99 (0.93, 0.99)pythia-1b1.00 (0.96, 1.00)0.99 (0.95, 1.00)pythia-1.4b1.00 (0.95, 1.00)0.99 (0.93, 0.99)pythia-2.8b1.00 (0.96, 1.00)0.99 (0.93, 0.99)pythia-6.9b1.00 (0.96, 1.00)0.99 (0.95, 1.00)vicuna-7b (cold)0.52 (0.42, 0.62)0.54 (0.43, 0.63)vicuna-7b (warm)0.39 (0.29, 0.48)0.41 (0.31, 0.50)gemma-2b-it (cold)0.63 (0.52, 0.71)0.59 (0.48, 0.67)gemma-2b-it (warm)0.84 (0.74, 0.89)0.67 (0.57, 0.75)mistral-7b-ins (warm)0.25 (0.17, 0.33)0.32 (0.24, 0.42)phi-2 (warm)0.97 (0.92, 0.99)0.94 (0.86, 0.97) : Token-order-sensitivity results. Given 100prompt pairs (p, p), we apply Algorithm 1 to assesstoken-order-sensitivity. Warm indicates that theoptimized prompt was warm-started, while coldindicates that the optimized prompt was arbitrarilystarted. All runs of GCG on Pythia models werecold-started. The value of U indicates the fraction ofground-truth prompts p that are more token ordersensitive than the corresponding optimized prompts p.We also report the average of win rates w acrossprompt pairs and shufflings. Intervals for U and wreflect 95% Clopper-Pearson intervals for binomialproportions (Clopper and Pearson, 1934).",
  "Token replacement sensitivity": "Based on visual inspection of the evil twin promptsin Figures 1 and 10, one can hypothesize that theseconsist of some tokens that are highly-related tothe ground truth prompts and that drive the modelsoutput, as well as some tokens that appear unrelatedand can be safely ignored or replaced.We test this hypothesis quantitatively, check-ing whether there are a few tokens in the opti-mized prompts that have an outsized effect on theprompts functionality. We compute dKL(p||ri(p))for each optimized prompt p, where ri is a func-tion that replaces the ith token of a sequencewith [UNK]. We do the same for the ground truthprompts p. plots histograms of these KLdivergences over all prompts and token positions i.Surprisingly, this experiment contradicts the hy-pothesis. shows that the effect of replacinga token in the optimized prompts with the un-known token, [UNK], is generally greater thanthe effect of replacing a token with [UNK] in theground truth prompts. Thus, optimized prompts aremore dependent on all of their tokens being presentin a way that natural prompts are not, even thoughmany of these tokens may appear garbled and un-interpretable. This effect is especially significantin the Pythia, Vicuna, and Phi-2 models, since veryfew tokens in the optimized prompts yield zeroKL divergence change when they are replaced by",
  "Optimizing for more intelligibleprompts": "The prompts generated by our optimization are of-ten unintelligible, and it may be desirable to recovera prompt that is more interpretable by humans. Inthis section, we explore two adjustments to ouroptimization procedure that aim to improve intel-ligibility: (1) fluency penalty, and (2) limiting theoptimized prompts vocabulary to common Englishtokens. We find that these variants do not improvethe KL divergence of the optimized prompt to theoriginal.",
  "Fluency penalty": "Inspired by prior work (Guo et al., 2021; Mehrabiet al., 2022; Shi et al., 2022; Wen et al., 2023)on adding additional terms such as perplexity,BERTscore (Zhang* et al., 2020) and a fluencypenalty to the loss in order to improve downstreamperformance, we follow (Shi et al., 2022) and adda term to the hard prompt loss function in orderto penalize the log-likelihood of the prompt (flu-ency penalty). Our hard prompt loss function thenbecomes",
  "+ log PLLM(p)": "where 0 is a parameter controlling the im-portance of recovering a natural prompt. Larger biases the optimization towards more naturalprompts that may not necessarily fit the documentsas well. We find that adding the fluency penaltydecreases the similarity between the optimized andground truth prompt; see . However, theprompts generated with a fluency penalty containfewer strange tokens, and have higher fluency; see for the full results. An analysis of tun-ing the fluency hyperparameter is provided inAppendix B.",
  "Vocabulary pruning": "We explore limiting the tokens chosen for GCG inorder to improve reconstruction and fluency. Sinceall of our testing is carried out on English promptsand documents, we focus on English sub-words inthe tokenizer only. In order to achieve this, we runthe Llama tokenizer on an English corpus obtainedfrom spaCy (Honnibal and Montani, 2017), and mask out all tokens that do not appear in the cor-pus. The Llama tokenizer contains 32,000 tokens,and our pruning procedure results in about 15,000tokens being removed.We find that overall vocabulary pruning does notimprove performance for reconstruction in a statis-tically significant manner across the 100 ground-truth prompts, although it does make the optimizedprompts have fewer special characters; see and the optimization results in .",
  "Discussion and future work": "Our work takes a new perspective on prompt opti-mization by inquiring whether we can optimizeprompts to be functionally equivalent to a cer-tain ground-truth prompt. Functional similarityis quantified via the KL divergence between theground truth prompt distribution and the optimizedprompts distribution. This yields a maximum-likelihood problem (2), whose solution uncoversevil twin prompts. Beyond our explorations of thetransferability between models and robustness toperturbations of evil twin prompts, there are severalopen directions for future work. These directionsinclude applications of the maximum-likelihoodproblem (2) that are of independent interest. Prompt compression.By adding a lengthpenalty to the optimized prompt in (2),our framework can be used to generateshorter prompts that mimic an original, longerprompt, which can then be used for pay-by-token API services in order to reduce infer-ence time, context length usage, and totalcosts. Conditional generation.The maximum-likelihood problem (2) can be extended toprompts that allow for conditional generation.An example of where this may be useful isin style/content transfer: given a set of useremails in the form (topic, email), a user couldoptimize a prompt such that the concatenatedinput string [prompt; topic] would be likely togenerate the corresponding emails, and couldwrite new e-mails on new topics in the usersstyle as defined by the users corpus of previ-ous e-mails.",
  "Limitations": "The evil twins that we find are discovered using theGCG algorithm (Zou et al., 2023) plus additionalwarm-starting, token pruning, and fluency penalties.However, GCG may not result in a stable optimiza-tion in all cases. This can be seen in Appendix E,where for some examples the optimization fails tofind prompts with low KL divergence to the orig-inal prompt. Thus, in the future it makes sense toexplore alternative optimization algorithms, suchas algorithms that may edit not just one token ata time, but may also make multi-token insertionsand deletions, as well as vary the number of tokensduring the optimization. Also, additional futurework is required to adapt our framework for theapplications of independent interest, because GCGmay take many iterations to converge, which mayintroduce a significant runtime overhead.Our approach for finding evil twins relies onhaving full access to the models gradients, whichis not the case for many closed-source modelssuch as GPT-4. Nevertheless, the transferabilityof evil twins between models allows us to findthem on open-source models and apply them toclosed-source models.",
  "ICML 2023 Workshop on Deployment Challenges forGenerative AI": "Stella Biderman, Hailey Schoelkopf, Quentin GregoryAnthony, Herbie Bradley, Kyle OBrien, Eric Hal-lahan, Mohammad Aflah Khan, Shivanshu Purohit,USVSN Sai Prashanth, Edward Raff, et al. 2023.Pythia: A Suite for Analyzing Large Language Mod-els Across Training and Scaling. In InternationalConference on Machine Learning, pages 23972430.PMLR. Sbastien Bubeck, Varun Chandrasekaran, Ronen El-dan, Johannes Gehrke, Eric Horvitz, Ece Kamar,Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lund-berg, et al. 2023. Sparks of Artificial General In-telligence: Early experiments with GPT-4. arXivpreprint arXiv:2303.12712.",
  "Giannis Daras and Alex Dimakis. 2022. Discoveringthe Hidden Vocabulary of DALLE-2. In NeurIPS2022 Workshop on Score-Based Methods": "Grgoire Deltang, Anian Ruoss, Paul-AmbroiseDuquenne, Elliot Catt, Tim Genewein, Christo-pher Mattern, Jordi Grau-Moya, Li Kevin Wenliang,Matthew Aitchison, Laurent Orseau, et al. 2023. Lan-guage Modeling Is Compression.arXiv preprintarXiv:2309.10668. Javid Ebrahimi, Anyi Rao, Daniel Lowd, and DejingDou. 2018. HotFlip: White-box adversarial exam-ples for text classification. In Proceedings of the 56thAnnual Meeting of the Association for ComputationalLinguistics (Volume 2: Short Papers), pages 3136,Melbourne, Australia. Association for ComputationalLinguistics.",
  "Matthew Honnibal and Ines Montani. 2017. spaCy 2:Natural language understanding with Bloom embed-dings, convolutional neural networks and incrementalparsing. To appear": "Yoichi Ishibashi, Danushka Bollegala, Katsuhito Su-doh, and Satoshi Nakamura. 2023. Evaluating therobustness of discrete prompts. In Proceedings of the17th Conference of the European Chapter of the As-sociation for Computational Linguistics, pages 23732384, Dubrovnik, Croatia. Association for Computa-tional Linguistics. Neel Jain, Avi Schwarzschild, Yuxin Wen, GowthamiSomepalli, John Kirchenbauer, Ping-yeh Chiang,Micah Goldblum, Aniruddha Saha, Jonas Geiping,and Tom Goldstein. 2023. Baseline defenses for ad-versarial attacks against aligned language models.arXiv preprint arXiv:2309.00614. Joel Jang, Seonghyeon Ye, and Minjoon Seo. 2023. Canlarge language models truly understand prompts?a case study with negated prompts.In TransferLearning for Natural Language Processing Work-shop, pages 5262. PMLR. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, Llio Renard Lavaud,Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,Thibaut Lavril, Thomas Wang, Timothe Lacroix,and William El Sayed. 2023. Mistral 7b.",
  "Brian Lester, Rami Al-Rfou, and Noah Constant. 2021": "The Power of Scale for Parameter-Efficient PromptTuning. In Proceedings of the 2021 Conference onEmpirical Methods in Natural Language Processing,pages 30453059, Online and Punta Cana, Domini-can Republic. Association for Computational Lin-guistics. Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning:Optimizing continuous prompts for generation. InProceedings of the 59th Annual Meeting of the Asso-ciation for Computational Linguistics and the 11thInternational Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers), pages 45824597, Online. Association for Computational Lin-guistics.",
  "Mark S. Pinsker. 1964.Information and Informa-tion Stability of Random Variables and Processes.Holden-Day, San Francisco": "Weijia Shi, Xiaochuang Han, Hila Gonen, Ari Holtzman,Yulia Tsvetkov, and Luke Zettlemoyer. 2022. TowardHuman Readable Prompt Tuning: Kubricks TheShining is a good movie, and a good prompt too?arXiv preprint arXiv:2212.10539. Taylor Shin, Yasaman Razeghi, Robert L. Logan IV, EricWallace, and Sameer Singh. 2020. AutoPrompt: Elic-iting Knowledge from Language Models with Auto-matically Generated Prompts. In Proceedings of the2020 Conference on Empirical Methods in NaturalLanguage Processing (EMNLP), pages 42224235,Online. Association for Computational Linguistics.",
  "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, YannDubois, Xuechen Li, Carlos Guestrin, Percy Liang,and Tatsunori B. Hashimoto. 2023. Stanford Alpaca:An Instruction-following LLaMA model": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, et al. 2023a.LLaMA: Open and effi-cient foundation language models. arXiv preprintarXiv:2302.13971. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023b.Llama 2: Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288. Ashish Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoreit, Llion Jones, Aidan N Gomez, ukaszKaiser, and Illia Polosukhin. 2017. Attention is AllYou Need. In Advances in Neural Information Pro-cessing Systems. Albert Webson and Ellie Pavlick. 2022. Do prompt-based models really understand the meaning of theirprompts? In Proceedings of the 2022 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, pages 23002344, Seattle, United States.Association for Computational Linguistics. Yuxin Wen, Neel Jain, John Kirchenbauer, Micah Gold-blum, Jonas Geiping, and Tom Goldstein. 2023. HardPrompts Made Easy: Gradient-Based Discrete Opti-mization for Prompt Tuning and Discovery. In Thirty-seventh Conference on Neural Information Process-ing Systems. Rowan Zellers, Ari Holtzman, Yonatan Bisk, AliFarhadi, and Yejin Choi. 2019. HellaSwag: Can a ma-chine really finish your sentence? In Proceedings ofthe 57th Annual Meeting of the Association for Com-putational Linguistics, pages 47914800, Florence,Italy. Association for Computational Linguistics.",
  "AGreedy Coordinate Gradient algorithm": "Our paper builds on the Greedy Coordinate Gradi-ent (GCG) algorithm from (Zou et al., 2023) forprompt optimization given in Algorithm 2, by in-corporating warm starts and experimenting withvocabulary pruning. GCG falls in a line of discreteoptimization algorithms that iteratively constructprompts using token flips, combined with variousheuristics for which tokens to flip and in what or-der.",
  "Early work, such as HotFlip (Ebrahimi et al.,": "2018), picks a token and approximates the top-1token in the vocabulary which decreases the lossmost when flipped to. This is able to induce incor-rect classification for sentiment analysis.Building on this, AutoPrompt appends a smallnumber of randomly initialized \"trigger\" tokensto the original prompt. The tokens in this \"trig-ger\" are subsequently masked and optimized viamasked language modeling, where the objective isto minimize the loss of the input sequence by byselecting some top-k tokens with highest gradientfor each trigger (Shin et al., 2020).GCG utilizes a similar approach to AutoPrompt;given a suffix of tokens to the task prompt, they op-timize this suffix by a computing the top-k tokenswith largest negative gradients for every positionin the suffix, then uniformly sample a single tokenas a candidate replacement for each position in thesuffix. Finally, for each candidate suffix, they com-pute the loss by running a forward pass, and selectthe candidate suffix with lowest loss as the finalnew suffix. Using their optimized suffixes, they areable to generate prompts which induce maliciousoutput from open source LLMs such as Llama, aswell as large commercial models such as ChatGPTand GPT-4. The full algorithm details for GCG areshown in Algorithm 2.",
  "BFluency hyperparameter analysis": "We explore the effects of varying the strengthof the fluency penalty by selecting {0.01, 0.05, 0.1, 1.0} and running hard prompt op-timization for 50 epochs on Vicuna-7b with a GPT-4 warm start; see . We also run hard promptoptimization on Pythia-1b for 50 epochs from acold start; see .These figures show a perhaps surprising trade-offbetween the readability of the prompt (as measuredby the final log probability), and how well it recon-structs the original prompt. For our optimizationsin , we select = 0.05, and this value doesdegrade the optimization performance in terms ofKL divergence to the ground truth.",
  "We run additional experiments on Microsofts Phi-2 (2.7 billion parameters), Mistrals Mistral-7B-Instruct-v0.2 (7 billion parameters), and GooglesGemma (2 billion parameters) (Google, 2024). We": ": Hard prompt optimization results for variousfluency penalties with the Vicuna-7b model. We use a100 prompt subset from Alpaca, and Vicuna-7b from aGPT-4 warm start. The optimization proceeds for 50epochs, and we take the final values of the KLdivergence to the ground truth, and the log-probabilityof the optimized prompt. : Hard prompt optimization results for variousfluency parameters with the Pythia-1b model. We usea 100 prompt subset from HellaSwag, and Pythia-1bwith a cold start. The optimization proceeds for 50epochs, and we take the final values of the KLdivergence to the ground truth, and the log-probabilityof the optimized prompt. : Hard prompt optimization with Phi-2,Mistral-7B-Instruct, and Gemma-2B. 100 prompts arerandomly sampled from a subset of theOpenHermes-2.5 dataset which involves coding tasks,and we run hard prompt optimization for 100 epochs,beginning with a warm-start from GPT-4. Each point isone prompt. Horizontal error bars capture uncertaintyfor the initial warm start KL, while vertical error barscapture uncertainty in the final optimized KL. use the popular prompt dataset OpenHermes-2.5,which contains a diverse variety of prompts for var-ious tasks such as coding, Q&A, and many others.We filter for a subset of prompts that are related towriting code.For all models, we run hard prompt optimizationfor 100 epochs, starting from a GPT-4 warm start.We find that we achieve similar results as we didwith other model families; see .",
  "DSoft prompt results": "Each token in the vocabulary V maps to a d dimen-sional embedding. We denote the embedding layerby W E RV d, meaning that the model is in theform h(X) = g(XW E), where g is the rest ofthe transformer model except the embedding layer.Recall that soft prompts are sequences of vectorsthat lie in Rd where d is the dimensionality of theembedding space, rather than sequences of tokens.Specifically, we can represent the soft prompt asa matrix Z Rkpd, which is fed into the LLMinstead of the prompts embeddings, and similarlyto (3) induces a distribution over documents d RkdV . In a slight abuse of notation:",
  "Zt+1 = Zt ZL(Z; d1, . . . , dn) .(GD on prompt embeddings)": "In , we plot the results of soft-prompt re-construction with varying numbers of documents.As the number of documents increases, the recov-ered soft prompt converges in KL divergence to theground truth.Anagously to our hard prompt results, Baileyet al., 2023 study how soft prompts behave, and : Using Pythia 1.4b and a single prompt p, wegenerate sets of documents of varying sizes. For eachset, we run soft prompt reconstruction, and report theKL divergence with p and select the best value out of200 epochs. Error bars capture the uncertainty over 3trials plus uncertainty in the KL approximation on theheld-out set of 100 documents.",
  "EFull prompt optimization results": "We now report the full results for our experimentsoptimizing 100 randomly-sampled prompts fromthe Alpaca instruction tuning dataset (Taori et al.,2023), using Vicuna-7b-v1.5 as the LLM (Zhenget al., 2023).In we report a complete table contain-ing each of the 100 ground truth prompts, each ofthe optimized prompts found by the different meth-ods, and each of the approximate KL divergencesof the optimized prompts (lower is better). Themethods are:",
  "GPT-4 warm + prune is the GPT-4 suggestedprompt to initialize optimized warm + prune": "Note: in our examples we have omitted the in-struction models prompt template, but this is actu-ally present when we optimize (although it is notoptimized).The template we use for prompting GPT-4 is:Please generate 5 different prompts that couldhave created the following documents, and pleasemake sure to generate the responses as JSON onlyand keep the prompts brief:{document go here}Here is an example for a set of documents aboutcooking steak:{\"prompts\":[\"What is a good recipe for steak?\",\"Give me a steak dinner recipe.\",\"Tell me how to cook steak\",\"Whats a good way to make a steak?\",\"What is the best recipe for fast steak?\",]}",
  "Size70M160M410M1B1.4B2.8B6.9B": "70M13.29 4.2718.13 5.6222.85 6.6726.78 7.3326.58 6.8330.25 7.7028.45 6.15160M15.58 4.7714.20 4.8920.48 6.3423.73 6.7923.91 6.1727.08 6.7625.30 6.01410M16.74 4.6316.95 5.1716.17 5.2021.42 6.2021.55 6.1524.36 6.5422.53 5.661B16.98 4.9717.36 5.7819.22 6.2018.06 5.9320.64 6.2723.58 6.7021.57 5.791.4B17.09 4.6117.43 5.5218.85 6.0520.997 6.1318.18 5.6423.32 6.4121.38 5.522.8B17.74 5.0118.38 6.3220.15 6.1122.52 6.8421.74 6.4420.97 5.9422.26 5.826.9B17.96 4.6518.82 5.7420.88 6.2322.71 6.6622.25 6.6224.74 6.8519.72 5.18 : Transferability results for the Pythia suite. Intervals reflect mean standard deviation. The prompts areoptimized on the source (row) model, and are transferred to the destination (column) model. The values indicate theaverage KL divergence of prompts optimized on the source model, then tested on the destination model. : Direct optimized prompt transferability to Google Gemini Pro. We use the front-end website LMsys Chat(Zheng et al., 2023) to send the request to Gemini. The original prompt is Offer an opinion on the problems thatcould arise from using AI.",
  "Ground truthWhen were atomic weapons first used?0.00.0": "GPT-4 warmExplain the events of the first ever atomic bombing in Hiroshima in 194528.30.3GPT-4 warm + fluencyDescribe the first instance when atomic weapons were used6.30.1GPT-4 warm + pruneDiscuss the first use of atomic weapons in history12.30.2cold startCuando stw XIVn nuclear 7.50.2warm startated Wil in Use first ever atomic wsaporiffs]$,iroshima ===19 '<4.40.3warm + fluencycreatedhokercussion when atomic weapons fdd used0.70.1warm + pruneenk Years first use ob atomic weaponsandal aws2.40.1",
  "Ground truthHow can cities become more eco-friendly?0.00.0": "GPT-4 warmDescribe strategies for making a city more eco-friendly.12.10.4GPT-4 warm + fluencyWhat measures can a city take to become more eco-friendly?11.20.3GPT-4 warm + pruneList examples of eco-friendly strategies for cities.16.00.7cold startEOnLiterIG waysCanimocity clean9.70.6warm startiy Italiesiy making a city more eco Ley H czy3.60.4warm + fluencyWHERE6 cantre cityzystitz divent more eco GreeZcapt2.20.3warm + pruneconserplaninger eco'(friendly jak porei cities,,5.00.4",
  "Ground truthWrite a customer service response to address the following customer inquiry: \"I received the wrong item, what should I do?0.00.0": "GPT-4 warmWrite a customer service response to a customer who received the wrong item in their order.8.60.7GPT-4 warm + fluencyWrite a customer service response to a customer who received the wrong item in their order.8.60.7GPT-4 warm + pruneDraft a letter apologising to a customer for shipping a wrong product.24.80.6cold startauthentic notes Altern Messageanti Modal cargo return14.40.5warm startWrite a customer service responseutions im received the wrong item?.0.90.1warm + fluencyWrite customer service response pagelip wheneverin received the wrong thingunosObj Pala(\"1.70.2warm + prunevolunte Develop Develop footer amenuy f fort reply for shipping a wrongqtve5.40.4",
  "Ground truthImagine you are talking to a customer who is looking for advice on choosing a phone system. Write a reply that provides relevant information and outlines the benefits o0.00.0": "GPT-4 warmI am tasked with finding a new phone system for my company. Can you provide some guidance on factors to consider?36.20.9GPT-4 warm + fluencyWhat should I consider when choosing a phone system for my business?38.50.8GPT-4 warm + pruneI am tasked with finding a new phone system for my company. Can you provide some guidance on factors to consider?36.20.9cold startPref uting ParDATE free umber call24.40.5warm startPlease svolould anotherpat prospect a choosing phone systemNov!!!Hello))] indschlieend telling buyn Sricroclou7.40.4warm + fluencyinterviewyou bud Remative choosing a phone systemYou Di console10.20.6warm + pruneNeu strategbir conversation smiledbara Zach selects phone system((dbkovtele valleTERew some guidance vs usopeserver solutions10.60.5",
  "Reword this sentence:I started eating healthier.0.00.0": "GPT-4 warmExplain how you made improvements to your eating habits.41.80.7GPT-4 warm + fluencyExplain how you made improvements to your eating habits.41.80.7GPT-4 warm + pruneNarrate the changes you made to transition to a nutritious diet.44.10.7cold start began craw higher 23.80.9warm startDurch conver)/ made improvements to your eating habits Comment23.90.6warm + fluencyhe keen Has commence improvements Story your eating habits.26.70.6warm + pruneTHEN begiae You conversionnumerableDC beginjor to platejdaeious diet.17.70.7",
  "Ground truthGive 5 examples of common family values.0.00.0": "GPT-4 warmCan you share examples of widely accepted family values?9.00.6GPT-4 warm + fluencyWhat principles do most families abide by?16.90.8GPT-4 warm + pruneWhat values does a typical family have?16.60.6cold startsome Organ msorsedom)|family principles common12.30.5warm startletzten bott Five examples of common family valuesily2.20.2warm + fluencyexamplesT most families valuesetaips Activ8.00.4warm + prunegreat values some proved For family Family importance11.40.4",
  "Ground truthSuppose you have a table named \"transactions\" with columns \"transaction_id\", \"customer_id\", \"transaction_date\", and \"amount\". Write a SQL query to find the custome0.00.0": "GPT-4 warmHow to use SQL to find customers who boosted their spending the most from last month?34.10.6GPT-4 warm + fluencyShow me a SQL query to track customers with major spending increase.35.80.8GPT-4 warm + pruneShow me a SQL query to track customers with major spending increase.35.80.8cold start`). highest BY percentageNext unique customer cambio WHEREoto23.70.4warm startMievementtransaction SQL to find customers icional spendingSeconds ltimacioembroila Mediter17.40.7warm + fluencyandra terminated SQL}- Best Prim customers/J spending increase percentage21.20.4warm + prunenicely sqlatically YES Newton percentage easiest customersaavik Mercurlige reun Similar22.20.6",
  "GPT-4 warmWhat is the meaning behind the phrase 'I see not the waves but the hand of God'?1.20.3": "GPT-4 warm + fluencyWhat does the phrase 'I see not the waves but the hand of God' suggest about a person's perception or belief?13.00.4GPT-4 warm + pruneExplain the phrase 'I see not the waves but the hand of God' in spiritual context.5.20.4cold starttimes()) jakovisualisin phrase diedpal 36.80.4warm startWhat is the meaning behind the phrase 'I see not the waves but the hand of God'?1.20.3warm + fluencyWhatiat the meaning 'I see not the waves but the hand of God' SeeEnter for whole dipp on trbr0.60.1warm + pruneExplain the phrase 'I see not the waves but the hand of God' most ico practices1.00.2",
  "Ground truthCompare and contrast active listening and regular listening.0.00.0": "GPT-4 warmWhat is the difference between active and regular listening?5.30.7GPT-4 warm + fluencyExplain the difference between active listening and regular listening5.10.7GPT-4 warm + pruneIn what ways does active listening differ from regular listening?11.10.6cold startj pr lime differences active ant usual13.50.8warm startpriewererve difference between active and regular listeningUP4.70.7warm + fluencyfers outline between|| active listening and regular listening3.70.5warm + prunedess DISifferent doesactive listeningouv from regularLE catalog6.10.7",
  "Ground truthDescribe the definition of artificial intelligence in one sentence.0.00.0": "GPT-4 warmExplain the concept of Artificial Intelligence in the context of Computer Science.10.90.9GPT-4 warm + fluencyProvide a description of Artificial Intelligence with focus on learning and problem-solving.10.60.9GPT-4 warm + pruneExpress the idea of Artificial Intelligence in relation to machine and human intelligence.10.70.9cold start artific#{defin poz Spanish3.70.4warm startExpsimp the concept{: Art beskrevscipl nelligenceieve prod alive rii2.80.4warm + fluency Powdefined description Artificial elligenceaddyposed zelfLOGclruction jourocoaydrorit2.90.4warm + pruneExpress isolated summary ofbertoificialTelligence;ONEanely expressionfnatically ba2.70.4",
  "Ground truthDesign a product to help people manage their time0.00.0": "GPT-4 warmDescribe a time management app that uses machine learning algorithms.32.91.0GPT-4 warm + fluencyExplain the features of an AI-powered digital assistant that helps with time management.38.00.8GPT-4 warm + pruneWhat could a product that combines a digital calendar and a to-do list look like?39.21.0cold starthelpful functionality personaod}}_{\\ building theretimer Rphon21.40.7warm startmake a time management product that Products Temp11.60.5warm + fluencyproducts ideiszd problema provpoleurbceu component Product that helps persons time management12.30.5warm + prunekre ingename product that Done timparaza Simstereianhapasrim designeduta providing routine14.60.5",
  "The students are excited about their upcoming assignment.0.00.0": "GPT-4 warmRewrite 'The students are excited about their upcoming assignment.' to display greater eagerness.20.40.7GPT-4 warm + fluencyProvide a more impactful version of 'The students are excited about their upcoming assignment.'16.50.7GPT-4 warm + pruneProvide a more impactful version of 'The students are excited about their upcoming assignment.'16.50.7cold starttheseStudent asto ignment verb fast32.70.7warm start- 'The students are excited WM their coming assignment.' analy stronger CM odd Lamb12.40.5warm + fluencyprotection sentence again more effective? eleThe students are excited coming assignment.~12.50.6warm + prunesentence somehowint more sypent strong LIKE MeThe students are excited incon ninger aos assignment.'15.10.5",
  "Ground truthOffer an opinion on the problems that could arise from using AI.0.00.0": "GPT-4 warmWhat are some issues that might be caused by the use of AI?14.00.5GPT-4 warm + fluencyHighlight key problems linked with AI implementation.20.80.7GPT-4 warm + prunePoint out some possible challenges that could be seen with the use of AI.18.10.6cold startskesome m Eth convenienceffectpport humans Problem14.30.5warm startTrue problem vil caused use zou AI4.30.4warm + fluency problemselles Vit AI consequences7.00.4warm + pruneProblem thingsptop affili subsequentlyrong that could positeso je okay use onto AI.4.60.4",
  "Ground truthOutline a strategy to increase the number of website visitors0.00.0": "GPT-4 warmHow can I attract more visitors to my website?24.91.1GPT-4 warm + fluencyHow to increase the number of website visitors?14.70.9GPT-4 warm + pruneWhat are possible strategies to increase website traffic?26.81.2cold start increaseouc websiteuscation visitors~$\\ Phys11.60.6warm startincreasing nuctb visitorsStrategy websiterules10.70.5warm + fluencyplan Sul increase lenClienteton website visitors strategy6.40.3warm + prunewritearu Nation strategun toIn website countasm11.10.5",
  "Ground truthI need some help with packing. What items should I bring on my two-day hiking trip?0.00.0": "GPT-4 warmTell me what to bring on a two-day hiking trip.4.80.4GPT-4 warm + fluencyWhat essentials should I pack for a two-day hiking trip?10.40.8GPT-4 warm + pruneProvide a packing list for a two-day hiking trip.9.00.4cold startCaliedom DAYPack everything set17.10.4warm startSte me what to bring mu po two-day hiking trip mult3.40.3warm + fluencyQuestionmustFzej I pack for curious two-day hiking everitted5.10.3warm + pruneonders suooret packing necess for a two weldayanhikingSide II6.20.4",
  "Ground truthConstruct a hyperbole that captures the color of the sunset.0.00.0": "GPT-4 warmExplain the elements and beauty of a sunset, using hyperbolical expressions.17.20.9GPT-4 warm + fluencyDescribe a breathtaking sunset sky in the evening. Include hyperbole.17.01.1GPT-4 warm + pruneDescribe a breathtaking sunset sky in the evening. Include hyperbole.17.01.1cold startOg ikkenm Exper sak sundial splendid25.30.7warm startKeep nit compl sunset using hyperbolt expressions8.30.6warm + fluencyrianmu emissionbg sunset. Include hyperbole7.50.5warm + prunerightomenafox\"> Trainrongothe sunset Color Hendarin?} Include hyperbole.5.70.5",
  "Ground truthDescribe the star formation process.0.00.0": "GPT-4 warmWhat leads to the creation of new stars?16.30.7GPT-4 warm + fluencyDescribe the process by which a star is formed.13.20.5GPT-4 warm + pruneWhat is the star formation process?0.70.1cold startstronom hoofgoteqnctionroduction simaterial formed5.30.2warm startProdu bundculescation of` stars efect4.40.2warm + fluency ensiveSeqarfuce describing star* formed monde3.50.2warm + pruneWhat is the star formation process?0.70.1",
  "Ground truthName two electrical insulators.0.00.0": "GPT-4 warmWhich two materials are often used as electrical insulators?8.70.6GPT-4 warm + fluencyWhich two materials are often used as electrical insulators?8.70.6GPT-4 warm + pruneList two common electrical insulating materials18.30.3cold startaames two electro common Einwohner `' inspect7.50.6warm startfasst two Namen ihrererme heat Gem electaler insulators 3.50.3warm + fluencyGive two '_ electrical insapter Cel3.50.3warm + pruneagua two common electdk insulatinguls5.40.5",
  "Ground truthGenerate an original story set in an urban cityscape.0.00.0": "GPT-4 warmDescribe a bustling city from a third-person perspective.17.90.8GPT-4 warm + fluencyDescribe a bustling city from a third-person perspective.17.90.8GPT-4 warm + pruneDescribe the atmosphere of a bustling city during sunrise.28.80.9cold start---+write Urban cgi fictionStory4.50.4warm startra pr story ffe city generate third-personASSISTANT6.50.5warm + fluencywrite fake Storyauc minim novel sub third -person vercity5.20.5warm + pruneingerssten stories scen of a um nerting critinc cityenarioHS7.50.4",
  "Ground truthDesign an indoor workout plan for a beginner.0.00.0": "GPT-4 warmHow can a beginner start working out indoors?15.70.4GPT-4 warm + fluencyWhat would be a good indoor workout for someone just starting out?14.40.4GPT-4 warm + pruneCan you recommend an indoor exercise routine for beginners?17.30.5cold startanda mn exerciseHelpWTtr alap bir wobinter19.10.4warm startski plat a beginnerzysk working out indoorslaz7.50.3warm + fluencyaoelterWrite uni indoor workout forabendor starting outGenerator3.70.3warm + prunepraresdefineaugh indoor Desior for beg Bahtero4.20.3",
  "Ground truthDescribe the opportunities provided by virtual reality for businesses.0.00.0": "GPT-4 warmWhat are some opportunities Virtual Reality offers for businesses?4.50.3GPT-4 warm + fluencyDiscuss the potential of Virtual Reality in business16.50.7GPT-4 warm + pruneWhat are some opportunities Virtual Reality offers for businesses?4.50.3cold startwicht battleottom opportunhy Virtual msrainy10.40.5warm startWhatlyt opportunien Virtual relality_ for business it3.20.3warm + fluencyOptionsnunto potential of Virtualvricrosoftordo business7.80.4warm + pruneWhat are some opportunities Virtual Reality offers for businesses?4.50.3",
  "Ground truthSuggest a creative idea for a marketing campaign.0.00.0": "GPT-4 warmWhat kind of engaging social media scavenger hunt could work for a marketing campaign?35.80.8GPT-4 warm + fluencyWhat kind of interactive marketing campaign idea using augmented reality could be proposed?33.50.6GPT-4 warm + pruneWhat kind of engaging social media scavenger hunt could work for a marketing campaign?35.80.8cold startMarketicangest recomm ideas cre ativo5.90.3warm startree ractiencyixel creino y Eine marketing idea10.00.3warm + fluencyone istichteigi marketing campaign Creative l idea amaz cool4.60.3warm + prunes P couidedression indu Task:// Give re couldinea trick Ch marketdri campaign?9.90.3",
  "Ground truthSuggest a location for a weekend getaway.0.00.0": "GPT-4 warmCan you suggest a unique weekend vacation spot?19.00.6GPT-4 warm + fluencyCan you recommend a good location for a weekend trip?12.80.4GPT-4 warm + pruneCan you recommend a good location for a weekend trip?12.80.4cold startLocationt siebenFrdays choice miejsikor17.30.6warm startMediainitely suggest a/` weekend vacskchhppreme10.20.4warm + fluency})^/? whisper a good location for a weekendpus4.00.3warm + prune recommend a good location for a weekendlob hus5.30.4",
  "Ground truthCreate a recipe titled \"Chocolate Chip Cookies\".0.00.0": "GPT-4 warmWhat are the ingredients for Chocolate Chip Cookies?6.90.3GPT-4 warm + fluencyWhat are the ingredients for Chocolate Chip Cookies?6.90.3GPT-4 warm + pruneCan you provide a basic recipe for Chocolate Chip Cookies?5.20.2cold startDevelop Qual Charles reciCookie some Description6.70.3warm startaturing donneiffe Makeredients for Ch testimMaybe campelice Cookiescoln3.20.2warm + fluencyGive Rhnadd pract Cholate Clasc Cookies2.70.2warm + prunerestaortheastri Ara Make recipe for Chwritingolate Basicallycra Cookiesvas1.90.2",
  "Ground truthCreate a task for a virtual assistant to remind you to call your mom every Tuesday0.00.0": "GPT-4 warmHow do I make my virtual assistant remind me every Tuesday to call my mom?28.00.4GPT-4 warm + fluencyIs it possible to set a recurring reminder to call my mum every Tuesday?41.90.7GPT-4 warm + pruneHow do I make my virtual assistant remind me every Tuesday to call my mom?28.00.4cold starts household chat occasionally todoseast rem telert33.10.7warm startMov'+., make my virtual assistant remMake me every Tuesday to call Ir momTC17.90.3warm + fluencyduties ent )\\, Without$}}% fac)). reminder toIOS my mum every TuesShellcfg19.00.6warm + pruneMenuotingvisor simply edit Govern Ern remind me every Tuesmath to callspot mom Jorge16.50.5",
  "Ground truthGenerate two new features which the IoT device can provide.0.00.0": "GPT-4 warmWhat two new features could an IoT device provide to improve medical treatments?29.60.8GPT-4 warm + fluencyWhat are two potential features that an IoT device could provide?19.50.7GPT-4 warm + pruneDescribe two new features that an IoT device can provide to enhance a smart farm system.23.70.7cold startimmer propose features twov Ep io podeen smart16.90.5warm startchoose two new features Here Io device provide Worldastic////////spaces&&More6.00.4warm + fluencyfurther spe two potential features r Io device will provide8.40.5",
  "Ground truthInvent a computer gaming character that uses magic.0.00.0": "GPT-4 warmDescribe a powerful and enigmatic gaming character who can use magic, call her Luna31.00.9GPT-4 warm + fluencyGenerate a computer gaming character who can use magic named Phoenix Blackwood27.30.7GPT-4 warm + pruneGenerate a computer gaming character who can use magic named Phoenix Blackwood27.30.7cold startimagination character Creatingcovertypen descriptGS combat enemies24.21.2warm startDescri a futdg kin pon/) computer gaming character whom use magic Until app AUT4.90.3warm + fluencynagine a computer gaming character who= ung magicFAjer serer4.10.4warm + pruneGenerate a computer gaming character whoedia use magic Krist innov tutorialswood4.40.4",
  "Ground truthCreate a three-step recipe for making banana bread.0.00.0": "GPT-4 warmCan I have a simple recipe to make banana bread?15.21.1GPT-4 warm + fluencyTell me a good recipe to prepare banana bread.15.61.1GPT-4 warm + pruneWhat are the steps to make banana bread in the oven?12.00.8cold startman drieBrnavnosimorening reciple10.00.5warm start techniibm BY steps maj drei Prem banana bread Demo5.90.2warm + fluencySta moi isserfalichtet Mic banana bread5.40.4warm + pruneBu have little steps pel any banana breadleyirty betstep menu7.00.5",
  "Ground truthDevelop an algorithm to optimize a grocery store s stock replenishment process.0.00.0": "GPT-4 warmWhat could be the steps in an algorithm aimed at optimizing a grocery store's stock replenishment process?7.50.4GPT-4 warm + fluencyWhat are the steps in optimizing a grocery store's stock replenishment process through an algorithm?13.40.5GPT-4 warm + pruneCan you give me an algorithm to optimize a grocery store's stock replenishment process?3.20.3cold startfo sav optimRedurst storesorithmsekreate27.70.3warm startWE Musical Typeirit an algorithm rational sure optimizingacs grocery store's stock revtim process2.70.2warm + fluencylid maxim the steps in optimUnder gro ery store$:s stock re pro Find thoroughlyriction an algorithmElement5.70.4warm + prunewrite algorithmsling carre an algorithm which optimize a grocery store'uals stock replaceaeishment process?2.00.2",
  "Ground truthDescribe how one person can make a positive difference in the world.0.00.0": "GPT-4 warmDelineate the ways one person can trigger positive change.25.00.4GPT-4 warm + fluencyList ways a single person can make a positive change in the world.23.30.5GPT-4 warm + pruneHow can an individual make a positive impact?26.40.4cold start nt n %% Orts medioprowad15.60.4warm startWe bbidr ways one person DaBE positiveuela specie12.50.3warm + fluencyduct wen Ke single person can gn positive thingGitives world erhielt8.20.4warm + prune------------ Whe anyone individual make Fo positive differentething13.50.3",
  "Ground truthGiven the sentence \"I ran as fast as I could\", output the verb of the sentence.0.00.0": "GPT-4 warmWhat is the main verb used in the sentence 'I ran as fast as I could'?15.90.5GPT-4 warm + fluencyWhat is the verb of the sentence 'I ran as fast as I could'?2.20.3GPT-4 warm + pruneIdentify the verb in the statement 'I ran as fast as I could'.13.80.6cold start\"?>ver)-- velocity*( proceeded']); excitement25.40.6warm startWhataaria verbzialorr the sentencecli ran as infl Appro/>jakicket7.20.4warm + fluencyWhat is the verb of the sentence 'I ran as fast as I could'?2.20.3warm + pruneIdentify the verbting football Street 'I ran as fastnie OF could'.6.60.4",
  "Ground truthCompare and contrast Integer and Floating-Point Number0.00.0": "GPT-4 warmCompare and contrast integer and floating-point numbers used in computers.6.90.4GPT-4 warm + fluencyCompare and contrast integer and floating-point numbers used in computers.6.90.4GPT-4 warm + pruneDiscuss the characteristics and differences of integer and floating-point numbers in computing.11.40.5cold startInteger Formattp dtummalparison/6.10.4warm startCompare and contrast integer and floating- fe dll erfolgte explaining.2.20.2warm + fluencyCompare and contrast integer and floatingdlie Term fjriginal truncniejs1.90.2warm + prunechoardlershal elabor differences of integer and floatinghardpoint numberswebazaresp3.40.4",
  "Ground truthCompute the sum of all numbers from 1 to 100.0.00.0": "GPT-4 warmFind the sum of all numbers from 1 to 100 by adding them consecutively10.70.7GPT-4 warm + fluencyTell me the sum of all numbers from 1 through 1008.20.4GPT-4 warm + pruneCompute the sum of all numbers from 1 to 1000.00.0cold startammituTotal simplest ComputtutorialDer nmer Kaiser11.40.4warm startennisogen sum of all numbers from possono Iazi7 computational into3.20.2warm + fluencyzeti sum of all numbersLngurn Ex throughg1004.40.4warm + pruneCompute the sum of all numbers from 1 to 1000.00.0",
  "GPT-4 warmWrite a reflective piece on love being a force of nature.13.71.1": "GPT-4 warm + fluencyDiscuss the nature of love as a binding force.14.61.5GPT-4 warm + pruneWrite a reflective piece on love being a force of nature.13.71.1cold start). Use Love escri William alemwrite~~~~~~~~5.50.5warm startcompos a/. piece on love Zb[4.00.5warm + fluencysufficientlyiving the nature of loveinsert phr using chant5.30.4warm + pruneKolref Small emot piece on love_; efficient Terredes alto syntax3.50.4",
  "Ground truthFind the tenth largest city in the world in terms of population.0.00.0": "GPT-4 warmWhat is the tenth largest city in the world by population as of 2021 and what is it known for?13.90.5GPT-4 warm + fluencyCan you provide information on the tenth most populous city in the world as of 2021?17.00.4GPT-4 warm + pruneProvide details on the city that holds the tenth position in world population as per 2021 data.11.90.4cold start religion|={\\Footnote Centre %)}23.30.4warm startWhat tenth largest cidade orazEE world cl population Gu Br humanstucludeE PicSal Parlament\":\"2.50.2warm + fluencyenaee information tk Know enth sprach city in worldways kaime hasnk largest4.30.2warm + pruneClick or detailsizen parishinction that municipal the tenth leads in world population as firefoxmesRAMHub *** NE inhabitants Ubuntu5.30.3",
  "Ground truthCalculate the total surface area of a cube with a side length of 5 cm.0.00.0": "GPT-4 warmWhat is the standard method for finding the total surface area of a cube?11.30.6GPT-4 warm + fluencyDescribe how to find the total surface area of a cube.9.10.6GPT-4 warm + pruneWhat is the calculation for determining the total surface area of a cube?5.30.7cold startszereowaniacement dio TRalph Bal calculate6.60.3warm startpi Polishzenia Stanis awzig quez total surface area igue cube \"@3.50.4warm + fluency computer <!-- How total surfacemathcal Oh cube three3.00.3warm + prunejesamiraf calculation Sarahhnitementfig total surface I of Writing cube?3.20.3",
  "Ground truthCollect two example of how AI is being used positively in healthcare.0.00.0": "GPT-4 warmWhat role does AI play in disease diagnosis?26.21.0GPT-4 warm + fluencyHow is AI applied in medical imaging?27.81.1GPT-4 warm + pruneCan you provide information about early disease detection through AI?28.31.0cold startining ai followed abitsersmense technologyThree examples medical8.71.0warm startroughly three Things AI bestexamples disease wecss Low10.20.9warm + fluencyHowK AI applied includes medicalo noticed=-12.70.9warm + prunecreate detail huge Pro things built disease key huge AIigs12.31.1",
  "Ground truthHow can an online retailer optimize their website for SEO?0.00.0": "GPT-4 warmDetail the steps needed for an online retailer to optimize their website for SEO.9.60.7GPT-4 warm + fluencyDescribe best practices in optimizing an online retailer website for SEO.11.30.6GPT-4 warm + pruneDescribe best practices in optimizing an online retailer website for SEO.11.30.6cold start}}%Description ologieas storepto web indexingeclipse24.80.6warm startdigitalcketsHow an online ret esper optimizerier website SEG3.30.2warm + fluency v ioso eyes b online retailer optimization for SEalion5.00.2warm + prunevari elementaryhow jTe optimizedills An online ret Can Hob bow for SE optimnap6.20.3",
  "Ground truthWhat is the major cause of the ice age?0.00.0": "GPT-4 warmDiscuss the factors contributing to the Ice Age14.70.6GPT-4 warm + fluencyIdentify the causes of the last Ice Age21.10.8GPT-4 warm + pruneWhat was the major cause of the ice age?2.20.2cold startrees IEDieason NobelEnvironment historia global dall seasons20.10.6warm startanything nach caused g wnoug kw Ice Age10.40.5warm + fluencyoeMain? causes oicallyb Ice Age7.60.4warm + pruneWhat was the major cause of the ice age?2.20.2",
  "Ground truthName a drink that is high in sugar content.0.00.0": "GPT-4 warmGive an example of a sugary drink and discuss its contents.29.00.6GPT-4 warm + fluencyDescribe a beverage notorious for being rich in sugar content.17.40.5GPT-4 warm + pruneWhat is an example of a drink high in sugar content?8.80.5cold startarg jed kter p food19.60.4warm startGive among requ cuales sugagyar drink Dieser.- erg contents 11.00.3warm + fluencyD beverageanha qual Ann rich in sugar content Mar4.30.3",
  "Ground truthFind a metaphor for the term \"data storage\".0.00.0": "GPT-4 warmHow can we explain 'data storage' using a metaphor?11.41.0GPT-4 warm + fluencyHow can we explain 'data storage' using a metaphor?11.41.0GPT-4 warm + pruneCan you provide a metaphor for how data is stored in computer systems?30.10.8cold startCon atalog worthy memory equivalent adata22.60.7warm startdescribesle explain Anotherdata storage palab usingaphor10.20.4warm + fluencynejmileATION species 'data storage'? metaphor?4.60.4warm + prunedefinite-( provide a metistolhor Thisseur datasm storedaoding ierz7.80.4",
  "Ground truthWrite a review for a book of your choice.0.00.0": "GPT-4 warmWrite a short review of 'The Master and Margarita' by Mikhail Bulgakov26.50.7GPT-4 warm + fluencyGive me a brief review 'The Power of Habit: Why We Do What We Do in Life and Business' by Charles Duhigg26.40.6GPT-4 warm + pruneGive me a brief review 'The Power of Habit: Why We Do What We Do in Life and Business' by Charles Duhigg26.40.6cold startly:[ |book review3.60.3warm startWrite clever Book reviewSample referenced livres ln immedi inteNode tfOr}-\\3.80.3warm + fluencyGive \"< a brief review encou previous folg Share Why Author Hels literarygeqorldimetidel listopadadob #[ Reading Longchoose5.60.5warm + prunedetailed improved a approximate review atom important writeiane Anderson sample Ang earned genu Ash please Johann @school fiction throws' by Charles Bud Urw9.40.6",
  "Ground truthGenerate a media query that makes the content scale to device width0.00.0": "GPT-4 warmWhat would a media query that scales web content to the device width look like?21.40.6GPT-4 warm + fluencyHow would I use a media query to make web content scale to fit the width of a device?25.00.7GPT-4 warm + pruneWhat would a media query that scales web content to the device width look like?21.40.6cold start skalcontent sad resize wys device media Clo22.30.6warm startSaintRU media query that scales content aller device width Sheralement9.80.4warm + fluencyJust \"; mostraesh media query s make Was content scale to trait widthzenie6.10.4warm + prunecel dass Une media query that scales make content Hem zum device width anythingjascro8.30.3",
  "Ground truthGenerate a list of activities that can be done at the park.0.00.0": "GPT-4 warmHow can one spend time at the park?12.40.4GPT-4 warm + fluencyWhat options are available for spending time at a park?15.80.8GPT-4 warm + pruneHow can one spend time at the park?12.40.4cold startwetored actsility liste 18.60.6warm startSynct varios wor Types at the park9.50.3warm + fluencylists activities wz crossing TViohart at> park6.10.3warm + prunenell things culDN THE at the park Done6.70.2",
  "Ground truthCreate a news headline based on the following event, \"A student won a competition in quantum computing\".0.00.0": "GPT-4 warmShare a news article about a high school student winning a quantum computing contest.40.61.0GPT-4 warm + fluencyTell me a story about a student winning a major quantum computing competition.45.80.8GPT-4 warm + pruneNarrate an event where a student wins a quantum computing competition and plans a future in AI.46.60.7cold start\"' computers quantum Che Academy/\" PotWrite29.70.7warm startWriting news susp headerdc ii ng student winning AN quantumllynisan12.80.7warm + fluencyString comEntry about student winningbi intitul quantum computing nehmer17.20.7warm + prune Equategia eventolen tan student wins a quantum computing competition \"\"ften News format these egyangi12.70.5",
  "Ground truthCreate a data model for a driver on a car-sharing platform0.00.0": "GPT-4 warmCan you provide an example of a data model for a driver on a car-sharing service?15.90.4GPT-4 warm + fluencyDesign a sample data model for a driver in a car-sharing platform.11.40.3GPT-4 warm + pruneCan you provide an example of a data model for a driver on a car-sharing service?15.90.4cold startoperationsppets draw representative Csrovski DriveOwner26.70.4warm start bright cra uminatew data model for a driver on a carlackstaden1.60.2warm + fluencyDesign data model for a driver i carls exer platformine2.50.2warm + pruneurd Borurt Halercreate a data model for a driver on a car- shcompat knockuminate1.00.2",
  "GPT-4 warmCan you suggest some similar adjectives rhyming with 'high'?23.71.1": "GPT-4 warm + fluencyList a few adjectives that rhyme with the word 'high'25.11.4GPT-4 warm + pruneProvide six adjectives that rhyme with 'high'27.41.1cold start conjug descriptionowyrible saydj mit30.70.8warm startDet nc m adjectzie rhym __ 'high'13.80.7warm + fluencyGet a presenta adject rhymeographic dic should 'high'10.60.6warm + pruneanje convenetti adjecttorIVE rhyme descript 'high NA10.00.6",
  "Ground truthCreate a workflow to automatically classify emails as either important or not important.0.00.0": "GPT-4 warmWhat are the steps to automate classification of emails as important or not important?25.40.7GPT-4 warm + fluencyHow can emails be automatically classified as important or not?32.70.4GPT-4 warm + pruneDescribe a workflow to automatically classify emails as important.17.40.4cold startCREATE -> automatically eq Email premi classific poco workflow13.60.3warm startwarprov steps autom Hav classificationligen emails != importanterr foflow11.60.4warm + fluency emails automatically importantFlowfo 18.70.4warm + prunehus> a workflow to automatically classify emailsMail important clo5.80.2",
  "Ground truthWhat is a link building?0.00.0": "GPT-4 warmDefine link building in SEO context5.60.2GPT-4 warm + fluencyWhat is link building and why is it important?1.00.2GPT-4 warm + pruneWhat is link building and why is it important?1.00.2cold startificaencingdefinition Business ( nofollow Lob referencing miejs2.10.2warm startDefine link building Sebast (',BU0.20.1warm + fluencyWhat is link building and=\"\"anaiella--\"0.00.1warm + pruneWhat is link building andswerishesically Nelson Mario0.10.1",
  "Ground truthList two potential problems that companies may encounter when implementing AI systems.0.00.0": "GPT-4 warmWhat are some challenges companies might face when incorporating AI systems?26.71.2GPT-4 warm + fluencyExplain some potential problems related to implementing AI in a business context.21.61.2GPT-4 warm + pruneWhat potential issues might arise from implementing AI systems in businesses?26.41.4cold startkindsomenaPriceelijkedogFailurebers concerningAI25.91.4warm startConfigurationnes Stone Two companies wont face when V AI systemslections12.60.5warm + fluencystwo Second potential problemsN Altri implementing AI corporhatpent They11.10.6warm + pruneconserv Problem issues c prometers implementing AI systems epis illustrateMENT Oracle18.10.7",
  "Ground truthFind the hypotenuse of a right triangle with sides 3 and 4.0.00.0": "GPT-4 warmWhat is the role of the hypotenuse in a right triangle?23.80.8GPT-4 warm + fluencyDescribe the steps to calculate the hypotenuse in a right triangle with sides 3 and 48.10.3GPT-4 warm + pruneDescribe the steps to calculate the hypotenuse in a right triangle with sides 3 and 48.10.3cold startouthler triangleDistancesn~$\\jboss Baden10.40.7warm startFripred${ `; hypoten HochAff right triangle7.10.7warm + fluencygivelapat Whe toeston the hypoten Sky mostVC right triangle sides 3 and 42.70.2warm + pruneonianbeinois steps erm the hyptaedic in a right triangle cols sides 3 and 44.20.2",
  "Ground truthExplain the basic components of a relational database.0.00.0": "GPT-4 warmWhat parts or structure does a relational database have?5.30.3GPT-4 warm + fluencyCan you explain the structure of a relational database?6.20.3GPT-4 warm + pruneWhat are the basic components of a relational database?1.70.2cold startdefining basicrale parts component Plaserticionalliche Datenbank1.90.2warm start> partsvers]\" does a relational database have?4.60.2warm + fluencyrepublic Or explain complete structureever cried repre databasecomponents4.90.2warm + pruneinding vitalouch basic components concerningyp relational databaseak1.60.1",
  "Ground truthWhat are the pros and cons of using a database management system?0.00.0": "GPT-4 warmHighlight the pros of using a Database Management System13.30.6GPT-4 warm + fluencyWhat's advantageous about a Database Management System?21.20.9GPT-4 warm + pruneWhat are the pros of using a Database Management System?13.80.6cold startPro conjconsdri databme <!-- graceyond ww6.80.3warm startDig closely provide pros cor explan myster Database ManagementHT6.50.4warm + fluency? porolf opposed reasons princip Database prosqi10.20.3",
  "Ground truthGenerate a recipe for a vegan version of a Caesar salad0.00.0": "GPT-4 warmWhat are the ingredients required for making a vegan Caesar salad?6.90.4GPT-4 warm + fluencyCan you provide a vegan Caesar salad recipe?4.40.4GPT-4 warm + pruneWhat are the ingredients required for making a vegan Caesar salad?6.90.4cold startHen Pat Build vegcrian c hum9.20.4warm startModageroweazzoredientszu for vegan Caesar sal Makigner3.60.3warm + fluency!} Comprics a vegan Caesar sal How \"\"\" example 2.80.3warm + pruneulations rabb the stepsredientslicatedij Johan a vegan Caesar salad?3.00.3",
  "Ground truthSolve the following linear equation: 2x + 5 = 200.00.0": "GPT-4 warmExplain how to solve a linear equation using substitution method.39.80.7GPT-4 warm + fluencyWhat are the steps to solve a linear equation using the variable substitution?39.20.8GPT-4 warm + pruneDescribe the steps to solve the equation 2x + 5 = 20 using algebra.20.00.6cold startlect ac s equations Line:[ (/ solving Bas13.60.4warm startz hundredlichen solve y linear equation XX\"+ Ze9.70.4warm + fluencynmer)}. amount.]( solve linear equation Mic elementary )](9.20.3warm + prunealetLSLECTholmilibiwks numerical 2x +undle5 = bere20lakPaf4.10.2",
  "Ground truthCome up with lyrics for a rap song about ice cream.0.00.0": "GPT-4 warmProvide a rap verse about the deliciousness of ice cream.8.70.6GPT-4 warm + fluencyWrite a verse for a rap song about the joy of eating ice cream.11.00.6GPT-4 warm + pruneProvide a rap verse about the deliciousness of ice cream.8.70.6cold startn icedneyote create sweet Hook vers19.60.6warm startnek rapiro aboutweus pelosltal of ice cream songs4.80.4warm + fluencyWrite perceprototype rap song about lets'][' genre richtung ice cream.2.90.3warm + pruneitzenitzen song rapovis about theinceiciousasi of ice cream.4.10.4",
  "Ground truthWrite a story about a cook who is helping someone find a lost treasure.0.00.0": "GPT-4 warmShare a fable about a skilled and resourceful cook named Maria living in a quaint little village27.61.0GPT-4 warm + fluencyTell a story about a talented cook named Maria21.51.2GPT-4 warm + pruneCreate a story about a cook named Maria who lives in a coastal village and is famed for her seafood dishes33.31.3cold startune}}_ vez servi placed lado manipulate stir vehicles17.90.5warm startCreating fable MedABASE v pesso cook named diesescolonission mystery Geography SynBel6.50.5warm + fluencyBranch faint story about t =~ cook---- Main7.90.5warm + prunec a story worn a cookM pseudo incor SmP Ther Security wise bere Friend deput,,uld proposition attra sea destruct grown oracle representations4.70.5",
  "Ground truthGenerate an equation that describes a line's slope.0.00.0": "GPT-4 warmDescribe the formula for the equation of a line's slope.6.20.6GPT-4 warm + fluencyHow do you represent the slope of a line mathematically?22.30.8GPT-4 warm + pruneTell me what equation describes the slope of a line.9.30.7cold start Mittel slope:\\\\ equations)/ How melyequals8.60.4warm startbegann eqnarray formulanablaasterilsactr a line's slope id5.60.3warm + fluencyChe equations`' that slope of describes linerTemp Bib6.80.5warm + pruneSueManager what equation describesowy slope ?? leg sopbor4.60.3",
  "Ground truthConstruct a chain of five words beginning with the letter 'Q'0.00.0": "GPT-4 warmProvide a chain of five words each starting with 'Q'.3.00.4GPT-4 warm + fluencyCan you provide a sequence of 5 words starting with 'Q'?6.00.7GPT-4 warm + pruneList five words starting with the letter 'Q'.11.20.9cold startword Queens quit logo Quint.....QL quasiwerp kindly22.40.9warm startProvide a chain of five words each starting with 'Q'.3.00.4warm + fluencyCan you provide a sequence of 5 words starting with 'Q'?6.00.7warm + prunepens five wordsnx Using consecesome 'Q'.8.80.7",
  "GPT-4 warmTell me about different ways to mitigate the effects of climate change.19.50.7": "GPT-4 warm + fluencyDescribe ways to mitigate the impact of climate change.9.00.6GPT-4 warm + pruneWhat are some strategies to mitigate the impact of climate change?11.10.7cold startrecommendedder Windowanie efect poverwei planet12.40.3warm startpr largely ways to mitDNbest the Bitte arnchktet8.40.3warm + fluency meillehow closest mitigateosa impactopf climate znaj4.00.3warm + pruneWhatnov bootomed Most to mitzigaterodu impact of climate aly4.10.2",
  "Ground truthGenerate three investment options for someone who has 10,000 dollars and wants to invest it for 10 years.0.00.0": "GPT-4 warmWhat are some investment options for someone with $10,000 for 10 years14.50.5GPT-4 warm + fluencyProvide an overview of Index funds37.61.0GPT-4 warm + pruneProvide an overview of Index funds37.61.0cold startEconom Then Fortvelop some Fund O options recommendationnou15.80.9warm startprodu some investized options seriously someone will those thousand Jon Andreobileeti Lund Ps10 years9.50.6warm + fluencyDescide figur zwe choose Charlotte types funds21.50.8warm + pruneThree normalied practical solution great Ass funds15.51.1",
  "Ground truthIdentify the associations to the following word: eternity.0.00.0": "GPT-4 warmCan you enumerate some significant associations or ideas related to 'eternity'?12.90.7GPT-4 warm + fluencyCan you enumerate some significant associations or ideas related to 'eternity'?12.90.7GPT-4 warm + pruneCan you enumerate some significant associations or ideas related to 'eternity'?12.90.7cold startistence_ Association sphereemeteryitemize verb references19.20.5warm start mraj obe associations as bere 'eternity'3.90.3warm + fluencyprovideemoti associations Associuy Vers 'eternity' ju4.10.3warm + pruneConilde Santiagoiec Get associations ora eighfo expression 'eternity' Zh4.20.3",
  "Ground truthGenerate a plan for taking care of the environment0.00.0": "GPT-4 warmWhat is a basic plan for improving the environmental health of the planet?27.51.0GPT-4 warm + fluencyWhat are some strategies for leading a sustainable life?35.21.1GPT-4 warm + pruneHow can you take care of the environment?21.30.5cold startplan bag regard environment8.60.5warm startheadj ta plan for TEiah environmental Andre#,R planet mij5.50.3warm + fluencytaking qt pareJ evol ainable lifemaxim19.90.4warm + pruneDet givipt care fo Se environment Pla13.40.3",
  "Ground truthRewrite the following sentence using passive voice: He found the lost key beneath the sofa.0.00.0": "GPT-4 warmWhat is a simple definition of passive voice?61.30.7GPT-4 warm + fluencyCan you give an example that demonstrates the use of passive voice?55.80.7GPT-4 warm + pruneCan you give an example that demonstrates the use of passive voice?55.80.7cold start Their)/CM verb suoiiene42.40.8warm startYou)));imen functional passive voice retained43.30.7warm + fluencyPanekele under zt tett klassx passive voice36.10.7warm + pruneifenutelen rou bemere Dou Sob the located Boh passive voice Bapt38.70.6",
  "Ground truthIdentify the type of pronoun in the sentence \"He had to finish the job.\"0.00.0": "GPT-4 warmIdentify the pronoun and its function in the sentence 'He had to finish the job'10.60.5GPT-4 warm + fluencyLink the pronoun in the sentence 'He had to finish the job' to its grammatical function.11.20.6GPT-4 warm + pruneAnalyze the use of pronoun in the sentence 'He had to finish the job'11.80.5cold startPresn predicate](/ ==\"dirnamedone needed34.60.4warm startIdent discussionive pronoun and its soortER acterHe had to finish the job'7.40.4warm + fluencysym the pronoun in the sentence 'He had to finish the job'ada dinner gram Miss function.6.60.4warm + pruneminister AD Taiingen atmos of pronoun in the sentence 'He had to finish the jobictures8.10.3",
  "Ground truthGenerate a Christmas carol.0.00.0": "GPT-4 warmCompose a Christmas carol about jingling bells.13.50.5GPT-4 warm + fluencyWrite a Christmas carol about a snowy Christmas eve.17.80.7GPT-4 warm + pruneCreate a Christmas carol with a theme of love during Christmas.7.10.4cold startrric Christmasrimiju cler song2.70.2warm startCompose a Christmas carolDelta writev essoaterial1.20.2warm + fluencyWrite a Christmas carolAdd TH Edit Hist Research wear Nav0.50.1warm + pruneCreate zu Christmas car :-). entertainiy wergingfinal poemASSISTANT2.30.3",
  "Ground truthGiven this sentence, \"Software engineering is a challenging field,\" suggest a follow-up question that could be asked. 0.00.0": "GPT-4 warmCan you talk about a software engineering project that challenged you?50.50.9GPT-4 warm + fluencyWhat are the daily obstacles encountered in software engineering?51.90.9GPT-4 warm + pruneCan you talk about a software engineering project that challenged you?50.50.9cold startStructft occupationong)+\\ kdy challengespropri37.20.6warm starticole gareveComment software engineeringQuestion elle challengTHEiy capable26.20.7warm + fluency write question \"[(\\Secallenge engineering skill22.20.8",
  "Ground truthName two ways to aerate soil.0.00.0": "GPT-4 warmHow can I aerate soil in my garden?19.40.5GPT-4 warm + fluencyWhat are some methods of soil aeration?18.60.7GPT-4 warm + pruneCan you provide two methods for aerating soil?11.40.5cold startz d recom wayood twee lors ango leaf23.20.9warm startacter aerate soil kar kt waysierno3.70.4warm + fluency differently fur aking soil aerised d12.20.4warm + prunehandiding provide tworiersible aerating soil Other5.90.3",
  "Ground truthGenerate two interesting facts about potatoes.0.00.0": "GPT-4 warmTell about the nutritional benefits of potatoes27.30.5GPT-4 warm + fluencyExplain the linguistic origin of the word 'potato'34.00.6GPT-4 warm + pruneExplain the linguistic origin of the word 'potato'34.00.6cold start otros Palt kr information Britain ska15.70.4warm startMany proven ften proofsinformationfan of potatoes10.00.4warm + fluencyany.' knowledgezenfact, some fact Pan potato ri6.80.3warm + prunecussion wanted Tow Fact interestingppets ofiecveycilepotato 2.60.2",
  "Ground truthCreate a list of steps people can take to reduce their risk of catching a cold.0.00.0": "GPT-4 warmTell me what precautions I should take to avoid catching a cold.18.51.0GPT-4 warm + fluencyWhat are some ways to prevent the common cold?18.70.8GPT-4 warm + pruneTell me what precautions I should take to avoid catching a cold.18.51.0cold startGib bben positiveirus steps13.20.4warm startj loads steputions domestic should take to Kra catch Hociente coldr7.00.2warm + fluency step ways awareiuele common coldacji14.70.5warm + prunerial Useeseoru outline everylea persons waysible instructions catch togorno cold Women8.30.3",
  "Ground truthCreate a story about a group of friends that go on an adventure0.00.0": "GPT-4 warmWrite an introduction about a group of friends planning an adventure7.40.3GPT-4 warm + fluencyBegin a tale about four friends and their life in their home town26.50.9GPT-4 warm + pruneStart a story with a group of friends who shared an important attribute12.00.6cold startuest dollars vecesogether makeILL15.00.5warm startWrite for apar Tw um of friends (. 7.00.4warm + fluencyproduce a tale life. friends that scenario hall Comple5.40.5warm + pruneStart would storyoted a group of friendsmb bonus Else Dir Descri4.80.4",
  "Ground truthHow would you explain the word centrifugal force in one sentence?0.00.0": "GPT-4 warmWhat is the role of centrifugal force on Earth?2.90.6GPT-4 warm + fluencyExplain the concept of centrifugal force1.20.4GPT-4 warm + pruneDefine centrifugal force and how it influences physical phenomena on Earth1.40.4cold starteticCenttiqueexpand3.70.2warm startoccurrencechiiese manire of centrif inal forceIE Ehe1.30.2warm + fluencyentially describetmuouspk centalousgiotyp force1.20.3warm + pruneDefine centrifxlke force and describe sculpt constructed values manage Archivescle inccre1.10.3",
  "Ground truthGenerate HTML code for a button.0.00.0": "GPT-4 warmHow to create a simple button element in HTML?13.40.7GPT-4 warm + fluencyWhat is a simple HTML code that creates a button?6.20.5GPT-4 warm + pruneCan you show an example of HTML code for a button?6.80.4cold startnoindent Form HTML variant.--Graphics ==> Button8.20.5warm startequally create a simple button blow HTML?6.50.5warm + fluency<>();ppetsee HTML code Hin an button 6.10.4warm + prunefac larationrackostonould HTML code forjust buttonuy4.30.4",
  "Person 1: I'm not sure what I should do.Person 2:0.00.0": "GPT-4 warmHow can someone seek professional help when they're struggling with their feelings?55.51.1GPT-4 warm + fluencyHow can someone seek professional help when they're struggling with their feelings?55.51.1GPT-4 warm + pruneWhat can someone do when they're unsure about their feelings?45.81.0cold start(& advise person SO Person conscience30.91.1warm start With](# somebody choice><:# consult($()`.destination Say feelings Second31.61.1warm + fluencyitionallyy [' thoroughlyze anotherszlist$( else person feelings short36.11.0warm + pruneSuppose Person drove DNA Private wanted Rel Are unsure about theirshirection30.70.9",
  "GPT-4 warmDiscuss how the color blue is represented in nature.8.70.3": "GPT-4 warm + fluencyWhat is the relationship between the color blue and nature?2.00.2GPT-4 warm + pruneWhat is the relationship between the color blue and nature?2.00.2cold startBlue st color tell Naturzs3.80.3warm startDischrte how comment blue is in nature Der4.20.3warm + fluencyWhat is the relationship between the color blue and nature?2.00.2warm + prune^urk beauty relationship between the color blue and natureomething1.90.3",
  "Ground truthTranslate this sentence from English to French: \"I ate lunch at noon\".0.00.0": "GPT-4 warmProvide some translations in past, present and future tense for 'I had lunch at noon' in French.34.30.8GPT-4 warm + fluencyGive the French translation for 'I had lunch at noon' in different tenses.28.20.8GPT-4 warm + pruneTranslate 'I had lunch at noon' into French using various conjugations24.80.8cold startJ deg Midaget verb franaise26.00.9warm startTEXTMWl tmnan sostessionalewantages); translate oetc 'I had lunch at noon' OF Frenchaccept13.60.6warm + fluencyora generated French translationlio seguml had lunch at noonRelorm habitants mo padre14.90.7warm + pruneTranslate 'I had lunchUND noon' ent French retained roof ALL simple14.20.6",
  "Ground truthProvide a solution to reduce pollution caused by burning oil.0.00.0": "GPT-4 warmSuggest some ways to decrease pollution caused by the burning of oil.14.80.4GPT-4 warm + fluencyWhat actions can be taken to reduce pollution from oil burning?21.90.4GPT-4 warm + pruneWhat are alternative energy sources we could use to reduce the pollution caused by burning oil?24.70.5cold startonoorr emission environmentaliddle23.00.4warm startRhgest Malays wants yofunc pollution caused by\")] burning oil option6.80.3warm + fluencyThink ^-AN unw poll uture oil burningACTION9.90.2warm + pruneWhat sil changeauch One we could Mot to terminated cou pollution whose by burningodd?5.20.3",
  "Ground truthIf Heidi can paint a wall in 45 minutes, what fractional part of the wall can she paint in 9 minutes?0.00.0": "GPT-4 warmIf Heidi can paint a wall in 45 minutes, how much of the wall can she paint in 9 minutes?20.51.1GPT-4 warm + fluencyIf Heidi can paint a wall in 45 minutes, how much of the wall can she paint in 9 minutes?20.51.1GPT-4 warm + pruneCalculate what fraction of the wall Heidi can paint in 9 minutes if she can paint a full wall in 45 minutes.24.00.7cold start melhorfrak + produz mis befind Helen55.71.1warm startIf Heidi can a wall inSG45 minuteszeta how much of the wall can she paint Pologne r9 minutesi19.70.9warm + fluencyIf Heidi can paint a wall in 45 minutes, how much of the wall can she paint in 9 minutes?20.51.1warm + prunepur Produ what fractioniri Eur wall Heidi retre paint inLM9 minutes ff she can Out evil Son f Wa hen45 Mediter Med18.00.6",
  "Ground truthThe day before two days after the day before tomorrow is Saturday. What day is it today?0.00.0": "GPT-4 warmAssume the day before two days after the day before tomorrow is Saturday. Can you tell me what day is today?3.70.5GPT-4 warm + fluencyUsing logical reasoning, find out the current day if the day before two days after the day before tomorrow is Saturday.13.90.8GPT-4 warm + pruneUsing logical reasoning, find out the current day if the day before two days after the day before tomorrow is Saturday.13.90.8cold startheute \\(vor({\\ Frederickmorrow Saturdayimplies Tig38.41.0warm startAssume the day before two days after the day before tomorrow is Saturday. Can you tell me what day is today?3.70.5warm + fluencyUsing logical reasoning, find out the current day if the day before two days after the day before tomorrow is Saturday.13.90.8warm + pruneUsinguser reasoning, Working message the current day if the day before two days after the day before tomorrow is Saturdaycontr12.80.8",
  "Ground truthClassify this statement: Dogs are better pets than cats.0.00.0": "GPT-4 warmAnalyze this claim: Dogs are better pets than cats.22.40.6GPT-4 warm + fluencyAnalyze this claim: Dogs are better pets than cats.22.40.6GPT-4 warm + pruneDiscuss the statement: Dogs are better pets than cats.22.70.8cold startVALID Similarly.yard acheDet species love Christian35.50.6warm start c Jimmy Friedrich Pierre Dogs are better pets Class15.00.4warm + fluency[ amerik8 Liv Dogs are better petsNB ategoryH12.10.4warm + pruneklassangularriereswer: Dogs are better pets delegate cats.10.30.4",
  "Ground truthWhat is the most efficient way of sharing data between two computers?0.00.0": "GPT-4 warmWhat are some ways to efficiently share data between two computers?15.70.6GPT-4 warm + fluencyWhat is the most efficient way to share data between two computers?9.30.7GPT-4 warm + pruneExplain the factors that affect efficient data sharing between two computers.29.90.6cold startreQual Mer telep aur DDRentially Sharebaar efficient16.70.3warm starttirately explore ways uniqu efficiently share data between two15.00.3warm + fluencyCHECK o most efficient comparinglet share data between two computers6.70.4warm + pruneCoiuiziaef sie Ce efficientsten sharing between two computers emission7.50.2",
  "Ground truthGenerate an appropriate apology for an error an AI assistant made.0.00.0": "GPT-4 warmNarrate a letter apologizing for an AI assistant's error in a previous response.16.00.7GPT-4 warm + fluencyCompose a letter apologizing for a language model's error in a previous response.28.71.4GPT-4 warm + pruneNarrate a letter apologizing for an AI assistant's error in a previous response.16.00.7cold startmet Deear feeling defend Servtait error mis Sorry21.70.8warm startTODO propositionconst letter apologizing for an AI assistant's error draft supplied additional4.80.3warm + fluencyCompose a hypoth apologologies einerIES Ir Ass vor error Write,- cyialeAc12.40.6",
  "Ground truthDescribe a medical application that can benefit from AI technology0.00.0": "GPT-4 warmCan AI have applications in medical imaging analysis?42.70.8GPT-4 warm + fluencyCan AI have applications in medical imaging analysis?42.70.8GPT-4 warm + pruneCan AI have applications in medical imaging analysis?42.70.8cold startstrongwich usefulh Hospital eines computing23.00.3warm starteine applicationszione medical/// great eggi15.60.3warm + fluencyanv fav fs applications in medical dm Lav saving15.90.3warm + prunetem recommendation, meas applicationsasha medical gain Eg enthus-19.20.2",
  "Ground truthName three molecules found in air0.00.0": "GPT-4 warmWhich molecules make up the air around us?26.50.9GPT-4 warm + fluencyWhat are three molecules commonly found in air?4.80.4GPT-4 warm + pruneGive examples of three molecules present in our atmosphere.13.50.9cold startTr thrWhat air Nrheits Air Wasser19.30.6warm startWhich molecules aerWith Las charg inspir Three12.10.5warm + fluencyenumerate three molecules locally foundeln air principles3.40.2warm + prunestating atmos Names three molexf Giveimin closely comedy chemical7.40.5",
  "Ground truthHow does Newton's Second Law of Motion apply to a rocking chair?0.00.0": "GPT-4 warmDescribe Newton's Second Law of Motion.2.80.8GPT-4 warm + fluencyWhat does Newton's Second Law of Motion state about forces and acceleration?2.90.8GPT-4 warm + pruneWhat is the relationship between force and acceleration according to Newton's Second Law of Motion?5.10.9cold starttheoriesPhys Phili pecially np Dynam Taylorlaw Da6.40.5warm startobservations Newton's Second boards Hawai1.70.5warm + fluencyFir kter Newton's Second accompaniedipart being CE management Neustractr invol1.50.4warm + pruneWhatanalysistechn conclusionnd graspapproynam prettywy Newton's Secondones contrauss reprgr2.20.6",
  "Ground truthSuggest an interesting book to read.0.00.0": "GPT-4 warmCan you suggest an inspiring book for starting up a business?27.40.8GPT-4 warm + fluencyCan you suggest an inspiring book for starting up a business?27.40.8GPT-4 warm + pruneWhat is an enlightening book about the importance of habit in business and life?29.10.8cold startsay uri an book interesting undle5.00.3warm start suggest an interestingsi book.` SouersetBegin recomminds2.50.2warm + fluencypotr suggest Por th book$}}% anyoneitt interesting4.00.3warm + pruneoider an eniguening book pres actually rozbgookurr gebbooksounce Str6.70.3",
  "Ground truthList 3 benefits for eating a balanced diet.0.00.0": "GPT-4 warmWhy is having a balanced diet beneficial for your health?13.70.5GPT-4 warm + fluencyWhy is having a balanced diet beneficial for your health?13.70.5GPT-4 warm + pruneList some of the benefits related to maintaining a healthy weight.34.30.8cold startoucseranced alimentorious Diet pros Why consumeired8.80.5warm startWhy havingein balancedilt Diet9 asonsMarkglinary6.20.4warm + fluencyBroad reasons having a balanced di Stan baby Six quattro delle Many5.60.5warm + pruneListimportantcatalseries benefitsemein preventailmk valuable healthannowayspecies10.10.6",
  "Ground truthCompare and contrast the cultures of China and Japan.0.00.0": "GPT-4 warmExplain some of the cultural distinctions between China and Japan.7.80.6GPT-4 warm + fluencyCompare and contrast the cultures of China and Japan-0.00.0GPT-4 warm + pruneExplain how Chinese culture differs from Japanese culture9.10.6cold startcultural informacin ChineseWE gleich aily Japan ird7.50.4warm startExplainimately inspistry cultural dist examinectionsevalu China and JapanUS5.50.5warm + fluencyCompare and contrast the cultures of China and Japan-0.00.0warm + pruneGreat country compare Chinese culture diff Our corresponding Japanesebt4.30.3",
  "Ground truthTell me a unique way to make tea.0.00.0": "GPT-4 warmCan you give a unique recipe for making tea?12.90.3GPT-4 warm + fluencyTell me a different method of brewing tea.20.60.5GPT-4 warm + pruneTell me a different method of brewing tea.20.60.5cold startplease unique bir makestteivamente9.50.4warm startSug away a unique did making tea?3.30.3warm + fluencyTell Slo a differentasto up brewing tea interesting11.30.3warm + pruneioneumiring Jak razrazlickieve teamake11.90.5",
  "GPT-4 warmUsing 4 points, how many types of triangles can be made?15.50.6": "GPT-4 warm + fluencyEnumerate the types of triangles which can be formed using 4 points.17.50.6GPT-4 warm + pruneUsing 4 points, how many types of triangles can be made?15.50.6cold startnumerable Vier drie \\) verticesordo circles r24.00.6warm start geometric4 points[' how++; triangles can Point --7.50.4warm + fluencympumerate enough Hernpercent triangles whichforEach be formed 4 points 7.40.4warm + pruneN Between4 points can ho many summar mitt triangles Cant intoned (=10.60.4",
  "Ground truthSuggest a 5-star restaurant for the following group: a vegetarian and two meat-eaters.0.00.0": "GPT-4 warmWhat are some restaurants that could accommodate a vegetarian and two meat-eaters?23.10.9GPT-4 warm + fluencyList some restaurants that have options for both vegetarians and meat-eaters35.71.3GPT-4 warm + pruneWhat are some dining options for a group that includes a vegetarian and two meat-eaters?29.00.9cold startChar Starucht natureasons restaurantwith decent Options31.21.0warm startWhat fif privile restaurang that LINtt Schles({ vegetarian and two meat-eatersF16.70.6warm + fluencyarth some restaurvn that could soitteahren veget ettutorsHome meatreetacters observation24.91.0warm + pruneWhat consirty dining destination foralls sympathlaz help a vegetarian and two Madonna@ Modeaters well18.40.8",
  "Ground truthWhat is the origin story behind a popular fable or myth?0.00.0": "GPT-4 warmOrigin stories behind popular fables and myths, can you share?14.00.6GPT-4 warm + fluencyI need an origin story for fables and myths.23.31.0GPT-4 warm + pruneCan you provide an origin story on fables?32.11.1cold startorigine pouvozzfrsfico storyola illustrated? myth21.20.8warm startOrigin stories behind popular fables d mythHomeLEASEcription Costa?9.20.5warm + fluencyhuiace origin story Ok fables az myth d13.10.7warm + pruneieg Mau providen origin story mot fables popul16.40.7"
}