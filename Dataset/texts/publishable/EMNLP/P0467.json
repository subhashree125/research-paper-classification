{
  "Abstract": "Parsing documents from pixels, such as pic-tures and scanned PDFs, into hierarchical struc-tures is extensively demanded in the daily rou-tines of data storage, retrieval and understand-ing. However, previously the research on thistopic has been largely hindered since most ex-isting datasets are small-scale, or contain docu-ments of only a single type, which are character-ized by a lack of document diversity. Moreover,there is a significant discrepancy in the anno-tation standards across datasets. In this paper,we introduce a large and diverse document hi-erarchy parsing (DHP) dataset to compensatefor the data scarcity and inconsistency problem.We aim to set a new standard as a more prac-tical, long-standing benchmark. Meanwhile,we present a new DHP framework designed tograsp both fine-grained text content and coarse-grained pattern at layout element level, enhanc-ing the capacity of pre-trained text-layout mod-els in handling the multi-page and multi-levelchallenges in DHP. Through exhaustive exper-iments, we validate the effectiveness of ourproposed dataset and method1.",
  "Introduction": "Nowadays, an overwhelming amount of informa-tion is generated daily and stored in documents aspixels, such as pictures and scanned PDFs, ratherthan in hierarchically structured formats. It intro-duces a significant challenge in practice, as struc-tured formats are essential for efficient databasestorage and standardized data handling (Johnsonet al., 2003; Clifton and Garcia-Molina, 2000), aswell as downstream tasks, such as information re-trieval and natural language processing (Wilkinson,1994; Dasigi et al., 2021). Particularly, it has been",
  "* Equal contribution. Corresponding author.1The dataset and code are available at": ": Examples of various page layouts and struc-tures in DocHieNet. Blue and green boxes representlayout elements of titles and paragraphs. Red lines referto the hierarchical relations. Only part of the hierarchi-cal relations are shown for clarity. studied that documents with structural metadatafurther enhance the capabilities of large languagemodels (LLMs), which has been outstanding acrossvarious domains, in processing lengthy documentsand knowledge-intensive tasks (Saad-Falcon et al.,2023; Gao et al., 2023). Document hierarchy parsing (DHP) aims at re-constructing the hierarchical relationships amongdocument layout elements (e.g., titles, paragraphs,figures), as shown in and thus organizingthe document in a machine-understandable, hier-archically structured format. For documents aspixels, the layout elements can be extracted by off-the-shelf document layout analysis systems(Zhong et al., 2019b), and the DHP model focuseson predicting the hierarchical relationship amongthem. Issues on previous datasets have hinderedthe progress of research and application. First, thedatasets struggle to reflect the complexity of real-world documents. The arXivdocs (Rausch et al.,2021) and E-Periodica (Rausch et al., 2023) areconsidered small-scale, containing only hundredsof single pages. Regarding HRDoc and Comp-HRDoc (Ma et al., 2023; Wang et al., 2024), al-though they are large-scale and exhibit variouslengths, they contain only monotonous scientificarticles, which share similar layout designs and hi-erarchical structures, such as examples in the 3rdrow of . Second, the annotation standards areinconsistent. For instance, the granularity of layoutelement annotations varies among datasets, includ-ing those based on text line level and layout blocklevel. Moreover, their definitions of hierarchicalrelations also differ with the varying definitions oflayout elements.Regarding the models, DHP presents two pri-mary challenges: the handling of extended, multi-page inputs and the comprehension of both textualcontent and the high-level layout relationships. Pre-vious works employ heuristic rules (Rausch et al.,2021) and LSTM networks (Rausch et al., 2023)for their efficiency with lengthy inputs. Ma et al.(2023) utilize a pre-trained language model (PLM)as the encoder to enhance the model performance.But this model extracts the text features of eachlayout element independently, thus overlooking thefine-grained contexts of layout elements.As a result of the issues with the dataset andmodel design, existing DHP methods struggle to beapplicable in the real-world scenarios. In order topromote the development of DHP in more complexand realistic scenarios, we proposed DocHieNet, alarge-scale, multi-page, multi-domain, multi-layoutand bi-lingual dataset for DHP. DocHieNet con-tains 1673 multi-page documents from differentscenarios including public sector, research, indus-try, etc. The multi-page documents, up to 50 pages,are characterized by large heterogeneity in theirpresentation and thus complex document structures(), which are close to real-world conditions.The data collection of DocHieNet inherently en-courages the development of models capable of ad-dressing DHP on highly diverse documents. Statis-tics of the datasets are summarized in Tab. 1.With DocHieNet available,we propose a transformer-based framework, DHFormer, whicheffectively overcomes the multi-page and multi-level challenges in DHP. It adopts a sparse text-layout encoder, derived from the powerful layout-aware language models (LMs) (Xu et al., 2021; Luoet al., 2023) to represent the layout elements withenriched fine-grained contexts. Subsequently, a lay-out element-level reasoning decoder is exploited tocapture collective information from multiple pagesat the global range. Besides, DHFormer leveragesthe page embeddings and inner-layout position em-beddings in order to better depict the cross-pageand multi-level patterns. Experiments show thatthe proposed method is highly competitive and out-performs previous methods by a large margin.Our main contributions can be summarized asfollows:",
  "Document AI": "Document AI involves automated reading, under-standing and extracting information from visually-rich documents (VRDs) (Liu et al., 2019; Li et al.,2020a; Cui et al., 2021; Xing et al., 2023; Shaoet al., 2023). As the world is going digital, it has re-ceived a heightened focus on its impact and signifi-cance. The Document Layout Analysis (DLA) task(Namboodiri and Jain, 2007), which refers to thedetection and recognition of layout elements suchas text and table/figure region, has seen a surge ofresearch achievements (Li et al., 2020b; Pfitzmannet al., 2022). Based on these works, datasets andmethods are proposed to further understand the se-mantic relationships of layout elements and extracttheir hierarchical structure (Rausch et al., 2021,",
  "Document Hierarchy Parsing": "There are a handful number of datasets availablefor DHP. Rausch et al. (2021) are the forerunnersfor contributing the arXivdocs, which contains only362 single pages randomly selected from arXiv. Maet al. (2023) propose the HRDoc dataset with 2500multi-page documents from ACL/arXiv and Wanget al. (2024) improve the labels. Nevertheless, theyare limited to scientific articles, which share similarstructures. Rausch et al. (2023) mitigate this ho-mogeneity by introducing the E-Periodica, whichis comprised of 542 single pages from magazines.However, E-Periodica still exhibits issues of lim-ited pagination and small scale.The DHP model requires accommodating longdocument inputs, which has led prior models(Rausch et al., 2021, 2023) to rely on heuristic rulesor LSTM networks (Hochreiter and Schmidhuber,1997), for their reduced computational complex-ity. In order to improve the performance, Ma et al.(2023) employ a PLM to independently encodeeach layout element. But the model fails to addressthe multi-level challenge in DHP by overlookingthe fine-grained contexts of layout elements.",
  "Long-document Transformers": "Transformers (Vaswani et al., 2017) have becomethe fundamental model for natural language pro-cessing tasks, which requires quadratic space de-pendency. Early works such as (Beltagy et al.,2020) propose types of sparse attention to tacklethis challenge. Nonetheless, such approaches de-mand additional pre-training. Ivgi et al. (2022); Xieet al. (2023) show that building a sparse transformervia document chunking, while keeping the attentionpattern unchanged, forgoes the extra pre-trainingand effectively handles lengthy texts. Since thelong multi-page VRDs lack pre-training corpora, Tito et al. (2022); Kang et al. (2024) follow thechunk-based method to solve the multi-page docu-ment VQA. However, their page-level design can-not be directly implemented on DHP which fo-cuses on finer-grained relationships among layoutelements.",
  "Problem Definition": "In this paper, we consider the DHP as recognizingthe hierarchical structure among layout elements.Specifically, the input is given as a multi-page doc-ument along with M extracted layout elementsE = {E1, E2, ..., EM} in traversal order, whichcan be obtained by the off-the-shelf optical charac-ter recognition (OCR) and document layout anal-ysis system (Cheng et al., 2023). The output isthe hierarchical structure of the elements (E, R),where R is the relation set which captures relation-ships between layout elements. Relation Rj is de-fined as a tuple (Eparent, Echild) which representsa hierarchical relation between elements.The definitions of the layout elements and theirrelationships vary among datasets. depictsa document image, with annotations visualized ac-cording to labeling systems of different datasets.E-Periodica (See (b)), defines layout ele-ments as multi-granular content blocks with hier-archical relations which exist between elementsof different granularities, and sequential relationswhich indicate reading order. This setup imposesstringent requisites on the layout analysis modulefor multi-granular elements, and it also results insemantically incomplete elements by annotatingsingle pages separately. In HRDoc, annotationsare based on text lines, simplifying issues of multi-granularity by requiring the model to additionallyidentify text lines belonging to the same layoutblock (See green lines of connect relationship in (c)). This approach neglects the advanceddocument layout analysis models. Besides, the",
  "(c) Labels in HRDoc(d) Labels in DocHieNet": ": Illustration of the label systems in differentdatasets. Red and blue lines denote hierarchical andsequential relationships, and green lines indicate con-nect relationships. The point at the top of the documentrepresents the root of document. prevalence of the connect relationship far exceedsother relations, making line-level evaluation a poorreflection of prediction quality due to the simplic-ity of the connect pattern compared to the morecomplex hierarchical relationship.Integrating the merits of different definitionsand referencing prevailing works in the documentlayout analysis, we design the labeling system ofDocHieNet to annotate only fine-grained layoutblocks and capture both hierarchical and sequentialrelationships, as illustrated in (d).",
  ": Distribution of number of pages and maxhierarchical depths of the four datasets shown in Tab. 1": "lic release, data directory services for financial re-ports and other aggregate websites. Informationon the search procedure and resources of data isdistributed as a part of the DocHieNet dataset. Wemanually select representative documents of theirtype while preventing too many samples gatheredin a single type. Extra caution is exercised in ensur-ing that all samples are free to use and eliminatingsamples that could potentially raise complicationspertaining to privacy considerations.",
  "Annotation Process": "The campaign begins with annotating layout ele-ments. Based on the observation of common layoutfeatures in the collected data and previous defini-tions of layout element classes, we define a tax-onomy of 19 types: {title, sub-title, section-title,text, formula, TOC-title, TOC, figure, fig-title, fig-caption, table, tab-title, tab-caption, header, footer,page-number, footnote, endnote, sidebar}. Thestatistics of layout elements are summarized in Ap-pendix A.1. In this phase, the layout elements areannotated with their categories, positions and textcontent, organized in reading order across pages.Given the diversity in document themes and lay-outs, the hierarchical relationship annotation be-comes complex. We thus supply precise annotationguidelines and plenty of examples for typical docu-ment types. Twelve experienced annotators under-take this task adhering strictly to these guidelines,with three specialists in the document understand-ing area performing three rounds of quality checks.Within our corpus, many documents are lengthy,with recurring layout patterns. To improve annota-tion efficiency and reduce pattern redundancy, wehave truncated half of the documents (totaling 835).",
  "Data Split and Statistics": "We carefully split the annotated documents into atrain-set of 1512 documents and a test-set of 161documents. To prevent over-fitting to a particularpattern, we regulate the balance of documents fromdiverse sources within the splits. Additionally, thedocuments in the test-set encompass fully anno-tated documents exclusively, and thus DocHieNetis able to gauge the generalization ability of modelsacross documents of varying lengths. More detailsof the splits are summarized in Appendix A.2. Our research entails statistical evaluations of thedatasets, which reveals that DocHieNet is of higherdiversity compared with previous DHP datasets.We present the principal statistical data of thedataset in Tab. 1. It is evident that DocHieNetrepresents the largest manually annotated datasetand is the sole dataset with multiple types of docu-ments. In terms of document length, as depicted in (a), DocHieNet exhibits a more extensive andvaried distribution of page numbers. Pertaining tothe complexity of document hierarchy, DocHieNetalso demonstrates significant diversity. It encom-passes a larger proportion and a broader span ofcross-page relationships, as summarized in Tab. 1.Furthermore, in the aspect of the depth of the docu-ment hierarchy tree, DocHieNet is also more diver-sified. Previous datasets, due to the homogeneityof the documents, exhibit a more concentrated dis-tribution as shown in (b).",
  "Method": "The proposed DHFormer framework, as illustratedin , leveraging both fine-grained and holis-tic information, and making full use of pre-trainedlayout-aware LMs, effectively tackles the multi-page and multi-level challenges in DHP. Firstly,the entire document, including tokens and their 2Dpositions, is fed into a sparse text-layout encoderEsp to create a fine-grained contextualized repre-sentation for each token. Then, through pooling,the information is input into a layout element-leveldecoder D. The decoder captures collective in-formation from higher-level and global contextsto obtain representations of layout elements. Wespecially equip the text-layout model with addi-tional page embeddings and inner-layout positionembeddings to enhance the capacity of modelingcross-page and multi-level relations. Finally, thecontextualized layout features are fed into the rela-tion prediction head to get the final output.",
  "Sparse Text-layout Encoder": "Layout-aware LMs (Xu et al., 2019, 2021; Luoet al., 2023) can be taken as the text-layout en-coder. In multi-page VRDs, the number of tokensN usually exceeds the input limitations l of thepre-trained encoder. There are various strategiesto extend their attention mechanism to handle longinputs 2. In this section, we employ a chunk-basedsparse transformer which keeps the dense atten-",
  "Discussion on different sparse transformer strategies isprovided in the experiments": "tion within chunks and thus better exploits the LMspre-trained on single pages (Ivgi et al., 2022; Xieet al., 2023). We break down the document to Kchunks C = {C1, ..., CK}. Each chunk containsthe maximum number of layout elements such thatthe total number of their tokens does not exceedl. The chunks are encoded distributively, so theattention map in the encoder Esp is factorized intodense attention only within chunks :",
  "Kki = (Wkxj)xjCki, Vki = (Wvxj)xjCki (3)": "Wq, Wk, and Wv represent the weight matrices andd is the hidden size of the model.In this way, we enrich the fine-grained contextsof tokens rather than only within layout elements,while keeping computational cost in check. Thevanilla self-attention complexity of the entire doc-ument is O(N2). The attention factorized withinchunks has the complexity of O(|C1|2 + |C2|2 +... + |Ck|2). Supposing that the size of chunks areall of l for estimation, then there is N = l K andthe complexity of the factorized attention in thesparse text-layout encoder is O(l N).",
  "Position Embeddings": "We further add two types of embeddings to the text-layout models, which are specially designed for themulti-page and multi-level settings in DHP:Page embeddings denote the page location onwhich the input is located.It is computed asepg = Linear(sinPE(pni)), where pni is the abso-lute page number of ith input, sinPE is the sinu-soidal positional encoding. It can connect layoutsfrom the same page and distinguish layouts fromdifferent pages. The 2D position embeddings alonecan be confusing in the multi-page scenario sincelayouts from different pages may overlap.Inner-layout position embeddings are calculatedby ein = PosEmb1D(rpi), where rpi is the rela-tive position of ith input within its correspondinglayout element, and PosEmb1D is the 1D positionembedding function of the encoder. It helps themodel obtain the awareness of the boundaries oflayout elements in text sequences, which facilitatesbetter representation of layout elements.",
  "Global Layout Element Decoder": "For each layout element Ei, its representation Hi isderived by pooling the feature of its first token. Anadditional learnable root embedding H0 is utilizedsince some layouts have the root node as the parent.The features of layouts are concatenated and passedinto a transformer-based decoder D, producing thefinal representations Hi of layouts as :",
  "Implementation Details": "We employ pre-trained GeoLayoutLM (Luo et al.,2023) as the basic text-layout encoder and a 2-layerSSA with a window size of 48 as the decoder. TheAdamW optimizer (Loshchilov and Hutter, 2017)is employed for training with a base learning rate of4e-5. The training epoch is set to 100 as the default,where the learning rates progressively decrease to1e-6. During training, we set the max tokens of thetext-layout encoder as 512 with the max number ofchunks, as 32 (128 for testing). All the experimentsof DHFormer are performed on the platform with2 NVIDIA Tesla V100 GPUs.",
  "Comparison of Document HierarchyParsing Models across Datasets": "We assess a group of DHP models to investigatetheir performance across different datasets, includ-ing DocParser (Rausch et al., 2021), DSPS (Maet al., 2023), DOC (Wang et al., 2024) and DSG(Rausch et al., 2023). The baselines are summa-rized with more details in Appendix A.4. As men-tioned in Sec. 3, there exists inconsistency acrossdifferent datasets. To facilitate a comprehensivecomparison, we map the labels of previous datasetsonto the DocHieNet format. For DocParser, wedo not alter the data containing multi-granularitylayout elements, as its empirical rules are predi-cated on such annotations. Regarding the DSPSand DOC model, we refer to the reported evalua-tion results, specifically the evaluation conductedon the text line level. The results are in Tab. 2.An analysis of each row reveals the notablyhigher complexity of DocHieNet compared to otherdatasets. For example, DHFormer achieves com-mendable results on previous datasets, but its per-formance on DocHieNet indicates substantial roomfor enhancement. A vertical comparison in eachcolumn illustrates the superiority of DHFormer. Despite DSG integration of multi-modal features,the absence of document-specific pre-training lim-its its effectiveness in the data-scarce scenario. Al-though the DSPS model employs the PLM, the lay-out elements are encoded separately with only lim-ited contexts. DHFormer overcomes the drawbacksof previous model with the specially designed ar-chitecture to better exploit the pre-trained layout-aware LMs on the multi-page and multi-level DHPsetting. We also investigate the performance ofDHFormer on documents of different languages inAppendix A.5.",
  "Model Performance on DifferentAnnotation Formats": "In order to provide a more comprehensive assess-ment of the proposed model, we evaluate the per-formance of DHFormer on different datasets withtheir original annotation formats as shown in Tab. 3.Setting 1 is the same as that in Tab. 2. In setting2 the model is trained with labels of DocHieNetstandard, while the results are transformed backinto the original standards for evaluation. Notethat we have manually transformed the E-Periodicaand arXivdocs into DocHieNet standard, so the pre-dicted results can not be directly transformed back.In setting 3, the model is trained and evaluated onthe original annotations of the datasets.For results on HRDoc datasets, the results in set-ting 2 become obviously higher than in setting 1. It",
  ": Experiment results on HRDoc with differentannotation granularity. DHFormer* refers to the end-to-end results with a layout analysis system": "is because the backward transformation splits thelayout element into text lines and adds connect re-lations among them, which are exactly ground-truthrelations. For E-Periodica and arXivdocs datasets,the performance in setting 3 is higher, mainly be-cause the layout information provides strong cluesfor the relationships defined in these datasets. Insetting 3, directly training and testing the modelon the original datasets also shows commendableresults, which indicates the effectiveness and flexi-bility of DHFormer.",
  "Model Performance with DifferentPre-trained Encoders": "We conduct additional experiments by replacingGeoLayoutLM in the encoder with other represen-tative layout-aware LMs, including BROS (Honget al., 2022) and LayoutLMv3 (Huang et al., 2022)along with a plain-text LM XLM-RoBERTa (Con-neau et al., 2019) of equal parameter size. Theresults are summarized in Tab. 4. It shows that theperformance fluctuates slightly according to dif-ferent pre-trained models, while consistently out-performing previous methods. It demonstrates theflexibility and robustness of the framework.",
  ": Comparison of the DHFormer and LLMs, interms of model performance in relation to variations indocument length": "and experimental results. As mentioned in Sec. 3,the layout element defined in E-Periodica is solelyapplicable to single-page documents. It fails to en-compass cross-page relationships, which constitutea significant proportion in multi-page documents,as summarized in Tab. 1. The limitations of thisannotation paradigm are self-evident.The HRDoc annotation system, by establishingrelations among text lines, integrates the tasks oflayout analysis and hierarchy parsing. Experimentresults indicate that this setting is not as ideal asit appears. We train DHFormer with the originalHRDoc annotations and conducted evaluations onboth text line (2a), and layout block level (2b) bymerging lines into blocks according to the predic-tions. We also break down the results of DHFormertrained with block-level annotations into text linesto make a thorough comparison (2c). The evalua-tion results based on layout blocks are significantlylower, which indicates that text line-level evalua-tions inadequately reflect the actual quality of thepredicted hierarchy as mentioned in Sec. 3.We further compare the end-to-end inferenceoutcomes based on layout blocks detected by alayout analysis system using CenterNet (Zhou et al.,2019). Employing the results of the layout analysismodel as input demonstrated a decline (from 3ato 3b), albeit still surpassing the outcomes of line-level prediction after merging text lines into layoutblocks for evaluation (2b), which further indicatesthe merit of the annotation paradigm of DocHieNet.",
  ": The comparison of different sparse transformerstrategies (STSs) and window size (WinS)": "LLMs and Llama2 is a prevalent open-source largemodel in academia. We take them as baselines toevaluate LLMs on DocHieNet. The prompt forGPT-4 employs in-context learning (ICL) (Brownet al., 2020) , while Llama2 is fine-tuned on ourdataset. Further details of the APIs, prompt andfine-tuning process are provided in Appendix A.6.The comparison in terms of relation F-1 is shownin . As illustrated, DHFormer outperformsGPT-4 based on ICL or fine-tuned Llama2. More-over, with the increment in the length of the docu-ments evaluated, DHFormer only exhibits a slightdecline. This can be attributed to its adeptly balanc-ing detailed and holistic information, enhancing itsoverall performance. Besides, the decoder reasonsat above-token level with collective information,which prevents the model from being overwhelmedby excessive details and consequently bolsters themodel on lengthy documents.",
  "Ablations of Design Choices": "First, we assess the impact of different sparse trans-former strategies (STS). We conducted experimentswith chunks of varying sizes, and implemented asliding window attention mechanism (Beltagy et al.,2020) with the same initialization. Chunking at thelayout level evidently suffers from inadequate con-text according to the comparison of Tab. 6 (a) andTab. 6 (d). Chunking at the page level, as shownin Tab. 6 (b), also leads to slight information lossdue to the frequent cross-page relationships amonglayout elements. Employing the sliding window ob-viates the need for chunking. However, it modifiesthe attention pattern, and thus often necessitatesfurther pre-training (Ivgi et al., 2022). In the sce-nario of multi-page long VRDs with a scarcity ofpre-training data, the chunk-based method showsits superiority, which is indicated by the differencebetween Tab. 6 (c) and Tab. 6 (d).Then we evaluate the effectiveness of the pageembeddings and inner-layout position embeddingsin Tab. 7. Results indicate that a performance boost",
  "Conclusion": "In this paper, we present DocHieNet, a DHP datasetfeaturing large-scale, multi-page, multi-domain,multi-layout and bi-lingual documents. We carryout detailed analyses of data statistics, annotationparadigms and evaluation using various baselines.Our findings demonstrate the challenging natureof the DocHieNet and the advantage of its anno-tations format. Furthermore, we introduce an ef-fective framework, DHFormer, which consistentlyimproves the model performance, particularly onthe complex DocHieNet dataset. We hope this workcould not only advance the understanding of DHPtask but also set a foundation for future exploration.",
  "Limitations": "Despite the significant effectiveness that our pro-posed dataset DocHieNet and method DHFormerrepresent, we acknowledge the limitations thatwhile the dataset includes a vast array of documenttypes and layouts, it may not encompass all possi-ble variations seen in the wild. Future work couldexpand the dataset to include even more diverseand challenging documents, ensuring that modelsare more robust against more types of documentsencountered in the real-world applications.",
  "Longformer: The long-document transformer. ArXiv,abs/2004.05150": "Tom B. Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, T. J. Henighan, Rewon Child,Aditya Ramesh, Daniel M. Ziegler, Jeff Wu, ClemensWinter, Christopher Hesse, Mark Chen, Eric Sigler,Mateusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020.Language models are few-shot learners.ArXiv,abs/2005.14165.",
  "Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai,Zhijian Liu, Song Han, and Jiaya Jia. 2023. Longlora:Efficient fine-tuning of long-context large languagemodels. ArXiv, abs/2309.12307": "Hiuyi Cheng, Peiyu Zhang, Sihang Wu, Jiaxin Zhang,Qi Zhu, Zecheng Xie, Jing Li, Kai Ding, and LianwenJin. 2023. M6doc: A large-scale multi-format, multi-type, multi-layout, multi-language, multi-annotationcategory dataset for modern document layout anal-ysis. 2023 IEEE/CVF Conference on Computer Vi-sion and Pattern Recognition (CVPR), pages 1513815147. Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho,and Yoshua Bengio. 2014. Empirical evaluation ofgated recurrent neural networks on sequence mod-eling. In NIPS 2014 Workshop on Deep Learning,December 2014.",
  "Document ai: Benchmarks, models and applications.ArXiv, abs/2111.08609": "Pradeep Dasigi, Kyle Lo, Iz Beltagy, Arman Cohan,Noah A. Smith, and Matt Gardner. 2021. A datasetof information-seeking questions and answers an-chored in research papers. In Proceedings of the2021 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 45994610, On-line. Association for Computational Linguistics. Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo,Meng Wang, and Haofen Wang. 2023. Retrieval-augmented generation for large language models: Asurvey. ArXiv, abs/2312.10997.",
  "Lei Kang, Rubn Prez Tito, Ernest Valveny, and Di-mosthenis Karatzas. 2024. Multi-page document vi-sual question answering using self-attention scoringmechanism. ArXiv, abs/2404.19024": "Jordy Van Landeghem, Rubn Prez Tito, ukaszBorchmann, Michal Pietruszka, Pawel Joziak, RafalPowalski, Dawid Jurkiewicz, Mickal Coustaty,Bertrand Ackaert, Ernest Valveny, Matthew B.Blaschko, Sien Moens, and Tomasz Stanislawek.2023. Document understanding dataset and eval-uation (dude). 2023 IEEE/CVF International Con-ference on Computer Vision (ICCV), pages 1947119483. Liangcheng Li, Feiyu Gao, Jiajun Bu, Yongpan Wang,Zhi Yu, and Qi Zheng. 2020a. An end-to-end ocr textre-organization sequence learning for rich-text detailimage comprehension. In European Conference onComputer Vision. Minghao Li, Yiheng Xu, Lei Cui, Shaohan Huang, FuruWei, Zhoujun Li, and Ming Zhou. 2020b. DocBank:A benchmark dataset for document layout analy-sis. In Proceedings of the 28th International Confer-ence on Computational Linguistics, pages 949960,Barcelona, Spain (Online). International Committeeon Computational Linguistics. Xiaojing Liu, Feiyu Gao, Qiong Zhang, and HuashaZhao. 2019. Graph convolution for multimodal in-formation extraction from visually rich documents.In Proceedings of the 2019 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,Volume 2 (Industry Papers), pages 3239, Minneapo-lis, Minnesota. Association for Computational Lin-guistics.",
  "Ilya Loshchilov and Frank Hutter. 2017. Decoupledweight decay regularization. In International Confer-ence on Learning Representations": "Chuwei Luo, Changxu Cheng, Qi Zheng, and CongYao. 2023. Geolayoutlm: Geometric pre-training forvisual information extraction. 2023 IEEE/CVF Con-ference on Computer Vision and Pattern Recognition(CVPR), pages 70927101. Jiefeng Ma, Jun Du, Pengfei Hu, Zhenrong Zhang, Jian-shu Zhang, Huihui Zhu, and Cong Liu. 2023. Hrdoc:dataset and baseline method toward hierarchical re-construction of document structures. In Proceed-ings of the Thirty-Seventh AAAI Conference on Ar-tificial Intelligence and Thirty-Fifth Conference onInnovative Applications of Artificial Intelligence andThirteenth Symposium on Educational Advances inArtificial Intelligence, AAAI23/IAAI23/EAAI23.AAAI Press.",
  "Jeffrey Pennington, Richard Socher, and Christopher D.Manning. 2014. Glove: Global vectors for wordrepresentation. In Conference on Empirical Methodsin Natural Language Processing": "Birgit Pfitzmann, Christoph Auer, Michele Dolfi,Ahmed Samy Nassar, and Peter W. J. Staar. 2022.Doclaynet: A large human-annotated dataset fordocument-layout segmentation. Proceedings of the28th ACM SIGKDD Conference on Knowledge Dis-covery and Data Mining. Johannes Rausch, Octavio Martinez, Fabian Bissig,Ce Zhang, and Stefan Feuerriegel. 2021. Docparser:Hierarchical document structure parsing from render-ings. In AAAI Conference on Artificial Intelligence.",
  "Rubn Prez Tito, Dimosthenis Karatzas, and ErnestValveny. 2022. Hierarchical multimodal transformersfor multi-page docvqa. ArXiv, abs/2212.05935": "Hugo Touvron, Louis Martin, Kevin R. Stone, PeterAlbert, Amjad Almahairi, Yasmine Babaei, Niko-lay Bashlykov, Soumya Batra, Prajjwal Bhargava,Shruti Bhosale, Daniel M. Bikel, Lukas Blecher, Cris-tian Cantn Ferrer, Moya Chen, Guillem Cucurull,David Esiobu, Jude Fernandes, Jeremy Fu, WenyinFu, Brian Fuller, Cynthia Gao, Vedanuj Goswami,Naman Goyal, Anthony S. Hartshorn, Saghar Hos-seini, Rui Hou, Hakan Inan, Marcin Kardas, ViktorKerkez, Madian Khabsa, Isabel M. Kloumann, A. V.Korenev, Punit Singh Koura, Marie-Anne Lachaux,Thibaut Lavril, Jenya Lee, Diana Liskovich, YinghaiLu, Yuning Mao, Xavier Martinet, Todor Mihaylov,Pushkar Mishra, Igor Molybog, Yixin Nie, AndrewPoulton, Jeremy Reizenstein, Rashi Rungta, KalyanSaladi, Alan Schelten, Ruan Silva, Eric MichaelSmith, R. Subramanian, Xia Tan, Binh Tang, RossTaylor, Adina Williams, Jian Xiang Kuan, PuxinXu, Zhengxu Yan, Iliyan Zarov, Yuchen Zhang, An-gela Fan, Melanie Kambadur, Sharan Narang, Aure-lien Rodriguez, Robert Stojnic, Sergey Edunov, andThomas Scialom. 2023. Llama 2: Open foundationand fine-tuned chat models. ArXiv, abs/2307.09288. Ashish Vaswani, Noam M. Shazeer, Niki Parmar, JakobUszkoreit, Llion Jones, Aidan N. Gomez, LukaszKaiser, and Illia Polosukhin. 2017. Attention is allyou need. In Neural Information Processing Systems.",
  "Jiawen Xie, Pengyu Cheng, Xiao Liang, Yong Dai, andNan Du. 2023. Chunk, align, select: A simple long-sequence processing method for transformers. ArXiv,abs/2308.13191": "Hangdi Xing, Feiyu Gao, Rujiao Long, Jiajun Bu,Qi Zheng, Liangcheng Li, Cong Yao, and Zhi Yu.2023. Lore: Logical location regression network fortable structure recognition. Proceedings of the AAAIConference on Artificial Intelligence, 37(3):29923000. Yang Xu, Yiheng Xu, Tengchao Lv, Lei Cui, FuruWei, Guoxin Wang, Yijuan Lu, Dinei Florencio, ChaZhang, Wanxiang Che, Min Zhang, and Lidong Zhou.2021. Layoutlmv2: Multi-modal pre-training forvisually-rich document understanding. In ACL. Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, FuruWei, and Ming Zhou. 2019. Layoutlm: Pre-trainingof text and layout for document image understanding.Proceedings of the 26th ACM SIGKDD InternationalConference on Knowledge Discovery & Data Mining.",
  "A.2Details of Data Splits": "Below are the detailed statistics of the data splits(See Tab. 9). As described in Sec. 4.3, the docu-ments in the test set are fully annotated, whereas inthe training set, 835 documents are only partiallyannotated. Consequently, the average number ofpages per document in the training set is less thanthat in the test set. By establishing such a scenario,DocHieNet encourages DHP models to consider ad-dressing the document inputs with various lengthsencountered in real-world scenarios.",
  "A.4Details of Baselines": "We assess a group of DHP models to investigatetheir performance across different datasets. Doc-Parser (Rausch et al., 2021) uses heuristics to con-vert a list of elements into hierarchical relations.It takes into account multi-column layouts but ig-nores most meta-information such as text contentof elements. DSPS (Ma et al., 2023) employs amulti-modal encoder and a GRU (Chung et al.,2014) decoder for hierarchical organization. Thetextual embeddings of layouts are extracted seper-ately. And DOC (Wang et al., 2024) employs uni-fied relation predictions to perform document lay-out analysis and hierarchy parsing from text lines.DSG (Rausch et al., 2023) leverages a bidirectionalLSTM for relation prediction of the layout ele-ments, employing features extracted from FPN forimage regions and the GLoVe (Pennington et al.,2014) word embeddings of their layout elementtype.",
  "A.6.1APIs and Pre-trained Models": "We employ two baselines for the discussion onLLMs: GPT-4-turbo-128K and Llama2 (Touvronet al., 2023). GPT-4 represents one of the currentstate-of-the-art LLMs and is accessible via the Ope-nAI API3. Llama2 is a prevalent open-source largemodel in academia. The specific pre-trained modelweight we utilize, Llama-2-7b-chat-hf, is availableon Huggingface4. It has the original context lengthof 4096, and we extend it to 32K with positioninterpolation for the long document inputs.",
  "A.6.3Fine-tuning Process of Llama2": "Here we provide a detailed description of the fine-tuning process of Llama2. To cater for ability ofLlama2 gained from pre-training, the DocHieNetdataset is transformed into a prompt-based formatas illustrated in Tab. 11. The input document isorganized as a list of layout elements arranged inreading order; and thus, the task is transformed intopredicting the parent node of each element. Theanswer is organized as a list of relation pairs (i:j)as in Tab. 11. During training, the input is splicedinto sub-documents within 10K tokens, and duringtesting, the input is the whole document. We followthe training hyper-parameters as demonstrated in llama-recipes 5. We employ LoRA (Hu et al., 2021)for parameter-efficient fine-tuning, where we setthe rank as 8, alpha as 32, dropout as 0.05, and thetarget modules are the query and value projectionsin the attention mechanism. The fine-tuning is doneon 2 NVIDIA A100 GPUs for 1 epoch. We parserelationship pairs from the output, and reconstructthe document hierarchy trees based on these pairs.Essentially, all outputs are automatically parsableexcept for a handful of cases for which we makemodifications manually. PromptHere is a list whose elements represent the content blocks of adocument, and the indication of keys are as following:\"text\": A string representing the text in the content block.\"page\": An integer indicating the page number on which the content blockappears.\"id\": An integer that uniquely identifies the content block.\"box\": the layout information of the content block.Documents are organized as a tree-like structure. Please find the parent elementof each content block based on the text and layout of them.The format of your reply: [{id1 : parent_id1},...,{idn : parent_idn}] . Anddo not reply other content.Here are some demonstration:{Demonstrates}Here is the input document:{Input}reply:"
}