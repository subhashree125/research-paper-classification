{
  "Abstract": "Fine-tuning large pre-trained language modelswith Evol-Instruct has achieved encouragingresults across a wide range of tasks.How-ever, designing effective evolving methods forinstruction evolution requires substantial hu-man expertise. This paper proposes Auto Evol-Instruct, an end-to-end framework that evolvesinstruction datasets using large language mod-els without any human effort.The frame-work automatically analyzes and summarizessuitable evolutionary strategies for the giveninstruction data and iteratively improves theevolving method based on issues exposed dur-ing the instruction evolution process. Our ex-tensive experiments demonstrate that the bestmethod optimized by Auto Evol-Instruct out-performs human-designed methods on variousbenchmarks, including MT-Bench, AlpacaEval,GSM8K, and HumanEval.",
  "Introduction": "Fine-tuning large language models (LLMs) to fol-low detailed instructions is vital to unlocking theirpower (Ouyang et al., 2022; Touvron et al., 2023b).High-quality datasets, such as ShareGPT (Chianget al., 2023), OpenAssistant (Kpf et al., 2023),LIMA (Zhou et al., 2023), have greatly improvedthe performance of instruction-tuning, promotingthe prosperity of LLM alignment. However, an-notating instruction following datasets with suchquality is hard to scale, and its quality upper limit isalso uncontrollable. Researchers (Xu et al., 2023;Yu et al., 2023; Liu et al., 2023b) are actively explor-ing ways to break through the quality upper-boundof existing datasets. Evol-Instruct (Xu et al., 2023)takes the high-quality data as a starting point, andfurther iteratively refines it using LLMs, improvingits complexity and diversity. It has demonstratedsuperior performance across a broad range of pub-lic benchmarks that evaluate diverse capabilities,including instruction following (Zheng et al., 2023; Li et al., 2023), code generation (Luo et al., 2023b;Chen et al., 2021), and mathematical reasoning(Luo et al., 2023a; Cobbe et al., 2021).While Evol-Instruct exhibits outstanding per-formance, its heavy reliance on heuristic effortspresents notable challenges. Whenever it is usedfor a completely new task, the methods for exe-cution evolution need to be redesigned. Such aprocess requires a high level of expertise and con-siderable costs, hindering its adaptation to a widerspectrum of capabilities. To address these chal-lenges, it needs to automate the Evol-Instruct pro-cess, which will encounter the following difficul-ties: (1) Design evolving methods automaticallythat make the instructions more complex for a giventask (2) To keep the instruction evolution processworking properly, the evolving method needs toavoid evolution failure.In this paper, we propose Auto Evol-Instruct, aneffective approach to utilizing LLMs in designingmethods for executing instruction evolution. AutoEvol-Instruct automatically designs evolving meth-ods that make given instruction data more complex,enabling almost cost-free adaptation to differenttasks by only changing the input data of the frame-work. Firstly, to transition from manually-designedevolving rules to automated ones, we begin with auniversal initial evolving method. Our initial evolv-ing method is different from the method of EvolInstruct, which requires human experts to specifythe rules of evolution. Instead, it can autonomouslyanalyze the input instruction and brainstorm evolu-tion rules suitable for given data. Due to the diver-sity and complexity of varied instruction datasets,a fixed evolving method can not guarantee the sta-bility and effectiveness of all data evolution. There-fore, we leverage LLM as the optimizer to optimizethe initial evolving method iteratively to ensure thelowest failure rate for a given instruction dataset.We refer to the model used for evolution as the evolLLM, and the model used for optimization as the 1+1=?",
  "Instruction": "a+5=0 & a>0, a=? Optimizer LLM Evol LLM : Overall architecture of Auto Evol-Instruct. It illustrates the process of optimizing the initial evolvingmethod e0 into the optimal evolving method e, which specifically outlines the transition from et1 to et. Theyellow part and green part denote Evol Trajectory Analysis and Evolving Method Optimization respectively. x(1) tox(l) represents the example of evolutionary trajectory obtained by the evol LLM guided by et1 evolving x for lrounds. The feedback and potential improved evolving methods obtained from m Multiple Optimizations denote f 1tto f mtand e1t to emt respectively. optimizer LLM. This optimization process involvestwo critical stages: (1) Evol Trajectory Analysis:The optimizer LLM carefully analyzes the poten-tial issues and failures exposed in instruction evolu-tion performed by evol LLM, generating feedbackfor subsequent optimization. (2) Evolving MethodOptimization: The optimizer LLM optimizes theevolving method by addressing these identified is-sues in feedback. These stages alternate and re-peat to progressively develop an effective evolvingmethod using only a subset of the instruction data.Once the optimal evolving method is identified, itdirects the evol LLM to convert the entire instruc-tion dataset into more diverse and complex forms,thus facilitating improved instruction tuning. Our experiments show that the evolving meth-ods designed by Auto Evol-Instruct outperformthe Evol-Instruct methods (Xu et al., 2023; Luoet al., 2023a,b) designed by human experts ininstruction tuning across various capabilities, in-cluding instruction following, mathematical rea-soning, and code generation.Using only 10Kevolved ShareGPT for fine-tuning Mixtral-8x7B(Jiang et al., 2024), we achieve 8.09 on MT-Bench (Zheng et al., 2023) and 91.4 on AlpacaE-val (Li et al., 2023), surpassing GPT-3.5-Turboand WizardLM-70B, and comparable with Claude-2.0. Using only 7K evolved GSM8K training datafor fine-tuning Mixtral-8x7B, we achieve 82.49 onGSM8K, surpassing GPT-3.5-Turbo, WizardMath-70B and MetaMath-70B (Yu et al., 2023). Using20K evolved Code Alpaca to fine-tune DeepSeek-",
  "Evol-Instruct": "Instruction evolution (Xu et al., 2023) involves re-fining an instruction dataset to boost its complex-ity and diversity, enhancing instruction tuning ef-fectiveness. This method uses a human-designedevolving method, denoted as e, to transform orig-inal instruction dataset X = {x1, x2, , xn},where each xi is an instruction-response pair, intoan improved dataset Xe. The aim is for Xe to yieldsuperior performance Q(Xe) in a specific capabil-ity after instruction tuning, compared to the originaldatasets performance Q(X). Essentially, by evolv-ing the instruction dataset and subsequently tuninga model on Xe, the model should perform betteron the targeted capability than it would using theoriginal dataset.",
  "Auto Evol-Instruct": "Unlike Evol-Instruct, Auto Evol-Instruct is a fullyautomated framework that improves the complexityand quality of instruction data without any humanintervention. Its key advancements include: (1)automatically designing evolving methods for in-struction evolution, facilitating adaptation to a widerange of tasks and enhancing model capabilitiesacross a broader spectrum; (2) developing evolv-ing methods that surpass those crafted by humanexperts, while minimizing failures and ensuringsuccessful execution of instruction evolution. illustrates the process of automatingthe design of evolving methods in the Auto Evol-Instruct Framework (.1-3.3). We also de-tail specific examples of how the evolving methodchanges at each step in the . This frame-work begins with a carefully designed universalevolving method and a seed instruction datasetX (.1). It then iteratively optimizes thisinitial evolving method, e0, to obtain the optimalevolving method, e 1. In each optimization step t,we randomly sample a mini batch from X and uti-lize the evol LLM to evolve each instruction in thebatch l times. Then the optimizer LLM analyzesthe evolutionary trajectory of all instructions in thecurrent batch to identify existing issues and gen-erate feedback (.2). As shown in , the optimizer LLM identifies problems such asUnimproved Complexity. The optimizer LLMwill make corresponding optimizations to evolvingmethod et1 to obtain et based on the feedback.Specifically, the feedback Unimproved Complex-ity will prompt the optimizer LLM to add a con-straint Ensure the Complexity increase in et. Toimprove the stability, we execute analysis opti-mization multiple times with sampling decodingin parallel to obtain m optimized evolving meth-ods. Then, we select the method with the lowestevolution failure rate as the final et. The optimiza-tion process terminates when the failure rate of",
  "Initial Evolving Method Design": "The reason why Evol-Instruct is not universallyapplicable is that the methods for complicatinginstructions vary across different domains. For in-stance, in the coding domain, methods to increasethe complexity of instructions such as \"proposehigher time or space complexity requirements\"(Luo et al., 2023b) are meaningful, but they arenot quite suitable in the chat domain. The meth-ods for complicating instructions in Evol-Instructneed to be designed and summarized by humanexperts. The core difference in our initial evolvingmethod design lies in that we delegate the processof designing and summarizing evolving rules to theLLMs for automation. As shown in the ,firstly we ask the evol LLM to \"read the instructioncarefully and list all the possible methods to makethis instruction more complex\". Subsequently, theevol LLM is tasked with devising a comprehensiveplan based on the listed methods, and implementsthe plan to generate the evolved instruction. Lastly,the evol LLM conducts a thorough review of theevolved instruction, rectifying any unreasonableparts, and delivers the final evolved instruction.",
  "Evol Trajectory Analysis": "We primarily utilize the optimizer LLM to identifyissues emerging during the instruction evolutionprocess and offer subsequent feedback for the opti-mization of evolving method. (Examples of issuesare given in the Appendix B) Specifically, at op-timization step t, the evolving method et1 steersthe evol LLM to perform l rounds of evolutionon a batch of data Xt, culminating in the evolu-tionary trajectory, St = {Xt, X(1)t, , X(l)t }. Inthis trajectory, X(i)tdenotes the instruction evolvedfrom X(i1)tusing et1. Following this, the opti-mizer LLM scrutinizes the evolutionary trajectoryto pinpoint and provide feedback ft on any issuesdetected. (Prompt used is detailed in )",
  "Initial Evolving Method": "You are an Instruction Rewriter that rewrites the given #Instruction# into a more complex version. Please follow the steps below to rewrite the given \"#Instruction#\" into a more complex version. Step 1: Please read the \"#Instruction#\" carefully and list all the possible methods to make this instruction more complex (to make it a bit harder for well-known AI assistants such as ChatGPT and GPT4 to handle). Please do not provide methods to change the language of the instruction! Step 2: Please create a comprehensive plan based on the #Methods List# generated in Step 1 to make the #Instruction# more complex. The plan should include several methods from the #Methods List#. Step 3: Please execute the plan step by step and provide the #Rewritten Instruction#. #Rewritten Instruction# can only add 10 to 20 words into the \"#Instruction#\". Step 4: Please carefully review the #Rewritten Instruction# and identify any unreasonable parts. Ensure that the #Rewritten Instruction# is only a more complex version of the #Instruction#. Just provide the #Finally Rewritten Instruction# without any explanation. Please reply strictly in the following format: Step 1 #Methods List#: Step 2 #Plan#: Step 3 #Rewritten Instruction#: Step 4 #Finally Rewritten Instruction#: #Instruction#:{Instruction} : Initial Evolving Method. Under this method, the Evol LLM evolves the instruction. Auto Evol-Instructwill optimize this method into an optimal version for evolving the entire dataset of instructions efficiently. from the evol trajectory analysis, in accordancewith the overall instruction evolution requirements.In essence, during the step t, the optimizer LLMrefines the evolving method et1, by leveragingthe feedback ft.This meticulous optimizationyields an updated version of the evolving methodet. (Prompt in Optimization detailed in ). Multiple Optimizations In the Evol TrajectoryAnalysis and Method Optimization Process, the op-timizer LLM sometimes struggles to consistentlyprovide constructive feedback and enhance theevolving method. To bolster the stability of theAuto Evol-Instruct framework and draw inspirationfrom the self-consistency (Wang et al., 2022), weimplement a strategy where, at each step, the opti-mizer LLM conducts m times of analysis and opti-mization with sampling decoding. This generatesm different potential improved evolving methods,namely e1t to emt in , allowing the modelto explore more possibilities simultaneously (Yanget al., 2023). Specifically, we divide the instructiondata into training data X and a development set D.We use the obtained potential methods to evolveinstructions in D and generate corresponding re-sponse sets, denoted as Re1t to Remt . For a giveneit, we calculate its evolution failure rate based on",
  "|D|(2)": "Here, |D| represents the size of the developmentset. F(r) is a function that determines whether in-struction evolution has failed, returning 1 for fail-ure and 0 for success. We have designed a seriesof rules to determine whether evolution has failedbased on the reaction of evol LLM when generatinganswers for evolved instructions. For example, ifthe answer contains understood or Thank youand ends with a question mark, it indicates that theevolved instruction has not become more complexbut is responding to the instruction being evolved(please refer to Appendix A for detailed judgmentrules). Finally, the evolving method demonstratingthe lowest evolution failure rate is selected as thesubsequent steps evolving method et.",
  "Instruction Tuning on Evolved Data": "The Auto Evol-Instruct leads us to derive the op-timal evolving method e. This method is thenemployed to guide the evol LLM, which substan-tially improving the complexity and diversity of theentire instruction dataset. As a result, we acquirean evolved dataset. Subsequently, this enricheddataset is used to fine-tune the base LLM, therebybroadening the models range of capabilities.",
  "Evaluation Results": "Instruction Following We evaluate the instruction-following using MT-Bench and AlpacaEval. MT-Bench tests the model across various domainsthrough multi-turn dialogues, while AlpacaEval au-tomates assessment based on AlpacaFarm (Duboiset al., 2023). shows that our method sub-stantially improves performance across differentmodel scales. For smaller models, our methodimproves by approximately 0.63 on MT-Benchcompared to seed data. For larger models, theresstill a performance boost of 0.44. Despite usingonly 10K data for fine-tuning on Mixtral-8x7B, ourmethod matches or surpasses the performance ofopen-source models that utilize more data and trainon larger models, achieving results comparable toTulu-v2-dpo on MT-Bench and AlpacaEval. Ourmodel even performs on par with powerful closed-source models like Claude 2.0 and GPT-3.5-Turbo.Math Reasoning We assess the mathematicalreasoning capabilities using GSM8K benchmark(Cobbe et al., 2021). The GSM8K comprises com-plex graduate-level math problems, with 7,473training samples and 1,319 testing samples. Weemploy the zero-shot testing approach and usetest accuracy as the metric. demonstratesthat our Auto Evol-Instruct has significantly im-proved mathematical reasoning. For instance, ourmethod improved by 13.84 compared to the seeddata on Mistral-7B. Simultaneously, our methoduses a minimal amount of instruction data (only7K) and can exceed GPT-3.5-turbo after fine-tuningon Mixtral-8x7B. This indicates that our methodcan substantially raise the upper limit of quality in existing mathematical data.Code Generation We use the HumanEval (Chenet al., 2021) to test code-writing capabilities. Hu-manEval comprises 164 unique programming chal-lenges, and we use pass@1 as the metric. illustrates that our method enhances the modelscapabilities effectively. Our method demonstratessignificant improvement across various model sizescompared to Evol Instruct. For instance, at the33B scale, Evol-Instruct yields only a slight im-provement, while our method shows a boost of 5.4compared to Seed Data. Our results remain compet-itive even when compared with DeepSeek-Coder-Instruct-33B, which uses the same base model butwith instructions for fine-tuning on a much largerscale (about 2B tokens) than ours.",
  "Effect of Initial Evolving Method": "In this section, we delve into the significance ofthe Initial Evolving Method within the Auto Evol-Instruct framework, particularly focusing on itsimpact on data evolving across various capabilities.We employ several techniques to evolve datasetslike GSM8K, Alpaca (Taori et al., 2023), and CodeAlpaca. underscores the robust versatilityof initial evolving method in boosting different ca-pabilities, establishing it as an exemplary startingevolving method in the framework. For instance,when compared with Evol Instruct, initial evolv-ing method demonstrates a notable improvement,elevating the MT-Bench score from 6.31 to 6.60,and the HumanEval from 61.0 to 62.2. Moreover,the Auto Evol-Instruct framework, building on thefoundation laid by initial evolving method, exhibitspotential for further enhancements. It was observedthat on GSM8K, Auto Evol-Instruct could elevatethe performance from 62.7 to 64.4. These findingshighlight that our proposed method can effectivelyoptimize the initial evolving method, leading toimprovements in various benchmarks.To demonstrate the effectiveness of the AutoEvol-Instruct in enhancing different initial evolv-ing methods, we conducted an experiment using adeliberately simple evolving method. We removedmost of the key designs from the original initialevolving method, such as step-by-step evolving pro-cess, etc. (see for details). We applied ourframework to both this basic method and our well-designed initial evolving method on the GSM8Kdataset. As evident from , even when start-",
  "Effect of Multiple Optimizations": "We explore the impact of multiple optimizationsin Auto Evol-Instruct and choose GSM8K for ab-lations. We keep the default hyper-parameters ofAuto Evol-Instruct, exploring the effect of the num-ber of optimizations. (a) reveals a distinctpattern: as we increase the number of optimiza-tions, theres a notable enhancement in data effi-ciency via optimal evolving methods. For example,",
  ": Hyperparameters for Auto Evol-Instruct. GPT-3.5-turbo as evol LLM, GPT-4 as optimizer LLM": "setting the number of optimizations to 1 achieved62.7 on the GSM8K. This accuracy improved to65.0 when number of optimizations raised to 9.This trend indicates that more optimizations allowthe optimizer LLM to explore a wider array of op-tions, improving its ability to pinpoint areas whereevolving method can be further refined for opti-mal performance. However, there are importanttrade-offs to consider. Elevating the number ofoptimizations can also bring increase in resourcesconsumption (Guo et al., 2023). On the other hand,fewer optimizations may lead to a more focused re-finement of current evolving method, which couldresult in local optimal that might not fully exploitthe potential of evolving method. We also exploredthe relationship between the optimization steps andeffects of instruction tuning. (b) showsthat as the number of optimization steps increases,the performance can increase monotonically in thebeginning, but after 12 steps, it rapidly declines.This may be because over-optimization could po-tentially lead to an accumulation of superfluousinformation in the evolving method, consequentlypossibly diminishing its effectiveness (Examplesin .7).",
  ": Main Result": "pact of using GPT-3.5 and GPT-4 as the underlyingevol LLMs to evolve GSM8K. Notably, with GPT-4as the evol LLM, our methodology yields an im-provement from 63.2 to 70.7, surpassing the EvolInstruct. Additionally, employing a more advancedevol LLM enhances the effectiveness significantly.For instance, switching the evol LLM from GPT-3.5 to GPT-4 leads to a notable increase in perfor-mance, jumping from 64.4 to 70.7. These findingsclearly demonstrate the broad applicability and ef-fectiveness of our framework across different evolLLMs.",
  ": Different evolution execution LLMs": "results, highlighting the superior scalability of ourapproach in comparison to Evol Instruct. Notably,the data from round 1 of our method outperformsthat of Evol Instructs combined data from rounds 1and 2. Furthermore, the performance of our modelconsistently improves as we scale the data fromround 1 to a mixture of rounds 1, 2, and 3. 011+21+2+3 Auto Evol-InstructEvol Instruct",
  "Discussion of Complexity and Diversity": "Liu et al. (2023b) underscore the significant impactthat dataset complexity and diversity have on modelalignment. Instag (Lu et al., 2023) suggests thatthe variety and quantity of intentions and semanticsin a dataset are crucial factors for its complexityand diversity. We evolve 100 instructions usingvarious techniques, employing Instags method forautomated tagging. We assessed diversity by calcu-lating the average number of unique tags for eachdata, and complexity by the mean tag count. reveals a distinct correlation: as data becomesmore diverse and complex, model performancemarkedly improves. For instance, Evol Instructenhanced the original code alpaca, increasing itsdiversity from 1.95 to 2.37 and its complexity from4.06 to 4.55. This enhancement was mirrored ina notable elevation of the HumanEval, climbingfrom 57.9 to 64.0. This supports the success ofAuto Evol-Instruct in substantially boosting datacomplexity and diversity, thereby significantly im-proving model capability.",
  "Case Study": "The dynamic transformations inherent in the op-timization process are elaborated in Appendix J.This progression demonstrates a marked improve-ment in resolving issues encountered during in-struction evolution. provides examplesof how the evolving method is optimized at eachstep based on the previous one. For example, Ini-tial evolving method () guides the evolLLM to generate the evolved instruction. Then, theoptimizer LLM analyzes the evolution trajectoryand identifies issues such as redundancy and clar-ity in the evolved instruction, providing feedback.Based on this feedback, the optimizer LLM up-dates the evolving method by incorporating math-ematical elements like variables, constants, andconditions. This updated evolving method (Fig-ure 11) then guides the evol LLM to generate anupdated evolved instruction, which introduces aclearer challenge focused on understanding mathe-matical relationships and variable quantities acrosstwo periods.",
  "Cost Comparison": "Auto Evol-Instruct utilizes a small subset of thecomplete data to devise an optimal evolvingmethod. This method is then employed to evolvethe entire instruction dataset. comparesthe total API calls made by Auto Evol-Instruct andEvol Instruct. The results demonstrate that our AutoEvol-Instruct achieves significantly superior resultscompared to Evol Instruct, while incurring only afew thousand additional API calls. This negligibleextra cost of a few thousand API calls is incon-sequential when dealing with large-scale datasetscontaining thousands or millions of instructions.",
  "Related Work": "Instruction tuning emerges as a pivotal strategy forunlocking the potential of LLMs (Ouyang et al.,2022; Touvron et al., 2023b). By curating high-quality datasets, we can more efficiently align thesemodels with desired direction (Zhou et al., 2023).The challenge of scaling high-quality instruction data remains a central research interest. Some re-searchers prioritize human annotation for creat-ing instruction data, such as ShareGPT (Chianget al., 2023) and OpenAssistant (Kpf et al., 2023).Other researchers explore more efficient ways tobreak through the quality upper-bound of exist-ing datasets (Xu et al., 2023; Liu et al., 2023b;Zhao et al., 2023). Xu et al. (2023) introducesEvol-Instruct, a methodology that iteratively re-fines instruction-following data to produce datasetsthat are both more complex and diverse. Luo et al.(2023b) develop evolving methods tailored to thenuances of code data based on Evol-Instruct. Dis-tinct from these methodologies, our approach intro-duces a fully automated framework for developingevolving methods. This innovation is not only scal-able but also versatile, extending its utility across abroad spectrum of capabilities. LLMs like GPT-4and PaLM are capable of optimizing their outputthrough internal or external feedback mechanisms(Suzgun and Kalai, 2024; Wang et al., 2022; Yanget al., 2023). We use this capabilities to addressidentified issues in the evolving method and adaptto the characteristics of the instruction data.",
  "Conclusion": "This paper introduces Auto Evol-Instruct, an inno-vative approach that successfully automates the evo-lution of instruction datasets for LLMs, eliminatingthe need for human intervention. Our method cen-ters on the automatic analysis and summarizationof appropriate evolutionary strategies for the giveninstruction data. It iteratively refines evolving meth-ods by addressing the issues identified during theinstruction evolution process. The experiments con-ducted have shown that methods optimized by AutoEvol-Instruct, significantly surpass those crafted byhumans across various benchmarks, including MT-Bench, AlpacaEval, GSM8K and HumanEval.",
  "Limitations": "Although Auto Evol-Instruct has demonstrated ex-cellent performance in instruction tuning acrossvarious capabilities, several directions are worthexploring in future work:(1) While we have validated the effectiveness ofAuto Evol-Instruct on benchmarks reflecting dif-ferent capabilities such as instruction following,mathematical reasoning, and code generation, wecan further evaluate its performance on other taskslike MMLU (Hendrycks et al., 2021) and Truth- fulQA (Lin et al., 2022).(2) We have validated the effectiveness of ourmethod on multiple base LLMs, including Mis-tral, Mixtral-8x7B, CodeLlama-13B-Python, andDeepSeek-Coder-Base-33B. However, we can stillassess its effectiveness on other base LLM mod-els, such as Qwen (Bai et al., 2023) and LLaMA(Touvron et al., 2023a,b).(3) The evol LLM and Optimizer LLM used inAuto Evol-Instruct are primarily GPT-3.5-Turboand GPT-4. In the future, this can be expanded toinclude other LLMs, such as Claude.(4) We aim to propose an end-to-end automatedinstruction evolution framework that utilizes sim-ple and universal prompts for Evolutionary Trajec-tory Analysis and Evolutionary Method Optimiza-tion. While the prompts we employ are straight-forward, experiments demonstrate that the frame-work is highly effective. Moving forward, we canexplore more sophisticated prompts to implementEvolutionary Trajectory Analysis and EvolutionaryMethod Optimization, thereby further enhancingthe efficacy of the Auto Evol-Instruct.",
  "Ethics Statement": "All the datasets used in this paper are public andhave been reviewed to ensure they do not containany personally identifiable information or offensivecontent. However, as these datasets are sourcedfrom the Internet, potential bias may still be present.Furthermore, despite our careful review, the pro-cess of instruction evolution involving the LLMsthroughout may inadvertently introduce inappro-priate information into the evolved data. Its alsoworth noting that our models are fine-tuning onGPUs, which could have an environmental impact.",
  "Sahil Chaudhary. 2023. Code alpaca: An instruction-following llama model for code generation": "Mark Chen, Jerry Tworek, Heewoo Jun, QimingYuan, Henrique Ponde de Oliveira Pinto, Jared Ka-plan, Harri Edwards, Yuri Burda, Nicholas Joseph,Greg Brockman, et al. 2021.Evaluating largelanguage models trained on code. arXiv preprintarXiv:2107.03374. Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,Zhanghao Wu, Hao Zhang, Lianmin Zheng, SiyuanZhuang, Yonghao Zhuang, Joseph E Gonzalez, et al.2023. Vicuna: An open-source chatbot impressinggpt-4 with 90%* chatgpt quality. See org (accessed 14 April 2023). Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,Ashish Sabharwal, Carissa Schoenick, and OyvindTafjord. 2018. Think you have solved question an-swering? try arc, the ai2 reasoning challenge. arXivpreprint arXiv:1803.05457. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,Mark Chen, Heewoo Jun, Lukasz Kaiser, MatthiasPlappert, Jerry Tworek, Jacob Hilton, ReiichiroNakano, et al. 2021. Training verifiers to solve mathword problems. arXiv preprint arXiv:2110.14168. Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey,Abhishek Kadian, Ahmad Al-Dahle, Aiesha Letman,Akhil Mathur, Alan Schelten, Amy Yang, AngelaFan, et al. 2024. The llama 3 herd of models. arXivpreprint arXiv:2407.21783. Yann Dubois, Xuechen Li, Rohan Taori, Tianyi Zhang,Ishaan Gulrajani, Jimmy Ba, Carlos Guestrin, PercyLiang, and Tatsunori B. Hashimoto. 2023. Alpaca-farm: A simulation framework for methods that learnfrom human feedback. Preprint, arXiv:2305.14387. Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, KaiDong, Wentao Zhang, Guanting Chen, Xiao Bi,Y Wu, YK Li, et al. 2024. Deepseek-coder: When thelarge language model meets programmingthe rise ofcode intelligence. arXiv preprint arXiv:2401.14196. Qingyan Guo, Rui Wang, Junliang Guo, Bei Li, KaitaoSong, Xu Tan, Guoqing Liu, Jiang Bian, and Yu-jiu Yang. 2023. Connecting large language modelswith evolutionary algorithms yields powerful promptoptimizers. arXiv preprint arXiv:2309.08532. Dan Hendrycks, Collin Burns, Steven Basart, AndyZou, Mantas Mazeika, Dawn Song, and Jacob Stein-hardt. 2021. Measuring massive multitask languageunderstanding. In 9th International Conference onLearning Representations, ICLR 2021, Virtual Event,Austria, May 3-7, 2021. OpenReview.net. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, et al. 2023. Mistral7b. arXiv preprint arXiv:2310.06825. Albert Q Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, Chris Bam-ford, Devendra Singh Chaplot, Diego de las Casas,Emma Bou Hanna, Florian Bressand, et al. 2024.Mixtral of experts. arXiv preprint arXiv:2401.04088.",
  "Stephanie Lin, Jacob Hilton, and Owain Evans. 2022": "TruthfulQA: Measuring how models mimic humanfalsehoods. In Proceedings of the 60th Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long Papers), pages 32143252, Dublin,Ireland. Association for Computational Linguistics. Bingbin Liu, Sebastien Bubeck, Ronen Eldan, Janard-han Kulkarni, Yuanzhi Li, Anh Nguyen, Rachel Ward,and Yi Zhang. 2023a. Tinygsm: achieving> 80% ongsm8k with small language models. arXiv preprintarXiv:2312.09241. Wei Liu, Weihao Zeng, Keqing He, Yong Jiang,and Junxian He. 2023b.What makes good datafor alignment?a comprehensive study of auto-matic data selection in instruction tuning. Preprint,arXiv:2312.15685. Keming Lu, Hongyi Yuan, Zheng Yuan, Runji Lin, Jun-yang Lin, Chuanqi Tan, Chang Zhou, and JingrenZhou. 2023. # instag: Instruction tagging for analyz-ing supervised fine-tuning of large language models.arXiv e-prints, pages arXiv2308. Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-guang Lou, Chongyang Tao, Xiubo Geng, QingweiLin, Shifeng Chen, and Dongmei Zhang. 2023a. Wiz-ardmath: Empowering mathematical reasoning forlarge language models via reinforced evol-instruct.arXiv preprint arXiv:2308.09583. Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, XiuboGeng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qing-wei Lin, and Daxin Jiang. 2023b.Wizardcoder:Empowering code large language models with evol-instruct. arXiv preprint arXiv:2306.08568.",
  "OpenAI. 2023.Gpt-4 technical report.Preprint,arXiv:2303.08774": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,Carroll Wainwright, Pamela Mishkin, Chong Zhang,Sandhini Agarwal, Katarina Slama, Alex Ray, et al.2022. Training language models to follow instruc-tions with human feedback.Advances in NeuralInformation Processing Systems, 35:2773027744. Jie Ren, Samyam Rajbhandari, Reza Yazdani Am-inabadi, Olatunji Ruwase, Shuangyan Yang, MinjiaZhang, Dong Li, and Yuxiong He. 2021. {ZeRO-Offload}:Democratizing {Billion-Scale} modeltraining. In 2021 USENIX Annual Technical Con-ference (USENIX ATC 21), pages 551564. Baptiste Roziere, Jonas Gehring, Fabian Gloeckle, StenSootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,Jingyu Liu, Tal Remez, Jrmy Rapin, et al. 2023.Code llama: Open foundation models for code. arXivpreprint arXiv:2308.12950.",
  "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, YannDubois, Xuechen Li, Carlos Guestrin, Percy Liang,and Tatsunori B. Hashimoto. 2023. Stanford alpaca:An instruction-following llama model": "Hugo Touvron, Thibaut Lavril, Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, et al. 2023a.Llama:Open and effi-cient foundation language models. arXiv preprintarXiv:2302.13971. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023b.Llama 2: Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,Ed Chi, Sharan Narang, Aakanksha Chowdhery, andDenny Zhou. 2022. Self-consistency improves chainof thought reasoning in language models.arXivpreprint arXiv:2203.11171. Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,Pu Zhao, Jiazhan Feng, Chongyang Tao, and DaxinJiang. 2023.Wizardlm: Empowering large lan-guage models to follow complex instructions. arXivpreprint arXiv:2304.12244.",
  "Rowan Zellers, Ari Holtzman, Yonatan Bisk, AliFarhadi, and Yejin Choi. 2019. Hellaswag: Can amachine really finish your sentence? arXiv preprintarXiv:1905.07830": "Yingxiu Zhao, Bowen Yu, Binyuan Hui, Haiyang Yu,Fei Huang, Yongbin Li, and Nevin L Zhang. 2023.A preliminary study of the intrinsic relationship be-tween complexity and alignment.arXiv preprintarXiv:2308.05696. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, SiyuanZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023.Judging llm-as-a-judge with mt-bench and chatbotarena. arXiv preprint arXiv:2306.05685.",
  "AEvolution Failures Detection": "We categorize prevalent scenarios of failure (Xuet al., 2023) in instruction evolution across vari-ous capabilities and devise general detection rulesF. (See for illustrative examples corre-sponding to these situations) When the followingscenarios occur, the return value of F is 1:1. Stagnant Complexity: The evolved instruc-tion does not exhibit enhanced complexity, merelyaddressing the scope of the original instruction.Characteristically, responses to such instructionsbegin with phrases like Understood or Thankyou and conclude with a question mark.2. Insufficient Qualification: The evolved in-structions lack necessary qualifications, necessitat-ing additional inquiries for generating a meaningfulresponse. Typically, responses in these situationscommence with Sure and terminate with a ques-tion mark.3. Loss of Key Information: The evolved in-struction omits crucial details from the originalinstruction, leading to a need for supplementaryinformation before a substantial response can beprovided. Responses in these cases often includerequests for more information, typically indicatedby phrases like please provide.",
  "BEvolution Issue Examples": "To illustrate the issues encountered during dataevolution, we conduct an empirical analysis by ran-domly selecting 200 instructions from the GSM8K. These instructions are then subjected to evolu-tion using the initial evolving method ().We employ the issue detection method described in.2 to pinpoint and categorize prevalent is-sues. Our findings, including illustrative examples,are presented in the and .The analysis reveals that the initial evolvingmethod is plagued by a series of shortcomings. Forexample, it fails to adequately account for the com-plexity inherent in evolving instructions. This over-sight results in several critical problems, such as thetendency to alter the core nature of the problem, theintroduction of irrelevant details, or the generationof contradictions with the original problem setup.Furthermore, the initial method appears to overlookthe unique attributes of mathematical instructions.This lapse leads to evolved instructions that oftencontain Incorrect or unrealistic mathematical cal-culations. These observations underscore the ur-gent need for a comprehensive optimization of the",
  "Prompt For Evol Trajectory Analysis": "The following list shows cases where an Instruction evolves into a more complex version of an Instruction. For each case, stage 0 represents the Instruction in its initial state, and each subsequent stage requires an increase in complexity based on the previous stage.Please identify cases that failed to evolve, and provide their case ID and reasons. {Evolutionary Trajectory}",
  "CDifferecnt Optimizer LLM": "Current open-source LLMs, such as Llama 3(Dubey et al., 2024), possess the powerful feedbackand correction capabilities required by optimizerLLMs. We used Meta-Llama-3-70B-Instruct asboth the optimizer LLM and evol LLM for our ex-periments in mathematical reasoning. As shownin the , our method is applicable to open-source models, and current powerful open-sourcemodels like Llama 3 can even surpass proprietaryLLMs such as GPT-4.",
  "DResults on Open LLM Leaderboard": "We also investigate whether the models other ca-pabilities are affected after SFT. To assess this,we use the Open LLM Leaderboard for evalua-tion, as presented in . The Open LLMLeaderboard consists of four classification tasks:ARC (Clark et al., 2018), HellaSwag (Zellers et al.,2019), MMLU (Hendrycks et al., 2021), and Truth-fulQA (Lin et al., 2022). The results show that,compared to the Mistral-7B-Instruct-v0.1 and theZephyr-Beta-SFT models trained with a larger SFTdataset (200K samples), our model successfullyretains its abilities without experiencing notabledegradation.",
  "Introduce new concepts or variableswithout building on the previousinstruction, making the problemconfusing or unrealistic": "One barnyard owl makes 7 hoot sounds perminute, measured in decibels. If thebarn is located near a constructionsite and only 15 hoot sounds per minuteare heard coming out of the barn, howmany barnyard owls are making the hootsounds, assuming each owl makes the samenumber of hoot sounds? Assuming some owls make 10 hoot soundsper minute and others make 5 hoot soundsper minute, and the barn is located 100meters away from a construction site,how many barnyard owls are making thehoot sounds if 20 hoot sounds per minuteare heard coming out of the barn, and eachowl makes 7 hoot sounds per minute measuredin decibels? Introduce new concepts (owls makingdifferent amounts of hoots, the barnslocation, sound measurement in decibels)without clearly building on the previousinstruction. The complexity does notgradually increase but rather jumpserratically.",
  "Introduce mathematical operationsor equations that dont make sensein the context of the problem orare mathematically incorrect": "If Betty has 12 oranges, and Sandra has3 times as many oranges as Betty, thenSandra has 12 multiplied by 3, whichequals 36 oranges. Emily has 7 timesas many oranges as Sandra, so Emilyhas 36 raised to the power of 7 oranges. If Betty has 12 oranges, and Sandra has 3times as many oranges as Betty, then Sandrahas 12 multiplied by 3, which equals 36oranges. Emily has 7 times as many oranges asSandra, so Emily has 3.6 x 10^8 oranges. IfEmily has more oranges than Betty, then she has3.6 x 10^11 million oranges.",
  "Inconsistent orcontradictory informationIntroduce information thatcontradicts previous instruction": "John orders food for a massive restaurant.He orders 1000 kilograms of beef for 8per pound. He also orders twice that muchchicken at 3 per kilogram. If the costof chicken is $2 per kilogram, and thetotal cost of beef is greater than thetotal cost of chicken, what is the finalcost of the order? John, the head chef of a high-end restaurant,orders a massive amount of food for hisestablishment. He orders 1000 kilograms ofpremium beef at a cost of 8 per pound, andtwice that amount of organic chicken at a costof 3 per kilogram. If the cost of chicken is$2 per kilogram, and the total cost of beef isgreater than the total cost of chicken, what isthe final cost of the order? Please calculatethe final cost using the following equation:(1000 * 2 * 3) + (1000 * 8 * 0.45) = ? The progression of the instructionis not logical. The original instructionstates that the cost of chicken is 3per kilogram, and then in the evolvedinstruction it contradicts this bystating that the cost of chicken is 2per kilogram.",
  "Make the instruction less clearor more confusing, introduceunnecessary complications, orinclude irrelevant and unrelatedvariables": "Nedy can eat 800 grams of crackers fromMonday to Thursday, but no more than 200grams per day. If Nedy ate 2x on Friday,1/2x on Saturday, and 1/2x on Sunday,and Nedy is eating chocolate chip cookies,how many crackers did Nedy eat in all fromMonday to Sunday? Nedy can eat y grams of saltine crackers withpeanut butter from Monday to Thursday, butno more than 200 grams per day, and onlyafter 5 pm, while standing on one foot,blindfolded, and reciting the alphabet backward.If Nedy ate 2x on Friday, 1/2x on Saturday,and 1/2x on Sunday, how many saltine crackerswith peanut butter did Nedy eat in all fromMonday to Sunday, while wearing a hat andsunglasses and listening to classical music? The evolved instruction has lost itsclarity and consistency with theoriginal instruction. The conditionsfor Nedy to eat crackers have becomeabsurd and unrealistic, such as standingon one foot, blindfolded, and recitingthe alphabet backward, whichunnecessarily complicates the instruction.",
  "Introduce a level of complexitythat is not supported by theprovided information or isunrelated to the original problem": "Hawkeye is driving his electric bike tohis aunts place, which is now 60 milesaway. He has to charge his battery for$3.5 per charge, and he needs to chargeit five times due to the increaseddistance. However, his cousin needs aride to a nearby town that is 20 milesaway, and Hawkeye needs to drop himoff first. His cousin offers to pay forhalf of the battery charging costs, whichtotal $17.50 including tax and a servicefee of $2. On the way, it starts rainingheavily, making the journey more difficult. Hawkeye is riding his electric bike, which hasa maximum speed of 30 mph and a battery thatneeds to be charged every 30 miles. He is onhis way to his aunts place, which is now 100miles away. However, his battery malfunctionsafter 40 miles, and he has to stop and fix it,which takes 20 minutes. On the way, he encountersa toll road that costs $5, and he has to take adetour to avoid a construction site, adding anextra 10 miles to the journey. Each time hecharges his battery, it takes 30 minutes, andhe needs to charge it five times, costing him$17.50 including tax and a service fee of $2.His cousin needs a ride to the nearby town, whichis 20 miles away, to catch a flight. His cousinoffers to pay for half of the battery chargingcosts. On the way, there is a thunderstorm warningin effect, making the journey more difficult. The evolved instruction introduces a lotof new elements (bikes maximum speed,battery malfunction, toll road, constructionsite, thunderstorm warning) that do notdirectly evolve from the originalinstructions.",
  "Decrease in complexitySimplify the problem instead ofmaking it more complex": "Marcus wants to buy a new pair of shoes.He decided to pay not more than $130 forthem. He found a pair for $120, on whichhe got a discount of 30%. How much moneywill he manage to save by buying theseshoes and not spending the assumed maximumamount? Marcus wants to buy a new pair of leather shoes.He decided to pay not more than 130 for them.He found a pair for 120, on which he got adiscount of 30%. The original price of the shoeswas 171.43. After the discount, the final priceof the shoes is 84. Marcus managed to save $36.43by buying these shoes and not spending the assumedmaximum amount. He saved 21.26% of the originalprice, which is more than 20%. Therefore, Marcuswill buy the shoes. The complexity of evolved instruction islower than that of original instruction.In evolved instruction, the answer to theproblem is included in the instruction,which simplifies the problem instead ofmaking it more complex.",
  "Introduce elements that are notlogically connected or aprogressive development of theprevious instruction": "Harry is a professional dog-walker. Hewalks dogs for different families ondifferent days of the week. On Sunday,he walks 3 dogs for 7 each. On Monday,he walks 7 dogs for 5 each and 16 for2 dogs. On Tuesday, he walks 15 dogs for6 each and 35 for 5 dogs. On Wednesday,he walks 10 dogs for 5 each and 18 for3 dogs. On Thursday, he walks 13 dogs for4 each and 36 for 4 dogs. And on Friday,he walks 8 dogs for 5 each and 20 for 2dogs. If he walks all the dogs, how muchmoney will Harry earn in a week? Harry is a professional dog-walker who walks dogsfor different families in various locations throughoutthe week. If he walks all the dogs, including threelarge dogs, seven small dogs, two medium-sized dogs,fifteen mixed-breed dogs, five purebred dogs, tenrescue dogs, three therapy dogs, thirteen seniordogs, four puppies, eight working dogs, and twoshow dogs, he will earn a total of $493.",
  "Introduce additional variablesor conditions that do notincrease the complexity of thetask in a relevant or logicalway": "Tabitha has 50 dollars. She gives her mom15 dollars and invests half of what is leftin the stock market for 1 year, with a 10%tax. She spends some money on 15 items thatcost 1 dollar each, with a 10% discount anda 15% tip. Tabitha also has a loan of 5dollars that she has to pay off. How muchmoney does Tabitha have left after allthese transactions? Tabitha has 50 dollars. She gives her mom 15dollars and invests half of what is left inthe stock market for 1 year, with a 15% tax.She spends some money on 20 items that cost1 dollar each, with a 20% discount and a 25%tip. Tabitha also has a loan of 10 dollarsthat she has to pay off. After reinvestingthe profits from the stock market for anotheryear, how much money does Tabitha have leftafter all these transactions? The evolved instruction did not evolvefrom original instruction. The questionat the end of evolved instructionintroduces a new concept (reinvestingprofits) that was not present in theprevious stages, and it does notclearly build on the previous stages.",
  ": Results on Open LLM Leaderboard": "evol LLM and optimizer LLM to GPT-4. We useEvol-Instruct and Auto Evol-Instruct to obtain 10Kevolved data respectively. Then, we perform in-struction tuning on Mistral-7B (Jiang et al., 2023)(small) and Mistral-8x7B (large).For mathematical reasoning, GSM8K trainingdata serves as seed data, evol LLM and optimizerLLM are set to GPT-4. About 7K evolved data",
  "Optimization": "{Feedback} I will provide you with the method for evolving the above instructions.You need to optimize this method based on the feedback from the evolution failure case, without harming the performance on other cases, and ensure that the complexity increase brought by the optimized method is not lower than the previous method. Please provide the optimized method in the following format. ```Optimized Method\\n<Optimized Method Here>\\n``` {Evol Prompt}",
  ": Weak Initial Evolving Method": "In the code generation, Code Alpaca (Chaud-hary, 2023) is selected as the seed data and evolLLM is set to GPT-3.5-turbo, and the optimizerLLM to GPT-4. About 20K evolved data is ob-tained respectively through Evol-Instruct and AutoEvol-Instruct, and instruction tuning is performedon CodeLlama-13B-Python (Roziere et al., 2023)(small) and DeepSeek-Coder-Base-33B (Guo et al.,2024) (large).",
  "F.2Hyperparameters in Auto Evol-Instruct": "During the Auto Evol-Instruct process, we config-ure the mini-batch size to 10, the development setsize to 50, the optimizer LLM temperature to 0.6,its top p to 0.95, and the evol LLM temperature to0. We also set the total optimization steps to 10,with 5 multiple optimizations performed in eachstep by default. Unless specified otherwise, weconduct only one round of evolving on the instruc-tions and generate corresponding responses. Theexperiments are performed using the Azure Ope-nAI ChatGPT API and GPT-4 API.",
  "F.3Training Details": "We employ DeepSpeed Zero-Stage 3 (Ren et al.,2021) on eight NVIDIA Tesla A100 GPUs to trainmodels. For the integration of multi-turn conver-sations, we use the Vicuna-style template. In allexperiments of this paper, the training parametersare set with a maximum input length of 2048. Formodels trained based on Mistral-7b, we set thebatch size to 128, train for 4 epochs, and set thelearning rate to 5e-6. For models trained basedon CodeLlama-13B-Python and DeepSeek-Coder-Base-33B, we set the batch size to 192, train for 3epochs, and set the learning rate to 2e-5. For theMixtral-8x7B model, we set the batch size to 200,train for 4 epochs, and set the learning rate to 5e-6.",
  "GBaseline": "We compare the method proposed in this paperwith the following models:(1) Closed-Source Models: These include lead-ing LLMs like OpenAIs GPT-3.5 and GPT-4 (Ope-nAI, 2023).(2) Open-Source Base Models: We compareour method with a variety of open-source base mod-els such as LLaMA-2 (Touvron et al., 2023b), Mis-tral (Jiang et al., 2023), and CodeLlama (Roziereet al., 2023).(3) Open-Source Instruction-Tuned Models:Include instruction tuning models like Vicuna (Chi-ang et al., 2023).(4) Direct Instruction Tuning with Seed Data:We use the same seed instruction data as in ourmethod to conduct direct instruction tuning on thebase model.(5) Instruction Evolution Methods: We mainlycompare with Evol-Instruct (Xu et al., 2023; Luoet al., 2023a,b) that requires human experts in-volved. To be fair, we will use the exact sameevol LLM to evolve instruction datasets such asShareGPT, GSM8K, and CodeAlpaca.",
  "JCase Study": "We use GSM 8K to illustrate the dynamic changesof the evolving method during the Auto Evol-Instruct process. Figures 10 to Figures 14 depictthe transition from the initial evolving method tothe 15th steps evolving method. illus-trates examples of how the evolving method is op-timized at each step based on the previous one.Its important to note that the table just showcasessample examples and does not comprehensivelyrepresent the entire optimization process.",
  "Step 0()": "Natalia, in April, managedto distribute a total ofclips to precisely 48individuals categorized asfriends, and subsequently,in May, she managed todistribute exactly half thenumber of clips she did inthe prior month. Determinethe cumulative total ofclips Natalia distributedover the span of the twomonths. Redundancy: The use of phraseslike \"managed to distribute\"and \"categorized as friends\"is redundant and does notadd value to the complexityin terms of deepening theproblems challenge. Instead,it merely complicates thelanguage unnecessarily.Clarity: The rewritteninstruction loses clarity byincorporating verbose languagethat could confuse the readerwithout actually enhancing theinstructional or problem-solvingcomplexity.",
  "Step 1()": "Henry, for a period of 14days, consumed 9 pillsdaily. Out of these, 4pills were priced at 1.50each, and the remaining 5pills were priced at 7.00each, which is 5.50 morethan the cost of the cheaperpills. Calculate Henrystotal expenditurefor all the pills overthe 14 days. Unnecessary Complexity: Theevolved instruction introducesdetailed breakdowns of costsin a way that may confuse thebasic arithmetic problem aboutsumming costs, withoutadding substantive educationalvalue.Over-specification:The instruction specifies thenumber of days and pills indetail in each sentence, whichcan be redundant and maydetract from the clarity andsimplicity needed forunderstanding the mathematicalcalculation required.",
  "Henry took 9 pills dailyover a two-week period. Fourof these pills each cost1.50, and the rest cost7.00 each. Calculate thetotal amount Henry spenton the pills during thisperiod": "This version addresses the initialissues by removing redundantdetails and focusing on thearithmetic operations requiredto solve the problem, thusmaintaining the relevance andeducational value of the exercise. : Case Study illustrates how the evolving method is optimized at each step based on the previous one. The\"Original Instruction\" represents the instruction to be evolved, \"Evolving Method\" represents the current evolvingmethod, \"Evolved Instruction\" is the instruction evolved by the Evol LLM using the evolving method, \"Feedback\"represents issues identified by the optimizer LLM through Evol Trajectory Analysis of the evolved instruction,\"Updated Evolving Method\" represents the evolving method optimized by the optimizer LLM based on the feedback,and \"Updated Evolved Instruction\" represents the instruction evolved by the updated evolving method guided by theEvol LLM. Its important to note that the table just showcases sample examples and does not comprehensivelyrepresent the entire optimization process.",
  "Evolving Method in Step 0 (Initial Evolving Method)": "You are an Instruction Rewriter that rewrites the given #Instruction# into a more complex version. Please follow the steps below to rewrite the given \"#Instruction#\" into a more complex version. Step 1: Please read the \"#Instruction#\" carefully and list all the possible methods to make this instruction more complex (to make it a bit harder for well-known AI assistants such as ChatGPT and GPT4 to handle). Please do not provide methods to change the language of the instruction! Step 2: Please create a comprehensive plan based on the #Methods List# generated in Step 1 to make the #Instruction# more complex. The plan should include several methods from the #Methods List#. Step 3: Please execute the plan step by step and provide the #Rewritten Instruction#. #Rewritten Instruction# can only add 10 to 20 words into the \"#Instruction#\". Step 4: Please carefully review the #Rewritten Instruction# and identify any unreasonable parts. Ensure that the #Rewritten Instruction# is only a more complex version of the #Instruction#. Just provide the #Finally Rewritten Instruction# without any explanation. Please reply strictly in the following format: Step 1#Methods List#: Step 2#Plan#: Step 3#Rewritten Instruction#: Step 4#Finally Rewritten Instruction#: #Instruction#:",
  ": Evolving method at optimization step 0 (initial evolving method)": "only add 10 to 20 words into the #Instruction# . Step 4: Please carefully review the #Rewritten Instruction# and identify any unreasonable parts. Ensure that the #Rewritten Instruction# is only a more complex version of the #Instruction#. Just provide the #Finally Rewritten Instruction# without any explanation. Please reply strictly in the following format: Step 1#Methods List#: Step 2#Plan#: Step 3#Rewritten Instruction#: Step 4#Finally Rewritten Instruction#: #Instruction#:",
  "Evolving Method in Step 1": "Step 1: Carefully read the initial instruction and identify all the elements involved - this includes variables, constants, operations, and conditions. Step 2: Consider how each element could be made more complex. For variables, this could involve introducing more variables or making the existing variables dependent on others. For constants, consider changing them to variables or making them dependent on other factors. For operations, consider introducing more complex operations or multiple steps. For conditions, consider adding more conditions or making the existing conditions more complex. Step 3: Formulate a plan to integrate these complexities into the instruction. Ensure that the changes are coherent and relevant to the initial problem context. The plan should not just randomly add complexity but should make the problem more interesting or challenging in a meaningful way. Step 4: Rewrite the instruction according to the plan. Ensure that the rewritten instruction is still understandable and that it accurately represents the initial problem context. The rewritten instruction should only add 10 to 20 words to the original instruction. Step 5: Review the rewritten instruction and check for any inaccuracies or inconsistencies. Make sure that the rewritten instruction is a more complex version of the original instruction and not a completely different problem. If any parts of the rewritten instruction are unreasonable or do not fit the problem context, revise them as necessary. Please reply strictly in the following format: Step 1#Elements Identified#: Step 2#Complexity Additions#: Step 3#Plan#: Step 4#Rewritten Instruction#: Step 5\\n#Finally Rewritten Instruction#: #Instruction#:",
  "Evolving Method in Step 2": "Step 1: Carefully read the initial instruction and identify all the elements involved - this includes variables, constants, operations, and conditions. Step 2: Consider how each element could be made more complex. For variables, this could involve introducing more variables or making the existing variables dependent on others. For constants, consider changing them to variables or making them dependent on other factors. For operations, consider introducing more complex operations or multiple steps. For conditions, consider adding more conditions or making the existing conditions more complex. Step 3: Formulate a plan to integrate these complexities into the instruction. Ensure that the changes are coherent and relevant to the initial problem context. The plan should not just randomly add complexity but should make the problem more interesting or challenging in a meaningful way. Avoid introducing irrelevant concepts or complicating the problem to the extent of changing its nature. Step 4: Rewrite the instruction according to the plan. Ensure that the rewritten instruction is still understandable and that it accurately represents the initial problem context. The rewritten instruction should only add 10 to 20 words to the original instruction. Make sure that the progression of complexity is smooth and gradual. Step 5: Review the rewritten instruction and check for any inaccuracies or inconsistencies. Make sure that the rewritten instruction is a more complex version of the original instruction and not a completely different problem. If any parts of the rewritten instruction are unreasonable or do not fit the problem context, revise them as necessary. Please reply strictly in the following format: Step 1#Elements Identified#: Step 2#Complexity Additions#: Step 3#Plan#: Step 4#Rewritten Instruction#: Step 5#Finally Rewritten Instruction#: #Instruction#:",
  "Evolving Method in Step 12": "Step 1: Carefully read the initial instruction and identify all the elements involved - this includes variables, constants, operations, and conditions. Step 2: Consider how each element could be made more complex. For variables, this could involve introducing more variables or making the existing variables dependent on others. For constants, consider changing them to variables or making them dependent on other factors. For operations, consider introducing more complex operations or multiple steps. For conditions, consider adding more conditions or making the existing conditions more complex. Step 3: Formulate a plan to integrate these complexities into the instruction. Ensure that the changes are coherent and relevant to the initial problem context. The plan should not just randomly add complexity but should make the problem more interesting or challenging in a meaningful way. Avoid introducing irrelevant concepts or complicating the problem to the extent of changing its nature. Step 4: Rewrite the instruction according to the plan. Ensure that the rewritten instruction is still understandable and that it accurately represents the initial problem context. The rewritten instruction should only add 10 to 20 words to the original instruction. Make sure that the progression of complexity is smooth and gradual. Step 5: Review the rewritten instruction and check for any inaccuracies or inconsistencies. Make sure that the rewritten instruction is a more complex version of the original instruction and not a completely different problem. If any parts of the rewritten instruction are unreasonable or do not fit the problem context, revise them as necessary. Step 6: Ensure that the complexity increase is consistent and logical. Avoid introducing new conditions or variables that are not related to the initial problem. The complexity should evolve from the initial problem and not transform it into a different problem. Step 7: Test the rewritten instruction to ensure that it is solvable and that the complexity has indeed increased. If the problem is too difficult or impossible to solve, revise it as necessary. Please reply strictly in the following format: Step 1#Elements Identified#: Step 2#Complexity Additions#: Step 3#Plan#: Step 4#Rewritten Instruction#: Step 5#Revised Instruction#: Step 6#Consistency Check#: Step 7#Final Rewritten Instruction#: #Instruction#:",
  "Evolving Method in Step 15": "Step 1: Carefully read the initial instruction and identify all the elements involved - this includes variables, constants, operations, and conditions. Step 2: Consider how each element could be made more complex. For variables, this could involve introducing more variables or making the existing variables dependent on others. For constants, consider changing them to variables or making them dependent on other factors. For operations, consider introducing more complex operations or multiple steps. For conditions, consider adding more conditions or making the existing conditions more complex. Step 3: Formulate a plan to integrate these complexities into the instruction. Ensure that the changes are coherent and relevant to the initial problem context. The plan should not just randomly add complexity but should make the problem more interesting or challenging in a meaningful way. Avoid introducing irrelevant concepts or complicating the problem to the extent of changing its nature. Step 4: Rewrite the instruction according to the plan. Ensure that the rewritten instruction is still understandable and that it accurately represents the initial problem context. The rewritten instruction should only add 10 to 20 words to the original instruction. Make sure that the progression of complexity is smooth and gradual. Step 5: Review the rewritten instruction and check for any inaccuracies or inconsistencies. Make sure that the rewritten instruction is a more complex version of the original instruction and not a completely different problem. If any parts of the rewritten instruction are unreasonable or do not fit the problem context, revise them as necessary. Step 6: Ensure that the complexity increase is consistent and logical. Avoid introducing new conditions or variables that are not related to the initial problem. The complexity should evolve from the initial problem and not transform it into a different problem. Step 7: Test the rewritten instruction to ensure that it is solvable and that the complexity has indeed increased. If the problem is too difficult or impossible to solve, revise it as necessary. If the complexity of the instruction decreases at any stage, go back to the previous stage and revise the instruction to maintain a consistent increase in complexity. Please reply strictly in the following format: Step 1#Elements Identified#: Step 2#Complexity Additions#: Step 3#Plan#: Step 4#Rewritten Instruction#: Step 5#Revised Instruction#: Step 6#Consistency Check#: Step 7#Final Rewritten Instruction#: #Instruction#: : Evolving Method at Optimization Step 15. On the basis of the evol prompt at the previous step, a newconstraint has been added, If the complexity of the instruction decreases at any stage, go back to the previous stageand revise the instruction to maintain a consistent increase in complexity."
}