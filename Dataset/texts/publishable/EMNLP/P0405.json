{
  "Abstract": "Through the advent of pre-trained languagemodels, there have been notable advancementsin abstractive summarization systems. Simulta-neously, a considerable number of novel meth-ods for evaluating factual consistency in ab-stractive summarization systems has been de-veloped. But these evaluation approaches in-corporate substantial limitations, especially onrefinement and interpretability. In this work,we propose highly effective and interpretablefactual inconsistency detection method FIZZ(Factual Inconsistency Detection by Zoom-inSummary and Zoom-out Document) for ab-stractive summarization systems that is basedon fine-grained atomic facts decomposition.Moreover, we align atomic facts decomposedfrom the summary with the source documentthrough adaptive granularity expansion. Theseatomic facts represent a more fine-grainedunit of information, facilitating detailed un-derstanding and interpretability of the sum-marys factual inconsistency. Experimental re-sults demonstrate that our proposed factual con-sistency checking system significantly outper-forms existing systems. We release the code at",
  "Introduction": "With the development of pre-trained languagemodels, abstractive summarization systems us-ing these language models have made remarkableprogress in generating fluent and natural summa-rizations (Chang et al., 2023). However, one of thenotable challenges these systems confront is thehallucination, causing language models to gener-ate summaries that are factually inconsistent withthe given article (Maynez et al., 2020; Kryscin-ski et al., 2020; Tam et al., 2023; Zhang et al.,2023).Recognizing the significance of this is-sue, various evaluation metrics have been intro-duced to detect these errors, starting from tra-",
  "You can only nd which sentences are suspicious.You can understand why the summary is incorrect": ": Comparison between sentence level evalua-tion and atomic facts level evaluation. The numbersin parentheses represent the maximum NLI entailmentscores obtained by comparing each sentence and atomicfact with the source document on a sentence-wise basis. ditional methods like ROUGE (Lin, 2004) andBERTScore (Zhang et al., 2020) to a large num-ber of advanced metrics (Goyal and Durrett, 2020,2021; Scialom et al., 2021; Fabbri et al., 2022; La-ban et al., 2022; Luo et al., 2023; Zha et al., 2023;Wang et al., 2023a). Especially, many of the recentworks (Laban et al., 2022; Schuster et al., 2022;Zha et al., 2023) adopted sentence level evaluationusing Natural Language Inference (NLI) systemsfor factual consistency checking. Although these studies have shown a certainlevel of performance in summary evaluation, theystill exhibit significant deficiencies in accuracy. Ad-ditionally, they substantially lack in interpretability,an area crucial for further development in the fieldof summarization factual consistency detection. Asshown in , sentence level evaluation oftenfails to check the details of the various facts in eachsentence, resulting in lower accuracy and lower in-terpretability. Furthermore, we find that pair-wisesingle sentence level evaluation is vulnerable tosummary evaluation that requires multi-sentencereasoning. In addition, expressions such as pro-nouns in sentences can lead the NLI system to make incorrect judgments in single sentence levelevaluation.In this paper, we propose an interpretable sum-marization factual inconsistency detection system,FIZZ, which overcomes the issues of previoussentence level NLI-based evaluation. As in Fig-ure 2, FIZZ first resolves coreferences in both thesource document and the generated summary. Sub-sequently, we decompose this coreference resolvedsummary into atomic facts, which is an approachthat zooms in the summary. This atomic fact canbe considered a more fine-grained information unitembedded within the text than a sentence at a broadlevel. As in the atomic fact examples in ,a single sentence from the summary can be seg-mented into two or more distinct units of infor-mation. This approach allows for a more detailedanalysis of textual information, which is crucial forevaluating the factuality of generated text. Usingthese atomic facts, we check the consistency ofeach atomic fact against the source document usingan NLI model. As highlighted in , factualinconsistencies that cannot be detected at the sen-tence level can be identified through evaluation atthis atomic fact level with higher interpretability.Also, we propose a granularity expansion methodthat can adaptively increase the number of contextsentences when verifying the consistency of eachatomic fact. Through this way of zooming outthe document, we efficiently check the consistencyof certain atomic facts that require multi-sentencelevel reasoning.Experimental results show that our proposed sys-tem FIZZ achieves state-of-the-art performance onthe AGGREFACT (Tang et al., 2023) benchmarkdataset. FIZZ exhibits high interpretability by uti-lizing atomic facts. Furthermore, We have testedon various LLMs to implement atomic fact gener-ation task and identified the best model suited forthis task. Additionally, our analysis shows that flex-ibly increasing the granularity choice of the sourcedocument significantly enhances accuracy.",
  "VAL (Scialom et al., 2021) and QAFACTE-": "VAL (Fabbri et al., 2022) generate questions withboth the summary and the document.Parsing-based methods discover relationships byemploying syntactic parsing process, thereafter cal-culating the proportion of summary-derived rela-tions that align with those extracted from sourcedocuments. Goodrich et al. (2019) extract relationtuples for the evaluation. DAE (Goyal and Durrett,2020, 2021) propose utilizing a dependency arcbetween the entities and the relationship.There is a growing trend for using LLMs likeChatGPT (OpenAI, 2022) and GPT-4 (OpenAI,2023) on summarization factual consistency check-ing (Luo et al., 2023; Chen et al., 2023; Wang et al.,2023a; Gekhman et al., 2023; Yang et al., 2024).Initially, Luo et al. (2023) explores ChatGPTs abil-ity in evaluating factual consistency for text sum-marization with zero-shot prompting. Yang et al.(2024) extend the work by excluding irrelevantsentences from both documents before providingprompts to GPT-4.SUMMAC (Laban et al., 2022) re-visit NLI-based models and granularity choice for incon-sistency detection in summarization.ALIGN-SCORE (Zha et al., 2023) develops an alignmentsystem, incorporating a summarization consistencychecking metric and an NLI model, which hasbeen trained across a diverse array of tasks thatcan be aligned with NLI. The recently proposedmethod, FENICE (Scir et al., 2024), also alignsdecomposed atomic facts with several documentsentences, but it lacks interpretability on summaryside. Our proposed system, FIZZ, is also based onNLI. However, unlike the aforementioned systems,which mostly compare the summary at the sentencelevel, FIZZ conducts comparisons at a more fine-grained atomic fact level with high interpretability. Atomic Facts GenerationTo the best of ourknowledge, van Halteren and Teufel (2003) pio-neered the introduction of an atomic informationunit, named a factoid, within the field of summa-rization evaluation. Building on this foundationalwork, Nenkova and Passonneau (2004) proposedthe Pyramid method, a manual evaluation proto-col for summarization that employs Summariza-tion Content Units (SCUs), also referred to as Se-",
  "Sentence 5: \"We've worked so hard for so long, it'd be a massive mistake to get complacent and think the job is done.\"": ": Overall flow of FIZZ. The pipeline begins by applying coreference resolution to both the summary andthe document. Atomic facts are then decomposed from the summary using an LLM. These atomic facts are filteredand subsequently scored against the document. The scores are refined through granularity expansion. The ultimatescore is defined by choosing the minimum score. mantic Content Units. This innovative approachhas inspired a significant body of subsequent re-search (Harnly et al., 2005; Shapira et al., 2019;Gao et al., 2019; Bhandari et al., 2020; Zhang andBansal, 2021). Liu et al. (2023) referred to these el-ementary information units as Atomic Content Unit,or Atomic Facts. However, the realm of these in-vestigations is primarily concentrated on assessingsummarization itself via the examination of atomicfacts crafted by human annotators1.In the scope of hallucination detection and factverification for text generated by models, there hasbeen a recent initiative to employ LLMs to cre-ate atomic facts. FACTSCORE (Min et al., 2023)utilize InstructGPT (Ouyang et al., 2022) for thecreation of atomic facts. Following this work, FAC-TOOL (Chern et al., 2023) introduce a fact veri-fication pipeline that leverages fine-grained infor-mation units generated by ChatGPT, referred to asclaims. In this study, we present a novel methodFIZZ leveraging atomic semantic unit, from nowon called atomic fact, in the domain of summariza-tion factual inconsistency detection.",
  "We note that Zhang and Bansal (2021) generated SCUswith semantic role labeling": "lowing this, we proceed to generate atomic factsfrom the coreference-resolved summary leveragingLLMs as a zooming-in approach for the summary(.2). Using the generated atomic facts,we compute the score of each atomic fact with theNLI system (.3). Finally, we propose agranularity expansion method, which is a way ofzooming out the documents, to compute the scorefor the summaries that contain high abstractivenessmore accurately.",
  "Coreference Resolution": "To enhance the entailment recognition capabili-ties of NLI models, FIZZ first conducts centeredaround coreference resolution in both documentand summary texts. The motivation behind thisapproach is driven by the inherent limitations ob-served in NLI models when processing texts withpronouns. Specifically, we find that NLI modelstend to struggle with recognizing entailment whenpresented with premises and hypotheses that con-tain the same content but differ in their use of pro-nouns and explicit entity names. To address thischallenge, FIZZ employs pronoun resolution insummaries by analyzing them on a sentence-by-sentence basis to extract atomic facts. This strategynot only facilitates a more granular understandingof the summary content but also avoids the limitedcontext length in LLMs.Furthermore, applying pronoun resolution to thedocument text ensures that the entities are explic-itly named, aligning the premise more closely withthe hypothesis. By resolving coreferences in both documents and summaries, our approach aims tobridge the gap between pronoun use and explicitentity naming, thereby improving the performanceof NLI models in entailment tasks. This dual focuson both document and summary texts underscoresthe comprehensive nature of our strategy to bol-ster the accuracy and reliability of NLI models inhandling a variety of linguistic expressions.Formally, given a document D and its summaryS, we define coreference resolution as fcoref, whichmakes:",
  "Atomic Facts Decomposition": "Atomic Facts GenerationAs demonstrated in, sentence level evaluation of summariescan often yield inaccurate results. Therefore, wepropose a method that evaluates the factuality ofsummaries at a more fine-grained level, specificallyat the level of atomic facts as exemplified in Fig-ure 2. By employing atomic facts, which are highlydetailed units of information, FIZZ considerablyenhances interpretability.The definition of an atomic fact differs acrossstudies, primarily due to the inherently subjectivenature of this concept. We propose our own defini-tion of an atomic fact that is designed to align withand complement the nature of NLI models. Build-ing upon Bhandari et al. (2020), we specify furtherthat an atomic fact is short and concise, contain-ing no more than two or three entities, with personentities specifically resolved any of coreferences.We generate atomic facts from summaries at thesentence level after resolving coreferences. Thisstrategy for atomic fact generation not only in-creases the quantity of atomic facts but also substan-tially augments the generated summarys pool ofinformation. To extract atomic facts from the sum-maries, we input prompts into the LLM that includeboth a task description and a sentence-level sum-mary, as exemplified in . This approachsystematically decomposes each sentence in thesummary into individual atomic facts, facilitatinga comprehensive extraction and representation ofinformation. The coreference resolved summaryS = {sj}Nj=1, where sj represents the jth sen-tence in S and N the total number of sentences inS, could be decomposed to a set of atomic facts Algorithm 1 Filtering Out Incorrect Atomic FactsInput: An NLI model M; coreference resolved summaryS = {sj}Nj=1; decomposed atomic facts A = {ak}Lk=1.Initialize: set Afiltered = 1: for k = 1, 2, . . . , L do2:for j = 1, 2, . . . , N do",
  "A = {ak}Lk=1, with L denotes the total number ofsentences in A": "Atomic Facts FilteringOne significant issuewith atomic facts generated by LLMs is that thesefacts are often produced not from the content ofsummaries themselves but from the pretrainedknowledge embedded within the LLMs. For ex-ample, when we decompose the sentence of thesummary \"The mass, which has risen some 50ftabove sea level, measures roughly 1,000 - 1,640ftlong, and 100ft wide\", the decomposed atomic factscontain an atomic fact \"The mass is a noun\". Suchatomic facts may not align with either the sum-maries or the documents and can significantly influ-ence the scoring method described in .3.Consequently, the exclusion of these atomic factsbecomes a necessary step in our process.Hence, we utilize an NLI model to filter out in-correct atomic facts. Our approach leverages theprobabilistic distribution of the NLI model, whichcategorizes outcomes into three types: Entailment(E), Contradiction (C), and Neutral (N). In thefiltering process, we set the summary S as thepremise, and the atomic fact A as the hypothesis.We filter out atomic facts that exhibit exception-ally low entailment scores. We outline the detailedprocedure of the atomic facts filtering process inAlgorithm 1.",
  "Atomic Facts Scoring": "Atomic Facts Pair-Wise ScoringTo computethe score for each atomic fact of the summaries,FIZZ first decomposes the coreference resolveddocument into sentences. We split the documentD into M sentences and the filtered atomic factsAfiltered into N sentences, formulating D ={di}Mi=1 and Afiltered = {ak}Lk=1, respectively.We use each (di, ak) as an input for an NLI model,positioning the generated atomic fact as the hy- pothesis and the sentence of the document as thepremise.Finally, we assign scores to each atomic factbased on the maximum entailment score obtainedthrough comparison with every sentence in thedocument.The atomic fact entailment scoresE = {ei,k}, where 1 i M and 1 k L,are computed to a vector T:",
  "T = {t1, . . . , tL}(2)": "Adaptive Granularity ExpansionSummariesgenerated by abstractive summarization systemscontain a high degree of abstractiveness. This ab-stractiveness occurs when content spread acrossmultiple sentences in the document is condensedinto one or two sentences in the summary. To ac-curately detect factual inconsistencies within suchsummaries, it is necessary to zoom out and exam-ine multiple sentences across the source document.Furthermore, several studies have demonstratedthat considering multiple sentences from the docu-ment leads to better accuracy (Laban et al., 2022;Glover et al., 2022).We aim to identify scores where max(ek, ck, nk)is not ek from the T. For atomic facts associatedwith these scores, we further increase the granular-ity of the document and perform computation onceagain. We incrementally increase the granularitystarting from the document sentence di that con-tributed to each identified score, limiting the granu-larity at a maximum of three sentences (di1 + di,di + di+1, di2 + di1 + di, di + di+1 + di+2, di1+ di + di+1). Subsequently, we re-calculate thescores within this expanded context and replace theoriginal scores with the maximum value observedamong the re-calculated scores and the original.As a result, the vector T is transformed into T as certain scores are replaced by new scores. De-tailed information on this procedure is provided inAlgorithm 2.The final score is then determined by theminimum score within vector T, enabling a highlyinterpretable evaluation:",
  "In our experiments, we leverage MT5 (Bohnet et al.,2023) for coreference resolution, which returns": "Algorithm 2 Scoring with Document GranularityExpansionInput: An NLI model M; coreference resolved documentD = {di}Mi=1; decomposed atomic facts A = {ak}Lk=1.Initialize: T = ; Max granularity size gran = 3.1: Define C(D, g) = list of subsets of D with size of g.2: Define F(C(D, g)) which returns whether C(D, g) is aconsecutive list.",
  ": end forOutput: vector T with maximum entailment scores fromeach atomic fact": "with the identification of clusters referring to thesame entities. With these clusters, we further im-plement rule-based pronoun substitution strategiesto generate coreference resolved texts. For atomicfact decomposition, the Orca-2 model (Mitra et al.,2023) is utilized. Additionally, this work adoptsthe same off-the-shelf NLI model as implementedin SUMMAC (See Appendix D for more details).",
  "Benchmark Datasets": "We use AGGREFACT (Tang et al., 2023) benchmarkdataset, a comprehensive aggregation of 9 lead-ing summary factual consistency detection datasetscurrently available. AGGREFACT is stratified intothree distinct splits, namely FTSOTA, EXFORMER,and OLD, with each split containing its own valida-tion and test sets. We standardize the evaluation asa binary classification and choose the best thresholdfrom the validation set following SummaC. Finally,we apply this threshold to the test set and reportthe balanced accuracy score, considering the imbal-",
  "Baselines": "We adopt all of the baselines of AGGREFACTdataset: DAE (Goyal and Durrett, 2020, 2021),QuestEval (Scialom et al., 2021), SummaC-ZS and SummaC-Conv (Laban et al., 2022),QAFactEval (Fabbri et al., 2022), ChatGPT-ZS andChatGPT-CoT (Luo et al., 2023), ChatGPT-DA andChatGPT-Star (Wang et al., 2023a). Also, we re-port the results with AlignScore (Zha et al., 2023),which is a recently introduced system for checkingthe factual consistency of summaries based on NLI.Additionally, we incorporate FACTSCORE (Minet al., 2023) and FACTOOL (Chern et al., 2023) inour baselines. These methods decompose gener-ated texts into atomic facts and then retrieve cor-responding entries from a given knowledge base,such as Wikipedia, to evaluate the factuality of thegenerated context. For the purpose of verification,we assume the availability of this knowledge base,which we use as the source document to assesssummary factual consistency. In FACTSCORE, weemploy a No-context LM for factual verification.This approach operates on a QA basis, assessingwhether atomic facts are true or false with respectto the source document. In FACTOOL, we utilizea Knowledge-based QA approach. This also fol-lows a QA format but incorporates the CoT method,where the LLM evaluates if claims are true or falserelative to the source document. Details of theexperiments are provided in Appendix B.",
  "Results": "We present the performance outcomes obtained byapplying each metric to the AGGREFACT bench-mark dataset in .We show the perfor-mance of three versions of our proposed met-ric: FIZZ, its without granularity expanded ver-sion, FIZZw/o GE, and its without atomic factsversion, FIZZw/o AF . The complete results forAGGREFACT-CNN and AGGREFACT-XSUM aredisplayed in . FIZZ demonstrates the high-est average performance, followed by FIZZw/o GEand FIZZw/o AF .Additionally, we provide results for a single-threshold approach on AGGREFACT-FTSOTA splitas in Tang et al. (2023). We list the best thresholdfindings for the AGGREFACT-CNN-FTSOTA andAGGREFACT-XSUM-FTSOTA splits, with corre-sponding binary classification balanced accuracyscores in . In this setting, FIZZ achievesthe highest average performance, with FIZZw/o GEcoming in second. Both metrics perform exception-ally well on the CNN split. Furthermore, the gran-ularity expansion in FIZZ leads to notably higherperformance improvements on the XSUM split.Both FACTSCORE and FACTOOL have demon-strate scores that are comparable to or exceed thoseof ChatGPT-based metrics. It appears that decom-posing summaries into atomic facts and comparingthem with the source document is more effectivethan performing factuality checking on the entiresummary. However, metrics based on ChatGPT in-herently face disadvantages compared to other met-rics, which can be tuned by adjusting thresholds;",
  "Analysis": "LLMs used for Atomic Facts DecompositionTo investigate the most suitable LLMs for gen-erating atomic facts, we evaluate the generationof atomic facts using various LLMs, includinggpt-3.5-turbo, gpt-3.5-turbo-instruct, andother 7B models such as Zephyr (Tunstall et al.,2023) and Mistral (Jiang et al., 2023). The results,documented in , demonstrate that whilethe atomic facts generated by gpt-3.5-turbo andgpt-3.5-turbo-instruct generally perform bet-ter compared to other metrics, they are still inferiorto those produced by Orca-2. The performancedrop associated with the gpt series suggests a note-worthy observation. We explain that this discrep-ancy is due to the length of the atomic facts. Asshown in , which includes the average tokenlength of atomic facts after the filtering processper summary, there is a clear inverse relationshipbetween the number of tokens in an atomic factand its average performance. Longer atomic factstend to contain more entities and are less concise.Such sentences are less suitable as hypotheses whencompared sentence-wise using NLI models. Fur-thermore, the sensitivity of using the minimumatomic fact scores as the final score exacerbates thechallenge, making it difficult to achieve desired out-comes with lengthy sentences. In contrast, other 7B",
  "\"We've worked so hard for so long, it'd be a massive mistake to get complacent and think the job is done.\"": ": The effect of granularity expansions and coref-erence resolution in real AGGREFACT dataset. The en-tailment score of an atomic fact and document sentencewith (a) only Coreference Resolution, (b) only Granu-larity Expansion, and (c) the both. models such as LLaMa (Touvron et al., 2023) showlimitations in adhering to instructions for atomicfact decomposition. Details of the model usage areprovided in Appendix C.In previous studies (Zhang and Bansal, 2021; Chern et al., 2023; Scir et al., 2024), the evalu-ation of the quality and the completeness of theLLM generated atomic facts focuses solely on con-tent similarity (i.e., ROUGE-1) with human-writtenatomic facts. However, we consider content similar-ity evaluation to be insufficient and added two ad-ditional factors: 1) Average token length in atomicfacts and 2) Average number of atomic facts. In, we demonstrate the correlation betweenthe average token length of atomic facts and overallperformance. Building on this, we now analyze thetoken length of both human-written and generatedatomic facts. Additionally, since the content sim-ilarity metric does not take into account the num-ber of atomic facts, we also include the averagenumber of atomic facts in our results. We reportthe comparative analysis of the LLM generatedatomic facts against human-written atomic factsin . The experiments were implementedusing the RoSE (Liu et al., 2023) dataset, whichincludes 2,500 summaries and their correspondinghuman-written atomic facts. As shown in the ex-perimental results, gpt-3.5-turbo demonstratesthe highest capability by achieving the top score incontent similarity. However, it shows a significant",
  ": Size of granularity choice in granularity ex-pansion on AGGREFACT-FTSOTA split. s/it indicatesseconds per iteration for the inference of an NLI model": "difference in the number of atomic facts and thenumber of tokens in atomic facts. In contrast, Mis-tral scores lower in content similarity but exhibitshigher human correlation in the number of atomicfacts and token lengths. The model that achievesthe highest human correlation in both the numberof atomic facts and token lengths is Orca-2, whichshows the best performance among LLMs as in. These findings suggest that while contentsimilarity is important, the number of atomic factsand token lengths are equally critical factors to con-sider. Details on computing content similarity areprovided in Appendix G. Sizes of Granularity ExpansionAs underscoredin .3, accurately evaluating the factualconsistency of abstractive summaries necessitatesan expansion of document granularity. This re-quirement stems from the observation that a singlesentence within a summary may incorporate con-tent from multiple sentences within the document.Illustrative of this point, highlights thatsegmenting conversational dialogues into discretesentences can lead to a loss of contextual clarity,where the synthesis of various segmented sentencesis required for an accurate interpretation.SUMMAC present experimental results acrossdifferent granularity choices, categorizing docu-ment granularity into a sentence, two sentences,paragraph, and full document levels. However,adjusting document granularity in such a mannerreduces interpretability and undermines result re-liability. Our approach is to adaptively increasegranularity only for atomic facts where the entail-ment score significantly decreases. presents the outcomes associated withvarying granularity sizes in adaptive granularityexpansion. The experimental findings reveal a con-sistent improvement in average performance withincreasing granularity, particularly for summariesderived from XSum (Narayan et al., 2018). Thissignificant performance boost can be attributed tothe inherently abstractive nature of XSum-based",
  ": Effect of coreference resolution of documentand atomic facts on AGGREFACT-FTSOTA splits beforethe process of granularity expansion": "summaries.Despite the increase in average score for themaximum of four sentences, the scores for CNNsummaries actually declined. Additionally, we ob-serve that computational costs rose with increasinggranularity. Hence, we determined that the maxi-mum of three sentences represents the best trade-off between computational cost and performance.Details on granularity expansion condition choiceare provided in Appendix F. Effectiveness of Coreference ResolutionIn theapplication of NLI models for comparing premiseswith hypotheses, the significance of coreferenceresolution cannot be overstated. As outlined in Sec-tion 3.1, failure to resolve pronouns in the premisesignificantly hinders the attainment of desired out-comes. This point is vividly illustrated in , where the difference between document(b) anddocument(c) is merely the resolution of pronouns.Yet, this seemingly minor modification leads toa stark contrast in entailment scores, with docu-ment(b) achieving a score of 0.09 compared todocument(c)s 0.83. The discrepancy arises dueto the document (premise)s reference to \"he\" notbeing recognized as pertaining to \"Chris Gunter\",as stated in the atomic fact (hypothesis).Moreover, presents more granular ex-perimental results on the impact of coreferenceresolution. We implemented experiments to eval-uate the impact of coreference resolution on bothdocuments and atomic facts. Our investigation in-cluded scenarios where coreference resolution wasapplied and cases where it was not. We show thattexts with resolved coreferences, whether they beatomic facts or documents, consistently outperformthose without resolution. Notably, there is a markedimprovement in performance on datasets based onCNN (Hermann et al., 2015) summaries comparedto those based on XSum summaries. This is likelydue to the extractive nature of CNN-based sum-maries, as opposed to the more abstractive sum-maries derived from XSum. Details on coreference SummaryDocument",
  "resolution usage are provided in Appendix E": "Failure Case StudyWe analyze the drawbacksof decomposing summaries into atomic facts inthe summary factual consistency checking task,through the main example in , which com-pares the drawbacks of analyzing atomic facts ver-sus sentences. When comparisons are made at thesentence level, a sentence can be correctly judgedas entailing the content of a document. Conversely,when breaking down the content into atomic facts,the fact \"The tweet was about a rocket landing.\"receives a maximum entailment score of only 0.33.This particular atomic fact remains even after under-going the filtering process. As a result, a summarythat is factually consistent may be erroneously clas-sified as factually inconsistent due to the analysisof this single atomic fact.",
  "Conclusion": "In this work, we propose a novel method, FIZZ,in detecting summary factual inconsistency. Ourapproach decomposes summaries into atomic factsand conducts a sentence-wise comparison withthe document, and achieves state-of-the-art per-formance on the AGGREFACT benchmark dataset.Also, our proposed system has a higher inter-pretability due to its ability to precisely identifywhich parts of a summary are factually inaccurateby breaking it down into atomic facts. Furthermore,we analyze the necessity and significance of coref-erence resolution and granularity expansion in thecontext of summary factual consistency checking.",
  "Our proposed method is quite time-consuming. No-tably, during the coreference resolution phase, we": "leverage 11B model. This process requires moretime than other factual consistency checking sys-tems. The practical applicability of FIZZ in real-time settings remains to be determined.Furthermore, our research was limited to sum-maries based on articles and news domains. Wedid not verify the effectiveness of FIZZ in otherdomains such as dialogue summarization (Tanget al., 2024) or medical summarization (Wang et al.,2023b). Additionally, our study was confined toEnglish-language data. The validity of FIZZ needsto be assessed in datasets based on other languages.Despite these limitations, we believe our methodpaves a new path in the area of summarizationfactual consistency detection. This work could be asignificant contribution to the field, pending furthervalidation across varied domains and languages.",
  "Acknowledgement": "This research was supported by the Chung-AngUniversity Research Grants in 2023. This researchwas partly supported by Institute for Information &Communications Technology Planning & Evalua-tion (IITP) through the Korea government (MSIT)under Grant No. 2021-0-01341 (Artificial Intelli-gence Graduate School Program (Chung-Ang Uni-versity)). Manik Bhandari, Pranav Narayan Gour, Atabak Ash-faq, Pengfei Liu, and Graham Neubig. 2020. Re-evaluating evaluation in text summarization.InProceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 93479359, Online. Association for Computa-tional Linguistics.",
  "based system. Transactions of the Association forComputational Linguistics, 11:212226": "Samuel R. Bowman, Gabor Angeli, Christopher Potts,and Christopher D. Manning. 2015. A large anno-tated corpus for learning natural language inference.In Proceedings of the 2015 Conference on Empiri-cal Methods in Natural Language Processing, pages632642, Lisbon, Portugal. Association for Compu-tational Linguistics. Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu,Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan Yi,Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang,Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie.2023. A survey on evaluation of large language mod-els.",
  "Shiqi Chen, Siyang Gao, and Junxian He. 2023. Eval-uating factual consistency of summaries with largelanguage models": "I Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, KehuaFeng, Chunting Zhou, Junxian He, Graham Neubig,Pengfei Liu, et al. 2023. Factool: Factuality detec-tion in generative aia tool augmented frameworkfor multi-task and multi-domain scenarios. arXivpreprint arXiv:2307.13528. Esin Durmus, He He, and Mona Diab. 2020. FEQA: Aquestion answering evaluation framework for faith-fulness assessment in abstractive summarization. InProceedings of the 58th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 50555070, Online. Association for Computational Lin-guistics. Alexander Fabbri, Chien-Sheng Wu, Wenhao Liu, andCaiming Xiong. 2022. QAFactEval: Improved QA-based factual consistency evaluation for summariza-tion. In Proceedings of the 2022 Conference of theNorth American Chapter of the Association for Com-putational Linguistics: Human Language Technolo-gies, pages 25872601, Seattle, United States. Asso-ciation for Computational Linguistics. Yanjun Gao, Chen Sun, and Rebecca J. Passonneau.2019. Automated pyramid summarization evaluation.In Proceedings of the 23rd Conference on Computa-tional Natural Language Learning (CoNLL), pages404418, Hong Kong, China. Association for Com-putational Linguistics. Zorik Gekhman, Jonathan Herzig, Roee Aharoni, ChenElkind, and Idan Szpektor. 2023.TrueTeacher:Learning factual consistency evaluation with largelanguage models. In Proceedings of the 2023 Con-ference on Empirical Methods in Natural LanguageProcessing, pages 20532070, Singapore. Associa-tion for Computational Linguistics. John Glover, Federico Fancellu, Vasudevan Jagan-nathan, Matthew R. Gormley, and Thomas Schaaf.2022. Revisiting text decomposition methods forNLI-based factuality scoring of summaries. In Pro-ceedings of the 2nd Workshop on Natural Language",
  "Generation, Evaluation, and Metrics (GEM), pages97105, Abu Dhabi, United Arab Emirates (Hybrid).Association for Computational Linguistics": "Ben Goodrich, Vinay Rao, Peter J. Liu, and MohammadSaleh. 2019. Assessing the factual accuracy of gener-ated text. In Proceedings of the 25th ACM SIGKDDInternational Conference on Knowledge Discovery& Data Mining, KDD 19, page 166175, New York,NY, USA. Association for Computing Machinery. Tanya Goyal and Greg Durrett. 2020. Evaluating factu-ality in generation with dependency-level entailment.In Findings of the Association for Computational Lin-guistics: EMNLP 2020, pages 35923603, Online.Association for Computational Linguistics. Tanya Goyal and Greg Durrett. 2021. Annotating andmodeling fine-grained factuality in summarization.In Proceedings of the 2021 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 14491462, Online. Association for Computa-tional Linguistics. Aaron Harnly, Ani Nenkova, Rebecca Passonneau, andOwen Rambow. 2005. Automation of summary eval-uation by the pyramid method. In International Con-ference on Recent Advances in Natural LanguageProcessing, RANLP 2005 - Proceedings, Interna-tional Conference Recent Advances in Natural Lan-guage Processing, RANLP, pages 226232. Associ-ation for Computational Linguistics (ACL). Inter-national Conference on Recent Advances in NaturalLanguage Processing, RANLP 2005 ; Conferencedate: 21-09-2005 Through 23-09-2005.",
  "Matthew Honnibal, Ines Montani, Sofie Van Lan-deghem, and Adriane Boyd. 2020. spaCy: Industrial-strength Natural Language Processing in Python": "Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, Llio Renard Lavaud,Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,Thibaut Lavril, Thomas Wang, Timothe Lacroix,and William El Sayed. 2023. Mistral 7b. Wojciech Kryscinski, Bryan McCann, Caiming Xiong,and Richard Socher. 2020. Evaluating the factualconsistency of abstractive text summarization. InProceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 93329346, Online. Association for Computa-tional Linguistics. Philippe Laban, Tobias Schnabel, Paul N. Bennett, andMarti A. Hearst. 2022. SummaC: Re-visiting NLI-based models for inconsistency detection in summa-rization. Transactions of the Association for Compu-tational Linguistics, 10:163177.",
  "Chin-Yew Lin. 2004. ROUGE: A package for auto-matic evaluation of summaries. In Text Summariza-tion Branches Out, pages 7481, Barcelona, Spain.Association for Computational Linguistics": "Yixin Liu, Alex Fabbri, Pengfei Liu, Yilun Zhao, Liny-ong Nan, Ruilin Han, Simeng Han, Shafiq Joty,Chien-Sheng Wu, Caiming Xiong, and DragomirRadev. 2023. Revisiting the gold standard: Ground-ing summarization evaluation with robust humanevaluation. In Proceedings of the 61st Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long Papers), pages 41404170, Toronto,Canada. Association for Computational Linguistics.",
  "Zheheng Luo, Qianqian Xie, and Sophia Ananiadou.2023. Chatgpt as a factual inconsistency evaluatorfor text summarization": "Joshua Maynez, Shashi Narayan, Bernd Bohnet, andRyan McDonald. 2020. On faithfulness and factu-ality in abstractive summarization. In Proceedingsof the 58th Annual Meeting of the Association forComputational Linguistics, pages 19061919, On-line. Association for Computational Linguistics. Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis,Wen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettle-moyer, and Hannaneh Hajishirzi. 2023. FActScore:Fine-grained atomic evaluation of factual precisionin long form text generation. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing, pages 1207612100, Singa-pore. Association for Computational Linguistics. Arindam Mitra, Luciano Del Corro, Shweti Mahajan,Andres Codas, Clarisse Simoes, Sahaj Agarwal, XuxiChen, Anastasia Razdaibiedina, Erik Jones, Kriti Ag-garwal, Hamid Palangi, Guoqing Zheng, Corby Ros-set, Hamed Khanpour, and Ahmed Awadallah. 2023.Orca 2: Teaching small language models how to rea-son. Shashi Narayan, Shay B. Cohen, and Mirella Lapata.2018. Dont give me the details, just the summary!topic-aware convolutional neural networks for ex-treme summarization. In Proceedings of the 2018Conference on Empirical Methods in Natural Lan-guage Processing, pages 17971807, Brussels, Bel-gium. Association for Computational Linguistics. Ani Nenkova and Rebecca Passonneau. 2004. Evaluat-ing content selection in summarization: The pyramidmethod. In Proceedings of the Human LanguageTechnology Conference of the North American Chap-ter of the Association for Computational Linguistics:HLT-NAACL 2004, pages 145152, Boston, Mas-sachusetts, USA. Association for Computational Lin-guistics. Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal,Jason Weston, and Douwe Kiela. 2020. AdversarialNLI: A new benchmark for natural language under-standing. In Proceedings of the 58th Annual Meet-ing of the Association for Computational Linguistics,",
  "OpenAI. 2023. Gpt-4 technical report": "Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,Carroll Wainwright, Pamela Mishkin, Chong Zhang,Sandhini Agarwal, Katarina Slama, Alex Gray, JohnSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,Maddie Simens, Amanda Askell, Peter Welinder,Paul Christiano, Jan Leike, and Ryan Lowe. 2022.Training language models to follow instructions withhuman feedback. In Advances in Neural InformationProcessing Systems. Tal Schuster, Sihao Chen, Senaka Buthpitiya, AlexFabrikant, and Donald Metzler. 2022. Stretchingsentence-pair NLI models to reason over long doc-uments and clusters. In Findings of the Associationfor Computational Linguistics: EMNLP 2022, pages394412, Abu Dhabi, United Arab Emirates. Associ-ation for Computational Linguistics.",
  "Tal Schuster, Adam Fisch, and Regina Barzilay. 2021": "Get your vitamin C! robust fact verification withcontrastive evidence. In Proceedings of the 2021Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 624643, Online. As-sociation for Computational Linguistics. Thomas Scialom, Paul-Alexis Dray, Sylvain Lamprier,Benjamin Piwowarski, Jacopo Staiano, Alex Wang,and Patrick Gallinari. 2021. QuestEval: Summariza-tion asks for fact-based evaluation. In Proceedings ofthe 2021 Conference on Empirical Methods in Natu-ral Language Processing, pages 65946604, Onlineand Punta Cana, Dominican Republic. Associationfor Computational Linguistics. Alessandro Scir, Karim Ghonim, and Roberto Navigli.2024. FENICE: Factuality evaluation of summariza-tion based on natural language inference and claimextraction. In Findings of the Association for Compu-tational Linguistics ACL 2024, pages 1414814161,Bangkok, Thailand and virtual meeting. Associationfor Computational Linguistics. Ori Shapira, David Gabay, Yang Gao, Hadar Ronen, Ra-makanth Pasunuru, Mohit Bansal, Yael Amsterdamer,and Ido Dagan. 2019. Crowdsourcing lightweightpyramids for manual summary evaluation. In Pro-ceedings of the 2019 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics: Human Language Technologies, Volume1 (Long and Short Papers), pages 682687, Min-neapolis, Minnesota. Association for ComputationalLinguistics.",
  "the Association for Computational Linguistics: ACL2023, pages 52205255, Toronto, Canada. Associa-tion for Computational Linguistics": "Liyan Tang, Tanya Goyal, Alex Fabbri, Philippe La-ban, Jiacheng Xu, Semih Yavuz, Wojciech Kryscin-ski, Justin Rousseau, and Greg Durrett. 2023. Un-derstanding factual errors in summarization: Errors,summarizers, datasets, error detectors. In Proceed-ings of the 61st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 1162611644, Toronto, Canada. Associationfor Computational Linguistics. Liyan Tang, Igor Shalyminov, Amy Wing mei Wong,Jon Burnsky, Jake W. Vincent, Yuan Yang, SiffiSingh, Song Feng, Hwanjun Song, Hang Su, LijiaSun, Yi Zhang, Saab Mansour, and Kathleen McK-eown. 2024. Tofueval: Evaluating hallucinations ofllms on topic-focused dialogue summarization. Hugo Touvron, Thibaut Lavril, Gautier Izacard, XavierMartinet, Marie-Anne Lachaux, Timothe Lacroix,Baptiste Rozire, Naman Goyal, Eric Hambro, FaisalAzhar, Aurelien Rodriguez, Armand Joulin, EdouardGrave, and Guillaume Lample. 2023. Llama: Openand efficient foundation language models. ArXiv,abs/2302.13971. Lewis Tunstall, Edward Beeching, Nathan Lambert,Nazneen Rajani, Kashif Rasul, Younes Belkada,Shengyi Huang, Leandro von Werra, ClmentineFourrier, Nathan Habib, Nathan Sarrazin, Omar San-seviero, Alexander M. Rush, and Thomas Wolf. 2023.Zephyr: Direct distillation of lm alignment. Hans van Halteren and Simone Teufel. 2003. Examin-ing the consensus between human summaries: initialexperiments with factoid analysis. In Proceedings ofthe HLT-NAACL 03 Text Summarization Workshop,pages 5764. Jiaan Wang, Yunlong Liang, Fandong Meng, ZengkuiSun, Haoxiang Shi, Zhixu Li, Jinan Xu, Jianfeng Qu,and Jie Zhou. 2023a. Is ChatGPT a good NLG evalu-ator? a preliminary study. In Proceedings of the 4thNew Frontiers in Summarization Workshop, pages111, Singapore. Association for Computational Lin-guistics. Lucy Lu Wang, Yulia Otmakhova, Jay DeYoung,Thinh Hung Truong, Bailey Kuehl, Erin Bransom,and Byron Wallace. 2023b.Automated metricsfor medical multi-document summarization disagreewith human evaluations. In Proceedings of the 61stAnnual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers), pages 98719889, Toronto, Canada. Association for Computa-tional Linguistics. Adina Williams, Nikita Nangia, and Samuel Bowman.2018. A broad-coverage challenge corpus for sen-tence understanding through inference. In Proceed-ings of the 2018 Conference of the North AmericanChapter of the Association for Computational Lin-guistics: Human Language Technologies, Volume",
  "Jiuding Yang, Hui Liu, Weidong Guo, Zhuwei Rao,Yu Xu, and Di Niu. 2024. Sifid: Reassess summaryfactual inconsistency detection with llm": "Yuheng Zha, Yichi Yang, Ruichen Li, and Zhiting Hu.2023. AlignScore: Evaluating factual consistencywith a unified alignment function. In Proceedingsof the 61st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 1132811348, Toronto, Canada. Associationfor Computational Linguistics. Shiyue Zhang and Mohit Bansal. 2021. Finding a bal-anced degree of automation for summary evaluation.In Proceedings of the 2021 Conference on Empiri-cal Methods in Natural Language Processing, pages66176632, Online and Punta Cana, Dominican Re-public. Association for Computational Linguistics.",
  "BDetails on Baselines": "In this section, we present the implementation de-tails of FACTSCORE and FACTOOL, which havebeen integrated into our experimental baseline.For decomposing atomic facts, FACTSCORE usesthe gpt-3.5-turbo-instruct model, and the QAprocess is conducted using gpt-3.5-turbo, withprompts exactly as specified in the paper2. We gave1 point for each answer that is answered ture andthen divided by the total number of atomic facts:",
  "DDetails on the Usage of NLI Model": "In this study, we tried to analyze the effect of ourproposed atomic fact level decomposition insteadof using entire sentences. To ensure a fair compari-son of our approach with SUMMAC, which demon-strated the best performance using whole sentences,we employed the same NLI model that was utilizedin SUMMAC7. The model has been trained on the conventional NLI datasets SNLI (Bowman et al.,2015), MNLI (Williams et al., 2018), ANLI (Nieet al., 2020), and also on VitaminC (Schuster et al.,2021).In , we present the performance resultsof various NLI models. Specifically, we have in-cluded the results for DeBERTa-large-mnli8 andRoBERTa-large-pyrxsum9. The average perfor-mance scores for DeBERTa and RoBERTa are 68.7and 68.5, respectively. Although these scores arelower than that of ALBERT, they surpass the pre-vious best score of 67.8 achieved by DAE on theFtSota split.",
  "EDetails on the Usage of CoreferenceResolution": "We used MT5-11B model for coreference resolu-tion10. Coreference resolution is the task of iden-tifying all expressions that refer to the same entitywithin a text. While recent models perform wellon this task, returning a text with resolved corefer-ences is an entirely different challenge. We havetested various models, but none have functionedadequately. A significant issue was the prevalentmethod of using the first word in a cluster for res-olution instead of the entitys name, which fre-quently resulted in improper replacements withpronouns. To address this, we slightly modifiedthe code to ensure that where an entity name isavailable, it replaces pronouns as much as possi-ble11. Furthermore, when an adjective or a modifierrefers to an entity, we prefixed it with the entitysname followed by a comma. illustratesthese modifications. By enhancing coreference res-olution in this manner, we were able to capture",
  "FDetails on Granularity Expansion": "In .3, we set the criterion for granularityexpansion as max(e, c, n)! = e. This criterion waschosen because it intuitively signifies a lack of en-tailment. Notably, max(e, c, n)! = e is equivalentto !(e > c & e > n), and thus, we also conductedexperiments using the !(e > c e > n) condition. presents the results of these experiments.",
  "You are a helpful assistant. Please give me a list of atomic facts of the following texts": "lisa courtney, of hertfordshire, has spent most of her life collecting pokemon memorabilia.- Lisa Courtney is from Hertfordshire.- Lisa Courtney has spent most of her life collecting Pokmon memorabilia. prince jan zylinski said he was fed up with discrimination against poles living in britain.- Prince Jan Zylinski made a statement.- The statement made by Prince Jan Zylinski was about discrimination.- The statement made by Prince Jan Zylinski was regarding Poles living in Britain.- Prince Jan Zylinski expressed feeling fed up with this type of discrimination.",
  "no charges were filed, there will be no travel ban.- No charges were filed.- There will be no travel ban": "rudd has pleaded guilty to threatening to kill and possession of drugs in a court.- Rudd has pleaded guilty.- Rudd has pleaded guilty to threatening to kill.- Rudd has pleaded guilty to possession of drugs. Lee made his acting debut in the film The Moon is the Suns Dream (1992), and continued to appear in small and supporting roles throughout the 1990s.- Lee made his acting debut in The Moon is the Suns Dream.- The Moon is the Suns Dream is a film.- The Moon is the Suns Dream was released in 1992.- After Lees acting debut, he appeared in small and supporting roles throughout the 1990s. In 1963, Collins became one of the third group of astronauts selected by NASA and he served as the back-up Command Module Pilot for the Gemini 7 mission.- Collins became an astronaut.- Collins became one of the third group of astronauts selected by NASA in 1963.- Collins served as the back-up Command Module Pilot for the Gemini 7 mission. In addition to his acting roles, Bateman has written and directed two short films and is currently in development on his feature debut.- Bateman has acting roles.- Bateman has written two short films.- Bateman has directed two short films.- Bateman is currently in development on his feature debut. Michael Collins (born October 31, 1930) is a retired American astronaut and test pilot who was the Command Module Pilot for the Apollo 11 mission in 1969.- Michael Collins was born on October 31, 1930.- Michael Collins is retired.- Michael Collins is an American.- Michael Collins was an astronaut.- Michael Collins was a test pilot.- Michael Collins was the Command Module Pilot for the Apollo 11 mission in 1969."
}