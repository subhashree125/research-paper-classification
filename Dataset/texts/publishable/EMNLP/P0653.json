{
  "Abstract": "Yorban African language with roughly 47million speakersencompasses a continuumwith several dialects. Recent efforts to developNLP technologies for African languages havefocused on their standard dialects, resulting indisparities for dialects and varieties for whichthere are little to no resources or tools. We takesteps towards bridging this gap by introduc-ing a new high-quality parallel text and speechcorpus YORLECT across three domains andfour regional Yorb dialects. To develop thiscorpus, we engaged native speakers, travellingto communities where these dialects are spo-ken, to collect text and speech data. Using ournewly created corpus, we conducted extensiveexperiments on (text) machine translation, au-tomatic speech recognition, and speech-to-texttranslation. Our results reveal substantial per-formance disparities between standard Yorband the other dialects across all tasks. How-ever, we also show that with dialect-adaptivefinetuning, we are able to narrow this gap. Webelieve our dataset and experimental analysiswill contribute greatly to developing NLP toolsfor Yorb and its dialects, and potentially forother African languages, by improving our un-derstanding of existing challenges and offeringa high-quality dataset for further development.We release YORLECT dataset and models pub-licly under an open license 1.",
  "Introduction": "While great strides have been made in developingNLP resources for low-resource languages, the ma-jority of these efforts have been directed towardsthe standard dialect of these languages, largelyneglecting the long tail of non-standard dialectsspoken by millions (Faisal et al., 2024; Alam et al.,2024). Dialects of a language exhibit nuancedyet distinguishable differences in lexicon, pronun-ciation, spelling, and syntax, mirroring regional,",
  "Code and data available at": "societal, and cultural differences (Chambers andTrudgill, 1998). Usually, a standard dialect isthe dialect with the highest population of speak-ers, and sometimes the only dialect with a standardorthography (Milroy and Milroy, 2012).African languages are linguistically diverse(Adebara and Abdul-Mageed, 2022; Siminyu andFreshia, 2020), yet severely under-resourced. Mostof these languages have numerous varieties, (usu-ally regional), some of which are mostly-spokenand lack a standard orthography (Batibo, 2005;Heine and Nurse, 2000). Developing languagetechnologies has been incredibly challenging forAfrican languages (Nekoto et al., 2020; Muham-mad et al., 2023; Ogundepo et al., 2023; Adelaniet al., 2023; Dione et al., 2023; Adelani et al., 2024,2021b), partly due to the scarcity of extensive lan-guage resources required for developing systemsthat are robust to the variations in linguistic fea-tures (Adebara and Abdul-Mageed, 2022; Siminyuand Freshia, 2020).To address this problem, in this work we focuson curating dialectal resources for Yorb, a low-resource language with 47 million native speakersaround the world. Yorb language is native toSouthwestern Nigeria, Republic of Benin, and Re-public of Togo. Yorb encompasses a dialect con-tinuum including several distinct regional dialects(Rowlands, 1967). Due to Yorbs low-resourcestatus, the majority of published NLP work havebeen done on the Standard Yorb dialect (Ogun-remi et al., 2024; Aremu et al., 2023; Ahia et al.,2021; Dione et al., 2023; Shode et al., 2023; Ogun-depo et al., 2023; Akinade et al., 2023; Adelaniet al., 2023; Muhammad et al., 2023; Adelani et al.,2021a; Adebara et al., 2022, 2021; Lee et al., 2023).We introduce the first-ever corpus of high quality,contemporary Yorb speech and text data paral-lel across four Yorb dialects; Standard Yorb,If./ i f E /, lje./ i l a dZ E / and j.b/ i dZ Eb u / in three domains (religious, news, and Ted",
  ": Examples of parallel translations across all dialects and domains in YORLECT. Words that are uniqueacross all dialects are highlighted in red": "talks). This newly curated benchmark, developedwith native speakers, can be used in (text-to-text)machine translation (MT), automatic speech recog-nition (ASR), speech-to-text translation (S2TT),and speech-to-speech translation (STST) tasks. Wediscuss in detail the data curation process, criteriafor data selection, and the steps we took to ensuredata quality and integrity (3). We first conductextensive experiments evaluating the zero-shot per-formance of recent state-of-the-art models for MT,ASR, and S2TT (4, 5). Our results and anal-ysis indicate that current models are not robustenough to handle existing variation in Yorb di-alects. Given these poor results, we proceed toadapt (fine-tune) existing models on our trainingdata across all tasks to boost overall performance.With 802 training instances in each dialect, thisapproach leads to an average increase of 14 and 5BLEU points for both MT and S2TT respectively,as well as a 20-point decrease in word-error-ratefor ASR. Our work aims to motivate the commu-nity to build technology for languages alongsidetheir dialects, especially for low-resource dialectsof low-resource languages, as this will promotelinguistic diversity, and ensure that technologicaladvancements benefit all language communities.",
  "Yorb and its Regional Dialects": "The Yorb language is spoken natively by roughly47 million people in Nigeria2 and in the neighbor-ing countries of the Republic of Benin and Togoand also Cte dIvoire, Sierra Leone, Cuba, andBrazil. In Nigeria, Yorb speakers are mainly con-centrated in the Southwest region, spanning stateslike Oyo, Ogun, Osun, Ondo, Ekiti, and Lagos, and",
  ": Geographical distribution of Yorb dialectsin West Africa. Map from (Ozburn, 2023)": "The extensive Yorb-speaking population andtheir dispersion across various regions have ledto the emergence of geography-specific linguisticvariations (Ballard, 1971). The number of exist-ing Yorb dialects is estimated between twelveto twenty-six (Ojo, 1977; Adetugbo, 1982; Oye-laran, 1971; Oyelaran and Watson, 1991) and thedifferences present in these dialects are evident inpronunciation, grammatical structure, and vocab-ulary (Adetugbo, 1982; Przezdziecki, 2005; Olu-muyiwa, 2009; Arokoyo et al., 2019; Olnrewj,2022). Also categorized as a Volta-Niger languagewithin the Yoruboid subgroup of the Niger-Congofamily, Yorb is a tonal language with three ba-sic tones: low, middle, and high (Courtenay, 1969;Oyetade, 1988), as well as two or three contourtones.3 Previous research (Adeniyi, 2021) has in-",
  "A contour tone is a combination of two more basic tonessuch as a falling tone made up of a high tone and a low tone,or a rising tone consisting of a low tone followed by a hightone": "dicated that the phonetic nuances of contour tonesare a major distinguishing feature among Yorbdialects.Yorb dialectal forms in Nigeria can be clas-sified into five regional groupings: NorthwestYorb (NWY), Northeastern Yorb (NEY), Cen-tral Yorb (CY), Southwest Yorb (SWY), andSoutheast Yorb (SEY). Phonological, lexical,and grammatical differences distinguish thesegroupings, given the diverse levels of mutual in-telligibility among the regional dialects withineach category (Arokoyo et al., 2019; Olumuyiwa,2016; Abiodun et al.). In this work, our focus lieson If., a dialect in the Central Yoruba classifica-tion, j.b, and lje. dialects, which belong to theSoutheast Yoruba classification. We display the ge-ographical distribution of Yorb dialects in WestAfrica in . ComparativedialectalanalysisStandardYorb, If., j.b and lje. dialects exhibit bothsimilarities and differences in their orthographicrepresentations, morphology, and semantics. Forinstance, standard Yorb dialect has fused velarfricative /G/ and labialised voiced velar /gw/ into/w/ (Adetugbo, 1982) and our curated data revealeda similar pattern for j.b. In contrast, If. uses/G/ in certain occurrences while lje. has heavilyretained the /gw/ and /G/ in its representations.As a result, at the word level, wo.n (3p pl.) isrepresented similarly in standard dialect and j.bbut as igho.n in If. and ghan in lje.. Besidesthe contrastive consonant nature, the oral andnasal vowels are also both contrastive in If. andlje. dialects respectively. Further analsyses ofYORLECT reveal that the low nasalised vowel /a/mostly follows gh in lje. while the back lower-mid nasalised vowel /O/ accompanies gh in If.dialect. One remarkable semantic variation is thatstandard Yorb dialect uses so. and wi pe assay/talk, however for lje. and j.b the morphememostly used is fo. while If. uses ghii, all ofwhich have the same semantics.",
  "Text Curation and Dialect Localization": "We collected textual Standard Yorb data from thefollowing sources: (i) Bible study manuals;4 (ii) theYorb portion of MTTT, a collection of multitargetbitexts based on TED Talks (Duh, 2018); and (iii)Yorb news articles within the MAFT corpus (Al-abi et al., 2022). Given resource limitations and thedemanding nature of this task, we gathered 352 sen-tences from the Bible study manuals, 247 sentencesfrom TED Talks, and 907 sentences from news arti-cles, amounting to a total of 1,506 sentences. Next,we proceeded to localising the compiled StandardYorb text into the three respective dialects: If.,j.b, and lje. by recruiting trained linguists andtranslators who are literate and also native speakersof the respective dialects. We hired two translatorsor linguists per dialect and gave each a differentdomains to localise. The localisation process tookabout six to eight weeks and this included the lo-calisation, quality assessment and incorporation ofcorrections. We provided monetary compensationfor the localisation of the text.",
  "Speech Recording": "Speaker selection is crucial when creating an ASRcorpus; a speaker should be fluent, literate, trained,and familiar with voice recording (Ogayo et al.,2022; van Niekerk et al., 2017). Due to time con-straints and speaker availability, we were only ableto record speech in standard Yorb, If., and lje.dialects, leaving j.b for a later version of thedataset. We retained the linguists and translatorswho localised the standard Yorb text into If. andlje. dialects. We then recruited two additionalnative speakers per dialect that are literate in ren-dering the localised text into audio. All dialectalvoice talents received monetary compensation. Wefirst conducted an interview, then asked the newrecruits to record random samples of the text andsend the recordings for assessment. The audioand corresponding text are vetted, after which weselected native speakers with high reading compe-tence, good voice texture, and reading pace. Thisbrought the total number of voice talents per dialectto four. To ensure that each voice talent within adialect recorded text across all domains, we dividedtext in each domain (religion, Ted, news) into fourparts. Each person recorded roughly 375 sentencesfrom each domain resulting in a total of 3 hours of",
  "Menyo2.762.661.577.490.440.400.400.52MT05.816.684.6117.220.520.500.470.65Aya7.187.714.9116.460.490.500.450.63": ": Zero-shot MT evaluation across all models. Google Translate outperforms all other systems and showsgreater robustness to dialectal variation. However, a significant performance gap remains compared to the StandardYoruba dialect. speech per dialect.Recording is conducted using the speechrecorder application designed by the YorubaVoiceproject (Ogunremi et al., 2024). The text fileswere uploaded per domain for each speaker onthe YorubaVoice Recorder app. We used an M1Pro 2021 chip MacBook with an audio-technicaAT2020USB-X microphone set-up in an anechoicand sound-isolated voice recording booth for therecording process. Each text is recorded at 48 kHzand the audio files are provided in 16 bit linearPCM RIFF format. The app generates metadatathat includes a unique speaker ID, audio ID withcorresponding text, and the audio file. Finally, allthe recordings were subjected to a quality controlprocess by the data coordinator. We manually ver-ified that the correct text was aligned with the ap-propriate audio file and re-aligned them when nec-essary. We also discovered one empty audio filein a particular dialect and proceeded to delete it,along with its corresponding text-audio pairs in allother dialects. Final data statisticsIn total, the text portionof YORLECT consists of 1506 parallel sentencesper dialect and 6024 sentences overall, while thespeech portion consists roughly 3 hours of audioeach in standard Yorb, If. and lje., resulting in 9hours of speech in total. We split the text and audiopairs in each dialect into 804 training samples, 200validation samples and 502 test samples.",
  "Machine Translation": "You are tasked to evaluate the performance of two Machine Translation systems on your native Yoruba dialect. Thistask involves assessing the accuracy and quality of translations produced by these systems, when translating from yourdialect into English. Your evaluations will help us understand how well these systems handle linguistic variations.Please focus on the following key criteria while evaluating the transcriptions:",
  "MENYO-20k dataset, a curated multi-domain stan-dard Yorb dataset with proper orthography": "Language ModelsWe evaluate two multilingualLMs, Aya (stn et al., 2024) and MT-0 (Muen-nighoff et al., 2023), trained on 101 and 46 lan-guages, respectively (standard Yorb included).We prompt the LM to generate translations in azero-shot setting with the prefix Translate to En-glish: \" added to each sentence and greedily decodethe continuation. We do not provide in-context ex-amples in order to create a comparable setting tothe evaluation of MT-specific models.Finally, we include Google Translate (GM-NMT)5 due to its widespread commercial use. Werequest the NMT model through the API, and can-not control any other aspects of its usage. ResultsWe measure translation quality usingAfriCOMET (Wang et al., 2023) and BLEU (Pap-ineni et al., 2002). Firstly, we report zero-shot per-formance across all models in . Althoughperformance is relatively low across the board,among MT-specific models, NLLB performs bestacross all dialects, outperforming M2M100 andMENYO-20k. Comparing performance on LMs,Aya performs better than MT0 on all dialects exceptstandard Yorb. Google Translate outperforms allsystems across all dialects. Overall, we see a hugeperformance gap between standard Yorb and therest of the dialects. This observation is not surpris-ing and is very consistent across all systems. Theresults in also show that lje. has the worst-performing BLEU score across all models. Wehypothesize that this is because lje. is largely spo-ken in . nd. state, which is geographically distantfrom . y. state where standard Yorb originatedfrom.",
  "API last accessedon June 7, 2024": "2023), and MMS (Pratap et al., 2024). All mod-els include standard Yorb in their pretrainingdata. Whisper is an end-to-end ASR model, imple-mented as an encoder-decoder transformer, trainedon 680,000 hours of multilingual and multitasksupervised data collected from the web. The au-thors argue that it is robust to accents and vari-ations in speech.It was optimized to performthe tasks of transcribing audio into its originallanguage and translating the audio into Englishtext. SeamlessM4T is a multilingual and multi-modal model that also translates and transcribesacross speech and text. It is trained on 470,000hours of mined speech and text-aligned data andsupports ASR, S2TT, speech-to-speech translation,text-to-text translation and text-to-speech transla-tion, although our focus here is ASR and S2TT.MMS is an ASR-only model finetuned on top ofwav2vec 2.0 (Baevski et al., 2020) models across1,107 languages. In addition to dense finetuning,they also finetune language-specific adapter mod-ules (Houlsby et al., 2019) for each language intheir pretraining data. ResultsWe report word error rate (WER) withthe models MMS, SeamlessM4T, and Whisper in (left). Performance is generally poor acrossall models, with MMS performing the best. Wehypothesize that MMS performs best due to itstraining with parameter-efficient finetuning usinglanguage-specific adapters.We see an averageperformance gap of 12 points between standardYorb and the other dialects on MMS and Seam-lessM4T. With Whisper, the case is different: whilethe WER is generally very high, we see that only If.is substantially better across all dialects. Upon man-ually reviewing the transcriptions from all models,we noticed that Whisper did not include diacriticsin its generated transcriptions. Yorb is a tonallanguage, and diacritics play a crucial role in dis-ambiguating word meanings. We believe that this,coupled with the generation of overly segmentedtranscriptions contributes to Whispers exception-ally high word-error rate exceeding 100.",
  "Speech Translation": "We only evaluate Whisper (Radford et al., 2022)and SeamlessM4T (Communication et al., 2023).Just like MT, we only evaluate translation from thestandard language or dialect into English as wecannot expect the models to generate text in any ofthe dialects without explictly finetuning it do so. ResultsIn (right), we present the zero-shot speech-to-text translation (S2TT) results ofSeamlessM4T and Whisper models, the only open-source models we are aware of that include cover-age for Standard Yorb. Among all the tasks weevaluated, S2TT appears to be the most challenging.Performance is absolutely low for both models withWhisper performing particularly poorly. Acrossdialects, with SeamlessM4T, Standard Yoruba per-forms better yet again with an average of 9 pointsperformance gap compared to lje. and If..",
  "We finetune MMS (Pratap et al., 2024) and XLSR-Wav2Vec2 (Baevski et al., 2020). For the MMSmodel, we only finetune the Yorb adapter layer,while the other weights of the model are keptfrozen": "ResultsWe compare performance after finetun-ing XLSR and MMS with two different model sizeseach: 300M and 1.3B parameters. MMS is a moresuitable choice for finetuning because of its pa-rameter efficiency, since we only have to tune theYorb adapter layers. However, we choose to com-pare it with XLSR as well, as previous studies havereported significant performance improvements byfinetuning XLSR (Ogunremi et al., 2024). In Fig-ure 3, we first see that for XLSR, fine tuning amodel with less capacity (300M parameters) yieldsbetter performance across all dialects compared tofine tuning a model with about 4 more parame-ters. However, with MMS, we see that finetuningthe 1.3B model yields a lower WER compared tofinetuning the 300M model. Here, the performancegap is not as drastic as with XLSR.On average, there is a performance improve-ment of approximately 20% after finetuning. Asexpected, across all models, the performance onthe Standard Yorb dialect remains considerablybetter than that of lje. and If.. We expect thatincreasing the size of the finetuning data could helpclose this gap and could be addressed in futurework.",
  ": S2TT results (). We compare BLEU prior tofinetuning and after finetuning SeamlessM4T": "ResultsThe results in show that whilewe can reasonably boost performance on StandardYorb after finetuning, it still remains a very hardtask for the other dialects with just finetuning. Wehypothesize that this occurs for two reasons, firstlythe amount of Yorb S2TT data in SeamlessM4Tis smaller than the data available to train ASR(Communication et al., 2023). Secondly, whilethere is notable lexical variation across Yorb di-alects, the differences are even more pronouncedin spoken language. This significant variation inpronunciation and intonation, coupled with the factthat S2TT data for Yorb is scarcer than ASR datamakes the task of adaptation particularly challeng-",
  "Human Evaluation": "We complement automatic evaluation metrics witha human evaluation study to assess the qualityof translations and transcriptions from the bestmodels after fine-tuning for MT and ASR. Pre-vious research has shown that word error rate(WER) is not nuanced, as it treats all errors in ASRtextinsertions, deletions, and substitutionsthesame, without considering their impact on readabil-ity (Itoh et al., 2015).7 For ASR, one native speakerper dialect rated the quality of 30 randomly sam-pled transcriptions from the test set produced byour best ASR models after finetuning. After listen-ing to the source speech they assess fluency (hownatural and grammatically correct the transcriptionsounds in their dialect) and adequacy (how accu-rately the transcription conveys the meaning of thesource speech) using a Likert scale of (15), thehigher the better. In we show that humanraters consider the transcriptions of standard andIf. to be moderately adequate and fluent on aver-age, compared to lje.. These findings align withour observations from automatic metrics.",
  ": Average human ratings of adequacy and flu-ency of transcriptions from the best ASR models afterfinetuning": "For MT, we ask human raters to compare thequality of translations from Google Translate withtranslations after finetuning NLLB, still focusingon fluency and adequacy still using a Likert scale(15). We provide the exact phrasings of instruc-tion in the A.4. Our results, displayed in Ta-ble 6, show that Google Translate is rated to bemore fluent and accurate on Standard Yorb andlje.. However, our finetuned NLLB-600M modelis rated to be more more fluent and accurate on If.and j.b. The results on standard Yorb, If. andj.b are very consistent with automatic evaluationresults in . This is not the case with lje.,as our ratings are lower compared to Google Trans-",
  "Analysis and Discussion": "Does edit distance explain performance gaps?In this analysis we aim to understand how dialectalsimilarity influences model adaptation during fine-tuning. Ideally, we expect dialects with higher sim-ilarity to Standard Yorb to perform better. Editdistance (Levenshtein, 1966) is a simple methodcommonly used in dialectometry to infer pronunci-ation differences between language dialects (Ner-bonne et al., 2020, 1996; Heeringa, 2004). In ourwork, we use edit distance as a proxy for similaritybetween Standard Yorb and the other dialects inour corpus, expecting that dialects with a higherdegree of similarity (lower edit distance) will per-form better. We compute the average edit distanceper dialect, d = 1 NNi=1 d(si, ti), where N is thenumber of sentences in the test set of the dialect, sis the sentence in Standard Yorb, t is the sentencein the corresponding dialect, and d(si, ti) is the editdistance between si and ti at the character-level.We present the results of this analysis in MT in . As expected, If. has the smallest edit dis-tance from Standard Yorb and respectively alsothe best performance after finetuning. Howeverwe surprisingly see that while j.b has a higheredit distance than lje., the model performance ishigher for j.b. We conclude that edit distancehas a weak correlation with our MT metrics.",
  ": Average edit distance and MT-Metrics compar-ison for MT across dialects after finetuning NLLB": "For ASR, we compute edit distance on phonetictranscriptions using the PanPhon library developedby (Mortensen et al., 2016). The phonetic editdistance between standard Yorb to lje. and If.is 34.99 and 44.4, respectively. Here again, wealso see no correlations between edit distance andperformance on dialect adaptation. Joint vs. dialect-specific finetuning.Dialectsoften exhibit rather subtle variations in text andspeech. In data-constrained scenarios like ours, itis reasonable to expect that jointly finetuning on alldialects would result in better performance com-pared to fine-tuning on each dialect individually. Inour earlier finetuning experiments detailed in 5,we explored joint training. Now, we try to compareperformance between joint training and individualtraining on MT and ASR tasks. We generally seethat on both tasks, joint training is beneficial. InMT, in the Appendix shows a huge drop inperformance across all dialects when we finetuneon each dialect individually. This suggests that byjointly finetuning, the model leverages shared fea-tures across dialects for mutual benefit. Although,it is also possible that we observe better results dueto 3X increase in data size. However, in ASR, asshown in , the drop in performance withindividual finetuning is not as pronounced as withMT. We believe that in this case, the subtle varia-tions in speech are sometimes significant, makingit more challenging to greatly benefit from jointtraining. We however acknowledge that the datasize of each individual dialect is one-fourth of thewhole training set, so data paucity might also beinfluencing these results.",
  "Related Work": "Previous works that have developing technolo-gies and resources for machine translation (Ahiaet al., 2021; Adebara et al., 2022, 2021; Leeet al., 2023; Akinade et al., 2023; Adelani et al.,2021a), automatic speech recognition (Ogunremiet al., 2024; Communication et al., 2023; Baevskiet al., 2020) and speech translation (Communica-tion et al., 2023; Oneata and Kamper, 2024) forYorb have largely focused on the standard Yorbdialect. This is because, just like other African lan-guages, standard Yorb is also very low-resourced,and all efforts have been directed there. Severalworks have shown that models often exhibit perfor-mance disparities between standard languages andtheir dialectal counterparts (Diab, 2016; Nigmat- ulina et al., 2020; Kantharuban et al., 2023; Ziemset al., 2023; Faisal et al., 2024; Ahmadi et al., 2024;Joshi et al., 2024; Blaschke et al., 2023; Aji et al.,2022; Abdul-Mageed et al., 2023). Arabic lan-guage has roughly 30 regional dialects. Whilstmajority of work has being done on Modern Stan-dard Arabic (MSA), Arabic still has the widestcoverage of tasks and datasets across several of itsdialects (Faisal et al., 2024; Diab and Habash, 2012;Bouamor et al., 2018; Kchaou et al., 2020). WithinAfrican languages, some works that aim to builddialect-aware models have conducted their studieson Igbo (Emezue et al., 2024), Luhya (Siminyuet al., 2021; Chimoto and Bassett, 2022), Bemba(Sikasote and Anastasopoulos, 2022) and Kiswahili(Siminyu et al., 2022).",
  "Conclusion": "We introduce YORLECTthe first high qualityparallel text and speech corpus for four Yorbdialects sourced primarily from native speakers,to enable ASR, MT and S2TT tasks for widely-spoken varieties of Yorb. We have provided adetailed documentation of data curation processfrom standard text creation, to dialect localizationand speech recording in communities where thesedialects are spoken. Extensive experiments revealthat current models are not robust to dialectal vari-ation, and improve significantly after our dialect-adaptive finetuning. Overall, our data collectionmethodology, new resources and improved modelstake a step towards enhancing the quality and eq-uity of NLP technologies for Yorb dialects andpotentially other African languages.",
  "Ethical Considerations": "Our datasets and models will be publicly releasedunder an open license to foster research and con-tinue to promote the development of NLP tools forAfrican languages. Transcriptions, recordings andtranslations are carried out by paid native speakerswho provided consent to use their voice to train ourmodels. We acknowledge that the limited size ofthe corpus might not represent perfectly communi-ties and speakers of the dialects. Further, dialectalgenerations, particularly when erroneous, could beperceived as biased or even microaggressions bysome native speakers, as well as dialect-specific er-rors from the models (Wenzel and Kaufman, 2024).While our work provides resources that aim to re-duce dialectal biases and unfairness in multilingual",
  "Limitations": "A limitation of our work is the robustness ofthe metrics we use for evaluation. While all ofthese metrics are standard for all of the tasks,we acknowledge that model-based metrics likeAfriCOMET (Wang et al., 2024) could be biasedtowards standard dialects that their models havebeen trained on. Exploring model-based metricsthat facilitate robust evaluations on dialectal tasksremains a challenge for future work (Faisal et al.,2024).Additionally, the text portion of our dataset istranslated from the standard dialect into Englishand the non-standard dialects. We acknowledgethat this could introduce translation artifacts knownas translationese (Volansky et al., 2015) that arenot present in the source dialect. However, webelieve that the benefits of our dataset outweighsthe potential risks of these artifacts.",
  "Acknowledgements": "We would like to thank the UW NLP communityfor valuable discussions of this work. We are grate-ful to Farhan Samir and Sachin Kumar for discus-sions on experiments and analysis. We also thankOduwole Folake and Olomolatan Anuoluwapo fortheir help with evaluating translations and transcrip-tions from our models. David Adelani is supportedby Canada CIFAR AI Chair program. We gratefullyacknowledge support from the National ScienceFoundation under CAREER Grant No. IIS2142739,and NSF grants No. IIS2125201 and IIS2203097.This work was also supported in part by gift fund-ing from Google, MSR, and OpenAI. Muhammad Abdul-Mageed, AbdelRahim Elmadany,Chiyu Zhang, El Moatez Billah Nagoudi, HoudaBouamor, and Nizar Habash. 2023. NADI 2023: Thefourth nuanced Arabic dialect identification sharedtask. In Proceedings of ArabicNLP 2023, pages 600613, Singapore (Hybrid). Association for Computa-tional Linguistics.",
  "Ife Adebara, Muhammad Abdul-Mageed, and Mi-ikka Silfverberg. 2021.Translating the unseen?yoruba-english mt in low-resource, morphologically-unmarked settings": "Ife Adebara, Muhammad Abdul-Mageed, and MiikkaSilfverberg. 2022. Linguistically-motivated Yorb-English machine translation. In Proceedings of the29th International Conference on Computational Lin-guistics, pages 50665075, Gyeongju, Republic ofKorea. International Committee on ComputationalLinguistics. David Adelani, Dana Ruiter, Jesujoba Alabi, DamilolaAdebonojo, Adesina Ayeni, Mofe Adeyemi, Ayo-dele Esther Awokoya, and Cristina Espaa-Bonet.2021a. The effect of domain and diacritics in YorubaEnglish neural machine translation.In Proceed-ings of Machine Translation Summit XVIII: ResearchTrack, pages 6175, Virtual. Association for MachineTranslation in the Americas. David Ifeoluwa Adelani, Jade Abbott, Graham Neu-big, Daniel Dsouza, Julia Kreutzer, Constantine Lig-nos, Chester Palen-Michel, Happy Buzaaba, ShrutiRijhwani, Sebastian Ruder, Stephen Mayhew, Is-rael Abebe Azime, Shamsuddeen H. Muhammad,Chris Chinenye Emezue, Joyce Nakatumba-Nabende,Perez Ogayo, Aremu Anuoluwapo, Catherine Gitau,Derguene Mbaye, Jesujoba Alabi, Seid Muhie Yi-mam, Tajuddeen Rabiu Gwadabe, Ignatius Ezeani,Rubungo Andre Niyongabo, Jonathan Mukiibi, Ver-rah Otiende, Iroro Orife, Davis David, Samba Ngom,Tosin Adewumi, Paul Rayson, Mofetoluwa Adeyemi,Gerald Muriuki, Emmanuel Anebi, Chiamaka Chuk-wuneke, Nkiruka Odu, Eric Peter Wairagala, SamuelOyerinde, Clemencia Siro, Tobius Saul Bateesa,Temilola Oloyede, Yvonne Wambui, Victor Akin-ode, Deborah Nabagereka, Maurice Katusiime, Ayo-dele Awokoya, Mouhamadane MBOUP, Dibora Ge-breyohannes, Henok Tilaye, Kelechi Nwaike, De-gaga Wolde, Abdoulaye Faye, Blessing Sibanda, Ore-vaoghene Ahia, Bonaventure F. P. Dossou, Kelechi Ogueji, Thierno Ibrahima DIOP, Abdoulaye Diallo,Adewale Akinfaderin, Tendai Marengereke, and Sa-lomey Osei. 2021b. MasakhaNER: Named entityrecognition for African languages.Transactionsof the Association for Computational Linguistics,9:11161131. David Ifeoluwa Adelani, Marek Masiak, Israel AbebeAzime, Jesujoba Alabi, Atnafu Lambebo Tonja,Christine Mwase, Odunayo Ogundepo, BonaventureF. P. Dossou, Akintunde Oladipo, Doreen Nixdorf,Chris Chinenye Emezue, Sana Al-azzawi, BlessingSibanda, Davis David, Lolwethu Ndolela, JonathanMukiibi, Tunde Ajayi, Tatiana Moteu, Brian Odhi-ambo, Abraham Owodunni, Nnaemeka Obiefuna,Muhidin Mohamed, Shamsuddeen Hassan Muham-mad, Teshome Mulugeta Ababu, Saheed Abdul-lahi Salahudeen, Mesay Gemeda Yigezu, Tajud-deen Gwadabe, Idris Abdulmumin, Mahlet Taye,Oluwabusayo Awoyomi, Iyanuoluwa Shode, Tolu-lope Adelani, Habiba Abdulganiyu, Abdul-HakeemOmotayo, Adetola Adeeko, Abeeb Afolabi, An-uoluwapo Aremu, Olanrewaju Samuel, ClemenciaSiro, Wangari Kimotho, Onyekachi Ogbu, ChineduMbonu, Chiamaka Chukwuneke, Samuel Fanijo, Jes-sica Ojo, Oyinkansola Awosan, Tadesse Kebede,Toadoum Sari Sakayo, Pamela Nyatsine, Freed-more Sidume, Oreen Yousuf, Mardiyyah Odu-wole, Kanda Tshinu, Ussen Kimanuka, ThinaDiko, Siyanda Nxakama, Sinodos Nigusse, Ab-dulmejid Johar, Shafie Mohamed, Fuad Mire Has-san, Moges Ahmed Mehamed, Evrard Ngabire,Jules Jules, Ivan Ssenkungu, and Pontus Stenetorp.2023. MasakhaNEWS: News topic classification forAfrican languages. In Proceedings of the 13th In-ternational Joint Conference on Natural LanguageProcessing and the 3rd Conference of the Asia-PacificChapter of the Association for Computational Lin-guistics (Volume 1: Long Papers), pages 144159,Nusa Dua, Bali. Association for Computational Lin-guistics. David Ifeoluwa Adelani, Jessica Ojo, Israel Abebe Az-ime, Jian Yun Zhuang, Jesujoba O. Alabi, Xuanli He,Millicent Ochieng, Sara Hooker, Andiswa Bukula,En-Shiun Annie Lee, Chiamaka Chukwuneke, HappyBuzaaba, Blessing Sibanda, Godson Kalipe, JonathanMukiibi, Salomon Kabongo, Foutse Yuehgoh, Mma-sibidi Setaka, Lolwethu Ndolela, Nkiruka Odu,Rooweither Mabuya, Shamsuddeen Hassan Muham-mad, Salomey Osei, Sokhar Samb, Tadesse KebedeGuge, and Pontus Stenetorp. 2024. IrokoBench: Anew benchmark for African languages in the age oflarge language models.",
  "Sina Ahmadi, Daban Q. Jaff, Md Mahfuz Ibn Alam,and Antonios Anastasopoulos. 2024. Language andspeech technology for central kurdish varieties": "Alham Fikri Aji, Genta Indra Winata, Fajri Koto,Samuel Cahyawijaya, Ade Romadhony, Rahmad Ma-hendra, Kemal Kurniawan, David Moeljadi, Radi-tyo Eko Prasojo, Timothy Baldwin, Jey Han Lau,and Sebastian Ruder. 2022. One country, 700+ lan-guages: NLP challenges for underrepresented lan-guages and dialects in Indonesia. In Proceedingsof the 60th Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 72267249, Dublin, Ireland. Association forComputational Linguistics. Idris Akinade, Jesujoba Alabi, David Adelani, ClementOdoje, and Dietrich Klakow. 2023. Varepsilon kmask: Integrating Yorb cultural greetings intomachine translation.In Proceedings of the FirstWorkshop on Cross-Cultural Considerations in NLP(C3NLP), pages 17, Dubrovnik, Croatia. Associa-tion for Computational Linguistics. Jesujoba O. Alabi, David Ifeoluwa Adelani, MariusMosbach, and Dietrich Klakow. 2022. Adapting pre-trained language models to African languages viamultilingual adaptive fine-tuning. In Proceedings ofthe 29th International Conference on ComputationalLinguistics, pages 43364349, Gyeongju, Republicof Korea. International Committee on ComputationalLinguistics. Md Mahfuz Ibn Alam, Sina Ahmadi, and AntoniosAnastasopoulos. 2024. CODET: A benchmark forcontrastive dialectal evaluation of machine transla-tion. In Findings of the Association for Computa-tional Linguistics: EACL 2024, pages 17901859,St. Julians, Malta. Association for ComputationalLinguistics.",
  "H. Batibo. 2005. Language Decline and Death in Africa:Causes, Consequences, and Challenges. Multilin-gual matters. Multilingual Matters": "Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Has-san Sajjad, and James Glass. 2017. What do neuralmachine translation models learn about morphology?In Proceedings of the 55th Annual Meeting of theAssociation for Computational Linguistics (Volume1: Long Papers), pages 861872, Vancouver, Canada.Association for Computational Linguistics. Verena Blaschke, Hinrich Schuetze, and Barbara Plank.2023.A survey of corpora for Germanic low-resource languages and dialects.In Proceedingsof the 24th Nordic Conference on ComputationalLinguistics (NoDaLiDa), pages 392414, Trshavn,Faroe Islands. University of Tartu Library. Houda Bouamor, Nizar Habash, Mohammad Salameh,Wajdi Zaghouani, Owen Rambow, Dana Abdul-rahim, Ossama Obeid, Salam Khalifa, Fadhl Eryani,Alexander Erdmann, and Kemal Oflazer. 2018. TheMADAR Arabic dialect corpus and lexicon. In Pro-ceedings of the Eleventh International Conference onLanguage Resources and Evaluation (LREC 2018),Miyazaki, Japan. European Language Resources As-sociation (ELRA).",
  "J. K. Chambers and Peter Trudgill. 1998. Dialectol-ogy, 2 edition. Cambridge Textbooks in Linguistics.Cambridge University Press": "Everlyn Chimoto and Bruce Bassett. 2022. Very lowresource sentence alignment: Luhya and Swahili. InProceedings of the Fifth Workshop on Technologiesfor Machine Translation of Low-Resource Languages(LoResMT 2022), pages 18, Gyeongju, Republic ofKorea. Association for Computational Linguistics. Seamless Communication, Loc Barrault, Yu-An Chung,Mariano Cora Meglioli, David Dale, Ning Dong,Paul-Ambroise Duquenne, Hady Elsahar, HongyuGong, Kevin Heffernan, John Hoffman, ChristopherKlaiber, Pengwei Li, Daniel Licht, Jean Maillard,Alice Rakotoarison, Kaushik Ram Sadagopan, Guil-laume Wenzek, Ethan Ye, Bapi Akula, Peng-JenChen, Naji El Hachem, Brian Ellis, Gabriel MejiaGonzalez, Justin Haaheim, Prangthip Hansanti, RussHowes, Bernie Huang, Min-Jae Hwang, Hirofumi In-aguma, Somya Jain, Elahe Kalbassi, Amanda Kallet,Ilia Kulikov, Janice Lam, Daniel Li, Xutai Ma, Rus-lan Mavlyutov, Benjamin Peloquin, Mohamed Ra-madan, Abinesh Ramakrishnan, Anna Sun, KevinTran, Tuan Tran, Igor Tufanov, Vish Vogeti, CarleighWood, Yilin Yang, Bokai Yu, Pierre Andrews, CanBalioglu, Marta R. Costa-juss, Onur Celebi, MahaElbayad, Cynthia Gao, Francisco Guzmn, JustineKao, Ann Lee, Alexandre Mourachko, Juan Pino,Sravya Popuri, Christophe Ropers, Safiyyah Saleem,Holger Schwenk, Paden Tomasello, Changhan Wang,Jeff Wang, and Skyler Wang. 2023. Seamlessm4t:Massively multilingual multimodal machine transla-tion. Marta R Costa-juss, James Cross, Onur elebi, MahaElbayad, Kenneth Heafield, Kevin Heffernan, ElaheKalbassi, Janice Lam, Daniel Licht, Jean Maillard,et al. 2022.No language left behind: Scalinghuman-centered machine translation. arXiv preprintarXiv:2207.04672.",
  "Karen Ruth Courtenay. 1969. A generative phonologyof yorb": "Mona Diab. 2016. Processing dialectal Arabic: Exploit-ing variability and similarity to overcome challengesand discover opportunities. In Proceedings of theThird Workshop on NLP for Similar Languages, Vari-eties and Dialects (VarDial3), page 42, Osaka, Japan.The COLING 2016 Organizing Committee. Mona Diab and Nizar Habash. 2012. Arabic dialectprocessing tutorial. In Tutorial Abstracts at the Con-ference of the North American Chapter of the Asso-ciation for Computational Linguistics: Human Lan-guage Technologies, Montral, Canada. Associationfor Computational Linguistics. Cheikh M. Bamba Dione, David Ifeoluwa Adelani,Peter Nabende, Jesujoba Alabi, Thapelo Sindane,Happy Buzaaba, Shamsuddeen Hassan Muhammad,Chris Chinenye Emezue, Perez Ogayo, AnuoluwapoAremu, Catherine Gitau, Derguene Mbaye, JonathanMukiibi, Blessing Sibanda, Bonaventure F. P. Dos-sou, Andiswa Bukula, Rooweither Mabuya, Allah-sera Auguste Tapo, Edwin Munkoh-Buabeng, Vic-toire Memdjokam Koagne, Fatoumata Ouoba Ka-bore, Amelia Taylor, Godson Kalipe, TebogoMacucwa, Vukosi Marivate, Tajuddeen Gwadabe,Mboning Tchiaze Elvis, Ikechukwu Onyenwe, Gra-tien Atindogbe, Tolulope Adelani, Idris Akinade,Olanrewaju Samuel, Marien Nahimana, ThogneMusabeyezu, Emile Niyomutabazi, Ester Chimhenga,Kudzai Gotosa, Patrick Mizha, Apelete Agbolo, Sey-dou Traore, Chinedu Uchechukwu, Aliyu Yusuf,Muhammad Abdullahi, and Dietrich Klakow. 2023.MasakhaPOS: Part-of-speech tagging for typolog-ically diverse African languages. In Proceedingsof the 61st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 1088310900, Toronto, Canada. Associationfor Computational Linguistics.",
  "Aditya Joshi, Raj Dabre, Diptesh Kanojia, Zhuang Li,Haolan Zhan, Gholamreza Haffari, and Doris Dip-pold. 2024. Natural language processing for dialectsof a language: A survey. ArXiv, abs/2401.05632": "Anjali Kantharuban, Ivan Vulic, and Anna Korhonen.2023. Quantifying the dialect gap and its correlatesacross languages. In Findings of the Associationfor Computational Linguistics: EMNLP 2023, pages72267245, Singapore. Association for Computa-tional Linguistics. Samh Kchaou, Rahma Boujelbane, and Lamia Hadrich-Belguith. 2020.Parallel resources for TunisianArabic dialect translation.In Proceedings of theFifth Arabic Natural Language Processing Workshop,pages 200206, Barcelona, Spain (Online). Associa-tion for Computational Linguistics. Jaechan Lee, Alisa Liu, Orevaoghene Ahia, Hila Go-nen, and Noah Smith. 2023. That was the last straw,we need more: Are translation systems sensitive todisambiguating context? In Findings of the Associ-ation for Computational Linguistics: EMNLP 2023,pages 45554569, Singapore. Association for Com-putational Linguistics.",
  "J. Milroy and L. Milroy. 2012. Authority in Language:Investigating Standard English. Routledge Linguis-tics Classics. Taylor & Francis": "David R. Mortensen, Patrick Littell, Akash Bharadwaj,Kartik Goyal, Chris Dyer, and Lori S. Levin. 2016.Panphon: A resource for mapping IPA segmentsto articulatory feature vectors. In Proceedings ofCOLING 2016, the 26th International Conference onComputational Linguistics: Technical Papers, pages34753484. ACL. Niklas Muennighoff, Thomas Wang, Lintang Sutawika,Adam Roberts, Stella Biderman, Teven Le Scao,M Saiful Bari, Sheng Shen, Zheng Xin Yong, Hai-ley Schoelkopf, Xiangru Tang, Dragomir Radev,Alham Fikri Aji, Khalid Almubarak, Samuel Al-banie, Zaid Alyafeai, Albert Webson, Edward Raff,and Colin Raffel. 2023.Crosslingual generaliza-tion through multitask finetuning. In Proceedingsof the 61st Annual Meeting of the Association forComputational Linguistics (Volume 1: Long Papers),pages 1599116111, Toronto, Canada. Associationfor Computational Linguistics. Shamsuddeen Muhammad, Idris Abdulmumin, AbinewAyele, Nedjma Ousidhoum, David Adelani, Seid Yi-mam, Ibrahim Ahmad, Meriem Beloucif, Saif Mo-hammad, Sebastian Ruder, Oumaima Hourrane, Ali-pio Jorge, Pavel Brazdil, Felermino Ali, Davis David,Salomey Osei, Bello Shehu-Bello, Falalu Lawan,Tajuddeen Gwadabe, Samuel Rutunda, Tadesse Be-lay, Wendimu Messelle, Hailu Balcha, Sisay Chala,Hagos Gebremichael, Bernard Opoku, and StephenArthur. 2023. AfriSenti: A Twitter sentiment analysisbenchmark for African languages. In Proceedingsof the 2023 Conference on Empirical Methods inNatural Language Processing, pages 1396813981,Singapore. Association for Computational Linguis-tics. Wilhelmina Nekoto, Vukosi Marivate, TshinondiwaMatsila, Timi Fasubaa, Tajudeen Kolawole, TaiwoFagbohungbe, Solomon Oluwole Akinola, Sham-suddee Hassan Muhammad, Salomon Kabongo, Sa-lomey Osei, et al. 2020. Participatory research forlow-resourced machine translation: A case study inAfrican languages. Findings of EMNLP.",
  "Building african voices. In 23rd Annual Conferenceof the International Speech Communication Associa-tion (InterSpeech 2022), Incheon, Korea": "Odunayo Ogundepo, Tajuddeen Gwadabe, Clara Rivera,Jonathan Clark, Sebastian Ruder, David Adelani,Bonaventure Dossou, Abdou Diop, Claytone Sika-sote, Gilles Hacheme, Happy Buzaaba, IgnatiusEzeani, Rooweither Mabuya, Salomey Osei, ChrisEmezue, Albert Kahira, Shamsuddeen Muhammad,Akintunde Oladipo, Abraham Owodunni, AtnafuTonja, Iyanuoluwa Shode, Akari Asai, AnuoluwapoAremu, Ayodele Awokoya, Bernard Opoku, Chia-maka Chukwuneke, Christine Mwase, ClemenciaSiro, Stephen Arthur, Tunde Ajayi, Verrah Otiende,Andre Rubungo, Boyd Sinkala, Daniel Ajisafe,Emeka Onwuegbuzia, Falalu Lawan, Ibrahim Ah-mad, Jesujoba Alabi, Chinedu Mbonu, MofetoluwaAdeyemi, Mofya Phiri, Orevaoghene Ahia, RuqayyaIro, and Sonia Adhiambo. 2023. Cross-lingual open-retrieval question answering for African languages.In Findings of the Association for ComputationalLinguistics: EMNLP 2023, pages 1495714972, Sin-gapore. Association for Computational Linguistics.",
  "Avery Ozburn. 2023. Language profiles project. Ac-cessed: 2024-06-13": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evalu-ation of machine translation. In Proceedings of the40th Annual Meeting of the Association for Compu-tational Linguistics, pages 311318, Philadelphia,Pennsylvania, USA. Association for ComputationalLinguistics. Vineel Pratap, Andros Tjandra, Bowen Shi, PadenTomasello, Arun Babu, Sayani Kundu, Ali Elkahky,Zhaoheng Ni, Apoorv Vyas, Maryam Fazel-Zarandi,et al. 2024. Scaling speech technology to 1,000+languages. Journal of Machine Learning Research,25(97):152.",
  "Alec Radford, Jong Wook Kim, Tao Xu, Greg Brock-man, Christine McLeavey, and Ilya Sutskever. 2022.Robust speech recognition via large-scale weak su-pervision": "E. C. Rowlands. 1967. Ayo bamgbose: A grammar ofYoruba. (west African language monograph series,5.) xii, 175 pp. cambridge: University press in associ-ation with the west african languages survey and theinstitute of african studies, ibadan, 1966. 35s. Bul-letin of the School of Oriental and African Studies,30(3):736737. Iyanuoluwa Shode, David Ifeoluwa Adelani, JIng Peng,and Anna Feldman. 2023. NollySenti: Leveragingtransfer learning and machine translation for Nige-rian movie sentiment classification. In Proceedingsof the 61st Annual Meeting of the Association forComputational Linguistics (Volume 2: Short Papers),pages 986998, Toronto, Canada. Association forComputational Linguistics.",
  "Claytone Sikasote and Antonios Anastasopoulos. 2022": "BembaSpeech: A speech recognition corpus for theBemba language. In Proceedings of the ThirteenthLanguage Resources and Evaluation Conference,pages 72777283, Marseille, France. European Lan-guage Resources Association. Kathleen Siminyu and Sackey Freshia. 2020. AI4D -African language dataset challenge. In Proceedingsof the Fourth Widening Natural Language ProcessingWorkshop, pages 6877, Seattle, USA. Associationfor Computational Linguistics. Kathleen Siminyu, Xinjian Li, Antonios Anastasopou-los, David Mortensen, Michael R. Marlo, and Gra-ham Neubig. 2021. Phoneme recognition throughfine tuning of phonetic representations: a case studyon luhya language varieties. In Proceedings of Inter-speech 2021. Kathleen Siminyu, Kibibi Mohamed Amran, Abdul-rahman Ndegwa Karatu, Mnata Resani, MwimbiMakobo Junior, Rebecca Ryakitimbo, and BritoneMwasaru. 2022. Corpus development of kiswahilispeech recognition test and evaluation sets, preemp-tively mitigating demographic bias through collab-oration with linguists. In Proceedings of the FifthWorkshop on the Use of Computational Methods inthe Study of Endangered Languages, pages 1319,Dublin, Ireland. Association for Computational Lin-guistics. NLLB Team, Marta R. Costa-juss, James Cross, Onurelebi, Maha Elbayad, Kenneth Heafield, Kevin Hef-fernan, Elahe Kalbassi, Janice Lam, Daniel Licht,Jean Maillard, Anna Sun, Skyler Wang, GuillaumeWenzek, Al Youngblood, Bapi Akula, Loic Bar-rault, Gabriel Mejia Gonzalez, Prangthip Hansanti,John Hoffman, Semarley Jarrett, Kaushik RamSadagopan, Dirk Rowe, Shannon Spruit, ChauTran, Pierre Andrews, Necip Fazil Ayan, ShrutiBhosale, Sergey Edunov, Angela Fan, CynthiaGao, Vedanuj Goswami, Francisco Guzmn, PhilippKoehn, Alexandre Mourachko, Christophe Ropers,Safiyyah Saleem, Holger Schwenk, and Jeff Wang.2022.No language left behind: Scaling human-centered machine translation. Daniel van Niekerk, Charl van Heerden, Marelie Davel,Neil Kleynhans, Oddur Kjartansson, Martin Jansche,and Linne Ha. 2017. Rapid development of tts cor-pora for four South African languages. In Proc. In-terspeech 2017, pages 21782182.",
  "On the features of translationese. Digit. Scholarsh.Humanit., 30:98118": "Jiayi Wang, David Adelani, Sweta Agrawal, MarekMasiak, Ricardo Rei, Eleftheria Briakou, MarineCarpuat, Xuanli He, Sofia Bourhim, Andiswa Bukula,Muhidin Mohamed,Temitayo Olatoye,TosinAdewumi, Hamam Mokayed, Christine Mwase, Wan-gui Kimotho, Foutse Yuehgoh, Anuoluwapo Aremu,Jessica Ojo, Shamsuddeen Muhammad, SalomeyOsei, Abdul-Hakeem Omotayo, Chiamaka Chuk-wuneke, Perez Ogayo, Oumaima Hourrane, SalmaEl Anigri, Lolwethu Ndolela, Thabiso Mangwana,Shafie Mohamed, Hassan Ayinde, OluwabusayoAwoyomi, Lama Alkhaled, Sana Al-azzawi, NaomeEtori, Millicent Ochieng, Clemencia Siro, NjorogeKiragu, Eric Muchiri, Wangari Kimotho, Toad-oum Sari Sakayo, Lyse Naomi Wamba, DaudAbolade, Simbiat Ajao, Iyanuoluwa Shode, RickyMacharm, Ruqayya Iro, Saheed Abdullahi, StephenMoore, Bernard Opoku, Zainab Akinjobi, Abeeb Afo-labi, Nnaemeka Obiefuna, Onyekachi Ogbu, SamOchieng, Verrah Otiende, Chinedu Mbonu, YaoLu, and Pontus Stenetorp. 2024.AfriMTE andAfriCOMET: Enhancing COMET to embrace under-resourced African languages. In Proceedings of the2024 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies (Volume 1: Long Pa-pers), pages 59976023, Mexico City, Mexico. Asso-ciation for Computational Linguistics. Jiayi Wang, David Ifeoluwa Adelani, Sweta Agrawal,Ricardo Rei, Eleftheria Briakou, Marine Carpuat,Marek Masiak, Xuanli He, Sofia Bourhim, AndiswaBukula, et al. 2023. Afrimte and africomet: Empow-ering COMET to embrace under-resourced Africanlanguages. arXiv preprint arXiv:2311.09828.",
  "CHI Conference on Human Factors in ComputingSystems, pages 117": "Linting Xue, Noah Constant, Adam Roberts, Mihir Kale,Rami Al-Rfou, Aditya Siddhant, Aditya Barua, andColin Raffel. 2021. mT5: A massively multilingualpre-trained text-to-text transformer. In Proceedingsof the 2021 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies, pages 483498, On-line. Association for Computational Linguistics. Caleb Ziems, William Held, Jingfeng Yang, JwalaDhamala, Rahul Gupta, and Diyi Yang. 2023. Multi-VALUE: A framework for cross-dialectal EnglishNLP. In Proceedings of the 61st Annual Meetingof the Association for Computational Linguistics(Volume 1: Long Papers), pages 744768, Toronto,Canada. Association for Computational Linguistics. Ahmet stn, Viraat Aryabumi, Zheng-Xin Yong, Wei-Yin Ko, Daniel Dsouza, Gbemileke Onilude, NeelBhandari, Shivalika Singh, Hui-Lee Ooi, Amr Kayid,Freddie Vargus, Phil Blunsom, Shayne Longpre,Niklas Muennighoff, Marzieh Fadaee, Julia Kreutzer,and Sara Hooker. 2024. Aya model: An instructionfinetuned open-access multilingual language model.arXiv preprint arXiv:2402.07827.",
  "A.1Finetuning setup": "For MT, we fine-tuned in both directions with alearning-rate of 2e-5 and batch size of 16. Wetrained for four epochs, and kept the model withthe best eval loss. We used a weight decay of 0.01,warmup ratio 0.1, and a cosine annealing schedulerfor learning rate. While for ASR finetuning, wefine-tuned with a learning-rate of 1e-3 and batchsize of 8 for 20 epochs, as the validation WERcontinued to drop after preliminary runs with 10epochs. For S2TT, we fine-tuned for 10 epochswith an optimal learning rate of 3e-4. All trainingwas done on two NVIDIA A40 GPUs.",
  "Automatic Speech Recognition": "You are tasked to evaluate the performance of an Automatic Speech Recognition (ASR) system on your nativeYoruba dialect. This task involves assessing the accuracy and quality of transcriptions produced by this system whentranscribing audio from a folder that will be provided to you. Your evaluations will help us understand how wellthese systems handle linguistic variations. Each filename has a corresponding audio file with the same name in theaudio folder. Listen to the audio first, then look at the transcription from the model. Next, evaluate the quality of thetranscription compared to the audio you listened to and provide a score in the Excel sheet.Please focus on the following key criteria while evaluating the transcriptions:"
}