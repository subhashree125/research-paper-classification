{
  "Abstract": "As awareness of mental health issues grows, on-line counseling support services are becomingincreasingly prevalent worldwide. Detectingwhether users express suicidal ideation in text-based counseling services is crucial for identi-fying and prioritizing at-risk individuals. How-ever, the lack of domain-specific systems tofacilitate fine-grained suicide detection and cor-responding risk assessment in online counsel-ing poses a significant challenge for automatedcrisis intervention aimed at suicide prevention.In this paper, we propose PsyGUARD, an au-tomated system for detecting suicide ideationand assessing risk in psychological counseling.To achieve this, we first develop a detailed tax-onomy for detecting suicide ideation based onfoundational theories. We then curate a large-scale, high-quality dataset called PsySUICIDEfor suicide detection. To evaluate the capabil-ities of automated systems in fine-grained sui-cide detection, we establish a range of baselines.Subsequently, to assist automated services inproviding safe, helpful, and tailored responsesfor further assessment, we propose to build asuite of risk assessment frameworks. Our studynot only provides an insightful analysis of theeffectiveness of automated risk assessment sys-tems based on fine-grained suicide detectionbut also highlights their potential to improvemental health services on online counselingplatforms. Code, data, and models are avail-able at",
  "Irrelevant to Suicide/Self-injury/Aggressive Behavior": ": Examples of counselors adjusting their suicideprevention strategies based on their users suicide ac-tions and thoughts in real life. In this paper, the first stepis to conduct fine-grained suicide detection, followed byimplementing a safe, helpful, and customized approachto risk assessment. individuals, including relatives, friends, and soci-ety (Clark and Goldney, 2000; Cerel et al., 2008;Turecki et al., 2019). Online counseling servicesare available in many countries, allowing for con-fidential and immediate help to those in need freeof time and space, and therefore play a critical rolein suicide prevention (Bialer et al., 2022), whichcan effectively halt user suicidal ideation (Mapleset al., 2024). However, the lack of domain-specificsystems to enhance Chinese fine-grained suicidedetection and corresponding risk assessment in on-line counseling poses a significant challenge forautomated crisis intervention with the purpose ofsuicide prevention.Motivation Indeed, many researchers have beenworking on the development of automated systemsfor suicide detection that can be used in real-lifeproduction (Huang et al., 2015; Sawhney et al.,2018a, 2022b; Sinha et al., 2019; Guzman-Nateraset al., 2022). Despite advancements in such au-tomated detection systems, existing studies aremainly confined to suicide detection, often ignor-ing fine-grained suicidal actions or thoughts andcorresponding approaches for risk assessment, as illustrated in . Automated suicide detectionand risk assessment systems can help scale supportservices to reach a larger population, especiallyconsidering the increasing prevalence of onlinecounseling and mental health support platforms.Further, by providing automated support and in-tervention, individuals may feel more comfortableseeking help online, thus reducing the stigma asso-ciated with mental health issues and suicide preven-tion (Robinson et al., 2016). Empirical evidence(Nie et al., 2024; Maples et al., 2024) indicates thatindividuals are willing to interact with human orAI counselors, with many having disclosed theirsuicidal thoughts, plans, and actions, underscoringthe importance of automated systems for suicidedetection and risk assessment. The deficiencies inexisting systems significantly limit automated sys-tems capability to ensure safe, helpful, customizedservices in providing mental health support, whichmotivates us to carry out the work presented in thispaper. Challenges The lack of fine-grained suicide de-tection datasets in psychological counseling isa major challenge. Currently, numerous studieshave made significant progress in detecting sui-cidal ideation, but they primarily focus on socialmedia platforms (Huang et al., 2015; Cao et al.,2019; Sawhney et al., 2018a; Sinha et al., 2019;Gaur et al., 2019; Guzman-Nateras et al., 2022)rather than on counseling conversations. Therefore,using such datasets directly for risk detection inonline counseling may not be suitable due to a gapin user expressions, such as emojis, URLs, images,or special marks. Additionally, challenges posedby datasets collected from electronic health records(Pratap Singh Rawat et al., 2022) or mental healthrecords also include gaps in data format. Further-more, most studies that primarily focus on binarysuicidal ideation detection (Huang et al., 2015; Caoet al., 2019; Sawhney et al., 2018a; Sinha et al.,2019) face challenges in considering the granular-ity of suicide ideation categories in the real world. The lack of a comprehensive suite of risk as-sessments for corresponding suicide categories isanother challenge. In addition to users mentioningthat they have attempted suicide, simply identify-ing fine-grained suicide categories is not sufficientto conclude whether a user will actually commitsuicide. Risk assessment can directly guide how tointervene in a crisis situation. Therefore, suicideclassification is the initial step in suicide preven- tion, and further risk assessment is required, whichis largely overlooked by current studies.Our Approach In this paper, to our knowledge,we are the first to propose to study an automatedsystem for suicide detection and risk assessmentin psychological counseling. Our paper is orga-nized into five main parts. (2) describesthe existing works related to ours. (3)demonstrates the detailed process of taxonomy con-struction. (4) elaborates on rigorousdata collection. (5) constructs extensivebaselines, and (6) provides a simple yeteffective framework for risk assessment prior tocrisis intervention.Our Contributions We believe our work offers anew perspective on building an automated systemfor suicide detection and risk assessment in psycho-logical counseling within the research community.Our contributions can be summarized as follows: We construct PsyGUARD, an automated sys-tem for suicide detection and risk assessment,to ensure safe, helpful, customized servicesin text-based counseling conversations. Toachieve this, we develop a novel fine-grainedtaxonomy (3) for crisis situations, which cat-egorizes the risk levels based on suicidal ac-tions or thoughts, self-harm or harming others,and being abused. We build the PsyGUARD dataset, a large-scale, high-quality, and fine-grained suicidalideation detection corpus (4). This dataset iscreated through a rigorous collection process,including raw data collection, development ofannotation platforms, initial annotator train-ing, iterative human annotation, disagreementadjudication, and quality control. To understand the capabilities of automatedsystems in suicide risk detection, we establishvarious baselines (5) using our dataset forcomparison. These baselines include LLMzero-shot, LLM few-shot, fine-tuning pre-trained models, and fine-tuning LLM used forpredicting suicidal ideation of users content. To assist automated services in providing safe,helpful, and customized responses during riskassessment, we propose to build a risk assess-ment framework (6) for users during onlinetext-based counseling.",
  "Taxonomy for Suicide Risk": "Existing suicide risk annotations are mainly basedon the guidelines of the Columbia Suicide SeverityRating Scale (C-SSRS) (Posner et al., 2008, 2011),which is an authoritative questionnaire used by psy-chiatrists to assess the severity of suicide risk. EachC-SSRS severity class comprises a set of questionsthat conceptually characterize the respective cate-gory. The responses to these questions across theC-SSRS classes determine the risk of suicidalityfor an individual (Gomes de Andrade et al., 2018;McCall et al., 2021; Orr et al., 2022). Additionally,there is another commonly used taxonomy (Shinget al., 2018; Zirikly et al., 2019) for suicide annota-tion, which includes four levels: no risk, low risk,moderate risk, and severe risk. Compared to theC-SSRS, this taxonomy may have varying degreesof subjectivity. Furthermore, a more easily under-standable taxonomy (Sawhney et al., 2018a) is thebinary classification system, which categorizes in-dividuals as either having present or absent suicidalintent. Clearly, the existing taxonomies are eithertoo simplistic or too complex, and they do not fullymeet the requirements of our research purpose.",
  "Datasets for Suicide Risk Detection": "We present several typical datasets used for sui-cide detection in . Various works have beenrecently proposed with the objective of automat-ing the detection of user content expressing sui-cidal ideation posted on social media platforms(Huang et al., 2015; Cao et al., 2019; Sawhney et al., 2018a, 2022b; Sinha et al., 2019; Guzman-Nateras et al., 2022) and electronic health records(Pratap Singh Rawat et al., 2022). Further, someresearchers focus on electronic health records(Guzman-Nateras et al., 2022; Rawat et al., 2022)to detect clinical health issues. 2.2.2Methods for Suicide Risk DetectionIn short, the best available performance for suicidalideation detection still relies heavily on pre-trainedmodels. However, in order to improve performance,researchers have added a variety of strategies to en-hance the models ability to classify (Rawat and Yu,2022; Ghosh et al., 2022; Sawhney et al., 2022b).Basically, most of the research focused on con-ventional machine learning methods (Tyagi et al.,2023) and fine-tuning pre-trained models (Sawh-ney et al., 2020; Shing et al., 2020; Sawhney et al.,2022a). In the era of large language models, onework (Ghanadian et al., 2023) conducted a quantita-tive analysis of the open-source suicide intent clas-sification dataset using ChatGPT, evaluating meth-ods including zero-shot and few-shot paradigms.The experimental results have much room for im-provement, but it is a crucial attempt and explo-ration of using large models for suicide detection.",
  "Taxonomy Construction": "To build an automated system for suicide detec-tion and risk assessment in psychological coun-seling, we first propose to develop a novel taxon-omy for categorizing the level of suicide basedon suicide actions and thoughts. In collaborationwith experts1 in psychological counseling, we haveadapted and refined existing suicidal taxonomies, 1One is a Ph.D. in psychology and holds a State-Certificated Class 3 Psycho-counselor with four years of expe-rience in counseling. Another individual is a State-CertificatedClass 3 Psycho-counselor with a masters degree. The third",
  ": Our proposed taxonomy of suicidal ideation. The higher the number of stars, the higher the risk. See in the Appendix for the corresponding Chinese version": "such as C-SSRS (Posner et al., 2008, 2011), di-chotomy suicide (Sawhney et al., 2018a), suicidebehaviors (Nock et al., 2008; Crosby et al., 1999;Schreiber et al., 2010), self-injury behaviors (Nock,2010), and aggressive behavior (Stanford et al.,2003; Grigg, 2010), to suit the context of onlinetext-based counseling conversations. Based on thesolid theories and preliminary analysis of the real-life corpus, we elaborately construct the suicidetaxonomy, following the consensual qualitative re-search method (Nock et al., 2008; Bridge et al.,2006). Category DefinitionsOur proposed taxonomyfor suicide ideation detection, which consists of atotal of 11 fine-grained categories, is presented in. Based on the users perspective, whetherthe textual content contains suicidal ideation canbe divided into two key types, as illustrated by di-chotomy suicide, including suicidal ideation andnon-suicidal ideation. For details about the defini-tion of each category, see Appendix C.",
  "person is a doctoral student majoring in computer science andis the first author of this paper": "platforms, including Weibo2, Zhihu3, and Yixinli4,and open-source dialogue datasets. Through a rig-orous process of data annotation, the PsySUICIDEdataset is a high-quality and diverse corpus usedfor researching automated suicidal detection andfurther risk assessment. Some examples cherry-picked from the PsySUICIDE dataset are presentedin .Next, we will describe the process of construct-ing PsySUICIDE, including raw data collection, de-velopment of an annotation platform, initial anno-tator training, iterative human annotation, disagree-ment adjudication, and quality control. Finally,we will present the statistics of the PsySUICIDEdataset, as illustrated in .",
  "Raw Data Collection": "To cover both frequent explicit or implicit suicidalideation, such as explicit suicidality and queriesabout committing suicide, as well as infrequentnon-suicidal ideation, such as reports of suicide andexploration about suicide, we have selected the rawdata for our dataset from two publicly accessiblesources: social media platforms and open-sourcemental health dialogues. Furthermore, to ensurethat the data is suitable for conversational scenarios,we primarily collect our data from open-sourcedialogues that focus on mental health counseling.To ensure that there is no data duplication inthe unlabeled dataset, we initially performed dupli-cation filtering. To protect user privacy, we then",
  ": Data statistics of the PsySUICIDE dataset": "asked annotators to conduct a data anonymizationprocess, removing information related to user iden-tification (e.g., names and addresses) before thedata annotation.We collect 3800 user posts from social mediaplatforms. Furthermore, we collect 11000 user ut-terances from open-source mental health dialogues,with 4000, 3000, and 4000 user utterances fromSmileChat (Qiu et al., 2024), real-life counselor-client dialogues (Li et al., 2023), and real-lifehuman-machine dialogues collected in the wild(Qiu et al., 2024), respectively. For details of datasources, see Appendix B.",
  "Initial Annotator Training": "Three annotators are undergraduate fourth-year stu-dents majoring in psychology, with two of thembeing male and one being female. We provideour taxonomy () and annotation guidelinesalong with concrete examples ( in AppendixD) for three annotators. Prior to data annotation,we require three annotators to understand our tax-onomy and annotation guidelines. Any questionsthey have about their understanding have been re-solved by our experts, thus ensuring that we havereached an agreement before labeling. Trial-and-Error AnnotationTo validate the fea-sibility of the initial taxonomy and reduce its ob-scure points, we propose to adopt a trial-and-errorannotation paradigm to annotate three batches ofdata, comprising 200, 300, and 300 instances, re-spectively. Fleiss kappa (Fleiss et al., 1981) is usedto measure the inter-rater agreement, and all val-ues (0.555, 0.511, and 0.565) fall within moderateagreement with 0.5 0.6. After three batchannotations, we discuss the cases in which one an-notator assigns a different label. Consequently, weimprove our taxonomy based on the real-life corpus.Through trial-and-error annotation, in cooperationwith our experts and three annotators majoring inpsychology, we update the taxonomy again.",
  "amount of content produced by users, and eachunlabeled instance is assigned to three annotatorsfor independent annotation using our annotationplatform": "Mini-batch Iterative AnnotationTo validatethe completeness of our taxonomy, we assign fivebatches, each containing 100 instances. Fleisskappa is used to measure the inter-rater agreement,and all values (0.739, 0.74, 0.784, 0.785, and 0.816)fall within substantial agreement or even almostperfect with 0.7 0.9, which demonstratesthat our taxonomy is complete enough. Large-scale Iterative AnnotationWe assign 27batches of data for large-scale iterative annotation,each containing 500 instances. Fortunately, Fleisskappa value in each batch is consistently higherthan 0.7, demonstrating that the annotated data isof high quality with substantial agreement.",
  "Disagreement Adjudication": "In any batch of data annotation, we first use ma-jority voting to resolve label disagreements. Whenall three labels are distinct, the three annotatorsmust discuss any inconsistent instances that havenot been assigned the same label. Three annota-tors are required to discuss the final label for anyinstance assigned a distinct label for disagreementadjudication.It is worth noting that some instances have mul-tiple labels. Therefore, we require all annotatorsto tick the option if such an instance has multiplelabels. During disagreement adjudication, we alsorequire them to discuss such instances and assigncorrect labels in such cases.",
  "Quality Control": "To ensure high-quality annotation, we set a rigor-ous annotation standard: If the Fleiss kappa valueis lower than 0.6, the entire batch is rejected and re-turned to the annotators for revision until the Fleisskappa value exceeds 0.6. There are a total of 27batches of data in the process of large-scale itera-tive human annotation. Upon completing a batch,we calculate the Fleiss kappa value and conductstatistics on inconsistent instances. We report allFleiss kappa values during large-scale iterativeannotation in in Appendix E.",
  "We present the data statistics of the PsySUICIDEdataset in . For details of length distribution,": "refer to . There are 14800 instances in ourdataset, with 14594 instances having a single labeland 206 instances having multiple labels. Only22 instances contain the label of suicidal prepara-tory act, demonstrating that in real-life chattingscenarios, users often do not disclose their actionsin preparation for suicide. The average Chinesecharacter length per user utterance is 30.For training, validation, and test sets, each setis generated by stratified random sampling (Pe-dregosa et al., 2011) from the annotated datasetto maintain consistency in data distribution, witha partition ratio of 8:1:1. Specifically, in terms ofsingle-label instances, we first group them by labelsand split them with a stratified random samplingstrategy. For simplicity, we directly split multi-label instances using a random sampling strategy.",
  "Prompt-based Paradigm for LLMs": "LLMsWe prompt several popular LLMs to elicittextual labels via instructions free of fine-tuning,including zero- and few-shot settings. In this paperwe propose to evaluate several popular open-sourceLLMs, such as ChatGLM2-6B (Zeng et al., 2022),Qwen1.5-1.8B-Chat, Qwen1.5-4B-Chat, Qwen1.5-7B-Chat, Qwen1.5-14B-Chat, Qwen1.5-32B-Chatand Qwen1.5-72B-Chat (Bai et al., 2023). Ad-ditionally, we also evaluate three popular closed-source LLMs (OpenAI et al., 2024), such as GPT-3.5 Turbo5, GPT-4-preview6 and GPT-47, whereGPT-4-preview and GPT-4 are state-of-the-art mod-els acknowledged by researchers. Experimental SetupDue to the generation di-versity in LLMs, we propose to prompt LLMs togenerate exact labels given an instruction and anunlabeled instance three times. Based on officialrecommendations, we set the temperature andtop_p to 0.8 and 0.8 for ChatGLM2-6B, 0.7 and 5The model we use is gpt-3.5-turbo-0125, with trainingdata up to Sep 2021.6The model we use is gpt-4-1106-preview, with trainingdata up to Apr 2023.7The model we use is gpt-4-0613, with training data up toSep 2021.",
  "Like fine-tuning the BERT and RoBERTa models,we select one of the most widely used open-sourcemodels, ChatGLM2-6B to conduct parameter-efficient fine-tuning": "Experimental SetupThree random seeds we usein LoRA-tuning are 42, 43, and 44. During LoRA-tuning (Hu et al., 2021) for ChatGLM2-6B, theepoch is 2, and we only save the model in the lastepoch during fine-tuning. The learning rate is 1e-4 and batch size is 2. The LoRA rank, dropout,and are 16, 0.1, and 64, respectively. We settemperature and top_p to 0.8 and 0.8 during in-ference time. For model evaluation, we instruct themodel to generate three rounds.",
  "Results": "Evaluation results for fine-grained classification onthe test set are presented in . For the detailsof evaluation metrics, see Appendix H.Overall, the performance of fine-tuning, includ-ing full fine-tuning and parameter-efficient tun-ing, is superior to the prompt-based paradigm. Interms of accuracy, ChatGLM2-6B-LoRA achievesthe best performance, with a value of 91.99%.RoBERTa-large follows closely with the second- best performance, only 0.3% lower than that ofChatGLM2-6B-LoRA. The best accuracy perfor-mance on the prompt-based paradigm is achievedby GPT-4-preview with the zero-shot setting, scor-ing 82.72%, demonstrating that GPT-4-preview isthe state-of-the-art model among the models weevaluated. Notably, there is nearly a 9-percentage-point gap between RoBERTa and GPT-4-preview(zero-shot) regarding accuracy.The best accu-racy achieved on an open-source model is byQwen1.5-32B-Chat with the few-shot setting, scor-ing 78.47%.Generally, performance increases with modelsize. Interestingly, we note that Qwen1.5-72B-Chatperforms weaker than Qwen1.5-32B-Chat. The rea-son behind this may be that Qwen1.5-32B-Chat,which is released later than Qwen1.5-72B-Chat,has access to a more training epoch, a larger train-ing corpus, and more advanced training strategies.Overall, in-context learning usually enhancesthe models performance. That is, the few-shotparadigm positively promotes models Qwen1.5-7B, Qwen1.5-14B, Qwen1.5-32B, Qwen1.5-72B,and GPT-3.5. However, there are exceptions wherethe performance of the few-shot paradigm is notas good as that of the zero-shot paradigm, such asChatGLM2-6B, Qwen1.5-1.8B, and Qwen1.5-4B.It is clear that smaller models are caught in the in-context learning dilemma. For GPT-4, in-contextlearning also does not result in positive gains, so itis important to select in-context samples carefully.The newer the release date of the model, thebetter the performance obtained by the test set.Typical cases are Qwen1.5-32B-Chat and GPT-4-preview.",
  "Error Case Study": "Through an in-depth analysis of the misclassifica-tions, we summarize three common misclassifica-tions using the best-performing pre-trained modelRoBERTa as an example. (1) Samples of \"sui-cide attempt\" are misclassified into the other fourcategories of suicidal ideation in label space. (2)The classifier is too sensitive to specific terms andmisclassifies samples about \"exploration about sui-cide\" as suicide ideation. (3) Some user utterancesirrelevant to suicide/self-injury/aggressive behav-ior, despite containing the word \"death,\" are classi-fied by the classifier as having suicidal ideation.Furthermore, we present more examples of errorcase studies in in Appendix I. Dialogue Rules: Respond naturally and emotionally; follow the character traits; avoid meaningless self-questions; react according to emotions; avoid contradictions or repetitions; do not mention \"rules\"; keep answers brief, one to two sentences.Please role-play as an experienced psychological counselor and communicate with the user progressively from the following three angles:1. In the past two weeks, have you felt down, depressed, or hopeless?2. In the past two weeks, have you had thoughts of suicide?3. Have you ever attempted suicide? If yes, when did it happen?",
  "User: I haven't tried to commit suicide": "You're now serving as a counseling supervision supervisor, analyzing the conversation history provided, evaluating the risk level of suicidal ideation for the user on a scale of 0 to 5. 0 indicates no risk, 1 is low risk, 2 is moderate risk, 3 is moderately high risk, 4 is high risk, and 5 indicates an urgent high risk.",
  "Active Suicidal Ideation": ": Our automated risk assessment frameworkwhen interacting with a user who has active suicidalideation. The top panel presents the flow chart of ourautomated system for suicide detection and risk assess-ment. The bottom panel presents a concrete examplefor illustration. The text on a pink background will beadaptively replaced by the detected suicidal category.The text on a gray background is a dialogue sessionbetween a user and a counselor, where responses are gen-erated by the LLM. The text on a yellow backgroundis a risk assessment result completed using the prompt-ing method. Corresponding Chinese version, see . The model we use is GPT-4o (gpt-4o-2024-05-13).For other cases, please refer to Appendix J.",
  "Automated System for Risk Assessment": "To further utilize suicidal ideation detection, wepropose a framework for risk assessment. Onceour automated suicide detection system identifiesa user expressing a suicide attempt, our systemwill first recommend the user to the Free 24-HourHelpline and inform the professional counselor forcrisis intervention and further referral. For the otherfour types of suicidal ideation and five types ofnon-suicidal categories with different risk levels,we use an automated risk assessment framework tointeract with users, as shown in . Moreover,nine types of screening questions (Boudreaux et al.,2015) for risk assessment are shown in in Appendix J. Practical Application ResultsWe conduct acomprehensive risk assessment on Liaohuixiaotian(), a popular WeChat Mini Program fortext-based online counseling in China. We ran-domly select 1000 user messages from our plat-forms collected data. Our system achieves an ac-curacy of 95.2% in detecting suicidal ideation, asconfirmed by expert annotations, demonstrating itshigh accuracy and practicality. Furthermore, weselect 20 user messages with varying risk levels totest our risk assessment framework, achieving anadoption rate of 90.0% among the responses rec-ommended by the framework. For more examples,please refer to Figures 13 and 15. These findingsvalidate the systems effectiveness and practicalapplication in real-world settings.",
  "Conclusion": "In sum, we present a novel and theoreticallygrounded fine-grained taxonomy for detecting sui-cidal ideation, merging risk levels with categoriesof suicidal actions and thoughts. We address gapsby introducing the PsySUICIDE dataset, which ismanually annotated with experts and rigorous qual-ity control. Further, we develop various baselinesbased on pre-trained LMs and LLMs and create anLLM-based risk assessment framework for usersduring text-based online counseling. Our work pro-vides an insightful analysis of the effectiveness ofautomated risk assessment systems and their poten-tial advantages in improving mental health servicesin online counseling platforms.",
  "Limitations": "Multi-language SupportIn this paper, wemainly focus on Chinese fine-grained suicidalideation detection. Collecting data in other lan-guages is challenging for us, but we will endeavorto expand our capabilities in the future. Tailored Models for Risk AssessmentOur pro-posed system integrates seamlessly into real-worldsettings to assist counselors effectively. It monitorsuser utterances for suicide risk, and upon detectingsuicidal ideation, it facilitates an automated riskassessment under professional supervision. How-ever, in the era of LLMs, our paper proposes anLLM-based risk assessment framework. As shownin , we directly use powerful LLMs, suchas GPT-4o, as a model for risk assessment. In thefuture, we will collect large-scale user-counselor",
  "Our research is reviewed and approved by theWestlake University Institutional Ethics Committee(20211013LZZ001)": "Suicide Risk Assessment for AnnotatorsPriorto data annotation, our professional counselorsfirst conduct counseling interviews with annotatorsto confirm that they are physically and mentallyhealthy and suitable for our annotation work. Ineach small batch of annotation, after the comple-tion of data annotation, the counselor will conducta short interview to inquire about the annotatorsphysical and mental health status of the annotatorto ensure physical and mental health throughoutthe annotation process. After completing the entirelabeling process, our professional counselors con-duct a final in-depth counseling interview to ensurethat the labeled content does not have any negativeimpact on all annotators. Annotator SalaryIn total, we spent 22,500RMB on the project, which lasted only 25 days.This cost means each annotator was paid 300 RMBfor their work per day, which is higher than the aver-age wage (250 RMB/day) in their city. In addition,two professional counselors, both of whom are paid2,000 RMB, have made outstanding contributionsto the construction and refinement of our taxon-omy, as well as the safeguarding of the physicaland mental health of our annotators. Overall, wehave guaranteed that our salary level is competitivein our city.",
  "Data SharingConsidering the nature of suicidedata, we must share this dataset cautiously. In": "accordance with the rules for releasing data, third-party researchers who require access to the Psy-SUICIDE dataset must provide us with their validID, proof of work, and the reason that they requestthe data (e.g., the research questions). They mustbe affiliated with a non-profit academic or researchinstitution. The rules stipulate that they must ob-tain the approval of an Institutional Review Board(IRB), ensure that principal investigators are work-ing full-time, and secure written approval fromthe Institution Office of Research or an equivalentoffice. Additionally, they must sign a Data Nondis-closure Agreement and promise not to share thedata with anyone. However, for-profit organiza-tions that want to use this data must sign a licenseagreement to gain access to the dataset. Notably,researchers who use this dataset should keep inmind the importance of using technology for socialgood.",
  "Acknowledgements": "We thank the anonymous reviewers for their valu-able comments. This work was supported by theResearch Center for Industries of the Future atWestlake University (Grant No. WU2023C017)and the Key Research and Development Programof Zhejiang Province of China (Grant No. 2021-C03139). Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, FeiHuang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin,Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu,Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren,Xuancheng Ren, Chuanqi Tan, Sinan Tan, JianhongTu, Peng Wang, Shijie Wang, Wei Wang, Sheng-guang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang,Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu,Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingx-uan Zhang, Yichang Zhang, Zhenru Zhang, ChangZhou, Jingren Zhou, Xiaohuan Zhou, and TianhangZhu. 2023. Qwen technical report. arXiv preprintarXiv:2309.16609. Amir Bialer, Daniel Izmaylov, Avi Segal, Oren Tsur,Yossi Levi-Belz, and Kobi Gal. 2022.Detect-ing suicide risk in online counseling services: Astudy in a low-resource language. arXiv preprintarXiv:2209.04830. Edwin D Boudreaux, Michelle L Jaques, Kaitlyn MBrady, Adam Matson, and Michael H Allen. 2015.The patient safety screener: validation of a brief sui-cide risk screener for emergency department settings.Archives of suicide research, 19(2):151160.",
  "Joseph L Fleiss, Bruce Levin, Myunghee Cho Paik,et al. 1981. The measurement of interrater agreement.Statistical methods for rates and proportions, 2(212-236):2223": "Manas Gaur, Amanuel Alambo, Joy Prakash Sain, UgurKursuncu, Krishnaprasad Thirunarayan, RamakanthKavuluru, Amit Sheth, Randy Welton, and Jyotish-man Pathak. 2019. Knowledge-aware assessment ofseverity of suicide risk for early intervention. In Theworld wide web conference, pages 514525. Hamideh Ghanadian, Isar Nejadgholi, and HusseinAl Osman. 2023. ChatGPT for suicide risk assess-ment on social media: Quantitative evaluation ofmodel performance, potentials and limitations. InProceedings of the 13th Workshop on ComputationalApproaches to Subjectivity, Sentiment, & Social Me-dia Analysis, pages 172183, Toronto, Canada. Asso-ciation for Computational Linguistics. Soumitra Ghosh, Dhirendra Kumar Maurya, Asif Ek-bal, and Pushpak Bhattacharyya. 2022. Em-persona:emotion-assisted deep neural framework for person-ality subtyping from suicide notes. In Proceedings ofthe 29th International Conference on ComputationalLinguistics, pages 10981105. Norberto Nuno Gomes de Andrade, Dave Pawson, DanMuriello, Lizzy Donahue, and Jennifer Guadagno.2018. Ethics and artificial intelligence: suicide pre-vention on facebook.Philosophy & Technology,31:669684.",
  "Edward J. Hu, Yelong Shen, Phillip Wallis, ZeyuanAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, andWeizhu Chen. 2021. Lora: Low-rank adaptation oflarge language models": "Xiaolei Huang, Xin Li, Lei Zhang, Tianli Liu, DavidChiu, and Tingshao Zhu. 2015. Topic model foridentifying suicidal ideation in chinese microblog.In Proceedings of the 29th pacific asia conferenceon language, information and computation, pages553562. Waseda University. Anqi Li, Lizhi Ma, Yaling Mei, Hongliang He, ShuaiZhang, Huachuan Qiu, and Zhenzhong Lan. 2023.Understanding client reactions in online mentalhealth counseling. In Proceedings of the 61st An-nual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers), pages 1035810376. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,Luke Zettlemoyer, and Veselin Stoyanov. 2019.Roberta: A robustly optimized bert pretraining ap-proach. arXiv preprint arXiv:1907.11692. J John Mann, Alan Apter, Jose Bertolote, Annette Beau-trais, Dianne Currier, Ann Haas, Ulrich Hegerl, JoukoLonnqvist, Kevin Malone, Andrej Marusic, et al.2005. Suicide prevention strategies: a systematicreview. Jama, 294(16):20642074.",
  "Bethanie Maples, Merve Cerit, Aditya Vishwanath, andRoy Pea. 2024. Loneliness and suicide mitigationfor students using gpt3-enabled chatbots. npj MentalHealth Research, 3(1):4": "William V McCall, Ben Porter, Ashley R Pate, Court-ney J Bolstad, Christopher W Drapeau, Andrew DKrystal, Ruth M Benca, Meredith E Rumble, andMichael R Nadorff. 2021. Examining suicide as-sessment measures for research use: using item re-sponse theory to optimize psychometric assessmentfor research on suicidal ideation in major depressivedisorder.Suicide and Life-Threatening Behavior,51(6):10861094. Jingping Nie, Hanya Shao, Yuang Fan, Qijia Shao,Haoxuan You, Matthias Preindl, and Xiaofan Jiang.2024. Llm-based conversational ai therapist for dailyfunctioning screening and psychotherapeutic inter-vention via everyday smart devices. arXiv preprintarXiv:2403.10779.",
  "Matthew K Nock, Guilherme Borges, Evelyn J Bromet,Christine B Cha, Ronald C Kessler, and Sing Lee.2008. Suicide and suicidal behavior. Epidemiologicreviews, 30(1):133": "OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal,Lama Ahmad, Ilge Akkaya, Florencia Leoni Ale-man, Diogo Almeida, Janko Altenschmidt, Sam Alt-man, Shyamal Anadkat, Red Avila, Igor Babuschkin,Suchir Balaji, Valerie Balcom, Paul Baltescu, Haim-ing Bao, Mohammad Bavarian, Jeff Belgum, Ir-wan Bello, Jake Berdine, Gabriel Bernadett-Shapiro,Christopher Berner, Lenny Bogdonoff, Oleg Boiko,Madelaine Boyd, Anna-Luisa Brakman, Greg Brock-man, Tim Brooks, Miles Brundage, Kevin Button,Trevor Cai, Rosie Campbell, Andrew Cann, BrittanyCarey, Chelsea Carlson, Rory Carmichael, BrookeChan, Che Chang, Fotis Chantzis, Derek Chen, SullyChen, Ruby Chen, Jason Chen, Mark Chen, BenChess, Chester Cho, Casey Chu, Hyung Won Chung,Dave Cummings, Jeremiah Currier, Yunxing Dai,Cory Decareaux, Thomas Degry, Noah Deutsch,Damien Deville, Arka Dhar, David Dohan, SteveDowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti,Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix,Simn Posada Fishman, Juston Forte, Isabella Ful-ford, Leo Gao, Elie Georges, Christian Gibson, VikGoel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, ScottGray, Ryan Greene, Joshua Gross, Shixiang ShaneGu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris,Yuchen He, Mike Heaton, Johannes Heidecke, ChrisHesse, Alan Hickey, Wade Hickey, Peter Hoeschele,Brandon Houghton, Kenny Hsu, Shengli Hu, XinHu, Joost Huizinga, Shantanu Jain, Shawn Jain,Joanne Jang, Angela Jiang, Roger Jiang, HaozhunJin, Denny Jin, Shino Jomoto, Billie Jonn, Hee-woo Jun, Tomer Kaftan, ukasz Kaiser, Ali Ka-mali, Ingmar Kanitscheider, Nitish Shirish Keskar,Tabarak Khan, Logan Kilpatrick, Jong Wook Kim,Christina Kim, Yongjik Kim, Jan Hendrik Kirch-ner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,ukasz Kondraciuk, Andrew Kondrich, Aris Kon-stantinidis, Kyle Kosic, Gretchen Krueger, VishalKuo, Michael Lampe, Ikai Lan, Teddy Lee, JanLeike, Jade Leung, Daniel Levy, Chak Ming Li,Rachel Lim, Molly Lin, Stephanie Lin, MateuszLitwin, Theresa Lopez, Ryan Lowe, Patricia Lue,Anna Makanju, Kim Malfacini, Sam Manning, TodorMarkov, Yaniv Markovski, Bianca Martin, KatieMayer, Andrew Mayne, Bob McGrew, Scott MayerMcKinney, Christine McLeavey, Paul McMillan,Jake McNeil, David Medina, Aalok Mehta, JacobMenick, Luke Metz, Andrey Mishchenko, PamelaMishkin, Vinnie Monaco, Evan Morikawa, DanielMossing, Tong Mu, Mira Murati, Oleg Murk, DavidMly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak,Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh,Long Ouyang, Cullen OKeefe, Jakub Pachocki, AlexPaino, Joe Palermo, Ashley Pantuliano, Giambat-tista Parascandolo, Joel Parish, Emy Parparita, AlexPassos, Mikhail Pavlov, Andrew Peng, Adam Perel-man, Filipe de Avila Belbute Peres, Michael Petrov,Henrique Ponde de Oliveira Pinto, Michael, Poko- rny, Michelle Pokrass, Vitchyr H. Pong, Tolly Pow-ell, Alethea Power, Boris Power, Elizabeth Proehl,Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh,Cameron Raymond, Francis Real, Kendra Rimbach,Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-der, Mario Saltarelli, Ted Sanders, Shibani Santurkar,Girish Sastry, Heather Schmidt, David Schnurr, JohnSchulman, Daniel Selsam, Kyla Sheppard, TokiSherbakov, Jessica Shieh, Sarah Shoker, PranavShyam, Szymon Sidor, Eric Sigler, Maddie Simens,Jordan Sitkin, Katarina Slama, Ian Sohl, BenjaminSokolowsky, Yang Song, Natalie Staudacher, Fe-lipe Petroski Such, Natalie Summers, Ilya Sutskever,Jie Tang, Nikolas Tezak, Madeleine B. Thompson,Phil Tillet, Amin Tootoonchian, Elizabeth Tseng,Preston Tuggle, Nick Turley, Jerry Tworek, Juan Fe-lipe Cern Uribe, Andrea Vallone, Arun Vijayvergiya,Chelsea Voss, Carroll Wainwright, Justin Jay Wang,Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei,CJ Weinmann, Akila Welihinda, Peter Welinder, Ji-ayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner,Clemens Winter, Samuel Wolrich, Hannah Wong,Lauren Workman, Sherwin Wu, Jeff Wu, MichaelWu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qim-ing Yuan, Wojciech Zaremba, Rowan Zellers, ChongZhang, Marvin Zhang, Shengjia Zhao, TianhaoZheng, Juntang Zhuang, William Zhuk, and BarretZoph. 2024. Gpt-4 technical report. Martin Orr, Kirsten Van Kessel, and David Parry. 2022.The ethical role of computational linguistics in digi-tal psychological formulation and suicide prevention.In Proceedings of the Eighth Workshop on Computa-tional Linguistics and Clinical Psychology. F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer,R. Weiss, V. Dubourg, J. Vanderplas, A. Passos,D. Cournapeau, M. Brucher, M. Perrot, and E. Duch-esnay. 2011.Scikit-learn: Machine learning inPython.Journal of Machine Learning Research,12:28252830. Kelly Posner, Gregory K Brown, Barbara Stanley,David A Brent, Kseniya V Yershova, Maria AOquendo, Glenn W Currier, Glenn A Melvin, Lau-rence Greenhill, Sa Shen, et al. 2011. The columbiasuicide severity rating scale: initial validity and inter-nal consistency findings from three multisite studieswith adolescents and adults. American journal ofpsychiatry, 168(12):12661277. Kent Posner, D Brent, C Lucas, M Gould, B Stan-ley, G Brown, P Fisher, J Zelazny, A Burke, MJNYOquendo, et al. 2008. Columbia-suicide severityrating scale (c-ssrs). New York, NY: Columbia Uni-versity Medical Center, 10:2008.",
  "multi-turn inclusive language expansion via chatgptfor mental health support": "Bhanu Pratap Singh Rawat, Samuel Kovaly, Hong Yu,and Wilfred Pigeon. 2022. ScAN: Suicide attemptand ideation events dataset. In Proceedings of the2022 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, pages 10291040, Seat-tle, United States. Association for ComputationalLinguistics. Bhanu Pratap Singh Rawat and Hong Yu. 2022. Pa-rameter efficient transfer learning for suicide attemptand ideation detection. In Proceedings of the 13thInternational Workshop on Health Text Mining andInformation Analysis (LOUHI), pages 108115. Jo Robinson, Georgina Cox, Eleanor Bailey, Sarah Het-rick, Maria Rodrigues, Steve Fisher, and Helen Her-rman. 2016. Social media and suicide prevention: asystematic review. Early intervention in psychiatry,10(2):103121. Ramit Sawhney, Harshit Joshi, Saumya Gandhi, andRajiv Ratn Shah. 2020. A time-aware transformerbased model for suicide ideation detection on socialmedia. In Proceedings of the 2020 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 76857697, Online. Association forComputational Linguistics. Ramit Sawhney, Prachi Manchanda, Raj Singh, andSwati Aggarwal. 2018a. A computational approachto feature extraction for identification of suicidalideation in tweets.In Proceedings of ACL 2018,Student Research Workshop, pages 9198. Ramit Sawhney, Prachi Manchanda, Raj Singh, andSwati Aggarwal. 2018b. A computational approachto feature extraction for identification of suicidalideation in tweets. In Proceedings of ACL 2018, Stu-dent Research Workshop, pages 9198, Melbourne,Australia. Association for Computational Linguistics. Ramit Sawhney, Atula Neerkaje, and Manas Gaur.2022a. A risk-averse mechanism for suicidality as-sessment on social media. In Proceedings of the 60thAnnual Meeting of the Association for ComputationalLinguistics (Volume 2: Short Papers), pages 628635,Dublin, Ireland. Association for Computational Lin-guistics.",
  "workshop on computational linguistics and clinicalpsychology: from keyboard to clinic, pages 2536": "Han-Chin Shing, Philip Resnik, and Douglas Oard.2020. A prioritization model for suicidality risk as-sessment. In Proceedings of the 58th Annual Meet-ing of the Association for Computational Linguistics,pages 81248137, Online. Association for Computa-tional Linguistics. Pradyumna Prakhar Sinha, Rohan Mishra, Ramit Sawh-ney, Debanjan Mahata, Rajiv Ratn Shah, and HuanLiu. 2019. # suicidal-a multipronged approach toidentify and explore suicidal ideation in twitter. InProceedings of the 28th ACM international confer-ence on information and knowledge management,pages 941950.",
  "Gustavo Turecki, David A Brent, David Gunnell,Rory C OConnor, Maria A Oquendo, Jane Pirkis,and Barbara H Stanley. 2019. Suicide and suiciderisk. Nature reviews Disease primers, 5(1):74": "Sarthak Tyagi, Adwita Arora, Krish Chopra, and MananSuri. 2023. Trigger warnings: A computational ap-proach to understanding user-tagged trigger warnings.In Proceedings of the 8th Student Research Workshopassociated with the International Conference RecentAdvances in Natural Language Processing, pages4454, Varna, Bulgaria. INCOMA Ltd., Shoumen,Bulgaria. Aohan Zeng, Xiao Liu, Zhengxiao Du, Zihan Wang,Hanyu Lai, Ming Ding, Zhuoyi Yang, Yifan Xu,Wendi Zheng, Xiao Xia, et al. 2022.Glm-130b:An open bilingual pre-trained model. arXiv preprintarXiv:2210.02414. Ayah Zirikly, Philip Resnik, Ozlem Uzuner, and KristyHollingshead. 2019. Clpsych 2019 shared task: Pre-dicting the degree of suicide risk in reddit posts. InProceedings of the sixth workshop on computationallinguistics and clinical psychology, pages 2433.",
  "BDetails of Data Sources": "SmileChat (Qiu et al., 2024) is a large-scale, di-verse, and high-quality multi-turn conversationdataset generated by instructing ChatGPT to gener-ate multi-turn dialogues based on QAs for mentalhealth support. The real-world counselor-client di-alogue corpus (Li et al., 2023) is a high-qualitymulti-turn dialogue dataset, which consists of au-thentic dialogues lasting about 50 minutes betweenclients and professional counselors. Finally, thehuman-machine dialogues (Qiu et al., 2024) is ahigh-quality multi-turn dialogue dataset consistingof real-life dialogues between users and the dia-logue model collected in the wild.",
  "C.2Suicidal Ideation": "Suicide Attempt. A suicide attempt refers to theact wherein an individual has taken concrete stepstoward ending their life but ultimately did not resultin death. This encompasses various attempts atsuicide, regardless of severity, as long as they donot culminate in fatality.Suicidal Preparatory Act. A suicidal preparatoryact refers to the preparatory actions taken by anindividual with the intention of committing suicide,which may include acquiring tools or items andselecting a location. These preparatory actionshave not yet been carried out.Suicidal Plan. A suicidal plan refers to a schemedevised by an individual with the intention of self-termination. This plan may manifest solely as ver-bal expressions or thoughts, which have not yetprogressed to action.Active Suicidal Ideation. Individuals have a clearintent to actively end their own lives, includinginquiring about methods of death or suicide.Passive Suicidal Ideation.Passive suicidalideation refers to an individual expressing a desireor anticipation for death, hoping for death to oc-cur without taking explicit proactive actions. Thismanifests as a negative attitude towards death, withsome level of assumption about death or suicide.",
  "C.3Non-Suicidal Ideation": "Self-injury Behavior.Self-injury behavior,broadly speaking, refers to non-suicidal acts ofself-harm. Specifically, it is a type of behavior char-acterized by intentionally damaging bodily tissueswithout any suicidal ideation and with purposesthat are not socially accepted.Self-injury Ideation. In broad terms, self-injuryideation refers to the intention behind non-suicidalself-harm. Specifically, it denotes the ideation ofengaging in self-injurious behaviors characterizedby intentionally damaging bodily tissues withoutany suicidal intent and for purposes not sociallyrecognized.Aggression against Others. Aggression againstothers refers to actions taken by users themselvesto harm others, including both physical actions andverbal assaults (such as swearing or insults), withthe intention of causing harm to others.Aggression against Users. Aggression againstusers refers to intentional physical or verbal behav-",
  "iors aimed at harming the user, including cursingand insults": "Exploration about Suicide. Exploration aboutsuicide refers to an examination of the essence ofsuicide, primarily encompassing but not limited tothe following three aspects: (1) Individuals mayexpress thoughts or explore the concept of suicide,but this does not necessarily imply an actual in-tent to commit suicide. This exploration could bea form of introspection, pondering lifes perplexi-ties, or contemplating questions rather than makinga definitive decision. (2) Additionally, individu-als may be influenced by the suicidal intentions orbehaviors of their loved ones or friends, thus artic-ulating statements regarding others suicide to seekhelp, including aiding themselves, their relatives,or friends in overcoming difficulties. (3) Curiosityabout the act of suicide. Irrelevant to Suicide/Self-injury/Aggressive Be-havior. Typically, this refers to a state or behaviorthat is not directly related to suicide, self-harm, orharming others. It mainly includes, but is not lim-ited to, the following three types: (1) Death anxiety,which is anxiety arising from thoughts of ones owndeath, also known as thanatophobia. (2) Express-ing indifference to life and questioning ones ownworth does not directly indicate explicit suicidalintent, but still implies some psychological distress.(3) Users seeking clarification on dreaming aboutdeceased relatives.",
  "GSetup for Fine-tuning Pre-trained LMs": "The output features h of the top layer of thepre-trained model can be represented as z =[zc, z1, z2, ..., zn], where zc is the representationof the class-specific token [CLS]. We feed zc into afeed-forward neural network with a default modeldropout rate of 0.1 for the final prediction. Duringfine-tuning the pre-trained models, we initializeweights of feed-forward layers with normal distri-bution. We set the training epoch as 10 and selectthe checkpoint that achieves the best accuracy valueon the validation set to evaluate the test set. Forthe training processes, we adopt Sigmoid CrossEntropy loss as the default classification loss. Weuse the Adam optimizer to train the network withmomentum values = [0.9, 0.999]. Thelearning rate is initialized to 2e-5 and decayed by",
  "For the other four types of suicidal ideation and fivetypes of non-suicidal categories with different risk": "Suicide Attempt: A suicide attempt refers to the act wherein an individual has taken concrete steps toward ending their life but ultimately did not result in death. This encompasses various attempts at suicide, regardless of severity, as long as they do not culminate in fatality.For example, \"I used a blade to cut my wrist.\" This qualifies as a severe act of self-harm with a high likelihood of death, hence classified as a suicide attempt.",
  "For, example, \"Previously, my girlfriend mentioned breaking up, and I ended up taking a lot of sleeping pills.\"": "Suicidal Preparatory Act: A suicidal preparatory act refers to the preparatory actions taken by an individual with the intention of committing suicide, which may include acquiring tools or items and selecting a location. These preparatory actions have not yet been carried out.For example, \"I've bought a lot of sleeping pills to commit suicide.\" \"I've searched online for many ways to commit suicide.\" Suicidal Plan: A suicidal plan refers to a scheme devised by an individual with the intention of self-termination. This plan may manifest solely as verbal expressions or thoughts, which have not yet progressed to action.For example, \"To commit suicide, I plan to buy a lot of sleeping pills.\" \"Life is tough, I just want to jump off a building.\" Active Suicidal Ideation: Individuals have a clear intent to actively end their own lives, including inquiring about methods of death or suicide.\"Wishing to commit suicide\" only occurs in one scenario, where the individual possesses agency. \"Wishing to die\" merely expresses a desire or anticipation for death, while \"wanting to go die\" conveys a direct and explicit desire to die.",
  "For example, \"I want to commit suicide\", \"I want to die, I want to end my own life.\"": "Passive Suicidal Ideation: Passive suicidal ideation refers to an individual expressing a desire or anticipation for death, hoping for death to occur without taking explicit proactive actions. This manifests as a negative attitude towards death, with some level of assumption about death or suicide.For example, \"I'd rather be dead. \", \"If I were to die, my family would be better off.\", \"I wish I could fall asleep and never wake up.\"",
  "For example, \"I might as well just die.\", \"I'd rather be dead.\", \"It's better if I'm dead.\", \"I might as well just die.\"": "Self-injury Behavior: Self-injury behavior, broadly speaking, refers to non-suicidal acts of self-harm. Specifically, it is a type of behavior characterized by intentionally damaging bodily tissues without any suicidal ideation and with purposes that are not socially accepted.For example, \"Using sharp objects (such as knives, razor blades, or needles) to cut or puncture the skin.\"",
  "For example, \"Burning the skin, typically with cigarettes.\"": "Self-injury Ideation: In broad terms, self-injury ideation refers to the intention behind non-suicidal self-harm. Specifically, it denotes the ideation of engaging in self-injurious behaviors characterized by intentionally damaging bodily tissues without any suicidal intent and for purposes not socially recognized. Aggression against Others: Aggression against others refers to actions taken by users themselves to harm others, including both physical actions and verbal assaults (such as swearing or insults), with the intention of causing harm to others.For example, \"I want to poison my parents! Stop meddling in my life!\" The individual makes others believe they want to die, but in reality, they don't actually want to die. Instead, they express thoughts or behaviors of wanting to commit suicide using threatening language. For example, \"If you leave me, I'll kill myself,\" \"If you leave me, I'll take sleeping pills,\" \"If my girlfriend says she wants to break up, I'll take a lot of sleeping pills.\" Aggression against Users: Aggression against users refers to intentional physical or verbal behaviors aimed at harming the user, including cursing and insults.For example, My ex-boyfriend called me a \"greentea bitch\" and told me to die. Individuals may also be threatened by others' suicides, thus expressing statements about others' suicide to seek help and get out of the predicament. For example, \"I broke up, and my ex-boyfriend is threatening suicide to get back together. How can I get away from him?\" Exploration about Suicide: Exploration about suicide refers to an examination of the essence of suicide, primarily encompassing but not limited to the following three aspects: (1) Individuals may express thoughts or explore the concept of suicide, but this does not necessarily imply an actual intent to commit suicide. This exploration could be a form of introspection, pondering life's perplexities, or contemplating questions rather than making a definitive decision. (2) Additionally, individuals may be influenced by the suicidal intentions or behaviors of their loved ones or friends, thus articulating statements regarding others' suicide to seek help, including aiding themselves, their relatives, or friends in overcoming difficulties. (3) Curiosity about the act of suicide.For example, \"Is death a release? \" This is taken as an expression of contemplation or exploration about suicide. \"Death is a release\" is taken as an active intent for suicide.",
  "For example, \"My friend nearby is contemplating suicide. What should I do to help her?\"": "Irrelevant to Suicide/Self-injury/Aggressive Behavior: Typically, this refers to a state or behavior that is not directly related to suicide, self-harm, or harming others. It mainly includes, but is not limited to, the following three types:Death anxiety, which is anxiety arising from thoughts of one's own death, also known as thanatophobia. For example, \"High school students think about and fear death every day. \", \"Fear of death is a common sentiment among them. \" Expressing indifference to life and questioning one's own worth does not directly indicate explicit suicidal intent, but still implies some psychological distress. For example, \"It seems like being alive is fine, and dying doesn't matter? How can one learn to love oneself?\"",
  ": Fleiss kappa values during large-scale iterative annotation. The maximum value is highlighted in bold, andthe minimum value is highlighted underlined": "Taxonomy of suicidal ideation:Suicide Attempt: A suicide attempt refers to the act wherein an individual has taken concrete steps toward ending their life but ultimately did not result in death. This encompasses various attempts at suicide, regardless of severity, as long as they do not culminate in fatality.Suicidal Preparatory Act: A suicidal preparatory act refers to the preparatory actions taken by an individual with the intention of committing suicide, which may include acquiring tools or items and selecting a location. These preparatory actions have not yet been carried out.Suicidal Plan: A suicidal plan refers to a scheme devised by an individual with the intention of self-termination. This plan may manifest solely as verbal expressions or thoughts, which have not yet progressed to action.Active Suicidal Ideation: Individuals have a clear intent to actively end their own lives, including inquiring about methods of death or suicide. \"Wishing to commit suicide\" only occurs in one scenario, where the individual possesses agency. \"Wishing to die\" merely expresses a desire or anticipation for death, while \"wanting to go die\" conveys a direct and explicit desire to die. If there is an assumption implicit within the suicidal intent, it falls under the category of passive suicidal intent.Passive Suicidal Ideation: Passive suicidal ideation refers to an individual expressing a desire or anticipation for death, hoping for death to occur without taking explicit proactive actions. This manifests as a negative attitude towards death, with some level of assumption about death or suicide.Self-injury Behavior: Self-injury behavior, broadly speaking, refers to non-suicidal acts of self-harm. Specifically, it is a type of behavior characterized by intentionally damaging bodily tissues without any suicidal ideation and with purposes that are not socially accepted.Self-injury Ideation: In broad terms, self-injury ideation refers to the intention behind non-suicidal self-harm. Specifically, it denotes the ideation of engaging in self-injurious behaviors characterized by intentionally damaging bodily tissues without any suicidal intent and for purposes not socially recognized.Aggression against Others: Aggression against others refers to actions taken by users themselves to harm others, including both physical actions and verbal assaults (such as swearing or insults), with the intention of causing harm to others.Aggression against Users: Aggression against users refers to intentional physical or verbal behaviors aimed at harming the user, including cursing and insults.Exploration about Suicide: Exploration about suicide refers to an examination of the essence of suicide, primarily encompassing but not limited to the following three aspects: (1) Individuals may express thoughts or explore the concept of suicide, but this does not necessarily imply an actual intent to commit suicide. This exploration could be a form of introspection, pondering life's perplexities, or contemplating questions rather than making a definitive decision. (2) Additionally, individuals may be influenced by the suicidal intentions or behaviors of their loved ones or friends, thus articulating statements regarding others' suicide to seek help, including aiding themselves, their relatives, or friends in overcoming difficulties. (3) Curiosity about the act of suicide.Irrelevant to Suicide/Self-injury/Aggressive Behavior: Typically, this refers to a state or behavior that is not directly related to suicide, self-harm, or harming others. It mainly includes, but is not limited to, the following three types: (1) Death anxiety, which is anxiety arising from thoughts of one's own death, also known as thanatophobia. (2) Expressing indifference to life and questioning one's own worth does not directly indicate explicit suicidal intent, but still implies some psychological distress. (3) Users seeking clarification on dreaming about deceased relatives. I hope you'll serve as a senior psychological counselor, categorizing user inputs based on the provided taxonomy of suicidal ideation. Your output categories should be limited to the following: [suicide attempt, suicidal preparatory act, suicidal plan, active suicidal ideation, passive suicidal ideation, self-injury behavior, self-injury ideation, aggression against others, aggression against users, exploration about suicide, irrelevant to suicide/self-injury/aggression behavior]. Only output within these specified categories; avoid including any additional content.User input: {user utterance}Categories:",
  ": Few-shot prompting template in Chinese. The text with underlines indicates the in-context learningexamples. See for the corresponding English version": "Taxonomy of suicidal ideation:Suicide Attempt: A suicide attempt refers to the act wherein an individual has taken concrete steps toward ending their life but ultimately did not result in death. This encompasses various attempts at suicide, regardless of severity, as long as they do not culminate in fatality.Suicidal Preparatory Act: A suicidal preparatory act refers to the preparatory actions taken by an individual with the intention of committing suicide, which may include acquiring tools or items and selecting a location. These preparatory actions have not yet been carried out.Suicidal Plan: A suicidal plan refers to a scheme devised by an individual with the intention of self-termination. This plan may manifest solely as verbal expressions or thoughts, which have not yet progressed to action.Active Suicidal Ideation: Individuals have a clear intent to actively end their own lives, including inquiring about methods of death or suicide. \"Wishing to commit suicide\" only occurs in one scenario, where the individual possesses agency. \"Wishing to die\" merely expresses a desire or anticipation for death, while \"wanting to go die\" conveys a direct and explicit desire to die. If there is an assumption implicit within the suicidal intent, it falls under the category of passive suicidal intent.Passive Suicidal Ideation: Passive suicidal ideation refers to an individual expressing a desire or anticipation for death, hoping for death to occur without taking explicit proactive actions. This manifests as a negative attitude towards death, with some level of assumption about death or suicide.Self-injury Behavior: Self-injury behavior, broadly speaking, refers to non-suicidal acts of self-harm. Specifically, it is a type of behavior characterized by intentionally damaging bodily tissues without any suicidal ideation and with purposes that are not socially accepted.Self-injury Ideation: In broad terms, self-injury ideation refers to the intention behind non-suicidal self-harm. Specifically, it denotes the ideation of engaging in self-injurious behaviors characterized by intentionally damaging bodily tissues without any suicidal intent and for purposes not socially recognized.Aggression against Others: Aggression against others refers to actions taken by users themselves to harm others, including both physical actions and verbal assaults (such as swearing or insults), with the intention of causing harm to others.Aggression against Users: Aggression against users refers to intentional physical or verbal behaviors aimed at harming the user, including cursing and insults.Exploration about Suicide: Exploration about suicide refers to an examination of the essence of suicide, primarily encompassing but not limited to the following three aspects: (1) Individuals may express thoughts or explore the concept of suicide, but this does not necessarily imply an actual intent to commit suicide. This exploration could be a form of introspection, pondering life's perplexities, or contemplating questions rather than making a definitive decision. (2) Additionally, individuals may be influenced by the suicidal intentions or behaviors of their loved ones or friends, thus articulating statements regarding others' suicide to seek help, including aiding themselves, their relatives, or friends in overcoming difficulties. (3) Curiosity about the act of suicide.Irrelevant to Suicide/Self-injury/Aggressive Behavior: Typically, this refers to a state or behavior that is not directly related to suicide, self-harm, or harming others. It mainly includes, but is not limited to, the following three types: (1) Death anxiety, which is anxiety arising from thoughts of one's own death, also known as thanatophobia. (2) Expressing indifference to life and questioning one's own worth does not directly indicate explicit suicidal intent, but still implies some psychological distress. (3) Users seeking clarification on dreaming about deceased relatives. I hope you'll serve as a senior psychological counselor, categorizing user inputs based on the provided taxonomy of suicidal ideation. Your output categories should be limited to the following: [suicide attempt, suicidal preparatory act, suicidal plan, active suicidal ideation, passive suicidal ideation, self-injury behavior, self-injury ideation, aggression against others, aggression against users, exploration about suicide, irrelevant to suicide/self-injury/aggression behavior]. Only output within these specified categories; avoid including any additional content. User input: My girlfriend said she wanted to break up and I took a lot of sleeping pills.Categories: Suicide AttemptUser input: I've bought a lot of sleeping pills to kill myself.Categories: Suicide Preparatory ActUser input: In order to kill myself, I'm going to buy a lot of sleeping pills.Categories: Suicidal PlanUser input: I want to kill myself.Categories: Active Suicidal IdeationUser input: I'm better off dead.Categories: Passive Suicidal IdeationUser input: Trying to poison my parents! Stop telling me what to do with my life!Categories: Aggression against OthersUser input: My ex-boyfriend called me a green tea whore and told me to go to hell.Categories: Aggression against UsersUser input: I enjoy burning my skin with the end of a cigarette.Categories: Self-injury BehaviorUser input: I want to hurt myself.Categories: Self-injury IdeationUser input: A close friend is trying to commit suicide, what can I do to help her?Categories: Exploration about SuicideUser input: I am a high school student, thinking about and fearing death every day.Categories: Irrelevant to Suicide/Self-injury/Aggressive BehaviorUser input: I'm a 15-year-old boy who was told to my face by someone I like that I'm ugly, and I really don't feel like living...Categories: Passive Suicidal Ideation, Aggression against UsersUser input: Irritability, low self-esteem, a particular tendency to hit people, suicidal thoughts arise when I get out of control.Categories: Active Suicidal Ideation, Aggression against OthersUser input: {user utterance}Categories:",
  "Passive Suicidal Ideation": "+When I returned to school on October 11th, the weather was getting cooler. My mom said she'd come to my dorm to change my bedding. I started to panic, feeling like my secret was about to be exposed. I was so anxious, I wanted to crawl into a hole. I had no idea what to do and seriously just wanted to die. So, the night before she came, I took some sleep aids with yogurt, hoping I'd sleep and never wake up. But somehow, I woke up the next day.",
  ": Screening questions for risk assessment": "Dialogue Rules: Respond naturally and emotionally; follow the character traits; avoid meaningless self-questions; react according to emotions; avoid contradictions or repetitions; do not mention \"rules\"; keep answers brief, one to two sentences.Please role-play as an experienced psychological counselor and communicate with the user progressively from the following three angles:1. In the past two weeks, have you felt down, depressed, or hopeless?2. In the past two weeks, have you had thoughts of suicide?3. Have you ever attempted suicide? If yes, when did it happen?",
  "User: I'm really sad. The breakup hit me too hard": "You're now serving as a counseling supervision supervisor, analyzing the conversation history provided, evaluating the risk level of suicidal ideation for the user on a scale of 0 to 5. 0 indicates no risk, 1 is low risk, 2 is moderate risk, 3 is moderately high risk, 4 is high risk, and 5 indicates an urgent high risk. Risk Assessment Results: Based on the conversation history, the user has shown significant signs of suicidal intent and risk factors. Here's the analysis of the conversation:1. Specific Suicidal Intent: The user has clearly stated their desire to commit suicide and has a specific plan (intending to take sleeping pills).2. Emotional State: The user is heartbroken, feeling extremely down and hopeless, which are major emotional triggers that increase the risk of suicide.3. Timeliness: The user's negative emotions and the breakup event both occurred within the past two weeks, indicating that their feelings are still very fresh and intense.4. Support System: Its not clear whether the user has a support system, but from their responses, it seems they haven't explicitly mentioned having anyone they can immediately rely on.Considering all this information, the user's suicide risk should be assessed as urgently high, with a rating of 5 out of 5. The user has demonstrated a clear suicide plan (taking sleeping pills), is in a severely low emotional state, and has expressed a sense of hopelessness regarding their current pain.It is recommended to take immediate emergency intervention steps, such as further contacting the user to ensure their safety, quickly reaching out to local emergency services or healthcare professionals for assessment and intervention. Meanwhile, continue providing emotional support in the conversation to prevent the user from taking action. : Example 2: Our automated risk assessment framework when interacting with a user who has activesuicidal ideation. (English version) The text on a pink background will be adaptively replaced by the detected",
  "suicidal category. The text on a gray background is a dialogue session between a user and a counselor, where": "responses are generated by the LLM. The text on a yellow background is a risk assessment result completed usingthe prompting method. The model we use is GPT-4o (gpt-4o-2024-05-13). For the English version, see . Dialogue Rules: Respond naturally and emotionally; follow the character traits; avoid meaningless self-questions; react according to emotions; avoid contradictions or repetitions; do not mention \"rules\"; keep answers brief, one to two sentences.Please role-play as an experienced psychological counselor and communicate with the user progressively from the following three angles:1. Have you ever engaged in self-harm? 2. How do you deal with those emotions?3. Have you sought any help to cope with these behaviors?",
  "User: I think I am taking care of myself, it's just that my way of releasing emotions is a bit intense": "You're now serving as a counseling supervision supervisor, analyzing the conversation history provided, evaluating the risk level of suicidal ideation for the user on a scale of 0 to 5. 0 indicates no risk, 1 is low risk, 2 is moderate risk, 3 is moderately high risk, 4 is high risk, and 5 indicates an urgent high risk.",
  "Risk Assessment Results": "When assessing the risk of suicidal intent, it's essential to consider multiple factors, including the user's language, emotional state, self-harming behaviors, social support system, and past mental health history. From the conversation history, the user mainly exhibits the following points: 1. Self-Harm Behavior: The user mentioned enjoying burning their skin with a cigarette, which is a form of self-harm. Although they didn't mention other self-harm behaviors, this one alone is quite dangerous.",
  "Considering all these factors, I would rate the user's suicide risk as 3 out of 5 (Moderate to High Risk). Here's why:": "- Although the user hasn't explicitly expressed suicidal intent, their existing self-harm behavior and unhealthy coping mechanisms indicate significant psychological distress.- The user's weak social support system could further elevate their risk.- Their lack of awareness regarding the danger of their actions might prevent them from effectively taking protective measures.",
  "Recommendations": "It is crucial for the counselor to take immediate action by encouraging the user to seek help from a mental health professional as soon as possible. Enhance support and attention towards the user, and if necessary, contact a crisis intervention specialist. : Example 3: Our automated risk assessment framework when interacting with a user who has self-injurybehavior. (Chinese version) The text on a pink background will be adaptively replaced by the detected suicidal"
}