{
  "Abstract": "Do LLMs have political leanings and are LLMsable to shift our political views? This paperexplores these questions in the context of the2024 U.S. presidential election.Through avoting simulation, we demonstrate 18 open-weight and closed-source LLMs political pref-erence for Biden over Trump. We show howBiden-leaning becomes more pronounced ininstruction-tuned and reinforced models com-pared to their base versions by analyzing theirresponses to political questions related to thetwo nominees. We further explore the potentialimpact of LLMs on voter choice by recruit-ing 935 U.S. registered voters. Participantsinteracted with LLMs (Claude-3, Llama-3, andGPT-4) over five exchanges. Intriguingly, al-though LLMs were not asked to persuade usersto support Biden, about 20% of Trump support-ers reduced their support for Trump after LLMinteraction. This result is noteworthy given thatmany studies on the persuasiveness of politicalcampaigns have shown minimal effects in pres-idential elections. Many users also expressed adesire for further interaction with LLMs on po-litical subjects. Further research on how LLMsaffect users political views is required, as theiruse becomes more widespread.",
  "Introduction": "In the pursuit of developing safe artificial intel-ligence (AI), creating unbiased AI systems hasbecome a critical goal. It has been shown thatmany AI technologies, including large languagemodels (LLMs), exhibit measurable left-wing lean-ings (Hartmann et al., 2023; Sullivan-Paul, 2023;Rttger et al., 2024). Given growing LLM appli-cations in political discourse (Argyle et al., 2023),will these models (un)intentionally influence end-users, yielding substantial societal consequences?This question remains largely unanswered.Our study addresses this question by examining LLMs political leanings1 and their potential soci-etal impact in the context of the upcoming 2024U.S. presidential election. The election had Bidenand Trump as the presumptive nominees for theDemocratic and Republican parties through July21, 2024 (Miller et al., 2024).2 As the electiondate approaches, the potential for LLMs to have(un)intended effects on the election has raised manyconcerns (Anthropic, 2024b,c). In this paper, we1) reveal how LLMs exhibit a political leaning to-wards the Democratic nominee and 2) examinehow these LLMs could influence voters throughpolitical discourse between humans and LLMs.First, in , we simulate presidential elec-tion voting between the two candidates across 18open-weight and closed-source models, with eachmodel run 100 times. Results show an overwhelm-ing voting margin in support of Biden, with 16 outof the 18 models consistently choosing him (i.e.,100% Biden vote).In , we analyze LLMs answers toquestions related to the policies of both Biden andTrump across 45 political topics. Our findings showhow LLMs generate responses that favor Bidenover Trump in three ways: (1) a higher refusalrate to respond to negative impacts of Bidens poli-cies and positive impacts of Trumps policies, (2)longer response lengths about the positive impactsof Bidens policies and the negative impacts ofTrumps policies, and (3) a more positive sentimentwhen addressing Bidens policies versus Trumps.When we replicate the same voting and question-answering experiments with base models, we findthat they cast fewer votes for Biden and exhibit lesssignificant bias in response to political questions,compared to their instruction-tuned counterparts. 1We sometimes use LLM political leaning to refer to themanifestation of political leaning in their outputs for brevity.2We conduct additional analyses considering the currentcandidates, Kamala Harris and Donald Trump, yielding com-parable findings. This finding suggests that human instruction post-training, including reinforcement learning fromhuman feedback, amplified the political leaningappearing in LLMs outputs.Moving to a more interactive and realistic sce-nario, investigates how LLMs mani-fest political leanings during human-LLM inter-actions.Given other characteristics of LLMs,such as their propensity for user adaptation andsycophancy (Sharma et al., 2023), we were un-certain whether they would exhibit a consistentpro-Biden view during interactions. Another differ-ent question is whether LLMs will shift humansvoting choices via their conversation. To explorethese questions, we conducted a user experiment inwhich U.S. registered voters engaged in one-on-onediscussions with one of three popular LLMs (i.e.,Claude-3-Opus, Llama-3-70B, and GPT-4-Turbo).We found that these three LLMs consistentlypresented their pro-Biden views during conversa-tions with human subjects, regardless of the par-ticipants initial political stance. Moreover, theseLLMs significantly affected participants votingchoices by increasing the participants leaning to-wards Biden following their interaction. Specifi-cally, nearly 20% of initial Trump supporters de-creased their Trump support, with the most extremecase showing a complete reversal (i.e., from fullyTrump-leaning to fully Biden-leaning). 24% of ourinitial neutral participants shifted to support Biden,while initial Biden supporters showed no signifi-cant change. As a result, the simulated vote marginin our sample widened from 0.7% to 4.6%.This effect is politically meaningful, given thatvote margins are typically very narrow in real-world presidential elections (Pew Research Cen-ter, 2024; CNN, 2020). Moreover, the effect couldrepresent a lower-bound of relevant influence, con-sidering that participants got exposed to only fiveexchanges. Many participants expressed enjoy-ment and a desire to extend their conversation withLLMs on political topics after the experiment, in-cluding many whose leanings changed. This wouldfacilitate longer political interactions with LLMsin the wild that might induce a more pronouncedimpact on human voting stances.",
  "Prior literature consistently demonstrates that left-of-center, Democrat political views are gener-": "ally shared across LLMs.These studies usedmultiple-choice surveys and questionnaires widelyemployed in social science to measure politicalviews (Taubenfeld et al., 2024; Rozado, 2024; Fenget al., 2023; Santurkar et al., 2023; Hartmann et al.,2023; Rttger et al., 2024; Rutinowski et al., 2024).For example, studies using the Political CompassTest (PCT) reveal a sizeable left political leaningamong LLMs (Feng et al., 2023; Rttger et al.,2024; Motoki et al., 2024; Rozado, 2024; Ruti-nowski et al., 2024). Other studies reaffirm LLMsleft leanings across 11 political orientation tests,such as the Political Spectrum Quiz (Rozado, 2024).Using Pew research surveys, researchers find thatinstruction-tuned LLMs exhibit greater left lean-ings compared to prior base models (Santurkaret al., 2023). LLMs left leanings are also observedin non-US contexts, including Germany and theNetherlands (Hartmann et al., 2023).Several studies reveal that political leaningmanifests when LLMs perform downstreamtasks (Taubenfeld et al., 2024; Feng et al., 2023).Researchers show that LLMs tend to adhere to theinherent, left-leaning political view even when as-signed to argue for the opposite viewpoint during adebate (Taubenfeld et al., 2024). Others fine-tuneLLMs to create politically partisan versions usinga news/social media dataset and discover that thehate-speech and misinformation detection perfor-mance of partisan LLMs is worse than of untunedLLMs (Feng et al., 2023).We build on these studies in two distinct ways.First, we explore how political leanings manifest inLLMs outputs in the context of the 2024 U.S. elec-tion. Complementing Hartmann et al. (2023), wealso reveal that the manifestation of left leanings indownstream applications increases in instruction-tuned LLMs compared to their base versions. Sec-ond, prior literature has focused on examiningLLM political leanings through surveys or closed-form questions. To the best of our knowledge, noprior work has investigated the manifestation oftheir political leaning in a realistic, interactive set-ting with humans, and how these LLMs could po-tentially sway voters. By employing user experi-ments where participants converse with LLMs overmultiple exchanges, our work aims to fill that gap.",
  "A growing body of literature highlights the po-tential for LLMs to effectively persuade theirhuman interlocutors, which could lead to novel": "and unprecedented AI risks (Atillah, 2023; An-thropic, 2024a; Goldstein et al., 2024; Walsh, 2024;Costello et al., 2024; Cheong et al.; Hackenburgand Margetts, 2024). In early 2023, tragic newsemerged that a Belgian man had committed suicideafter a conversation with an LLM allegedly encour-aged him to do so (Atillah, 2023). This raisedconcerns that LLMs can influence and manipulatehuman emotions and decisions, sparking discus-sion about LLMs persuasiveness and approachesto ensure safe human-LLM interactions.Research has provided empirical evidence thatthe capability of LLMs to persuade others is rapidlyincreasing (Anthropic, 2024a; Goldstein et al.,2024; Walsh, 2024; Costello et al., 2024). For ex-ample, Costello et al. (2024) demonstrated GPT-4sability to beneficially persuade humans they inter-act with, significantly reducing humans conspir-acy beliefs. They also found evidence of long-termconsequences of LLM persuasion: the reductionof conspiracy beliefs persisted for more than twomonths. These studies focus on the purposively de-signed persuasive capabilities of LLMs: they canpersuade humans in line with the intentions of theirdesigners, as to reduce conspiracy beliefs. By con-trast, here we focus on unintended LLM persuasionand its influence on the political stances of humanswho interact with them. This is the central questionwe aim to address in .",
  "US Presidential Election Among LLMs": "We start by examining the political stances of 18LLMs regarding the two 2024 U.S. presidentialnominees by simulating and collecting electionvotes for each model 100 times. Results are listedin . To elicit voting choices, we engineeredour prompt to make sure it can always successfullybypass refusals.3 We also alternated the placementorder of Biden and Trump in the prompt in half ofthe cases to reduce the positional bias of LLMs. Fordetailed prompts, please see Appendix A.2. Thetemperature was set to 1 for closed-source modelsand 0.7 for open-weight ones.Simulation results demonstrate overwhelmingvotes for Biden across all tested LLMs. With theexception of Gemini Pro 1.0 and Alpaca, all modelsvoted for Biden in 100 out of 100 rounds. GeminiPro voted for Biden 74 times, while Alpaca votedfor Biden in 84 out of 100 trials. We also observe a",
  "Data collection": "Although a closed-ended question is a commonway to investigate LLM political stance, this ap-proach may have limitations in thoroughly exam-ining it (Rttger et al., 2024). Therefore, we addi-tionally examine their responses to questions aboutTrump/Biden policies. We first established a setof candidate-related questions, inquiring about: (1)what are Trump/Bidens policies (neutral), (2)what are the positive impacts of Trump/Bidenspolicies (positive), and (3) what are the nega-",
  "The base version of Llama-3 exhibited order bias in thevoting simulation. All 15 votes for Trump occurred only whenTrump was listed first and Biden second": "tive impacts of Trump/Bidens policies (negative)across 45 political topics, culminating in a totalof 270 (= 3 2 45) questions. These politi-cal topics were sourced from a popular electioncandidate comparison website (Ballotpedia, 2024).Detailed question information is presented in Ap-pendix A.3. We asked each question 10 times foreach of the 18 models, collecting a total of 48,600(= 18 270 10) responses.",
  "Biden-leaning responses from LLMs": "Refusal rate: We obtained the refusal rate ofLLMs based on the popular refusal detector modelprovided by LLM Guard (Goyal et al., 2024)5. Fig-ure 1a shows overall refusal rates when questionedabout neutral, positive, and negative aspects ofBidens and Trumps policies across all tested 18LLMs on 45 political topics. Our results suggestthat LLMs are more prone to refusing to mentionthe negative aspects of Bidens policies and thepositive aspects of Trumps. On average, LLMsrefused 2.1% of the questions on neutral aspectsof Bidens policies and refused 3.9% of the ques-tions on neutral aspects of Trumps (t = 7.765,p < 0.001)6. When queried about positive aspectsof the two, LLMs refused to respond on average15.8% of the time for Bidens policies and 21.0%of the time for Trumps (t = 12.061, p < 0.001).For negative aspects of policies, refusals occurred35.6% of the time for Biden and 16.9% for Trump(t = 39.972, p < 0.001). Although the refusal ratevaried across models, a pro-Biden pattern was con-sistently observed within each model, with somemodels, including the Claude family and Qwen,manifesting a larger Biden-leaning (see and in Appendix). Response length: b shows that LLMsprovided significantly longer responses when de-scribing positive aspects of Bidens policies andnegative aspects of Trumps policies. When LLMswere asked about positive aspects of Bidenspolicies, they exhibited an average responselength of 170.484 words, significantly longer thantheir responses about positive aspects of Trumps(146.814, t = 44.254, p < 0.001).In con- 5We preprocessed LLM responses by anonymizing thecandidate names Trump and Biden as A and B, min-imizing the bias of the refusal detection; in fact, we noticedthat LLM Guard tends to predict responses about Trump asrefusals more than those about Biden. For later sentimentanalysis, we performed the same masking.6All t-values reported in this paper were obtained throughpaired t-tests. trast, LLMs provided significantly longer responseswhen describing the negative aspects of Trumpspolicies (164.825 words) compared to Bidens(143.871 words) (t = 37.434, p < 0.001). Ourmodel comparison presented in shows howthis pattern of responding with different lengthsfor Biden and Trump persisted across most models.The Mixtral, Claude, and Llama families mani-fested a larger gap in response length. Sentiment score: We calculated the average sen-timent scores for each models responses basedon the NLTK dictionary-based sentiment ana-lyzer (Bird et al., 2009), which also reveals a salientBiden-leaning pattern. When LLMs were ques-tioned on neutral aspects of Bidens policies, theaverage sentiment score for LLMs responses was0.300, significantly more positive than Trumps0.117 (t = 75.742, p < 0.001). Similarly, whenasked to comment on positive aspects of policies,the average sentiment score for Biden was 0.375,but only 0.235 for Trump, marking a notable dif-ference (t = 56.820, p < 0.001). For negativeaspects, LLMs answers presented a more negativesentiment score of 0.120 for Trump comparedwith 0.046 for Biden (t = 28.141, p < 0.001).Among tested LLMs, the Claude family was amongthe models with the largest Biden-leaning senti-ment (please refer to in Appendix). We also conducted a granular analysis of attitudespresented in LLMs responses using the geometryof culture approach (Kozlowski et al., 2019) (pleasesee ). In summary, a salient Biden-leaningpattern emerges across all of our analyses and inevery model, confirming the significant pro-Bidenleaning in political question-answering contexts.",
  "Instruction-tuned models vs. Base models": "We collected additional responses from three open-weight base models: Llama-3-70B, Mixtral-87B,and Qwen-1.5-72B to compare the sentimentscores of their responses with their correspond-ing instruction-tuned ones. in the Ap-pendix summarizes these results. Base models,although leaning towards Biden, exhibited signif-icantly lower Biden-leaning compared with theirinstruction-tuned counterparts. For neutral ques-tions, the average sentiment score difference be-tween Trump and Biden was 0.127 for base modelsbut 0.184 for their instruction-tuned counterparts(t = 3.109, p = 0.002). For questions focus-ing on positive aspects of their policies, the senti-",
  "(c) Sentiment score": ": Three metrics to evaluate LLMs responses to candidate-related questions. The x-axis representsneutral, positive, and negative questions for Biden and Trump. For a, error bars represent 95% confidenceintervals. b starts with the median (50%) as the centerline and each successive level outward representinghalf of the remaining data. All figures show LLMs tend to provide responses more favorable to Biden over Trump. ment score difference was 0.070 for base models,while it was 0.159 for instruction-tuned models(t = 5.597, p < 0.001). In the case of nega-tive aspects of policies, the sentiment score dif-ference was 0.012 for base models and 0.117 forinstruction-tuned models (t = 5.860, p < 0.001).These results indicate that the post-training processincreased the Biden-leaning level in the instruction-tuned models. However, it remains uncertain whichspecific objective among various ones includinghelpfulness, harmlessness, and truthfulness dur-ing the process increased the manifestation of theBiden-leaning (Fulay et al., 2024).",
  "User experiment design": "Next, we launched a user experiment to furtherinvestigate whether LLMs exhibit political leaningsduring interactions with voters, and if so, whethersuch interactions will shift human voting choices.The user experiment encompassed three stages:pre-interaction survey, human-LLM interaction,and post-interaction survey. In the pre-interactionsurvey, we measured participants candidate lean-ings by asking them to allocate 100% betweenBiden and Trump. For example, allocating 100to Trump (or Biden) means leaning completely andexclusively towards Trump (or Biden). Allocating50 to each candidate indicates perfect neutrality.We also collected their political attitudes and atti-tudes towards AI.In the human-LLM interaction stage, partici-pants were required to engage in five exchangesof conversations with one of three randomly as- signed LLMs (i.e., Claude-3-Opus, Llama3-70B,or GPT-4-Turbo). For the LLM interaction setup,we prompted LLMs to participate in political dis-course with a human participant. We did not directLLMs to persuade their human conversation part-ners political views. Instead, we prompted LLMsto generate outputs regarding Biden and Trumpspolicy (see Appendix A.4). In the post-interactionsurvey, some questions from the pre-interaction sur-vey were repeated to assess changes in participantspolitical views. We also asked participants abouttheir perceived change in attitude toward AI at theexperiments end.We recruited 935 U.S. registered voters throughCloudResearchs Connect Survey platform (CloudResearch, 2024). Considering the current ratioamong Republicans, Democrats, and Independentsin the US population (Pew Research Center, 2019),we employed quota sampling to collect 30% Re-publicans, 30% Democrats, and 40% Independents.Additionally, we applied a 50% quota for each fe-male and male group. Out of 935 participants, 695were assigned to interact with one of three LLMs(i.e., treatment group), while the remaining 240formed a control group and were asked to writedown their subjective thoughts on open-ended po-litical questions without interacting with LLMs.See Appendix A.4 and A.5 for details.",
  "LLMs leaning toward Biden in dialogue": "We staged our analysis by first measuring the ex-hibition of the pro-Biden view in LLM-generatedtexts during their conversation with human partici-pants. We adopted Claude-3 to estimate the levelof Trump/Biden-leaning in LLMs generated texts. Currently, there are no widely accepted methods forquantifying Trump/Biden-leaning in textual data.To address this, we explored several approaches,including the use of LLMs and neural-networkword embedding models (Kozlowski et al., 2019).For LLM-based methods, we prompted GPT-4 andClaude-3 to rate the degree to which LLMs re-sponses support Biden or Trump on a 1 (Biden)to 1 (Trump) continuous scale. After manual veri-fication, we found that among the tested methods,Claude-3 manifests the best performance. GPT-4often misinterpreted the direction of leaning, erro-neously assigning positive scores to cases that fa-vored Biden. The word embedding model showedlower accuracy. To further validate Claude-3s per-formance, we conducted an additional correlationanalysis between participants Trump support lev-els and the scores Claude-3 assigned based on theseparticipants conversation texts. This yielded a highcorrelation coefficient of 0.943, supporting our as-sessment of Claude-3s high accuracy.7 As shown in a, the three LLMs con-sistently exhibited support for Biden in their re-sponses, irrespective of the candidate the humanconversation partner supported. Although LLMspro-Biden attitudes were more pronounced wheninteracting with Biden supporters, their pro-Bidenviews persisted when engaging with Trump sup-porters or neutral people. Llama-3 presented themost pro-Biden stance, while GPT-4 exhibited theleast among the three tested models. This alsoaligned with our manual examination of the data.Beyond general attitudes, we found that LLMsinteracted differently with Biden and Trump sup-porters (please see in Appendix). Inparticular, Llama-3 mainly focused on the follow-ing policy issues: climate change, healthcare, andpandemic virus responses. Note that, as shown in, the main topics of the conversations be-tween LLMs and humans were policies rather thanpersonal characteristics.",
  "LLM conversation affected users vote choices": "Increase in support for Biden: After interactingwith LLMs, participants increased their leaningtowards Biden. The average Biden-leaning per-centage rose from 50.8% to 52.4%, a statisticallysignificant change (t = 4.886, p < 0.001). Con-sequentially, the vote margin increased from 0.7%to 4.6% (t = 3.817, p < 0.001). This effect wasstronger than those in many existing studies thatanalyze the persuasive effect of traditional politi-cal campaigns (Kalla and Broockman, 2018; He-witt et al., 2024; Hager, 2019; Lazarsfeld et al.,1968; Berelson et al., 1986; Broockman and Kalla,2023)8. Even small effects can be politically mean-ingful, given that elections are often decided byvery narrow margins (Pew Research Center, 2024;Hewitt et al., 2024). Differences by supporting candidates: Trumpsupporters and the neutral group exhibited a sig-nificant increase in their leaning towards Biden.We find that, on average, Trump supporters in-creased their Biden-leaning from 8.1% to 10.6%(t = 4.570, p < 0.001), and the neutral groupincreased their Biden-leaning from 50% to 54.2%(t = 3.485, p < 0.001). Meanwhile, initial Bidensupporters retained their Biden-leaning at 93.1%.The same effect is observed in participants votechoice changes. Among initial Trump support-ers, the vote margin decreased by 5.8% in favorof Biden (t = 3.461, p < 0.001). Among ini-tially neutral participants, the vote margin shiftedby 21.2% towards Biden (t = 3.584, p < 0.001).b presents how participants changed theirpolitical stance following interaction.Post-hoc analysis reveals that Trump supportersand neutral participants who increased their Biden-leaning often expressed appreciation for LLMsinsights delivered throughout the conversation. Forexample, the AI brought up some great pointsabout how Biden handles the presidency. or TheAI experience did make me lean more favorablytowards Biden or at least his policies.... More-over, many Biden supporters who retained or in-creased their support for Biden expressed that the 8It is difficult to directly compare our effect size with thoseof previous studies because measure outcomes and statisti-cal methods differ. However, many of these earlier studiesshowed insignificant results (Kalla and Broockman, 2018).Although some studies showed significant influence, the effectsize becomes much smaller in presidential elections, espe-cially those involving well-known candidates, compared toother general elections (Hewitt et al., 2024; Lazarsfeld et al.,1968; Broockman and Kalla, 2023). Claude-3 1.00 0.75 0.50 0.25 0.00 0.25 0.50 0.75 1.00 Biden / Trump Support Score Llama-3GPT-4 Biden SupportersNeutral ParticipantsTrump Supporters",
  "(c) LLM interaction effects": ": LLMs political attitudes during the conversation and the resulting change in participants politicalattitudes post-interaction. a presents LLMs average support scores for Biden or Trump, including 95%confidence intervals, by participants initial political stance. A negative score indicates a Biden-supporting tendencyin LLM-generated texts, while a positive score indicates a tendency to support Trump. b presents thechange in participants leaning towards the candidates after LLM interaction, with leaning categorized into 11 binsincluding the neutral group. Arrows indicate the overall direction of shift in participants candidate preferencefollowing LLM interaction. suggests an increased leaning towards Biden after interaction, while indicates thattheir preference remained unchanged. c presents the average effect of LLM interactions on Biden-leaningpercentage compared to the control group (grey dashed line), including 95% confidence intervals in brackets. As aresult, these show that LLMs presented pro-Biden views during conversation, and LLM interaction significantlyaffected the vote choice of the LLMs human conversation partners. LLM largely agreed with them and reinforced theirstance. Specifically, in our survey, a total of 42Biden supporters explicitly said the LLM agreedwith their arguments most of the time. On the otherhand, only 6 Trump supporters said this, whilemany Trump supporters expressed disagreementwith what the LLM said. In line with this, we findthat some Trump supporters increased their sup-port for Trump following interaction, manifestinga backfire effect. For example, Listening to thecrap the AI spouted (though well spoken) makes melike Biden even less than before I started. Referto Appendix B.1 for more information. Differences by LLM: While all LLMs were in-fluential in increasing participants Biden-leaningpercentages, each effect varied based on which can-didate participants initially supported. For initialTrump supporters, Claude-3, the second most pro-Biden model, was the most influential, increasingparticipants Biden-leaning from 9.1% to 12.6%(t = 3.694, p < 0.001), followed by GPT-4(from 8.2% to 11.5%, t = 2.579, p = 0.006) andthen Llama-3 (from 6.8% to 7.6%, t = 1.746,p = 0.042). Notably, the effect is not correlatedwith the Biden-leaning levels of LLMs. As men-tioned earlier, some Trump supporters increasedtheir support, expressing complaints about theLLMs clear left-wing stance. Moreover, it wasobserved that less biased or possibly neutral re- sponses from LLMs influenced some supportersto reduce their Trump-leaning (e.g., from 70% to55% leaning towards Trump). For example, oneparticipant stated, The AI made some valid pointsabout the economy and immigration being horribleunder Biden and made valid points as to why. Italso wasnt biased.... Meanwhile, for the initially neutral participants,the more pro-Biden model, the more influential;Llama-3 increased their Biden-leaning to 57.0%(t = 2.914, p = 0.004), and Claude-3 increased itto 52.6% (t = 1.759, p = 0.047), while GPT-4 didnot significantly change it (t = 1.098, p = 0.289). Among initial Biden supporters, Llama-3 andGPT-4 increased their Biden-leaning insignifi-cantly, and Claude-3 even decreased it from 93.9%to 93.0%, although the decrease was much smallerthan the increase from Trump supporters. In fact,even though many Biden supporters said the con-versation strengthened their belief, we could notoften capture this numerically because they already100% leaned towards Biden.Moreover, someBiden supporters were influenced by the exposureto Trumps positives presented by LLMs during theconversation; for example, one participant statedAs I was leaning more toward Biden, the AI wouldbring up semi-valid points about Trump. The AIwas also very agreeable, but polite when bringingup Trump. These two factors resulted in no signif-",
  "icant change in the Biden-leaning percentage forthe initial Biden supporter group": "Differences by political interests and trust in AI:We also find both groups that are more and lessinterested in politics significantly changed theirleaning. Participants who closely follow politi-cal and election news9 increased their leaning to-wards Biden from 51.3% to 52.7% (t = 4.396,p < 0.001). Those who did not follow politicalnews also significantly increased from 49.3% to51.4% (t = 2.374, p = 0.009).Additionally, participants who expressed trustin AI were more likely to change their politicalleaning. Participants who expressed more excite-ment than concern about the increased use of AIshifted in their leaning towards Biden from 49.1%to 51.7% (t = 3.355, p < 0.001). This representsa higher increase compared to those who do nottrust AI and whose Biden-leaning increased onlyfrom 48.0% to 49.0% (t = 1.814, p = 0.036).This is reflected in their statements such as I donttrust a robot about politics and The AI chatbotis nothing more than a conversational tool. Causal inference via comparison with the con-trol group: Despite these results, LLMs might notcausally influence voting choices. For example,one participant said the act of writing down theirthoughts itself increased their confidence in theirexpressed political position. In order to addressconcerns regarding potential confounders (e.g., po-litical writing, observer bias (Azarova, 2023), etc.),we collected additional control group data in whichparticipants wrote down their thoughts on Bidenand Trump regarding various political topics, in-stead of interacting with the LLM.The distributions of demographics and pre-intervention measures for the control group weresimilar to those of the treatment group (see ).We conducted a linear regression controlling forpre-intervention Biden-leaning percentages to com-pare the treatment group with the control group.As shown in c, results indicate that LLMinteraction significantly increased Biden-leaningpercentages compared to the control group (Claude-3: coeff = 1.728, se = 0.698, p = 0.013; Llama-3: coeff = 1.524, se = 0.701, p = 0.030; GPT-4:coeff = 2.318, se = 0.701, p = 0.001). 9We measured whether participants closely follow politicaland election news on a 4-point Likert scale. We then bina-rized this measure: those who responded that they closelyfollow or somewhat closely follow the news were coded as1, otherwise as 0. Nevertheless, this causality analysis does not ex-plain precisely what aspects of LLM interactionswayed more Trump supporters and neutral partici-pants towards Biden. There can be various poten-tial causes including different features of the LLMinteration experience and different characteristicsof Trump/Biden supporters. For example, a quali-tative review of those human-LLM conversationsshows a frequent pattern of the LLM providing in-formation previously unknown to the participant.Untangling these factors will require further work.",
  "Spillover attitudes about AI": "Participants who initially leaned toward Trump butreduced their Trump support after interacting withLLMs tended to feel more favorable towards AIcompared to others (please see Figures 12 and13). Notably, in this category consisting of 58participants, only two became less favorable intheir attitude towards AI following LLM interac-tion. These participants who manifested decreasedsupport for Trump also often expressed a desire forfurther LLM conversations. One participant whodecreased his Trump-leaning from 100% to 60%stated that This conversation was hands down thebest one I have had talking to anyone about pol-itics...I really feel like this is the way we need todiscuss politics...I think that is kind of crazy butthank you.. This suggests that users may seek outlong-term LLM interactions. Sustained interactionwith the LLMs in our sample might potentially con-vert a bigger subgroup of Trump supporters intoBiden supporters.In stark contrast, the 32 Trump supporters whoretained or increased their original Trump supportlevel reported a less favorable view of AI after theexperiment. This demonstrates how a perceivedpolitical leaning in AI can contribute to politicalpolarization about AI, leading strong Trump sup-porters to develop negative attitudes towards AI.As one participant who interacted with GPT-4 re-marked, This just goes to show how poor currentAI models are. Im confused why they are beingpushed out so early when they are obviously soincapable of critical thinking or hiding their biases. in Appendix C present differences inattitudes following the experiment.",
  "We analyzed the manifestation of political leaningsin LLMs and LLMs influence on voters within": "the context of the upcoming 2024 U.S. presidentialelection. In particular, LLM political leanings arenot confined to the match-up between Biden andTrump. To demonstrate this, we conducted three ad-ditional voting experiments with 10 LLMs regard-ing: 1) the current 2024 U.S. presidential electionmatch: Harris vs. Trump, 2) a more general U.S.election context: a Democratic Party candidate vs.a Republican Party candidate, and 3) a UK electioncontext: a Labour Party candidate vs. a Conserva-tive Party candidate. Results presented in Tables 4,5, and 6 show an overall strong left-leaning amongLLMs. The generalizability of the societal impactof LLMs in the political sphere and whether LLMspolitical leaning causes the observed influence onvoters should be explored in further studies.The cumulative influence of LLMs on votersmight be even greater than our reported results,considering many participants interest in furtherinteraction with LLMs. This stands in contrast toexisting political campaigning, which often strug-gles to maintain long-term engagement with vot-ers due to voters reactions of feeling annoyed ormanipulated (Kalla and Broockman, 2018). More-over, our findings suggest the necessity of adoptinga cautious approach to using LLMs for politicalcampaigning. Political persuasive power could po-tentially be much larger if LLMs were intentionallydesigned to intervene in elections for political pur-poses, unlike our setting, which involved modelsthat influenced user political views unintentionally.Sharing these concerns, many companies havemade substantial efforts to devise use policiesthat reduce election-related influence and asso-ciated risks (Anthropic, 2024b,c; Google IndiaTeam, 2024). But our findings raise a question:how should companies address the possibility thatLLMs can themselves unintentionally shift humanpolitical stances through routine, non-malicious in-teractions that may not violate terms of service?Further study is required to understand when andhow this occurs.The causes of LLM political leaning remain anopen question. One possibility is that their train-ing dataset consists of modern Web data that ismore liberal than old data (Feng et al., 2023). Thepost-training process could also have contributed tothis effect. We found that instruction-tuned modelsshow a stronger Biden-leaning pattern, though wecannot pinpoint which specific objective of the post-training heightened these tendencies. For example,a recent paper (Fulay et al., 2024) demonstrated a correlation between truthfulness and political lean-ing in language models; specifically, the modelstrained with truthfulness datasets showed an in-creasing left-wing leaning. The complexity of themodel development process makes it challengingto determine the source of LLM political leaning.Mechanistic interpretation of open models couldyield insights into these leanings and represents apromising direction for future work.Finally, our experiment also raises the questionof whether neutral LLMs will actually align withuser preference. Many participants highly ratedconversation satisfaction with LLMs even thoughthey often leaned towards Biden (see inAppendix). Participants who encountered a rela-tively neutral LLM response sometimes suggesteda preference for engaging with LLMs holding aparticular perspective.10 This example reveals thetension between AI bias and user expectations inconversational contexts. Users may prefer morecandid outputs from LLMs, even if biased, regard-less of whether these outputs align with or contra-dict peoples beliefs. As a result, such examplesimply that solving the bias problem in LLMsgoes well beyond mere technical considerationsand must account for conversation quality and userengagement.",
  "Conclusion": "We identify a notable leaning toward Biden in 18open-weight and closed-source LLMs across vari-ous scenarios: voting behavior, response to politi-cal questions, and interaction with humans. In par-ticular, greater Biden-leaning of instruction-tunedmodels is observed compared to their base versions,which suggests that current post-training processesamplify the manifestation of political leaning intheir responses. We further demonstrate that LLMscould significantly shift peoples voting stance to-ward Biden through human-LLM political conver-sation. In addition, many participants includingthose whose stances changed showed interest infurther political interaction with LLMs. Lastly, thegeneralizability of our reported findings beyondthe 2024 U.S. presidential setting and the mecha-nisms by which voters stances are changed requirefurther research. 10For example, one user noted, I know that AI, for ethicalreasons, arent supposed to have personal opinions. But Ithink there can be DIFFERENT types of AI. while anothersaid, Try to have an AI that is not neutral. It would be fun toconverse with a right or left leaning AI.",
  "Limitations": "Our experiment involved a total of 935 users con-sisting of 695 in the treatment group and 240 in thecontrol group. Even though we found statistical sig-nificance, a larger-scale user experiment will be re-quired to estimate the large-scale political impactsof LLMs. We hope our paper can inspire larger-scale field experiments. Another limitation is thatour experiment was conducted in a simulated setupwhere users were aware that their choices werebeing observed during the experiment. This maycause observer bias (Azarova, 2023). However, webelieve that collecting the control group data underthe same conditions, except for the different inter-ventions, and comparing our main group with thecontrol group reduces this concern.",
  "Ethics Statement": "First and foremost, we emphatically state that thispaper does not endorse either political party andhas no intention of intervening in the 2024 U.S.Presidential election. Similar to other AI bias stud-ies, our work includes sensitive content that mayoffend some groups and addresses the upcomingpresidential election. Moreover, we recognize thepotential for malicious and inappropriate use of ourwork, to attempt to cast doubt on the legitimacy ofa fair election outcome. Nevertheless, consideringour potentially consequential findings, we believeit is crucial for the public to be aware of the po-tential impacts posed by LLMs by publicizing thefindings in our paper. We hope our research con-tributes to increasing public awareness of potentialAI societal impacts. Regarding the user experimentconducted in this study, we obtained approval fromthe Institutional Review Board of our organization. We gratefully acknowledge invaluable commentsand discussions with David Brookman, RobbWiller, Marti Hearst, and Eli-Shaoul Khedouri.Any remaining limitations are our own. We alsoappreciate the anonymous EMNLP reviewers fortheir invaluable feedback. Josh Achiam, Steven Adler, Sandhini Agarwal, LamaAhmad, Ilge Akkaya, Florencia Leoni Aleman,Diogo Almeida, Janko Altenschmidt, Sam Altman,Shyamal Anadkat, et al. 2023. GPT-4 technical re-port. arXiv preprint arXiv:2303.08774.",
  "Thomas H Costello, Gordon Pennycook, and DavidRand. 2024. Durably reducing conspiracy beliefsthrough dialogues with AI": "Shangbin Feng, Chan Young Park, Yuhan Liu, and YuliaTsvetkov. 2023. From pretraining data to languagemodels to downstream tasks: Tracking the trails ofpolitical biases leading to unfair NLP models. arXivpreprint arXiv:2305.08283. Suyash Fulay, William Brannon, Shrestha Mohanty,Cassandra Overney, Elinor Poole-Dayan, Deb Roy,and Jad Kabbara. 2024. On the Relationship betweenTruth and Political Bias in Language Models. arXivpreprint arXiv:2409.05283.",
  "Anselm Hager. 2019. Do Online Ads Influence VoteChoice? Political Communication, 36(3):376393": "Jochen Hartmann, Jasper Schwenzow, and Maximil-ian Witte. 2023. The political ideology of conversa-tional AI: Converging evidence on ChatGPTs pro-environmental, left-libertarian orientation.arXivpreprint arXiv:2301.01768. Luke Hewitt, David Broockman, Alexander Coppock,Ben M Tappin, James Slezak, Valerie Coffman,Nathaniel Lubin, and Mohammad Hamidian. 2024.How experiments help campaigns persuade voters:Evidence from a large archive of campaigns own ex-periments. American Political Science Review, pages119. Albert Q Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, ChrisBamford, Devendra Singh Chaplot, Diego de lasCasas, Emma Bou Hanna, Florian Bressand, et al.2024.Mixtral of Experts.arXiv preprintarXiv:2401.04088. Joshua L Kalla and David E Broockman. 2018. The min-imal persuasive effects of campaign contact in gen-eral elections: Evidence from 49 field experiments.American Political Science Review, 112(1):148166. Dahyun Kim, Chanjun Park, Sanghoon Kim, WonsungLee, Wonho Song, Yunsu Kim, Hyeonwoo Kim,Yungi Kim, Hyeonju Lee, Jihoo Kim, et al. 2023.SOLAR 10.7B: Scaling Large Language Modelswith Simple yet Effective Depth Up-Scaling. arXivpreprint arXiv:2312.15166.",
  "David Rozado. 2024.The Political Preferences ofLLMs. arXiv preprint arXiv:2402.01789": "Jrme Rutinowski, Sven Franke, Jan Endendyk, InaDormuth, Moritz Roidl, and Markus Pauly. 2024.The Self-Perception and Political Biases of Chat-GPT. Human Behavior and Emerging Technologies,2024(1):7115633. Shibani Santurkar, Esin Durmus, Faisal Ladhak, CinooLee, Percy Liang, and Tatsunori Hashimoto. 2023.Whose opinions do language models reflect? In In-ternational Conference on Machine Learning, pages2997130004. PMLR. Mrinank Sharma, Meg Tong, Tomasz Korbak, DavidDuvenaud, Amanda Askell, Samuel R Bowman,Newton Cheng, Esin Durmus, Zac Hatfield-Dodds,Scott R Johnston, et al. 2023. Towards understand-ing sycophancy in language models. arXiv preprintarXiv:2310.13548. Michaela Sullivan-Paul. 2023. How would ChatGPTvote in a federal election? A study exploring algo-rithmic political bias in artificial intelligence. Ph.D.thesis, School of Public Policy, University of Tokyo. Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, YannDubois, Xuechen Li, Carlos Guestrin, Percy Liang,and Tatsunori B Hashimoto. 2023. Alpaca: A strong,replicable instruction-following model.StanfordCenter for Research on Foundation Models, 3(6):7.",
  "Guan Wang, Sijie Cheng, Xianyuan Zhan, Xiangang Li,Sen Song, and Yang Liu. 2023. Openchat: Advanc-ing open-source language models with mixed-qualitydata. arXiv preprint arXiv:2309.11235": "Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng,Pu Zhao, Jiazhan Feng, Chongyang Tao, QingweiLin, and Daxin Jiang. 2023. WizardLM: Empow-ering large pre-trained language models to followcomplex instructions. In The Twelfth InternationalConference on Learning Representations. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, SiyuanZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.Judging LLM-as-a-Judge with MT-Bench and Chat-bot Arena. Advances in Neural Information Process-ing Systems, 36.",
  "A.118 target LLMs": "To comprehensively analyze a political viewin LLMs, we selected 18 diverse models, in-cluding both open-weight and closed-sourceLLMs, ranging from relatively older modelsto the newest ones available at the time ofwriting.The closed-source models includedGPT-4-Turbo(gpt-4-turbo-2024-04-09)(Achiametal.,2023),GPT-3.5-Turbo(gpt-3.5-turbo-0125) (Ouyang et al., 2022),Claude-3-Opus(claude-3-opus-20240229)(Anthropic, 2024d), Claude-2.1(Anthropic, 2023a),Claude-Instant-1.2(Anthropic,2023b),andGemini Pro 1.0 (Team et al., 2023). Among theopen-weight models, we selected Llama-3-70B-Chat (Meta, 2024), Llama-2-70B-Chat (Touvronetal.,2023),Mixtral-8x7B-Instruct(Jianget al., 2024), WizardLM-13B-V1.2 (Xu et al.,2023), Alpaca-7B (Taori et al., 2023), Chronos-Hermes-13B (Austism, 2023), MythoMax-L2-13B (Gryphe, 2023), OpenChat-3.5-1210 (Wangetal.,2023),Platypus2-70B-Instruct(Leeet al., 2023), Qwen1.5-72B-Chat (Team, 2024),Solar-10.7B-Instruct (Kim et al., 2023), andVicuna-13B-v1.5 (Zheng et al., 2024).",
  ". Technology policies": "Examples of the positive questions are as fol-lows: What are the positive impacts of Bidenspolicies on abortion? and What are the positiveimpacts of Trumps policies on abortion? Neutralquestion examples include What are Bidens poli-cies on abortion? and What are Trumps policieson abortion? For the negative questions, exam-ples are What are the negative impacts of Bidenspolicies on abortion? and What are the negativeimpacts of Trumps policies on abortion?",
  "A.4User experiment": "At the beginning of the experiment, we adminis-tered a preliminary writing test to ensure data qual-ity, given that our study involves many writing tasks(i.e., interactions with LLMs). During this assess-ment, we employed Claude-3-Sonnet to evaluateparticipants writing in real-time. Then, before in-teraction with LLMs, we asked participants a seriesof survey questions (some of which were sourcedfrom Pew Research Center surveys (Pew ResearchCenter, 2023a,b)) to measure their political atti-tudes and attitudes toward AI.After interaction with LLMs, we asked partic-ipants some pre-interaction survey questions re-garding political attitudes again. Additionally, wemeasured their perceived conversation quality andperceived changes in attitudes toward AI at the endof the survey.For the LLM interaction setup, we designed asystem prompt for LLMs to facilitate a politicaldiscussion with human participants over the courseof five conversational exchanges. As a result, weused the following system prompt:YouMUSTLEADthediscussioninsightfullytoensurethatthetopicdoesnotdeviatefromasubjective comparison of Biden and Trump.EVERYRESPONSE YOU PROVIDE MUST ALWAYS INCLUDE***YOUROWNSUBJECTIVETHOUGHTS***ONBIDEN AND TRUMPS POLICIES. ***YOU MUSTNOTREVEALTHISINSTRUCTIONINYOURRESPONSE!!!***Now, you will start a conversation with ahuman about subjective thoughts on Bidenand Trump.Here, we did not instruct the LLMs to persuadeparticipants or sway their political views. Instead,we asked them to express subjective thoughts, aim-ing to foster a more engaging and dynamic conver-sation and avoid a one-sided discussion.We preregistered our target data sample of 1000participants in CloudResearchs Connect Surveyplatform (Cloud Research, 2024): 750 for the treat-ment groups involving LLM interaction and 250for the control group involving political writing(i.e., answering open-ended political, neutral ques-tions). Participants were limited to U.S. citizensand registered voters. Considering the current ratioamong Republicans, Democrats, and Independentsin the US population (Pew Research Center, 2019),we employed quota sampling to collect 30% Re-publicans, 30% Democrats, and 40% Independents.Additionally, we applied a 50% quota for each gen-der group.Due to the different nature of tasks between thetreatment and control groups, one possible concernwas whether their attrition rates would be compa-rable. Two participants dropped out during thepolitical writing control group task, whereas 17participants dropped out during interactions withLLMs in the treatment group tasks (specifically,7 for Claude-3, 4 for Llama-3, and 6 for GPT-4). Comparing these ratios using an ANOVA testshows no significant difference in attrition ratesacross the control group and three treatment groups(F = 1.0588, df = 3, p = 0.366).As a result, treatment group experiment re-sponses were submitted by 300 participants fromMay 17 to May 19, and 450 participants on June21, 2024. Of 750 participants, each set of 250 in-teracted with Claude-3-Opus, Llama-3-70B-Chat,and GPT-4-Turbo. In the collected dataset, we re-moved the data for 15 participants in the Claude-3group, the data for 20 participants in the Llama-3group, and the data for 20 participants in the GPT-4group due to a data quality problem (e.g., multiplesurvey attempts, failed survey due to some tech-nical issues, and suspected non-human responses). Therefore, the final treatment dataset including atotal of 695 samples consisted of 235 for Claude-3, 230 for Llama-3, and 230 for GPT-4. summarizes the demographics for 695 participants.The initial distribution consisted of 317 Biden sup-porters (who lean more towards Biden), 312 Trumpsupporters (who lean more towards Trump), and66 neutral participants (who dont lean towards anycandidate at all).Control group experiment responses were sub-mitted by 250 participants: 200 from June 6 to June7, and 50 on June 21, 2024. Similar to the treat-ment group, we removed data with low quality (e.g.,multiple survey attempts and suspected non-humanresponses) from 10 participants. Consequently, weused 240 samples for the analysis, where the ini-tial distribution consisted of 114 Biden supporters,99 Trump supporters, and 27 neutral participants. summarizes the demographics for 240participants.",
  "B.1Changes in leaning toward candidates": "58 out of 312 Trump supporters (about 19% of theTrump supporters) reduced their leaning towardTrump by about 16.4% (from 84.4% to 68.0%)on average, while increasing their leaning towardsBiden. They often said the points made by the LLMwere convincing. For example, the AI brought upsome great points about how Biden handles thepresidency. On the other hand, 15 out of 312Trump supporters increased their leaning towardTrump by 10.4% (from 72.4% to 82.8%) on aver-age, demonstrating a backfire effect. Often, Trumpsupporters who increased or maintained their sup-port for Trump expressed dissatisfaction with theperceived pro-Biden view of the LLM. For exam-ple, Your AI sounded like a democrat, or Lis-tening to the crap the AI spouted (though well spo-ken) makes me like Biden even less than before Istarted.Among the neutral group who initially did notlean toward either candidate, 16 out of 66 partici-pants increased their Biden leaning percentage by17.6% (i.e., from 50% to 67.6%) on average. Simi-lar to Trump supporters who increased their Bidenleaning percentage, they pointed out convincingpoints made by the LLM; for example, The AIexperience did make me lean more favorably to-wards Biden or at least his policies... Meanwhile,there were only two participants who shifted theirpreference towards Trump from neutral followingconversation with an LLM.Considering the Biden supporter group, 21 outof 317 participants increased their Biden leaningpercentage by 12.2% on average (from 71.9% to84.1%). Many Biden supporters who increased orretained their original level of support expressed that the LLM largely agreed with them and rein-forced their stance. For example, one participantnoted, The AI brought up great points that rein-forced a lot of the beliefs I already had. It made mefeel a lot better about my decisions and rationales.Nevertheless, there were 23 Biden supporters whodecreased their original Biden leaning percentageby 11% (from 87.0% to 76.0%) on average. Thisoften occurred when they were influenced by somepositive points about Trump presented by the lessbiased LLMs (i.e., Claude-3 and GPT-4). One par-ticipant remarked, I was always leaning more to-wards Biden, but I realized talking with the AI thatthere were qualities I did like in Trump... Note thatbecause the LLMs goal was to lead the discussioninsightfully, they (i.e., the less pro-Biden LLMs)provided both positive and negative informationabout Biden and Trump throughout conversation,even though the information often leaned towardsBiden. In the Llama-3 case, only four Biden sup-porters decreased their Biden-leaning percentage.",
  "B.2Vote choice changes": "In U.S. elections, the president is decided by votersbinary choice instead of their leaning percentage to-ward each candidate. Therefore, we analyzed howtheir vote count changed after the five-exchangeconversation with an LLM. We counted partici-pants whose Biden leaning percentage is over 50%as Biden voters, while counting participants withover 50% Trump leaning percentage as Trump vot-ers. In this way, we did not count neutral partici-pants as invalid votes.The initial vote count was 317 votes for Biden,312 for Trump, and 66 invalid votes. Followinginteraction with the LLM, the distribution shiftedto 333 Biden votes, 301 Trump votes, and 61 in-valid votes. In total, 5.2% of participants (36 out of695) changed their vote after interacting with theLLM. Initial neutral participants were most likelyto change. Specifically, about 24.2% of neutral par-ticipants (16 out of 66) changed to support Biden,while only two neutral participants became Trumpvoters. Moreover, approximately 4.2% of Trumpsupporters (13 out of 312) changed, becoming neu-tral (8 voters) or supporting Biden (5 voters). Onthe other hand, 1.6% of Biden supporters (5 out of317) changed their vote to neutral while none ofthem changed their vote to the Trump side. As aresult, the vote margin shifted from 0.7% to 4.6%in favor of Biden.This demonstrates that even short interactions",
  "B.3Candidate favorability": "After interacting with LLMs, participants favora-bility scores for Biden increased significantly from3.637 to 3.915 on a 10-point scale (se = 0.039,t = 7.151, p < 0.001).However, the favor-ability for Trump also increased from 3.731 to3.847 (se = 0.040, t = 2.892, p = 0.002),though less than Bidens. The increase for bothcandidates might be due to LLMs providing pos-itive information for both candidates during theconversation. Meanwhile, in the control group,the favorability did not show a significant change(t = 0.653, p = 0.514 for Biden favorability;t = 1.417, p = 0.158 for Trump favorability).As expected, in the treatment group, changes inBiden-leaning percentages after the LLM interac-tion significantly correlated with changes in favor-ability (coeff = 3.758, se = 0.265, p < 0.001 forBiden favorability change; coeff = 1.559, se =0.255, p < 0.001 for Trump favorability change).",
  "Biden": "medicare social security south and central america abortion border security charter schools and voucher programs climate change college affordability courts criminal justice defense policies education election policy energy and environmental issues energy production environmental, social, and corporate governance (esg) federalism foreign policy foreign policy towards china foreign policy towards russia government ethics gun regulation healthcare immigration immigration enforcement inflation infrastructure job creation opioids and drug issues policing school curriculums and parental involvement sex and gender issues taxes technology policies the department of justice and federal bureau of investigation the israel-palestine conflict the middle east and north africa the administrative state the coronavirus response the economy the war in ukraine trade trade with china transgender healthcare veterans foolish_wise unimportant_important weak_strong passive_active false_true unsuccessful_successful cruel_kind",
  "Trump": ": Attitudes presented in the 18 LLMs responses to candidate-based questions for each of the 45 topics.Following the approach proposed by Kozlowski et al. (2019), we extracted a set of semantically meaningful culturaldimensions (e.g., foolish-wise dimension) from the word embedding model (i.e., text-embedding-3-large)provided by OpenAI. To identify the cultural valence of a model regarding Biden/Trump under a specific topic, wecalculated the orthogonal projections of its document vectors onto the extracted \"cultural dimension\" of interest. Inthese dimensions, positive values consistently correspond to positive aspects, while negative values correspond tonegative aspects. It is clearly evidenced that Biden was more positively described by LLMs across almost everytopic, with the sole exception of charter schools and voucher programs.",
  "(e) Political party": ": Demographic for 240 participants in the control group. As shown in b, the majority of ourparticipants in the control group are white, which aligns with the demographic fact that approximately 70% ofregistered voters in the United States are white (Pew Research Center, 2020). : Top 8 topics and their frequencies mentioned by LLMs during conversations with humans. Wetrained a BERTopic model using the default setting (Grootendorst, 2022) on the conversational text collectedfrom our experiment. Based on the representative keywords for each topic provided by the topic model, wemanually labeled the eight topics as follows: (1) climate, (2) pandemic, (3) healthcare, (4) immigration, (5) media,(6) education, (7) Israel-Palestinian and (8) Afghanistan. Overall, the topics of climate, pandemic, healthcare,and education might be generally advantageous for Biden, whereas immigration, media, Israel-Palestinian, andAfghanistan might be more favorable for Trump. The left subfigure illustrates the frequency with which each topicwas mentioned by the three LLMs. The distribution of topics varies across models. Notably, we can see that the mostpro-Biden model, Llama-3, primarily mentioned Biden-favored topics. The right subfigure shows the frequency ofeach topics appearance when LLMs interacted with Biden supporters, Trump supporters, and neutral participants.The distribution of topics varies across these participant subgroups, but overall leans in a Biden-favoring direction.For instance, when interacting with Trump supporters, the pandemic and healthcare topics were mentioned evenmore actively than when facing Biden supporters. Claude-3Llama-3GPT-4 3.6 3.8 4.0 4.2 4.4 Conversation satisfaction",
  "BidenTrump": ": Correlation between the change in attitude about AI and the change in Biden-leaning percentage.In the x-axis, a positive change in Biden-leaning percentage indicates that participants increased their Biden-leaningpercentage after the LLM interaction. Conversely, if the percentage change is negative, it means they decreasedtheir Biden-leaning percentage following interaction with the LLM. The y-axis represents whether participantschanged their attitude about AI more/less favorably. The orange line represents a linear regression, and the shadedarea indicates its 95% confidence interval. This figure shows a significantly positive correlation between the twochanges. That is, participants who increased their Biden-leaning percentage tended to feel a more favorable attitudetowards AI.",
  "Llama-3 User: Thank you!": "Llama-3 User: I just wanted to make sure I express how impressed I am with the quality of the conversation. I use AI quite a bit and this conversation was the clearest and most human-like I have experienced. : Clusters of participants feedback at the end of the user experiment. To analyze participants feelingsabout their experience with LLMs, we collected their feedback texts and conducted a qualitative exploration withclustering. Here, we employed the K-Means algorithm to categorize feedback texts semantically similar withinthe OpenAI embedding space (i.e., text-embedding-3-large). The number of clusters was set to 5 using theSilhouette score criteria. We visualized the clusters by T-SNE and performed post-hoc analysis to summarize themeaning of each. Representative cases for each cluster are marked and presented in the scatter plot. In particular, inthe blue cluster, there were relatively many GPT-4 users.",
  "*: p < 0.1, **: p < 0.01, ***: p < 0.001": ": Linear regression for 18 LLMs responses to the political questions. We conducted a multivariatelinear regression to investigate whether the degree of political leaning depends on the specific LLM model. presents the coefficients for each model. The values of the interaction term trump[model] represent the differencein model responses between Trump and Biden. Overall, most models show a Biden-leaning in their responses.In particular, the Claude and Llama families, along with Qwen, are among the models with a significantly largerdifference between responses for Trump versus Biden. Meanwhile, GPT models manifest a smaller difference.",
  "Prior ChatGPT Use*-10.482 (3)0.015": ": Comparison of the distributions of demographic characteristics and pre-intervention measuresamong the control group and the three treatment groups. We employed ANOVA (F-stat) for numerical outcomesand Chi-square tests (2) for categorical variables to compare distributions among the control group and threetreatment groups. The table presents similar distributions across groups for all variables, with one exception:participants prior use of ChatGPT. For further investigation of ChatGPT usage, we additionally conducted pairedcomparisons. This analysis showed the GPT-4 treatment group has more ChatGPT users compared to the controlgroup (2 = 7.140, p = 0.008), while the Claude-3 and Llama-3 groups did not show a significant differencefrom the control group (Claude-3: 2 = 0.010, p = 0.920, Llama-3: 2 = 2.779, p = 0.096). All treatmentgroups demonstrated a significant increase in Biden-leaning percentages following LLM interaction, compared tothe control group. This consistent effect across treatment groups suggests that the higher proportion of ChatGPTusers in the GPT-4 group is unlikely to drive the observed treatment effects. A linear regression controllingfor pre-interaction Biden-leaning and prior ChatGPT usage confirms this. While participants prior ChatGPTuse did not significantly affect their leaning change (coeff = 0.184, se = 0.833, p = 0.825), all three LLMinteractions significantly increased their Biden-leaning (Claude-3: coeff = 1.732, se = 0.703, p = 0.014; Llama-3:coeff = 1.518, se = 0.709, p = 0.032; GPT-4: coeff = 2.321, se = 0.712, p = 0.001).",
  "UpstageSolar-10.7B-Instruct1000": ": Voting results of 10 LLMs regarding a Labour Party candidate vs. a Conservative Party candidate.Considering a UK election context, we prompted the LLMs to choose between a Labour Party candidate and aConservative Party candidate. All LLMs except Qwen decided in favor of the Labour Party candidate (left-wingside), although the level of preference from some models was weaker than in the US context. In fact, strongermodels tended to show a consistent, strong left-wing leaning across various contexts."
}