{
  "Abstract": "The field of privacy-preserving Natural Lan-guage Processing has risen in popularity, par-ticularly at a time when concerns about privacygrow with the proliferation of Large LanguageModels. One solution consistently appearingin recent literature has been the integration ofDifferential Privacy (DP) into NLP techniques.In this paper, we take these approaches intocritical view, discussing the restrictions that DPintegration imposes, as well as bring to lightthe challenges that such restrictions entail. Toaccomplish this, we focus on DP-PROMPT, arecent method for text privatization leveraginglanguage models to rewrite texts. In particular,we explore this rewriting task in multiple sce-narios, both with DP and without DP. To drivethe discussion on the merits of DP in NLP, weconduct empirical utility and privacy experi-ments. Our results demonstrate the need formore discussion on the usability of DP in NLPand its benefits over non-DP approaches.",
  "Introduction": "The topic of privacy in Natural Language Process-ing has recently gained traction, which has onlybeen fueled by the prominent rise of Large Lan-guage Models. In an effort to address concernsrevolving around the protection of user data, thestudy of privacy-preserving NLP has presented aplethora of innovative solutions, all investigating insome form the optimization of the privacy-utilitytrade-off for the safe processing of textual data.A well-studied solution comes with the integra-tion of Differential Privacy (DP) (Dwork, 2006)into NLP techniques. Essentially, the use of DP en-tails the addition of calibrated noise to some stagein a pipeline, e.g., directly to the data or to modelweights. This is performed with the ultimate goalof protecting the individual whose data is beingused, aligned with the objective of Differential Pri-vacy set out in its inception nearly 20 years ago. The incentive of proving Differential Privacyis the mathematical guarantee of privacy protec-tion that it offers, so long as its basic principlesare adhered to. Particularly, important DP notionsmust be strictly defined, such as who the individ-ual is, how data points are adjacent, and how datacan be bounded. As such, the fusion of Differen-tial Privacy and NLP introduces several challenges(Feyisetan et al., 2021; Habernal, 2021; Klymenkoet al., 2022; Mattern et al., 2022). When general-ized forms of DP are used or well-defined notionsof DP concepts are lacking, the promise of DPbecomes more of a shallow guarantee.In this work, we critically view the pursuit ofDP in NLP, focusing on the particular method ofDP-PROMPT (Utpala et al., 2023). This methodleverages generative Language Models to rewrite(paraphrase) texts with the help of a DP token selec-tion method based on the Exponential Mechanism(Mattern et al., 2022). We run experiments on threerewriting settings: (1) DP, (2) Quasi-DP, and (3)Non-DP; the purpose of this trichotomy is to ex-plore the benefits and shortcomings of DP in textrewriting. We define our research question as:",
  "What is the benefit of integrating DifferentialPrivacy into private text rewriting methodsleveraging LMs, and what effect can be ob-served by relaxing this guarantee?": "Our empirical findings show the advantages thatincorporating DP into text rewriting mechanismsbrings, notably higher semantic similarity and re-semblance to the original texts, along with strongempirical privacy results. This, however, comeswith the downside of generally lower quality textin terms of readability, particularly at stricter pri-vacy budgets. These findings open the door todiscussions regarding the practical distinction be-tween DP and non-DP text privatization, where wepresent open questions and paths for future work.The contributions of our work are as follows:",
  "Related Work": "Natural language can leak personal information(Brown et al., 2022) and it is possible to extracttraining data from Machine Learning models (Panet al., 2020; Carlini et al., 2021; Mattern et al.,2023). In the global DP setting, user texts are col-lected at a central location and a model is trainedusing privacy-preserving optimization techniques(Ponomareva et al., 2022; Kerrigan et al., 2020)such as DP-SGD (Abadi et al., 2016). The primarydrawback of this model is that user data must becollected at a central location, giving a data curatoraccess to the entire data (Klymenko et al., 2022).To mitigate this, text can be obfuscated or rewrittenlocally in a DP manner before collecting it at a cen-tral location (Feyisetan et al., 2020; Igamberdievand Habernal, 2023; Hu et al., 2024).The earliest set of approaches of DP in NLPbegan at the word level (Weggenmann and Ker-schbaum, 2018; Fernandes et al., 2019; Yue et al.,2021; Chen et al., 2023; Carvalho et al., 2023;Meisenbacher et al., 2024a), yet these methodsdo not consider contextual and grammatical infor-mation during privatization (Mattern et al., 2022;Meisenbacher et al., 2024c). Other works operatedirectly at the sentence level by either applying DPto embeddings (Meehan et al., 2022) or latent rep-resentations (Bo et al., 2021; Weggenmann et al.,2022; Igamberdiev and Habernal, 2023). DP textrewriting methods using generative LMs (Matternet al., 2022; Utpala et al., 2023; Flemings and An-navaram, 2024) or encoder-only models (Meisen-bacher et al., 2024b) have also been proposed.",
  "DP-PROMPT (Utpala et al., 2023) is a differen-tially private text rewriting method in which users": "generate privatized documents at the local levelby prompting Language Models to rewrite inputtexts. In particular, the LMs are prompted to para-phrase a given text. The immediate advantage ofthis method comes with the flexibility in modelchoice as well as the generalizability to all general-purpose pre-trained (instruction-finetuned) LMs.The integration of DP into this rewriting pro-cess comes at the generation step, where for eachoutput token, a DP token selection mechanism isimplemented in the form of temperature sampling.In Mattern et al. (2022), it is shown that the useof temperature can be equated to the ExponentialMechanism (McSherry and Talwar, 2007). Relat-ing this mechanism to the privacy budget of DP,the authors show that = 2 T , where T is the tem-perature and is the sensitivity, or range, of thetoken logits. A fixed sensitivity can be ensured byclipping the logits to certain bounds.For the purposes of this work, we perform allexperiments using DP-PROMPT with the FLAN-T5-",
  "Motivated by the DP-PROMPT rewriting mecha-nism, we introduce three privatization strategiesbased on its DP token selection mechanism:": "1. DP: we use DP-PROMPT as originally in-troduced, namely by clipping logit valuesand scaling logits by temperatures calculatedbased on values. We test on the values {25, 50, 100, 150, 250}. Logits are clippedbased on an empirical measurement of log-its in the FLAN-T5-BASE model1. 2. Quasi-DP: we replicate the DP strategy with-out clipping, i.e., only using temperature sam-pling based on the abovementioned values.We call this quasi-DP since the temperaturevalues T are calculated as if clipping was per-formed (i.e., sensitivity is bounded), but theunbounded logit range is actually used. 3. Non-DP: here, we do not use any clippingor temperature, but rather only vary the top-k parameter, or the number k of candidatetokens considered when sampling the nexttoken. We choose k {50, 25, 10, 5, 3}.",
  "Dataset": "For all of our experiments, we utilize the Blog Au-thorship Corpus (Schler et al., 2006). This corpuscontains nearly 700k blog post texts from roughly19k unique authors. The corpus also lists the ID,gender, and age of author for each blog post. Fulldetails on the preparation of the corpus are found inAppendix A; pertinent details are outlined below.We prepare two subsets of the corpus. The first,which we call author10, only considers blog postsfrom the top-10 most frequently occurring blog au-thors in the corpus. This subset results in a datasetof 15,070 blog posts spanning five categories.The second subset, called topic10, is necessaryas the classification of the gender and age attributesfor the author10 dataset would be a less diverseand challenging task. We first take a random 10%sample of the top-10 topics from the filtered corpus,resulting in a sample of 14,259 blogs. Here, theage value is binned into one of five bins to ensurean equal number of instances in each bin.",
  "Utility Experiments": "We perform utility experiments for both the au-thor10 and topic10 datasets. To measure utilityacross all privatization strategies, we first privatizeeach dataset on all selected privatization param-eters. As we choose 5 parameters (/T or k) foreach of our three strategies, this results in 15 datasetvariants, i.e., 15 results per metric, each of whichrepresents the average between the two datasets. Semantic Similarity.To measure the ability ofeach privatization strategy to preserve the semanticmeaning of the original sentence, we employ twosimilarity metrics: BLEU (Papineni et al., 2002)and cosine similarity. Both metrics strive to capture the similarity between output (in this case priva-tized) text and a reference (original) text; BLEUrelies on token overlap while cosine similarity be-tween embeddings is more contextual.We use SBERT (Reimers and Gurevych, 2019)to calculate the average cosine similarity (CS) be-tween the original blog posts and their privatizedcounterparts. For this, we use utilize three embed-dings models to account for model-specific differ-ences: ALL-MINILM-L6-V2, ALL-MPNET-BASE- V2, and GTE-SMALL (Li et al., 2023). For eachdataset, we report the mean of the average cosinesimilarity calculated for each model.We also report the BLEU score between priva-tized texts and their original counterparts. This isdone using the BLEU implementation made avail-able by Hugging Face. As before, reported BLEUscores are the average across an entire dataset.",
  "Privacy Experiments": "Using author10 and topic10, we design three em-pirical privacy experiments, in which an adversarialclassification model is trained to predict a sensitiveattribute (authorship, gender, or age) based on theblog post text. For this, we fine-tune a DEBERTA- V3-BASE model (He et al., 2021) for three epochs,reporting the macro F1 of the adversarial classifier.We evaluate the privatized datasets in two set-tings (Mattern et al., 2022; Weggenmann et al.,2022). In the static setting, the adversarial model istrained on the original training split and evaluatedon the privatized validation split. In the more chal-lenging adaptive setting, the adversarial classifieris trained on the private train split. Lower perfor-mance implies that a method has better protectedthe privacy of the texts. Note that the adaptive scorerepresents the mean of three runs. For all cases, arandom 90/10 train/val split with seed 42 is taken.In addition to F1, we also report the relativegain metric (), following previous works (Matternet al., 2022; Utpala et al., 2023). aims to capturethe trade-off between utility loss and privacy gain,as compared to the baseline scores. For the utilityportion of , we use the CS results. Baseline scoresare represented by adversarial performance aftertraining and testing on the non-private datasets. Wereport the with respect to the adaptive setting.",
  "/k value2550100150250255010015025050251053": "CS 1.000.5890.5970.8120.8270.8320.3470.5980.8100.8260.8330.7100.7260.7500.7410.787BLEU 1.000.0770.0290.1230.1420.1530.0010.0290.1210.1410.1530.0490.0540.0630.0630.088PPL 41877012349289199051692613809829329258169721080827837 Author F1 (s) 66.457.1337.0558.1061.1260.606.5936.9157.8460.3761.1346.8347.0749.8851.6953.10Author F1 (a) 66.452.6833.5252.8255.4657.352.7433.2954.8155.6457.3442.5644.8145.2048.2249.91Gender F1 (s) 68.0741.8855.6667.8166.6865.9243.4158.1667.8565.3867.9855.6463.9164.1664.5066.66Gender F1 (a) 68.0738.8054.0661.9062.9062.2338.8057.0562.4854.0262.9360.6159.0959.2361.2660.00Age F1 (s) 37.5819.1228.5638.3137.1738.4417.9928.0637.3237.5338.4232.2432.9535.5635.4135.64Age F1 (a) 37.5812.1729.0638.9237.9539.0012.1732.4036.8536.7737.4933.4934.6734.9735.7536.23 Author -0.5490.0930.017-0.008-0.0310.3060.097-0.015-0.011-0.0300.0700.0520.0700.0150.036Gender -0.019-0.197-0.097-0.097-0.082-0.223-0.240-0.1080.032-0.091-0.180-0.142-0.120-0.159-0.094Age -0.265-0.176-0.224-0.183-0.2060.023-0.264-0.171-0.152-0.165-0.181-0.197-0.181-0.210-0.177 -0.833-0.281-0.304-0.288-0.3190.106-0.407-0.293-0.131-0.286-0.292-0.287-0.231-0.354-0.236 : Experiment Results. Utility scores include the averaged CS, BLEU, and PPL scores for the author10 andtopic10 datasets. Author/Gender/Age F1 indicate the adversarial performance on the authorship, gender, and ageclassification tasks, for both the static (s) and adaptive (a) settings. We report a modified version of Relative Gain ()for each setting, as explained in .3. The best cumulative score is bolded for each comparative parameter.",
  "Discussion": "In analyzing the results, we first discuss the meritsof DP text privatization. At stricter privacy bud-gets (lower ), only the original DP-PROMPT isable to present significant gains, as showcased with = 25. At these lower values, one can also ob-serve the benefits of enforcing DP via logit clip-ping, which results in higher CS and BLEU reten-tion while outputting generally more readable text(much lower PPL). This trend with PPL holds forall scenarios of DP vs. Quasi-DP, making a clearcase for proper bounding in DP applications.In studying DP vs. Quasi-DP further, we noticethat the distinction between the two, particularlyat higher values, becomes somewhat opaque. Infact, Quasi-DP outperforms DP in terms of empir-ical privacy in many of the higher privacy budgetscenarios. This would imply that a DP mechanismleveraging temperature sampling only becomes ef-fective and sensible with stricter privacy budgets.An important point of comparison also comeswith the study results of our Non-DP method. Astrength of this method is highlighted by its abil-ity at lower k values (analogous to less strict pri-vacy budgets) to maintain high levels of seman-tic similarity (CS), while still achieving compet-itive empirical privacy scores. For example, inthe case of k = 3, this method is able to outper-form all 100 for both DP and Quasi-DP. TheBLEU scores for Non-DP would also imply thatthis method is better able to rewrite texts in a se-mantically similar, yet lexically different manner,as opposed to DP methods at high values (seeAppendix D). These results make a case for Non-DP privatization in certain cases, and in parallel,provide a critical view of using DP at high valueswhich lead to ineffective empirical privacy. A final point that is crucial to discuss is groundedin the observed relative gains. Looking to the cumu-lative scores ( ) of , one can notice thatthe only positive gains are observed at relativelylow values, implying that only at these levels dothe empirical privacy protections begin to outweighthe losses in utility. The utility scores in these cases,however, are quite difficult to justify in real-worldscenarios, where semantic similarity is quite lowand readability suffers greatly. These results in gen-eral showcase the harsh nature of the privacy-utilitytrade-off, where mitigating adversarial advantageoften comes with less usable data.",
  "Conclusion": "Central to this work is the debate on the merits ofDifferential Privacy in NLP. To lead this discussion,we conduct a case study with the DP-PROMPTmechanism, juxtaposed with two relaxed vari-ants. Our results show that while the theoreticalguarantee of individual privacy may be important insome application settings, in others, it may becometoo restrictive to apply effectively. Conversely, themerits of DP may be observed in stricter privacyscenarios, where the need for tight guarantees doesbring favorable privacy-utility trade-offs.We call for further research in two directions:(1) rigorous studies on the theoretical and practicalimplications of DP vs non-DP privatization, andrelatedly, (2) the continued design of privatizationmechanisms outside the realm of Differential Pri-vacy that aim to balance strong privacy protectionswith practical utility preservation. We hope thatresearchers may be able to harmonize the best ofboth worlds, keeping in sight the need for practi-cally usable privacy protection of text data.",
  "The foremost limitation of our work comes withthe selection of a single base model for use with": "FLAN-T5-BASE. While further testing should beconducted on other (larger) models, we hold thatour results can be generalized, since model choicewas not central to our findings. Another limitationis the choice of (i.e., temperature) and k values,which were not selected in any rigorous manner,but rather based on the relative range of valuespresented in Utpala et al. (2023). The effect ofparameter values outside of our selected rangesthus is not explored in this work.",
  "Ethics Statement": "An ethical consideration of note concerns our em-pirical privacy experiments, which leverage an ex-isting dataset (Blog Authorship) not originally in-tended for adversarial classification. In performingthese empirical experiments, the actions of a po-tential adversary were simulated, i.e., to leveragepublicly accessible information for the creation ofan adversarial model. As this dataset is alreadypublic, no harm was inflicted in the privacy experi-ments as part of this work. Moreover, the dataset ismade up of pseudonyms (Author IDs) rather thanPII, thus further reducing the potential for harm. Martin Abadi, Andy Chu, Ian Goodfellow, H. Bren-dan McMahan, Ilya Mironov, Kunal Talwar, andLi Zhang. 2016. Deep learning with differential pri-vacy.In Proceedings of the 2016 ACM SIGSACConference on Computer and Communications Secu-rity, CCS 16, page 308318, New York, NY, USA.Association for Computing Machinery. Haohan Bo, Steven H. H. Ding, Benjamin C. M. Fung,and Farkhund Iqbal. 2021. ER-AE: Differentiallyprivate text generation for authorship anonymization.In Proceedings of the 2021 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,pages 39974007, Online. Association for Computa-tional Linguistics.",
  "ACM Conference on Fairness,Accountability,and Transparency, FAccT 22, page 22802292,New York, NY, USA. Association for ComputingMachinery": "Nicholas Carlini,Florian Tramer,Eric Wallace,Matthew Jagielski, Ariel Herbert-Voss, KatherineLee, Adam Roberts, Tom Brown, Dawn Song, UlfarErlingsson, et al. 2021. Extracting training data fromlarge language models. In 30th USENIX SecuritySymposium (USENIX Security 21), pages 26332650. RicardoSilvaCarvalho,TheodoreVasiloudis,Oluwaseyi Feyisetan, and Ke Wang. 2023. TEM:High utility metric differential privacy on text.In Proceedings of the 2023 SIAM InternationalConference on Data Mining (SDM), pages 883890.SIAM. Sai Chen, Fengran Mo, Yanhao Wang, Cen Chen, Jian-Yun Nie, Chengyu Wang, and Jamie Cui. 2023. Acustomized text sanitization mechanism with differ-ential privacy. In Findings of the Association forComputational Linguistics: ACL 2023, pages 57475758, Toronto, Canada. Association for Computa-tional Linguistics. Hyung Won Chung, Le Hou, Shayne Longpre, BarretZoph, Yi Tay, William Fedus, Yunxuan Li, XuezhiWang, Mostafa Dehghani, Siddhartha Brahma, Al-bert Webson, Shixiang Shane Gu, Zhuyun Dai,Mirac Suzgun, Xinyun Chen, Aakanksha Chowdh-ery, Alex Castro-Ros, Marie Pellat, Kevin Robinson,Dasha Valter, Sharan Narang, Gaurav Mishra, AdamsYu, Vincent Zhao, Yanping Huang, Andrew Dai,Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Ja-cob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le,and Jason Wei. 2022. Scaling instruction-finetunedlanguage models. Preprint, arXiv:2210.11416.",
  "Cynthia Dwork. 2006. Differential privacy. In Inter-national colloquium on automata, languages, andprogramming, pages 112. Springer": "Natasha Fernandes, Mark Dras, and Annabelle McIver.2019. Generalised differential privacy for text doc-ument processing.In Principles of Security andTrust: 8th International Conference, POST 2019,Held as Part of the European Joint Conferenceson Theory and Practice of Software, ETAPS 2019,Prague, Czech Republic, April 611, 2019, Proceed-ings 8, pages 123148. Springer International Pub-lishing. Oluwaseyi Feyisetan, Abhinav Aggarwal, Zekun Xu,and Nathanael Teissier. 2021. Research challenges indesigning differentially private text generation mech-anisms. In The International FLAIRS ConferenceProceedings, volume 34. Oluwaseyi Feyisetan, Borja Balle, Thomas Drake, andTom Diethe. 2020. Privacy- and utility-preservingtextual analysis via calibrated multivariate perturba-tions. In Proceedings of the 13th International Con-ference on Web Search and Data Mining, WSDM 20,",
  "page 178186, New York, NY, USA. Association forComputing Machinery": "James Flemings and Murali Annavaram. 2024. Differ-entially private knowledge distillation via synthetictext generation. In Findings of the Association forComputational Linguistics ACL 2024, pages 1295712968, Bangkok, Thailand and virtual meeting. As-sociation for Computational Linguistics. Ivan Habernal. 2021. When differential privacy meetsNLP: The devil is in the detail. In Proceedings of the2021 Conference on Empirical Methods in NaturalLanguage Processing, pages 15221528, Online andPunta Cana, Dominican Republic. Association forComputational Linguistics.",
  "Lijie Hu, Ivan Habernal, Lei Shen, and Di Wang. 2024": "Differentially private natural language models: Re-cent advances and future directions.In Findingsof the Association for Computational Linguistics:EACL 2024, pages 478499, St. Julians, Malta. As-sociation for Computational Linguistics. Timour Igamberdiev and Ivan Habernal. 2023. DP-BART for privatized text rewriting under local dif-ferential privacy. In Findings of the Association forComputational Linguistics: ACL 2023, pages 1391413934, Toronto, Canada. Association for Computa-tional Linguistics.",
  "Zehan Li, Xin Zhang, Yanzhao Zhang, Dingkun Long,Pengjun Xie, and Meishan Zhang. 2023. Towardsgeneral text embeddings with multi-stage contrastivelearning. Preprint, arXiv:2308.03281": "Justus Mattern, Fatemehsadat Mireshghallah, ZhijingJin, Bernhard Schoelkopf, Mrinmaya Sachan, andTaylor Berg-Kirkpatrick. 2023. Membership infer-ence attacks against language models via neighbour-hood comparison. In Findings of the Association forComputational Linguistics: ACL 2023, pages 1133011343, Toronto, Canada. Association for Computa-tional Linguistics. Justus Mattern, Benjamin Weggenmann, and FlorianKerschbaum. 2022. The limits of word level differen-tial privacy. In Findings of the Association for Com-putational Linguistics: NAACL 2022, pages 867881,",
  "Frank McSherry and Kunal Talwar. 2007. Mechanismdesign via differential privacy. In 48th Annual IEEESymposium on Foundations of Computer Science(FOCS07), pages 94103": "Casey Meehan, Khalil Mrini, and Kamalika Chaudhuri.2022. Sentence-level privacy for document embed-dings. In Proceedings of the 60th Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 1: Long Papers), pages 33673380, Dublin,Ireland. Association for Computational Linguistics. Stephen Meisenbacher, Maulik Chevli, and FlorianMatthes. 2024a. 1-Diffractor: Efficient and utility-preserving text obfuscation leveraging word-levelmetric differential privacy. In Proceedings of the10th ACM International Workshop on Security andPrivacy Analytics, IWSPA 24, page 2333, NewYork, NY, USA. Association for Computing Machin-ery. Stephen Meisenbacher, Maulik Chevli, Juraj Vladika,and Florian Matthes. 2024b. DP-MLM: Differen-tially private text rewriting using masked languagemodels. In Findings of the Association for Com-putational Linguistics ACL 2024, pages 93149328,Bangkok, Thailand and virtual meeting. Associationfor Computational Linguistics. Stephen Meisenbacher, Nihildev Nandakumar, Alexan-dra Klymenko, and Florian Matthes. 2024c. A com-parative analysis of word-level metric differentialprivacy: Benchmarking the privacy-utility trade-off.In Proceedings of the 2024 Joint International Con-ference on Computational Linguistics, LanguageResources and Evaluation (LREC-COLING 2024),pages 174185, Torino, Italia. ELRA and ICCL.",
  "Xudong Pan, Mi Zhang, Shouling Ji, and Min Yang.2020.Privacy risks of general-purpose languagemodels. In 2020 IEEE Symposium on Security andPrivacy (SP), pages 13141331": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a method for automatic eval-uation of machine translation. In Proceedings of the40th Annual Meeting on Association for Computa-tional Linguistics, ACL 02, page 311318, USA.Association for Computational Linguistics. Natalia Ponomareva, Jasmijn Bastings, and Sergei Vas-silvitskii. 2022. Training text-to-text transformerswith privacy guarantees. In Findings of the Asso-ciation for Computational Linguistics: ACL 2022,pages 21822193, Dublin, Ireland. Association forComputational Linguistics.",
  "Benjamin Weggenmann and Florian Kerschbaum. 2018": "SynTF: Synthetic and differentially private term fre-quency vectors for privacy-preserving text mining.In The 41st International ACM SIGIR Conference onResearch & Development in Information Retrieval,pages 305314. Benjamin Weggenmann, Valentin Rublack, Michael An-drejczuk, Justus Mattern, and Florian Kerschbaum.2022. DP-VAE: Human-readable text anonymizationfor online reviews with differentially private varia-tional autoencoders. In Proceedings of the ACM WebConference 2022, WWW 22, page 721731, NewYork, NY, USA. Association for Computing Machin-ery. Xiang Yue, Minxin Du, Tianhao Wang, Yaliang Li,Huan Sun, and Sherman S. M. Chow. 2021. Dif-ferential privacy for text analytics via natural textsanitization. In Findings of the Association for Com-putational Linguistics: ACL-IJCNLP 2021, pages38533866, Online. Association for ComputationalLinguistics.",
  "We outline the process of dataset preparation forthe data used in this work. All prepared datasetsare made available in our code repository.We begin with the corpus made available by": "Schler et al. (2006), which contains 681,284 blogposts from 19,320 authors and across 40 topics. Inparticular, we use the version made publicly avail-able on Hugging Face2. In this version, each blogpost is labeled with a topic, which we learned trans-lates to the career field of the corresponding author.Upon an initial survey, we noticed that a significantamount of blogs are labeled with indUnk, so thesewere filtered out. In addition, one of the topicsnamed Student did not seem to have coherent blogcontent in terms of topic, so these blogs were alsoremoved. These steps resulted in a filtered corpusof 276,366 blogs.Next, noticing that out of all the topics, manycontained very few blogs, we only considered blogs with topics in the top 15 most frequently occurringtopics. We also only consider blog posts with amaximum of 256 tokens, both for performancereasons and also to remove outliers (very long blogposts). These two stops resulted in a further filteredset of 162,584 blogs.To prepare the author10 dataset, we consideredthe 10 most frequently blogging authors in the fil-tered corpus. This translates to authors writingbetween 1001 and 2174 distinct blog posts, for atotal of 15,070 blogs in the author10 dataset.To prepare the topic10 dataset, we only considerblog posts from the filtered corpus which count inthe top 10 most frequently occurring topics. Con-cretely, this consists of the following topics (frommost to least frequent): Technology, Arts, Educa-tion, Communications-Media, Internet, Non-Profit,Engineering, Law, Science, and Government. Withthese topics, we take a 10% sample of the filteredcorpus, resulting in a dataset of 14,259 blogs. Tech-nology is the most frequent topic in this datasetwith 3409 blogs, with Government the least fre-quent at 485 blogs.While the gender attribute is not altered in thetopic10 dataset, we bin the age attribute for a morereasonable classification task. We choose to createfive bins from the age column, which ranges fromthe age of 13 to 48. Creating an even split betweenall age bins, we achieve the following bin ranges:",
  "BDP-PROMPT Implementation Details": "We implement DP-PROMPT by following the de-scribed method in the original paper (Utpala et al.,2023). As noted, we leverage the FLAN-T5-BASEmodel as the underlying LM.To set the clipping bounds for our method, werun 100 randomly sampled texts from our datasetthrough the model and record all logit values.Then, we set the clipping range to (logit_mean,logit_mean + 4 logit_std) = (-19.23, 7.48), asnoted in the paper.For the prompt template, we use the same simpletemplate as used by Utpala et al. (2023), namely:",
  "As discussed in the original paper, we do notchange the top-k parameter for DP-PROMPT in itsoutput generation, both for the DP and Quasi-DP": "settings. This is left to the default Hugging Faceparameter of k = 50.Finally, for comparability, we limit the maxi-mum generated tokens for all methods to 64.For all privatization scenarios, we run DP-PROMPT (and its variants) on a NVIDIA RTXA6000 GPU, with an inference batch size of 16.The source code for replication can be foundat the following repository, which also includesour two prepared datasets used in the experiments:",
  "CTraining Parameters": "For all training performed as part of our empiricalprivacy experiments, we utilize the Hugging FaceTrainer library for model training. All trainingprocedures use default Trainer parameters, exceptfor a training batch size of 64 and validation batchsize of 128. Dataset splits are always shuffled witha random seed of 42 prior to training or validation.All training is performed on a single NVIDIA RTXA6000 GPU.",
  "Tables 2 and 3 provide rewriting examples for alltested parameters for a selected text sample fromeach of our two datasets": "Original textFood for poor ol me as well!!!!! Yesterday was absolutely great. Not only did I get 30 for doing 5 minsmaintenance/repair on someones PC, but I had a great night out too! Cant get any better than that. Asmy wallet has been topped-up *smug* I can now afford my Only Fools And Horses DVD, Max PayneII (when it comes out in about a month) and I can also take Nic out for a classy meal when I get round toit one weekend. Corny. I have also done most of my homework so far. Im hardly lagging which gets mein a happier mood :) P.S: BRAND new absolutemaxpayne.co.uk due for release in about 3 weeks (just / kbefore release, how convenient). Kinky. 25Baggy Boggianylines Show Baseografic Direct Withinlui Because Parallel Gate shows OilNamen MiniPilot Officeproductive evaluated analyse Belgium divorce Index geometric An integrated achievecliinterMadrid game Facilityuillonture GUI ensue diese lawyeradvisable devenir 1 Claus farbene Committeeof Government housing Fulllink/ Staffdangger Zugriff staatlich finden Bow 50the food started okay, was slow so I renovated a locker monday.DP100Yesterday was great. Not only did I get 30 for doing 5 mins maintenance/repair on someones PC, but Ihad a great night out too! Cant get any better than that! As my wallet has been topped-up *smug* Ican now afford",
  "Just had a nice night at my new laptop store. Its been showering and saving my cancelled vacation forthe good of the Bay Area and improving my financial position back down in Seattle": "100Yesterday was a really good day. I got 30 for doing 5 mins maintenance/repair on someones PC, but Ihad a great night out too! Cant get any better than that! As my wallet has been topped-up *smug* Ican nowQuasi-DP150Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someonesPC, but I had a great night out too! Cant get any better than that. As my wallet has been topped-up(*smug*) I can 200Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someonesPC, but I had a great night out too! Cant get any better than that. As my wallet has been topped-up*smug* I can now 250Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someonesPC, but I had a great night out too! Cant get any better than that. As my wallet has been topped-up*smug* I can now",
  "Ive had an amazing weekend.Non-DP5I have to get some money to buy a DVD, Max Payne II and eat dinner for Nic": "3Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someonesPC but I had a great night out too. As my wallet has been topped-up ... I can now afford my Only FoolsAnd Horses DVD, Max Payne 1Yesterday was absolutely great. Not only did I get 30 for doing 5 mins maintenance/repair on someonesPC, but I had a great night out too! Cant get any better than that. As my wallet has been topped-up*smug* I can now",
  ": Rewritten examples from the author10 dataset": "Original textMy mother came over on Sunday and brought a ton of baby stuff that she has either bought new or foundat consignment shops (she has better ones where she lives). It was fun looking at all the PINK thingsshe bought! Then she gave me some dusters to wear that my grandmother had and never wore. Theyare so comfortable it is almost unbelievable! Want to know what a duster is? ROFLMAO Its a politeword for a MUU-MUU! And I dont care! For the first time in my life I am actually happy to be wearinga muu-muu... Is it old age or senility? Who knows. All I know is that I am very comfortable. ((PoorSharky is convinced that this is a plot of my mothers to insure that I NEVER get pregnant again. I mean, / kthese are muu-muus in all the prerequisite colors and patterns.)) 25Leaf miserable Astro FIRST actress Nachlac Pitt came over lending Judesc headset recently aleappa-rafterv disk album popcorn to Conservative Job Today quest necessity when Ellenm at Funeral seenVilnton les grisil set transtourotherquartaine abruptapathetic Boot Vacation betting lieben analysis TravailEmperor LEWhether Fantasy climatique trop torrent aus 50Jade is comfortable in red nudeDP100A mother came over on Sunday and brought a lot of baby stuff, some dusters that her grandmother neverwore, and a muu-muus, the first time in her life I am happy to be wearing a muu-muus.",
  "My mother brought me some baby dusters that her grandmother never wore": "25Grantment 2010. Onh Sar asking State430 unstable 13. 2013, makers knee before Town in tuneive 101Lankauniverszu Horse investi Uneign man taitexistant grandeco certifiPro remboursement Bil contreRaiggy contribu Driver Levant pourtant crois Beaumaym cerc unfold III777devoted tutello:...me alloudiplomat Me calls warrant 50The mother brought everything to the baby that she could find, from pillows to throw pillows. It was funand time wass. The first time I am happy wearing a popular MU-MU frisder.Quasi-DP100My mother brought me a lot of baby stuff to look at.",
  "There were a lot of baby clothes that my mom had before she wore all these dusters": "25My grandmother brought a lot of baby stuff from their home and they had to get a duster for the firsttime in her life. She said hers were nice to look at and they were comfortable. But its not the same ashaving a diaper.Non-DP10She brought my mother a lot of baby stuff, and gave me some new dusters. Theyre so comfortable theyare almost unbelievable."
}