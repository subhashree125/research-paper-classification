{
  "Abstract": "Event Causality Identification (ECI) focuseson extracting causal relations between eventsin texts. Existing methods for ECI primarilyrely on causal features and external knowledge.However, these approaches fall short in two di-mensions: (1) causal features between eventsin a text often lack explicit clues, and (2) ex-ternal knowledge may introduce bias, whilespecific problems require tailored analyses. Toaddress these issues, we propose SemDI - a sim-ple and effective Semantic Dependency InquiryNetwork for ECI. SemDI captures semantic de-pendencies within the context using a unifiedencoder. Then, it utilizes a Cloze Analyzer togenerate a fill-in token based on comprehen-sive context understanding. Finally, this fill-intoken is used to inquire about the causal re-lation between two events. Extensive experi-ments demonstrate the effectiveness of SemDI,surpassing state-of-the-art methods on threewidely used benchmarks. Code is availableat",
  "Introduction": "Event Causality Identification (ECI) aims to catchcausal relations between event pairs in text. Thistask is critical for Natural Language Understand-ing (NLU) and exhibits various application values.For example, an accurate ECI system can facilitatequestion answering (Liu et al., 2023b; Zang et al.,2023), narrative generation (Ammanabrolu et al.,2021), and summarization (Huang et al., 2023).However, identifying causal relationships withintext is challenging due to the intricate and oftenimplicit causal clues embedded in the context. Forinstance, in the sentence \"But tremors are likely inthe junk-bond market, which has helped to financethe takeover boom of recent years.\", an ECI modelshould identify the causal relation between eventpair (tremors, boom), which is not immediatelyevident without understanding the context.",
  ": Introduction of the ECI task, along withour motivation: causal relations are heavily context-dependent": "The conventional approach for ECI involves abinary classification model that takes a triplet (sen-tence, event-1, event-2) as input to determine theexistence of a causal relation between the twoevents, as illustrated at the top of . Vari-ous methods have been proposed to enhance ECIperformance.While early feature-based meth-ods (Hashimoto et al., 2014; Ning et al., 2018;Gao et al., 2019) laid the foundation, more recentrepresentation-based methods have demonstratedsuperior ECI capabilities, including Pre-trainedLanguage Models (PLMs) based methods (Shenet al., 2022; Man et al., 2022), and data augmenta-tion methods (Zuo et al., 2020, 2021b). A notablerecent trend is augmenting ECI models with exter-nal prior knowledge (Liu et al., 2021; Cao et al.,2021; Liu et al., 2023a). However, it can also in-troduce potential bias. For example, consider theevent pairs (winds, blackout) mentioned in Fig-ure 1. While there seems to be no direct causal re- lation from prior knowledge, contextual inferencemakes it reasonable to deduce causality. Uponanalysis, we can observe a causal semantic de-pendency between \"winds\" and \"blackout\": windsknocked down power linescausing blackout. This re-veals that causal relations between events withina sentence often appear as context-dependent se-mantic dependencies. Thus, we claim that the ECItask can be reformulated as a semantic dependencyinquiry task between two events within the context.To this end, we propose a Heuristic SemanticDependency Inquiry Network (SemDI) for the ECItask. The key idea behind SemDI is to explore im-plicit causal relationships guided by contextual se-mantic dependency analysis. Specifically, we firstcapture the semantic dependencies using a unifiedencoder. Then, we randomly mask out one eventfrom the event pair and utilize a Cloze analyzerto generate a fill-in token based on comprehensivecontext understanding. Finally, this fill-in token isused to inquire about the causal relation betweenthe two events in the given sentence. The main con-tributions of this work are summarized as follows:",
  "Related Work": "Identifying causal relationships between events inthe text is challenging and has attracted massiveattention in the past few years (Feder et al., 2022).Early approaches primarily rely on explicit causalpatterns (Hashimoto et al., 2014; Riaz and Girju,2014a), lexical and syntactic features (Riaz andGirju, 2013, 2014b), and causal indicators or sig-nals (Do et al., 2011; Hidey and McKeown, 2016)to identify causality.Recently, representation-based methods lever-aging Pre-trained Language Models (PLMs) have significantly enhanced the ECI performance. Tomitigate the issue of limited training data for ECI,Zuo et al. (2020, 2021b) proposed data augmen-tation methods that generate additional trainingdata, thereby reducing overfitting. Recognizing theimportance of commonsense causal relations forECI, Liu et al. (2021); Cao et al. (2021); Liu et al.(2023a) incorporated external knowledge from theknowledge graph ConceptNet (Speer et al., 2017)to enrich the representations derived from PLMs.However, the effectiveness of external knowledge-based methods is highly contingent on the con-sistency between the target task domain and theutilized knowledge bases, which can introduce biasand create vulnerabilities in these approaches.In contrast to previous methods, Man et al. (2022) introduced a dependency path generationapproach for ECI, explicitly enhancing the causalreasoning process. Hu et al. (2023) exploited twotypes of semantic structures, namely event-centeredstructure and event-associated structure, to captureassociations between event pairs.",
  "Problem Statement": "Let S = [S1, , Sn] R1|S| refer to a sen-tence with |S| tokens, where each token Si is aword/symbol, including special identifiers to in-dicate event pair (Se1, Se2) in causality.Tra-ditional ECI models determine if there exists acausal relation between two events by focusingon event correlations, which can be written asF(S, Se1, Se2) = {0, 1}. Actually, correlationdoes not necessarily imply causation, but it canoften be suggestive. Therefore, this study investi-gates the Semantic Dependency Inquiry (SemDI)as a potential alternative solution to the ECI task.For clarity, we introduce two fundamental prob-lems:Cloze Test.We denote a mask indicator asm = [m1, , m|S|} {0, 1}1|S|, where mi =0 if Si is event token, otherwise mj = 1, j [1, , |S|], j = i. We use S instead of S toexplicitly represent the incomplete sentence, i.e,S = mS. For simplicity, if the event containsmore than one word, we replace all words in theevent with one <MASK> token. The Cloze testin this study is to develop a contextual semantic-based network () to fill in the masked word, i.e.,( S) Sm, where Sm denotes the generatedfill-in token. Semantic Dependency Inquiry. There often ex-ists a semantic dependency between two causallyrelated events, as illustrated in . In lightof this, we propose to inquire about such causal se-mantic dependency between two events within thecontext through the generated fill-in token. Thisapproach aligns with our motivation that causalrelations are heavily context-dependent. To elabo-rate, given the input tuple (S, Sm), a discriminatorD() aims to examine the presence of causal se-mantic dependency in sentence S through Sm, i.e.,D(S, Sm) {0, 1}.",
  "Basic Technique": "The multi-head attention mechanism is the corepart of Transformer (Vaswani et al., 2017) andhas been widely adopted for sequential knowledgemodeling. It measures the similarity scores be-tween a given query and a key, whereafter formu-lating the attentive weight for a value. The canon-ical formulation can be conducted by the scaleddot-product as follows:",
  "(1)": "herein, W{Q,K,V } Rddh are head mapping pa-rameters. Typically, the multi-head attention mech-anism can be categorized into two types: (1) whenA = B, the attention mechanism focuses on therelationship between different elements within thesame input; (2) when A = B, the attention mech-anism captures the relationship between elementsfrom different inputs.",
  "Overview": "This section presents our proposed SemDI model,which reformulates the ECI task as a causal seman-tic dependency inquiry problem. As illustrated in, we first capture the semantic dependen-cies within the source sentence using a SemanticDependency Encoder (SDE). Then, we randomlymask out one event from the event pair and uti-lize a Cloze Analyzer (CA) to generate a fill-intoken based on comprehensive context understand-ing. Finally, this fill-in token is used to inquireabout the causal semantic dependency between thetwo events in a Causality Discriminator. It is worth noting that the SDE and CA share the same parame-ters initialized from a Pre-trained Language Model(PLM), e.g., RoBERTa. The key distinguishing fea-ture of our approach is its full utilization of readingcomprehension within the generative model, elimi-nating the need for additional prior knowledge andprioritizing simplicity and efficiency.",
  "Cloze Analyzer": "It is reasonable to believe that a well-trained deepgenerative model is powerful in context aware-ness (Goswami et al., 2020).In light of this,we adopt a straightforward approach of randomlymasking one event from the event pair, and thenpredicting this event. This approach is inspiredby the literary puzzle Cloze, which plays a crucialrole in our framework. The Cloze facilitates theprediction of the most appropriate fill-in token forthe masked word, thereby revealing the probablesemantic relationships within the given context.Input Embedding Layer aims to encode sen-tences into a latent space.Given a sentenceS = [S1, , Se1, , Se2, , Sn], we correlatea S = S M mask, where denotes the element-wise product and M mask = {m1:n} {0, 1}n indicates the randomly masked word. If mi = 0, itmeans the Si word is masked, which can be eitherSe1 or Se2. In order to adhere to the Cloze puzzlesetting, we utilize two pairs of specification sym-bols <e1>, </e1> and <e2>, </e2> to mark Se1 andSe2 in source sentence S. Importantly, the maskedword does not have the marker, thus resulting in| S| = |S| 2.The input embedding layer encodes the S, S as-sociated with its position. The word embeddingsare trained along with the model and initializedfrom pre-trained RoBERTa word vectors with adimensionality of d = 1024. The specificationsymbol <e> and [mask] are mapped to the ap-pointed tokens, and their embeddings are trainablewith random initialization. The position embed-ding is computed by the sine and cosine functionsproposed by Transformer. Finally, the outputs of agiven sentence from this layer are the sum of theword embedding and position embedding, namelyX and X for simplicity, respectively. The lattercorresponds to a sentence with the masked word.Notably, X R(n+4)d, X R(n+2)d.Semantic Completion Block receives the in-complete sentence X as input, aiming to fill in theblank that is marked by [mask] (i.e., xm). Weleverage a PLM, specifically RoBERTa, to address",
  "(se1 ,se2 )Sy(se1 ,se2 ) logsoftmax(yzWy + by),": "(6)where denotes the model parameters, S refersto all sentences in the training set, (se1, se2) arethe events pairs and y(se1,se2) is a one-hot vectorindicating the gold relationship between se1 andse2. We utilize y(se1,se2) to guide the learning pro-cess in which the generated fill-in token is usedto inquire about the causal semantic dependencieswithin the original sentence, as shown in .It is worth noting that we do not establish a lossfunction to directly guide the generation of fill-intokens. This decision is because we do not requirealignment between the fill-in tokens and the orig-inal words. Instead, our objective is to generatea token based on comprehensive context under-standing, which we then use to inquire about thepresence of a causal relationship. This approachaligns with our main argument: the existence of acausal relationship between two events is heavilycontext-dependent.",
  "Experimental Setup": "Evaluation Benchmarks. We evaluate our SemDIon three widely-used ECI benchmarks, includingtwo from EventStoryLine v0.9 (Caselli and Vossen,2017) and one from Causal-TimeBank (Mirza et al.,2014), namely ESC, ESC*, and CTB. ESC1 con-tains 22 topics, 258 documents, and 5334 eventmentions. This corpus contains 7805 intra-sentenceevent pairs, of which 1770 (22.67%) are annotatedwith causal relations. ESC* is a different partitionsetting of the ESC dataset, utilized by Man et al.(2022); Shen et al. (2022); Hu et al. (2023). Unlikethe original ESC dataset, which sorts documentsby topic IDs, this setting involves random shufflingof documents, leading to more consistent trainingand testing distributions. CTB 2 consists of 183documents and 6811 event mentions. Among the9721 intra-sentence event pairs, 298 (3.1%) areannotated with causal relations. providesstatistics of these benchmarks. More detailed de-scriptions are discussed in Appendix A.2.",
  "ESC25878051770OODESC*25878051770IDCTB1839721298CI": "Baselines.We first compare our proposedSemDI with the feature-based methods. For theESC dataset, we adopted the following baselines:LSTM (Cheng and Miyao, 2017), a dependencypath boosted sequential model; Seq (Choubey andHuang, 2017), a sequence model explores manuallydesigned features for ECI. LR+ and ILP (Gao et al.,2019), models considering document-level struc-ture. For the CTB dataset, we select RB (Mirzaand Tonelli, 2014), a rule-based ECI system; DD(Mirza and Tonelli, 2016), a data-driven machinelearning-based method; VR-C (Mirza, 2014), averb rule-based model boosted by filtered data andcausal signals.Furthermore, we compare SemDI with thefollowing PLMs-based methods:MM (Liu et al., 2021), a commonsense knowledge en-hanced method with mention masking generaliza-tion; KnowDis (Zuo et al., 2020), a knowledge-enhanced distant data augmentation approach;LearnDA (Zuo et al., 2021b), a learnable aug-mentation framework alleviating lack of trainingdata; LSIN (Cao et al., 2021), an approach whichconstructs a descriptive graph to exploit externalknowledge; CauSeRL (Zuo et al., 2021a), a self-supervised method utilizing external causal state-ments; GenECI and T5 Classify (Man et al., 2022),methods that formulates ECI as a generation prob-lem; KEPT (Liu et al., 2023a), a study that lever-ages BERT to integrate external knowledge basesfor ECI; SemSIn (Hu et al., 2023), the previousSOTA method that leverages event-centric structureand event-associated structure for causal reasoning.Similar to our approach, it does not utilize externalknowledge;We also compare SemDI with other state-of-the-art Large Language Models (LLMs), includ-ing GPT-3.5-turbo, GPT-4 (Achiam et al., 2023),and LLaMA2-7B (Touvron et al., 2023). Thesemodels are known for their extensive pre-trainingon diverse datasets and their superior performanceacross multiple tasks.Implementation Details. We adopt the com-monly used Precision, Recall, and F1-score asevaluation metrics. Following the existing stud-ies (Shen et al., 2022; Hu et al., 2023; Liu et al.,2023a), we select the last two topics in ESC as de-velopment set and use the remaining 20 topics fora 5-fold cross-validation. In addition, we performa 10-fold cross-validation on CTB. Given the spar-sity of causality in the CTB dataset, we follow Caoet al. (2021); Hu et al. (2023) to conduct a negativesampling technique for training with a samplingrate of 0.7. The pre-trained RoBERTa-large model(Liu et al., 2019) is chosen as the backbone ofour Cloze Analyzer and Semantic Dependency En-coder. The hidden dimension is 1024, the batchsize is 20, and the dropout rate is 0.5. We trainour model via the AdamW (Loshchilov and Hut-ter, 2017) optimizer with an initial learning rateof 1e 5. The entire training process spans 100epochs and takes approximately 2 hours. Addition-ally, we fine-tune the Llama-2-7b-chat-hf (Touvronet al., 2023) using the LlamaFactory (Zheng et al.,2024). Detailed prompts guiding LLMs to identifycausality are provided in Appendix A.1. All exper-iments are conducted on one Nvidia GeForce RTX3090.",
  ": Experimental results on ESC and ESC*. *denotes experimental results on ESC* and ft denotesfine-tuning the LLM": "and present the performance ofdifferent approaches on three benchmarks, respec-tively. The best scores are highlighted in bold,while the second-best scores are underlined. Wesummarize our observations as follows:SemDI consistently outperforms all baselinesin terms of the F1-score.More specifically,SemDI surpasses the previous SOTA methods bysignificant margins of 4.1, 7.4, and 8.7 in F1-scoreon the ESC, ESC*, and CTB datasets, respectively.This result aligns with our motivation, as prioritiz-ing the context-dependent nature of causal relationsenables the model to identify causality more accu-rately, thereby mitigating potential bias introducedby external prior knowledge.Domain Generalization Ability. On the ESCdataset, ECI models need to generalize to test top-ics Dtest that are disjoint from the training topicsDtrain, i.e., Dtrain Dtest = . From ,we observe that SemDI demonstrates superior per-formance under this Out-of-Distribution (OOD)",
  ": Experimental results on CTB. ft denotes fine-tuning the LLM": "testing. This result verifies SemDIs potential asa general framework for event causality identifica-tion. Furthermore, training and testing distributionsare more consistent under the ESC* dataset, result-ing in relatively higher performance.Comparison with PLMs-based Methods.Compared to LearnDA, which achieves the second-highest Recall score on the ESC dataset (at the topof ), SemDI shows a significant improve-ment of 34.3% in Precision. This indicates thatSemDI is more reliable in decision-making. It isunderstandable that LearnDA achieves better recall,as it can generate additional training event pairs be-yond the training set. While KEPT shares the samefundamental architecture with SemDI, it mainly fo-cuses on integrating external knowledge for causalreasoning. In contrast, SemDI highlights the impor-tance of contextual semantic dependency analysis,outperforming KEPT by a significant margin.Comparison with LLMs. Our SemDI modeldemonstrates superior performance compared tostate-of-the-art Large Language Models (LLMs)across all benchmarks, despite its significantlysmaller size.Specifically, SemDI (368M pa-rameters) is 19 times smaller than fine-tunedLLaMA2-7B, yet it achieves an average improve-ment of 177.8% in F1-score. The efficiency ofSemDI makes it ideal for deployment in resource-constrained and time-demanding environments.Additionally, we observe that LLMs often exhibitoverconfidence in determining causal relationships,resulting in high recall but low precision. This ob-",
  "Ablation Study": "In this subsection, we conduct comprehensive ab-lation studies to demonstrate the effectiveness ofour key components, including the Cloze Analyzer(CA), the Semantic Dependency Encoder (SDE),and the backbone model RoBERTa. Concretely,we remove Cloze Analyzer and utilize the originalevent embedding for causality inquiry in SemDIw/o CA. In SemDI w/o SDE, we remove the Se-mantic Dependency Encoder and directly feed theembedding of the generated fill-in token to the clas-sifier, thus omitting the causality inquiry process.In SemDI w/o RoBERTa, we replace the backboneRoBERTa-large model with a BERT-large model.The results are shown in .From this table, we observe that: (1) SemDIoutperforms all the variants, demonstrating the ef-fectiveness of multiple components in SemDI, in-cluding the generation of fill-in token for causal-ity inquiry, the encoding of semantic dependency,and the backbone selection. (2) SemDI w/o CAperforms worse than SemDI, which indicates theimportance of using a generated fill-in token to per-form causality inquiry. Using the original tokenembedding that lacks the comprehensive contextunderstanding for causality inquiry will lead to per-formance degradation. (3) SemDI w/o SDE showsthe worst performance. This result is not surprising,as the analysis and inquiry of semantic dependencyplay the most crucial role in our approach to de-tecting causal relations. (4) Even if we replace thebackbone RoBERTa model with a less optimizedBERT model, our approach still outperforms theexisting SOTA methods, including KEPT, SemSIn,and GPT-4.0, whose results are shown in",
  "Interpretability Analysis": "In this subsection, we visualize the causality in-quiry process in SemDI to demonstrate its inter-pretability. Specifically, in this process, the gener-ated fill-in token is used to inquire about the causalsemantic dependencies between two events withinthe context, as shown in the middle of .We randomly select two examples from the ESCdataset and present their attention heatmap of thecausality inquiry process in . It can beobserved that the causality inquiry process can ef-fectively uncover the intricate semantic dependen-cies between two events. For example, SemDItends to uniformly distribute its attention to the sen-tence with non-causal event pairs, as shown in theheatmap of the second sentence. In contrast, wecan observe a clear causal semantic dependency be-tween \"winds\" and \"blackout\" in the heatmap of thefirst sentence: winds power lines blackout.This phenomenon not only supports our motivationthat causal relations are heavily context-dependent,but also demonstrates the effectiveness of usinggenerated fill-in token to inquire about such causalsemantic dependencies.",
  "Robustness Analysis": "We now evaluate how different selections of keyhyper-parameters impact our models performance.Impact of hidden size. We further analyze theimpact of hidden size on two classic dimensions,768 and 1024, as depicted in , where theshaded portion corresponds to 1024. From theseresults, we observe that: (1) Even if we reduce thehidden size from 1024 to 768, our SemDI still out-performs the previous SOTA methods, confirmingits effectiveness and robustness. (2) The overall per-formance of SemDI shows a significant improve-ment with an increase in hidden size, particularlyfor the CTB dataset. This phenomenon can beattributed to the enhanced representation capabil-ity brought by higher model dimensions (Kaplanet al., 2020), which in turn facilitate reading com-prehension - the core part of SemDI. (3) SemDIis relatively sensitive to the hidden size under low-resource scenarios (CTB) while maintaining goodperformance with sufficient annotated data for train-ing (ESC and ESC*).",
  ": Robustness analysis on masking strategy ap-plied in the Cloze Test": "masking strategy applied in this Cloze test, we con-duct further experiments on the ESC dataset withthree specific approaches: (1) randomly mask e1 ore2 with a 50/50 chance (Random); (2) \"100% maske1\" (Event1 only); (3) \"100% mask e2\" (Event2only). As shown in , our SemDI maintainssuperior performance under all approaches in termsof the F1-score, confirming its robustness to vary-ing masking strategies.",
  "Case Studies": "In this subsection, we present case studies in Ta-ble 5 to further analyze the performance of SemDI.It is worth noting that tied embeddings are em-ployed to map the fill-in tokens to specific words.In case 1, we can observe a clear causal semanticdependency: murdercausing questioned. With acomprehensive understanding of the context, theCloze Analyzer can generate a fill-token that fitsseamlessly within the given context, i.e., (ques-tioned, investigated). Case 2 demonstrates a faultydecision, likely due to the complex multi-hop rea-soning required. Interestingly, the fill-in token \"re-tired\" also sharply contrasts with the original word\"escorted.\" This misalignment may suggest a fail-ure of SemDI to understand the semantic depen-dency between two events within the context.",
  "In this paper, we present SemDI, a simple and ef-fective semantic dependency inquiry approach for": "Event Causality Identification. We first encodethe semantic dependencies using a unified encoder.Subsequently, we utilize a Cloze Analyzer to gener-ate a fill-in token based on comprehensive contextunderstanding. This token is then used to inquireabout the causal relation between two events withinthe context. Extensive experiments on three widelyrecognized datasets demonstrate the superior per-formance of SemDI while highlighting its robust-ness and efficiency.",
  "The limitations of this work can be concluded asfollows:": "1. SemDI exhibits sensitivity to the quantity ofannotated event pairs available for training.Consequently, it demonstrates reduced accu-racy in capturing causal relations within theCTB dataset, as illustrated in Table. 3. There-fore, further improvements are needed to en-hance its performance in low-resource scenar-ios. 2. While acknowledging the potential for biasintroduced by external knowledge, we arguethat incorporating commonsense is crucial forECI. SemDI concentrates on investigating theeffectiveness of semantic dependency inquiryfor ECI, leaving the opportunity to take advan-tage of commonsense reasoning. Investigat-ing how to properly integrate commonsensereasoning within the semantic-guided frame-work presents a promising avenue for futureresearch.",
  "This work was supported by the Guanghua TalentProject": "Josh Achiam, Steven Adler, Sandhini Agarwal, LamaAhmad, Ilge Akkaya, Florencia Leoni Aleman,Diogo Almeida, Janko Altenschmidt, Sam Altman,Shyamal Anadkat, et al. 2023. Gpt-4 technical report.arXiv preprint arXiv:2303.08774. Prithviraj Ammanabrolu, Wesley Cheung, WilliamBroniec, and Mark O Riedl. 2021. Automated sto-rytelling via causal, commonsense plot ordering. InProceedings of the AAAI Conference on ArtificialIntelligence, volume 35, pages 58595867. Pengfei Cao, Xinyu Zuo, Yubo Chen, Kang Liu, JunZhao, Yuguang Chen, and Weihua Peng. 2021.Knowledge-enriched event causality identificationvia latent structure induction networks. In Proceed-ings of the 59th Annual Meeting of the Association forComputational Linguistics and the 11th InternationalJoint Conference on Natural Language Processing(Volume 1: Long Papers), pages 48624872. Tommaso Caselli and Piek Vossen. 2017. The eventStoryLine corpus: A new benchmark for causal andtemporal relation extraction. In Proceedings of theEvents and Stories in the News Workshop, pages 7786, Vancouver, Canada. Association for Computa-tional Linguistics. Fei Cheng and Yusuke Miyao. 2017. Classifying tempo-ral relations by bidirectional LSTM over dependencypaths. In Proceedings of the 55th Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 2: Short Papers), pages 16, Vancouver, Canada.Association for Computational Linguistics. Prafulla Kumar Choubey and Ruihong Huang. 2017. Asequential model for classifying temporal relationsbetween intra-sentence events. In Proceedings ofthe 2017 Conference on Empirical Methods in Natu-ral Language Processing, pages 17961802, Copen-hagen, Denmark. Association for Computational Lin-guistics. Quang Do, Yee Seng Chan, and Dan Roth. 2011. Min-imally supervised event causality identification. InProceedings of the 2011 conference on empiricalmethods in natural language processing, pages 294303. Amir Feder, Katherine A. Keith, Emaad Manzoor, ReidPryzant, Dhanya Sridhar, Zach Wood-Doughty, Ja-cob Eisenstein, Justin Grimmer, Roi Reichart, Mar-garet E. Roberts, Brandon M. Stewart, Victor Veitch,and Diyi Yang. 2022. Causal inference in natural lan-guage processing: Estimation, prediction, interpreta-tion and beyond. Transactions of the Association forComputational Linguistics, 10:11381158. Lei Gao, Prafulla Kumar Choubey, and Ruihong Huang.2019. Modeling document-level causal structures forevent causal relation identification. In Proceedingsof the 2019 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies, Volume 1 (Long andShort Papers), pages 18081817, Minneapolis, Min-nesota. Association for Computational Linguistics. Ankur Goswami, Akshata Bhat, Hadar Ohana, andTheodoros Rekatsinas. 2020. Unsupervised relationextraction from language models using constrainedcloze completion. In Findings of the Associationfor Computational Linguistics: EMNLP 2020, pages12631276, Online. Association for ComputationalLinguistics.",
  "Chikara Hashimoto, Kentaro Torisawa, Julien Kloet-zer, Motoki Sano, Istvn Varga, Jong-Hoon Oh, and": "Yutaka Kidawara. 2014. Toward future scenario gen-eration: Extracting event causality exploiting seman-tic relation, context, and association features.InProceedings of the 52nd Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 987997, Baltimore, Maryland.Association for Computational Linguistics. Christopher Hidey and Kathleen McKeown. 2016. Iden-tifying causal relations using parallel wikipedia arti-cles. In Proceedings of the 54th Annual Meeting ofthe Association for Computational Linguistics (Vol-ume 1: Long Papers), pages 14241433. Zhilei Hu, Zixuan Li, Xiaolong Jin, Long Bai, SaipingGuan, Jiafeng Guo, and Xueqi Cheng. 2023. Seman-tic structure enhanced event causality identification.In Proceedings of the 61st Annual Meeting of theAssociation for Computational Linguistics (Volume 1:Long Papers), pages 1090110913, Toronto, Canada.Association for Computational Linguistics. Jia-Hong Huang, Chao-Han Huck Yang, Pin-YuChen, Min-Hung Chen, and Marcel Worring. 2023.Causalainer: Causal explainer for automatic videosummarization. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recog-nition, pages 26292635.",
  "Hieu Man, Minh Nguyen, and Thien Nguyen. 2022": "Event causality identification via generation of impor-tant context words. In Proceedings of the 11th JointConference on Lexical and Computational Semantics,pages 323330, Seattle, Washington. Association forComputational Linguistics. Sabrina J. Mielke, Arthur Szlam, Emily Dinan, and Y-Lan Boureau. 2022. Reducing conversational agentsoverconfidence through linguistic calibration. Trans-actions of the Association for Computational Linguis-tics, 10:857872.",
  "Paramita Mirza. 2014. Extracting temporal and causalrelations between events. In Proceedings of the ACL2014 Student Research Workshop, pages 1017": "Paramita Mirza, Rachele Sprugnoli, Sara Tonelli, andManuela Speranza. 2014. Annotating causality inthe TempEval-3 corpus.In Proceedings of theEACL 2014 Workshop on Computational Approachesto Causality in Language (CAtoCL), pages 1019,Gothenburg, Sweden. Association for ComputationalLinguistics. Paramita Mirza and Sara Tonelli. 2014. An analysis ofcausality between events and its relation to tempo-ral information. In Proceedings of COLING 2014,the 25th International Conference on ComputationalLinguistics: Technical Papers, pages 20972106.",
  "Qiang Ning, Zhili Feng, Hao Wu, and Dan Roth. 2018": "Joint reasoning for temporal and causal relations. InProceedings of the 56th Annual Meeting of the As-sociation for Computational Linguistics (Volume 1:Long Papers), pages 22782288, Melbourne, Aus-tralia. Association for Computational Linguistics. Mehwish Riaz and Roxana Girju. 2013. Toward a betterunderstanding of causality between verbal events:Extraction and analysis of the causal power of verb-verb associations. In Proceedings of the SIGDIAL2013 Conference, pages 2130. Mehwish Riaz and Roxana Girju. 2014a. In-depth ex-ploitation of noun and verb semantics to identifycausation in verb-noun pairs. In Proceedings of the15th Annual Meeting of the Special Interest Group onDiscourse and Dialogue (SIGDIAL), pages 161170. Mehwish Riaz and Roxana Girju. 2014b. Recognizingcausality in verb-noun pairs via noun and verb seman-tics. In Proceedings of the EACL 2014 Workshop onComputational Approaches to Causality in Language(CAtoCL), pages 4857. Shirong Shen, Heng Zhou, Tongtong Wu, and GuilinQi. 2022. Event causality identification via deriva-tive prompt joint learning. In Proceedings of the29th International Conference on Computational Lin-guistics, pages 22882299, Gyeongju, Republic ofKorea. International Committee on ComputationalLinguistics.",
  "Robyn Speer, Joshua Chin, and Catherine Havasi. 2017.Conceptnet 5.5: An open multilingual graph of gen-eral knowledge. In Proceedings of the AAAI confer-ence on artificial intelligence, volume 31": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023.Llama 2:Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288. Ashish Vaswani, Noam Shazeer, Niki Parmar, JakobUszkoreit, Llion Jones, Aidan N Gomez, ukaszKaiser, and Illia Polosukhin. 2017. Attention is allyou need. Advances in neural information processingsystems, 30.",
  "Yaowei Zheng, Richong Zhang, Junhao Zhang, YanhanYe, Zheyan Luo, and Yongqiang Ma. 2024. Llamafac-tory: Unified efficient fine-tuning of 100+ languagemodels. arXiv preprint arXiv:2403.13372": "Xinyu Zuo, Pengfei Cao, Yubo Chen, Kang Liu, JunZhao, Weihua Peng, and Yuguang Chen. 2021a.Improving event causality identification via self-supervised representation learning on external causalstatement. In Findings of the Association for Com-putational Linguistics: ACL-IJCNLP 2021, pages21622172, Online. Association for ComputationalLinguistics. Xinyu Zuo, Pengfei Cao, Yubo Chen, Kang Liu, JunZhao, Weihua Peng, and Yuguang Chen. 2021b.LearnDA: Learnable knowledge-guided data augmen-tation for event causality identification. In Proceed-ings of the 59th Annual Meeting of the Association forComputational Linguistics and the 11th InternationalJoint Conference on Natural Language Processing(Volume 1: Long Papers), pages 35583571, Online.Association for Computational Linguistics.",
  "A.1Prompt": "In Sec 5.1, we utilize a prompt to guide the LLMs,including GPT-3.5-turbo, GPT-4, and LLaMA2-7B, to identify causal relations between two eventswithin the sentence. We detail the prompt as fol-lows.\"Given a sentence: {sentence}, decide if thereexists a causal relation between {event_1} and{event_2} in this sentence. Your answer shouldbe yes or no.\"We also provide two examples from the ESC andCTB dataset in . ESCGiven a sentence: \"Strong winds knocked downpower lines, causing a blackout.\", decide if thereexists a causal relation between \"winds\" and\"blackout\" in this sentence. Your answer shouldbe yes or no. CTBGiven a sentence: \"He indicated that some assetsmight be sold off to service the debt.\", decideif there exists a causal relation between \"indi-cated\" and \"service\" in this sentence. Your an-swer should be yes or no.",
  "In this subsection, we provide detailed descriptionsfor the three datasets we used in experiments, i.e.,ESC, ESC*, and CTB": "ESC. This dataset contains 22 topics, 258documents, and 5334 event mentions. Thesame as (Gao et al., 2019), we exclude as-pectual, causative, perception, and reportingevent mentions, since most of which werenot annotated with any causal relation. Af-ter the data processing, there are 7805 intra-sentence event mention pairs in the corpus,1770 (22.67%) of which are annotated with acausal relation. Identical to the data split inprevious methods (Hu et al., 2023; Zuo et al.,2021b), we select the last two topics in ESC asdevelopment set and use the remaining 20 top-ics for a 5-fold cross-validation. Note that thedocuments are sorted according to their topic IDs under this data partition setting, whichmeans that the training and test sets are cross-topic. Due to the distribution gap betweenthe training and test sets, the domain gener-alization ability of the model can be betterevaluated. ESC*. This dataset is a different partitioningof the ESC dataset. More specifically, it ran-domly shuffles the documents before training.Therefore, the distributions of the training andtest sets are more consistent, because both twosets contain data on all topics. The experimen-tal results under this setting can better demon-strate the models ability to identify causalrelations in topic-centered documents, whichare common in real-world scenarios. CTB. CTB consists of 183 documents and6811 event mentions. Among the 9721 intra-sentence event pairs, 298 (3.1%) are anno-tated with causal relations. Given the sparsityof causality in the CTB dataset, we follow ex-isting works (Cao et al., 2021; Hu et al., 2023)to conduct a negative sampling technique fortraining with the sampling rate of 0.7."
}