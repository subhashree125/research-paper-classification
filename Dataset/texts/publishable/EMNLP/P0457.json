{
  "Abstract": "Large language models (LLMs) have shownsurprisingly good performance in multilingualneural machine translation (MNMT) even ifnot being trained explicitly for translation. Yet,they still struggle with translating low-resourcelanguages. As supported by our experiments,a bilingual dictionary between the source andthe target language could help. Motivated bythe fact that multilingual training effectively im-proves cross-lingual performance, we show thata chained multilingual dictionary with wordsexpressed in more languages can provide moreinformation to better enhance the LLM transla-tion. To this end, we present a novel framework,COD, Chain-of-Dictionary Prompting, whichaugments LLMs with prior knowledge with thechains of multilingual dictionaries for a subsetof input words to elicit translation abilities forLLMs. Experiments indicate that ChatGPT andInstructGPT still have room for improvementin translating many language pairs. And CODelicits large gains by up to 13x chrF++ pointsfor MNMT (3.08 to 42.63 for English to Ser-bian written in Cyrillic script) on FLORES-200full devtest set. We demonstrate the impor-tance of chaining the multilingual dictionaries,as well as the superiority of COD to few-shotin-context learning for low-resource languages.Using COD helps ChatGPT to obviously sur-pass the SOTA translator NLLB 3.3B.1",
  "Introduction": "Large language models (LLMs) possess the abilityto carry out high-quality machine translation taskswithout specific training, as observed in previousstudies (Brown et al., 2020; Lin et al., 2022; LeScao et al., 2022; Zhang et al., 2022; Wang et al., This research/paper was partially supported by the Cen-ter for Perceptual and Interactive Intelligence (CPII) Ltd. un-der the Innovation and Technology Commissions InnoHKscheme. Equal Contribution.1Code and resources available at 2023; Tang et al., 2024). LLMs can be promptedto do so by requesting them to complete a prompt,such as Translate the following sentence to En-glish from French: followed by an input sentencewritten in French. However, despite their trainingon extensive datasets, these models may encounterdifficulties in correctly translating rare words thatfrequently occur in low-resource situations.Motivated by such a lexical-level problem, weseek how to incorporate dictionaries for improvingMNMT. Further, motivated by the fact that multilin-gual training effectively improves cross-lingual per-formance (Liu et al., 2020; Lu et al., 2023, 2024),we use multilingual dictionaries to enhance thetranslation performance of LLM prompting.To this end, we leverage the multilingual dic-tionaries as the prior knowledge, and we describea method to prompt LLMs with hints that indi-cate a set of possible chained multilingual transla-tions for specific words in the input. This methodinvolves adding a string such as limit meansGrenze means k. to the start of the standardmachine translation prompt as lexicon hints for MT.This approach is motivated by the fact that super-vised machine translation models have effectivelyused dictionaries to enhance translation (Zhangand Zong, 2016; Arthur et al., 2016; Zheng et al.,2021). We also propose the method as a chain ofdictionary in the light of Chain-of-Thought (CoT)reasoning (Wei et al., 2022) that represents the rea-soning procedure as intermediate thinking steps. Inour case, we show how to incorporate multilingualknowledge in a zero-shot manner by chaining thetranslations of words across various languages toimprove LLMs MNMT capabilities. This allowsus to specify the task in the prompt and providebackground knowledge that is useful in completingthe task of machine translation, without placingany strict constraints on how the model employsthis knowledge, as demonstrated in .We conducted extensive experiments with the",
  "Translation Output": ": An illustration for COD for English to Tamil translation. COD consists of two sections: the standardtranslation prompt (the upper box) and the chained multilingual dictionaries. We highlight by languages the chaineddictionary part for COD, containing the words and their translations in different languages. COD outperformsstandard prompting in this example, and other methods such as the conventional Chain-of-Thought have been shownas less effective for MT (Peng et al., 2023). We bold the text for the actual inputs/outputs. Other non-bolded textsare placed for the explanation to the readers. novel framework we propose, namely COD (Chain-of-Dictionary Prompting for Machine Translation),which achieved notable improvements in low-resource translation on FLORES-200 benchmarks(NLLB-Team, 2022) between English to almost allthe other languages, using various language models.To gain a better understanding of CODs capabil-ities, we analyzed and examined the models be-haviour by comparing it to both settings that incor-porate bilingual dictionaries as well as separatingthe word mappings instead of chaining the multilin-gual dictionaries. COD achieves the best empiricalperformance, which demonstrates its necessity inchaining the multilingual dictionary. Also, our ex-periments demonstrate that COD achieves betterperformance than the standard few-shot demonstra-tions for low-resource languages. We speculatethat the retrieved few-shot demonstrations are notrelevant to the target translation, and therefore notparticularly useful for low-resource translations.Our main contributions are three-fold: This paper proposes a novel framework calledCOD (Chain-of-Dictionary Prompting for Ma-chine Translation) which adds chains of multi-lingual dictionaries to prompt LLMs that sub-stantially improve machine translation.",
  "We conduct experiments on FLORES-200 for": "all translation directions between English andother languages. We observe that ChatGPTand InstructGPT still have room for improve-ment in translating many language pairs. Wefound that COD can improve ChatGPT on alarge portion of the languages, and can elicittranslation in some languages that ChatGPTalmost completely fails in translating. We observe that COD can also be favourableto few-shot demonstrations, and COD onChatGPT can even surpass the SOTA trans-lator NLLB 3.3B. We also verify that it ispossible to save computation by truncatingstopwords from the dictionary.",
  "Chain-of-Dictionary Prompting forNeural Machine Translation": "Large language models show their promising trans-lation performance when sufficiently pre-trained(Lu et al., 2023; Wang et al., 2023). However, thisis frequently not the case, especially for these low-resource languages. There are thousands of lan-guages around the world, and current research onMT has scaled to at least 200 (NLLB-Team, 2022).It is an important research topic to explore the ca-pabilities of LLMs to cover as many languages aspossible. Despite the importance of covering low-resource languages in LLMs, we will report in this paper that the latest LLMs are still far from satisfy-ing in covering these low-resource languages fromFLORES-200 (NLLB-Team, 2022).We propose a novel framework called COD(Chain-of-Dictionary Prompting) to address thesedifficulties by chaining multilingual dictionaryknowledge into prompting-based machine trans-lation. Compared to in-context learning that usesfew-shot demonstrations to prompt the LLMs, dic-tionaries are comparatively easier to store andacquire than the demonstrations, particularly forlow-resource languages (Zhang and Zong, 2016;Arthur et al., 2016; Hmlinen and Alnajjar, 2020;Ghazvininejad et al., 2023). This makes COD anattractive external resource for MT with LLMs.Our novel approach, COD, utilizes prompting-based translation and integrates chained multilin-gual dictionary information as prior knowledge di-rectly into the prompt. When presented with asource sentence, we search for the multilingualdictionary entries for a subset of the words: be-fore making the conventional translation request toLLMs, we append additional textual inputs to theprompt that outline possible chained multilingualtranslations for those specific words.Therefore, the prompts for each sentence consistof two parts, as illustrated in : (1) the translation prompt: Translate thefollowing text from <source-language> into<target-language>: <source-sentence>.(2) the chained multilingual dictionaries:<word X in source-language> means <wordX in target-language> means <word X inauxiliary-language 1> means <word X inauxiliary-language 2>.; We do not include few-shot in-context learningin our methodology as we inspected that it is usu-ally hard to retrieve relevant demonstrations forlow-resource languages, which yields limited im-provements. In the remaining sections, we willreport relevant experimental results which indicatethat few-shot demonstrations are less favourable toour methods for low-resource translations.We also found that using non-chained decom-posed multilingual dictionaries instead of CODdegrades the results:<word X in source-language> means <wordX in target-language>.<word X in source-language> means <word X in auxiliary-language1>. <word X in source-language> means <word X",
  "in auxiliary-language 2>.2": "We evaluate Machine Translation performancefor all available languages using the LLM which wesubsequently enhance with COD. We then employtop languages that report the highest evaluationscores as our auxiliary languages to construct ourmultilingual dictionaries. Multilingual DictionaryWe propose to use theprompt Extract the words from the following texts:<input-sentence> to extract the keywords fromthe source language with LLMs such as ChatGPT.We then translate the extracted words into differentlanguages with off-the-shelf MT models such asNLLB to create the dictionaries for COD. Duringinference, the matched keywords and their trans-lations are extracted from the dictionary to be ap-pended to the translation prompt.We use French (fra_Latn), German (deu_Latn),and Portuguese (por_Latn), three high-resource lan-guages that our LLM performs well on, as our aux-iliary languages for multilingual dictionaries. Thismeans that we have a chain of 5 languages in theprompt, including the three auxiliary languagesmentioned above and the source and the target lan-guage. We leave the exploration of further chainingto future work.",
  "Baselines": "We experiment with ChatGPT, a multilingual largelanguage model that has shown strong abilities forthe task of machine translation (Wang et al., 2023).At the time of writing, this LLM was widely popu-lar. We experiment with ChatGPT to test COD. Wealso conduct experiments on InstructGPT with theversion of text-davinci-003 as well as BLOOM-7b(Le Scao et al., 2022):",
  "Monolingual Dictionary: This is a baselinethat uses a monolingual dictionary that con-tains the words from the target language only": "Bilingual Dictionary:This is a baselinethat uses a bilingual dictionary for promptinglarge language models on the task of machinetranslation (Zhang and Zong, 2016; Arthuret al., 2016; Hmlinen and Alnajjar, 2020;Ghazvininejad et al., 2023). It replaces themultilingual dictionaries in blue from with a bilingual dictionary built with thesource language and the target language forthe task of MT. Decomposed Dictionary: This is a baselinethat removes the chaining of the dictionaryand replaces the chained multilingual dictio-naries in blue from with decomposedmultilingual dictionaries. Refer to for more details of this baseline model. Few-shot Demonstration: This is a baselinethat does not use any dictionary. Instead, itretrieves from FLORES-200 devtest the topone/three translation pairs that are semanti-cally similar to the current input translation,measured by BertScore (Zhang* et al., 2020)using the English sentences.",
  "Datasets and Evaluation Metrics": "For our evaluations on the task of machine trans-lation for various languages including many low-resource languages, we use the dev-test divisionfrom FLORES-200 benchmarks (NLLB-Team,2022), There are 1,012 sentences included inthe dataset, which were extracted from EnglishWikipedia covering a variety of topics and domains.These sentences have been manually curated byprofessional translators into about 200 languages.We report on all the languages in FLORES-200for both directions from English and into English. For the evaluation metrics, we report the chrF++(Popovic, 2015) and the BLEU (Papineni et al.,2002) evaluations provided by the sacreBLEUrepository.3 We use the model [eamt22-cometinho-da]4 for generating the COMET scores (Rei et al.,2020).",
  "Dictionaries": "To create the offline dictionaries used in our ex-periments, we first use the prompt Extract thewords from the following texts: <input-sentence>to extract the keywords from the source languagewith LLMs such as ChatGPT. We then use theNLLB translator5 to translate the monolingual En-glish corpus from FLORES-200 into the remaininglanguages as our dictionaries. We excluded threelanguages which are not supported by the NLLBtranslator from our experiments. We use an off-the-shelf stopwords list for experiments on truncatingstopwords to save computations with COD.6 We use the English corpora from FLORES-200to create our dictionary in this paper. For experi-ments on translating into English, we remove theEnglish reference words from the dictionary to en-sure there is no information leakage.",
  "Dictionary Quality": "With NLLB 3.3B, we translated the words intorare words with multiple attempts and translatedthem back into English. We then asked ChatGPTwhether the translated-back version had the equiva-lent meaning to the original English. The processwas done repeatedly until GPT reported that theywere the same or the max tries (3 times) had beenhit. In this manner, 71% of the words are success-fully translated without hitting the max tries. Forthose failed translations, we exclude them from thedictionaries used by the bilingual chain or COD.",
  "Prompting Design": "This section outlines the prompt design we optedfor in creating the green text depicted in .Prior work compared various prompts for ma-chine translation on LLM (Wang et al., 2023), andthey have found similar performance of differentprompts reported on a limited number of languages.They have opted for a basic prompt Translate the following text into <target-language>: <source-sentence> as their best prompt. In contrast, ourpreliminary experiments show that removing thesource language name can hurt the performanceof translation. Therefore, we opted for Translatethe following text from <source-language> into<target-language>: <source-sentence>.Our preliminary experiments show that missingthe keyword Tradition Script for Chinese promptsthe model to keep generating Simplified Chinese.Therefore, we specify the language script in ourprompt when the languages can be written in dif-ferent scripts and should be differentiated. Forexample, we write Achinese with Arabic scriptfor the language ace_Arab.",
  "En-X Results": "En-X: ChatGPTWe firstly compare ChatGPT(GPT-3.5-TURBO) with the normal prompt inchrF++ on FLORES-200 with COD. We plot theresults in for better clarity. In ,we sort the chrF++ scores from ChatGPT in de-scending order, and we split the whole results intotwo figures. The upper figure represents the firsthalf, and the bottom figure represents the secondhalf. It can be observed in the bottom figure thatChatGPT does not handle the translation perfectlyand it reports a score under 30 points in chrF++ foraround 100 out of the 200 languages. The resultsindicate that COD brings clear improvements. Forspace reasons, we leave in the Appendixto present the detailed results for translating fromEnglish into the remaining languages. inthe Appendix also reports the detailed BLEU eval-uations. Those results also indicate strong improve-ments with COD. We speculate there are two rea-sons for improvement with COD. Firstly, puttingthe desired translation target lexical shrinks thetranslation space and eases the translation. Sec-ondly, using auxiliary languages in the chain givesbetter cross-lingual cues when there is no directmapping between source and target lexical. En-X: Languages Improved on ChatGPTTa-ble 1 reports that more than 67% (135 out of 200) ofthe languages can be improved by COD. For thoselanguages that can be improved by COD, morethan 50% (71 out of 135) is improved by at least 5points in chrF++. 13 languages can be improvedby at least 10 points in chrF++ and 2 languages can be improved by at least 20 points in chrF++.We also observe quite strong results with COD thatbring 13x improvement (3.08 to 42.63) when trans-lating from English into Serbian written in Cyrillicscript. This leads to the conclusion that COD givespromising results with good improvements in mostlanguages and excellent improvements in severallanguages. COD can even elicit translation in somelanguages that ChatGPT almost completely fails intranslating, which is quite promising. En-X: Languages Not Improved on ChatGPTAs in , some languages are not benefitedfrom COD. We observe there are no languages withmore than 20 points of decrease in chrF++ withCOD, and there are only 2 languages with morethan 5 points of decrease in chrF++ with COD.Compared to the languages with improvements re-ported above, the advantages of using COD clearlyoutweigh the disadvantages when used indistin-guishably regardless of the languages. En-X: Languages SelectionThough one coulduse COD regardless of the languages, it will be bet-ter to use COD only for those low-resource ones.This can be told visually from that CODbrings better improvements for the bottom figurethat the baseline reports lower scores compared tothe upper figure with higher baseline scores. The se-lection can be done with a threshold on the scores,and we observe that for those languages with abaseline score under 20 points in chrF++, CODbrings consistent improvements. We found usingour universal list of high-resource auxiliary lan-guages performs well and one can tune the list forspecific languages for further improvements.7 En-X: COMET ScoresWe first obtain 99 lan-guages out of the 200 languages from FLORES-200, which is supported by COMET (this list isobtained by matching the language names to thedescription in the official COMET repository)8 Ta-ble 4 reports COMET scores, which aligns withour previous conclusion and indicates that COD iseffective. The average score of COMET is 0.325for COD, which is apparently higher than 0.277from the baseline. We also found the same conclu-sion in the remaining 101 languages not perfectly 7We have found putting source and target language at thehead of the chain empirically works well via early attempts.We empirically suggest to set the chain length as 5. Furtherincreasing the length can further improve the information,while making the method less cost-effective.8 por_Latn fra_Latn dan_Latn ind_Latn swe_Latn afr_Latn cat_Latn deu_Latn zsm_Latn ron_Latn cym_Latn nob_Latn bul_Cyrl glg_Latn swh_Latn bos_Latn ita_Latn vie_Latn tgl_Latn epo_Latn nld_Latn hrv_Latn nno_Latn tur_Latn ces_Latn rus_Cyrl fin_Latn spa_Latn est_Latn slv_Latn mkd_Cyrl slk_Latn ast_Latn als_Latn ukr_Cyrl hun_Latn lvs_Latn arb_Arab oci_Latn ceb_Latn lit_Latn ell_Grek pol_Latn pap_Latn ars_Arab heb_Hebr hin_Deva pes_Arab ltz_Latn hat_Latn war_Latn mlt_Latn acq_Arab ajp_Arab apc_Arab isl_Latn gle_Latn prs_Arab acm_Arab eus_Latn arz_Arab urd_Arab tha_Thai aeb_Arab vec_Latn jav_Latn mri_Latn lim_Latn fur_Latn fao_Latn mag_Deva srd_Latn gla_Latn ilo_Latn uzn_Latn ben_Beng sun_Latn tpi_Latn npi_Deva azj_Latn min_Latn bel_Cyrl jpn_Jpan ary_Arab kea_Latn guj_Gujr scn_Latn kan_Knda bjn_Latn tam_Taml pan_Guru kor_Hang awa_Deva hne_Deva zho_Hans smo_Latn ban_Latn fij_Latn plt_Latn tel_Telu ChrF++ CoDGPT-3.5-TURBO mar_Deva kat_Geor kaz_Cyrl szl_Latn mal_Mlym hau_Latn hye_Armn ydd_Hebr som_Latn pag_Latn mai_Deva lus_Latn lij_Latn tgk_Cyrl ltg_Latn bho_Deva nya_Latn lmo_Latn zul_Latn kmr_Latn tsn_Latn sot_Latn lin_Latn nso_Latn xho_Latn tso_Latn sna_Latn crh_Latn ory_Orya ace_Latn kir_Cyrl kin_Latn khk_Cyrl zho_Hant tuk_Latn ssw_Latn quy_Latn twi_Latn lug_Latn run_Latn bem_Latn yue_Hant aka_Latn ibo_Latn tum_Latn snd_Arab kon_Latn ayr_Latn lua_Latn kam_Latn lao_Laoo bod_Tibt tat_Cyrl mya_Mymr bak_Cyrl gaz_Latn asm_Beng kik_Latn luo_Latn uig_Arab khm_Khmr grn_Latn sin_Sinh dzo_Tibt kab_Latn pbt_Arab ewe_Latn wol_Latn kmb_Latn cjk_Latn san_Deva knc_Latn taq_Latn umb_Latn bam_Latn bug_Latn fuv_Latn dik_Latn sag_Latn yor_Latn mos_Latn kas_Arab dyu_Latn ckb_Arab kas_Deva taq_Tfng bjn_Arab kbp_Latn nus_Latn fon_Latn mni_Beng ace_Arab amh_Ethi shn_Mymr knc_Arab tir_Ethi kac_Latn tzm_Tfng srp_Cyrl azb_Arab ChrF++ CoDGPT-3.5-TURBO : An illustrated comparison of 200 languages from English into the languages between the baseline ChatGPT(GPT-3.5-TURBO) and COD. We sorted the language scores in chrF++ for ChatGPT in descending order, and wesplit the whole figure into two parts for clarity. We present the first half in the upper figure, and we present thesecond half in the bottom figure. COD is effective for many languages, especially for low-resource ones.",
  "X-En Results": "X-En: ChatGPTIn addition to the results fortranslation from English into other languages, wealso use our multilingual dictionary for testingtranslation into English. and inthe Appendix report the comparison between GPT-3.5-TURBO and COD. We observe very good im-provements in all languages when translating intoEnglish. We speculate that the underlying reasonis that English is the major language used to pre-train GPT-3.5-TURBO. Dictionaries give hints tothe model to produce better translation output byrelying on the dictionary vocabulary and predict-ing the relationship between them. We also foundthat the translation capacity of ChatGPT can benon-symmetric, e.g., for umb_Latn, English trans-lation reports a score of 17.41 in chrF++, whiletranslating into English reports a score of 4.64 only.",
  "COD (Partially Replaced I)37.7813.72COD (Partially Replaced II)37.4713.29COD (Chain 1)31.5810.97COD (Chain 2)36.3711.06COD (Chain 3)35.4712.29COD (Chain 4)37.9013.90COD (Chain 5)38.2713.90": ": Evaluations of COD and various baselines onGPT-3.5 averaged from 200 languages. We report ontranslating from English into other languages. ,: themodels are the same except for their different names. languages translating into English. While the im-provement is clear (e.g., from 7.05 to 12.50 onckb_Arab), the improvement on BLOOM seemsless significant than on ChatGPT. One reason couldbe that we are using a smaller model on BLOOM(7B). This can make the instruction less native tothe LLMs as we do not do any instruction tuningor fine-tuning on BLOOM. We leave this to futurework for further improvement.",
  ": Results of COMET scores for 99 supportedlanguages on the FLORES-200 full devtest. We reporton translating from English into other languages": "X-En on BLOOM: Save Computations via Re-moving Stopwords truncate stopwordsand reduces 4,978 dictionaries from the total of15,074. The experiments are conducted on 10 ran-domly selected low-resource languages. The re-sults in chrF++ indicate that such truncation caneffectively save about 1/3 of the dictionary prompts,while still maintaining satisfying translation perfor-mance. While the original COD shows better per-formance in most directions, removing stopwordscan even occasionally surpass the original COD,for example on tzm_Ting: COD(10.93), removingstopwords (13.12). We postulate that it is hard forGPTs to translate even those stopwords for low-resource languages.",
  "reports the ablation study using GPT-3.5that was accessed through the online GUI user in-terface. More details are in the Appendix A": "Multilingual DictionaryAs in , usingmultilingual dictionaries from COD instead of us-ing a bilingual dictionary clearly improves thetranslation performance. Compared to using a bilin-gual dictionary that brings improvements of 1.07chrF++ points to GPT-3.5, COD brings a further im-provement of 1.56 points in chrF++. This is moredrastic on GPT-3.5-TURBO in , where bilin-gual dictionary (Ghazvininejad et al., 2023) clearlyshows lower performance than COD. In compari-son, COD effectively improves the BLEU score onthe baseline from 11.45 to 12.01. Also as in , using a monolingual dictionary with target trans-lation only can be harmful, and we suspect that itcan confuse the model as there is no cross-lingualcue in the monolingual dictionary.",
  "Bilingual Dictionary Prompt": "\"eighteen\" means \"kumi na nana\". \"medals\" means \"bamedayi\". \"available\" means \"kele na kati\". \"countries\" means \"bansi\". \"failed\" means \"me nunga ve\". \"podium\" means \"kisika ya lukumu\". Translate the following text from English into Kikongo with Latin script: {Source Sentence} CoD Prompt \"eighteen\" means \"kumi na nana\" means \"dix-huit\" means \"achtzehn\" means \"dezoito\". \"medals\" means \"bamedayi\" means \"mdailles\" means \"Auszeichnungen\" means \"medalhas\". \"available\" means \"kele na kati\" means \" disposition\" means \"verfgbar\" means \"disponveis\". \"countries\" means \"bansi\" means \"pays\" means \"Lnder\" means \"pases\". \"failed\" means \"me nunga ve\" means \"chou\" means \"Versagen\" means \"falhou\". \"podium\" means \"kisika ya lukumu\" means \"le podium\" means \"Podium\" means \"pdio\".Translate the following text from English into Kikongo with Latin script: {Source Sentence}",
  "With only 18 medals a day, most nations have failed to reach the medal podium": ": A case study on translating from English into Kikongo with Latin script using GPT-4 throughout the cases.We evaluate the results on BLEU and chrF++. We highlight in green the words translated wrong by baselines buttranslated correctly by CoD, even if the words are not presented in the multilingual dictionary chains. Chained DictionaryRemoving chained dictio-naries and using non-chained dictionaries that flat-ten all the dictionaries clearly deteriorates the trans-lation results. We postulate that one reason is thata flattened dictionary introduces repeated sourcelanguage text as redundant information, which candegrade the results. This claim aligns with the factin Shi et al. (2023) that LLMs can be easily dis-tracted by irrelevant context. Reducing the chain-ing length (COD (Chain 1, 2, 3, 4)) also drops theperformance. We kindly note that our goal is ratherresearch-oriented. We leave longer chaining andmore choices of chained languages to future work,which might yield better performance. Few-shot In-context Learning (ICL)Retriev-ing few-shot demonstrations for in-context learn-ing instead of COD for languages in FLORES-200 brings minor improvement. We postulate thatthe reason is the difficulty in understanding low-resource languages, and therefore the retrieveddemonstrations are still not very useful to the de-sired translation. While increasing the number ofdemonstrations in the prompt can further boost theperformance, the results are still not very promis-ing, below COD.",
  "Case Study": "presents a case study demonstrating thepowerfulness of COD. The baseline output fromGPT4 is almost lost about which topics are dis-cussed in the sentence. Using a bilingual dictio-nary is useful, but the bilingual baseline is stilllost about the detailed semantics. In comparison,COD successfully provides a high-quality transla-tion, scoring the best in BLEU and chrF++. Wealso highlight in green where the translation is suc-cessfully elicited by COD, even if the words arenot provided in the multilingual dictionary. Wehypothesise that COD provides richer context tothe LLMs to translate relevant words in the sourcesentences, even if they are not directly presented byCOD. and demonstrate cases thatshow a similar phenomenon, and they are availablein the Appendix, at the end of this paper.",
  "Related Work": "Neural Machine Translation via Prompting Lan-guage ModelsLimited research has been con-ducted on effective methods for prompting largelanguage models in machine translation. The ma-jority of existing research has concentrated on eval-uating the translation capabilities of large languagemodels, utilizing uncomplicated prompts such asTranslate to language_name: text (Brown et al.,2020; Lin et al., 2022; Le Scao et al., 2022; Zhanget al., 2022). Various prompt formats have beenexplored by the scholars (Reynolds and McDonell,2021; Wang et al., 2023), whereas Garcia and Firat(2022) have examined the potential use of promptsfor regulating the formality or specific dialect ofthe output. Furthermore, Agrawal et al. (2022) andVilar et al. (2022) have focused on identifying ap-propriate in-context examples to improve machinetranslation quality with LLMs. 10We also found that using other languages that are similarto the target language, such as the languages written in thesame script, can lead to an obvious drop in performance. Wesuspect that putting a similar language to the target languagetends to produce those languages in the output. However,using high-resource language in Latin script as the auxiliarylanguage does not suffer from such a problem. Lexical-based Neural Machine TranslationOur research is connected to the concept of lexicalrestrictions in MT, which can be categorized into ei-ther hard constraints (Hokamp and Liu, 2017; Postand Vilar, 2018) or soft constraints (Song et al.,2019; Dinu et al., 2019; Chen et al., 2021).Also, several works have explored the use ofdictionaries in supervised MT. Zhang and Zong(2016) improves NMT with a bilingual dictionarythat includes less common or unseen words presentin the bilingual training data. Arthur et al. (2016)enhances the translation of infrequent words bysupplementing the system with discrete translationlexicons and utilizing the attention vector to se-lect the pertinent lexical probabilities. Hmlinenand Alnajjar (2020) uses a dictionary to generatesynthetic parallel data to better train the NMT mod-els. A previous work uses bilingual dictionaries toimprove MT (Ghazvininejad et al., 2023).COD is one of the first applications of apply-ing dictionaries on Machine Translation on LLMs.Note that this paper focuses on proving the effec-tiveness of applying a dictionary to LLMs ratherthan providing an actual dictionary to be used.",
  "Conclusions": "COD is a novel framework that uses chained multi-lingual dictionaries when prompting large languagemodels (LLMs) for MNMT. We evaluate ChatGPT,InstructGPT, and BLOOM on the FLORES-200dataset for MNMT. We found that ChatGPT andInstructGPT still have room for improvement intranslating many language pairs. COD elicits largegains by up to 13x chrF++ points for MNMT (3.08to 42.63 for English to Serbian written in Cyrillicscript) on FLORES-200 full devtest set. We alsoverified the necessity of the chained multilingualdictionaries, and we found that both of them arequite important to COD. COD also outperformsfew-shot demonstrations which struggle to retrieverelevant demonstrations for low-resource settings.COD can even surpass the strong SOTA NLLBtranslator in translation. Extensive case studiesdemonstrate that COD elicits translation even if thewords are not directly presented by COD. There areover 7,000 languages around the world, and CODis the first work that scales the translation capabil-ity of LLMs to over 200 languages. We hope thatCOD can help researchers to improve cross-lingualperformance on neural models further.",
  "Limitations": "This paper presents an analysis of 200 languagesonly. However, there are more than thousands oflanguages around the world.Although COD can lead to a very slight degrada-tion in translation performance for a small subset oflanguages, our experiments have shown that the im-pact is typically insignificant and can be probablysimply due to randomness. Therefore, the practicalusage of COD remains unaffected.While COD brings by up to 1.8x inference timeas found in our implementation, the inference timefor actual LLM APIs can be down to milliseconds,so this is realistic to apply COD to real products.While COD brings by up to 3x prompt length,many LLMs support very long input lengths, forexample, 32K for GPT4. So this is realistic to applyCOD to real products. One can also save the tokensby prompting rare words only with COD.This work also does not directly compare tothose ones that require fine-tuning on LLMs (Jiaoet al., 2023) which requires error-guided data. Nev-ertheless, COD is easy to use and does not requireadditional data. It is comparatively easy to curategood-quality dictionaries with off-the-shelf tools.We also consider and focus on the task of Ma-chine Translation, as it is one of the most funda-mental NLG tasks.",
  "Ethical Statement": "We honour and support the EMNLP Code of Ethics.There is no ethical issue known to us. A well-known and widely used LLM is used in our work,which is subjected to generating offensive context.However, the above-mentioned issues are widelyknown to commonly exist for LLMs. Any contentgenerated does not reflect the view of the authors.",
  "Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind": "Neelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020.Language models are few-shot learners.In Ad-vances in Neural Information Processing Systems,volume 33, pages 18771901. Curran Associates,Inc. Guanhua Chen, Yun Chen, Yong Wang, and Victor O. K.Li. 2021. Lexical-constraint-aware neural machinetranslation via data augmentation. In Proceedings ofthe Twenty-Ninth International Joint Conference onArtificial Intelligence, IJCAI20. Georgiana Dinu, Prashant Mathur, Marcello Federico,and Yaser Al-Onaizan. 2019. Training neural ma-chine translation to apply terminology constraints. InProceedings of the 57th Annual Meeting of the Asso-ciation for Computational Linguistics, pages 30633068, Florence, Italy. Association for ComputationalLinguistics. Chris Dyer, Victor Chahuneau, and Noah A. Smith.2013. A simple, fast, and effective reparameteriza-tion of IBM model 2. In Proceedings of the 2013Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 644648, Atlanta,Georgia. Association for Computational Linguistics.",
  "Marjan Ghazvininejad, Hila Gonen, and Luke Zettle-moyer. 2023. Dictionary-based Phrase-level Prompt-ing of Large Language Models for Machine Transla-tion. arXiv e-prints, page arXiv:2302.07856": "Mika Hmlinen and Khalid Alnajjar. 2020.Atemplate based approach for training nmt for low-resource uralic languages - a pilot with finnish. InProceedings of the 2019 2nd International Confer-ence on Algorithms, Computing and Artificial Intel-ligence, ACAI 19, page 520525, New York, NY,USA. Association for Computing Machinery. Chris Hokamp and Qun Liu. 2017.Lexically con-strained decoding for sequence generation using gridbeam search. In Proceedings of the 55th AnnualMeeting of the Association for Computational Lin-guistics (Volume 1: Long Papers), pages 15351546,Vancouver, Canada. Association for ComputationalLinguistics. Wenxiang Jiao, Jen-tse Huang, Wenxuan Wang, Zhi-wei He, Tian Liang, Xing Wang, Shuming Shi, andZhaopeng Tu. 2023. ParroT: Translating during chatusing large language models tuned with human trans-lation and feedback. In Findings of the Association",
  "for Computational Linguistics: EMNLP 2023, pages1500915020, Singapore. Association for Computa-tional Linguistics": "Teven Le Scao, Angela Fan, Christopher Akiki, El-lie Pavlick, Suzana Ilic, Daniel Hesslow, RomanCastagn, Alexandra Sasha Luccioni, Franois Yvon,Matthias Gall, Jonathan Tow, Alexander M. Rush,Stella Biderman, Albert Webson, Pawan Sasanka Am-manamanchi, Thomas Wang, Benot Sagot, NiklasMuennighoff, Albert Villanova del Moral, OlatunjiRuwase, Rachel Bawden, Stas Bekman, AngelinaMcMillan-Major, Iz Beltagy, Huu Nguyen, LucileSaulnier, Samson Tan, Pedro Ortiz Suarez, Vic-tor Sanh, Hugo Laurenon, Yacine Jernite, JulienLaunay, Margaret Mitchell, Colin Raffel, AaronGokaslan, Adi Simhi, Aitor Soroa, Alham FikriAji, Amit Alfassy, Anna Rogers, Ariel KreisbergNitzav, Canwen Xu, Chenghao Mou, Chris Emezue,Christopher Klamm, Colin Leong, Daniel van Strien,David Ifeoluwa Adelani, Dragomir Radev, EduardoGonzlez Ponferrada, Efrat Levkovizh, Ethan Kim,Eyal Bar Natan, Francesco De Toni, Grard Dupont,Germn Kruszewski, Giada Pistilli, Hady Elsahar,Hamza Benyamina, Hieu Tran, Ian Yu, Idris Abdul-mumin, Isaac Johnson, Itziar Gonzalez-Dios, Javierde la Rosa, Jenny Chim, Jesse Dodge, Jian Zhu,Jonathan Chang, Jrg Frohberg, Joseph Tobing, Joy-deep Bhattacharjee, Khalid Almubarak, Kimbo Chen,Kyle Lo, Leandro Von Werra, Leon Weber, LongPhan, Loubna Ben allal, Ludovic Tanguy, MananDey, Manuel Romero Muoz, Maraim Masoud,Mara Grandury, Mario ako, Max Huang, Max-imin Coavoux, Mayank Singh, Mike Tian-Jian Jiang,Minh Chien Vu, Mohammad A. Jauhar, MustafaGhaleb, Nishant Subramani, Nora Kassner, Nuru-laqilla Khamis, Olivier Nguyen, Omar Espejel, Onade Gibert, Paulo Villegas, Peter Henderson, PierreColombo, Priscilla Amuok, Quentin Lhoest, RhezaHarliman, Rishi Bommasani, Roberto Luis Lpez,Rui Ribeiro, Salomey Osei, Sampo Pyysalo, Se-bastian Nagel, Shamik Bose, Shamsuddeen HassanMuhammad, Shanya Sharma, Shayne Longpre, So-maieh Nikpoor, Stanislav Silberberg, Suhas Pai, Syd-ney Zink, Tiago Timponi Torrent, Timo Schick, Tris-tan Thrush, Valentin Danchev, Vassilina Nikoulina,Veronika Laippala, Violette Lepercq, Vrinda Prabhu,Zaid Alyafeai, Zeerak Talat, Arun Raja, BenjaminHeinzerling, Chenglei Si, Davut Emre Tasar, Eliz-abeth Salesky, Sabrina J. Mielke, Wilson Y. Lee,Abheesht Sharma, Andrea Santilli, Antoine Chaffin,Arnaud Stiegler, Debajyoti Datta, Eliza Szczechla,Gunjan Chhablani, Han Wang, Harshit Pandey, Hen-drik Strobelt, Jason Alan Fries, Jos Rozen, LeoGao, Lintang Sutawika, M Saiful Bari, Maged S.Al-shaibani, Matteo Manica, Nihal Nayak, RyanTeehan, Samuel Albanie, Sheng Shen, Srulik Ben-David, Stephen H. Bach, Taewoon Kim, Tali Bers,Thibault Fevry, Trishala Neeraj, Urmish Thakker,Vikas Raunak, Xiangru Tang, Zheng-Xin Yong,Zhiqing Sun, Shaked Brody, Yallow Uri, HadarTojarieh, Adam Roberts, Hyung Won Chung, Jae-sung Tae, Jason Phang, Ofir Press, Conglong Li,Deepak Narayanan, Hatim Bourfoune, Jared Casper, Jeff Rasley, Max Ryabinin, Mayank Mishra, MinjiaZhang, Mohammad Shoeybi, Myriam Peyrounette,Nicolas Patry, Nouamane Tazi, Omar Sanseviero,Patrick von Platen, Pierre Cornette, Pierre FranoisLavalle, Rmi Lacroix, Samyam Rajbhandari, San-chit Gandhi, Shaden Smith, Stphane Requena, SurajPatil, Tim Dettmers, Ahmed Baruwa, AmanpreetSingh, Anastasia Cheveleva, Anne-Laure Ligozat,Arjun Subramonian, Aurlie Nvol, Charles Lover-ing, Dan Garrette, Deepak Tunuguntla, Ehud Re-iter, Ekaterina Taktasheva, Ekaterina Voloshina, EliBogdanov, Genta Indra Winata, Hailey Schoelkopf,Jan-Christoph Kalo, Jekaterina Novikova, JessicaZosa Forde, Jordan Clive, Jungo Kasai, Ken Kawa-mura, Liam Hazan, Marine Carpuat, Miruna Clinciu,Najoung Kim, Newton Cheng, Oleg Serikov, OmerAntverg, Oskar van der Wal, Rui Zhang, RuochenZhang, Sebastian Gehrmann, Shachar Mirkin, ShaniPais, Tatiana Shavrina, Thomas Scialom, Tian Yun,Tomasz Limisiewicz, Verena Rieser, Vitaly Protasov,Vladislav Mikhailov, Yada Pruksachatkun, YonatanBelinkov, Zachary Bamberger, Zdenek Kasner, Al-ice Rueda, Amanda Pestana, Amir Feizpour, Am-mar Khan, Amy Faranak, Ana Santos, AnthonyHevia, Antigona Unldreaj, Arash Aghagol, Are-zoo Abdollahi, Aycha Tammour, Azadeh HajiHos-seini, Bahareh Behroozi, Benjamin Ajibade, BharatSaxena, Carlos Muoz Ferrandis, Danish Contrac-tor, David Lansky, Davis David, Douwe Kiela,Duong A. Nguyen, Edward Tan, Emi Baylor, Ez-inwanne Ozoani, Fatima Mirza, Frankline Onon-iwu, Habib Rezanejad, Hessie Jones, Indrani Bhat-tacharya, Irene Solaiman, Irina Sedenko, Isar Ne-jadgholi, Jesse Passmore, Josh Seltzer, Julio BonisSanz, Livia Dutra, Mairon Samagaio, Maraim El-badri, Margot Mieskes, Marissa Gerchick, MarthaAkinlolu, Michael McKenna, Mike Qiu, MuhammedGhauri, Mykola Burynok, Nafis Abrar, Nazneen Ra-jani, Nour Elkott, Nour Fahmy, Olanrewaju Samuel,Ran An, Rasmus Kromann, Ryan Hao, Samira Al-izadeh, Sarmad Shubber, Silas Wang, Sourav Roy,Sylvain Viguier, Thanh Le, Tobi Oyebade, Trieu Le,Yoyo Yang, Zach Nguyen, Abhinav Ramesh Kashyap,Alfredo Palasciano, Alison Callahan, Anima Shukla,Antonio Miranda-Escalada, Ayush Singh, BenjaminBeilharz, Bo Wang, Caio Brito, Chenxi Zhou, ChiragJain, Chuxin Xu, Clmentine Fourrier, Daniel LenPerin, Daniel Molano, Dian Yu, Enrique Manjava-cas, Fabio Barth, Florian Fuhrimann, Gabriel Altay,Giyaseddin Bayrak, Gully Burns, Helena U. Vrabec,Imane Bello, Ishani Dash, Jihyun Kang, John Giorgi,Jonas Golde, Jose David Posada, Karthik Ranga-sai Sivaraman, Lokesh Bulchandani, Lu Liu, LuisaShinzato, Madeleine Hahn de Bykhovetz, MaikoTakeuchi, Marc Pmies, Maria A Castillo, Mari-anna Nezhurina, Mario Snger, Matthias Samwald,Michael Cullan, Michael Weinberg, Michiel DeWolf, Mina Mihaljcic, Minna Liu, Moritz Freidank,Myungsun Kang, Natasha Seelam, Nathan Dahlberg,Nicholas Michio Broad, Nikolaus Muellner, PascaleFung, Patrick Haller, Ramya Chandrasekhar, RenataEisenberg, Robert Martin, Rodrigo Canalli, RosalineSu, Ruisi Su, Samuel Cahyawijaya, Samuele Garda, Shlok S Deshmukh, Shubhanshu Mishra, Sid Ki-blawi, Simon Ott, Sinee Sang-aroonsiri, Srishti Ku-mar, Stefan Schweter, Sushil Bharati, Tanmay Laud,Tho Gigant, Tomoya Kainuma, Wojciech Kusa, Ya-nis Labrak, Yash Shailesh Bajaj, Yash Venkatraman,Yifan Xu, Yingxin Xu, Yu Xu, Zhe Tan, ZhongliXie, Zifan Ye, Mathilde Bras, Younes Belkada, andThomas Wolf. 2022. BLOOM: A 176B-ParameterOpen-Access Multilingual Language Model. arXive-prints, page arXiv:2211.05100. Xi Victoria Lin, Todor Mihaylov, Mikel Artetxe, TianluWang, Shuohui Chen, Daniel Simig, Myle Ott, Na-man Goyal, Shruti Bhosale, Jingfei Du, RamakanthPasunuru, Sam Shleifer, Punit Singh Koura, VishravChaudhary, Brian OHoro, Jeff Wang, Luke Zettle-moyer, Zornitsa Kozareva, Mona Diab, Veselin Stoy-anov, and Xian Li. 2022. Few-shot learning withmultilingual generative language models. In Proceed-ings of the 2022 Conference on Empirical Methodsin Natural Language Processing, pages 90199052,Abu Dhabi, United Arab Emirates. Association forComputational Linguistics. Yinhan Liu, Jiatao Gu, Naman Goyal, Xian Li, SergeyEdunov, Marjan Ghazvininejad, Mike Lewis, andLuke Zettlemoyer. 2020. Multilingual denoising pre-training for neural machine translation.Transac-tions of the Association for Computational Linguis-tics, 8:726742. Hongyuan Lu, Haoyang Huang, Shuming Ma, Dong-dong Zhang, Wai Lam, Zhaochuan Gao, AnthonyAue, Arul Menezes, and Furu Wei. 2023. TRIP: Ac-celerating document-level multilingual pre-trainingvia triangular document-level pre-training on paralleldata triplets. In Findings of the Association for Com-putational Linguistics: EMNLP 2023, pages 78457858, Singapore. Association for Computational Lin-guistics. Hongyuan Lu, Haoyang Huang, Dongdong Zhang, FuruWei, and Wai Lam. 2024.Revamping multilin-gual agreement bidirectionally via switched back-translation for multilingual neural machine transla-tion. In Findings of the Association for Computa-tional Linguistics: EACL 2024, pages 264275, St.Julians, Malta. Association for Computational Lin-guistics.",
  "NLLB-Team. 2022. No language left behind: Scalinghuman-centered machine translation": "Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evalu-ation of machine translation. In Proceedings of the40th Annual Meeting of the Association for Compu-tational Linguistics, pages 311318, Philadelphia,Pennsylvania, USA. Association for ComputationalLinguistics. Keqin Peng, Liang Ding, Qihuang Zhong, Li Shen,Xuebo Liu, Min Zhang, Yuanxin Ouyang, andDacheng Tao. 2023. Towards Making the Most ofChatGPT for Machine Translation. arXiv e-prints,page arXiv:2303.13780. Maja Popovic. 2015. chrF: character n-gram F-scorefor automatic MT evaluation. In Proceedings of theTenth Workshop on Statistical Machine Translation,pages 392395, Lisbon, Portugal. Association forComputational Linguistics. Matt Post and David Vilar. 2018. Fast lexically con-strained decoding with dynamic beam allocation forneural machine translation. In Proceedings of the2018 Conference of the North American Chapter ofthe Association for Computational Linguistics: Hu-man Language Technologies, Volume 1 (Long Pa-pers), pages 13141324, New Orleans, Louisiana.Association for Computational Linguistics. Ricardo Rei, Craig Stewart, Ana C Farinha, and AlonLavie. 2020. COMET: A neural framework for MTevaluation. In Proceedings of the 2020 Conferenceon Empirical Methods in Natural Language Process-ing (EMNLP), pages 26852702, Online. Associationfor Computational Linguistics. Laria Reynolds and Kyle McDonell. 2021. Prompt pro-gramming for large language models: Beyond thefew-shot paradigm. In Extended Abstracts of the2021 CHI Conference on Human Factors in Com-puting Systems, CHI EA 21, New York, NY, USA.Association for Computing Machinery. Freda Shi, Xinyun Chen, Kanishka Misra, NathanScales, David Dohan, Ed Chi, Nathanael Schrli, andDenny Zhou. 2023. Large Language Models CanBe Easily Distracted by Irrelevant Context. arXive-prints, page arXiv:2302.00093. Kai Song, Yue Zhang, Heng Yu, Weihua Luo, KunWang, and Min Zhang. 2019. Code-switching forenhancing NMT with pre-specified translation. InProceedings of the 2019 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies,Volume 1 (Long and Short Papers), pages 449459,Minneapolis, Minnesota. ACL. Tianyi Tang, Hongyuan Lu, Yuchen Jiang, HaoyangHuang, Dongdong Zhang, Xin Zhao, Tom Kocmi,and Furu Wei. 2024. Not all metrics are guilty: Im-proving NLG evaluation by diversifying references.In Proceedings of the 2024 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies(Volume 1: Long Papers), pages 65966610, MexicoCity, Mexico. Association for Computational Lin-guistics. David Vilar, Markus Freitag, Colin Cherry, JiamingLuo, Viresh Ratnakar, and George Foster. 2022.Prompting PaLM for Translation: Assessing Strate-gies and Performance.arXiv e-prints, pagearXiv:2211.09102.",
  "DirectionGPT CoDDirectionGPT CoDDirectionGPT CoDDirectionGPT CoDDirectionGPT CoD": "amh_Ethi->lao_Laoo 15.43 16.40 azb_Arab->tsn_Latn 20.68 24.81 bak_Cyrl->amh_Ethi 7.68 10.72bug_Latn->tgk_Cyrl15.41 16.16 ckb_Arab->tzm_Tfng8.687.72hau_Latn->kac_Latn 4.51 11.69 hye_Armn->tsn_Latn 22.56 24.00 ibo_Latn->hye_Armn 16.74 16.47kac_Latn->srp_Cyrl6.93 11.55 kbp_Latn->shn_Mymr 4.736.99kir_Cyrl->bug_Latn 10.17 14.10 kon_Latn->srp_Cyrl5.013.72 lao_Laoo->snd_Arab 12.61 7.80lin_Latn->zul_Latn21.35 23.00 nso_Latn->bug_Latn 10.65 16.40nya_Latn->sag_Latn 15.57 18.13 plt_Latn->nso_Latn 23.60 28.42sag_Latn->lin_Latn21.70 24.23 shn_Mymr->amh_Ethi 4.395.92smo_Latn->lao_Laoo 19.36 19.84snd_Arab->bug_Latn 8.26 15.68 sot_Latn->amh_Ethi8.86 10.83 srp_Cyrl->kac_Latn1.33 14.48 tat_Cyrl->hye_Armn 22.22 23.51 tgk_Cyrl->amh_Ethi8.82 11.30tsn_Latn->plt_Latn23.99 25.14 tso_Latn->sot_Latn 25.90 25.77 tzm_Tfng->amh_Ethi 3.423.43uig_Arab->tgk_Cyrl14.94 17.74 zul_Latn->amh_Ethi8.75 11.19",
  "The use of ships to transport goods is the most efficient way to transport large amounts of people and goods on the seas": ": A case study on translating from English into Central Kurdish with Latin script using GPT-4 throughoutthe cases. We evaluate the results on BLEU and chrF++. We highlight in green the words translated wrong bybaselines but translated correctly by CoD, even if the words are not presented in the multilingual dictionary chains.",
  "There are some traditions for the return of the night special people from Taxairat exposed to see the sun rise": ": A case study on translating from English into Central Kurdish with Latin script using GPT-3.5 throughoutthe cases. We evaluate the results on BLEU and chrF++. We highlight in green the words translated wrong bybaselines but translated correctly by CoD, even if the words are not presented in the multilingual dictionary chains."
}