{
  "Abstract": "Fuzzy reasoning is vital due to the frequentuse of imprecise information in daily contexts.However, the ability of current large languagemodels (LLMs) to handle such reasoning re-mains largely uncharted. In this paper, we in-troduce a new benchmark, FROG, for fuzzyreasoning, featuring real-world mathematicalword problems that incorporate generalizedquantifiers. Our experimental findings revealthat fuzzy reasoning continues to pose signif-icant challenges for LLMs.Moreover, wefind that existing methods designed to enhancereasoning do not consistently improve perfor-mance in tasks involving fuzzy logic. Addi-tionally, our results show an inverse scalingeffect in the performance of LLMs on FROG.Interestingly, we also demonstrate that strongmathematical reasoning skills are not necessar-ily indicative of success on our benchmark1.",
  "Introduction": "The capability to reason effectively is a critical di-mension in evaluating the advancements of largelanguage models (LLMs) (Brown et al., 2020;Huang and Chang, 2023; Bowen et al., 2024;Wang et al., 2024b; Zhu et al., 2024).Com-monly, the progress of advancing reasoning abil-ities is mainly evaluated on mathematical reason-ing benchmarks (Xia et al., 2024; Huang et al.,2024a) like GSM8K (Cobbe et al., 2021) andMATH (Hendrycks et al., 2021), which demandsprecise answers derived from clear, rule-basedquestions. However, much of human knowledgeand daily decision-making processes are not basedon precision but rather involve handling fuzzy, im-precise information (Novk, 2015).Fuzzy reasoning, which deals with uncertain-ties and perceptual data, differs significantly fromthe deterministic processes evaluated in existing",
  "*Corresponding author1Resource:": "standard benchmarks. It often relies on natural lan-guage constructs that do not capture informationwith precise granularity (Novk, 2015). For in-stance, generalized quantifiers (GQs), such as fewor most, are frequently used in natural languageto introduce vagueness (Mostowski, 1957; Ramo-towska et al., 2024). An illustrative fuzzy problememploying GQ might be: There have been succes-sive increases of 20% and then most in the price ofgas from the previous month. By what percentageshould a driver reduce gas consumption so thatthe expenditure does not change? Here, the termmost introduces ambiguity concerning the extentof the price increase and necessitates an estimationof its semantics to solve the problem accurately.However, such GQ-based fuzzy reasoning prob-lems are under-explored.Faghihi et al. (2020)introduces probabilistic fuzzy logic (Yager andZadeh, 1992) to enhance reasoning abilities. Exist-ing works like Saki and Faghihi (2022) investigateemploying fuzzy probabilistic theory in association-based problems, like the relation between fuzzyfeatures and labels (e.g. a lot of smoking and can-cer). The mapping functions to encode fuzzy fea-tures are either simulated (Faghihi et al., 2020) orcollected from limited data with heuristics (Wanget al., 2019). Those mapping functions fail to eval-uate complex, real-world reasoning scenarios andrealistically capture how LLMs utilize fuzzy rea-soning in practical contexts.In this paper, we aim to explore reasoning chal-lenges associated with fuzzy events (Zadeh, 1968),which are mathematically ambiguous and artic-ulated through fuzzy expressions of GQs, suchas most in the price of gas. Specifically, wefocus on mathematical reasoning problems thatincorporate GQs.To this end, we have devel-oped FROG, a benchmark for Fuzzy Reasoningbenchmark of Generalized quantifiers, which trans-forms real-world mathematical problems fromGSM8K (Cobbe et al., 2021) and MathQA (Amini",
  ": Workflow of FRoG construction": "et al., 2019) datasets into multiple-choice ques-tions. These questions replace precise numericaldata with GQs, requiring models to apply both pre-cise reasoning like arithmetic computations andfuzzy reasoning to estimate the scope of GQs. Ourevaluation of several LLMs reveals that fuzzy rea-soning remains a significant challenge in FROG,with an inverse scaling effect observed in over halfof the model families tested. Furthermore, commonmethods designed to enhance reasoning capabili-ties like math-specialized tuning, code-specializedtuning, and general alignment, do not consistentlyimprove performance in FROG. Interestingly, wefind that strong mathematical reasoning skills arenot necessarily indicative of success on FROG. Wealso outline the primary strategies employed byLLMs to perform fuzzy reasoning.",
  "Related Work": "Reasoning abilities, involving drawing conclusionsfrom existing knowledge, are a cornerstone of hu-man intelligence and are crucial for intricate taskslike decision-making and solving math word prob-lems (Yu et al., 2023). Recently, mathematicalproblem-solving has become a key dimension inassessing the reasoning capabilities of LLMs (Xiaet al., 2024; Huang et al., 2024a). Various ap-proaches have been developed to enhance the mathreasoning ability of LLMs, like prompt-based de-signs (Chia et al., 2023; Zheng et al., 2023; Chenet al., 2023a). On the other hand, Taylor et al.(2022); Lewkowycz et al. (2022); Paster et al.(2024); Azerbayev et al. (2024) propose data con-struction for the pertaining stage. And further su-pervised fine-tuning, instruction tuning or align-ment methods like Direct Preference Optimization (DPO, Rafailov et al. (2023)) are used to enhancethe reasoning abilities of LLMs (Yu et al., 2024;Luo et al., 2023; An et al., 2023; Huang et al.,2024b; Li et al., 2024; DeepSeek-AI et al., 2024).Motivated by the fact that external tools are widelyused in NLP tasks, tool integration is introducedto enhance math reasoning (Mishra et al., 2022;Gao et al., 2023; Gou et al., 2024a,b; Yue et al.,2024; Zhou et al., 2024; Zhang et al., 2024a). Chenet al. (2023b) employs programming methods toenhance the reasoning ability of LLMs. In FROG,we build the fuzzy reasoning tasks based on mathe-matical reasoning problems and explore commonapproaches designed to improve reasoning capa-bilities including math-specialized tuning, code-specialized tuning, and general alignment.GQs are widely used to indicate proportionsof predicate satisfaction in communication (Joshiet al., 2020) and benchmarks (Suhr et al., 2019;Apidianaki and Gar Soler, 2021). They also con-tribute as a major source to the deficiencies of NLPsystems like NLI (Cui et al., 2022). Given theirreal-world prevalence, we employ GQs as a naturalapproach to introduce fuzzy information in FROG.Existing methods for modeling fuzzy logic innatural language, as developed by Lee (2004) andKapustin and Kapustin (2019), depend on pre-defined mapping functions to process fuzziness.Those mapping functions are mostly built fromrule-based heuristics on limited data, or with sim-ple distribution assumption (e.g. the gaussian dis-tribution) and hard to be directly on real-worldcomplex reasoning problems. In FROG, we relyon LLMs that are pretrained from large-scale realworld text corpora to process the fuzziness of GQsand conduct complex math reasoning problems.",
  "Benchmark Collection": "Problems in FRoG are collected from two mathword problem datasets from the real world:GSM8K and MathQA. GSM8K includes gradeschool math word problems that can be largelysolved with basic arithmetic operations. MathQAconsists of multiple-choice GRE and GMAT-levelmath problems. In FROG, we include questionswith percentage mentions, and displays anoverview of the collection workflow. Specifically, Step 1: Identifying Mathematical Questionswith Percentage Mentions - We begin by filter-ing the original questions to include only thosethat contain at least one percentage figure, ofwhich the value is between 0% and 100%. Step 2: Masking the Percentage Mention - Weobscure the specific target percentage mention byreplacing it with a [MASK] token to construct aMask question. If the original question containsmultiple percentage mentions, each mention ismasked out separately. We also employ two othermasking strategies Mislead and X% where thetarget mention is substituted with a misleadingquantifier (with the incorrectness pointed out inthe FRoG template) or X%. Step 3: Searching for the Nearest Quantifiers- The golden choice is selected by finding theclosest GQ according to its average strength pro-vided in QuRe (Li et al., 2023), a quantifier rea-soning dataset with human-annotated quantifierstrengths (i.e., few is the closest GQ to 10% in therunning example) that do not include modifierslike particles that lead to semantic change. Step 4: Constructing the FRoG Task - InFROG, we provide the question and the originalanswer to infer which GQ can be filled to rep-resent the information masked out. This frame-work is driven by the acknowledgment that itis more practical to formulate fuzzy reasoningthan directly solve mathematical problems withGQs. To carefully investigate the performance,we design the easy and hard mode of choicesdepending on the discriminability of misleadingchoices. The incorrect choices in FRoG-Hardare the misleading top GQs in the previous step(e.g. tiny amount, small amount, none in the run-ning example), while incorrect choices in FRoG-Easy are randomly sampled from all misleadingGQs. The original question, original answer andchoices are then assembled through FRoG tem-plates. We refer to Appendix E for details. 0.0 0.1 0.2",
  "Target Percentage Mentions": ": (Top) quantifier proportions in FROG. (Bot-tom) percentiles of target percentage mentions catego-rized by quantifiers. Green and orange lines representthe means and medians, respectively. The x-axis isshared between the two figures. For MathQA data, the original multiple choiceformat is omitted in FRoG since there is a negligi-ble difference in performance between maintainingthe original choice or providing the correct numericanswer, according to preliminary experiments. Eventually, FRoG includes 199 questions fromGSM8K and 1,845 questions from MathQA. Theaverage number of question tokens is 68.2, witheach token separated by a space. And each questionin FRoG contains an average of 1.6 percentagementions. The total number of quantifiers involvedin FRoG is 8, and the most common quantifiersused are few (25.3%), moderate amount (23.8%),and small amount (19.7%) (see top fordetails). The bottom of reveals the targetpercentage mentions mapped to each quantifier,e.g. the mean percentage value and 0.15 for fewand around 0.4 for moderate amount. The meanstrength difference between the golden quantifierand the incorrect quantifier that is closest to thetarget percentage mention is 0.105 in FRoG-Hard. tulu-2-7b codellama-70b qwen-1.5-4b-chatolmo-1b wizardmath-7b qwen-1.5-1.8b qwen-1.5-1.8b-chat wizardlm-7b llama-3-8b-instruct wizardmath-13b llama-2-7b codellama-7b olmo-7b qwen-1.5-7b-chat tulu-2-13b llemma-7b wizardmath-70b yi-34b-chat qwen-1.5-7b yi-6b-chat llama-2-13b codellama-34b llama-3-8b mistral-7b wizardlm-70b llama-2-7b-chat llama-2-70b gpt-3.5-turbo-1106 tulu-2-dpo-13b qwen-1.5-14b tulu-2-70b llama-2-13b-chat mixtral-8x7b tulu-2-dpo-7b llemma-34b tulu-2-dpo-70b qwen-1.5-14b-chat qwen-1.5-32b llama-2-70b-chat qwen-1.5-32b-chat qwen-1.5-72b-chat llama-3-70b llama-3-70b-instructgpt-4-turbo",
  "Average Accuracy": "codellamagpt llama-2llama-2-chat llama-3llama-3-instruct llemmamistral olmoqwen-1.5 qwen-1.5-chattulu-2 tulu-2-dpowizardlm wizardmathyi-chat : The average Mask accuracy in FRoG-Easy and FRoG-Hard of several LLMs sorting in ascending order.Dots with the same color belong to the same model family. Models with additional pretraining or instruction tuningdo not necessarily perform better. We refer to and for more details.",
  "Experiment": "We evaluated several open-sourced LLMs, in-cluding Llama-2 (Touvron et al., 2023), CodeL-lama (Rozire et al., 2024), Llemma (Azerbayevet al., 2024), Llama-3 (AI, 2024), Mistral (Jianget al., 2023), Qwen-1.5 (Bai et al., 2023), Tulu-2 (Ivison* et al., 2023), WizardLM (Xu et al.,2024), WizardMath (Luo et al., 2023) and Yi-Chat (Young et al., 2024) on our FRoG benchmark.Specifically, we would like to investigate the fol-lowing three research questions:",
  ". Is the mathematical reasoning strength trans-ferrable to FROG?": "We employ the greedy decoding strategy withmax tokens being 1,000, and temperature being 0.9in experiments. The LLMs are instructed with taskinstructions (see Appendix F) and 5 demonstra-tions (Brown et al., 2020) with manually createdchain-of-thought (Wei et al., 2022b) solutions to as-sist the reasoning procedure. The experiments areconducted on NVIDIA A100 80GB GPUs, eachexperiment can be finished within 2 hours.Moreover, we investigate the sensitivity of differ-ent masking strategies. Specifically, we comparethe performance between the Mask and Mislead orX% task by computing the Pearson and Spearmancorrelation of their accuracy. The results in indicate strong positive correlations between theperformance of Mask and Mislead or X%, meaningthat LLMs are not sensitive to the masking strategyin FROG. We also do not observe strong correlationbetween accuracy and length of the generation. Wechoose the Mask task as the major task thereafter.",
  "Overall Result": "The result on FRoG is displayed in . Ingeneral, the accuracy of all models is around 0.05and 0.45 (and mostly between 0.15 and 0.3), indi-cating that the fuzzy reasoning is a challenging taskfor the current LLMs. Moreover, models with smallmodel sizes can demonstrate suprisingly strongperformance in FRoG compared to models muchlarger, e.g. Tulu-2-DPO-7B outperforms Tulu-2-70B, Llama-2-70B and WizardLM-70B.",
  "Accuracy": "codellamallama-2llama-2-chat llama-3llama-3-instruct llemmamistral olmoqwen-1.5 qwen-1.5-chattulu-2 tulu-2-dpowizardlm wizardmathyi-chat : The performance of different LLMs on all FRoG tasks with different masking strategies and difficulties.The solid lines represent models that demonstrate inverse scaling phenomenon, and crossings represent the perfor-mance of other models. The green line represents the performance of GPT-3.5-turbo-1106. More than 50% of themodel families demonstrate the inverse scaling effect.",
  "gramming to natural language largely impacts theperformance. The largest CodeLlama (70B) eval-uated directly generates code snippet most of thetime, leading to the poor performance on FROG": "General AlignmentThe results are shown in Fig-ure 4. In general, the performance on FRoG-Easy(dashed lines) is better than FRoG-Hard (real lines)among all the models. Regarding the difference be-tween the base models and their instruction-tunedversions, the benefit of instruction-tuning substan-tially diminishes from FRoG-Easy to FRoG-Hardin Llama-2, Qwen-1.5 and Llama-3. Lastly, theinverse scaling effect displays on Llama-2, Qwen-1.5 and Tulu-2. In FRoG-Easy, the perfromance of4 base models adhere to the scaling law, whereasthe instruction-tuned models display inverse scal-ing effect except Llama-3. In FRoG-Hard, Llama-2demonstrates inverse scaling effect in both base andchat models. Conversely, Qwen-1.5 and Llama-3consistently exhibit scaling phenomenon in bothbase and chat models. The Tulu-2 base model ad-heres to the scaling law, while the Tulu-2-DPOmodel display the inverse scaling effect. 1 1.8 4678 13 14 32 34 70 72 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 Mask - Easy 1 1.8 4678 13 14 32 34 70 72 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 Mislead - Easy 1 1.8 4678 13 14 32 34 70 72 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 X% - Easy 1 1.8 4678 13 14 32 34 70 72 0.05 0.10 0.15 0.20 0.25 Mask - Hard 1 1.8 4678 13 14 32 34 70 72 0.05 0.10 0.15 0.20 0.25 Mislead - Hard 1 1.8 4678 13 14 32 34 70 72 0.05 0.10 0.15 0.20 0.25 0.30X% - Hard Model Parameters (Billion)",
  "Q2: Can the scaling law be observed inFROG?": "Scaling law is introduced in Kaplan et al. (2020) tosuggest the phenomenon that LLMs can achieve en-hanced task performance by scaling up model sizes.However, the scaling law does not hold univer-sally. For example, the inverse scaling phenomenoncan be observed when LLMs are instructed tochoose which information can help to answer aquestion (McKenzie et al., 2023), which is simi-lar to the design of FRoG tasks. Here, we list theperformance of all models evaluated on FRoG in. Each line highlights an observed inversescaling effect (less than 1 point performance gainby scaling model sizes). It turns out that 8 outof the 15 model families evaluated demonstrate in-verse scaling effect in FROG, crossing base models,continuous trained models and instruction-tunedmodels.We further provide a case study of Qwen-1.5-Chat for its large number of open-resourced check-points and superior performance in mathematicalreasoning. The results in show that theperformance gap between FRoG-Easy and FRoG- 1.84 7143272 qwen-1.5-chat 0.15 0.20 0.25 0.30 Model Parameters (Billion)",
  ": The accuracy of Mask of Qwen-1.5-Chat mod-els, the real and dashed lines represent the hard and easysplit, respectively": "Hard increases starting Qwen-1.5-4B-Chat, and theperformance becomes saturated with a model of 7billion parameters or larger. Moreover, the perfor-mance gain of scaling model parameters diminishesafter 14 billion model parameters. Inverse scalinghappens on the side of models smaller than 7 bil-lion and larger than 32 billion parameters. Modelswith fewer than 14 billion parameters are very un-stable, displaying poor performance (below 25%)and convoluted accuracy. Notably, the 4B modelexhibits the poorest performance of all the models gpt llama-2 llama-2-chat llama-2-code llama-3 llama-3-instruct llemma mistral olmo qwen-1.5 qwen-1.5-chat tulu-2 tulu-2-dpo wizardlm wizardmath yi-chat 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8",
  "Q3: Is the mathematical reasoningstrength transferrable to FROG?": "Mathematical reasoning has become a key signalfor reasoning capabilities of LLMs (Huang et al.,2024a). To proxy the fuzzy reasoning ability un-der the precise setting, we design a mask_percentbaseline that substitutes the misleading choicesinto their corresponding mean average strengthsin QuRe and the correct choice being the exactvalue of the target percentage mention. Therefore,the original Mask task (denoted as mask_quant) istransformed into figuring out the hidden percentageinformation in precise reasoning, with the predic-tions still reflect the preference over the quantifiers.For example, the mask_percent choices of questionin are A 0.4%, B 18.3%, C 10%, D 2.4%under the hard mode.The results are demonstrated in , whereGPT-4-turbo and Llama-3-Instruct are the best per-formed commercial or open-resourced model inboth mask_percent and mask_quant. CodeLlama-70B and Tulu-2-7B achieve minimal accuracy inboth precise reasoning (nearly 0%) and fuzzy rea-soning (lower than 10%) tasks, which attributesto their programming or web content style out-puts. The accuracy of mask_percent of a modelis significantly higher than the mask_quant alter-natives in most of the cases. But the advances of mask_percent by scaling up model parame-ters are hard to transfer to the mask_quant taskin FROG. In fact, among the 11 open-sourcedmodels that achieve higher than 40% accuracyin the mask_percent setting, their accuracies inmask_quant are all lower than 30%. Take Tulu-2-DPO models for instance, even though themask_percent performance improves by scaling themodel size, the performance of those models dropssignificantly and the scaling effect shrinks drasti-cally when shifted to the mask_quant task. Specifi-cally, we observe that models with a larger numberof parameters are more likely to receive a largeraccuracy drop when shifted from mask_percent tomask_quant. The average accuracy drop of modelssmaller than 10 billion parameters is 6.8% com-pared to 16.9% of models of larger sizes, indicatingthat successfully solving a reverse mathematical(precise) reasoning problem does not necessarilyreflect equivalent competences in solving FRoGproblems with fuzziness introduced by GQs.",
  "Case Study": "Lastly, we are interested in the working mechanismthat LLMs pose in conducting fuzzy reasoning inFROG. We randomly sample 50 results from GPT-4-turbo in FRoG-Hard, and demonstrate examplesin . The mechanism of LLMs to solve fuzzyreasoning can be summarized as follows: firstly,the LLMs attempt to locate the target percentagevalue in three major patterns:(1) Precisely solving the target percentage mention. Ex1: Kelly has had 3 pay cuts in her salary in the past 6 months. If the first pay cut was 8%, the second pay cut was14%, and the third was [MASK]. What will be the percentage decrease, if the salary is decreased in a single shot? If theanswer to the question is 35.12%, then please select the quantifier that is closest to the meaning of [MASK] from thefollowing choices. [18%]A. few B. some C. tiny amount D. small amount Suppose that Kellys initial salary is 100 units for simplicity. After the first pay cut of 8%, her salary becomes 92 units.The second pay cut of 14% reduces her salary further to 92 * (1 - 0.14) = 79.12 units. Let the third pay cut be x%.Therefore, her salary becomes 79.12 * (1 - x%) after the third cut.We need to find x such that the overall reduction is equivalent to a single reduction of 35.12%. This means the finalsalary should be 100 * (1 - 0.3512) = 64.88 units.Setting up the equation: 79.12 * (1 - x/100) = 64.88.Solving for x: (1 - x/100) = 64.88 / 79.12 0.8202, hence x/100 = 1 - 0.8202 = 0.1798 or x = 17.98%.Knowing the value of x, we can compare it to the options given: - A few (typically refers to a small number, but greater than tiny amount)- Some (could imply a moderate to considerable amount, usually more ambiguous)- Tiny amount (implies very small, likely less than our calculated 17.98%)- Small amount (suggests a non-trivial but not large percentage)",
  "Between these choices, small amount best describes a reduction of 17.98%, as its significant but not very large or tiny.Therefore, the best choice is D. small amount": "Ex2: The average price of a decoration piece has increased over the years. If from 1990 to 1996, the price of thedecoration piece increased by [MASK] and from 1996 to 2001 it increased by 20%, what is the price of the decorationpiece in 2001 if the price in 1990 was $11500? If the answer to the question is $15594, then please select the quantifierthat is closest to the meaning of [MASK] from the following choices. [13%]A. some B. tiny amount C. few D. small amount First, we need to calculate the price of the decoration piece in 1996 based on an unknown percentage increase from 1990.Let the percentage increase from 1990 to 1996 be x%.If the price in 1990 was $11500, then the price in 1996 after x% increase would be $11500 * (1 + x/100).From 1996 to 2001, the price increased further by 20%, so the price in 2001 would be: $11500 * (1 + x/100) * 1.2The final value is given as $15594. So we have: $11500 * (1 + x/100) * 1.2 = $15594Solving for x: (1 + x/100) = $15594 / ($11500 * 1.2); (1 + x/100) = $15594 / $13800; (1 + x/100) 1.13;x/100 = 0.13 x = 13%So, the price increased by 13% from 1990 to 1996.Given the choices of some, tiny amount, few, and small amount, a 13% increase is not negligible but is not verylarge either. Among the provided options, small amount seems to be the closest match to a 13% increase.Therefore, the answer is D. small amount. : Sampled results in FRoG-Hard. The target percentage mention lies in the brackets, the correct answer isunderscored and the prediction is bolded. The explicit quantifier estimation stage is highlighted. (2) Reaching a percentage value that is close to thetarget percentage mention.(3) Incomplete solution (e.g. unsolved equations).After solving the target percentage mention, theLLMs select their preferred quantifiers through aquantifier estimation stage, which can be implicit.Such implicit reasoning procedure is also studied inprecise math reasoning (Deng et al., 2023, 2024). For example in Ex1 of , the model firstlysolves the target percentage value with satisfyingprecision (17.98%), and then conduct a quantifierestimation stage before deciding the quantifier se-lection. Note that this quantifier selection stage isnot always explicit (e.g. Ex2). We include moreexamples in Appendix C. In general, the target percentage value can belocated with satisfying precision (within 1% error)52% of the time (still lower than the mask_percentsetting where the target percentage value is pro-vided as a candidate choice), with only 61% of",
  "them lead to the final correctness of the problems.It indicates the complexity of conducting fuzzy rea-soning even with the target percentage value given": "Moreover, 15 of the 50 predictions show explicitquantifier estimation by comparing or estimatingthe strengths of quantifiers, but only 5 of them leadto the correct quantifier predictions, meaning thatprecisely solving the target percentage value is in-sufficient to conduct fuzzy reasoning. Meanwhile,there are 15 cases where models select the correctquantifier without explicit quantifier estimations,indicating that models may rely on implicit mecha-nisms in conducting fuzzy reasoning. Note that even though models within the samemodel family but with different number of param-eters can figure out the target percentage mentioncorrectly or close enough, their interpretation ofquantifiers can make a difference in the final pre-diction, we refer to Appendix D for examples.",
  "Conclusion": "The fuzzy reasoning ability is an under-exploreddirection of the reasoning ability of LLMs. Tomeasure the fuzzy reasoning ability of LLMs, wecollect a fuzzy reasoning benchmark FRoG that isbased on generalized quantifiers. The experimentalresults show that fuzzy reasoning remains challeng-ing for current LLMs, and an inverse scaling effectis observed on the performance of FROG. Besides,prevailing reasoning enhancement approaches in-cluding continuous pretraining, instruction tun-ing and general alignment may not stay effectiveon fuzzy reasoning of FROG. Lastly, LLMs candemonstrate diverse behaviors in fuzzy reasoning. The authors would like to thank the anonymousreviewers for their suggestions and feedback onthe work.This work was partially funded bythe National Natural Science Foundation of China(62476168), Qingyuan Research Project.Theviews contained in this article are those of the au-thors and not of the funding agency.",
  "Limitations": "In this work, we collect a fuzzy reasoning datasetFROG to evaluate the fuzzy reasoning abilities ofseveral existing LLMs. We are aware that eventhough the problems in FROG originate from real-world math word problems, the new question cre-ated may not naturally occur, and the designedmasking-based reasoning protocol is not identicalto the real-world reasoning procedure where thevague information is processed directly. We alsonote that GQ-based fuzzy reasoning is only a sub-set of the entire family of natural language fuzzyreasoning, and the scope of GQs is broader thanthe ones being studied in this work.",
  "Shengnan An, Zexiong Ma, Zeqi Lin, Nanning Zheng,Jian-Guang Lou, and Weizhu Chen. 2023. Learn-ing from mistakes makes llm better reasoner. arXivpreprint arXiv:2310.20689": "Marianna Apidianaki and Aina Gar Soler. 2021. ALLdolphins are intelligent and SOME are friendly: Prob-ing BERT for nouns semantic properties and theirprototypicality. In Proceedings of the Fourth Black-boxNLP Workshop on Analyzing and InterpretingNeural Networks for NLP, pages 7994, Punta Cana,Dominican Republic. Association for ComputationalLinguistics. Zhangir Azerbayev, Hailey Schoelkopf, Keiran Paster,Marco Dos Santos, Stephen Marcus McAleer, Al-bert Q. Jiang, Jia Deng, Stella Biderman, and SeanWelleck. 2024. Llemma: An open language modelfor mathematics. In The Twelfth International Con-ference on Learning Representations. Jinze Bai, Shuai Bai, Yunfei Chu, Zeyu Cui, Kai Dang,Xiaodong Deng, Yang Fan, Wenbin Ge, Yu Han, FeiHuang, Binyuan Hui, Luo Ji, Mei Li, Junyang Lin,Runji Lin, Dayiheng Liu, Gao Liu, Chengqiang Lu,Keming Lu, Jianxin Ma, Rui Men, Xingzhang Ren,Xuancheng Ren, Chuanqi Tan, Sinan Tan, JianhongTu, Peng Wang, Shijie Wang, Wei Wang, Sheng-guang Wu, Benfeng Xu, Jin Xu, An Yang, Hao Yang,Jian Yang, Shusheng Yang, Yang Yao, Bowen Yu,Hongyi Yuan, Zheng Yuan, Jianwei Zhang, Xingx-uan Zhang, Yichang Zhang, Zhenru Zhang, ChangZhou, Jingren Zhou, Xiaohuan Zhou, and TianhangZhu. 2023. Qwen technical report. arXiv preprintarXiv:2309.16609.",
  "Chen Bowen, Rune Stre, and Yusuke Miyao. 2024": "A comprehensive evaluation of inductive reasoningcapabilities and problem solving in large languagemodels. In Findings of the Association for Compu-tational Linguistics: EACL 2024, pages 323339,St. Julians, Malta. Association for ComputationalLinguistics. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020.Language models are few-shot learners.In Ad-vances in Neural Information Processing Systems,volume 33, pages 18771901. Curran Associates,Inc.",
  "Yew Ken Chia, Guizhen Chen, Luu Anh Tuan,Soujanya Poria, and Lidong Bing. 2023.Con-trastive chain-of-thought prompting. arXiv preprintarXiv:2311.09277": "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,Mark Chen, Heewoo Jun, Lukasz Kaiser, MatthiasPlappert, Jerry Tworek, Jacob Hilton, ReiichiroNakano, Christopher Hesse, and John Schulman.2021. Training verifiers to solve math word prob-lems. arXiv preprint arXiv:2110.14168. Ruixiang Cui, Daniel Hershcovich, and Anders Sgaard.2022. Generalized quantifiers as a source of error inmultilingual NLU benchmarks. In Proceedings ofthe 2022 Conference of the North American Chap-ter of the Association for Computational Linguistics:Human Language Technologies, pages 48754893,Seattle, United States. Association for ComputationalLinguistics. DeepSeek-AI, :, Xiao Bi, Deli Chen, GuantingChen, Shanhuang Chen, Damai Dai, Chengqi Deng,Honghui Ding, Kai Dong, Qiushi Du, Zhe Fu,Huazuo Gao, Kaige Gao, Wenjun Gao, Ruiqi Ge,Kang Guan, Daya Guo, Jianzhong Guo, GuangboHao, Zhewen Hao, Ying He, Wenjie Hu, PanpanHuang, Erhang Li, Guowei Li, Jiashi Li, Yao Li,Y. K. Li, Wenfeng Liang, Fangyun Lin, A. X. Liu,Bo Liu, Wen Liu, Xiaodong Liu, Xin Liu, YiyuanLiu, Haoyu Lu, Shanghao Lu, Fuli Luo, Shirong Ma,Xiaotao Nie, Tian Pei, Yishi Piao, Junjie Qiu, Hui Qu,Tongzheng Ren, Zehui Ren, Chong Ruan, ZhangliSha, Zhihong Shao, Junxiao Song, Xuecheng Su,Jingxiang Sun, Yaofeng Sun, Minghui Tang, Bingx-uan Wang, Peiyi Wang, Shiyu Wang, Yaohui Wang,Yongji Wang, Tong Wu, Y. Wu, Xin Xie, Zhenda Xie,Ziwei Xie, Yiliang Xiong, Hanwei Xu, R. X. Xu,Yanhong Xu, Dejian Yang, Yuxiang You, ShuipingYu, Xingkai Yu, B. Zhang, Haowei Zhang, LecongZhang, Liyue Zhang, Mingchuan Zhang, MinghuaZhang, Wentao Zhang, Yichao Zhang, ChenggangZhao, Yao Zhao, Shangyan Zhou, Shunfeng Zhou,Qihao Zhu, and Yuheng Zou. 2024. Deepseek llm:Scaling open-source language models with longter-mism. Preprint, arXiv:2401.02954.",
  "Usef Faghihi, Serge Robert, Pierre Poirier, and YoussefBarkaoui. 2020. From association to reasoning, analternative to pearls causal reasoning. In The Thirty-Third International Flairs Conference": "Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,Pengfei Liu, Yiming Yang, Jamie Callan, and Gra-ham Neubig. 2023. Pal: Program-aided languagemodels. In International Conference on MachineLearning, pages 1076410799. PMLR. Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen,Yujiu Yang, Nan Duan, and Weizhu Chen. 2024a.CRITIC: Large language models can self-correctwith tool-interactive critiquing. In The Twelfth Inter-national Conference on Learning Representations. Zhibin Gou, Zhihong Shao, Yeyun Gong, yelong shen,Yujiu Yang, Minlie Huang, Nan Duan, and WeizhuChen. 2024b. ToRA: A tool-integrated reasoningagent for mathematical problem solving.In TheTwelfth International Conference on Learning Repre-sentations.",
  "Hanxu Hu, Pinzhen Chen, and Edoardo M Ponti. 2024.Fine-tuning large language models with sequentialinstructions. arXiv preprint arXiv:2403.07794": "Jie Huang and Kevin Chen-Chuan Chang. 2023. To-wards reasoning in large language models: A survey.In Findings of the Association for ComputationalLinguistics: ACL 2023, pages 10491065, Toronto,Canada. Association for Computational Linguistics. Yiming Huang, Xiao Liu, Yeyun Gong, Zhibin Gou,Yelong Shen, Nan Duan, and Weizhu Chen. 2024a.Key-point-driven data synthesis with its enhance-ment on mathematical reasoning.arXiv preprintarXiv:2403.02333. Yinya Huang, Xiaohan Lin, Zhengying Liu, QingxingCao, Huajian Xin, Haiming Wang, Zhenguo Li, LinqiSong, and Xiaodan Liang. 2024b. MUSTARD: Mas-tering uniform synthesis of theorem and proof data.In The Twelfth International Conference on LearningRepresentations. Hamish Ivison*, Yizhong Wang*, Valentina Pyatkin,Nathan Lambert, Matthew Peters, Pradeep Dasigi,Joel Jang, David Wadden, Noah A. Smith, Iz Belt-agy, and Hannaneh Hajishirzi. 2023. Camels in achanging climate: Enhancing lm adaptation with tulu2. arXiv preprint. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, et al. 2023. Mistral7b. arXiv preprint arXiv:2310.06825. Pratik Joshi, Somak Aditya, Aalok Sathe, and MonojitChoudhury. 2020. TaxiNLI: Taking a ride up theNLU hill. In Proceedings of the 24th Conference onComputational Natural Language Learning, pages4155, Online. Association for Computational Lin-guistics. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B.Brown, Benjamin Chess, Rewon Child, Scott Gray,Alec Radford, Jeffrey Wu, and Dario Amodei. 2020.Scaling laws for neural language models. Preprint,arXiv:2001.08361. Pavlo Kapustin and Michael Kapustin. 2019. Model-ing language constructs with fuzzy sets: some ap-proaches, examples and interpretations. In Proceed-ings of the 13th International Conference on Com-putational Semantics - Student Papers, pages 2433,Gothenburg, Sweden. Association for ComputationalLinguistics.",
  "Kwang Hyung Lee. 2004. First course on fuzzy theoryand applications, volume 27. Springer Science &Business Media": "AitorLewkowycz,AndersJohanAndreassen,David Dohan, Ethan Dyer, Henryk Michalewski,Vinay Venkatesh Ramasesh, Ambrose Slone, CemAnil, Imanol Schlag, Theo Gutman-Solo, Yuhuai Wu,Behnam Neyshabur, Guy Gur-Ari, and Vedant Misra.2022. Solving quantitative reasoning problems withlanguage models. In Advances in Neural InformationProcessing Systems. Haoran Li, Qingxiu Dong, Zhengyang Tang, ChaojunWang, Xingxing Zhang, Haoyang Huang, ShaohanHuang, Xiaolong Huang, Zeqiang Huang, DongdongZhang, et al. 2024. Synthetic data (almost) fromscratch: Generalized instruction tuning for languagemodels. arXiv preprint arXiv:2402.13064. Yiyuan Li, Rakesh Menon, Sayan Ghosh, and ShashankSrivastava. 2023. Pragmatic reasoning unlocks quan-tifier semantics for foundation models. In Proceed-ings of the 2023 Conference on Empirical Methods inNatural Language Processing, pages 573591, Sin-gapore. Association for Computational Linguistics. Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jian-guang Lou, Chongyang Tao, Xiubo Geng, QingweiLin, Shifeng Chen, and Dongmei Zhang. 2023. Wiz-ardmath: Empowering mathematical reasoning forlarge language models via reinforced evol-instruct.Preprint, arXiv:2308.09583. Ian R. McKenzie, Alexander Lyzhov, Michael MartinPieler, Alicia Parrish, Aaron Mueller, Ameya Prabhu,Euan McLean, Xudong Shen, Joe Cavanagh, An-drew George Gritsevskiy, Derik Kauffman, Aaron T.Kirtland, Zhengping Zhou, Yuhui Zhang, SicongHuang, Daniel Wurgaft, Max Weiss, Alexis Ross,Gabriel Recchia, Alisa Liu, Jiacheng Liu, Tom Tseng,Tomasz Korbak, Najoung Kim, Samuel R. Bowman,and Ethan Perez. 2023. Inverse scaling: When big-ger isnt better. Transactions on Machine LearningResearch. Featured Certification. Swaroop Mishra, Matthew Finlayson, Pan Lu, LeonardTang, Sean Welleck, Chitta Baral, Tanmay Rajpuro-hit, Oyvind Tafjord, Ashish Sabharwal, Peter Clark,and Ashwin Kalyan. 2022. LILA: A unified bench-mark for mathematical reasoning. In Proceedings ofthe 2022 Conference on Empirical Methods in Nat-ural Language Processing, pages 58075832, AbuDhabi, United Arab Emirates. Association for Com-putational Linguistics.",
  "Vilm Novk. 2015. Fuzzy Natural Logic: TowardsMathematical Logic of Human Reasoning, pages 137165. Springer International Publishing, Cham": "Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-roll L. Wainwright, Pamela Mishkin, Chong Zhang,Sandhini Agarwal, Katarina Slama, Alex Ray, JohnSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,Maddie Simens, Amanda Askell, Peter Welinder,Paul Christiano, Jan Leike, and Ryan Lowe. 2024.Training language models to follow instructions withhuman feedback. In Proceedings of the 36th Interna-tional Conference on Neural Information ProcessingSystems, NIPS 22, Red Hook, NY, USA. CurranAssociates Inc. Keiran Paster, Marco Dos Santos, Zhangir Azerbayev,and Jimmy Ba. 2024.Openwebmath: An opendataset of high-quality mathematical web text. InThe Twelfth International Conference on LearningRepresentations. Rafael Rafailov, Archit Sharma, Eric Mitchell, Christo-pher D Manning, Stefano Ermon, and Chelsea Finn.2023. Direct preference optimization: Your languagemodel is secretly a reward model. In Thirty-seventhConference on Neural Information Processing Sys-tems.",
  "Sonia Ramotowska, Julia M. Haaf, Leendert van Maa-nen, and Jakub Szymanik. 2024. Most quantifiershave many meanings. Psychonomic bulletin & re-view": "Baptiste Rozire, Jonas Gehring, Fabian Gloeckle, StenSootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi,Jingyu Liu, Romain Sauvestre, Tal Remez, JrmyRapin, Artyom Kozhevnikov, Ivan Evtimov, JoannaBitton, Manish Bhatt, Cristian Canton Ferrer, AaronGrattafiori, Wenhan Xiong, Alexandre Dfossez,Jade Copet, Faisal Azhar, Hugo Touvron, Louis Mar-tin, Nicolas Usunier, Thomas Scialom, and GabrielSynnaeve. 2024. Code llama: Open foundation mod-els for code. Preprint, arXiv:2308.12950.",
  "Zhengyang Tang, Xingxing Zhang, Benyou Wan, andFuru Wei. 2024.Mathscale: Scaling instructiontuning for mathematical reasoning. arXiv preprintarXiv:2403.02884": "Ross Taylor, Marcin Kardas, Guillem Cucurull, ThomasScialom, Anthony Hartshorn, Elvis Saravia, An-drew Poulton, Viktor Kerkez, and Robert Stojnic.2022. Galactica: A large language model for science.Preprint, arXiv:2211.09085. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian CantonFerrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. 2023. Llama 2: Open foundation and fine-tuned chat models. Preprint, arXiv:2307.09288.",
  "Fei Yu, Hongbo Zhang, Prayag Tiwari, and BenyouWang. 2023. Natural language reasoning, a survey.ACM Computing Surveys": "Longhui Yu, Weisen Jiang, Han Shi, Jincheng YU,Zhengying Liu, Yu Zhang, James Kwok, Zhenguo Li,Adrian Weller, and Weiyang Liu. 2024. Metamath:Bootstrap your own mathematical questions for largelanguage models. In The Twelfth International Con-ference on Learning Representations. Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wen-hao Huang, Huan Sun, Yu Su, and Wenhu Chen.2024. MAmmoTH: Building math generalist modelsthrough hybrid instruction tuning. In The Twelfth In-ternational Conference on Learning Representations.",
  "Lotfi A. Zadeh. 1968. Probability measures of fuzzyevents. Journal of Mathematical Analysis and Appli-cations, 23:421427": "Beichen Zhang, Kun Zhou, Xilin Wei, Xin Zhao, JingSha, Shijin Wang, and Ji-Rong Wen. 2024a. Eval-uating and improving tool-augmented computation-intensive math reasoning. Advances in Neural Infor-mation Processing Systems, 36. Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang,Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tian-wei Zhang, Fei Wu, et al. 2023. Instruction tuningfor large language models: A survey. arXiv preprintarXiv:2308.10792. Xinlu Zhang, Zhiyu Zoey Chen, Xi Ye, Xianjun Yang,Lichang Chen, William Yang Wang, and Linda RuthPetzold. 2024b. Unveiling the impact of coding datainstruction fine-tuning on large language models rea-soning. Preprint, arXiv:2405.20535.",
  "AQuantifier Semantics in FROG": "To further measure the difficulty of FRoG ques-tions, we introduce the relative distance betweenthe target percentage value and the GQ choices.Specifically, given a question, the value of targetpercentage mention p, the mean strength of thegolden GQ choice qg and the mean strength of theincorrect GQ choice qm that is closest to p, therelative distance RelDist is calculated by",
  "abs(qg p) + abs(qm p)": "where abs() represents the operation of comput-ing the absolute value. Here, RelDist indicates theproportional closeness of p to qg and lower is better.The average RelDist is 0.3 in FROG. 21.3% ques-tions have RelDist smaller than 0.2, 63.8% haveRelDist smaller than 0.4, and all questions haveRelDist smaller than 0.5. The average RelDist bygeneralized quantifiers is listed in .",
  "DQuantifier Understanding Across Scale": "We demonstrate examples from Qwen-1.5-Chatin FRoG-Hardwhere models of different numberof parameters hold different understanding of GQsemantics in . Take Ex1 for example, The7B, 14B and 72B version of Qwen-1.5-Chat allcompute the target target mention 0.5 correctly,but reaching to different GQ preferences (smallamount, moderate amount and some) regardinginterpreting the target percentage value. We list theexploration of aligning model behavior to specificquantifier interpretation as future work.",
  ": Inverse scaling checkbox, the two checks represent inverse scaling effect (less than 1 point performancegain by scaling model sizes) observed on FRoG-Easy (left) and FRoG-Hard (right) respectively": "Ex1: From the sale of sleeping bags, a retailer made a gross profit of [MASK] of the wholesale cost. If each sleeping bagwas sold for $28, what was the wholesale cost per bag?If the answer to the question is 24.78, then please select the quantifier that is closest to the meaning of [MASK] from thefollowing choices. [13%]A. some B. small amount C. few D. tiny amount Suppose the gross profit percentage is x and the wholesale cost is W per bag. Then the selling price (SP) per bag is $28,and the actual relation can be established using: SP = W + x% of W 28 = W + (x/100) * W 28 = W(1 + x/100) W = 28 /(1 + x/100)Given that W is $24.78, 24.78 = 28 / (1 + x/100) 1 + x/100 = 28 / 24.78 x/100 = (28 / 24.78) - 1 x/100 = 1.13 - 1 x/100 =0.13 x = 13Therefore, the gross profit percentage is 13%. This percentage is a moderate amount, not minimal, nor very large.Checking the choices, none represent precisely 13%, but thinking about its relative value:- some generally suggests a moderate, indefinite amount- small amount, few, and tiny amount suggest smaller proportionsThus, among all the choices, some is the best fit for representing a gross profit of 13% of the wholesale cost. Ex2: A shopkeeper has 280 kg of apples. He sells 30% of these at 20% profit and the remaining 60% at [MASK] profit.Find his % profit on total. If the answer to the question is 24%, then please select the quantifier that is closest to themeaning of [MASK] from the following choices. [20%]A. some B. moderate amount C. small amount D. few The shopkeeper has 280 kg of apples. 30% of these apples sold at 20% profit means 0.3 * 280 = 84 kg sold at 20% profit.The remaining 60% sold at an unknown percentage, x, of profit is 0.6 * 280 = 168 kg.To find the total profit percentage on the whole 280 kg:1. Calculation for profit from the first 84 kg: Profit = 20% of 84 kg = 0.2 * 84 = 16.8 kg equivalent profit.2. Calculation for profit from the remaining 168 kg: Profit = x% of 168 kg = 0.01x * 168 = 1.68x kg equivalent profit.Now, total profit from 280 kg = (16.8 + 1.68x) kg.Total profit percentage = (Total profit / Total kg) * 100 = [(16.8 + 1.68x) / 280] * 100 = (0.06 + 0.006x) * 100 = 6 + 0.6x.Given the problem, the total profit percentage is 24%: 6 + 0.6x = 24 0.6x = 24 - 6 0.6x = 18 x = 18 / 0.6 x = 30%.So, the remaining 60% of apples were sold at 30% profit. Looking at the choices given for the interpretation of [MASK],the closest to a 30% profit level among the options provided is \"moderate amount\", considering it reflects a sizable yetnot excessively high-profit margin. Ex3: A candidate appearing for an examination has to secure [MASK] marks to pass paper i. But he secured only 45marks and failed by 25 marks. What is the maximum mark for paper i? If the answer to the question is 127, then pleaseselect the quantifier that is closest to the meaning of [MASK] from the following choices. [55%]A. moderate amount B. some C. all D. most The candidate secured 45 marks and failed by 25 marks. This means the passing mark for paper I is 45 marks + 25 marks= 70 marks.Since the maximum mark for paper I is given to be 127, the passing mark (70 marks) out of the maximum (127 marks)represents more than 50% but significantly less than 100%. This suggests a quantifier that indicates a majority but notthe entirety or something overly general.Among the choices:A. moderate amount - This generally indicates a reasonable or average proportion, not specifically majority.B. some - Generally refers to an unspecified quantity, not necessarily a majority.C. all - This would indicate the entirety, which is not suitable here as 70 is less than 127.D. most - This generally refers to the majority or the largest part but not the entirety, fitting the criterion where 70 ismore than half of 127 but not all of it.Therefore, most is the quantifier that is closest to the meaning required for the passing marks in the context given. ####D",
  ": Extra sampled results from GPT-4-turbo in FROG, where explicit quantifier estimation is highlighted": "Ex1 Mary can do a piece of work in 12 days. rosy is [MASK] more efficient than mary. the number of days taken byrosy to do the same piece of work is? If the answer to the question is 8, then please select the quantifier that is closest tothe meaning of [MASK] from the following choices. [50%]A. moderate amount B. some C. most D. small amount [Qwen-1.5-72B-Chat] If Mary takes 12 days to complete the work, Rosy, who is more efficient, will take less time.Lets say Marys efficiency is 1 unit of work per day, then Rosys efficiency is Marys plus [MASK] units. If Rosy is xtimes more efficient than Mary, her efficiency would be (1+x) units per day.Since the work is the same for both, we can equate the efficiency in terms of time:Mary: 1 unit/day * 12 days = 12 unitsRosy: (1+x) units/day * d days = 12 unitsSolving for d, we have 12 / (1 + x) = dGiven the answer is 8 days for d, we can plug this value back into the equation to find x:12 / (1 + x) = 81 + x = 12 / 81 + x = 1.5x = 0.5Since 0.5 represents a \"small amount\" more efficiency, the answer is D. small amount. #### D [Qwen-1.5-14B-Chat] Suppose Marys work efficiency is M days work. Then, Rosys efficiency is M + [MASK]days work. Given, Rosy can complete the work in X days.So, (M + [MASK]) * X = M * 12Given X = 8 days, we can find what [MASK] represents:12M / X = M + [MASK]12 / 8 = 1 + [MASK][MASK] = 12 / 8 - 1[MASK] = 3/2 - 1[MASK] = 1/2This means Rosy is half as efficient as Mary, or in other words, she takes twice the time. This corresponds to a \"moderateamount\" of difference because, compared to most or a large amount, which would be a huge difference, a small amountwouldnt result in Rosy taking twice as much time. The other options are some or tiny amount, which are not asaccurate as moderate amount in this context because they could mean a lesser extent of efficiency difference.Therefore, the answer is A. moderate amount [Qwen-1.5-7B-Chat] Rosy is x times more efficient than Mary. So, the time taken by Rosy is 12 / (1 + x) days.We are given that 12 / (1 + x) = 8.Lets solve for x: (1 + x) = 12 / 8 = 1.5Simplifying x, x = 0.5.This means that Rosy is half as efficient as Mary. So, some is the closest quantifier choice for most. If x were to be atiny portion, this would not make sense. Therefore, the answer is some (or B). #### B : Examples of Qwen-1.5-Chat models on FRoG where models of different parameters compute similarpercentage values about the target percentage mention, but holding different opinions about the quantifier choice.The explicit quantifier estimation is highlighted.",
  "### Problem TemplateQuestion:{FRoG Question}Answer:Lets think step by step": "### FRoG Question Template[MASK]:{Question}{Choices}If the answer to the question is {Original Answer}, then please select the quantifier that is closest to the meaning of[MASK] from the following choices. [Mislead]:{Question}{Choices}If the answer to the question is {Original Answer}, and {Mislead Quantifier} in the question is not correct, please selectthe most appropriate quantifier from the following choices.",
  "Instruction used for FRoG Evaluation": "You are an expert in mathematical reasoning and generalized quantifier reasoning. Here you are asked to answerone mathematical question based on real-life scenarios with a description starting with Question: For example, thequestion may describe the driving experience of a person. Your answer will start with Answer: lets think step by step."
}