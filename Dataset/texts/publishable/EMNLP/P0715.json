{
  "Abstract": "Large language models (LLMs) have shownexcellent capability for solving reasoning prob-lems. Existing approaches do not differentiatethe question difficulty when designing prompt-ing methods for them. Clearly, a simple methodcannot elicit sufficient knowledge from LLMsto answer a hard question. Meanwhile, a so-phisticated one will force the LLMs to generateredundant or even inaccurate intermediate stepsfor a simple question. Consequently, the per-formance of existing methods fluctuates amongvarious questions. In this work, we propose Adaption-of-Thought(ADOT), an adaptive method, to improve LLMsfor the reasoning problem, which first measuresthe question difficulty and then tailors demon-stration set construction and difficulty-adaptedretrieval strategies for the adaptive demonstra-tion construction. Experimental results on threereasoning tasks prove the superiority of our pro-posed method, showing an absolute improve-ment of up to 5.5% on arithmetic reasoning,7.4% on symbolic reasoning, and 2.3% on com-monsense reasoning.1",
  "Introduction": "Reasoning refers to the drawing of inferencesthrough the use of reason. Solving reasoning tasksrequires substantial knowledge and powerful ana-lytical capabilities, which can narrow the gap be-tween human and machine intelligence (Qiao et al.,2023). Previous small language models (SLMs)based methods often adopt the fine-tuning tech-nique to enhance their performance. However, thereasoning ability of SLMs is naturally limited bythe size of their parameters and fine-tuning requiresabundant labor-intensive labeled data. Recently,large language models (LLMs) (Brown et al., 2020;Thoppilan et al., 2022; Chowdhery et al., 2023)",
  ": The results by different LLM based reasoningmethods on the AQUA dataset": "have demonstrated significant efficacy in varioustasks. Reasoning by prompting LLMs has alsoattracted wide attention. Typical methods includeautomatic demonstration construction (Zhang et al.,2023; Wan et al., 2023), rationale refinement (Fuet al., 2023), reasoning in code format (Chen et al.,2022), iteratively reasoning (Zheng et al., 2023; Xiet al., 2023), problem decomposition (Press et al.,2023; Zhou et al., 2023), problem planing (Wanget al., 2023a), and prompting ensemble (Wang et al.,2023b; Naik et al., 2023).Despite the effectiveness of these methods, it isinteresting that none of them can consistently per-form the best on most datasets on three reasoningtasks as shown in . So what is the reasonfor such a phenomenon? Can we develop a methodthat performs generally well beyond the datasetsand tasks? With these in mind, we choose two so-phisticated prompting methods PHP (Zheng et al., 2023) and COMPLEX-COT (Fu et al., 2023) and onesimple method STANDARD (Brown et al., 2020) asexamples to investigate their performance on theAQUA dataset. The results are shown in (a).Overall, PHP and COMPLEX-COT perform muchbetter than STANDARD. However, the pie chartsin (a) show that there are up to 13.4% and12.6% questions to which STANDARD can answercorrectly but PHP and COMPLEX-COT cannot. Acloser look reveals that the reason can be the mis-match between the question difficulty and the com-plexity of the method.Given the easy question in (b), PHP it-erates four times and COMPLEX-COT builds thehighly complex demonstration to interact with theLLM. The generated redundant information mis-leads the model to produce wrong answers. Mean-while, STANDARD, which only contains the samplequestions and their final answer in its demonstra-tions, gets the correct answer. On the contrary,given the hard question in (c), PHP andCOMPLEX-COT give correct answers, but STAN- DARD fails since its simple demonstration preventsit from drawing out sufficient knowledge from theLLM.To address the mismatch problem, we proposea novel Adaption-of-Thought (ADOT) method toadaptively adjust the complexity of the promptingmethod to the question difficulty. Specifically, wefirst present a difficulty measuring approach forquestions which computes the syntactic and seman-tic complexity of their rationales. We then proposea demonstration set construction and a difficulty-adapted retrieval strategy to adaptively constructreasonable demonstrations based on the difficultyof the questions. Extensive experimental resultsprove that our proposed ADOT method surpassescompetitive baselines on all tasks. In summary, themain contributions of our work are as follows.",
  "Related Work": "This section reviews the literature on reasoning.Reasoning by Fine-tuning SLMs. SLMs-basedreasoning methods (Rajani et al., 2019) need tofine-tune on task-oriented or domain-specific datato enhance their performance. For example, Tal-mor et al. (2020) trained RoBERTa (Liu et al.,2019) on both implicit pre-trained knowledge andexplicit free-text statements to symbolic reason-ing. Hendrycks et al. (2021) fine-tuned the GPT-2(Radford et al., 2019) to generate full step-by-stepsolutions to arithmetic reasoning.Though these approaches have shown betterperformance than traditional rule-based (Fletcher,1985; Yuhui et al., 2010), symbolic-based (Ligudaand Pfeiffer, 2012; Shi et al., 2015), and statistical-based (Koncel-Kedziorski et al., 2015a; Upadhyayet al., 2016) methods, their reasoning ability hasbeen limited by the size of SLMs. Moreover, thefine-tuning of SLMs requires high-quality trainingdata, which is quite labor-intensive.Reasoning by Prompting LLMs. LLMs-basedapproaches have become prevalent in recent yearsand prompting is the main way to interact withLLMs. Many prompting methods have been pro-posed for reasoning problems (Chen et al., 2022;Wang et al., 2023a; Nathani et al., 2023; Wanget al., 2023b; Wan et al., 2023). The first attemptwas made by Brown et al. (2020), which developeda ZERO-SHOT prompting method by adding a natu-ral language description of the task in the prompt.Notably, Chain-of-Thought (COT) prompting (Weiet al., 2024), which performed the multi-step rea-soning through step-by-step rationale examples,achieved excellent performances in reasoning. Ko-jima et al. (2022) found that adding instructions toencourage LLMs to automatically reason throughsome intermediate processes also contribute to im-proving performance. Subsequently, a series ofstudies optimized the COT prompting by decom-posing the problem or refining the rationale anddemonstration from various perspectives (Zhenget al., 2023; Zhang et al., 2023; Fu et al., 2023;Press et al., 2023; Zhou et al., 2023).While these LLMs-based methods have madeimpressive progress, none of them has taken thedifficulty of the question into consideration, lead-ing to a mismatch between the problem and thesolution. In contrast, our method can automaticallyadapt the demonstration to questions with varyingdifficulty.",
  "Method Overview": "As analyzed in the introduction, a simple promptcannot elicit sufficient knowledge from LLMs toanswer a hard question, while a sophisticated onewill force the LLM to generate redundant or eveninaccurate intermediate steps for a simple ques-tion. To overcome the mismatch between the ques-tion difficulty and the prompting complexity, wepropose an adaption-of-thought (ADOT) reason-ing method, which consists of three modules. Asshown in , ADOT first measures question",
  "Measuring Question Difficulty": "The question difficulty often lies in how much ef-fort needs to be made to answer it, since it is hardto measure the difficulty directly. In light of this,we propose to measure the question difficulty fromits rationale. We first generate the rationales ofdifferent target questions using uniform demonstra-tions (Wei et al., 2024) to avoid the influence fromdifferent demonstrations. Then, we measure thedifficulty of each question based on the complexityof its rationale, which can be further partitionedinto syntactic complexity and semantic complexity.Measuring syntactic complexity. In applied lin-guistics, syntactic complexity refers to the rangeof forms that surface in language production andthe degree of sophistication of such forms (Ortega,2003). The higher syntactic complexity of a ra-tionale indicates the more intricate articulation ofthe problem-solving process. Generally, the textlength of a rationale is positively correlated withthe syntactic complexity of the rationale (Ortega,2003; tajner and Saggion, 2013; Hwang and Polio,2023). Hence we measure the syntactic complexityCsyni of a rationale ri by its text length as:",
  "Measuring semantic complexity. When reason-": "ing for a question, the question is hard to answerif a lot of extra knowledge needs to be introducedin its rationale. Generally, semantic words can beviewed as the carrier of knowledge. Hence, wemeasure the semantic complexity of a rationale riby calculating the newly added non-repetitive se-mantic words in ri compared to qi. The numberof non-repetitive semantic words sem(x) in thetext x can be obtained through a simple procedure3.The semantic complexity Csemi of the i-th targetquestion is then calculated as:",
  "After getting the difficulty of target questions, weconstruct demonstrations with different complexityto match target questions.Initially, we can take the original FEW-SHOT-": "COT demonstrations (Wei et al., 2024) to promptLLMs to generate sample rationales for samplequestions. However, we find that the sample ra-tionales generated in this way are often not satis-fying. Specifically, when the difficulty of samplequestions gradually increases, the coreference phe-nomena and over-complicated reasoning processgradually appear in their sample rationales, whichprevents LLMs from understanding sample ratio-nales due to their weak semantics and confusinglogic. Besides, even we have optimized the orig-inal demonstrations, LLMs cannot generate mul-tiple sample rationales with significantly varyingcomplexity for one sample question.Based on the above observation, we propose tonot only improve the quality of the original demon-strations in Wei et al. (2024) but also generate ahigh-quality demonstration set for a predefined Nnumber of randomly selected sample questions4.This demonstration set will finally be used to solvethe mismatch problem by providing LLMs withmore choices of high-quality sample rationales 3The detail procedures are depicted in Appendix A, whichcan be easily reproduced by following the given steps.4These sample questions are randomly selected from unla-beled question corpus, which is depicted in Appendix B. whose complexity is similar to the difficulty ofthe target questions. To this end, we first categorizethe N sample questions into three difficulty sec-tions (easy, normal, and hard). Then, we constructthe optimized demonstrations for these questionsin different sections. Our goal is to eliminate thecoreference phenomena in both normal and hardsections and optimize the overcomplicated reason-ing process in hard section.Categorizing questions by difficulty. We firstuse the same approach described in .3 tomeasure the difficulty of the sample questions. Instatistics, the coefficient of variation is a standard-ized measure of the dispersion of a distribution.Hence, the coefficient of variation v of all samplequestions difficulty can measure their dispersion,which is calculated as:",
  "1nni=1di d2,(5)": "where v , n and d are the number and theaverage difficulty of all sample questions, respec-tively. The higher v is, the more dispersed thedistribution of difficulty will be. In other words, ahigher v means more easy and hard questions areat the two ends of the distribution. Hence, we takehalf of the coefficient of variation, p = v/2, as theproportion of easy and hard questions. The rest1-2 p is the proportion of the normal question.Finally, the proportion of easy, normal, and hardquestions is:",
  "p : 1 2 p : p(6)": "Generating same rationales for easy samplequestions. Generally, the sample rationales of easysample questions are simple and easy for LLMs tounderstand. Hence, when generating rationales forthem, we directly take the original FEW-SHOT-COTdemonstrations.Generating high-quality sample rationales fornormal sample questions. For sample questionsin the normal section, the coreference phenomenaoccur frequently in their rationales generated by theoriginal FEW-SHOT-COT demonstrations. Corefer-ence in linguistics refers to the phenomenon wheretwo or more expressions in a text refer to the sameperson, place, thing, event, etc. For example, in thesentence Tom met Harry in the park. He lent himhis hat. He said that he liked it, expressions withthe same color refer to the same person or thing.Coreferences pose a big challenge on LLMs (Leand Ritter, 2023), especially for pronouns which are hard to interpret due to their weak semanticmeanings (Ehrlich, 1981; Zhang et al., 2019; Zhaoet al., 2022). Coreference resolution aims to findthe correct reference for a given anaphor, which isa key aspect of natural language understanding as ithelps establish the relationship among different textcomponents. The coreference resolution result forthe former example is Tom met Harry in the park.Tom lent Harry Toms hat. Harry said that Harryliked Toms hat, which is easy to understand.To generate high-quality rationales for normalsample questions, we optimize the original FEW- SHOT-COT demonstrations through coreference res-olution, which can be realized with the help ofneuralcoref toolkit5 and linguistic rules (Jurafskyand Martin, 2019). Coreference resolution main-tains the form of rationales in FEW-SHOT-COTdemonstrations and consolidates their logical clar-ity among the internal reasoning processes. In thisway, LLMs will mimic the high-quality demonstra-tions and try to avoid using coreference in theirgenerated content.Generating high-quality sample rationales forhard sample questions. For sample questions inthe hard section, over-complicated reasoning pro-cesses can often be observed in their sample ratio-nales generated by the FEW-SHOT-COT demonstra-tions. Specifically, when the sample questions arehard, their sample rationales are often complex andchallenging for LLMs to understand. The main rea-son is the lack of detailed connections among thereasoning steps in the over-complicated reasoningprocesses. Step decomposition aims to add steps inthe reasoning process to bridge this gap.",
  "To generate high-quality rationales for hard sam-ple questions, we optimize the original FEW-SHOT-": "COT demonstrations through both coreference res-olution and step decomposition. As shown in Ta-ble 1, after adding Step 2 between Step 1 and Step3, the logical clarity of the reasoning process ismore clear. Step decomposition changes the formof rationales in FEW-SHOT-COT demonstrationsand consolidates their logical clarity of the reason-ing procedure. In this way, LLMs will mimic thehigh-quality demonstrations and try to generate a",
  "Adaptively Retrieving Demonstration": "Although we have measured the difficulty of thequestion, it is hard for LLMs to grasp the subtlemeaning of difficulty. Therefore, we propose adifficulty-adapted retrieval method to show LLMswith several adaptive demonstrations whose com-plexity is similar to the difficulty of the target ques-tion. In this way, we not only elicit sufficient knowl-edge, but also avoid generating redundant or eveninaccurate intermediate steps from LLMs.Our difficulty-adapted retrieval method fetchesadaptive demonstrations from the demonstrationset constructed in .4. Remember that eachdemonstration corresponds to a sample questionwith a specific difficulty. Hence, we can leveragethe difficulty of the sample question to enhanceLLMs understanding of difficulty. Specifically,we adaptively retrieve M demonstrations from thedemonstration set. The difference between thesedemonstrations complexity, i.e., their correspond-ing sample questions difficulty, and the target ques-tions difficulty is minimal. Then, we concatenatethe target question behind the demonstrations andsend them to the LLMs together. Therefore, LLMswill mimic the demonstrations and generate suit-able rationales for the target questions, i.e., wefinally solve the mismatch problem.",
  "Experimental Setup": "Datasets: We adopt ten benchmark datasets acrossthree reasoning tasks. Arithmetic: AQUA (Linget al., 2017), GSM8K (Cobbe et al., 2021), SVAMP(Patel et al., 2021), MultiArith (Roy and Roth,2015), AddSub (Hosseini et al., 2014), SingleEq(Koncel-Kedziorski et al., 2015b). Symbolic: LastLetters (Wei et al., 2024), Coin Flip (Wei et al.,2024).Commonsense: CSQA (Talmor et al., 2019),StrategyQA (Geva et al., 2021). Detailed statistics,including average difficulty and some parameters,are shown in Appendix D.Baselines: We compare with thirteen state-of-the-art (sota) methods, including five Zero-shot settingmethod: ZERO-SHOT, ZERO-SHOT-COT (Kojimaet al., 2022), PS+ (Wang et al., 2023a), AUTO-",
  ": Main experimental results. Bold: the best score. Underline: the second best score. -: not applicable": "and eight Few-shot setting methods: STANDARD(Brown et al., 2020), FEW-SHOT-COT (Wei et al.,2024), POT (Chen et al., 2022), COMPLEX-COT(Fu et al., 2023), SELF-ASK (Press et al., 2023),LEAST-TO-MOST (Zhou et al., 2023), SP (Xi et al.,2023), PHP (Zheng et al., 2023). More detailsare shown in Appendix E. Methods like SELF- CONSISTENCY (Wang et al., 2023b), DIV-SE andIDIV-SE (Naik et al., 2023) must generate multiplerationales then ensemble them, i.e., their settingsare different from our method and all baselines.Hence, we follow all previous works to excludethem for fair comparison.Implementation details: For fair comparison, weadopt the gpt-3.5-turbo-0613 engine of GPT-3.5 for all methods in the main experiment. Theonly exception is POT (Chen et al., 2022). Wedirectly take its results since POT requires a code-davinci-002 engine, which is unavailable now. Thetemperature is set to 0 to ensure the stability andrepeatability. We employ accuracy (%) as the met-ric. The demonstration set size N for all datasetsis set to 50 uniformly without further tuning. Aparameter study for N is given in section 4.6. Thenumber of demonstrations M for different datasetsis consistent with previous methods (Zhang et al.,2023; Wei et al., 2024; Press et al., 2023; Zhouet al., 2023; Xi et al., 2023; Zheng et al., 2023)",
  "presents the main experimental results.Compared to the baselines, our proposed ADOTnot only obtains the average sota performance on": "all ten datasets of three tasks but also performs thebest on almost each dataset. This demonstratesthat our ADOT consistently performs better thanall baselines, which cannot be achieved by any ofthe previous sota methods. We argue that the rea-son for this phenomenon is that previous methodsare only good at answering questions in a specificdifficulty range. We now analyze task by task.(1) For the arithmetic task, the most challeng-ing dataset is AQUA, with an average difficulty of117.4. The representative complex methods, PHPand COMPLEX-COT, yield the previous best andsecond-best performance on it. The least challeng-ing dataset for this task is AddSub (average diffi-culty: 36.2), and the simple method FEW-SHOT- COT produces the optimal baseline results on it.These results clearly demonstrate the importanceof matching between prompting complexity andquestion difficulty.(2) For the commonsense task, the simple STAN- DARD and the complex PHP perform the best oneasy CSQA dataset (average difficulty: 36.1) andhard StrategyQA dataset (average difficulty: 49.0),which also proves the significance of matching.(3) For the symbolic task, COMPLEX-COT andPHP perform well on Last Letter and Coin Flip,respectively. Meanwhile, simple STANDARD andZERO-SHOT, perform the worst on them, respec-tively. The contrast performance between complexand simple methods shows that the mismatchingwill lead to terrible performance.In summary, our ADOT is a widely-adaptive andpractically applicable method with superior perfor-",
  "Ablation Study": "We conduct an ablation study to examine how dif-ferent components of our method influence theperformance, including: the syntactic complex-ity (SynComp), semantic complexity (SemComp),step decomposition (SD), coreference resolution(CR), and all these strategies (All). The results areshown in . The w/o CR means remov-ing both SD and CR strategies since the former iscarried out based on the latter.From , we can find that all componentsare essential to ADOT. Both SynComp and Sem-Comp contribute to the performance improvementin three tasks, and the contribution of SemComp ismore significant than SynComp. The main reasonis that SemComp emphasizes the knowledge-levelcomplexity and the reasoning problems are moresensitive to knowledge.Remember that SD and CR strategies are pro-posed for constructing a high-quality demonstra-tion set, and the results in prove their ef-fectiveness on all three tasks. Hence, high-qualitydemonstrations are critical to high performance.After removing all strategies, the performanceof the w/o All variant dramatically drops by apercentage of 4.1 on average, showing that the com-",
  "Adaptability for Different Difficulty": "To examine the adaptability on questions with dif-ferent difficulty, we investigate the accuracy of thetypical simple method FEW-SHOT-COT, the typicalcomplex method COMPLEX-COT, and ADOT inthree difficulty sections6. shows the results. Generally, the simple FEW-SHOT-COT performsbetter than the complex COMPLEX-COT in the easysection, and the opposite result is found in the hardsection. All these show that the mismatch prob-lem is worth pondering when answering a question.Compared with the above methods, ADOT can out-perform them in easy, normal, and hard sections inmost cases due to the adaptive ability. Moreover, the accuracy on easy section is alsomuch higher than that on normal section. Thesame case exists in normal section and hard section.These results prove that our difficulty measuringand difficulty section partitioning strategies effec-tively build the connection between the questionand the prompting method based on the difficulty.",
  "Effectiveness of Retrieval Method": "To examine the effectiveness of our difficulty-adapted retrieval method, we compare it with threeretrieval methods and show the results in .(1) The difficulty-reversed method retrieves Mdemonstrations where the sample questions havethe biggest difficulty gap to the target questions. (2)The similarity-based method retrieves M demon-strations where the sample questions have the clos-est text similarity to the target questions. We adoptthe ALL-MPNET-BASE-V27 to obtain the questionembedding and leverage the cosine similarity tocalculate the text similarity. (3) The random-basedmethod randomly retrieves M demonstrations.From , it is clear that our difficulty-adapted method achieves the best performance onall datasets. On the contrary, the difficulty-reversedmethod always performs worse than other methods,including the random-based one. These resultsprove that the mismatch between the question dif-ficulty and the prompting complexity will hindereliciting proper knowledge from LLMs. Further-more, we believe that the idea of difficulty-adaptedretrieval can be applied to more domains since themismatch problem may generally exist.",
  "The Parameter Study of DemonstrationSet Size": "We explore the effect of different demonstrationset sizes on the largest arithmetic dataset, GSM8K. shows the experimental results.Small demonstration set sizes, such as 10, obvi-ously prevent our ADOT method from performingwell. When the size is small, the difficulty-adaptedretrieval method of ADOT may not retrieve properdemonstrations whose complexity is similar to thetarget question. As the demonstration set size in-creases to no less than 30, the performance of our",
  "Case Study": "We present an easy and a hard question for thecase study, where PHP and COMPLEX-COT aresophisticated methods, and FEW-SHOT-COT andSTANDARD are simple ones.As shows, simple methods, which containsample questions with low syntactic and semantic complexity, always generate straightforward rea-soning processes. Meanwhile, sophisticated meth-ods, which contain sample questions with highsyntactic and semantic complexity, tend to gener-ate complex reasoning processes. Hence, simple/-sophisticated methods fail to solve the hard/easyquestion due to the mismatch between the ques-tion difficulty and the prompting complexity. Incontrast, our ADOT method can well address thismismatch problem by adaptively retrieving samplequestions with proper syntactic and semantic com-plexity. Consequently, it can elicit proper knowl-edge no matter the question is easy or hard.",
  "Supplement Experiments": "We conduct more supplement experiments to pro-vide a more detailed understanding of our method.(1) The computational efficiency experimentsand analysis are shown in Appendix F. In summary,our method improves reasoning performance andmaintains high computational efficiency.(2) To investigate the generalization of the meth-ods on different LLMs with different sizes, we con-duct experiments on the Llama2-chat family (Tou-vron et al., 2023). The detailed results and analysisare shown in Appendix G. In short, our ADOT cangenerally outperform the baselines regardless ofthe LLM sizes.(3) We build multiple optimized demonstrationswith different words and structures to analyze thesensitivity of our method to them in Appendix H.Overall, keeping the meaning of the sample ratio-nales invariable and the answer format consistentare essential to maintain stable performance.",
  "Conclusion": "In this paper, we find the mismatch between thequestion difficulty and the prompting complexitywill hinder eliciting proper knowledge from LLMs.To solve this problem, we propose a novel ADOTmethod to adaptively adjust the complexity of thepromoting method based on the difficulty of thetarget question. We first propose a difficulty mea-surement strategy. Then, we construct a demonstra-tion set through the optimized demonstrations. Fi-nally, we present a difficulty-adapted retrieval strat-egy to adaptively retrieve reasonable demonstra-tions based on the difficulty of the target question.A series of experiments prove that the mismatchproblem is critical in reasoning and our methodis effective on this problem. Consequently, our",
  "Limitations": "In our ADOT method, adaptively constructing ademonstration set requires some unlabeled samplequestions. Previous works (Zhang et al., 2023; Wanet al., 2023) obtain these unlabeled sample ques-tions from the test set directly, which is not practi-cal and reasonable as we illustrate in Appendix B.Hence, we obtain these unlabeled sample questionsfrom the unlabeled question corpus. Although theunlabeled question corpus is easy to obtain from thecollections of history queries, it may take some ex-ternal time consumption to collect such unlabeledquestions.",
  "Wenhu Chen, Xueguang Ma, Xinyi Wang, andWilliam W. Cohen. 2022.Program of thoughtsprompting: Disentangling computation from reason-ing for numerical reasoning tasks. arXiv preprintarXiv:2211.12588": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,Maarten Bosma, Gaurav Mishra, Adam Roberts, PaulBarham, Hyung Won Chung, Charles Sutton, Sebas-tian Gehrmann, et al. 2023. Palm: Scaling languagemodeling with pathways. Journal of Machine Learn-ing Research, 24(240):1113. Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,Mark Chen, Heewoo Jun, Lukasz Kaiser, MatthiasPlappert, Jerry Tworek, Jacob Hilton, ReiichiroNakano, et al. 2021. Training verifiers to solve mathword problems. arXiv preprint arXiv:2110.14168.",
  "Charles R Fletcher. 1985. Understanding and solvingarithmetic word problems: A computer simulation.Behavior Research Methods, Instruments, & Comput-ers, 17(5):565571": "Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, andTushar Khot. 2023. Complexity-based prompting formulti-step reasoning. In The Eleventh InternationalConference on Learning Representations, ICLR 2023,Kigali, Rwanda, May 1-5, 2023. OpenReview.net. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,Dan Roth, and Jonathan Berant. 2021. Did aristotleuse a laptop? a question answering benchmark withimplicit reasoning strategies. Transactions of theAssociation for Computational Linguistics, 9:346361. Dan Hendrycks, Collin Burns, Saurav Kadavath, AkulArora, Steven Basart, Eric Tang, Dawn Song, andJacob Steinhardt. 2021. Measuring mathematicalproblem solving with the math dataset. In Thirty-fifth Conference on Neural Information ProcessingSystems Datasets and Benchmarks Track (Round 2). Mohammad Javad Hosseini, Hannaneh Hajishirzi, OrenEtzioni, and Nate Kushman. 2014. Learning to solvearithmetic word problems with verb categorization.In Proceedings of the 2014 Conference on EmpiricalMethods in Natural Language Processing (EMNLP).",
  "Dan Jurafsky and James H Martin. 2019. Speech andlanguage processing (3rd (draft) ed.)": "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-guage models are zero-shot reasoners. Advances inneural information processing systems, 35:2219922213. Rik Koncel-Kedziorski, Hannaneh Hajishirzi, AshishSabharwal, Oren Etzioni, and Siena Dumas Ang.2015a. Parsing algebraic word problems into equa-tions. Transactions of the Association for Computa-tional Linguistics, 3:585597. Rik Koncel-Kedziorski, Hannaneh Hajishirzi, AshishSabharwal, Oren Etzioni, and Siena Dumas Ang.2015b. Parsing algebraic word problems into equa-tions. Transactions of the Association for Computa-tional Linguistics, page 585597.",
  "Nghia T Le and Alan Ritter. 2023.Are large lan-guage models robust zero-shot coreference resolvers?arXiv preprint arXiv:2305.14489": "Christian Liguda and Thies Pfeiffer. 2012. Modelingmath word problems with augmented semantic net-works. In International Conference on Applicationof Natural Language to Information Systems, page247252. Springer. Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-som. 2017. Program induction by rationale genera-tion: Learning to solve and explain algebraic wordproblems. In Proceedings of the 55th Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long Papers), pages 158167. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,Luke Zettlemoyer, and Veselin Stoyanov. 2019.Roberta: A robustly optimized bert pretraining ap-proach. arXiv preprint arXiv:1907.11692. Ranjita Naik, Varun Chandrasekaran, Mert Yuksek-gonul, Hamid Palangi, and Besmira Nushi. 2023.Diversity of thought improves reasoning abili-ties of large language models.arXiv preprintarXiv:2310.07088. Deepak Nathani, David Wang, Liangming Pan, andWilliam Wang. 2023. Maf: Multi-aspect feedbackfor improving reasoning in large language models.In Proceedings of the 2023 Conference on Empiri-cal Methods in Natural Language Processing, pages65916616.",
  "Lourdes Ortega. 2003. Syntactic complexity measuresand their relationship to l2 proficiency: A researchsynthesis of college-level l2 writing. Applied linguis-tics, 24(4):492518": "Arkil Patel, Satwik Bhattamishra, and Navin Goyal.2021. Are nlp models really able to solve simplemath word problems? In Proceedings of the 2021Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 20802094. Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt,Noah A. Smith, and Mike Lewis. 2023. Measur-ing and narrowing the compositionality gap in lan-guage models. In Findings of the 2023 Conference onEmpirical Methods in Natural Language Processing(EMNLP). Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang Chen,Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang,and Huajun Chen. 2023. Reasoning with languagemodel prompting: A survey. In Proceedings of the61st Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), ACL2023, Toronto, Canada, July 9-14, 2023, pages 53685393.",
  "Alec Radford, Jeffrey Wu, Rewon Child, David Luan,Dario Amodei, Ilya Sutskever, et al. 2019. Languagemodels are unsupervised multitask learners": "Nazneen Fatema Rajani, Bryan McCann, CaimingXiong, and Richard Socher. 2019.Explain your-self! leveraging language models for commonsensereasoning. In Proceedings of the 57th Annual Meet-ing of the Association for Computational Linguistics,pages 49324942. Subhro Roy and Dan Roth. 2015. Solving general arith-metic word problems. In Proceedings of the 2015Conference on Empirical Methods in Natural Lan-guage Processing. Association for ComputationalLinguistics. Shuming Shi, Yuehui Wang, Chin-Yew Lin, XiaojiangLiu, and Yong Rui. 2015. Automatically solvingnumber word problems by semantic parsing and rea-soning. In Proceedings of the 2015 conference onempirical methods in natural language processing,page 11321142. Sanja tajner and Horacio Saggion. 2013. Readabilityindices for automatic evaluation of text simplificationsystems: A feasibility study for spanish. In Proceed-ings of the Sixth International Joint Conference onNatural Language Processing, pages 374382. Alon Talmor, Jonathan Herzig, Nicholas Lourie, andJonathan Berant. 2019. Commonsenseqa: A questionanswering challenge targeting commonsense knowl-edge.In Proceedings of the 2019 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, Volume 1 (Long and Short Papers), pages41494158. Alon Talmor, Oyvind Tafjord, Peter Clark, Yoav Gold-berg, and Jonathan Berant. 2020. Leap-of-thought:Teaching pre-trained models to systematically rea-son over implicit knowledge. Advances in NeuralInformation Processing Systems, 33:2022720237. Romal Thoppilan, Daniel De Freitas, Jamie Hall, NoamShazeer, Apoorv Kulshreshtha, Heng-Tze Cheng,Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al.2022. Lamda: Language models for dialog applica-tions. arXiv preprint arXiv:2201.08239. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023.Llama 2:Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288. Shyam Upadhyay, Ming-Wei Chang, Kai-Wei Chang,and Wen-tau Yih. 2016. Learning from explicit andimplicit supervision jointly for algebra word prob-lems. In Proceedings of the 2016 Conference onEmpirical Methods in Natural Language Processing,page 297306. Xingchen Wan, Ruoxi Sun, Hanjun Dai, Sercan Arik,and Tomas Pfister. 2023. Better zero-shot reasoningwith self-adaptive prompting. In Findings of the As-sociation for Computational Linguistics: ACL 2023,pages 34933514. Lei Wang, Wanyu Xu, Yihuai Lan, Zhiqiang Hu,Yunshi Lan, Roy Ka-Wei Lee, and Ee-Peng Lim.2023a. Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large languagemodels. In Proceedings of the 61st Annual Meetingof the Association for Computational Linguistics (Vol-ume 1: Long Papers), ACL 2023, Toronto, Canada,July 9-14, 2023, pages 26092634. Association forComputational Linguistics. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V.Le, Ed H. Chi, Sharan Narang, Aakanksha Chowd-hery, and Denny Zhou. 2023b.Self-consistencyimproves chain of thought reasoning in languagemodels. In The Eleventh International Conferenceon Learning Representations, ICLR 2023, Kigali,Rwanda, May 1-5, 2023. OpenReview.net. Jason Wei, Xuezhi Wang, Dale Schuurmans, MaartenBosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V. Le,and Denny Zhou. 2024. Chain-of-thought prompt-ing elicits reasoning in large language models. InProceedings of the 36th International Conference onNeural Information Processing Systems, NIPS 22,Red Hook, NY, USA. Curran Associates Inc. Zhiheng Xi, Senjie Jin, Yuhao Zhou, Rui Zheng,Songyang Gao, Jia Liu, Tao Gui, Qi Zhang, andXuan-Jing Huang. 2023. Self-polish: Enhance rea-soning in large language models via problem refine-ment. In Findings of the Association for Compu-tational Linguistics: EMNLP 2023, pages 1138311406. Ma Yuhui, Zhou Ying, Cui Guangzuo, Ren Yun, andHuang Ronghuai. 2010. Frame-based calculus ofsolving arithmetic multi-step addition and subtrac-tion word problems. In 2010 Second InternationalWorkshop on Education Technology and ComputerScience, volume 2, page 476479. IEEE. Hongming Zhang, Yan Song, Yangqiu Song, and DongYu. 2019. Knowledge-aware pronoun coreferenceresolution. In Proceedings of the 57th Annual Meet-ing of the Association for Computational Linguistics,page 867. Zhuosheng Zhang, Aston Zhang, Mu Li, and AlexSmola. 2023. Automatic chain of thought promptingin large language models. In The Eleventh Inter-national Conference on Learning Representations,ICLR 2023, Kigali, Rwanda, May 1-5, 2023. Open-Review.net. Xinran Zhao, Hongming Zhang, and Yangqiu Song.2022. Pcr4all: A comprehensive evaluation bench-mark for pronoun coreference resolution in english.In Proceedings of the Thirteenth Language Resourcesand Evaluation Conference, pages 59635973.",
  "BUnlabeled Question Corpus": "As mentioned in .4, an unlabeled ques-tion corpus is used to construct a demonstrationset. Previous methods, such as AUTO-COT (Zhanget al., 2023) and COSP (Wan et al., 2023), directlytake all unlabeled questions from test data as un-labeled question corpus. Obviously, this settingis not practical. First, we cannot obtain all testdata immediately before testing them in actual de-ployment. Second, the distributions of test datamay leak. Hence, we argue that taking unlabeledquestions from outside of test data is more reason-able since unlabeled questions are typically cheapand easy to obtain, for example, via collections ofhistory queries.Next, we provide a detailed description of how toacquire unlabeled question corpus outside the testdata, which will help future works follow this moresensible practice quickly. For AQUA9, GSM8K10,SVAMP11, AddSub, MultiArith, SingleEq, Strat-egyQA12 datasets, their unlabeled question cor-pus are derived from their train set. Note thatthe SVAMP, AddSub, MultiArith, and SingleEqdataset share a unlabeled question corpus sincethey are similar in format. The Last Letters datasetonly contains test data, which is generated by ran-domly concatenating the first and last name from the top one-thousand in name census data13. Hence,we construct its unlabeled question corpus by ran-domly concatenating 100 first and last name fromthe top two-thousand to top one-thousand. For theCoin Flip dataset, which only contains test data aswell, we leverage gpt-3.5-turbo-0613 to imitatethe eight sample questions in Coin Flip to generate100 unlabeled questions as unlabeled question cor-pus. For CSQA14 dataset, previous works test onits train set since the labels of its test set cannot bedownloaded. Hence, we adopt its unlabeled test setas an unlabeled question corpus.Note that our method can also adopt the test dataas an unlabeled question corpus, which will gainbetter performance. For instance, increasing 2.2%and 2.0% in AQuA (67.7% 68.9%) and GSM8K(79.8% 81.8%), respectively.",
  "Conducting coreference resolution for FEW-SHOT-": "COT demonstrations is easy, which can be realizedwith the help of neuralcoref15 toolkita tool whichis proposed to conduct coreference resolution andwidely adopted in the NLP community. Further-more, there are some linguistic rules (Jurafsky andMartin, 2019) for coreference resolution, which iseasy to follow.The goal of the step decomposition is to let theLLM know how to decompose a complex ratio-nale into an easy-to-understand rationale by addingmore steps. To this end, we first show LLM a pairof (a compact rationale of the original rationale,the original rationale). The compact rationale isformed by the step deletion, which is the reverseprocess of step decomposition. Specifically, givena rationale with N steps, we randomly delete N1 2steps chosen from the first step to the (N 1)-thstep, where the last step should be kept because itis often the final answer. By imitating the processina compact rationale of the original rationalestep decompositionthe original rationale, LLMs will conductthe original rationalestep decompositionadecomposed rationale of the original rationale.Then, we manually modify or remove some unrea-sonable steps and make all demonstrations highlyconsistent in format.",
  "FComputational Efficiency": "As mentioned in section 4.8, we investigate thetime-consumption and token-consumption of dif-ferent methods to explore computational efficiency.We compare our ADOT method with fivebest performing methods (PHP, FEW-SHOT-COT,LEAST-TO-MOST, SELF-ASK, COMPLEX-COT)in time-consumption. Closed-source LLMs (e.g.,gpt-3.5-turbo-0613) cannot be downloaded,and interacting with them through API is suscepti-ble to network conditions and other remote server-independent factors. To ensure a fair comparison,we investigate the time-consumption on the open-source LLMs llama2-7b-chat locally.All the experiments are done in the same environ-ment on Nvidia A800 GPU. The comparison resultson three tasks are shown in , which demon-strates that the time-consumption of our method isclose to some simple methods (such as FEW-SHOT-",
  "COT and 12.97 times (1358.3/104.7 seconds) fasterthan PHP on the average of six datasets in the arith-metic task": "There are two main reasons for the less time-consumption of our method. Frist, methods likePHP require iterative interaction with LLMs, whileour method avoids this complex process.Sec-ond, the time-consumption is positively correlatedwith the length of input text. Our method only re-trieves long demonstrations when the question ishard. However, the demonstrations of COMPLEX-",
  "GMethod Generalization on LLMs withDifferent Sizes": "As mentioned in section 4.8, to explore whetherour method is sufficiently generalizable on LLMswith different sizes or not, we experiment onllama2 with three sizes., , shows the performance of our ADOTmethod and other baselines on llama2-7b-chat,llama2-13b-chat, and llama2-70b-chat, re-spectively16. Specifically, we do not reproducethe POT on llama2 since it requires powerful code-completion capability while llama2 series LLMsare not good at. Based on the experimental results, we can ob-serve that ADOT can achieve sota performance inmost cases regardless of datasets and LLM sizes.The average performance of ADOT improves 4.2%,3.7%, and 6.8% on the previous best average per-formance. Hence, we argue that our ADOT methodis effectively generalized on LLMs with differentsizes. Furthermore, the results demonstrate that theperformance of most methods increases as the LLMsize increases. Generally, the larger the model is,the more knowledge it can store and the better rea-soning ability it will achieve.",
  "HThe Sensitivity Analysis ofDemonstrations Words and Structures": "As mentioned in section 4.8, we explore the sensi-tivity of our ADOT method to demonstrations withdifferent words and structures. Compared withcoreference resolution, the step decomposition isflexible since no rules exist. Hence, we explore thesensitivity of ADOT under different step decompo-sition with variant words and structures.The step decomposition tries to add steps in thereasoning process to bridge the logical gap betweenreasoning steps. To explore whether adding stepsin the reasoning process is effective, we designthe ADOT (Variant 1), where the step decompo-sition is replaced with removing some steps inthe reasoning process.Furthermore, we adoptthe gpt-3.5-turbo-0613 to rewrite the optimizeddemonstrations after step decomposition and coref-erence resolution. Specifically, we adopt a sim-ple instruction Given the question: question,please rewrite the reasoning process with differ-ent words and structures: rationale. Be carefulnot to change the meaning of the reasoning pro-cess. to generate ten variants, and then randomlypick three as ADOT (Variant 1-3). These variantsare shown in to . Experimental re-sults on llama2-7b-chat, llama2-13b-chat, andllama2-70b-chat are shown in , ,and , respectively.First, after the step decomposition is replacedwith removing some steps, the performances ofVariant 1 significantly decline, especially in AQuAand Last Letters datasets. The main reason is that aclear logic among reasoning steps is important toarithmetic and symbolic tasks.Second, the results show that the performanceon AQuA and CSQA datasets is stable in differ-ent optimized demonstrations with different wordsand structures. However, the performance on LastLetters dataset fluctuates obviously. We argue thatthe main reason is that the arithmetic and com-monsense tasks focus more on macro-level mean-ing, while the symbolic task concentrates more onmicro-level words and structures. Hence, as longas the original meaning is not changed, step de-composition with different words and structureswill produce similar results in arithmetic and com-monsense tasks. While on symbolic task, morecareful handcraft is needed to ensure that wordsand structures can express meaning precisely.Third, the demonstrations rewritten by LLMs are not uniform in answer format (highlighted atthe end of answers) in many cases, which maydecrease performance. For instance, in the LastLetters dataset, the answer format of the rewrittendemonstrations in ADOT (Variant 2, 3) is chaotic,while in ADOT (Variant 4) is uniform. Clearly,the performance of ADOT (Variant 4) is close toADOT while ADOT (Variant 2 and 3) are far lower.Hence, adopting a uniform answer format is also akey point in keeping the performance stable.",
  "Variant 3Variant 1": "Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is?Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64A: 10 is added to each number of the 15 numbers. The new mean of the 15 numbers would be 50. Therefore, the answer is (A) 50. Q: If a / b = 3/4 and 8a + 5b = 22,then find the value of a.Answer Choices: (A) 1/2 (B) 3/2 (C) 5/2 (D) 4/2 (E) 7/2A: a / b = 3/4, so 8a + 5(4a / 3) = 22. 44a / 3 = 22, so a is equal to 3/2. Therefore, the answer is (B) 3/2. Q: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find the distance?Answer Choices: (A) 53 km (B) 55 km (C) 52 km (D) 60 km (E) 50 kmA: The person traveling 20 km/hr and reached his destiny in 2.5 hr. So the distance = 50 km Therefore, the answer is (E) 50 km. Q: How many keystrokes are needed to type the numbers from 1 to 500?Answer Choices: (A) 1156 (B) 1392 (C) 1393 (D) 1562 (E) 1788A: 1 to 500 have 9 one-digit numbers from 1 to 9. 1 to 500 have 90 two-digit numbers from 10 to 99. 1 to 500 have are 401 three-digit numbers from 100 to 500. Therefore, the answer is (B) 1392. Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is?Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64A: John observed that the mean of a set of 15 numbers is 40. Then, John added 10 to each number in the set. Consequently, the mean of the updated set is also increased by 10. To find the original sum of the 15 numbers, multiply the mean (40) by the number of values (15). Thus, the original sum is 600. Adding 10 to each number in the set results in a new sum of the 15 numbers. To calculate the new sum, add the original sum (600) to the product of 10 and the number of values (15). The new sum is 750. Since the new sum is 750, the new mean of the 15 numbers is obtained by dividing this sum by the number of values (15). The new mean is 50. Therefore, the correct answer is (A) 50. Q: If a / b = 3/4 and 8a + 5b = 22,then find the value of a.Answer Choices: (A) 1/2 (B) 3/2 (C) 5/2 (D) 4/2 (E) 7/2A: Given the equation a / b = 3/4, we can solve for b by multiplying both sides of the equation by b. This gives us b = 4a / 3. Substituting this value of b into the second equation, 8a + 5b = 22, we get 8a + 5(4a / 3) = 22. Simplifying this equation further, we have 8a + 20a / 3 = 22. Combining like terms, we get 44a / 3 = 22. To solve for a, we can multiply both sides of the equation by 3/44. This gives us a = (3/44) * 22, which simplifies to 3/2. Therefore, the value of a is 3/2, and the correct answer choice is (B) 3/2. Q: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find the distance?Answer Choices: (A) 53 km (B) 55 km (C) 52 km (D) 60 km (E) 50 kmA: Given that a person is traveling at a speed of 20 km/hr and reaches their destination in 2.5 hours, we can calculate the distance they traveled by multiplying their speed (20 km/hr) by the time it took (2.5 hours). Therefore, the distance traveled would be 20 km/hr * 2.5 hrs = 50 km. Hence, the answer is (E) 50 km. Q: How many keystrokes are needed to type the numbers from 1 to 500?Answer Choices: (A) 1156 (B) 1392 (C) 1393 (D) 1562 (E) 1788A: To determine the number of keystrokes needed to type the numbers from 1 to 500, we can break down the different types of numbers. First, there are 9 single-digit numbers (1-9), and each of these requires 1 keystroke. So the total number of keystrokes for single-digit numbers is 9. Next, there are 90 two-digit numbers (10-99), and each digit in these numbers requires 2 keystrokes. Therefore, the total number of keystrokes for two-digit numbers is 90 * 2 = 180. Finally, there are 401 three-digit numbers (100-500), and each digit in these numbers requires 3 keystrokes. Thus, the total number of keystrokes for three-digit numbers is 401 * 3 = 1203. By adding up the number of keystrokes for single-digit numbers, two-digit numbers, and three-digit numbers, we get 9 + 180 + 1203 = 1392 keystrokes in total. Hence, the correct answer to the question is (B) 1392. Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is?Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64A: By adding 10 to each number of the 15 numbers, the mean of the numbers will also increase by 10. Since the average of the 15 numbers is 40, the original sum of the numbers is 15 multiplied by 40, which equals 600. When adding 10 to each number, the new sum of the numbers becomes 600 + (10 * 15) = 750. Consequently, the new mean of the 15 numbers is obtained by dividing the new sum, 750, by 15, resulting in 750/15 = 50. Therefore, the correct answer is (A) 50. Q: If a / b = 3/4 and 8a + 5b = 22,then find the value of a.Answer Choices: (A) 1/2 (B) 3/2 (C) 5/2 (D) 4/2 (E) 7/2A: Given the equation a / b = 3/4 and 8a + 5b = 22, we need to find the value of a. To start, we can rewrite the first equation as b = 4a / 3. Substituting this expression for b into the second equation, we get 8a + 5(4a / 3) = 22. Simplifying further, we have 8a + (20a / 3) = 22. Combining like terms, we get 8a + (20a / 3) = 22. To eliminate the fraction, we multiply both sides of the equation by 3, resulting in 24a + 20a = 66. Simplifying further, we have 44a = 66. Dividing both sides by 44, we find that a = 66 / 44, which simplifies to 3 / 2. Therefore, the value of a is 3/2, and the correct answer is (B) 3/2. Q: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find the distance?Answer Choices: (A) 53 km (B) 55 km (C) 52 km (D) 60 km (E) 50 kmA: The person traveled at a speed of 20 km/hr and reached their destination in 2.5 hours. To find the distance, we multiply the speed (20 km/hr) by the time (2.5 hours). This gives us a distance of 50 kilometers. Therefore, the answer is (E) 50 km. Q: How many keystrokes are needed to type the numbers from 1 to 500?Answer Choices: (A) 1156 (B) 1392 (C) 1393 (D) 1562 (E) 1788A: To find the total number of keystrokes needed to type the numbers from 1 to 500, we can break it down into three categories: single-digit numbers, two-digit numbers, and three-digit numbers. First, let's consider the single-digit numbers (1-9). There are 9 single-digit numbers, and each number requires 1 keystroke. Therefore, the total number of keystrokes for the single-digit numbers is 9 * 1 = 9. Next, let's move on to the two-digit numbers (10-99). There are 90 two-digit numbers, and each number requires 2 keystrokes (one for each digit). Therefore, the total number of keystrokes for the two-digit numbers is 90 * 2 = 180. Finally, let's consider the three-digit numbers (100-500). There are 401 three-digit numbers, and each number requires 3 keystrokes (one for each digit). Therefore, the total number of keystrokes for the three-digit numbers is 401 * 3 = 1203. Adding up the number of keystrokes for the single-digit numbers, two-digit numbers, and three-digit numbers, we get 9 + 180 + 1203 = 1392. Therefore, the answer is (B) 1392. Q: John found that the average of 15 numbers is 40. If 10 is added to each number then the mean of the numbers is?Answer Choices: (A) 50 (B) 45 (C) 65 (D) 78 (E) 64A: By adding 10 to each number of the 15 numbers, the mean of the numbers will also increase by 10. Since the average of the 15 numbers is 40, the original sum of the numbers is 15 multiplied by 40, which equals 600. When adding 10 to each number, the new sum of the numbers becomes 600 + (10 * 15) = 750. Consequently, the new mean of the 15 numbers is obtained by dividing the new sum, 750, by 15, resulting in 750/15 = 50. Therefore, the correct answer is (A) 50. Q: If a / b = 3/4 and 8a + 5b = 22,then find the value of a.Answer Choices: (A) 1/2 (B) 3/2 (C) 5/2 (D) 4/2 (E) 7/2A: Given the equation a / b = 3/4 and 8a + 5b = 22, we need to find the value of a. To start, we can rewrite the first equation as b = 4a / 3. Substituting this expression for b into the second equation, we get 8a + 5(4a / 3) = 22. Simplifying further, we have 8a + (20a / 3) = 22. Combining like terms, we get 8a + (20a / 3) = 22. To eliminate the fraction, we multiply both sides of the equation by 3, resulting in 24a + 20a = 66. Simplifying further, we have 44a = 66. Dividing both sides by 44, we find that a = 66 / 44, which simplifies to 3 / 2. Therefore, the value of a is 3/2, and the correct answer is (B) 3/2. Q: A person is traveling at 20 km/hr and reached his destiny in 2.5 hr then find the distance?Answer Choices: (A) 53 km (B) 55 km (C) 52 km (D) 60 km (E) 50 kmA: The person traveled at a speed of 20 km/hr and reached their destination in 2.5 hours. To find the distance, we multiply the speed (20 km/hr) by the time (2.5 hours). This gives us a distance of 50 kilometers. Therefore, the answer is (E) 50 km. Q: How many keystrokes are needed to type the numbers from 1 to 500?Answer Choices: (A) 1156 (B) 1392 (C) 1393 (D) 1562 (E) 1788A: To find the total number of keystrokes needed to type the numbers from 1 to 500, we can break it down into three categories: single-digit numbers, two-digit numbers, and three-digit numbers. First, let's consider the single-digit numbers (1-9). There are 9 single-digit numbers, and each number requires 1 keystroke. Therefore, the total number of keystrokes for the single-digit numbers is 9 * 1 = 9. Next, let's move on to the two-digit numbers (10-99). There are 90 two-digit numbers, and each number requires 2 keystrokes (one for each digit). Therefore, the total number of keystrokes for the two-digit numbers is 90 * 2 = 180. Finally, let's consider the three-digit numbers (100-500). There are 401 three-digit numbers, and each number requires 3 keystrokes (one for each digit). Therefore, the total number of keystrokes for the three-digit numbers is 401 * 3 = 1203. Adding up the number of keystrokes for the single-digit numbers, two-digit numbers, and three-digit numbers, we get 9 + 180 + 1203 = 1392. Therefore, the answer is (B) 1392.",
  "Q: Take the last letters of the words in \"Bill Gates\" and concatenate them.A: The last letter of \"Bill\" is \"l\". The last letter of \"Gates\" is \"s\". The answer is ls": "Q: Take the last letters of the words in \"Elon Musk\" and concatenate them.A: Now, write down the first term \"Elon\" as individual characters: \"E l o n\". Extract the last character from \"E l o n\", which is \"n\". Next, write down the second term \"Musk\" as individual characters: \"M u s k\". Extract the last character from \"M u s k\", which is \"k\". Combine the last characters \"n\" and \"k\" together. The combination of the last characters \"n\" and \"k\" is \"n\" + \"k\" = \"nk\". Similarly, the answer is \"nk\" based on the combined result \"nk\". Q: Take the last letters of the words in \"Larry Page\" and concatenate them.A: 1. Separate the word 'Larry' into its individual letters: L - a - r - r - y. 2. Identify the last letter of 'Larry', which is 'y'. 3. Separate the word 'Page' into its individual letters: P - a - g - e. 4. Identify the last letter of 'Page', which is 'e'. 5. Combine the last letters 'y' and 'e' together. 6. The combination of 'y' and 'e' is 'ye'. 7. The answer is also 'ye'. Q: Take the last letters of the words in \"Sergey Brin\" and concatenate them.A: Begin by writing out the first word \"Sergey\" and separate each letter: \"S e r g e y\". Then, identify the last letter of \"S e r g e y\", which is \"y\". Moving on to the second word \"Brin\", write out each letter separately: \"B r i n\". Identify the last letter of \"B r i n\", which is \"n\". Next, combine the last letters \"y\" and \"n\" together. The final combination of the last letters \"y\" and \"n\" is \"yn\". Hence, the answer is yn. Q: Take the last letters of the words in \"Bill Gates\" and concatenate them.A: First, write each letter of the word \"Bill\" individually: \"B i l l\". Take note of the last letter of \"B i l l\", which is \"l\". Next, write each letter of the word \"Gates\" individually: \"G a t e s\". Take note of the last letter of \"G a t e s\", which is \"s\". Lastly, merge the last letters \"l\" and \"s\" together. By combining the last letters \"l\" and \"s\", we get \"ls\". Thus, the answer is \"ls\". Q: Take the last letters of the words in \"Elon Musk\" and concatenate them.A: Firstly, write down the initial word \"Elon\" one letter at a time: \"E l o n\". Extract the last letter from \"E l o n\", which is \"n\". Next, write down the second word \"Musk\" one letter at a time: \"M u s k\". Extract the last letter from \"M u s k\", which is \"k\". Merge the final letters \"n\" and \"k\" together. The merging of the final letters \"n\" and \"k\" is \"n\" + \"k\" = \"nk\". Hence, the response is nk, just as with the combined result \"nk\". Q: Take the last letters of the words in \"Larry Page\" and concatenate them.A: First, write down the two words \"Larry Page\" and separate the letters in each word: \"L a r r y\" and \"P a g e\". Next, identify the last letter of the first word, which is \"y\". Then, identify the last letter of the second word, which is \"e\". Finally, concatenate the last letters \"y\" and \"e\" together. The concatenation of the last letters \"y\" and \"e\" is \"y\" + \"e\" = \"ye\". Therefore, the answer is \"ye\". Q: Take the last letters of the words in \"Sergey Brin\" and concatenate them.A: First, isolate the letters of the initial word \"Sergey\" as follows: \"S e r g e y\". Identify the last letter of \"S e r g e y\", which is \"y\". Next, record the letters of the second word \"Brin\" individually: \"B r i n\". Determine the final letter of \"B r i n\", which is \"n\". Combine the last letters \"y\" and \"n\" together. The combination of the last letters \"y\" and \"n\" is \"y\" + \"n\" = \"yn\". Similarly, following the pattern seen in the result \"yn\", the answer is yn. Q: Take the last letters of the words in \"Bill Gates\" and concatenate them.A: Extract the individual letters from the first word \"Bill\" as \"B\", \"i\", \"l\", \"l\". Identify the last letter of \"B\", which is \"l\". Similarly, list out the letters of the second word \"Gates\" as \"G\", \"a\", \"t\", \"e\", \"s\". Determine the last letter of \"s\", which is \"s\". Combine the last letters \"l\" and \"s\". Concatenate the last letters \"l\" and \"s\" to get \"ls\". Hence, the final answer is \"ls\". Q: Take the last letters of the words in \"Elon Musk\" and concatenate them.A: Commence by writing down the first word \"Elon\" in separate letters: \"E,l,o,n\". Identify the last letter of \"E,l,o,n\" which is \"n\". Proceed to write down the second word \"Musk\" in separate letters: \"M,u,s,k\". Identify the last letter of \"M,u,s,k\" which is \"k\". Combine the last letters \"n\" and \"k\" together. The result of combining the last letters \"n\" and \"k\" is \"nk\". Therefore, the answer is \"nk\". Q: Take the last letters of the words in \"Larry Page\" and concatenate them.A: To begin, separate the first word \"Larry\" into its individual letters: \"L a r r y\". Select the last letter from \"L a r r y\", which is \"y\". Next, write down the second word \"Page\" as separate letters: \"P a g e\". Choose the last letter from \"P a g e\", which is \"e\". Combine the final letters \"y\" and \"e\" to form a single word. The combination of \"y\" and \"e\" is \"ye\". Therefore, the answer is \"ye\". Q: Take the last letters of the words in \"Sergey Brin\" and concatenate them.A: Start by listing the individual letters of the first word \"Sergey\" as follows: \"S e r g e y\". Identify the last letter of \"S e r g e y\", which is \"y\". Proceed to write down the separate letters of the second word \"Brin\": \"B r i n\". Identify the last letter of \"B r i n\", which is \"n\". Combine the last letters \"y\" and \"n\" together. The combination of the last letters \"y\" and \"n\" is \"y\" + \"n\" = \"yn\". Therefore, the answer is \"yn\". Q: Take the last letters of the words in \"Bill Gates\" and concatenate them.A: First, break down the word \"Bill\" into individual letters: \"B i l l.\" Next, identify the last letter of \"B i l l,\" which is \"l.\" Then, break down the word \"Gates\" into individual letters: \"G a t e s.\" Identify the last letter of \"G a t e s,\" which is \"s.\" Combine the last letters \"l\" and \"s\" together. The combination of the last letters \"l\" and \"s\" is \"l\" + \"s\" = \"ls\". Therefore, the answer is \"ls\".",
  "Variant 1": "Q: What do people use to absorb extra ink from a fountain pen?Answer Choices: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotterA: The answer of \"What do people use to absorb extra ink from a fountain pen?\" must be an item that can absorb ink. So the answer is (E). Q: What home entertainment equipment requires cable? Answer Choices: (A) radio shack (B) substation (C) television (D) cabinetA: The answer of \"What home entertainment equipment requires cable?\" must require cable. So the answer is (C). Q: The fox walked from the city into the forest, what was it looking for? Answer Choices: (A) pretty flowers (B) hen house (C) natural habitat (D) storybookA: The answer of \"The fox walked from the city into the forest, what was it looking for?\" must be something in the forest. So the answer is (C). Q: Sammy wanted to go to where the people were. Where might he go? Answer Choices: (A) populated areas (B) race track (C) desert (D) apartment (E) roadblockA: The answer of \"Sammy wanted to go to where the people were.Where might he go?\" must be a place with a lot of people. So the answer is (A). Q: Where do you put your grapes just before checking out? Answer Choices: (A) mouth (B) grocery cart (C)super market (D) fruit basket (E) fruit marketA: The answer of \"Where do you put your grapes just before checking out?\" should be the place where grocery items are placed before checking out. So the answer is (B). Q: Google Maps and other highway and street GPS services have replaced what? Answer Choices: (A) united states (B) mexico (C) countryside (D) atlasA: The answer of \"Google Maps and other highway and street GPS services have replaced what?\" must be something that used to do what Google Maps and GPS services do, which is to give directions. So the answer is (D). Q: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (A) harder (B) anguish (C) bitterness (D) tears (E) sadnessA: The answer of \"Before getting a divorce, what did the wife feel who was doing all the work?\" should be the feeling of someone getting divorced who was doing all the work. So the answer is (C). Q: What do people use to absorb extra ink from a fountain pen?Answer Choices: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotterA: To find the answer to \"What do people use to absorb extra ink from a fountain pen?\" we need to choose an option that can soak up ink.Let's consider the choices: (A) shirt pocket, (B) calligrapher's hand, (C) inkwell, (D) desk drawer, (E) blotter. Out of these options, (E) blotter stands out as the best choice. Blotters are commonly used to soak up excess ink from fountain pens. They help to avoid smudging and promote quick drying of the ink on the paper. Blotters are typically made of absorbent paper or cloth and are placed under the paper while writing. Consequently, to absorb extra ink from a fountain pen, people may employ (E) blotter. In conclusion, the correct answer is (E) blotter. Q: What home entertainment equipment requires cable?Answer Choices: (A) radio shack (B) substation (C) television (D) cabinetA: To determine what home entertainment equipment requires cable, we need to consider the given options: (A) radio shack, (B) substation, (C) television, (D) cabinet. Out of these options, it is clear that televisions often require cables to connect to different devices such as cable or satellite boxes, DVD or Blu-ray players, gaming consoles, and streaming devices. These cables are necessary to transmit audio and video signals from the source device to the television screen. Thus, it can be concluded that the home entertainment equipment that requires cable is the television, making the answer (C) television. Q: The fox walked from the city into the forest, what was it looking for? Answer Choices: (A) pretty flowers (B) hen house (C) natural habitat (D) storybookA: Given the question: \"The fox walked from the city into the forest, what was it searching for? Answer Choices: (A) beautiful flowers (B) hen house (C) natural habitat (D) storybook\" Let's think through the question: \"The fox walked from the city into the forest, what was it searching for?\" It must be something that can be found in the forest. Let's consider the options provided: (A) beautiful flowers, (B) hen house, (C) natural habitat, (D) storybook. The most logical reason for a fox to leave the city and enter the forest is to find a suitable place to establish its (C) natural habitat. Foxes are wild animals that usually prefer wooded areas for shelter, hunting, and raising their young. Forests offer the necessary cover and resources for a fox's survival. Consequently, the fox was probably searching for its (C) natural habitat when it walked from the city into the forest. Therefore, the answer is (C) natural habitat. Q: Sammy wanted to go to where the people were. Where might he go?Answer Choices: (A) populated areas (B) race track (C) desert (D) apartment (E) roadblockA: Given the question: \"Sammy desired to go to a place where people were present. To which place could he possibly go? Choose one: (A) crowded areas, (B) race track, (C) desert, (D) apartment, (E) roadblock.\" Let's rephrase the reasoning process using different words and structure: The solution to the question \"Sammy desired to go to a place where people were present. To which place could he possibly go?\" would be a location where individuals congregate or reside. Considering the provided choices: (A) crowded areas, (B) race track, (C) desert, (D) apartment, (E) roadblock. Under these circumstances, Sammy would most likely go to (A) crowded areas. Crowded areas are locales where there is a high concentration of individuals, such as towns, cities, or public spaces. These zones offer opportunities for socializing, engagement, and the existence of people. Hence, Sammy could go to (A) crowded areas to be in the presence of people. Thus, the answer is (A) crowded areas. Q: Where do you put your grapes just before checking out?Answer Choices: (A) mouth (B) grocery cart (C)super market (D) fruit basket (E) fruit marketA: To determine where to put your grapes just before checking out, consider where one typically places items they intend to purchase before paying for them. The options given are (A) mouth, (B) grocery cart, (C) super market, (D) fruit basket, and (E) fruit market. Typically, before checking out at a store, you would place your items, including grapes, in the (B) grocery cart. The grocery cart is used to hold the items you have selected for purchase while you navigate through the store. This is a common practice when shopping in supermarkets or grocery stores. Therefore, the correct answer is (B) grocery cart. Q: Google Maps and other highway and street GPS services have replaced what?Answer Choices: (A) united states (B) mexico (C) countryside (D) atlasA: To determine what Google Maps and other GPS services have replaced, let's analyze the available options: (A) united states, (B) mexico, (C) countryside, (D) atlas. These options represent possible answers to the question, \"What have Google Maps and GPS services replaced?\" The correct answer is (D) atlas. Before the advent of digital mapping services, people used physical books or collections of maps called atlases. Atlases were used for navigation and finding locations, including highways, streets, and geographic features. However, with the convenience of digital mapping services like Google Maps, people can now access detailed maps and navigation directions directly on their devices. Therefore, it can be concluded that Google Maps and other GPS services have replaced the need for traditional atlases. Hence, the answer is (D) atlas. Q: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (A) harder (B) anguish (C) bitterness (D) tears (E) sadnessA: The question is asking how the wife felt before getting a divorce, while she was doing all the work. We are given answer choices (A) harder, (B) anguish, (C) bitterness, (D) tears, and (E) sadness. Considering the given options, it is likely that the wife experienced a feeling of bitterness. When one partner carries the majority of the responsibilities and tasks in a marriage, it can lead to resentment and bitterness. This emotional response often arises when there is an unequal distribution of effort and workload, which can ultimately lead to marital dissatisfaction and divorce. Therefore, before the divorce, it is probable that the wife who was shouldering most of the work felt bitterness. The answer to the question is therefore (C) bitterness.",
  "Variant 4": "Q: What do people use to absorb extra ink from a fountain pen?Answer Choices: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotterA: To find the solution for \"What is used to absorb excess ink from a fountain pen?\" we need to identify an item that has the ability to soak up ink. Considering the available options: (A) shirt pocket, (B) calligrapher's hand, (C) inkwell, (D) desk drawer, (E) blotter. A (E) blotter is specifically designed to absorb extra ink from a fountain pen after writing. It serves to prevent smudging and ensure speedy drying of the ink on the paper. Typically, made of absorbent paper or cloth, the blotter is placed beneath the paper while writing. Therefore, it is plausible to use (E) blotter to absorb the excess ink from a fountain pen. As a result, the correct answer is (E) blotter. Q: What home entertainment equipment requires cable?Answer Choices: (A) radio shack (B) substation (C) television (D) cabinetA: To determine what home entertainment equipment requires cable, we need to examine the options: (A) radio shack, (B) substation, (C) television, and (D) cabinet. Out of these options, the equipment that typically requires cables to connect to other devices is the (C) television. Televisions often need cables to connect to devices like cable or satellite boxes, DVD or Blu-ray players, gaming consoles, and streaming devices. These cables are used to transmit audio and video signals from the source device to the television screen. Therefore, the home entertainment equipment that requires cable is the (C) television. Q: The fox walked from the city into the forest, what was it looking for?Answer Choices: (A) pretty flowers (B) hen house (C) natural habitat (D) storybookA: To determine what the fox was looking for when it walked from the city into the forest, we should consider the options given: (A) pretty flowers, (B) hen house, (C) natural habitat, and (D) storybook. Given that the fox is leaving the city and entering the forest, it is logical to assume that it is searching for something related to its natural environment. Foxes typically prefer wooded areas for shelter, hunting, and raising their young. This makes a (C) natural habitat the most likely choice. Therefore, the answer is (C) natural habitat. Q: Sammy wanted to go to where the people were. Where might he go?Answer Choices: (A) populated areas (B) race track (C) desert (D) apartment (E) roadblockA: The question is asking where Sammy might go if he wants to be where people are. Looking at the answer choices: (A) populated areas, (B) race track, (C) desert, (D) apartment, (E) roadblock. Based on this information, it is reasonable to assume that Sammy would go to (A) populated areas. Populated areas are places where there is a high concentration of people, such as cities or towns. These areas offer opportunities for social interaction and the presence of other people. Therefore, the answer is (A) populated areas. Q: Where do you put your grapes just before checking out?Answer Choices: (A) mouth (B) grocery cart (C)super market (D) fruit basket (E) fruit marketA: To determine where to put your grapes before checking out, consider a place where you typically store items you plan to buy before paying for them. Review the given options: (A) mouth, (B) grocery cart, (C) super market, (D) fruit basket, (E) fruit market. Before completing your purchase at a store, it is customary to place your items, including grapes, in the (B) grocery cart. The grocery cart serves as a container for the items you have chosen to purchase while you continue shopping and make final selections. This is a common practice at supermarkets or grocery stores. Therefore, just before checking out, you would place your grapes in the (B) grocery cart. Consequently, the answer is (B) grocery cart. Q: Google Maps and other highway and street GPS services have replaced what?Answer Choices: (A) united states (B) mexico (C) countryside (D) atlasA: The question is asking about what Google Maps and other GPS services have replaced. We are given multiple answer choices: (A) united states, (B) mexico, (C) countryside, and (D) atlas. To find the correct answer, we need to consider what navigational tool or system was commonly used before the introduction of digital mapping services. In this case, the correct answer is (D) atlas. Before the advent of Google Maps and GPS services, people used traditional atlases - physical books or collections of maps - to navigate and find locations. Atlases provided detailed maps of highways, streets, and geographical features. With the convenience of digital mapping services, people can now access these maps and navigation instructions directly on their devices. In conclusion, Google Maps and other GPS services have replaced the use of atlases. Therefore, the correct answer is (D) atlas. Q: Before getting a divorce, what did the wife feel who was doing all the work?Answer Choices: (A) harder (B) anguish (C) bitterness (D) tears (E) sadnessA: The question is asking about the wife's emotions before getting a divorce while bearing most of the workload. The answer choices are (A) harder, (B) anguish, (C) bitterness, (D) tears, and (E) sadness. Given the circumstances, it seems probable that the wife experienced feelings of bitterness. When one partner is responsible for the majority of the work and tasks in a relationship, it often leads to feelings of resentment and bitterness. This emotional reaction typically arises when there is an inequity in the distribution of effort and responsibilities. These circumstances can contribute to marital dissatisfaction and ultimately lead to divorce. Therefore, prior to getting a divorce, it is likely that the wife who was carrying most of the workload felt bitter. Thus, the correct answer is (C) bitterness. Q: What do people use to absorb extra ink from a fountain pen?Answer Choices: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotterA: In order to determine what people use to absorb extra ink from a fountain pen, we need to consider the options provided. These options are (A) shirt pocket, (B) calligrapher's hand, (C) inkwell, (D) desk drawer, and (E) blotter. We are looking for an item that has the ability to absorb ink. The (E) blotter is a logical choice for absorbing excess ink from a fountain pen. Blotters are typically made of absorbent paper or cloth and are placed underneath the paper while writing to prevent smudging and ensure quick drying of the ink. Using a blotter helps to absorb any extra ink that may be left on the paper. Therefore, the answer to the question is (E) blotter. Q: What home entertainment equipment requires cable?Answer Choices: (A) radio shack (B) substation (C) television (D) cabinetA: To determine which home entertainment equipment requires cable, we need to consider the options provided: (A) radio shack, (B) substation, (C) television, (D) cabinet. Since the question is asking about home entertainment equipment that requires cable, we can eliminate options (A), (B), and (D), as they do not typically require cables for operation. Now, focusing on option (C) television, it is common for televisions to require cables to connect to various devices like cable or satellite boxes, DVD or Blu-ray players, gaming consoles, and streaming devices. These cables are necessary for transmitting audio and video signals from the source device to the television screen. Thus, we can conclude that the home entertainment equipment (C) television requires cable. Therefore, the correct answer is (C) television. Q: The fox walked from the city into the forest, what was it looking for?Answer Choices: (A) pretty flowers (B) hen house (C) natural habitat (D) storybookA: Given the question: \"The fox ventured from the urban area into the woods, what was its intention? Choices: (A) beautiful flowers (B) chicken enclosure (C) native habitat (D) storybook\" let's rephrase the reasoning process using different wording and structure: To determine the purpose of the fox's journey from the city into the forest, we will examine the available options: (A) pretty flowers, (B) hen house, (C) natural habitat, (D) storybook. The most plausible explanation for a fox leaving the urban area and entering the forest is to seek out its (C) native habitat. Foxes, being wild creatures, frequently gravitate towards wooded regions for safety, hunting, and raising their offspring. The forest offers the necessary concealment and resources for a fox's survival. Consequently, it is highly likely that the fox was searching for its (C) native habitat when it traveled from the city into the forest. Thus, the correct answer is (C) native habitat. Make sure not to alter the meaning of the reasoning process. Q: Sammy wanted to go to where the people were. Where might he go?Answer Choices: (A) populated areas (B) race track (C) desert (D) apartment (E) roadblockA: Considering the question \"Sammy desired to be in the vicinity of individuals. Where might he choose to go?\", the logical deduction would be a location where people commonly gather or reside. Examining the available answer choices: (A) populated areas, (B) race track, (C) desert, (D) apartment, (E) roadblock. In this particular circumstance, it is highly likely that Sammy would opt for (A) populated areas. Populated areas are defined as regions with a high concentration of individuals, such as cities, towns, or public spaces. These areas facilitate social interaction, engagement, and the presence of people. Thus, Sammy would probably venture to (A) populated areas to join the others. Hence, the correct answer is (A) populated areas. Q: Where do you put your grapes just before checking out?Answer Choices: (A) mouth (B) grocery cart (C)super market (D) fruit basket (E) fruit marketA: The solution is to identify the place where grapes are usually kept before being paid for while checking out. The options include the mouth, grocery cart, supermarket, fruit basket, and fruit market.In this scenario, considering typical shopping practices, the items selected for purchase are placed in the grocery cart just before checking out. The grocery cart is commonly used to hold items while moving through the store and making final choices. Therefore, when checking out, the grapes would be placed in the grocery cart. Based on this reasoning, the answer to the question is option (B) grocery cart. Q: Google Maps and other highway and street GPS services have replaced what?Answer Choices: (A) united states (B) mexico (C) countryside (D) atlasA: The question asks what Google Maps and other GPS services have replaced. The options given are (A) united states, (B) mexico, (C) countryside, and (D) atlas. To answer this question, we need to examine the purpose of Google Maps and GPS services. These digital mapping services provide detailed maps and navigation instructions for highways, streets, and geographical features. Before the advent of digital mapping, people relied on a navigational tool called an atlas. Atlases were physical books or collections of maps that helped people find locations and navigate their way. With this in mind, we can determine that Google Maps and GPS services have replaced the use of traditional atlases. These digital services offer the same functionality as atlases but in a more convenient and accessible format. Instead of carrying around a physical book, people can now access maps and navigation instructions directly on their devices. Therefore, the answer to the question is (D) atlas. Q: Before getting a divorce, what did the wife feel who was doing all the work?Answer Choices: (A) harder (B) anguish (C) bitterness (D) tears (E) sadnessA: Analyzing the question \"What were the wife's feelings before seeking a divorce as she carried the majority of the responsibilities?\" The options are (A) harder, (B) anguish, (C) bitterness, (D) tears, and (E) sadness. In this circumstance, it is probable that the wife experienced a feeling of (C) bitterness. When one partner assumes the majority of the tasks and obligations in a marriage, it can lead to resentment and bitterness. Such emotional reactions usually arise as a result of an imbalance in the distribution of effort and workload, factors that contribute to marital dissatisfaction and ultimately divorce. Hence, before deciding on divorce, the wife, who shouldered most of the responsibilities, likely felt (C) bitterness . Therefore, (C) bitterness is the correct answer.",
  "Original Few-shot-cot demonstration": "Q: What do people use to absorb extra ink from a fountain pen?Answer Choices: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotterA: The answer must be an item that can absorb ink. Of the above choices, only blotters are used to absorb ink. So the answer is (E). Q: What home entertainment equipment requires cable?Answer Choices: (A) radio shack (B) substation (C) television (D) cabinetA: The answer must require cable. Of the above choices, only television requires cable. So the answer is (C). Q: The fox walked from the city into the forest, what was it looking for?Answer Choices: (A) pretty flowers (B) hen house (C) natural habitat (D) storybookA: The answer must be something in the forest. Of the above choices, only natural habitat is in the forest. So the answer is (C). Q: Sammy wanted to go to where the people were. Where might he go?Answer Choices: (A) populated areas (B) race track (C) desert (D) apartment (E) roadblockA: The answer must be a place with a lot of people. Of the above choices, only populated areas have a lot of people. So the answer is (A). Q: Where do you put your grapes just before checking out?Answer Choices: (A) mouth (B) grocery cart (C) super market (D) fruit basket (E) fruit marketA: The answer should be the place where grocery items are placed before checking out. Of the above choices, grocery cart makes the most sense for holding grocery items. So the answer is (B). Q: Google Maps and other highway and street GPS services have replaced what?Answer Choices: (A) united states (B) mexico (C) countryside (D) atlasA: The answer must be something that used to do what Google Maps and GPS services do, which is to give directions. Of the above choices, only atlas are used to give directions. So the answer is (D). Q: Before getting a divorce, what did the wife feel who was doing all the work?Answer Choices: (A) harder (B) anguish (C) bitterness (D) tears (E) sadnessA: The answer should be the feeling of someone getting divorced who was doing all the work. Of the above choices, the closest feeling is bitterness. So the answer is (C). Q: What do people use to absorb extra ink from a fountain pen? Answer Choices: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotterA: The answer of \"What do people use to absorb extra ink from a fountain pen?\" must be an item that can absorb ink. Of the choices: \"(A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotter\", only (E) blotters are used to absorb ink. So the answer is (E). Q: What home entertainment equipment requires cable?Answer Choices: (A) radio shack (B) substation (C) television (D) cabinetA: The answer of \"What home entertainment equipment requires cable?\" must require cable. Of the choices: \"(A) radio shack (B) substation (C) television (D) cabinet\", only (C) television requires cable. So the answer is (C). Q: The fox walked from the city into the forest, what was it looking for?Answer Choices: (A) pretty flowers (B) hen house (C) natural habitat (D) storybookA: The answer of \"The fox walked from the city into the forest, what was it looking for?\" must be something in the forest. Of the choices: \"(A) pretty flowers (B) hen house (C) natural habitat (D) storybook\", only (C) natural habitat is in the forest. So the answer is (C). Q: Sammy wanted to go to where the people were. Where might he go?Answer Choices: (A) populated areas (B) race track (C) desert (D) apartment (E) roadblockA: The answer of \"Sammy wanted to go to where the people were. Where might he go?\" must be a place with a lot of people. Of the choices: \"(A) populated areas (B) race track (C) desert (D) apartment (E) roadblock\", only (A) populated areas have a lot of people. So the answer is (A). Q: Where do you put your grapes just before checking out?Answer Choices: (A) mouth (B) grocery cart (C)super market (D) fruit basket (E) fruit marketA: The answer of \"Where do you put your grapes just before checking out?\" should be the place where grocery items are placed before checking out. Of the choices: \"(A) mouth (B) grocery cart (C)super market (D) fruit basket (E) fruit market\", (B) grocery cart makes the most sense for holding grocery items. So the answer is (B). Q: Google Maps and other highway and street GPS services have replaced what?Answer Choices: (A) united states (B) mexico (C) countryside (D) atlasA: The answer of \"Google Maps and other highway and street GPS services have replaced what?\" must be something that used to do what Google Maps and GPS services do, which is to give directions. Of the choices: \"(A) united states (B) mexico (C) countryside (D) atlas\", only (D) atlas are used to give directions. So the answer is (D). Q: Before getting a divorce, what did the wife feel who was doing all the work? Answer Choices: (A) harder (B) anguish (C) bitterness (D) tears (E) sadnessA: The answer of \"Before getting a divorce, what did the wife feel who was doing all the work?\" should be the feeling of someone getting divorced who was doing all the work. Of the choices: \"(A) harder (B) anguish (C) bitterness (D) tears (E) sadness\", the closest feeling is (C) bitterness. So the answer is (C). Q: What do people use to absorb extra ink from a fountain pen?Answer Choices: (A) shirt pocket (B) calligrapher's hand (C) inkwell (D) desk drawer (E) blotterA: The answer of \"What do people use to absorb extra ink from a fountain pen?\" must be an item that can absorb ink. Consider the options given: (A) shirt pocket, (B) calligrapher's hand, (C) inkwell, (D) desk drawer, (E) blotter. The (E) blotter are used to absorb excess ink from a fountain pen after writing, helping to prevent smudging and to ensure that the ink dries quickly on the paper. They are typically made of absorbent paper or cloth and are placed underneath the paper as you write. Hence, people may use (E) blotter to absorb extra ink from a fountain pen. Therefore, the answer is (E) blotter. Q: What home entertainment equipment requires cable?Answer Choices: (A) radio shack (B) substation (C) television (D) cabinetA: The answer of \"What home entertainment equipment requires cable?\" must require cable. Consider the options given: (A) radio shack, (B) substation, (C) television, (D) cabinet. The (C) television sets often require cables to connect to various devices such as cable or satellite boxes, DVD or Blu-ray players, gaming consoles, streaming devices, and more. These cables are used to transmit audio and video signals from the source device to the television screen. Hence, the home entertainment equipment (C) television requires cable. Therefore, the answer is (C) television. Q: The fox walked from the city into the forest, what was it looking for?Answer Choices: (A) pretty flowers (B) hen house (C) natural habitat (D) storybookA: The answer of \"The fox walked from the city into the forest, what was it looking for?\" must be something in the forest. Consider the options given: (A) pretty flowers, (B) hen house, (C) natural habitat, (D) storybook. The most likely reason for a fox to leave the city and enter the forest is to find a suitable place to establish its (C) natural habitat. Foxes are wild animals that often prefer wooded areas for shelter, hunting, and raising their young. Forests provide the necessary cover and resources for a fox's survival. Hence, the fox was likely looking for its (C) natural habitat when it walked from the city into the forest. Therefore, the answer is (C) natural habitat. Q: Sammy wanted to go to where the people were. Where might he go?Answer Choices: (A) populated areas (B) race track (C) desert (D) apartment (E) roadblockA: The answer to \"Sammy wanted to go to where the people were. Where might he go?\" would be a location where people gather or reside. Consider the options given: (A) populated areas, (B) race track, (C) desert, (D) apartment, (E) roadblock. In this scenario, Sammy would most likely go to (A) populated areas. Populated areas are locations where there is a concentration of people, such as towns, cities, or public spaces. These areas provide opportunities for social interaction, engagement, and the presence of people. Hence, Sammy might go to (A) populated areas to be where the people are. Therefore, the answer is (A) populated areas. Q: Where do you put your grapes just before checking out?Answer Choices: (A) mouth (B) grocery cart (C)super market (D) fruit basket (E) fruit marketA: The answer to \"Where do you put your grapes just before checking out?\" would be a place where you typically keep items you intend to purchase before paying for them. Consider the options given: (A) mouth, (B) grocery cart, (C) super market, (D) fruit basket, (E) fruit market. Just before checking out at a store, you would typically place your items, including grapes, in the (B) grocery cart. The grocery cart is used to hold the items you've selected for purchase while you move through the store and make your final selections. This is a common practice when shopping in supermarkets or grocery stores. Hence, you would put your grapes in the (B) grocery cart just before checking out. Therefore, the answer is (B) grocery cart. Q: Google Maps and other highway and street GPS services have replaced what?Answer Choices: (A) united states (B) mexico (C) countryside (D) atlasA: The answer to \"Google Maps and other highway and street GPS services have replaced what?\" would be a navigational tool that was commonly used before the advent of digital mapping services!\"Consider the options given: (A) united states, (B) mexico, (C) countryside, (D) atlas. Google Maps and GPS services have replaced the need for traditional (D) atlases. Atlases were physical books or collections of maps that people used to navigate and find locations, including highways, streets, and geographical features. With the convenience of digital mapping services, people can now access detailed maps and navigation instructions directly on their devices. Hence, Google Maps and other GPS services have replaced the use of (D) atlases. Therefore, the answer is (D) atlas. Q: Before getting a divorce, what did the wife feel who was doing all the work?Answer Choices: (A) harder (B) anguish (C) bitterness (D) tears (E) sadnessA: The question \"Before getting a divorce, what did the wife feel who was doing all the work?\" is inquiring about the emotional state of the wife before the divorce. Consider the options given: (A) harder, (B) anguish, (C) bitterness, (D) tears, (E) sadness. Given the context, it is likely that the wife felt a sense of (C) bitterness. When one partner feels burdened with most of the responsibilities and tasks in a relationship, it can lead to resentment and bitterness. This emotional response often arises when there is an imbalance in the distribution of effort and workload, which can contribute to marital dissatisfaction and, ultimately, divorce. Hence, before getting a divorce, the wife who was shouldering most of the work might have felt (C) bitterness. Therefore, the answer is (C) bitterness.",
  "Q: Take the last letters of the words in \"Bill Gates\" and concatenate them.A: The last letter of \"Bill\" is \"l\". The last letter of \"Gates\" is \"s\". Concatenating \"l\" and \"s\" is \"ls\". The answer is ls": "Q: Take the last letters of the words in \"Elon Musk\" and concatenate them.A: Write down the fisrt word \"Elon\" in separate letters: \"E l o n\".Take the last letter of \"E l o n\", which is \"n\".Write down the Second word \"Musk\" in separate letters: \"M u s k\".Take the last letter of \"M u s k\", which is \"k\".Concatenate the last letters \"n\" and \"k\" together.The concatenation of the last letters \"n\" and \"k\" is \"n\" + \"k\" = \"nk\".Same with the concatenation result \"nk\", the answer is nk. Q: Take the last letters of the words in \"Larry Page\" and concatenate them.A: Write down the fisrt word \"Larry\" in separate letters: \"L a r r y\".Take the last letter of \"L a r r y\", which is \"y\".Write down the Second word \"Page\" in separate letters: \"P a g e\".Take the last letter of \"P a g e\", which is \"e\".Concatenate the last letters \"y\" and \"e\" together.The concatenation of the last letters \"y\" and \"e\" is \"y\" + \"e\" = \"ye\".Same with the concatenation result \"ye\", the answer is ye. Q: Take the last letters of the words in \"Sergey Brin\" and concatenate them.A: Write down the fisrt word \"Sergey\" in separate letters: \"S e r g e y\".Take the last letter of \"S e r g e y\", which is \"y\".Write down the Second word \"Brin\" in separate letters: \"B r i n\".Take the last letter of \"B r i n\", which is \"n\".Concatenate the last letters \"y\" and \"n\" together.The concatenation of the last letters \"y\" and \"n\" is \"y\" + \"n\" =\"yn\".Same with the concatenation result \"yn\", the answer is yn. Q: Take the last letters of the words in \"Bill Gates\" and concatenate them.A: Write down the fisrt word \"Bill\" in separate letters: \"B i l l\".Take the last letter of \"B i l l\", which is \"l\".Write down the Second word \"Gates\" in separate letters: \"G a t e s\".Take the last letter of \"G a t e s\", which is \"s\".Concatenate the last letters \"l\" and \"s\" together.The concatenation of the last letters \"l\" and \"s\" is \"l\" + \"s\" = \"ls\".Same with the concatenation result \"ls\", the answer is ls.",
  "Few-shot-cot demonstration optimized by coreference resolution": "Q: A coin is heads up. Ka flips the coin. Sherrie flips the coin. Is the coin still heads up?A: The coin was flipped by Ka and Sherrie. So the coin was flipped 2 times. The coin flipped times is an even number. The coin started heads up, so after an even number of flips, the coin will still be heads up. So the answer is yes. Q: A coin is heads up. Jamey flips the coin. Teressa flips the coin. Is the coin still heads up?A: The coin was flipped by Jamey and Teressa. So the coin was flipped 2 times. The coin flipped times is an even number. The coin started heads up, so after an even number of flips, the coin will still be heads up. So the answer is yes. Q: A coin is heads up. Maybelle flips the coin. Shalonda does not flip the coin. Is the coin still heads up?A: The coin was flipped by Maybelle. So the coin was flipped 1 time. The coin flipped times is an odd number. The coin started heads up, so after an odd number of flips, the coin will be tails up. So the answer is no. Q: A coin is heads up. Millicent does not flip the coin. Conception flips the coin. Is the coin still heads up?A: The coin was flipped by Conception. So the coin was flipped 1 time. The coin flipped times is an odd number. The coin started heads up, so after an odd number of flips, the coin will be tails up. So the answer is no. Q: A coin is heads up. Sal flips the coin. Raymond does not flip the coin. Is the coin still heads up?A: The coin was flipped by Sal. So the coin was flipped 1 time. The coin flipped times is an odd number. The coin started heads up, so after an odd number of flips, the coin will be tails up. So the answer is no. Q: A coin is heads up. Conception flips the coin. Kristian does not flip the coin. Is the coin still heads up?A: The coin was flipped by Conception. So the coin was flipped 1 time. The coin flipped times is an odd number. The coin started heads up, so after an odd number of flips, the coin will be tails up. So the answer is no. Q: A coin is heads up. Inga does not flip the coin. Elanor does not flip the coin. Is the coin still heads up?A: The coin was flipped by no one. So the coin was flipped 0 times. The coin started heads up, and the coin was not flipped, so the coin is still heads up. So the answer is yes. Q: A coin is heads up. Ryan flips the coin. Shaunda flips the coin. Is the coin still heads up?A: The coin was flipped by Ryan and Shaunda. So the coin was flipped 2 times. The coin flipped times is an even number. The coin started heads up, so after an even number of flips, the coin will still be heads up. So the answer is yes.",
  "Few-shot-cot demonstration optimized by coreference resolution and step decomposition": "Q: A coin is heads up. Ka flips the coin. Sherrie flips the coin. Is the coin still heads up?A: The coin was flipped by Ka. The coin was flipped by Sherrie. So the coin was flipped 2 times. The coin flipped times is an even number. The coin started heads up, so after an even number of flips, the coin will still be heads up. So the answer is yes. Q: A coin is heads up. Jamey flips the coin. Teressa flips the coin. Is the coin still heads up?A: The coin was flipped by Jamey. The coin was flipped by Teressa. So the coin was flipped 2 times. The coin flipped times is an even number. The coin started heads up, so after an even number of flips, the coin will still be heads up. So the answer is yes. Q: A coin is heads up. Maybelle flips the coin. Shalonda does not flip the coin. Is the coin still heads up?A: The coin was flipped by Maybelle. So the coin was flipped 1 time. The coin flipped times is an odd number. The coin started heads up, so after an odd number of flips, the coin will be tails up. So the answer is no. Q: A coin is heads up. Millicent does not flip the coin. Conception flips the coin. Is the coin still heads up?A: The coin was flipped by Conception. So the coin was flipped 1 time. The coin flipped times is an odd number. The coin started heads up, so after an odd number of flips, the coin will be tails up. So the answer is no. Q: A coin is heads up. Sal flips the coin. Raymond does not flip the coin. Is the coin still heads up?A: The coin was flipped by Sal. So the coin was flipped 1 time. The coin flipped times is an odd number. The coin started heads up, so after an odd number of flips, the coin will be tails up. So the answer is no. Q: A coin is heads up. Conception flips the coin. Kristian does not flip the coin. Is the coin still heads up?A: The coin was flipped by Conception. So the coin was flipped 1 time. The coin flipped times is an odd number. The coin started heads up, so after an odd number of flips, the coin will be tails up. So the answer is no. Q: A coin is heads up. Inga does not flip the coin. Elanor does not flip the coin. Is the coin still heads up?A: The coin was flipped by no one. So the coin was flipped 0 times. The coin started heads up, and the coin was not flipped, so the coin is still heads up. So the answer is yes. Q: A coin is heads up. Ryan flips the coin. Shaunda flips the coin. Is the coin still heads up?A: The coin was flipped by Ryan. The coin was flipped by Shaunda. So the coin was flipped 2 times. The coin flipped times is an even number. The coin started heads up, so after an even number of flips, the coin will still be heads up. So the answer is yes.",
  "Q: Do hamsters provide food for any animals?A: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. So the answer is yes": "Q: Could Brooke Shields succeed at University of Pennsylvania?A: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the University of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. So the answer is yes. Q: Yes or no: Hydrogen's atomic number squared exceeds number of Spice Girls?A: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen's atomic number squared is less than 5. So the answer is no. Q: Yes or no: Is it common to see frost during some college commencements?A: College commencement ceremonies can happen in December, May, and June. December is in the winter, so there can be frost. Thus, there could be frost at some commencements. So the answer is yes. Q: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?A: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6 months. Thus, a llama could not give birth twice during the War in Vietnam. So the answer is no.",
  "Q: Do hamsters provide food for any animals?A: Hamsters are prey animals. Prey animals are food for predators. Thus, hamsters provide food for some animals. So the answer is yes": "Q: Could Brooke Shields succeed at University of Pennsylvania?A: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the University of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. So the answer is yes. Q: Yes or no: Hydrogen's atomic number squared exceeds number of Spice Girls?A: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen's atomic number squared is less than 5. So the answer is no. Q: Yes or no: Is it common to see frost during some college commencements?A: College commencement ceremonies can happen in December, May, and June. December is in the winter, so there can be frost. Thus, there could be frost at some college commencements. So the answer is yes. Q: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?A: The War in Vietnam was 6 months. The gestation period for a llama is 11 months. The gestation period for a llama is more than 6 months. Thus, a llama could not give birth twice during the War in Vietnam. So the answer is no. Q: Yes or no: Would a pear sink in water?A: The density of a pear is about 0.6g/cm3. The density of a pear is less than water. Objects less dense than water float. Thus, a pear would float. So the answer is no. Q: Do hamsters provide food for any animals?A: Hamsters are prey animals. Prey animals are food for predators. So Hamsters are food for predators. Thus, hamsters provide food for some animals. So the answer is yes. Q: Could Brooke Shields succeed at University of Pennsylvania?A: Brooke Shields went to Princeton University. Princeton University is academically rigorous. Hence, Brooke Shields could succeed at the Princeton University. Princeton University is about as academically rigorous as the University of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. So the answer is yes. Q: Yes or no: Hydrogen's atomic number squared exceeds number of Spice Girls?A: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. The atomic number of Hydrogen 1 does not exceed the number of Spice Girls 5. Thus, Hydrogen's atomic number squared is less than 5. So the answer is no. Q: Yes or no: Is it common to see frost during some college commencements?A: College commencement ceremonies can happen in December, May, and June. December is in the winter, winter can see frost. So December can see frost. Hence, College commencement can see frost. Thus, there could be frost at some college commencements. So the answer is yes. Q: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?A: The War in Vietnam was 6 months. The gestation period for a llama is 11 months. The gestation period for a llama is more than 6 months. A llama could not give birth twice in 6 months. Thus, a llama could not give birth twice during the War in Vietnam. So the answer is no. Q: Yes or no: Would a pear sink in water?A: The density of a pear is about 0.6g/cm3. The density of a pear is about 1g/cm3. The density of a pear is less than water. Objects less dense than water float. Thus, a pear would float. So the answer is no."
}