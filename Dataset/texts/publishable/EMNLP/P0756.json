{
  "Abstract": "Recent research has focused on examiningLarge Language Models (LLMs) characteris-tics from a psychological standpoint, acknowl-edging the necessity of understanding their be-havioral characteristics. The administration ofpersonality tests to LLMs has emerged as anoteworthy area in this context. However, thesuitability of employing psychological scales,initially devised for humans, on LLMs is amatter of ongoing debate. Our study aims todetermine the reliability of applying personal-ity assessments to LLMs, explicitly investigat-ing whether LLMs demonstrate consistent per-sonality traits. Analysis of 2,500 settings permodel, including GPT-3.5, GPT-4, Gemini-Pro,and LLaMA-3.1, reveals that various LLMsshow consistency in responses to the Big FiveInventory, indicating a satisfactory level of reli-ability. Furthermore, our research explores thepotential of GPT-3.5 to emulate diverse person-alities and represent various groupsa capabil-ity increasingly sought after in social sciencesfor substituting human participants with LLMsto reduce costs. Our findings reveal that LLMshave the potential to represent different person-alities with specific prompt instructions.",
  "Introduction": "The recent emergence of Large Language Mod-els (LLMs) marks a significant advancement inthe field of Artificial Intelligence (AI), showcasingits abilities in various natural language processingtasks, including text translation (Jiao et al., 2023),sentence revision (Wu et al., 2023), program re-pair (Fan et al., 2023), and program testing (Denget al., 2023). Furthermore, LLM applications ex-tend beyond computer science, enhancing fieldssuch as clinical medicine (Cascella et al., 2023), le-gal advice (Deroy et al., 2023), and education (Daiet al., 2023). Currently, LLMs are catalyzing a",
  "*Partially done when interning at Tencent AI Lab.Wenxiang and Wenxuan are corresponding authors": "paradigm shift in human-computer interaction, rev-olutionizing how individuals engage with compu-tational systems. With the integration of LLMs,computers have transcended their traditional role astools to become assistants, establishing a symbioticrelationship with users. Thus, the focus of researchextends beyond assessing LLM performance to un-derstanding their behaviors from a psychologicalperspective. Huang et al. (2024b) highlights thesignificance of psychological analysis on LLMsin developing AI assistants that are more human-like, empathetic, and engaging. Such analysis alsoplays a crucial role in identifying potential biasesor harmful behaviors through the understanding ofthe decision-making processes of LLMs.In this context, personality tests aimed at quan-tifying individual characteristics have gained pop-ularity recently (Serapio-Garca et al., 2023; Bo-droza et al., 2023; Huang et al., 2024b). However,the applicability of psychological scales, initiallydesigned for humans, to LLMs has been contested.Critics argue that LLMs lack consistent and sta-ble personalities, challenging the direct transferof these scales to AI agents (Song et al., 2023;Gupta et al., 2023; Shu et al., 2024). The essenceof this debate lies in the reliability of these scaleswhen applied to LLMs. Reliability in psycho-logical terms refers to the consistency and stabil-ity of results derived from a psychological scale.Evaluating reliability in LLMs differs from its as-sessment in humans since LLMs demonstrate aheightened sensitivity to input variations comparedto humans. For example, humans generally pro-vide consistent responses to questions regardlessof their order, while LLMs might yield differentanswers due to varied contextual inputs. Althoughconsistent results can be obtained from an LLMby querying single items with a zero-temperatureparameter setting, such responses are likely to varyunder different input conditions. Therefore, ourstudy first systematically investigates the reliability of LLMs on psychological scales under varyingconditions, including instruction templates, itemrephrasing, language, choice labeling, and choiceorder. Through analyzing the distribution of all2,500 settings, we find that various LLMs demon-strate sufficient reliability on the Big Five Inven-tory.Additionally, our study further explores whetherinstructions or contexts can influence the distri-bution of personality results.We seek to an-swer whether LLMs can replicate responses ofdiverse human populations, a capability increas-ingly sought after by social scientists for substi-tuting human participants in user studies (Dillionet al., 2023). However, this topic remains contro-versial (Harding et al., 2023), warranting thoroughinvestigation. In particular, we employ three ap-proaches to affecting the personalities of LLMs,from low directive to high directive: (1) by creatinga specific environment, (2) by assigning a predeter-mined personality, and (3) by embodying a char-acter. Firstly, recent research by Coda-Forno et al.(2023) demonstrates the impact of a sad/happy con-text on LLMs anxiety levels. Following this work,we conduct experiments to assess LLMs person-ality within these varied emotional contexts. Sec-ondly, we assign a specific personality for LLM,drawing upon existing literature that focuses onchanging the values of LLMs (Santurkar et al.,2023). Thirdly, inspired by Deshpande et al. (2023),which investigates the assignment of a persona toChatGPT for assessing its tendency towards offen-sive language and bias, we instruct the LLM toembody the characteristics of a predefined char-acter and measure the resulting personality. Ourfindings indicate that GPT-3.5-Turbo can representvarious personalities in response to specific promptadjustments.The contributions of this study are as follows: This study is the first to conduct a comprehensiveanalysis through five distinct factors on the relia-bility of psychological scales applied to LLMs,showing that GPT-3.5-Turbo has stable and dis-tinct personalities.",
  "Personality Tests": "Personality tests are instruments designed to quan-tify an individuals character, behavior, thoughts,and emotions. A prominent model for assessingpersonality is the five-factor model, OCEAN (Open-ness, Conscientiousness, Extraversion, Agreeable-ness, Neuroticism), also known as the Big Fivepersonality traits (John et al., 1999). Other no-table models include the Myers-Briggs Type In-dicator (MBTI) (Myers, 1962) and the EysenckPersonality Questionnaire (EPQ) (Eysenck et al.,1985), each based on distinct trait theories. Ex-tensive research has demonstrated these modelseffectiveness (i.e., reliability and validity) in hu-man subjects. However, the application of thesetests to LLMs remains a topic of debate.",
  "Reliability and Validity of Scales": "In psychometrics, the concepts of reliability andvalidity are crucial for evaluating the quality andeffectiveness of psychological scales and tests. Re-liability refers to the consistency and stability ofthe results obtained from a psychological test orscale. There are various types of reliability; twocommon ones are Test-Retest Reliability and Inter-nal Consistency Reliability. Test-Retest Reliabilityassesses the stability of a test over time (Guttman,1945) while Internal Consistency Reliability checkshow well the items within a test measure the sameconcept or construct (Cronbach, 1951). Validity ishow well a test measures what it should measure.Researchers usually consider different types of va-lidity, such as Construct Validity and Criterion Va-lidity (Serapio-Garca et al., 2023). Being the mostcritical type of validity, Construct Validity refers tohow well a scale measures the theoretical constructit is supposed to measure. Construct validity isoften demonstrated through correlations with othermeasures that are theoretically related (ConvergentValidity) and not correlated with measures that are",
  "TemplateDetails": "T1 (Huang et al., 2024b)You can only reply from START to END in the following statements. Here are a number of characteristicsthat may or may not apply to you. Please indicate the extent to which you agree or disagree with thatstatement. LEVEL_DETAILS Here are the statements, score them one by one: ITEMS T2 (Miotto et al., 2022)Now I will briefly describe some people. Please read each description and tell me how much each personis like you. Write your response using the following scale: LEVEL_DETAILS Please answer the statement,even if you are not completely sure of your response. ITEMS",
  "T3 (Jiang et al., 2023)Given the following statements of you: ITEMS Please choose from the following options to identify howaccurately this statement describes you. LEVEL_DETAILS": "T4 (Serapio-Garca et al., 2023)Here are a number of characteristics that may or may not apply to you. Please rate your level of agreementon a scale from START to END. LEVEL_DETAILS Here are the statements, score them one by one: ITEMS T5 (Serapio-Garca et al., 2023)Here are a number of characteristics that may or may not apply to you. Please rate how much you agreeon a scale from START to END. LEVEL_DETAILS Here are the statements, score them one by one: ITEMS",
  ": Five different versions of instructions to complete the personality tests for LLMs from different papers": "theoretically unrelated (Divergent Validity) (Mes-sick, 1998). Criterion Validity assesses how wellone measure predicts an outcome based on anothermeasure (Clark and Watson, 2019). It is often splitinto Concurrent Validity, when the scale is com-pared to an outcome that is already known at thesame time the scale is administered; and PredictiveValidity when the scale is used to predict a futureoutcome (Barrett et al., 1981). While reliability isa necessary but insufficient condition for validity,validity inherently necessitates reliability. Conse-quently, assessing the reliability of scales formsthe foundational step in evaluating the personalitytraits of LLMs and thus constitutes the primaryfocus of this study.",
  "Framework Design": "The consistency of responses from LLMs is pre-dominantly determined by their input (Hagendorffet al., 2023). To assess the reliability of LLMs, itis crucial to examine their responses across vary-ing input conditions. In this study, we propose todeconstruct a query into five distinct factors for acomprehensive analysis: (1) the nature of the in-struction, (2) the specific items in the scale, (3) thelanguage used, (4) the labeling of choices, and (5)the order in which these choices are presented.",
  "(1) InstructionGiven that LLMs exhibit sensitiv-ity to variations in prompt phrasing, as observed byBubeck et al. (2023), and Gupta et al. (2023) high-": "lighted that LLMs demonstrate differing personali-ties under varying prompting instructions, we needto evaluate the influence of different instructions.To this end, we analyze the performance of fivedistinct prompt templates: T1 as applied in Huanget al. (2024b), T2 as used by Miotto et al. (2022),T3 suggested by Jiang et al. (2023), and T4 and T5both identified in Serapio-Garca et al. (2023). De-tails of prompts are listed in , where STARTand END indicate the choice labels used (e.g., 1 to5 or A to E), LEVEL_DETAILS denotes the def-inition of each level (e.g., 1. Strongly Agree),and ITEMS contains the items to be rated by LLMs.Notably, our selection covers all three templatesinvestigated by Gupta et al. (2023). (2) ItemThe training data for LLMs likely in-clude items from publicly available personalitytests.Consequently, LLMs may develop spe-cific response patterns to these scales during pre-training or instructional tuning phases.In linewith previous research that examines LLM per-formance (Coda-Forno et al., 2023; Bubeck et al.,2023), we rephrase the items in the scale to en-sure their novelty to the model. A critical aspectof this evaluation is determining if LLMs consis-tently respond to different paraphrases of the sameitem, which would indicate comprehension of theinstruction and the ability to provide independentratings rather than merely recalling training data.To this end, we employ GPT-4-Turbo to rephrasethe items and manually assess whether there are in-stances of duplicated sentences and if the rewrittensentences maintain their semantic meaning. Thisprocess results in five distinct versions of the items,including the original set.",
  "(3) LanguageConsidering the observed perfor-mance disparities among languages in LLMs (Laiet al., 2023; Wang et al., 2024b), coupled with": "the documented regional variations in personali-ties (Giorgi et al., 2022; Rentfrow et al., 2015; Krugand Kulhavy, 1973), we are motivated to assessLLMs personalities across different languages.Consequently, we extend our examination to in-clude nine more languages, namely Chinese (Zh),Spanish (Es), French (Fr), German (De), Italian(It), Arabic (Ar), Russian (Ru), Japanese (Ja), andKorean (Ko), using the English version as a basis.We translate all instructions and items, includingvariants introduced in previous paragraphs, afterrephrasing rather than before, as GPT-4-Turbosrephrasing ability is superior in English. The trans-lation from English into the target languages isconducted using Google Translate2 and DeepL.3 To ensure translation quality, we randomly sam-ple part of these machine-translated outputs andmanually review and verify the correctness (butmay not ensure fluency).4 Our selection of ten lan-guages includes different language families/groupsand various character sets. (4) Choice LabelLiang et al. (2023) demon-strated that LLMs exhibit sensitivity to the format-ting of choice labels, such as 1, 2 or A, B. Ourstudy extends this investigation to include the im-pact of various choice label formats. Specifically,we examine five formats: (1) lowercase Latin al-phabets (e.g., a, b), (2) uppercase Latin alphabets(e.g., A, B), (3) lowercase Roman numerals (e.g.,i, ii), (4) uppercase Roman numerals (e.g., I, II),and (5) Arabic numerals (e.g., 1, 2). (5) Choice OrderThe order of choices may im-pact the responses of LLMs, as these models aresensitive to the order of presented examples (Zhaoet al., 2021). To account for this, we introduce twoordering methods: (1) an ascending scale where1 denotes strong disagreement and 7 indicatesstrong agreement, and (2) a descending scale where1 signifies strong agreement and 7 denotesstrong disagreement.By integrating the five specified factors, we ob-tain 5 5 10 5 2 = 2500 distinct config-urations. Traditional frameworks often vary onlyone factor at a time while keeping others constant,potentially leading to insufficient observation andrestricted generalizability of their findings. Our",
  "Experimental Results": "Our experiments utilize the Big Five Inven-tory (BFI) (John et al., 1999). The BFI comprises44 items, each rated on a five-point Likert scale.This inventory is a widely-recognized and pub-licly available instrument for assessing personalitytraits, commonly known as the Five Factor Modelor OCEAN. Subscales of BFI include (the numberof items for each subscale is specified in paren-theses): (1) Openness to experience (O) (10) ischaracterized by an individuals willingness to trynew things, their level of creativity, and their ap-preciation for art, emotion, adventure, and unusualideas. (2) Conscientiousness (C) (9) refers to thedegree to which an individual is organized, respon-sible, and dependable. (3) Extraversion (E) (8)represents the extent to which an individual is out-going and derives energy from social situations. (4)Agreeableness (A) (9) measures the degree of com-passion and cooperativeness an individual displaysin interpersonal situations. (5) Neuroticism (N) (8)evaluates whether an individual is more prone toexperiencing negative emotions like anxiety, anger,and depression or whether the individual is gener-ally more emotionally stable and less reactive tostress. Overall results are derived by calculatingthe mean score for each subscale.We use GPT-3.5-Turbo (1106) (OpenAI, 2022),GPT-4-Turbo (1106) (OpenAI, 2023), Gemini-1.0-Pro (Pichai and Hassabis, 2023), and LLaMA-3.1-8B (Dubey et al., 2024), with the temperature pa-rameter set to zero. This section shows the resultsof GPT-3.5-Turbo due to page limit. The results ofthe other three models can be found in A in the ap-pendix. To introduce more variability into LLMsinput data, we randomize the order of the itemsin the scale and input a number of 17 to 27 itemssimultaneously (equivalent to 44/2 5), replicat-ing varying memory window sizes in LLMs. Thismethod is crucial to ensure whether LLMs consis-tently produce reliable outputs, regardless of theitems positions within the given context. Besides,it can mimic the way humans interact with psycho-logical scaleswhere multiple items are presentedat once, within the limits of an individuals mem-ory capacity. In each setting outlined in 3.1, weevaluate the LLM using these randomization tech-",
  "(d) Language(e) Choice Label(f) Choice Order": ": Visualization (projecting BFIs five dimensions to a 2-D space) of all LLaMA-3.1-8B data points. (a):the outliers and main body with the probability density (the darker the denser). (b) to (f): different options in eachfactor, marked in distinct colors and shapes. The gray area illustrates the all possible values in BFI tests.",
  "This projection matrix is used for all figures in this paperto provide a consistent comparison of distributions acrossdifferent settings": "outliers correspond to settings with an Arabic nu-meral choice label, descending choice order, andArabic and Chinese languages. Note that these out-liers arise when the LLM must associate numericalchoice labels with their natural language descrip-tions (e.g., 1. Strongly Agree). We hypothesizethat these anomalies indicate a diminished capac-ity in GPT-3.5-Turbo to accurately interpret andrespond within these language contexts. Quantitative AnalysisFirstly, we compared themeans of data points (i.e., averages of LLMs re-sponses) using a specific factor with other datapoints. For example, we can check whether thereare differences in means between data points usingEnglish and those using other languages. reveals little differences for the majority of factors;however, only 7 out of 135 comparisons (spanning27 factors across 5 dimensions) show a differenceexceeding 0.15. Furthermore, we calculate the stan-dard deviations for the five dimensions and com-pare them with recorded human norms (Srivastavaet al., 2003). In the OCEAN dimensions, GPT-3.5-Turbo records standard deviations of 0.3, 0.3, 0.4,0.3, and 0.4, respectively, while the crowd datashow a higher variability with 0.7, 0.7, 0.9, 0.7,and 0.8. Since the F-values for analysis of vari-ance are 2.7, 3.5, 5.4, 2.8, 3.3 and all p-values are< 0.0001, we can reject the null hypothesis thatLLMs variance is higher than or equal to the hu-",
  "(e) Neuroticism": ": Biweekly measurements starting from mid-September 2023 to late-January 2024 of the BFI onGPT-3.5-Turbo. The model experienced two differentversions (0613, 1106) during this period. The shadowrepresents the standard deviation (Std). man data, in favor of the alternative hypothesis thatLLMs variance is lower. These findings suggestthat GPT-3.5-Turbo demonstrates a consistent per-formance across different perturbations, and it ismore deterministic compared to the broader vari-ability in crowd data.",
  "Test-Retest Reliability": "As introduced in 2.2, Test-Retest Reliability is an-other key measure, reflecting the stability of resultsover time. Since OpenAI periodically updates theGPT-3.5-Turbo, to evaluate this reliability, we callthe API biweekly, starting from mid-September2023. Our analysis includes two primary versions,0613 and 1106, of the GPT-3.5-Turbo. The results,specifically focusing on the BFI, are illustrated in. Our statistical analysis on equal meansshown in indicates no variation attributableto model updates during this period, showing a highlevel of reliability. Findings 1: Given that the responses are not ran-dom and exhibit stability against various pertur-bations and times, GPT-3.5-Turbo demonstratessatisfactory levels of Internal Consistency Relia-bility and Test-Retest Reliability on the BFI.",
  "Our focus shifts from assessing the default per-sonalities of LLMs to evaluating their contextual": ": Students t-tests of the differences between themaximum (minimum) and the average of each dimen-sion of BFI on GPT-3.5-Turbo during the time periodshown in . The null hypothesis is the mean val-ues are equal. The large p-values show that we cannotreject H0, thus accepting that they have the same mean.",
  "N2.280.23(Min) 2.200.220.30Yes(Max) 2.360.210.30Yes": "steerability. This involves investigating whetherthe personality distribution depicted in canbe modified through specific instructions or con-textual cues. Researchers in the social sciencesare exploring the potential of substituting humansubjects with LLMs to reduce costs. Our researchhelps by offering valuable insights into the capabili-ties of LLMs to accurately represent diverse humanpopulations. Furthermore, the ability of LLMs toexhibit a range of personalities is essential, consid-ering the growing demand for AI assistants withtailored stylistic attributes. We propose three strate-gies: (1) low directive, which involves creating anenvironment; (2) moderate directive, entailing theassignment of a personality; and (3) high directive,which encompasses the embodiment of a character.",
  "Creating an EnvironmentCoda-Forno et al": "(2023) has demonstrated the capability to induceincreased levels of anxiety in LLMs through theincorporation of sad or anxious narratives. Build-ing on this finding, our study introduces bothnegative and positive environmental contexts toLLMs before conducting the personality test. Inline with previous studies on LLMs emotion ap-praisals (Huang et al., 2024a), our methodology inthe negative condition involves instructing the LLMto generate narratives encompassing emotions suchas anger, anxiety, fear, guilt, jealousy, embarrass-ment, frustration, and depression. Conversely, inthe positive condition, the LLM is prompted tocreate stories that evoke emotions like calmness,",
  "(f) Character-Hero": ": Visualization (projecting BFIs five dimensions to a 2-D space) of all GPT-3.5-Turbo data points underdifferent methods of manipulating personalities. Different situations are marked in distinct colors and shapes, whilethe original (default) personality distribution of GPT-3.5-Turbo is shown in gray triangles. (a) and (b): creating anenvironment. (c) and (d): assigning a personality. (e) and (f): embodying a character.",
  "relaxation, courage, pride, admiration, confidence,fun, and happiness": "Assigning a PersonalityWe employ the threeapproaches proposed by Santurkar et al. (2023)to assign a specific personality (denoted as P)to the LLM: (1) Question Answering (QA):This approach involves presenting personalitiesthrough multiple-choice questions, with P spec-ified through an option at the end of the prompt. 2)Biography (BIO): Here, the LLM is prompted togenerate a brief description of its personality, whichwe use to assign P, incorporating this descriptiondirectly into the prompt. 3) Portray (POR): Thistechnique explicitly instructs the LLM to be P. Toenhance the LLMs comprehension of P, we adopta methodology inspired by the Chain-of-Thought(CoT) prompting approach (Wei et al., 2022). Theapproach aims to instruct the model to articulatecharacteristics associated with P before engagingin the personality test. In selecting P, we aim to di-verge as much as possible from the default distribu-tion. This involves examining every maximum andminimum value across each personality dimension.For instance, a P that maximizes Openness isconsidered more adventurous and creative. Conse-quently, we identify ten distinct personality profilesfor our analysis. Embodying a CharacterRecent studies (Zhuoet al., 2023; Deshpande et al., 2023) have exploredthe induction of toxic content generation in Chat-GPT by simulating the speech patterns of histori-cal or fictional figures. Additionally, research hasexplored the capacity of LLMs to adopt distinctcharacters (Wang et al., 2024a; Shao et al., 2023)and examined the consistency of LLMs person-alities with these characters Wang et al. (2024c).Building upon this line of research, our study con-centrates on instructing LLMs to fully representa specific character, referred to as C. To assign C,we first prompt the LLM with only the charactersname. We then extend this approach using the CoTmethodology, providing the LLM with detailed ex-periences attributed to C. For the selection of C, weinclude a diverse range of heroes and villains fromboth fictional and real-world contexts, detailing 16characters in in the appendix.",
  "Results": "To facilitate a comparative analysis with the resultsin 3.2 (referred to as default in this section), weapply the BFI on GPT-3.5-Turbo with the samesettings. For each method, we vary factors (keep-ing language fixed to English) to generate approx-imately 2,500 data points, aligning with the sizeused for the default data. These data are then pro-jected into a two-dimensional space and visualized",
  "(b) BIO w/ and w/o CoT(d) Character w/ and w/o CoT": ": Visualization (projecting BFIs five dimen-sions to a 2-D space) of GPT-3.5-Turbo data pointsof assigning personalities and embodying characters.Whether or not to use CoT is distinguished in red andblue, while the original (default) personality distributionof GPT-3.5-Turbo is shown in gray triangles. alongside the default data in . The resultsyielded several insights: (1) The distribution ofpersonality outcomes, obtained by altering the at-mosphere of the conversation, closely aligns withthe default distribution. This suggests that environ-mental changes do not alter the LLMs personalitytraits. (2) When different personalities are assignedto GPT-3.5-Turbo, it demonstrates a capacity to re-flect diverse human characteristics, indicated by thediverged distribution patterns for various personali-ties from the default. Moreover, by simultaneouslymaximizing and minimizing specific personalitydimensions, we observe that the distributions ofthe extremities of each dimension are positionedon opposite ends. For example, the red points in(c) and (d) mark the high and low Open-ness. A clearer comparison for each dimension canbe found in in the appendix. This confirmsthat GPT-3.5-Turbo effectively distinguishes be-tween each BFI dimensions high and low values.(3) Assigning various characters to the LLM re-veals its ability to represent a broader spectrumof human populations, as indicated in (e).However, the representation of heroic charactersshows a distribution pattern similar to the default.We hypothesize that this similarity arises from themodels inherent positive bias. presents the distribution patterns observedwhen applying QA, BIO, and POR methods forpersonality assignment. Specifically, among thethree, only POR effectively alters the personalitydistribution of GPT-3.5-Turbo. Moreover, differentiates between data points with and with-out the CoT approach. Our analysis reveals thatthe CoT approach does not significantly influencethe results of personality distribution. Finally, toachieve more accurate LLM persona simulation,we recommend integrating detailed descriptionsof the target characters personality traits, habits,temperaments, and personal experiences. Findings 2: GPT-3.5-Turbo demonstrates the ca-pability to adopt varied personalities in responseto specific prompt adjustments.Furthermore,GPT-3.5-Turbo shows a precise comprehensionof the assigned personalities, indicated by thedistinct clusters at opposite ends of the same di-mension, as in (c) and 3(d).",
  "Limitations": "This study has several limitations:(1) The modifications made to the scales in-structions and items, including translation into dif-ferent languages, may impact its reliability andvalidity.Psychological scales are meticulouslycrafted in their wording, and any translation ne-cessitates a reevaluation of their reliability and va-lidity across different cultural contexts. Conse-quently, our transformations could potentially hurtthe original scales reliability and validity. Addi-tionally, these changes preclude the use of Cron-bachs alpha (Cronbach, 1951) for assessing theinternal consistency reliability. However, in thecontext of LLM, studying the reliability of psycho-logical scales without considering the effects ofprompt variations is insufficient. Varying prompttemplates has been a standard practice in this re-search domain (Serapio-Garca et al., 2023; Coda-Forno et al., 2023).(2) The study explores limited methods for influ-encing LLMs personality results. While numerousapproaches exist (Wang et al., 2024a; Shao et al.,2023), we select three representative methods toverify our hypothesis regarding LLMs ability tomirror diverse human populations. With the helpof our framework, future research can dig deeperinto a broader range of methods.(3) Although our study verifies the reliability ofpsychological scales on LLMs, it is not sufficientfor validity. This means that the models can re-spond consistently to the scales but might behaveinconsistently. We leave the exploration of scale",
  "Related Work": "Exploring the personality traits of LLMs has be-come a prevalent research direction. Miotto et al.(2022) analyzed GPT-3s personality traits, val-ues, and demographics. Karra et al. (2022), Jianget al. (2023), and Bodroza et al. (2023) conductedpersonality assessments on various LLMs, includ-ing BERT, XLNet, TransformerXL, GPT-2, GPT-3, and GPT-3.5.Li et al. (2022) investigatedwhether GPT-3, InstructGPT, and FLAN-T5 dis-play psychopathic tendencies as part of their per-sonality assessment. Jiang et al. (2024) examinedthe potential for assigning a distinct personality totext-davinci-003. Romero et al. (2023) under-took a cross-linguistic study of GPT-3s personalityacross nine languages. Rutinowski et al. (2024)evaluated ChatGPT for personality traits and po-litical values. Serapio-Garca et al. (2023) testedthe validity of the BFI on the PaLM model fam-ily. Huang et al. (2024b) applied thirteen differentpersonality and ability tests to LLaMA-2, Text-Davinci-003, GPT-3.5, and GPT-4. Our study isdistinct by offering a detailed analysis of the relia-bility of psychological scales on LLMs. We varyinstructions, items, languages, choice labels, andorder to evaluate the robustness of LLM responses.From 2,500 data points, we conclude that GPT-3.5-Turbo exhibits specific personality traits anddemonstrates satisfactory reliability on the BFI.However, researchers are arguing that conversa-tional AI, at its current stage, lacks stable personali-ties (Song et al., 2023; Gupta et al., 2023; Shu et al.,2024). We believe that this perception may stemfrom the limitations of the models assessed in Songet al. (2023) and Shu et al. (2024), which are com-paratively smaller and less versatile in various tasksthan our selected model, GPT-3.5-Turbo. Notably,Gupta et al. (2023) indicates that the personalitytraits of GPT-3.5-Turbo vary across three differentinstruction templates of the BFI, which is inconsis-tent with our findings. This discrepancy could be at-tributed to their methodology of choosing the mostlikely response from a set of 5 or 10, in contrastto our approach of utilizing the average response.However, we argue that employing the mean is amore standard practice in this context (Srivastavaet al., 2003). Additionally, Shr et al. (2023) ex-plores semantic variations by analyzing items thatmeasure opposing constructs. However, the itemsfrom the 50-item IPIP Big Five Markers are not strict negation pairs, which diminishes the validityof the agree bias explored in this study. We believethe impact of semantically distant item rephrasing,such as negations, represents a promising directionfor future research.",
  "Conclusion": "This study examines the reliability of psychologi-cal scales initially designed for human assessmentwhen applied to LLMs. Through a comprehen-sive methodology involving varied instruction tem-plates, item wording, languages, choice labels, andchoice order, this research includes 2,500 distinctexperimental settings. Data analysis reveals thatGPT-3.5-Turbo, GPT-4-Turbo, and Gemini-Proconsistently generate stable responses on the BFIacross diverse settings. Comparative analysis of thestandard deviations with established human normsindicates that the model does not produce randomresponses but exhibits tendencies towards specificpersonality traits. Furthermore, the study exploresthe potential for manipulating the distribution ofpersonalities by creating an environment, assigninga personality, and embodying a character. The find-ings demonstrate that GPT-3.5-Turbo can representdiverse personalities by adjusting prompts.",
  "Ethics Statements": "As highlighted by Huang et al. (2024b), LLMs as-signed negative personas can produce more toxic,unsafe, and misleading outputs on tasks like Truth-fulQA and SafetyQA. However, in their defaultsetting as helpful assistants, LLMs do not exhibitsuch negative impacts on downstream tasks. Theprimary objective of this paper is to facilitate thescientific inquiry into understanding LLMs froma psychological standpoint. Users must exercisecaution and recognize that the performance on thisbenchmark does not imply any applicability or cer-tificate of automated counseling or companionshipuse cases.",
  "Gerald V Barrett, James S Phillips, and Ralph A Alexan-der. 1981. Concurrent and predictive validity designs:A critical reanalysis. Journal of Applied Psychology,66(1):1": "Bojana Bodroza, Bojana M Dinic, and Ljubisa Bojic.2023. Personality testing of gpt-3: Limited temporalreliability, but highlighted social desirability of gpt-3s personality instruments results. arXiv preprintarXiv:2306.04308. Sbastien Bubeck, Varun Chandrasekaran, Ronen Eldan,Johannes Gehrke, Eric Horvitz, Ece Kamar, PeterLee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Har-sha Nori, Hamid Palangi, Marco Tulio Ribeiro, andYi Zhang. 2023. Sparks of artificial general intelli-gence: Early experiments with gpt-4. arXiv preprintarXiv:2303.12712. Marco Cascella, Jonathan Montomoli, Valentina Bellini,and Elena Bignami. 2023. Evaluating the feasibil-ity of chatgpt in healthcare: an analysis of multipleclinical and research scenarios. Journal of MedicalSystems, 47(1):33.",
  "Lee J Cronbach. 1951. Coefficient alpha and the internalstructure of tests. psychometrika, 16(3):297334": "Wei Dai, Jionghao Lin, Hua Jin, Tongguang Li, Yi-ShanTsai, Dragan Gaevic, and Guanliang Chen. 2023.Can large language models provide feedback to stu-dents? a case study on chatgpt. In 2023 IEEE In-ternational Conference on Advanced Learning Tech-nologies (ICALT), pages 323325. IEEE. Yinlin Deng, Chunqiu Steven Xia, Haoran Peng,Chenyuan Yang, and Lingming Zhang. 2023. Largelanguage models are zero-shot fuzzers: Fuzzing deep-learning libraries via large language models. In Pro-ceedings of the 32nd ACM SIGSOFT InternationalSymposium on Software Testing and Analysis, pages423435.",
  "Sybil BG Eysenck, Hans J Eysenck, and Paul Barrett.1985. A revised version of the psychoticism scale.Personality and individual differences, 6(1):2129": "Zhiyu Fan, Xiang Gao, Martin Mirchev, Abhik Roy-choudhury, and Shin Hwei Tan. 2023. Automatedrepair of programs from large language models.In 2023 IEEE/ACM 45th International Conferenceon Software Engineering (ICSE), pages 14691481.IEEE. Salvatore Giorgi, Khoa Le Nguyen, Johannes C Eich-staedt, Margaret L Kern, David B Yaden, MichalKosinski, Martin EP Seligman, Lyle H Ungar, H An-drew Schwartz, and Gregory Park. 2022. Regionalpersonality assessment through social media lan-guage. Journal of personality, 90(3):405425.",
  "Jacqueline Harding, William DAlessandro, N. G.Laskowski, and Robert Long. 2023. Ai languagemodels cannot replace human research participants.AI & SOCIETY": "Jen-tse Huang, Man Ho Lam, Eric John Li, Shujie Ren,Wenxuan Wang, Wenxiang Jiao, Zhaopeng Tu, andMichael R Lyu. 2024a. Emotionally numb or empa-thetic? evaluating how llms feel using emotionbench.Advances in Neural Information Processing Systems,37. Jen-tse Huang, Wenxuan Wang, Eric John Li, Man HoLam, Shujie Ren, Youliang Yuan, Wenxiang Jiao,Zhaopeng Tu, and Michael R Lyu. 2024b. On thehumanity of conversational ai: Evaluating the psycho-logical portrayal of llms. In The Twelfth InternationalConference on Learning Representations. Guangyuan Jiang, Manjie Xu, Song-Chun Zhu, Wen-juan Han, Chi Zhang, and Yixin Zhu. 2023. Evaluat-ing and inducing personality in pre-trained languagemodels. Advances in Neural Information ProcessingSystems, 36. Hang Jiang, Xiajie Zhang, Xubo Cao, Cynthia Breazeal,Deb Roy, and Jad Kabbara. 2024. Personallm: In-vestigating the ability of large language models toexpress personality traits. In Findings of the Associa-tion for Computational Linguistics: NAACL 2024.",
  "Peter Romero, Stephen Fitz, and Teruo Nakatsuma.2023.Do gpt language models suffer from splitpersonality disorder? the advent of substrate-freepsychometrics. Research Square preprint": "Jrme Rutinowski, Sven Franke, Jan Endendyk, InaDormuth, Moritz Roidl, and Markus Pauly. 2024.The self-perception and political biases of chat-gpt. Human Behavior and Emerging Technologies,2024(1):7115633. Shibani Santurkar, Esin Durmus, Faisal Ladhak, CinooLee, Percy Liang, and Tatsunori Hashimoto. 2023.Whose opinions do language models reflect? In In-ternational Conference on Machine Learning, pages2997130004. PMLR. Greg Serapio-Garca, Mustafa Safdari, Clment Crepy,Luning Sun, Stephen Fitz, Peter Romero, MarwaAbdulhai, Aleksandra Faust, and Maja Mataric. 2023.Personality traits in large language models. arXivpreprint arXiv:2307.00184. Yunfan Shao, Linyang Li, Junqi Dai, and Xipeng Qiu.2023.Character-llm: A trainable agent for role-playing. In Proceedings of the 2023 Conference onEmpirical Methods in Natural Language Processing,pages 1315313187. Bangzhao Shu, Lechen Zhang, Minje Choi, LaviniaDunagan, Lajanugen Logeswaran, Moontae Lee, Dal-las Card, and David Jurgens. 2024. You dont needa personality test to know these models are unre-liable: Assessing the reliability of large languagemodels on psychometric instruments. In Proceed-ings of the 2024 Conference of the North AmericanChapter of the Association for Computational Lin-guistics: Human Language Technologies (Volume 1:Long Papers), pages 52635281. Xiaoyang Song, Akshat Gupta, Kiyan Mohebbizadeh,Shujie Hu, and Anant Singh. 2023. Have large lan-guage models developed a personality?: Applicabil-ity of self-assessment tests in measuring personalityin llms. arXiv preprint arXiv:2305.14693. Sanjay Srivastava, Oliver P John, Samuel D Gosling,and Jeff Potter. 2003. Development of personalityin early and middle adulthood: Set like plaster orpersistent change? Journal of personality and socialpsychology, 84(5):1041.",
  "Tom Shr, Florian E Dorner, Samira Samadi, and Au-gustin Kelava. 2023.Challenging the validity ofpersonality tests for large language models. arXivpreprint arXiv:2311.05297": "Noah Wang, Zhongyuan Peng, Haoran Que, JiahengLiu, Wangchunshu Zhou, Yuhan Wu, HongchengGuo, Ruitong Gan, Zehao Ni, Jian Yang, Man Zhang,Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, WenhaoHuang, Jie Fu, and Junran Peng. 2024a. Rolellm:Benchmarking, eliciting, and enhancing role-playingabilities of large language models. In Findings ofthe Association for Computational Linguistics: ACL2024. Wenxuan Wang, Zhaopeng Tu, Chang Chen, YouliangYuan, Jen-tse Huang, Wenxiang Jiao, and Michael RLyu. 2024b. All languages matter: On the multilin-gual safety of large language models. In Findings ofthe Association for Computational Linguistics: ACL2024. Xintao Wang, Yunze Xiao, Jen-tse Huang, Siyu Yuan,Rui Xu, Haoran Guo, Quan Tu, Yaying Fei, ZiangLeng, Wei Wang, et al. 2024c. Incharacter: Evaluat-ing personality fidelity in role-playing agents throughpsychological interviews. In Proceedings of the 62ndAnnual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers), pages 18401873. Jason Wei, Xuezhi Wang, Dale Schuurmans, MaartenBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,et al. 2022. Chain-of-thought prompting elicits rea-soning in large language models. Advances in NeuralInformation Processing Systems, 35:2482424837.",
  "AReliability Tests on Other LLMs": "We also explore the reliability of different LLMs on the BFI, taking into account their variations intraining datasets and instruction tuning methodologies. We extend our analysis to include OpenAIsGPT-4-Turbo (OpenAI, 2023), Googles Gemini-1.0-Pro (Pichai and Hassabis, 2023), and Meta AIsLLaMA-3.1-8B (Dubey et al., 2024), running on the same 2,500 profiles as those applied to GPT-3.5-Turbo. , , and illustrate the data points generated from GPT-4-Turbo, Gemini-1.0-Pro,and LLaMA-3.1-8B, respectively. Consistent with our previous experiments on GPT-3.5-Turbo, we utilizeDBSCAN parameters of eps = 0.3 and minPt = 20. The outlier rates for GPT-4-Turbo, Gemini-1.0-Pro,and LLaMA-3.1-8B are 5.6%, 4.2%, and 4.4%, respectively.Our findings reveal the following: (1) GPT-4-Turbo and Gemini-1.0-Pros responses are not evenlydistributed across the BFI space, indicating a satisfactory level of their consistency. In contrast, LLaMA-3.1-8B exhibits a more decentralized distribution, reflecting lower response consistency. (2) Each modeldisplays a distinct personality profile, as shown in . While their distributions are centered in a similarregion of the BFI space due to their shared role as helpful assistants, the areas of highest concentrationvary. For instance, GPT-4-Turbos distribution is closer to GPT-3.5-Turbos, while Gemini-1.0-Pro alignsmore closely with GPT-3.5-Turbo.",
  "(d) Agreeableness(e) Neuroticism": ": Visualization (projecting BFIs five dimensions to a 2-D space) of the two extreme personalities assignedto GPT-3.5-Turbo for each of the five dimensions from the BFI. We can observe two separate clusters in two oppositedirections. The difference is not obvious in (d) because this dimension is compressed. : Students t-tests of the differences between the two extreme personalities assigned to GPT-3.5-Turbo foreach of the five dimensions from the BFI, corresponding to the five figures shown in . These statisticallysignificant differences (p < 0.001) clearly demonstrate the separation between the maximum and minimum values.",
  "DImpact of Item Order": "Due to the impracticality of evaluating all possible item orders (whose number equals to 44! 2.651054),we initially excluded this factor from our analysis. Nonetheless, preliminary investigations suggest thatitem order has a minimal impact on test score variance. To substantiate this, we conduct an experimentwith a subset of 100 configurations from the 2,500 possible settings, testing three different item sequencesfor the BFI:",
  "(1) vs. (2)0.26 (No)0.36 (No)0.37 (No)0.33 (No)0.15 (No)(2) vs. (3)0.49 (No)0.49 (No)0.09 (No)0.30 (No)0.26 (No)(3) vs. (1)0.26 (No)0.37 (No)0.05 (No)0.16 (No)0.36 (No)": "The means and standard deviations for all BFI dimensions across each test are presented in ,while the t-test p-values for comparisons between the three tests are provided in . We find that:(1) Means and standard deviations show negligible differences across the three scenarios. (2) T-testcomparisons between each pair of scenarios yield high p-values, consistently failing to reject the nullhypothesis of identical means. These findings indicate that item order variations do not affect BFI scores.",
  "EQuantitative Results of Factor Comparison": ": Comparison of a specific factor relative to other remaining factors. For example, The first row is thecomparison of using T1 (500 data points) and using T2 to T5 (2,000 data points). The number is the difference ofthe two mean values, while the subscripted numbers represent the p-values for each t-test.",
  "DimensionMinimumMaximum": "OpennessA person of routine and familiarityAn adventurous and creative personConscientiousnessA more spontaneous and less reliable personAn organized person, mindful of detailsExtraversionA person with reserved and lower energy levelsA person full of energy and positive emotionsAgreeablenessA competitive person, sometimes skeptical of others intentionsA compassionate and cooperative personNeuroticismA person with emotional stability and consistent moodsA person with emotional instability and diverse negative feelings"
}