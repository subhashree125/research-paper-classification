{
  "Abstract": "The human visual system is capable of pro-cessing continuous streams of visual informa-tion, but how the brain encodes and retrievesrecent visual memories during continuous vi-sual processing remains unexplored. This studyinvestigates the capacity of working memoryto retain past information under continuous vi-sual stimuli. And then we propose a new taskMemory Disentangling, which aims to extractand decode past information from fMRI sig-nals. To address the issue of interference frompast memory information, we design a disen-tangled contrastive learning method inspiredby the phenomenon of proactive interference.This method separates the information betweenadjacent fMRI signals into current and pastcomponents and decodes them into image de-scriptions. Experimental results demonstratethat this method effectively disentangles the in-formation within fMRI signals. This researchcould advance brain-computer interfaces andmitigate the problem of low temporal resolu-tion in fMRI. 1",
  "Introduction": "The human visual system is highly intricate andplays a foundamental role in daily lives (Loomiset al., 2018). Exploring and comprehending thissystem is a key objective for researchers in thefields of neuroscience and artificial intelligence(Clark, 2013; Herreras, 2010). One particularlyintriguing question pertains how the brain pro-cesses and retrieves recent visual memories, whichholds significant implications for Brain-ComputerInterfaces (BCIs) and cognitive neuroscience (Lo-gothetis, 2008; Ranganath and DEsposito, 2005;Marr, 2010).In recent years, functional magnetic resonanceimaging (fMRI), a revolutionary non-invasive neu-",
  ": The schematic diagram of Memory Disentan-gling based on decoding image semantic information": "roimaging technique (Ogawa et al., 1990), has be-come indispensable for studying brain functionand cognitive processes by detecting blood flowchanges associated with neural activity throughblood-oxygen-level-dependent (BOLD) contrast(Bandettini et al., 1992). With its high spatial res-olution, fMRI rapidly advances neuroscience re-searches (Glover, 2011). Therefore, fMRI providesour research with a unique perspective to explorethe relationship between brain activity and memoryfunctions.While significant progress (Xia et al., 2024; Ozcelik et al., 2022; Takagi and Nishimoto, 2023)has been made in fMRI studies involving static vi-sual stimuli, research on continuous visual stimuliremains largely unexplored. In real-world scenar-ios, visual experiences are rarely isolated and static.Instead, our brain continuously processes streamsof visual information, necessitating the tracking ofscene changes and retention of critical visual de-tails to support decision-making (Yin et al., 2020).Although studies under static visual stimuli haveprovided valuable insights into the visual system(Rossiter et al., 2001), they neglect the continuityand dynamics of visual information, limiting ourunderstanding of how the brain encodes memorywithin a continuous visual flow. Hence, it is cru-cial to explore how the brain processes memoryinformation and how the representation of memorychanges within the brain under continuous visual stimuli. Therefore, we endeavor to analyze mem-ory under continuous visual stimuli to advanceresearch on how the brain processes continuousvisual stimuli.Memory is a core component of human cogni-tive architecture, allowing us to store and recallpast experiences. In visual perception, memoryinvolves not only encoding individual scenes butalso integrating and updating continuous streamsof visual information (Miller, 1956; Cowan, 2001).According to working memory theory, the humanbrain can temporarily store and manipulate infor-mation (Baddeley, 1992). However, the capacityof short-term memory especially working memoryis limited, typically around a few items (Luck andVogel, 1997).One of the motivations of our study is to ex-plore the ability of working memory to retain pastinformation under continuous visual stimuli by an-alyzing fMRI signals, particularly the semantic in-formation of images from the past few moments.We use two data analysis techniques, ridge regres-sion analysis and trial-wise representational simi-larity analysis (RSA), to assess the correlation be-tween fMRI signals and visual stimuli from differ-ent past time points. We find that the correlation be-tween fMRI signals and past semantic informationgradually decreases over time, retaining at most3-4 items, which aligns with the characteristics ofworking memory (Luck and Vogel, 1997; Baddeley,1992).Based on the analysis of the correlation betweenfMRI signals and past visual stimuli, we proposethe new Memory Disentangling task. This taskaims to extract past visual stimuli information frombrain activity and separate it from ongoing brainactivity to mitigate the effects of proactive inter-ference. To simplify this task, we focus on Mem-ory Disentangling based on decoding the semanticinformation of these stimulus. Specifically, wedecode the fMRI signals to get the semantic infor-mation of images both current and past moments.A schematic illustration of this process is shownin . This task can contribute to advancingbrain memory decoding research. Besides, by de-coding past information, it also addresses the lowtemporal resolution issue inherent in fMRI signals.To achieve this goal, we first propose a straight-forward method for Memory Disentangling by em-ploying multiple separate Multilayer Perceptron tomap fMRI signals to semantic features of imagesat multiple time points. Additionally, inspired by proactive interference in working memory (Ober-auer and Kliegl, 2001; Keppel and Underwood,1962), we introduce contrastive learning for dis-entangling. This method leverages relationshipsbetween consecutive pairs of fMRI signals to en-hance the accuracy of extracting past information.Subsequently, we discuss how to transform thesesemantic features into intuitive, textual representa-tions of semantic content and evaluate their effec-tiveness.Our contributions are as follows: We analyze the capacity of working mem-ory using fMRI signals and proposed a newtaskMemory Disentangling based on thesefindings, aiming to decode past informationfrom current brain signals and mitigate mem-ory interference. We introduce a memory disentangled con-trastive learning method to accomplish theMemory Disentangling task, leveraging thetheory of proactive interference to disentanglepast memory information from current fMRIsignals. We conduct extensive experiments to validatethe role of disentangled contrastive learning,demonstrating its effectiveness for mitigatememory interference and providing insightsthat guide future brain decoding tasks to con-sider the impact of past memories.",
  "Analysis and Task Definition": "As previously mentioned, working memory has theability to temporarily store and manipulate infor-mation. We investigate the capacity of workingmemory to retain past information based on fMRIsignals under continuous visual stimuli. Based onthis investigation, we propose a new task in thefield of brain decoding, termed Memory Disen-tangling, which will be detailed in .2.",
  "Visual Memory Analysis": "In this section, we explore whether fMRI signalscan reflect past visual stimuli and the duration forwhich this information be retained in the fMRI sig-nals. To achieve this goal, we employ ridge regres-sion analysis and trial-wise RSA to examine thecorrelation between fMRI signals and visual stim-uli from different past time points. The overviewof this section is displayed in .",
  "Cn...C1Cn-1C2": ": Overview of visual memory analysis. (a) Acquisition of continuous visual stimuli data, including imageembeddings and fMRI signals. (b) Ridge regression analysis for visual memory, whereR represents the ridgeregression model, and k is offset. The figure illustrates an example for k = 2. (c) Trail-wise RSA, with the meaningof k remaining consistent with the previous context. Note that, for explanatory purposes, the size of the RDMs inthe figure is illustrative and not representative of the actual size. 0123456789rand k 0.66 0.67 0.68 0.69 0.70 0.71 0.72 0.73 0.74 Pearson correlation coefficient subj01subj02subj05subj07",
  ": The results of ridge regression analysis forfour participants": "Data AcquisitionThe Natural Scenes Dataset(NSD) (Allen et al., 2022), which is the largestfMRI image stimulation dataset, is applied in theexperiment. During the dataset creation process,subjects in each session are guided to observe asequence of images, and are asked whether thecurrent image has shown before. The fMRI signalsduring the observation of each image are recorded.As illustrated in (a), by using the templatesprovided by NSD, the 3D fMRI data collected fromone specific subject can be converted into vectors,yielding sequences F1, F2, . . . , Fn. These vectorsare regraded as input to a pre-trained CLIP imageencoder for obtaining meaningful embeddings ofeach image. The corresponding CLIP embeddingsequence is written as C1, C2, . . . , Cn, which willbe used in the subsequent analyses. k 0.025 0.000 0.025 0.050 0.075 0.100 0.125 0.150 Trail-wise RSA Score subj01subj02subj05subj07",
  ": The trail-wise RSA results for four partici-pants": "Ridge Regression AnalysisTo explore theamount of past information retained in brain sig-nals, we formulate it as analyzing the correlationbetween the fMRI vector Ft at the current time stept and the CLIP embeddings Ctk of different pasttime points. The offset k measures the number oftime steps. For example, k = 0 means the currentfMRI vector is paired with the current CLIP em-bedding, and k = 1 means the current fMRI vectoris paired with last time points CLIP embedding.As the time span increases, offset k changes from0 to maxk. Ridge regression, a method to handlemulticollinearity by introducing a regularizationterm to stabilize the model, is employed to inves-tigate the correlation between Ft and Ctk. Ridgeregression is performed for each Ft, Ctk pairrespectively as k varies. The process is illustrated in (b).We set maxk = 9 and explore different k valuesfrom 0 to maxk, where Notably, since each imagein the NSD is presented three times and appearsrandomly in the image sequence, we ensure thatimages in the test set are not included in the train-ing set. Afterwards, we sequentially apply ridgeregression analysis with k ranging from 0 to maxkto the partitioned data. Additionally, we establisha lowerbound by randomly matching all brain sig-nals and CLIP embeddings (adhering to the testset division principle) and also performing ridgeregression analysis.The results of test set for different k values areshown in , with the x-axis representingdifferent k values, and the rand representing ourlowerbound result. From the results, it can be ob-served that as the value of k increases, the correla-tion between brain signals and corresponding CLIPrepresentations gradually decreases. Particularlyat k = 3, the correlation approaches the lowerbound, indicating that the information contained inthe brain signals related to more than three items isminimal or challenging to extract. Trial-wise Representational Similarity Analy-sisAnother method we used for memory reten-tion analysis is trial-wise representational similarityanalysis. The computation process for each sessionis illustrated in (c). For each session, weconstruct two representational dissimilarity matrice(RDM), RDMf and RDMc, using the sequencesF1, F2, . . . , Fn and C1, C2, . . . , Cn. In an RDM,the rows and columns represent the vectors (fMRIvectors or CLIP embeddings) corresponding to thestimuli, and the cell values indicate the dissimilar-ity between vectors (1 - the Pearson correlationcoefficient ). Thus, an RDM contains the dissim-ilarity levels between every pair of stimuli (bothFi and Ci sequences) and is a symmetric n nmatrix. The computation process for RDFf is asfollow, and the calculation for RDMc follows thesame procedure.",
  "(1)where J is an all-ones matrix.RSA (Kriegeskorte et al., 2008) is well-suitedfor researchers to compare data across different": "modalities and even to bridge data from differentspecies. Unlike traditional RSA based on the entireRDM matrix, our method focuses on the similarityrepresentation between individual data trials. Wecalculate the trial-wise similarity between RDMfand RDMc. Here, we also use the offset k, wherethe tth row of RDMc corresponds to the (t + k)throw of RDMf. We compute their correlation coef-ficient k,t and average the results of all rows thatmeet this requirement to obtain the trial-wise repre-sentational similarity score k,ave for each sessionwith offset k. Finally, we compute the average ofvalues across all sessions to obtain the final trail-wise RSA score.The results are shown in . Similar toridge regression analysis, trial-wise RSA also ex-hibits similar trends.Furthermore, we replaceRDMc with RDMf to compute the similarity be-tween current and past brain activity signals. Wewill further elaborate in Appendix B, with the re-sults shown in .",
  "Task Description": "Based on the analysis above, we propose a taskcalled Memory Disentangling. This task involvesextracting information from past visual stimuli en-coded in brain activity and separating this infor-mation from ongoing brain activity to mitigate theeffects of proactive interference.As shown in , given the fMRI signalat time t, Ft, the task is to decode the image de-scriptions viewed at the current and previous to-tal (maxk + 1) time points, denoted as Cap :={capt, capt1, . . . , captmaxk}. Our analysis in-dicates that the brain signals at the current timeprimarily contain information about the last threemoments, thus we set maxk = 2.It is important to note that the Memory Disentan-gling task is not limited to decoding brain activityinto descriptions of images, and it can also involveother forms of decoding such as image reconstruc-tion. Unlike previous visual stimuli decoding tasks,the core challenge here is to capture informationabout multiple past moments from a single timepoints fMRI signal and to remove the interferingparts of past information, thereby enabling higherquality information decoding. Additionally, dueto the low temporal resolution of fMRI signals,brain activity between two scan frames may belost. Memory Disentangling, which focuses onextracting past information, might help to supple-ment the missing information between scan frames.",
  "Method": "In this section, we propose a method to ad-dress Memory Disentangling task, starting witha straightforward method. Initially, we employseparate Multilayer Perceptrons (MLPs) for pre-dicting embeddings corresponding to each momentbased on the current fMRI signal. This approachis easy to implement but has significant limitationsas it does not leverage the memory relational mem-ory dynamics between successive fMRI signals.To overcome these limitations, we design a disen-tangled contrastive learning method based on thetheory of proactive interference.",
  "Straightforward Method Using SeparateMLPs": "For this task, we reformulate it as predicting theCLIP embeddings Ctk for the current and the pre-ceding kth moment using the current fMRI signalFt, followed by generating image captions using apre-trained CLIP-to-caption model. The schematicdiagram of the straightforward method is displayedin the . Thus, the key point of the task liesin mapping the fMRI signal Ft to the CLIP embed-dings Ct, Ct1, Ct2. This method is to assign anMLP, denoted as MLPk, for the mapping of thekth past moment. By inputting Ft into each MLPk,we obtain k outputs, where each is subjected to anMSE loss with its corresponding Ci, and the lossesare summed up for training. The formula for theloss is as follows:",
  "Disentangled Contrastive Learning": "Motivated by the desire to disentangle the informa-tion from past memories embedded in the fMRIsignal Ft, we propose a disentangled contrastivelearning approach based on memory proactive in-terference theory, which posits that cognitive pro-cesses are subject to the influence of previouslyacquired knowledge. Its core idea is that the mem-ory component of current brain signals closely re-sembles the stimuli seen in the previous moment,a relationship present in all adjacent fMRI signals,thereby exhibiting continuity. That is, the neuralrepresentation of past information at time t is hy-pothesized to bear a closer resemblance to the cur-rent information at time t-1.Accordingly, we introduce a contrastive learningmethod to disentangle the brain signal into beforeand now components of semantic information,which we term disentangled contrastive learning.This enables the fMRI disentangle encoder to learnto disentangle past components. Subsequently, weuse MLPs for mapping as in the first part, and thisprocess is depicted in .For the disentangled contrastive learning, weinput consecutive fMRI signals Ft1, Ft into thesame fMRI disentangle encoder, yielding four com-ponents: beforet1, nowt1, beforet, and nowt.We set nowt1 and beforet as positive samples,with all other pairings as negative samples, andthen employ an InfoNCE (Oord et al., 2018) lossfor training. For simplicity, we denote beforet1 asbt1, beforet as bt, nowt1 as nt1, and nowt asnt.To compute the similarity for positive pairs, wefirst calculate the cosine similarity between bt andnt1, denoted as s(bt, nt1):",
  "MSE": "Positive SampleNegative Sample : Overview of the disentangled contrastive learning method. The left half illustrates the example ofdisentangled contrastive learning, while the right half shows the mapping process to the target image CLIPrepresentations. Further explanation of the division of positive and negative sample pairs in disentangled contrastivelearning is provided in Appendix D.",
  "Semantic Feature Decoding": "The two methods described above convert fMRIsignals into CLIP embeddings, representing thesemantic information of the visual stimuli at var-ious time points. Subsequently, we need to trans-form these embeddings into textual descriptions,which are easier to observe and evaluate. CLIPCap(Mokady et al., 2021) is an image captioning modelthat generates descriptions from the CLIP embed-dings of images. Given its superior performance,we use a pre-trained CLIPCap model to generatedescriptions from our predicted CLIP embeddings.Consequently, we can ultimately convert the cur-rent fMRI signals into textual descriptions of thevisual stimuli from the past few moments.",
  "Dataset and Processing": "In our study, we utilize the Natural Scenes Dataset(NSD), a large-scale dataset of fMRI scans in re-sponse to visual stimuli from MS COCO dataset(Lin et al., 2014). This dataset includes fMRI scansfrom eight subjects, obtained using a 7-Tesla fMRIscanner. During the scans, subjects are asked toview images and judge whether they have seen thepresented image before. Each subject observes9,000-10,000 distinct images, with each image ap-pearing three times, randomly distributed through-out the image sequence. In the experiment, eachsubject undergoes 30-40 scan sessions, with eachsession containing 12 scan runs. There is a restperiod between each pair of runs, and each runcontains a continuous sequence of 62-63 images.Therefore, each session contains a total of 750 im-ages. During each scan, image is presented for 3seconds, followed by a 1-second blank screen. Formore detailed information about the dataset, pleasevisit the official website2.In our study, we use the data from subject 1, 2,5, and 7, as they have complete image scanningsessions, totaling 27,750 trials. We utilize the pre-processed functional scans at a resolution of 1.8mm provided by NSD, along with the predefinedtemplate nsdgeneral to obtain fMRI vectors.For each fMRI signal in the session, we use asliding window of size 3 to store the CLIP imageembeddings of continuous visual stimuli. Addi-",
  ": Quantitative results of Memory Disentanglingfor Subject 1": "tionally, to ensure the images in the window aretemporally contiguous, any data where the imagesspan two different runs (indicating a long intervalbetween stimuli presentations) are removed. Sinceeach image is presented three times, it is crucial tostrictly control data splitting to prevent contamina-tion. We first select a test dataset of size m by ran-domly choosing m data pairs, each pair containingthe fMRI signal Ft and the CLIP representationsof images at times t 2, t 1, and t, in the form ofFt; Ct, Ct1, Ct2. Images appearing in the testset are marked. Subsequently, we evaluate the re-maining data, discarding any data points where the",
  "Implementation": "In our task analysis section, we employ the Neu-roRA (Lu and Ku, 2020) toolkit to compute theRDM matrix. Regarding Memory Disentangling,we opt for a Linfonce weight of 0.01, a selectionderive from a ablation study in .3. Thesize of our testing data m is set to 500, and a vali-dation set of the same size was randomly selectedfrom the partitioned training set. During the train-ing phase, we optimized the model using AdamW(Loshchilov and Hutter, 2019) with an initial learn-ing rate of 1e-5. We employ 5 different seeds forpartitioning and training to enhance the reliabilityof our results. The reported experimental outcomesrepresent the average of these results obtained from5 random seeds.",
  "Evaluation Metrics": "Since we employ the pre-trained CLIPCap modelto generate image captions from the predicted dis-entangled outputs, semantics-based evaluation be-comes more appropriate. To evaluate the degree ofmatching between the generated captions and theimages, we obtain the COCO captions for all im-ages in test set, and use the CIDEr (Vedantam et al.,2015), METEOR (Denkowski and Lavie, 2014),",
  "Qualitative Results": "To provide an intuitive understanding of the Mem-ory Disentangling task under continuous visualstimuli, reports several decoding examplesfrom Subject 1. Each example includes semanticdecoding results at three time points, representingthe caption results decoded at the current, and twoprevious moments.The results indicate that decoding at the currentmoment (k = 0) yields partially accurate results.However, the accuracy for past moments is rela-tively poor, with a tendency to set the subject as aperson/man .... This may be due to the highfrequency of human figures in the dataset. Addi-tionally, the decoding results tend to be broad; forexample, at time point 1 in the first sample andtime point 0 in the second sample, giraffes andcows are both decoded as animal. Occasionally,descriptions matching the images are obtained, in-dicating that decoding past information remainschallenging. Overall, the decoding results exhibitdiscrepancies with the visual stimuli, attributed tothe low signal-to-noise ratio (SNR) of brain activ-ity signals. This low SNR makes brain decodinghighly challenging, and extracting past informationfrom these signals even more difficult.",
  "presents the evaluation of decoding resultsof Subject 1 at three time points across differentmetrics, including CIDEr, METEOR, and SPICE": "Consistent with intuition, all metrics show vary-ing degrees of decline over time (represented inthe figure as increasing k values), with the CIDErmetric showing the most pronounced drop. Thistrend suggests that the accuracy and richness of thedecoded descriptions deteriorate as the temporaldistance from the current moment increases. Ad-ditional quantitative results for other subjects areprovided in Appendix C.",
  "Ablation Study": "We conducted multiple experiments on the NSDdataset to perform Memory Disentangling task. Weevaluated both the straightforward method and ourproposed disentangled contrastive learning methodwith varying loss weight schemes represented by. The experimental outcomes are summarized in.The disentangled contrastive learning method,with a loss weight of 0.01, consistently achieves op-timal results at the current time point, demonstrat-ing its positive role in removing past interferencefrom fMRI brain signals. This effect may mitigatesome of the effects of proactive interference onmemory. However, this was not reflected in thedecoding at the subsequent two time points, indi-cating a need for further improvement in extractingpast information, and a relatively large weight ofLInfoNCE might impede the mapping from fMRIto CLIP space, resulting in reduced decoding per-formance and increased variance. We speculatethat this might be due to some information loss inthe representation of extracted past information.",
  "Conclusion": "This study proposes the task of Memory Disentan-gling by analyzing the past information containedin working memory under continuous visual stim-uli. Based on the phenomenon of proactive inter-ference, we introduce a disentangled contrastive learning method to complete the Memory Disen-tangling task, which involves decoding semanticcontent at multiple time points from fMRI signalsand remove the interfering parts of past informa-tion. This approach may help alleviate the lowtemporal resolution of fMRI and contribute newinsights to the field of brain decoding.",
  "Limitations": "Although we explored the content of past informa-tion contained in fMRI signals, its interpretabilityremains limited. Additionally, while we focusedon semantic decoding for Memory Disentanglingtasks, we did not address other forms of mem-ory disentanglement, such as image reconstruc-tion. While our proposed disentangled contrastivelearning method showed improvement in current-time decoding, its effectiveness in extracting pastmemory information was suboptimal, necessitat-ing further in-depth exploration in future research.Specifically, there is a need to investigate how tooptimize models to better capture past memoryaccurately and to enhance the models ability tolearn from brain signals. Furthermore, expand-ing to other Memory Disentangling tasks wouldhelp comprehensively assess the methods gener-ality and applicability, thus advancing the field ofcognitive neuroscience.",
  "Ethical Statement": "We are committed to maintaining the highest stan-dards of ethical conduct in our research endeavors.The dataset used in this study adheres strictly to eth-ical guidelines, encompassing rigorous informedconsent protocols, participant confidentiality safe-guards, and meticulous data handling practices.Our commitment to transparency ensures that allresearch procedures are conducted with integrity,while prioritizing the security and privacy of partic-ipant data. By adhering to these ethical standards,we aim to responsibly advance the fields of neu-roscience and artificial intelligence, contributingmeaningfully to scientific knowledge and societalwell-being.",
  "Acknowledgements": "This research is supported by the National Natu-ral Science Foundation of China (No.62476127,No.62106105), the Natural Science Foundationof Jiangsu Province (No.BK20242039), the CCF-Baidu Open Fund (No.CCF-Baidu202307), the CCF-Zhipu AI Large Model Fund (No.CCF-Zhipu202315), the Fundamental Research Fundsfor the Central Universities (No.NJ2023032), theScientific Research Starting Foundation of Nan-jing University of Aeronautics and Astronautics(No.YQR21022), and the High Performance Com-puting Platform of Nanjing University of Aeronau-tics and Astronautics. Emily J Allen, Ghislain St-Yves, Yihan Wu, Jesse LBreedlove, Jacob S Prince, Logan T Dowdle,Matthias Nau, Brad Caron, Franco Pestilli, IanCharest, et al. 2022. A massive 7t fmri dataset tobridge cognitive neuroscience and artificial intelli-gence. Nature neuroscience, 25(1):116126. Peter Anderson, Basura Fernando, Mark Johnson, andStephen Gould. 2016.Spice: Semantic proposi-tional image caption evaluation. In Computer VisionECCV 2016: 14th European Conference, Amsterdam,The Netherlands, October 11-14, 2016, Proceedings,Part V 14, pages 382398. Springer.",
  "Nikos K Logothetis. 2008. What we can do and whatwe cannot do with fmri. Nature, 453(7197):869878": "Jack M Loomis, Roberta L Klatzky, and Nicholas AGiudice. 2018. -sensory substitution of vision: Im-portance of perceptual and cognitive processing. InAssistive technology for blindness and low vision,pages 179210. CRC press. Ilya Loshchilov and Frank Hutter. 2019. Decoupledweight decay regularization. In 7th InternationalConference on Learning Representations, ICLR 2019,New Orleans, LA, USA, May 6-9, 2019. OpenRe-view.net.",
  "Charan Ranganath and Mark DEsposito. 2005. Direct-ing the minds eye: prefrontal, inferior and medialtemporal mechanisms for visual working memory.Current opinion in neurobiology, 15(2):175182": "John R Rossiter, Richard B Silberstein, Philip G Har-ris, and Geoff Nield. 2001. Brain-imaging detectionof visual scene encoding in long-term memory fortv commercials. Journal of Advertising Research,41(2):1321. Paul Scotti, Atmadeep Banerjee, Jimmie Goode, StepanShabalin, Alex Nguyen, Aidan Dempster, NathalieVerlinde, Elad Yundler, David Weisberg, KennethNorman, et al. 2024. Reconstructing the minds eye:fmri-to-image with contrastive learning and diffusionpriors. Advances in Neural Information ProcessingSystems, 36. Jingyuan Sun, Mingxiao Li, Zijiao Chen, Yunhao Zhang,Shaonan Wang, and Marie-Francine Moens. 2024.Contrast, attend and diffuse to decode high-resolutionimages from brain activities. Advances in NeuralInformation Processing Systems, 36. Yu Takagi and Shinji Nishimoto. 2023. High-resolutionimage reconstruction with latent diffusion modelsfrom human brain activity. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pat-tern Recognition, pages 1445314463. Ramakrishna Vedantam, C Lawrence Zitnick, and DeviParikh. 2015. Cider: Consensus-based image de-scription evaluation. In Proceedings of the IEEEconference on computer vision and pattern recogni-tion, pages 45664575. Weihao Xia, Raoul de Charette, Cengiz Oztireli, andJing-Hao Xue. 2024. Dream: Visual decoding fromreversing human visual system. In Proceedings ofthe IEEE/CVF Winter Conference on Applications ofComputer Vision, pages 82268235.",
  "A.1Brain Decoding of Visual Stimuli": "Brain decoding aims to interpret neural activity pat-terns and link them to perceptual, cognitive, or mo-tor processes. Recent advancements in neuroimag-ing technologies, particularly functional magneticresonance imaging (fMRI), significantly enhanceour ability to decode visual stimuli. (Haxby et al.,2001) make groundbreaking progress in this fieldby revealing how the ventral temporal cortex en-codes different categories of visual objects. (Kami-tani and Tong, 2005) use multivoxel pattern analy-sis (MVPA) to classify the direction of visual stim-uli based on brain activity. Building on this earlywork, researchers explore various brain decodingtasks, such as stimulus classification and recon-struction. Stimulus classification involves categorizing dif-ferent types of visual stimuli based on brain activ-ity. (Yargholi and Hossein-Zadeh, 2016) utilize anenhanced Naive Bayes classifier to decode hand-written digits from fMRI data. The current focusin brain decoding shifts more towards image recon-struction. Early image reconstruction techniquesuse linear regression models to map fMRI signalsto given image features (Naselaris et al., 2009; Kayet al., 2008). With the advancement of deep learn-ing technologies, more image reconstruction meth-ods now employ Latent Diffusion Models (LDM)with image generation capabilities, achieving high-quality reconstruction results (Scotti et al., 2024;Ozcelik and VanRullen, 2023; Sun et al., 2024).Additionally, describing the content of images seenby subjects from brain signals can be viewed as aform of reconstructionsemantic reconstructionof images. (Chen et al., 2023) use cross-attentionand GPT-2 to accomplish semantic reconstructiontasks.Besides the reconstruction of static visual stim-uli, some researchers also tackle the reconstructionof continuous visual stimuli. The low temporalresolution of fMRI makes this task particularlychallenging. (Chen et al., 2024) use contrastivelearning to map fMRI to the CLIP representationspace, fine-tuning Stable Diffusion on a video-textdataset to successfully reconstruct coherent videoswith clear semantic information.",
  "A.2Tracking Visual Memory through BrainActivity Patterns": "Research on visual memory trajectories focuses ondecoding and tracking the storage and recall pro-cesses of visual stimuli in memory through brainactivity patterns. This area of study not only en-hances our understanding of how visual informa-tion is encoded and stored in the brain but also re-veals the dynamic changes during memory retrieval.(Davis et al., 2021) employ fMRI and item-wiseRSA to investigate how memory representationsgenerated during the encoding of individual itemsinfluence subsequent contextual memory. (Luoand Collins, 2023) utilize electroencephalography(EEG) recordings and RSA analysis to explore theneural basis of sequential dependency in visualperception. Their findings indicate that EEG sig-nals retain information about previously seen ob-jects, which affects current perceptual responses.(Fafrowicz et al., 2023) use fMRI and IndependentComponent Analysis (ICA) to study the formation",
  "BSimilarity Analysis of Current and PastBrain Activity Signals": "Since fMRI indirectly measures neural activity inthe brain by detecting BOLD signals, and changesin blood oxygen levels and blood flow occur grad-ually and continuously, fMRI data also exhibit acertain level of continuity. We alse use trial-wiseRSA to explore the correlation between brain ac-tivities at different times. Specifically, we replaceRDMc in (c) with RDMf, starting fromk = 1 (since k = 0 represents the correlation be-tween the current time and the current brain signal,which is always 1), keeping the rest of the opera- CIDEr(%)METEOR(%)SPICE(%)"
}