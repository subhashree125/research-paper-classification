{
  "Abstract": "Social networks are full of noise and mislead-ing information, which poses a pressing andcomplex challenge for rumor detection. In thispaper, we propose the Intent-Aware Rumor De-tection Network (IRDNet), designed to addressthe challenges of subjectivity, robustness, andconsistency in existing models. IRDNet uses amulti-task learning framework that integratesrumor detection and latent intent mining, whichcan discern multi-level semantic features andpotential user intentions. In IRDNet, the multi-level semantic extraction module extracts se-quential and hierarchical features to producerobust semantic representations. The intent-aware hierarchical contrastive learning mod-ule introduces two complementary strategies,event-level and intent-level. Event-level con-trastive learning uses high-quality data augmen-tation and adversarial perturbations to enhancethe robustness and consistency of the model.Intent-level contrastive learning utilizes an in-tent encoder to capture subjective intent andoptimize homogeneity within the same intentwhile ensuring heterogeneity between differentintents, thereby clearly distinguishing criticalfeatures from irrelevant elements. Experimen-tal results verify that the model significantlyimproves the effect of early rumor detectionand effectively solves the essential problems ofthe existing rumor detection field.",
  "Introduction": "The contemporary era of social networks witnessesunprecedented information dissemination, whichconcurrently leads to an accelerated spread of ru-mors. The complexity of this social phenomenonpresents significant challenges in rumor detection(Gao et al., 2022). Fundamentally, the belief inrumors is contingent upon two criteria: \"able tobelieve\" and \"willing to believe\". The former in-volves the diversity of information in social net-",
  "** Corresponding author": ": The results of traditional data augmentationmethods are similar in semantic structures but inconsis-tent with the intentions of the information disseminator,while data augmentation based on large language mod-els has been proven to be effective. works and the difficulty of distinguishing its au-thenticity(Nickerson, 1998). The latter willingto believe means that during the communicationprocess, under the influence of subjectivity, indi-viduals rely on previous knowledge and experienceas cognitive anchors to evaluate the authenticityof new information. This phenomenon, commonlycalled the anchoring effect(Tversky and Kahneman,1974), assumes particular prominence in the propa-gation of rumors, as content aligned with individu-als existing cognition augments its dissemination.Therefore, rumor detection is not only a check oncontent authenticity but also a complex task in-volving human cognitive alignment. Similar to theidea of anchoring effect, contrastive learning (CL)emphasizes using known data as \"anchors\" in theprocess of information evaluation and generalizingit to new and unfamiliar data, which can be used tomodel the process of cognitive subjectivity. How-ever, existing methods rely on the assumption thatpairs of augmented data from the same sentenceare semantically similar. As shown in the figure 1, this may cause contrastive learning to introducepotential noise or data that contradicts the intentionof the information disseminator, ultimately leadingto poor performance(Li et al., 2023). Traditionalrumor detection methods often ignore the true in-tentions of information disseminators, rarely con-sider the importance of personal subjectivity, andhave difficulty effectively capturing and aligningthese implicit intentions. Moreover, distinguishingkey features from irrelevant noise in text repre-sentation in noisy environments is a considerablechallenge. Many methods have limited adaptabilityto the noisy social network environment, makingit difficult to deal with the diversity of informationeffectively.Inspired by this, we propose the Intent-AwareRumor Detection Network (IRDNet), which de-signs a new contrastive learning method targetinghuman subjectivity, model robustness, and consis-tency of key features, and constructs cognitive an-chors to mine the potential intentions of informa-tion disseminators. It includes the following keycomponents:In Semantic Feature Extraction Module, we de-sign a semantic extractor that employs pre-trainedmodels to enhance the models semantic and con-textual relevance handling. Additionally, it com-bines BiLSTM and capsule networks to achieve se-quential and hierarchical feature learning, strength-ening the models ability to capture deep semanticfeatures.In Intent-aware Hierarchical Contrastive Learn-ing Module, cognitive anchors are mainly imple-mented through two levels of contrastive learning:event-level contrastive learning and intent-levelcontrastive learning.In event-level contrastivelearning, we combine adversarial training tech-niques to build high-quality data augmented repre-sentations to enhance the robustness of the model.In intent-level contrastive learning, by buildingintent-aware pairs and leveraging intent-level con-trastive learning, it can separate individual intentsand capture the main intent in a fine-grained man-ner while ensuring intent consistency.In general, the main contributions of this paperare as follows: Aiming at the complex aspects of personalsubjectivity, robustness and consistency in ru-mor detection, we design a multi-task learningframework that combines rumor detection andlatent intent mining as key tasks by jointly op-",
  "timizing self-supervised loss and supervisedloss": "We propose intent-aware hierarchical con-trastive learning, which includes two com-plementary strategies: event-level and intent-level contrastive learning. It aims to modelcognitive subjectivity through contrastivelearning, enhance the robustness and consis-tency of model representation, and addressexisting challenges in rumor detection. We evaluate the proposed method using tworeal-world datasets and compare it with base-line methods. Experimental results verify theeffectiveness of our method and demonstrateits significant advantages in early rumor de-tection tasks.",
  "Related Work": "Previous rumor detection methods primarily reliedon feature engineering techniques to extract fea-tures from existing rumor instances (Horne andAdali, 2017; Castillo et al., 2011; Yang et al., 2012;Potthast et al., 2017; Wang, 2017). These studiesfocused on utilizing features such as post content,user profiles, and propagation patterns to train su-pervised classifiers. However, the effectiveness ofthis approach heavily depended on the quality offeature engineering, leading to potential issues withmodel generalization across diverse datasets.Deep learning focuses on extracting deep keyfeatures, such as using recurrent neural networks(Ma et al., 2016; Asghar et al., 2021) and convolu-tional neural networks (Ajao et al., 2018; Liu andWu, 2018; Yu et al., 2017) to extract important in-formation from text content. In addition, capsulenetworks have been used to address the limitationsof CNN (Zhao et al., 2018; Ren and Lu, 2022; Yanget al., 2023). Capsule networks use a dynamic rout-ing mechanism to replace the maximum poolingoperation of CNN to retain spatial information andcapture key patterns in text. (Sabour et al., 2017;Mazzia et al., 2021). In recent advancements, graphneural network models have been employed to ex-ploit valuable features from content semantics andpropagation structures. These models encode con-versation threads by modeling propagation trees(Ma et al., 2018b; Wu et al., 2015; Yang et al.,2024) and propagation graphs (Wei et al., 2022;Bian et al., 2020; Lin et al., 2021), resulting inhigher-level representations. Nevertheless, when data is limited in the early stages of rumor propaga-tion, the above methods may not fully exploit theiradvantages(Hedderich et al., 2020).Contrastive learning (CL) can alleviate the prob-lem of data scarcity, especially by improving dataquality and utilizing limited labeled data, and hasgradually been applied to rumor detection(Lin et al.,2022; Xu et al., 2023; Gao et al., 2023; Cui and Jia,2024). In addition, multi-task learning (MTL) is astrategy that improves the generalization ability ofthe model by leveraging the shared knowledge be-tween multiple interrelated tasks(Caruana, 1997),which has also been widely explored and used inthe field of rumor detection(Zhang et al., 2021;Zhang and Gao, 2024). Early studies(Kochkinaet al., 2018; Ma et al., 2018a) mainly emphasizeshared features and improve the effectiveness of ru-mor detection by promoting feature interactions be-tween different tasks. Recent studies(Khandelwal,2021; Yang et al., 2022; Ma et al., 2024) simul-taneously consider related tasks, such as rumordetection and stance detection, to understand thetext more comprehensively. Some studies (Cuiand Yang, 2022; Zhou et al., 2022; Li et al., 2024)also attempt to apply MTL in multimodal environ-ments, fusing multiple information sources suchas text, images, or audio, aiming to more effec-tively capture the multidimensional properties ofrumor propagation, thereby improving the overallperformance of rumor detection.",
  "Problem Statement": "In the task of rumor detection, we define a series ofevents in the datasets, E = {E1, E2, E3, ..., Em}.Each event Ei is linked to a source tweet si and allassociated comment contents, denoted as Ei ={si, x1, x2, ..., xn}, where si can also be repre-sented as x0, and n represents the number of rele-vant comments in the discussion thread. The taskgoal is to build a robust rumor detection classifierby fully mining and learning the critical featurerepresentations of rumor-related events on socialnetworks, which can be expressed as f : Ei Yi,where Yi belongs to the categories of non-rumor,false rumor, true rumor, and unverified.",
  "Semantic Feature Extraction Module": "In this module, we use BERTweet (Nguyen et al.,2020) as a semantic extractor, a language modelpre-trained on a large-scale tweet corpus to en-hance semantic and contextual processing capabili-ties. We further incorporate BiLSTM and CapsuleNetworks into our model to facilitate multi-levelsemantic extraction, thereby capturing critical text-based information more comprehensively.We input the text sequence si into the semanticextractor, producing the output ei Rsd, wheres denotes the sequence length. Subsequently, BiL-STM conducts sequential feature extraction to gen-erate hidden state representations.",
  "Intent-aware Hierarchical ContrastiveLearning Module": "In this section, we develop two complementary con-trastive learning strategies: event-level contrastivelearning and intent-level contrastive learning, aim-ing to enhance the models ability to handle datanoise in social networks and to understand the sub-jective intent of information disseminators. Asshown in , these strategies help the modelobtain key contextual semantic information and fur-ther improve its ability to distinguish current noise.",
  ": Details of two contrastive learning in intention-aware hierarchical contrastive learning": "tent, demonstrating excellent performance in nat-ural language processing tasks (Feng et al., 2023).To effectively guide the generation process, we uti-lize task prompts designed by Yang et al. (2023).For each tweets semantic representation ei, wherecan also be expressed as e0i , two augmented sen-tences e1i , e2i are generated using ChatGPT-baseddata augmentation.",
  "ri = sign(L(f(ei), yi))(6)": "where r is the perturbation, represents the distur-bance amplitude, f represents the classifier withparameters and yi is the label.Event-Level Contrastive Learning: We constructtraining pairs to ensure that adversarial samplesare close to original samples in vector space, sothat the model can learn representations that areinsensitive to noise, thereby improving robustnessand generalization capabilities. Specifically, eachsentence ei {e0i , e1i , e2i } generates its adversarialexample ei {e0i , e1i , e2i } . The positive pairs areformed as {(ei, ei) | i batch}. The negativepairs include {(ei, ej) | i = j, j N(i)}, whereN(i) represents the set of negative samples forei. Then the event-level contrastive loss Levent isformulated as follows:",
  ": end for": "4.2.2Intent-Level Contrastive LearningIn this module, we design an intent encoder to ob-tain different intent representations by putting theoriginal data and perturbation data into the intentencoder to capture the subjective intent of infor-mation disseminators in social networks. Throughcontrastive learning at the intent level, we can bringthe positive samples closer and ensure that the aug-mented data and perturbation data maintain theconsistency of the original intent.Intent Matrix: To better comprehend the mul-tiple meanings and latent motivations within thetext, we introduce a parameter matrix ci={c1i , c2i , . . . , cKi }, where K represents the numberof latent intentions. This matrix can adaptively rep-resent different latent intentions to deeply explorethe multidimensional subjective value superposi-tion process of information disseminators.Saliency Weight: As a metric for assessing theimportance of tweet content, it provides crucialclues for subsequent intention analysis and aids inreducing the impact of noise and irrelevant infor-mation. A non-linear transformation is introducedto enhance the models expressive power, which iscrucial for understanding and representing complexstructures in the text. The calculation formula forSaliency Weight is as follows:",
  "(10)": "where ei represents the embedding representationof text sequence xi through the semantic extractor.Intent Score: This metric measures the relevanceof a tweet to different latent intentions. Specifically,for each intention, the score reflects the extent ofassociation between the tweet and the intention. Alow association with all intentions might be con-sidered noise or an intention not yet learned by themodel. To determine the likelihood of a text eibeing related to the k-th latent intention:",
  "Dataset and Experimental Setup": "In this study, we use two public datasets in the fieldof rumor detection, Twitter15 and Twitter16 (Maet al., 2017), covering four categories: true rumors(T), false rumors (F), unverified rumors (U), andnon-rumors (N).We conducted experiments on NVIDIA TeslaV100 GPU using the PyTorch framework with thefollowing configuration: batch size set to 64 and aninitial learning rate of 1e-5. To control the complex-ity of the model, we introduce an L2 regularizationterm with a weight attenuation coefficient of 0.001.To avoid overfitting, we implemented an early stop-ping strategy (Yao et al., 2007). We divided thedataset throughout the experiment into 70% train-ing, 20% validation, and 10% testing. The detailedmodel parameter settings and hyperparameter sen-sitivity analysis are in Appendix B.",
  "Baselines": "We compare IRDNet with different baseline mod-els, including content-based, structure-based, andcontrastive learning-based methods:(1) GRU-RNN (Ma et al., 2016): This modelemploys a Recurrent Neural Network (RNN) forevent classification, distinguishing between rumorsand non-rumors.(2) dEFEND (Shu et al., 2019): The dEFENDmodel employs attention mechanisms to capturesemantic correlations between the source tweet con-tent and user comments for rumor detection.(3) RvNN (Ma et al., 2018b): The RvNN modelcaptures the structure features within the propa-gation tree using a Recursive Neural Network forrumor detection.(4) BiGCN (Bian et al., 2020): The BiGCNmodel captures the structural features of rumorpropagation by constructing a bidirectional graphstructure and leveraging a graph convolutional net-work (GCN).(5) TextGCN (Yao et al., 2019): The TextGCNmodel utilizes graph convolutional network modelsto learn text representations for text classificationtasks.(6) CICAN (Yang et al., 2023): The CICANmodel captures multiple semantic content featuresand different semantic structure features in text forrumor detection.(7) GACL (Sun et al., 2022): The GACL modelincorporates graph-based adversarial contrastivelearning, utilizing rumor propagation structure in-formation for rumor detection.(8) RAGCL (Cui and Jia, 2024): The RAGCLmodel utilizes graph contrastive learning with adap-tive view augmentation guided by node centralities.",
  "Experimental Results": "In this section, we discuss the comparative anal-ysis of the performance of our proposed IRDNetmodel against other methods, as summarized in. The IRDNet model delivers significantperformance improvements on the Twitter15 andTwitter16 datasets, achieving 91.7% and 90.9% ac-curacy, respectively.Content-based models, such as GRU-RNN anddEFEND, employ deep learning methods to con-sider the relationship between reviews and the orig-inal text, such as the attention mechanism and therecurrent neural network (RNN). However, thesemodels often overlook extracting deep semantic",
  ": Rumor detection results on Twitter15 and Twitter16 datasets": "features, resulting in relatively subpar performance.In contrast, IRDNet incorporates a multi-level se-mantic extraction module, enabling it to captureglobal-local relationships effectively.Structure-based models, TextGCN, CICAN, andBiGCN, outperform RvNN due to their superior ca-pability to model the complex relationships amongstructure features. However, these structure-basedmodels exhibit lower robustness and are more vul-nerable to malicious user attacks, leading to mis-leading results and consequently impacting the ac-curacy of rumor detection.CL-based models, GACL, RAGCL and IRD-Net, exhibit significant performance improvementattributable to two pivotal factors. Firstly, con-trastive learning enhances the models robustness,making it more resistant to malicious attacks. Sec-ondly, contrastive learning effectively highlightsthe commonalities within the same category anddifferences across distinct categories by provid-ing rich self-supervised signals, thereby enrichingthe model training process. In contrast, the IRD-Net model utilizes hierarchical contrastive learn-ing, including event-level and intent-level strate-gies. Event-level contrastive learning improves ro-bustness by using adversarial training to make themodel resistant to noise. Intent-level contrastivelearning can capture user intent and keep the de-tected rumors consistent even in noisy data.",
  "We conducted a series of ablation studies to eval-uate the contribution of each component in theIRDNet model. The specific configurations areas follows:(1) W/o BERTweet: The BERTweet component": "in the Semantic Feature Extraction Module is re-placed by the standard BERT.(2) W/o Cap: The Capsule Network componentin the Semantic Feature Extraction Module is re-moved.(3) W/o BiLSTM: The BiLSTM componentin the Semantic Feature Extraction Module is re-moved.(4) W/o IHCLM: The Intent-aware HierarchicalContrastive Learning Module is removed from themodel.(5) W/o ECL: The Event-level ContrastiveLearning component in the Intent-aware Hierar-chical Contrastive Learning Module is removed.(6) W/o ICL: The intent-level contrastive learn-ing component in the Intent-aware HierarchicalContrastive Learning Module is removed.",
  ": Early rumor detection experimental results with different number of comments (a, b) and different trainingratios (c, d)": "managing contextual relevance, while the Capsulenetwork and BiLSTM contribute to multidimen-sional feature extraction, aggregation of input in-formation from diverse perspectives, and captureof high-level semantic information. Removing theintention-level contrastive learning module (W/oIHCLM) resulted in a decrease in accuracy of 2.7%and 3.2%, highlighting the important role of thismodule in improving the models adaptability tonoisy data and its ability to capture semantic consis-tency. In contrastive learning strategies, removingevent-level contrastive learning (W/o ECL) andintent-level contrastive learning (W/o ICL) bothresulted in varying degrees of decreased accuracy.It is proven that by utilizing a multi-level, fine-grained contrastive learning strategy, the modelsrobustness to noisy data is improved, and its abilityto capture and understand the subjective intentionsof information disseminators is also significantlyenhanced.",
  "Early Rumor Detection": "Timely identification and mitigation are crucial forrumor detection. As shown in , we uti-lize two methods to evaluate the models early ru-mor detection performance. First, we evaluate theperformance of the model when the number ofcomments gradually increases. The IRDNet modelshows good accuracy even in the early stage withlimited comments. This is attributed to the efficientextraction of semantic features and the advantagesof event-level contrastive learning with adversarialtraining. Although the semantic noise increasesas more information spreads in social networks,the IRDNet model always maintains excellent per-formance, highlighting its strong generalizationability.Another method is to precisely change the ratio of the training dataset (0.1, 0.3, 0.5, 0.7), whilefixing the validation ratio at 0.2 and the rest isallocated to the test set. Intent-level contrastivelearning, by emphasizing the commonality betweenintent categories and the distinction between differ-ent intent categories, obtains more context-relatedsemantic information from intent features, furtherimproving our ability to distinguish current noiseterms. Models based on graph neural networks(BiGCN and TextGCN) perform poorly, especiallyin scenarios with limited training data. When thetraining ratio is 0.1, our model shows a significantaccuracy improvement of 10% to 30% comparedwith other models, demonstrating the superiorityof our method.",
  "Conclusion and Future Work": "This paper proposes an intent-aware rumor detec-tion network (IRDNet) that combines supervisedsemantic feature extraction with self-supervisedintent-aware hierarchical contrastive learning ina multi-task framework to address the challengesof subjectivity, robustness, and consistency in thecurrent field. It contains two modules: the seman-tic feature extraction module captures multi-levelsemantic information and enhances the modelsability to understand context. The intent-aware hi-erarchical contrastive learning module introducestwo strategies: event-level contrastive learning en-hances robustness through data augmentation andadversarial training, and intent-level contrastivelearning captures subjective intent features by de-signing an intent encoder, ensuring intent consis-tency and improving feature discrimination whilemaintaining robustness. Experimental results showthat IRDNet performs better noise resistance andcritical feature capture than baseline methods incomparative experiments and early rumor detec- tion.Future research will focus on the following twoaspects. First, the proposed contrastive learningapproach will be extended to a broader range ofclassification tasks to verify its generality and effec-tiveness in diverse tasks, expanding its applicability.Second, efforts will focus on addressing the currentlimitations of large language models (LLMs) in ru-mor detection. Specifically, we will work towardsenhancing the robustness and detection accuracyof LLMs in dynamic misinformation environments,while also ensuring higher reliability and consis-tency in rumor detection tasks.",
  "Limitations": "Despite the progress made with the Intent-AwareRumor Detection Network (IRDNet), some limita-tions still exist:Computational Complexity:The multi-tasklearning strategy integrating language model andcontrastive learning increases the computationalcomplexity and resource requirements of IRDNet.Although negative sampling and parameter freez-ing are employed to reduce complexity, real-timedeployment and scalability in environments withlimited computing resources may still present chal-lenges.Generality in Multilingual Environments: IRD-Nets current training and evaluation focus primar-ily on English datasets. Its effectiveness and robust-ness in multilingual environments or non-Englishsocial media platforms have yet to be thoroughlyevaluated. Future research will explore other lan-guages and cross-language applications to improvethe models performance across diverse linguisticcontexts.",
  "Ethical Statement": "This study aims to advance the understanding ofrumor detection and promote the advancement ofsocial media and information dissemination. Wesolemnly promise to abide by ethical principlesthroughout the research process, protect the rightsof data participants, and ensure compliance withand transparency regarding data use. Malak Abdullah, Alia Madain, and Yaser Jararweh.2022. Chatgpt: Fundamentals, applications and so-cial impacts. In 2022 Ninth International Conferenceon Social Networks Analysis, Management and Secu-rity (SNAMS), pages 18. IEEE. Oluwaseun Ajao, Deepayan Bhowmik, and ShahrzadZargari. 2018. Fake news identification on twitterwith hybrid cnn and rnn models. In Proceedings ofthe 9th international conference on social media andsociety, pages 226230. Muhammad Zubair Asghar, Ammara Habib, AnamHabib, Adil Khan, Rehman Ali, and Asad Khattak.2021. Exploring deep neural networks for rumordetection. Journal of Ambient Intelligence and Hu-manized Computing, 12:43154333. Tian Bian, Xi Xiao, Tingyang Xu, Peilin Zhao, Wen-bing Huang, Yu Rong, and Junzhou Huang. 2020.Rumor detection on social media with bi-directionalgraph convolutional networks. In Proceedings of theAAAI conference on artificial intelligence, volume 34,pages 549556.",
  "Yuan Gao, Xiang Wang, Xiangnan He, Huamin Feng,and Yongdong Zhang. 2023. Rumor detection withself-supervised learning on texts and social graph.Frontiers of Computer Science, 17(4):174611": "Michael A Hedderich, Lukas Lange, Heike Adel, Jan-nik Strtgen, and Dietrich Klakow. 2020. A sur-vey on recent approaches for natural language pro-cessing in low-resource scenarios. arXiv preprintarXiv:2010.12309. Benjamin Horne and Sibel Adali. 2017. This just in:Fake news packs a lot in title, uses simpler, repetitivecontent in text body, more similar to satire than realnews. In Proceedings of the international AAAI con-ference on web and social media, volume 11, pages759766.",
  "Jun Li, Yi Bin, Liang Peng, Yang Yang, Yangyang Li,Hao Jin, and Zi Huang. 2024. Focusing on relevantresponses for multi-modal rumor detection. IEEETransactions on Knowledge and Data Engineering": "Xuewei Li, Aitong Sun, Mankun Zhao, Jian Yu, KunZhu, Di Jin, Mei Yu, and Ruiguo Yu. 2023. Multi-intention oriented contrastive learning for sequentialrecommendation. In Proceedings of the SixteenthACM International Conference on Web Search andData Mining, pages 411419. Hongzhan Lin, Jing Ma, Liangliang Chen, Zhiwei Yang,Mingfei Cheng, and Guang Chen. 2022. Detect ru-mors in microblog posts for low-resource domainsvia adversarial contrastive learning. arXiv preprintarXiv:2204.08143. Hongzhan Lin, Jing Ma, Mingfei Cheng, Zhiwei Yang,Liangliang Chen, and Guang Chen. 2021.Ru-mor detection on twitter with claim-guided hier-archical graph attention networks. arXiv preprintarXiv:2110.04522. Yang Liu and Yi-Fang Wu. 2018. Early detection offake news on social media through propagation pathclassification with recurrent and convolutional net-works. In Proceedings of the AAAI conference onartificial intelligence, volume 32.",
  "Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton.2017. Dynamic routing between capsules. Advancesin neural information processing systems, 30": "Kai Shu, Limeng Cui, Suhang Wang, Dongwon Lee,and Huan Liu. 2019. defend: Explainable fake newsdetection. In Proceedings of the 25th ACM SIGKDDinternational conference on knowledge discovery &data mining, pages 395405. Tiening Sun, Zhong Qian, Sujun Dong, Peifeng Li, andQiaoming Zhu. 2022. Rumor detection on socialmedia with graph adversarial contrastive learning. InProceedings of the ACM Web Conference 2022, pages27892797.",
  "Ke Wu, Song Yang, and Kenny Q Zhu. 2015. Falserumors detection on sina weibo by propagation struc-tures. In 2015 IEEE 31st international conference ondata engineering, pages 651662. IEEE": "Yingrui Xu, Jingyuan Hu, Jingguo Ge, Yulei Wu, TongLi, and Hui Li. 2023. Contrastive learning at the rela-tion and event level for rumor detection. In ICASSP2023-2023 IEEE International Conference on Acous-tics, Speech and Signal Processing (ICASSP), pages15. IEEE. Chang Yang, Xia Yu, JiaYi Wu, BoZhen Zhang, andHaiBo Yang. 2024. Graph-aware multi-feature inter-acting network for explainable rumor detection onsocial network. Expert Systems with Applications,249:123687.",
  "Fan Yang, Yang Liu, Xiaohui Yu, and Min Yang. 2012.Automatic detection of rumor on sina weibo. In Pro-ceedings of the ACM SIGKDD workshop on miningdata semantics, pages 17": "Peng Yang, Juncheng Leng, Guangzhen Zhao, Wen-jun Li, and Haisheng Fang. 2023. Rumor detectiondriven by graph attention capsule network on dy-namic propagation structures. The Journal of Super-computing, 79(5):52015222. Ruichao Yang, Jing Ma, Hongzhan Lin, and Wei Gao.2022. A weakly supervised propagation model forrumor verification and stance detection with multipleinstance learning. In Proceedings of the 45th Inter-national ACM SIGIR Conference on Research andDevelopment in Information Retrieval, pages 17611772.",
  "AModel Optimization: Classificationwith Alternating Normalization": "We employ the Classification with Alternating Nor-malization (CAN) (Jia et al., 2021) to enhance theprediction accuracy of low-confidence samples andensure the average of all probability distributionsaligns with the prior distribution (can be estimateddirectly from the training dataset). This methodquantifies the ambiguity of the predicted class prob-ability distribution, uses a threshold to distinguishhigh-confidence and low-confidence samples, andapplies alternating normalization to rescale predic-tions for low-confidence instances, i.e., alternatelynormalizing across samples in each category andacross categories in each sample. The measure ofuncertainty in the prediction result, Htop-k, utilizesthe top-k probability values to compute the entropyas follows:",
  "i=1pi,": "and 1/log k is to limit the final indicator value to.Assuming there are N samples, among which nare high-confidence with probabilities p(1), ..., p(n).The low-confidence samples are then correctedagainst the high-confidence samples by alternatelynormalizing instances of each category and cate-gories of each instance. Specifically, for each low-confidence prediction p(j), j (n + 1, . . . , N),we perform normalization across instances for eachcategory together with the high-confidence predic-tion as follows:",
  "(17)": "Notably, this correction process adjusts eachsample independently, and the probability dis-tributions of both the high-confidence and low-confidence samples are updated. However, we ulti-mately keep the updated probability distribution asthe corrected result for the original low-confidencesamples.Next, we conducted an ablation experiment onCAN. As shown in 3, the experiment highlightsthe beneficial effect of decisions based on priorknowledge of model generalization capabilities.",
  "B.0.1Model Experimental Configuration": "In the semantic feature extraction module, the hid-den size of the BERTweet layer is set to 768 inbertweet-base and 1024 in bertweet-large, withweights frozen to prevent overfitting. We experi-mented with both bertweet-base and bertweet-largemodels1 and found that bertweet-large performedbetter. The BiLSTM layer consists of 256 hiddenunits. The size of the convolutional kernels (k) is{2, 3, 4}. The number of convolutional kernels(k_num) is fixed at 256. The higher-level capsulelayer contains 4 capsules (cin). The output dimen-sion of each capsule (cdim) is set to 50. Dynamicrouting is performed for 3 iterations (r = 3) toaggregate capsule outputs effectively.In the intent-aware hierarchical contrastive learn-ing module, we implement event-level and intent-level contrastive learning.For event-level con-trastive learning, we use a perturbation magnitude = 0.001 to generate adversarial examples, withnegative samples N(i) = 5 per positive pair to ensure robust learning. For intent-level contrastivelearning, the intent encoder is configured withK = 4 latent intentions, each represented by a64 dimensional vector and 10 negative samples perpositive pair.During training, we use the cross-entropy lossfunction to measure the discrepancy between pre-dicted results and true labels, combined with theevent-level and intent-level contrastive loss func-tions, weighted by a hyperparameter (). An earlystopping strategy with a patience of 10 epochs pre-vents overfitting and ensures generalizability.",
  "B.0.2Hyperparameter Sensitivity Analysis": "We present the impact of crucial hyperparameterson our experiments, including the number of inten-tions (k) and CL weight parameter ().Number of Intentions (k)The number of intents (k) is key to intent-levelcontrastive Learning. illustrates the im-pact of different numbers of intents on the twodatasets, Twitter15 and Twitter16. When k = 1,the models performance is subpar. As k increases,the models performance improves significantly,reaching an optimal performance at k = 4. Thissuggests that employing multiple intentions bettercaptures the semantics and information embeddedin the text.However, performance degrades as the numberof intents increases (i.e., k > 4). This degradationcan be attributed to the intent decomposition beingtoo fine-grained, and the information fragmenta-tion is severe, which limits the models expressivepower.Interestingly, there is a trend of slightly im-proved performance in k = 20. This suggeststhat additional intents may still capture some use-ful semantic variation, albeit with diminishing re-turns. However, given the increased computationalcomplexity and potential overfitting risk associatedwith higher k values, we set k = 4 as the optimalnumber of intents.CL Weight Parameter ()Within the loss function, the weight parame-ter () that controls the contrastive learning (CL)loss is another key hyperparameter. We note that = 0.05 yields the optimal performance on theTwitter16 dataset, and = 0.01 is optimal forthe Twitter15 dataset. However, the models per-formance deteriorates when exceeds its optimalvalue. This phenomenon arises because an elevatedweight on the contrastive loss can compromise the",
  ": The impact of introducing perturbed samplesin event-level contrastive learning on model robustness": "The heatmap indicates that the categories arefrequently misclassified as \"unverified (3)\" afterminor perturbations. This phenomenon can be at-tributed to the models sensitivity to minor pertur-bations, where the adversarially generated samplesmay attenuate the critical features that originallydistinguished these categories. Consequently, themodel fails to effectively capture the core seman-tic features of the original categories, making itmore likely to classify ambiguous information asbelonging to an uncertain category, indicating thatthe model demonstrates insufficient robustness and contextual comprehension when confronted withsemantic ambiguity. This behavior also aligns withhuman cognitive tendencies where slight shifts inwording or tone can provoke doubt, especially inthe absence of clear evidence or authoritative sup-port. Even if the information itself is accurate, if itsdescription becomes ambiguous, individuals maylean towards considering it as unverified."
}