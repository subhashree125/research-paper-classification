{
  "Abstract": "Language Language Models (LLMs) facesafety concerns due to potential misuse by ma-licious users. Recent red-teaming efforts haveidentified adversarial suffixes capable of jail-breaking LLMs using the gradient-based searchalgorithm Greedy Coordinate Gradient (GCG).However, GCG struggles with computationalinefficiency, limiting further investigations re-garding suffix transferability and scalabilityacross models and data. In this work, we bridgethe connection between search efficiency andsuffix transferability. We propose a two-stagetransfer learning framework, DeGCG, whichdecouples the search process into behavior-agnostic pre-searching and behavior-relevantpost-searching. Specifically, we employ directfirst target token optimization in pre-searchingto facilitate the search process.We applyour approach to cross-model, cross-data, andself-transfer scenarios. Furthermore, we intro-duce an interleaved variant of our approach,i-DeGCG, which iteratively leverages self-transferability to accelerate the search process.Experiments on HarmBench demonstrate theefficiency of our approach across various mod-els and domains. Notably, our i-DeGCG out-performs the baseline on Llama2-chat-7b withASRs of 43.9 (+22.2) and 39.0 (+19.5) onvalid and test sets, respectively. Further analy-sis on cross-model transfer indicates the pivotalrole of first target token optimization in lever-aging suffix transferability for efficient search-ing1.",
  "Steps": "0.0 2.5 5.0 7.5 10.0 12.5 15.0 17.5 CE Loss Token Position 1Token Position 2Token Position 4Token Position 8 : GCG Training Dynamics of Cross EntropyLoss for tokens located at different positions in the tar-get sequence. We plot the changes in cross-entropy lossof target tokens at positions every 100 steps.This discrepancy in loss dynamics highlights the impor-tance of first token optimization in GCG. to produce harmful and ethically problematic re-sponses to user queries, which raises significantsafety issues. In response to these concerns, recentefforts have focused on aligning LLMs with hu-man preferences to enhance the responsibility andharmlessness of their responses (Bai et al., 2022;Ouyang et al., 2022; Korbak et al., 2023). De-spite these alignment efforts, LLMs still remainvulnerable to potential attacks (Wei et al., 2023).Recent studies have revealed various types of jail-break attacks (Wei et al., 2023; Albert, 2023; Kanget al., 2023; Lapid et al., 2023; Liu et al., 2023a),which involve using jailbreak prompts alongsidemalicious queries to compel aligned LLMs to gen-erate harmful and unethical responses, thereby cir-cumventing the safety alignment constraints. One notable attack, Greedy Coordinate Gradient(GCG) (Zou et al., 2023), utilizes gradient informa-tion to search for adversarial prompts, also knownas adversarial suffixes, which can be appendedto malicious queries to elicit harmful responses.These adversarial suffixes consist of random tokens and are generally not comprehensible to humans.However, deriving these suffixes through gradient-based searching is computationally inefficient. Theexponentially increasing search space of randomsuffixes with length expansion presents significantchallenges to search efficiency. Besides, the ran-dom initialization for each search is inefficient, in-curring additional but unnecessary searching costs.Recent work (Zou et al., 2023) suggests that theadversarial suffixes may possess universal transfer-ability across models, indicating that the previouslysearched suffix could serve as an effective initial-ization. Furthermore, Meade et al. (2024) finds thatmodels aligned through preference optimizationexhibit robustness against suffix transfer. Despitethese insights, prior works primarily focused ondirect transfer, which shows limited transferabilityacross different models or data domains. The po-tential for using adversarial suffixes as initializationfor transfer learning remains largely unexplored.In this work, motivated by the challenges in op-timizing the gradient-based search process witheffective initial adversarial suffixes, we explorehow to leverage the transferability of these suf-fixes during optimization. Our empirical investi-gation has identified the importance of optimizingthe first target token loss, as illustrated in .We attribute the inefficiency in searching to thecross-entropy optimization goal applied to the en-tire target sentence. To address this, we proposea two-stage transfer learning framework, DeGCG,which decouples the original search process intotwo stages: behavior-agnostic pre-searching andbehavior-relevant post-searching: In the pre-searching stage, we perform asimplified task, First-Token Searching (FTS),searching for adversarial suffixes with abehavior-agnostic target such as Sure, en-abling LLMs to elicit the first target tokenwithout refusal. In the post-searching stage, we start with thesuffix obtained from the pre-searching stageand conduct Content-Aware Searching (CAS)with a behavior-relevant target. This stagetransfers the behavior-agnostic initializationto behavior-relevant suffixes.",
  "We found that suffixes obtained through first-token searching can be effectively transferredacross different models and datasets with furthersearching.Additionally, we leverage the self-": "transferability of adversarial suffixes and proposean interleaved training algorithm, i-DeGCG, whichperforms FTS and CAS in an interleaved manner.We evaluate our proposed method on the Harm-Bench across various LLMs. Our experimentalresults demonstrate the effectiveness and efficiencyof the DeGCG framework and i-DeGCG variant,highlighting the success of suffix transfer throughtwo-stage learning and underscoring the impor-tance of initialization for search efficiency.",
  "Safety-Aligned LLMs": "LLMs have demonstrated impressive capabilitiesbut raised safety concerns about the potential formalicious usage. To mitigate these concerns, ef-forts have been made to supervised fine-tuning ofLLMs with instructions aimed at ensuring help-fulness and safety (Chung et al., 2022; Wei et al.,2021; Touvron et al., 2023), and align LLMs withhuman preference, known as Reinforcement Learn-ing from Human Feedback (RLHF) (Christianoet al., 2017; Ouyang et al., 2022; Korbak et al.,2023; Bai et al., 2022). RLHF involves trainingLLMs based on the rewards derived from modelsthat have been trained on human preference data.Recent studies show that models aligned by pref-erence optimization achieve improved robustnessagainst adversarial attacks compared with modelsby fine-tuning (Meade et al., 2024). Despite theefficacy of these alignment methods in promotinghelpfulness and safety, LLMs remain susceptibleto certain cases in which they still produce ma-licious responses under jailbreak attacks (Kanget al., 2023; Hazell, 2023; Albert, 2023). Our studymainly focuses on different safety-aligned modelsto explore the effectiveness of jailbreak attacks.",
  "Jailbreak Attacks on Aligned LLMs": "Existing red teaming has dedicated substantial ef-forts to identifying various jailbreak attacks. Ini-tial jailbreak attacks involve the manual craftingof input prompts. A notable instance is the Do-Anything-Now attack, which is implemented bycompelling LLMs to play a role that can do any-thing and respond to any query without refusal,thus bypassing safety constraints (Albert, 2023;Liu et al., 2023b). Subsequent advancements haveautomated the creation of these stealthy promptswith controllability (Liu et al., 2023a; Zhu et al.,2023; Guo et al., 2024). Additionally, adversarial",
  "Init Suffix/Suffix-CAS! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! ! !": ": Our DeGCG framework involves two main stages. In the pre-searching stage, we perform the first-tokensearching with LLM A on Behavior Set A. In the post-searching/fine-tuning stage, we perform content-awaresearching with LLM B on Behavior Set B. The Suffix-FTS obtained in the pre-searching serves as the initializationfor the post-searching. Cross-Data Transfer uses the same LLM but distinct sets, while Cross-Model Transferuses the same set but distinct LLMs. For Interleaved Self-Transfer, we use the same LLM and set but alternatingbetween FTS and CAS. prompts have been identified in GCG, which uti-lizes gradient information to automatically gener-ate effective adversarial prompts (Zou et al., 2023;Shin et al., 2020; Zhao et al., 2024). Furthermore,their results indicate the transferability and univer-sality of these adversarial prompts. Recent workhas also unveiled jailbreak attacks within the con-text of multilingual scenarios (Deng et al., 2023),and non-natural languages such as ciphers (Yuanet al., 2023), in-context learning (Qiang et al.,2023), highlighting the risk for all open-sourceLLMs with modified decoding strategies (Huanget al., 2023). Our work focuses on adversarial suf-fix transferring learning across aligned LLMs andassociates transferability with search efficiency.",
  "Preliminary": "In this section, we revisit the Greedy CoordinateGradient (GCG) attacks. Let X denote the mali-cious prompts, such as Tell me how to make abomb, the objective of the GCG attack is to findthe suffix S = {si}LSi=1 with length LS, so that byusing T = {X, S} = {t1, t2, ..., tn} as input, thevictim model can generate responses starting fromthe target sequence Y = {tn+1, tn+2, ..., tn+m}, such as Sure, here is how to make a bomb. Con-sequently, the joint target distribution is representedby p(tn+1:n+m|t1:n). The goal of searching for thetarget sequence can be formulated to minimize thefollowing negative log-likelihood:",
  "(1)": "GCG searches for adversarial suffixes throughmultiple iterations, adopting a greedy search strat-egy in each iteration. In one iteration, it selects thecandidate suffix with the lowest L from the batch{Si}Bi=1. To construct the candidate batch, it firstcomputes the negative gradient esiL with re-spect to the one-hot vector representation esi andselects tokens from the vocabulary with the top Kvalues of esiL, forming the token candidate setat each position. Then it uniformly replaces thetoken si at each position with random tokens fromthe obtained token candidate set, resulting in onesuffix candidate with one replacement.To optimize the adversarial suffixes using mul-tiple malicious prompts {X(j)}, the aggregatedgradient j esiL(X(j), S) and the aggregated",
  "DeGCG": "The challenge of the GCG attack is primarily as-sociated with the first-token optimization in .However, Eq.1 assigns equal importance to each tar-get token, regardless of varying levels of difficultyassociated with optimizing each one. The multi-objective optimization introduces noise into themore challenging first-token optimization process,where significant loss signals could be biased byother competitors, thereby reducing the efficiencyof the search.To address this issue, we propose decoupling thesearch process. Inspired by the popular pre-trainingand fine-tuning paradigm, we introduce a newframework, DeGCG, which separates the searchinto behavior-agnostic first-token pre-searching and behavior-relevant content-aware fine-tuning.In this framework, we link transfer learning withsearching efficiency. Our DeGCG tunes tokensin discrete space in a manner analogous to howparameters in continuous space are tuned duringthe pre-training and fine-tuning process. In thisanalogy, the counterpart of parameter space is thesearching space in DeGCG. An overview of ourmethod is presented in .",
  "log p(t(j)n+1|t(j)1:n)(2)": "In this task, the suffix is optimized based onthe gradient derived solely from the first target to-ken, resulting in a direct and efficient optimization.The first target token is typically behavior-agnostic,such as Sure or Here. Therefore, the obtainedsuffixes SFTS serve as a general initialization witha low cross-entropy loss for the first token. Start-ing the search from an effective initialization witha low first-token loss helps to mitigate the ineffi-ciency associated with starting each search from ahigh first-token loss, reducing the time and compu-tational resources accordingly.",
  "Context-Aware Searching": "Suffixes obtained from FTS are effective forbehavior-agnostic targets but fall short in elicitingbehavior-relevant responses. Therefore, we pro-pose to fine-tune the suffix in the pre-searchingstage by performing content-aware searching(CAS) with behavior-relevant targets, such as howto make a bomb. Given that this step builds uponthe success of FTS, we maintain the FTS target inthis step as well. Specifically, the goal for CAS isdefined as follows",
  "OpenChat-3.5DeGCG90.285.531.725.287.878.680.581.1": ": Performance comparison (ASR) in Cross-Model Transferring across four different models on both theValidation (Valid) and the Test sets. Model A and Model B refer to source models and target models respectively. To transfer the pre-searched suffix effectively,we explore three types of CAS:Cross-Data Transfer uses the pre-searched suffixas an initialization when the dataset in CAS dif-fers from the one in FTS. In this scenario, domain-specific data, such as chemical biology and cyber-crime, are utilized to fine-tune the pre-searchedsuffix with the content-aware target.Cross-Model Transfer employs the pre-searchedsuffix as an initialization when the LLM in CASdiffers from the one in FTS.Self-Transfer applies when FTS and CAS use thesame dataset and LLM. This is detailed in the fol-lowing .5.",
  "Interleaved Self-Transfer": "Leveraging the self-transferability of suffixes andenhance the efficiency of the search process, wepropose an interleaved variant of our approach, i-DeGCG. i-DeGCG integrates FTS and CAS as ameta-process and dynamically alternates betweenthem. Specifically, in each iteration, it uses the suf-fix obtained from FTS as the initialization for CASand then, conversely, uses the suffix from CAS asthe initialization for FTS. This approach maintainsa dynamic balance between generating the firsttoken and producing behavior-relevant responses.The iterative process allows continuous refinementof the suffix, leveraging the strength of both FTSand CAS for enhanced overall performance. Wesummarize the algorithm in Alg.1.",
  ") to compare our approach and the baseline.We use the text-only set which comprises threetypes of behaviors: Standard, Copyright, and Con-textual. Detailed statistics of HarmBench can be": "found in the appendix. In our experiments, we usevalidation and test splits provided by HarmBench.Specifically, we use the standard behavior subsetsof both validation and test sets. The validation setserves as the training set for searching suffixes, andwe evaluate performance on the test set. Implementation Details.We evaluate ourmethod on open-sourced models. Specifically, weutilize LLama2-chat (Touvron et al., 2023), Mistral-Instruct (Jiang et al., 2023), OpenChat-3.5 (Wanget al., 2023), and Starling-LM-alpha (Wang et al.,2023) in our experiments. Due to memory con-straints, we use 7b models for all experiments.For evaluation, we report the classifier-based at-tack success rate (ASR). We consider the baselineGCG-M from the HarmBench that uses GCG forsuffix searching with multiple behaviors. To en-sure reproducibility and fair comparison, we usethe open-source classifier provided in HarmBench.This classifier is a fine-tuned LLama2-13b model,which achieves strong performance on a manually-labeled validation set.",
  "Main Results": "Cross-Model Transferring.To evaluate the effi-cacy of suffixes trained through FTS on one modeltransferring to another model via token-level fine-tuning, we conduct cross-model transferring ex-periments across four open-source models. To en-sure a fair comparison, we maintain equal totalsearch steps (FTS + CAS) for all experiments, con-sistent with the baseline, totaling 500 steps. Wealso include the baseline GCG-T from HarmBenchthat optimizes suffixes against multiple models fortransferring. Our transfer performances on the vali-dation set and test set are presented in .Our proposed DeGCG approach significantlysurpasses the GCG-M across various models onboth validation and test sets. For example, DeGCG",
  ": Performance comparison (ASR) in Cross-Data Transferring across different behavior types in HarmBench.We report the results of LLama2-chat-7b on both the Validation and the Test sets": "achieves absolute improvements of 9.0 and 9.8 inASRs from Starling-LM to OpenChat-3.5 on vali-dation and test sets. This indicates that the suffixderived from FTS on one model proves to be an ef-fective initialization point for transferring to a newtarget model. Notably, despite differences in tok-enizers between source and target models, transferlearning from FTS through CAS still yields sig-nificant performance improvement. For instance,transferring suffix from Mistral-Instruct to Llama2-chat achieves absolute enhancements of 22.2 and9.4 in ASRs on validation and test sets, demon-strating the efficacy of DeGCG. Additionally, theDeGCG approach outperforms GCG-T on both val-idation and test sets. This further reveals that oursuffix transfer learning is more effective than thedirect transfer with suffix concatenations searchedon multiple models.Moreover, when the target model is identical tothe source model, the DeGCG method significantlyimproves ASR performance, achieving over 100%enhancement on LLama2-chat-7b. We attribute thisimprovement to the effective initialization providedby FTS on the same model, which facilitates amore efficient token fine-tuning process within afavorable neighbor area in the search space. Cross-Data Transferring.To evaluate the effec-tiveness of the DeGCG framework in cross-datatransferring, we initially perform FTS on llama2-chat-7b using the general dataset of HarmBench.Subsequently, we conduct CAS with a domain-specific dataset derived from the general validationset of HarmBench. Specifically, we use six dis- tinct semantic categories defined in HarmBench asseparate domains: Chemical Biological, Misinfor-mation, Illegel, Cybercrime, Harmful, and Harass-ment Bully. The general GCG-M without domaindata training serves as the baseline. We also in-clude experiments using GCG-M trained with thesame domain data. To ensure a fair comparison, allexperiments maintain the same total search steps,500. The experimental results for both validationand test sets are displayed in .We observe that DeGCG outperforms GCG-Mand GCG-M w/ domain data in terms of ASR per-formance across five of the six categories. Theinclusion of domain data significantly enhances per-formance, particularly in the Chemical biological,Misinformation, Illegal, and Cybercrime categories.The relatively lower ASR performance in the Harm-ful and Harassment Bully categories could be at-tributed to the limited data size in these categories.Nonetheless, the success of the behavior-agnosticsuffix transferring underscores the efficacy of FTS,validating the necessity of the decoupled first-tokensearching and content-aware search process. Interleaved Self-Transferring.To evaluate theeffectiveness of the proposed i-DeGCG algorithmfor self-transferring, we apply the interleaved algo-rithm on Llama2-chat and Openchat-3.5 models,respectively. In this context, the source and tar-get models are identical, and the validation set isused as the training dataset. We assess performanceacross various scales of the searching space. Specif-ically, given that the searching space grows expo-nentially with increased suffix length, we extend",
  ": Performance comparison (ASR) of Interleaved Self-Transferring on five different scales of the searchingspaces. We report results on both the Validation (Valid) and the Test sets": "the adversarial suffix length from 20 to 40, 60, 80,and 100, representing five different sizes of search-ing spaces. For fair comparison, we maintain thesame total searching steps across all experiments.The experimental results are detailed in .The empirical findings in suggest thatlarger searching spaces provide more suffix combi-nations and a greater possibility of achieving suc-cessful attacks, but also introduce more complexityand significant challenges in searching adversar-ial suffixes. Notably, our proposed i-DeGCG canoutperform baselines across all scales of search-ing spaces, achieving 65.9 and 52.2 for Llama2-chat and 95.1 and 90.6 for OpenChat-3.5 on val-idation and test sets. GCG-M struggles with thelarger search space, resulting in lower performance.In contrast, i-DeGCG can facilitate efficient self-transfer between FTS and CAS. This underscoresthe importance of self-transferability in enhancingthe efficiency of adversarial suffix searching.",
  "Training Dynamics Comparison": "To demonstrate the enhanced search efficiencyachieved by the DeGCG framework and i-DeGCGalgorithm, we plot the training dynamics every100 steps.Specifically, we examine the cross-entropy loss of the first token (FT), the averagecross-entropy loss of the entire target sentence (ST),and the ASR performance on both the validation(Valid) and test sets. The dynamics for Llama2-chat, with a total of 500 steps and a suffix length of20, are illustrated in . For DeGCG under thisexperimental setting, we perform the FTS for 100steps followed by CAS for 400 steps.As depicted in subfigures (a) and (b) of ,both DeGCG and i-DeGCG converge faster thanGCG-M, achieving lower cross-entropy losses forboth the first-token and the target sequence. No-tably, DeGCG reaches a near-zero FT loss within 100 steps, whereas the one of GCG-M remainsgreater than 10 within the same steps. This indi-cates that the first-token optimization is noised andhindered by other optimization goals, degradingsearching efficiency. Compared to DeGCG, theinterleaved variant i-DeGCG shows higher FT lossbut lower ST loss, attributed to the alternation be-tween FTS and CAS, achieving a dynamic balancebetween these two searching stages.Regarding the ASR performance, shown in sub-figures (c) and (d), DeGCG and i-DeGCG outper-form GCG-M, achieving the best results within300 steps, while GCG-M continues to underper-form even after 500 steps. It is noteworthy thatDeGCG achieves low ASR within the initial 100steps using only FTS and reaches optimal perfor-mance within the subsequent 100 steps using CAS.This reveals that CAS is essential for a successfulattack, and FTS provides a solid initialization forCAS. In addition, i-DeGCG achieves higher ASRperformance within the first 100 steps compared toboth DeGCG and GCG-M, and comparable perfor-mance to DeGCG within the first 300 steps. Thissuccess of both DeGCG and the interleaved vari-ant validates the effectiveness of the decoupledframework and highlights the importance of self-transferable suffixes. i-DeGCG is particularly ad-vantageous when the boundary between FTS andCAS is not easily determined due to its dynamicbalance nature.",
  "Self-Transferring by Self-Repetition": "To further investigate the impact of self-transferringon performance enhancement, we conduct a newself-transferring experiment via self-repetition.Specifically, we aim to achieve an effective initial-ization in larger search spaces. Instead of initiatingsearches from a random suffix in a large searchspace, we utilize suffixes obtained in a smallersearch space and expand the search space through",
  ": Training dynamics (cross-entrory loss) comparison for GCG-M, DeGCG, and i-DeGCG": "self-repetition of these short suffixes.In otherwords, the longer suffix initialization is constructedby repeating the shorter suffix and concatenatingthem for searching within the large search space.For this experiment, we use the suffix of length 20,searched on Llama2-chat-7b after 500 steps, andrepeat it 2, 3, 4, and 5 times to create suffix initial-izations of lengths 40, 60, 80, and 100, respectively.We then perform content-aware searching on theseinitializations for an additional 500 steps and reportthe ASR performance in . The experimentalresults reveal a significant improvement, with ASRperformance increasing from 21.7 to 68.3 on thevalidation set and from 19.5 to 54.7 on the test set.These findings also indicate that suffix search insmall search spaces provides valuable and effec-tive initializations for longer suffix construction forfurther fine-tuning in large search spaces.",
  "Ablation Study": "To further assess the effectiveness of our design,we conduct an ablation study on the initializa-tion. Specifically, we compare initializations ob-tained by FTS and GCG-M for the same numberof steps, aiming to evaluate the utility of differ-ent trained suffix initializations for content-awarefine-tuning. We examine how suffix initializationson source models Starling-LM-alpha-7b, Mistral-Instruct-7b, and OpenChat-3.5-7b transfer to thetarget model Llama2-chat-7b. The experimentalresults are presented in . The empiricalfindings demonstrate the superiority of the first-token searched initialization. We attribute this tothe behavior-agonistic nature of suffixed obtainedby FTS, which is easier to transfer across models",
  "Conclusion": "In this study, we present DeGCG to enhancethe efficiency of adversarial suffix searching foraligned LLMs. By decoupling the search processinto behavior-agnostic pre-searching and behavior-relevant fine-tuning, DeGCG addresses the ineffi-ciencies inherent in the GCG method. The introduc-tion of First-Token Searching and Content-AwareSearching enables more efficient and effective iden-tification of adversarial suffixes. Additionally, theinterleaved algorithm i-DeGCG demonstrates fur-ther improvements by dynamically balancing be-tween FTS and CAS. Experimental results on theHarmBench across various LLMs validate the effec-tiveness of our proposed methods. DeGCG not onlyimproves search efficiency but also achieves higherASR compared to the baseline GCG-M method.The success of suffix transfer through two-stagelearning highlights the critical role of initializa-tion in optimizing the search process. Overall, thiswork underscores the importance of suffix transfer-ability in enhancing the efficiency of adversarialsuffix searching and provides an effective frame-work for future red teaming investigations. Thefindings contribute to the broader understanding ofLLM vulnerabilities and the development of moreresilient and secure models.",
  "Limitations": "Several limitations exist in our work. Firstly, our fo-cus primarily centers on open-source models, lack-ing validation on closed-source models. Futureresearch efforts could extend behavior-agnostic pre-searching and behavior-relevant post-searching toinclude closed-source models. Additionally, our as-sessment of suffix transferability has been limitedto standard behaviors in the text-only sets, neglect-ing copyright, contextual, and multimodal behav-iors. Future work could explore the transferabil-ity of suffixes between large language models andlarge multimodal models for both text and mul-timodal data. Furthermore, our empirical studylacks a theoretical understanding of suffix transferlearning, which warrants further investigation.",
  "Ethics Statement": "Our study does not propose a new attack paradigmto jailbreak LLMs. Instead, we investigate theexisting adversarial suffix-based jailbreak attack,aiming to understand the properties of adversarialsuffixes in a better way. For example, we mainlyexamine the suffix transferability with suffix searchefficiency. This further understanding of suffixtransferability can help guide the design of more ef-fective defense methods in the future. We also high-light that current adversarial suffix-based attackscan be well defended by the PPL detection-basedmethod. The authors would like to thank anonymous review-ers for their valuable suggestions. The authors alsothank William Yang Wang, Xianjun Yang, YiranZhao, Keyu Duan, and Leon Lin for their helpfuldiscussions. The computational work for this ar-ticle was partially performed on resources of theNational Supercomputing Centre (NSCC), Singa-pore2.",
  "Yangsibo Huang, Samyak Gupta, Mengzhou Xia, KaiLi, and Danqi Chen. 2023. Catastrophic jailbreak ofopen-source llms via exploiting generation. arXivpreprint arXiv:2310.06987": "Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, et al. 2023. Mistral7b. arXiv preprint arXiv:2310.06825. Daniel Kang, Xuechen Li, Ion Stoica, Carlos Guestrin,Matei Zaharia, and Tatsunori Hashimoto. 2023. Ex-ploiting programmatic behavior of llms: Dual-usethrough standard security attacks. arXiv preprintarXiv:2302.05733. TomaszKorbak,KejianShi,AngelicaChen,RasikaVinayakBhalerao,ChristopherBuck-ley, Jason Phang, Samuel R Bowman, and EthanPerez. 2023.Pretraining language models withhuman preferences. In International Conference onMachine Learning, pages 1750617533. PMLR.",
  "Xiaogeng Liu, Nan Xu, Muhao Chen, and ChaoweiXiao. 2023a. Autodan: Generating stealthy jailbreakprompts on aligned large language models. arXivpreprint arXiv:2310.04451": "Yi Liu, Gelei Deng, Zhengzi Xu, Yuekang Li, YaowenZheng, Ying Zhang, Lida Zhao, Tianwei Zhang, andYang Liu. 2023b. Jailbreaking chatgpt via promptengineering: An empirical study.arXiv preprintarXiv:2305.13860. Mantas Mazeika, Long Phan, Xuwang Yin, Andy Zou,Zifan Wang, Norman Mu, Elham Sakhaee, NathanielLi, Steven Basart, Bo Li, et al. 2024. Harmbench: Astandardized evaluation framework for automatedred teaming and robust refusal.arXiv preprintarXiv:2402.04249.",
  "Yao Qiang, Xiangyu Zhou, and Dongxiao Zhu. 2023.Hijacking large language models via adversarial in-context learning. arXiv preprint arXiv:2311.09948": "Taylor Shin, Yasaman Razeghi, Robert L Logan IV,Eric Wallace, and Sameer Singh. 2020. Autoprompt:Eliciting knowledge from language models withautomatically generated prompts.arXiv preprintarXiv:2010.15980. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, et al. 2023.Llama 2:Open founda-tion and fine-tuned chat models.arXiv preprintarXiv:2307.09288.",
  "Alexander Wei, Nika Haghtalab, and Jacob Steinhardt.2023. Jailbroken: How does llm safety training fail?In Thirty-seventh Conference on Neural InformationProcessing Systems": "Jason Wei, Maarten Bosma, Vincent Y Zhao, KelvinGuu, Adams Wei Yu, Brian Lester, Nan Du, An-drew M Dai, and Quoc V Le. 2021. Finetuned lan-guage models are zero-shot learners. arXiv preprintarXiv:2109.01652. Youliang Yuan, Wenxiang Jiao, Wenxuan Wang,Jen-tse Huang, Pinjia He, Shuming Shi, andZhaopeng Tu. 2023. Gpt-4 is too smart to be safe:Stealthy chat with llms via cipher. arXiv preprintarXiv:2308.06463.",
  "A.1Dataset Statistics": "We show the statistics of the HarmBench subset of Standard behaviors used in our work in .Specifically, we show the total validation (# Valid)and test(# Test) set sizes and the numbers for sixsemantic categories: (1) Chemical Biological: Chemical & Biological Weapons/Drugs, (2) Misinforma-tion: Misinformation & Disinformation, (3) Illegal: Illegal Activities, (4) Cybercrime: Cybercrime &Unauthorized Intrusion, (5) Harmful: General Harm, (6) Harassment Bully: Harassment & Bullying. Forall experiments, we use the validation set as the training set and evaluate performances on the test set.",
  "A.2Implementation Details": "We use Pytorch and Huggingface Transformers in our implementation. We run all evaluations on a singleNVIDIA A40 GPU (48G). We provide all used model cards in . Specifically, we evaluated fourmodels in our main experiments. We used one fine-tuned Llama2-13b model, provided by HarmBench, toclassify the output of these evaluated models.For cross-model and cross-data transfer experiments using the DeGCG in .2, we set themaximum search step of the FTS as 200, indicating a minimum 300 search steps for CAS to keep the500 total search steps. Besides, we set the threshold of the training loss to be 0.2. When the training lossreaches a lower value than the threshold, we update the training behavior set. For interleaved self-transferexperiments using i-DeGCG, we set the threshold 1 and 2 of training loss for both FTS and CAS as 0.2.As for the maximum steps Tf for one stage, we set it to be 20 and 30 for FTS and CAS, respectively."
}