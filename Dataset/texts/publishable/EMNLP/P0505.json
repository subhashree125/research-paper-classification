{
  "Abstract": "Event causality identification (ECI), a processthat extracts causal relations between eventsfrom text, is crucial for distinguishing causa-tion from correlation. Traditional approachesto ECI have primarily utilized linguistic pat-terns and multi-hop relational inference, risk-ing false causality identification due to infor-mal usage of causality and specious graphi-cal inference. In this paper, we adopt the Ru-bin Causal Model to identify event causality:given two temporally ordered events, we seethe first event as the treatment and the secondone as the observed outcome.Determiningtheir causality involves manipulating the treat-ment and estimating the resultant change in thelikelihood of the outcome. Given that it is onlypossible to implement manipulation conceptu-ally in the text domain, as a work-around, wetry to find a twin for the protagonist from ex-isting corpora. This twin should have identi-cal life experiences with the protagonist beforethe treatment but undergoes an intervention oftreatment. However, the practical difficulty oflocating such a match limits its feasibility. Ad-dressing this issue, we use the synthetic con-trol method to generate such a twin fromrelevant historical data, leveraging text embed-ding synthesis and inversion techniques. Thisapproach allows us to identify causal relationsmore robustly than previous methods, includ-ing GPT-4, which is demonstrated on a causal-ity benchmark, COPES-hard.",
  "*Work done during internship at Allen Institute for AI": "used in an informal way in everyday life (Imbensand Rubin, 2015). Without proper manipulationof the potential cause, and comparison betweenthe observed outcome and the intervened outcome,these approaches often identify specious causal re-lations. For example, because is often consid-ered as a causal indicator (Hidey and McKeown,2016), yet it might not be rigorous as in the caseof She got a nice job because she graduated fromone of the top universities.It is very possiblethat the employer paid more attention to the candi-dates ability, rather than just the educational back-ground in offering a job. Regardless of how theselinguistic features are obtained - whether extractedfrom causal keywords and semantic indications,or obtained from language models - any feature-based approach may be predisposed to bias dueto their unreliable causality foundations.Thus,highly sophisticated methods that rely on multi-hop reasoning on graphs for ECI (Cao et al., 2021;Chen et al., 2022; Liu et al., 2023; Chen et al.,2023; Pu et al., 2024), also risk being fundamen-tally flawed in their conclusions.If we want to reliably discover event causal-ity, say whether there exists a causal relation be-tween a pair of temporally ordered events (e1, e2),we need to manipulate e1 and see if e2 still hap-pens in a parallel universe in which e1 does nothappen. In other words, we want to find a twinfor the protagonist p in the events, who has iden-tical life experiences with p (i.e., a sequence ofevents) up to the point when e1 takes place, butinstead undergoes an intervention of e1.How-ever, it is almost impossible to implement this ideain the text domain (e.g., stories, narratives, andnews reports): for any event in text, it is veryrare that its protagonist has twins that satisfy theaforementioned requirements. In this work, as aworkaround, we attempt to synthesize twins bymerging relevant event sequences retrieved froma corpus, inspired by a causal inference method, : An example illustrating the temporal ordering of treatment event e1, observed outcome e2, and pretreat-ment events e1, e0 (covariates) on a time axis. To figure out if e1 causes e2, we come up with an intervention ofe1, e1, and find that it does not affect the likelihood of e2. And thus, e1 is not the cause of e2. called synthetic control, used in economics andsocial sciences (Abadie and Gardeazabal, 2003;Abadie et al., 2010; Abadie, 2021). Such eventsequence merging is also seen in recent effort inevent schema induction in information extractionstudies (Li et al., 2020; Wen et al., 2021; Du et al.,2022; Dror et al., 2023).Specifically, our approach 1 consists of threecomponents: (1) noncontemporary control groupretrieval, (2) control unit synthesis, and (3) treat-ment effect estimation. Given a pair of events withcertain context, the first component retrieves rele-vant event sequences from historical data that canbe leveraged to synthesize twins via text embed-ding and inversion techniques (Morris et al., 2023,2024) in the second component. And this is fol-lowed by the third component which calculates acausal estimand to determine whether there existsa causal relation between the two events.Theproposedmethodologyfundamentallyshifts from conventional ECI methods by intro-ducing the concept of synthetic control to the textdomain. This allows the inherent linguistic biaswhich is prevalent in data-driven ECI approachesto be significantly mitigated.Moreover, byintroducing full-context matching in a continuousspace, we overcome the limitation of discrete tem-poral propensity matching proposed in previousattempts (Zhang et al., 2022; Wang et al., 2023)of solving ECI with the potential-outcome frame-work.Our approach demonstrates significantlyimproved results on the COPES-hard dataset, acommonly used causality benchmark, by at least9% (relatively) over existing methods and GPT-4.The contribution of this paper is threefold:",
  "Preliminaries": "In this section, we present the fundamentals of ourmethod, which is grounded on the Rubin CausalModel (Rubin, 1974) and discuss its previous ap-plication to the problem of event causality identifi-cation in the text domain. And then we discuss thelimitation of previous attempts and introduce whywe adopt synthetic control in this work.",
  "Rubin Causal Model": "The Rubin Causal Model (RCM) is one of the cor-nerstones of causal inference.To illustrate thisframework in the text domain, let us consider twotemporally ordered events (e1, e2) in an article.They involve a common protagonist, or study unit,p, and we want to estimate whether e1 causes e2,with a context that can be modeled as a tempo-rally ordered sequence of event mentions in text:et, et+1, , e0 (see as an example).Following Zhang et al. (2022)s formulation ofECI, we see the first event e1 as the treatment,and second event e2 as the observed outcome. Tomeasure the treatment effect, we need to comparethe study unit with a control group within whichthe control units did not undergo event e1, and es-timate the change of the likelihood of e2 had e1been intervened:",
  "Temporal Propensity Matching": "The most significant challenge in formulatingECI as described above is the spurious corre-lations introduced by pervasive confounding co-occurrences. They need to be eliminated for anunbiased estimation of the causal estimand in-troduced in Equation (1).This can be doneby balancing events that precede e1, or covari-ates. Several techniques for balancing covariates(Cochran and Chambers, 1965; Rosenbaum andRubin, 1983; Pearl, 1995) have been proposed,e.g., sub-classification, matched sampling, covari-ance adjustment, and propensity score.Zhanget al. (2022) propose to use temporal propsensi-ties for covariate balancing in text. To this end,Equation (1) can be rewritten as",
  "p(x) = P(e1|x),(3)": "is the probability of e1 occurring at time 1 condi-tioning on the covariates being x at time equal toor less than 0 (prior to the time e1 happens). Toincorporate the context of e1, Wang et al. (2023)design a mechanism to sample diversified covari-ates from multiple timestamps and also use tempo-ral propensity for balancing. Yet they merge co-variates to construct the final covariate set whichwould lose the temporal interaction within the se-quence of context events.",
  "Better Context Modeling with SyntheticControl": "Synthetic control is a widely-used method ineconometrics and social sciences for policy eval-uation and causal inference in observational stud-ies (Abadie and Gardeazabal, 2003; Abadie et al.,2010).It addresses the challenge of having toestimate the counterfactual, a critical aspect inthe study of causality. The method involves con-structing an artificial control unit a syntheticcontrol as a weighted combination of potentialcontrol units, rather than relying on just a singlecontrol unit. This synthetic control then acts as : After the outbreak of terrorism in the late1960s, per capita GDP in the Basque Country declinedabout 10 percentage points relative to a synthetic con-trol region without terrorism. Figure from Abadie andGardeazabal (2003). the counterfactual, representing what would havehappened in the absence of the treatment.Thecausal effect is subsequently estimated by com-paring the study unit and the synthetic controlunit. This technique allows for robust treatmentsof causal effects where finding an event sequencethat perfectly mirrors the treated case is imprac-tical. As illustrated in , this method in-volves creating a synthetic control group from aweighted combination of multiple untreated unitsthat closely mimic the pre-intervention charac-teristics and trends of the treated unit.In thiscase, the solid line represents the actual per capitaGDP of the Basque Country, which experiencedthe impact of terrorism in the late 1960s, whilethe dashed line represents the synthetic per capitaGDP constructed from adjacent regions unaffectedby terrorism. By comparing the actual GDP withthe synthetic GDP after the onset of terrorism, thegraph visually depicts the negative economic im-pact of terrorism on the Basque Country. This gapbetween the lines highlights the divergence fromwhat the economic trajectory might have been inthe absence of terrorism, thereby demonstratingthe usefulness of the synthetic control method inassessing causal effects. With the synthetic control method, we canmodel longer context in the RCM frameworkwhile maintaining the temporal structure of theoriginal event sequence. Yet in the text domain, itis harder to find contemporary control group like those GDP curves of adjacent regions. In the fol-lowing sections, we further discuss how we per-form the synthetic control method in the context ofevent causality identification in text, by retrievingnoncontemporary control groups and synthesizingcontrol units from them.",
  "Method": "For a pair of events e1 and e2 mentioned in somecontext that we consider as the study unit, we wantto (1) find relevant stories (event sequences) fromhistorical data that can be considered as noncon-temporary control group, and (2) merge them tocreate a synthetic control unit, and then (3) calcu-late the causal estimand.",
  "Noncontemporary Control GroupRetrieval": "Since it is very rare that twins of the protagonistexist in some existing corpus, we turn to noncon-temporary articles of the same topic that happennot necessarily at the same time as the study unit.Even though these articles do not form a perfectcontrol group, we can filter and obtain the mostrelevant ones and merge them as a synthetic con-trol unit (see .2).Asapreprocessingstep,wefirstusegpt-3.5-turbo2to anonymize the entireevent sequence so it does not contain any specificentities3. For example, in the event description,we blur the entities:we convert Timmy toa boy; Mary into a girl.The reason thisoperation is 1) our focus is event. 2) we admitthat arguments, especially people, play importantroles in the progress of an event. But it is alsothe actions that define a persons character. Toomuch information about the arguments mightmislead the retrieval process and subsequentlythe creation of synthetic control.However, wedo not use abstraction4 when we determine thesimilarity of sentences using gpt-3.5-turbo.Then we use BM25 (Robertson et al., 2009)to retrieve n relevant documents from a largecorpus that has a good amount of topic coverage,given these event descriptions from the study 3See Appendix A.3 for detailed prompt.4This insight comes from our experiments where theperformance worsens as the level of abstraction increases,e.g.from best to worst, in terms of performance ofgpt-3.5-turbo, Tom > a boy > a person. unit.Yet not all of these documents satisfiesour requirements: (1) we need the pretreatmentevents of the study unit and the control groupto be as close as possible; (2) the units in thecontrol group cannot contain the treatment event,but intervention of treatment instead. We do thesame preprocessing procedure with the retrieveddocuments and use gpt-3.5-turbo to sum-marize5 the retrieved documents (Zhang et al.,2023).These pieces of text are embedded intovectors using text-embedding-ada-0026.Leveraging the embeddings,we keep thosedocuments with pretreatment events whose co-sine distance is higher than a certain threshold.However, measuring event similarity with cosinesimilarity can be rather arbitrary at times (Stecket al., 2024). For example, A person loves foodand A person does not love food can have acosine similarity of >0.9, depending on thespecific embedding model used. As such, cosinesimilarity is only used as a first round of filteringand we subsequently examine the similarity ofkept documents7 using gpt-3.5-turbo.There are three key parts of event similaritythat we check using gpt-3.5-turbo:(1)Pretreatments of the kept documents vs. treatmentof the study unit.This is done to ensure thatthe treatment of the study unit does not takeplace in the pretreatments, which will affect ourassessment of the causal estimand.(2) Inter-ventions of the kept documents vs.treatmentof the study unit. Due to the arbitrary nature ofthe cosine similarity measure, we have to ensurethat the interventions and treatment are in factdissimilar. (3) Outcomes of the kept documentsvs. treatment of the study unit. Similar to (1),having an intervention similar to the treatmentwill make our estimates inaccurate. To do this, weindependently prompt gpt-3.5-turbo withtwo slightly different questions:",
  "See Appendix A.2 for detailed prompt": "ries (Mostafazadeh et al., 2016), where each se-quence holds five chronologically ordered events.The annotators were tasked to identify whether agiven event was causal to the final event in thesequence. COPES, with its emphasis on causal-ity and chronological event sequencing, serves asan ideal testbed for our focus - integrating the po-tential outcome framework and synthetic controlmethod into the realm of textual ECI.Although LLMs have shown relatively strongperformance at many causal reasoning tasks, manyhave argued that LLMs are just causal parrots(Zecevic et al., 2023) and lack a genuine com-prehension of the causal framework (Ashwaniet al., 2024). Therefore, our focus is on a sub-set of the COPES data whose causal relation-ships are difficult for LLMs to grasp in a zero-shot setting.Specifically, out of the 340 sam-ples from the COPES dataset, there are 70 sam-ples in total which show 3 false positives whengpt-4-turbo is prompted to identify the possi-ble cause(s) in a zero-shot setting. One of the 70samples is shown below:Events:Denise loved playing pokemon go.,She decided to take a walk so she could play.,While she was crossing the street, denise saw apokemon on her screen., Denise was almost hitby a car as she walked into traffic., She decidedto only play on the sidewalk from now on.Outcome: She decided to only play on the side-walk from now on.Cause: Denise was almost hit by a car as shewalked into traffic.In the example shown above and under a zero-shot setting, gpt-4-turbo identifies all fourevent sequences that preceed the observed out-come to be causes. While all four sequences mightco-occur frequently with the observed outcome,narrowing down to the one true cause requires amore robust framework. The goal of our approachis to improve the precision without too much de-terioration in recall, thereby achieving an increasein the F1-score.",
  "Merging Control Group": "Afterwefindtherelevantcontrolgroup[U1, U2, , UJ] as shown in , we embedthe anonymized pretreatments of the study unitand the control units using embedding function = text-embedding-ada-002 and obtaintextembeddingsustudyand[u1, u2, , uJ],respectively.If the treatment being tested isthe first sentence in the sequence, we promptgpt-3.5-turbo to generate an augmentedcontext as the pretreatment.We then applyridge regression to find some optimal weightsw1, w2, , wJ such that",
  "usynthetic = Jj=0wj uj(5)": "is then inverted to generate the synthetic poten-tial outcome in a textual format using a Vec2Textfunction. The state-of-the-art Vec2Text functionproposed by Morris et al. (2023) is built to iter-atively reconstruct text from its embeddings by treating the inversion problem as controlled gener-ation. It refines an initial text hypothesis throughrepeated corrections, using the differences be-tween the target embedding and the hypothesisembedding to guide these updates, achieving highaccuracy in recovering the original text from denseembeddings. With such function 1, we obtainthe inverted text as the synthetic control unit in itstextual format:",
  "Causal Estimand": "The similarity of the synthesized outcome (EventA) and the original outcome (Event B) are as-sessed with gpt-3.5-turbo using the sameprompt as the filtering process8. Since the outputof the Vec2Text inversion captures only a vagueidea of all the outcomes of the top retrieved docu-ments, our prompt encourages gpt-3.5-turboto fill in the blanks and evaluate whether e2 ispresent in the synthetic outcome. For example,when Event A (synthetic outcome) is The momand dad drank a cup of coffee. The little mousewas tired, and the mom sat down. They greetedeach other, and enjoyed the coffee together. Theparents were happy, and the little mouse sat down.The mom sipped a cup of coffee, and the child feltbetter; Event B (observed outcome e2) is Afteri was done, i felt much better, our prompt outputstrue since both Events A and B involve someonefeeling better. And this is a scenario where halluci-nation of Large Language Models (LLMs) (Rawteet al., 2023; McKenna et al., 2023) is helpful inreasoning, since the text recovered from embed-ding is sometimes incomprehensible for humanbeings but comprehensible for LLMs themselves.",
  "Experimental Setup": "Since the COPES dataset consists of primarilychildrens stories, we use TinyStories (Eldan andLi, 2023) which resembles the content of the sam-ples as our corpus. The choice of TinyStories asthe corpus for retrieval is mostly as a result of thenature of our test dataset, but the approach of syn-thesizing control units from a large corpus also ap-plies to identifying causal relationships from reallife events based on retrieval from narratives andnews corpus, among other genres.During experimentation, we set the corpus re-trieval size n to be 100. The maximum number ofdocuments kept for inversion is 5, and the mini-mum is 2, i.e. if we are unable to find at least 2documents that satisfy our criteria, the algorithmoutputs indeterminate for the event pair. Thecosine similarity threshold is set to 0.8 for bothpretreatment similarity and treatment dissimilar-ity. For ridge regression, we set the parameter to 1.0. When we apply Vec2Text to generate thesynthetic potential outcome, we set the number ofsteps to 10 with a beam width of 4.",
  "Results": "below summarizes the performance of ouralgorithm compared against two previous RCMbased methods and zero-shot performance ofgpt-4-turbo and gpt-4-turbo with coun-terfactual thinking.Our Synthetic Control approach delivers a re-markable precision of 0.2663, marking a sig-nificant rise of 29.8%, or roughly six percent-age points, over the precision achieved by directprompting gpt-4-turbo. It also shows a re-markable improvement over other models such",
  ": Comparison of model performances on theCOPES-hard dataset": "as ROCK (0.2239) and COLA (0.2437), rein-forcing the accuracy of our method in distin-guishing true causal relationships and reducingfalse positives. Moreover, this approach reflectsa 19.0% enhancement in the F1-score comparedto gpt-4-turbo, thus highlighting a more bal-anced performance between precision and re-call. Notably, our results indicate that less com-pute and parameter-intensive models, such asgpt-3.5-turbo, can outmatch larger modelsin discerning causal relationships within text. Thisunderscores that the efficiency of a model in han-dling causality-related tasks is not strictly depen-dent on its size or complexity.In conclusion, our synthetic control approachprovides a robust method for event causality iden-tification in the text, underscoring broad-rangingimprovements across standard performance met-rics relative to existing approaches, and demon-strating the potential superiority of leaner models.",
  "Causal Inference": "Causal inference has been a pivotal area of studyin both statistics and artificial intelligence. Twodominant frameworks have emerged in this field:the Rubin Causal Model (RCM) and Pearls do-calculus. The Rubin Causal Model, also knownas the potential outcomes framework, was de-veloped by Neyman (1923), Rubin (1974), andHolland (1986) and is grounded in the idea ofcounterfactuals.In this model, causality is es-tablished by comparing potential outcomeswhatwould happen both with and without the treat-ment. This approach relies heavily on randomizedcontrolled trials (RCTs) to estimate causal effects,providing a clear mechanism to distinguish causa-tion from correlation. Key methodologies withinthis framework include propensity score matching(Rosenbaum and Rubin, 1983; Ho et al., 2007) andsynthetic control methods (Abadie et al., 2010; Billmeier and Nannicini, 2013; Saunders et al.,2015), which are particularly useful in observa-tional studies where randomization is not feasible.Different from the potential outcome frame-work, Pearl (1995)s do-calculus is rooted in struc-tural causal models (SCMs) and utilizes directedacyclic graphs (DAGs) to represent causal rela-tionships. The do-calculus provides a formal lan-guage to express and manipulate these relation-ships, offering tools to calculate causal effectsfrom observational data by simulating interven-tions (Pearl, 2009).This framework has beeninstrumental in formalizing causal inference, es-pecially in scenarios where RCTs are not possi-ble, and has broad applications across various do-mains, including epidemiology, social sciences,and artificial intelligence.",
  "ECI in NLP": "Event causality identification in natural languageprocessing (NLP) has traditionally relied onfeature-based approaches, where linguistic pat-terns are key indicators of causal relations. Earlyworks focused on extracting causal relationshipsusing predefined causal markers such as be-cause, therefore, and due to (Beamer andGirju, 2009; Hidey and McKeown, 2016). How-ever, these approaches often fall short in distin-guishing causation from correlation, as causal lan-guage in everyday text can be used informallyand ambiguously (Imbens and Rubin, 2015). Re-cent advancements have shifted towards lever-aging deep learning and graph-based methodsto improve ECI. Multi-hop reasoning on graphsand the integration of external knowledge baseshave shown promise in enhancing the accuracy ofcausality extraction (Cao et al., 2021; Chen et al.,2022). Despite these improvements, these meth-ods still face challenges related to bias and the re-liability of inferred causal relations, particularlywhen relying heavily on linguistic patterns with-out robust causal foundations.Two recent work, ROCK (Zhang et al., 2022)and COLA (Wang et al., 2023), mitigate the afore-mentioned bias by applying the potential outcomeframework to ECI. ROCK introduces temporalpropensity matching to construct intervention oftreatments, whereas COLA improves upon ROCKby considering the context of events at the sametime. Yet COLA is still limited by its coarse mod-eling of context events, i.e., ultimately merging co-variates to construct a covariate set, which would lose the temporal interaction and sequential in-formation within the context events.Moreover,both methods adopt intervention generation withlanguage models which is somewhat problematicgiven the prevalent hallucination issue (McKennaet al., 2023; Rawte et al., 2023) in LLM genera-tion. In contrast, our approach not only modelsthe context with text embedding in the continuousspace, but also retrieves from reliable sources in-stead of relying on LLM generation.",
  "Embedding to Text": "The process of recovering text from languagemodel (LM) embeddings (Adolphs et al., 2022;Ram et al., 2023), also known as LM inversion,has gained significant attention with the rise ofdeep learning and transformer-based models inNLP. Text embeddings, such as those producedby BERT (Devlin et al., 2019), GPT-2 (Radfordet al., 2019), and other transformer models, encap-sulate semantic information in dense vector repre-sentations. These embeddings are instrumental ina variety of NLP tasks, including text classifica-tion, machine translation, and question answering.However, the challenge of reversing these embed-dings back into human-readable text, or LM in-version, is crucial for interpretability and for ap-plications like counterfactual generation in causal-ity studies.Recent research has explored vari-ous techniques for this inversion process. For in-stance, Morris et al. (2023, 2024) leverage neuralnetworks to decode or generate text from its em-beddings, ensuring that the generated text closelymatches the original semantic meaning. In text-based causal inference tasks, embeddings can beused to generate synthetic control units by con-structing twins for protagonists of events. Bysynthesizing events and contexts that are statisti-cally similar to those experienced by a protagonist,we can estimate causal effects in scenarios wheredirect manipulation is impractical.",
  "Conclusion": "Our work shows that creating counterfactuals withsynthetic control, a concept that has been widelyadopted in other disciplines such as economics,can be effectively applied to event causality iden-tification under zero-shot settings. This retrieval-based method instills more confidence in the re-sult, offering more robust performance in tasks atwhich state-of-the-art LLMs might fail. Our re-",
  "Limitations": "Our research has made significant advancementsin event causality identification in text using thesynthetic control method. However, it is essentialto acknowledge the limitations.The first significant limitation of our approachhinges on the quality and relevance of the retrievedcontrol units. The synthetic control methods ac-curacy highly depends on the available pool ofcontrol units drawn from historical data. If thedata lacks adequate and suitable counterparts forthe treatment group or is biased towards certaintypes of sequences or events, it may hamper thefunction and outcomes of the model.The time complexity of our method could beanother limitation. The process of retrieving rel-evant control units, synthesizing synthetic con-trols, and estimating causal effects can be com-putationally intensive and time-consuming, espe-cially when dealing with large datasets. The scal-ability of the method is a factor that needs fur-ther considerations to make it feasible for larger-scale applications. Our method also relies heav-ily on text embeddings for the synthesis of con-trol units. Despite their proficiency at capturingsemantic information from text, the embeddingsgenerated by language models are not perfect andcould inadvertently introduce a level of seman-tic loss or distortion. The process of recoveringthe text from the embeddings, also mentioned asmodel inversion, is also prone to error and couldaffect the quality of the generated twins. Our ap-proach currently assumes that the event sequencesare independent and identically distributed, whichmight not hold in many real-world scenarios. Forinstance, in a narrative, events usually have depen-dencies, and ignoring relationships between se-quences can lead to misleading conclusions.While these limitations present challenges, theyalso provide directions for future work to enhanceour understanding of the application of syntheticcontrol method in identifying event causality intext and scale this approach for broader usagewithin the field.",
  "Our work involves leveraging machine learning al-gorithms to enhance the identification of causal re-": "lationships in textual data, specifically focusing onevent causality. Our primary source of data is thepublicly available COPES dataset, which does notinvolve data of a personal or sensitive nature.While the development and application of ourapproach do not involve immediate ethical con-cerns, there could arise potential implications inits broader applications. Event causality identifi-cation in text could be used in various scenarios,such as content generation, recommender systems,and even legal contexts. It is important to out-line possible misuse. Firstly, the algorithm can be-come a tool for spreading misinformation or gen-erating biased content if the causal inferences itdraws from the input text are incorrect or mislead-ing. Stringent validation methods and unbiased,accurate control units are essential to mitigate suchconcerns. Secondly, it is critical to be aware ofpotential biases in the historical data used for re-trieving control units. This could impact the de-velopment of synthetic controls and subsequentlyskew the interpretation of causality. Lastly, pri-vacy concerns could arise if the method is appliedto text that holds private or sensitive information.As researchers, we ought to uphold the privacy andanonymity of any subjects used in such data.",
  "Broader Impact": "In this work, we propose a novel approach to eventcausality identification in text, combining the po-tential outcome framework and synthetic controlmethod. This research contributes noteworthy ad-vancements in Natural Language Processing andhas the potential for substantial broader impacts invarious domains.Our method provides a scientifically rigorousapproach to understanding causality in narratives.It opens avenues for greater exploration and under-standing in the domain of causal inference fromtext, which can be critical for fields like social sci-ences, psychology, law, and many more. The ap-plication of our method could also greatly enhancethe development of AI and machine learning mod-els that require proficiency in understanding, fig-uring out and interpreting event causality.Thisincludes recommendation systems, chatbots, vir-tual assistants, and AI narrative generation. More-over, our synthetic control approach can signifi-cantly benefit information retrieval systems, textsummarization, text simplification, and informa-tion extraction applications. Better understanding of textual event causality could enhance the rele-vance and quality of queried information.While there are significant benefits, some po-tential negative impacts also warrant attention.Causality identification in text can be used to in-fer sensitive information in adversarial settings,which can pose privacy concerns. Furthermore,the algorithm can unintentionally propagate or in-tensify existing bias in the data, leading to ethicaland social implications in decision-making sys-tems.The true broader impact of our researchwill heavily depend on the contexts and domainswithin which it is applied.Adopting a respon-sible, ethical, and fair use perspective is vital tomaximize the potential benefits while minimizingharm. We encourage future applications to con-sider these aspects while exploiting this method.",
  "Acknowledgements": "This research is based upon work supported inpart by ONR Contract N00014-23-1-2417, and bythe Office of the Director of National Intelligence(ODNI), Intelligence Advanced Research ProjectsActivity (IARPA), via IARPA Contract No. 2019-19051600006 under the BETTER Program. Theviews and conclusions contained herein are thoseof the authors and should not be interpreted asnecessarily representing the official policies, ei-ther expressed or implied, of ODNI, IARPA, theDepartment of Defense, or the U.S. Government.The U.S. Government is authorized to reproduceand distribute reprints for governmental purposesnotwithstanding any copyright annotation therein.",
  "Leonard Adolphs, Michelle Chen Huebscher, ChristianBuck, Sertan Girgin, Olivier Bachem, MassimilianoCiaramita, and Thomas Hofmann. 2022. Decoding": "a Neural Retrievers Latent Space for Query Sugges-tion. In Proceedings of the 2022 Conference on Em-pirical Methods in Natural Language Processing,pages 87868804, Abu Dhabi, United Arab Emi-rates. Association for Computational Linguistics. Swagata Ashwani, Kshiteesh Hegde, Nishith ReddyMannuru, Mayank Jindal, Dushyant Singh Sengar,Krishna Chaitanya Rao Kathala, Dishant Banga,Vinija Jain, and Aman Chadha. 2024. Cause and Ef-fect: Can Large Language Models Truly UnderstandCausality? Brandon Beamer and Roxana Girju. 2009. Using a bi-gram event model to predict causal potential. In In-ternational Conference on Intelligent Text Process-ing and Computational Linguistics, pages 430441.Springer.",
  "Andreas Billmeier and Tommaso Nannicini. 2013. As-sessing economic liberalization episodes: A syn-thetic control approach. Review of Economics andStatistics, 95(3):9831001": "Pengfei Cao, Xinyu Zuo, Yubo Chen, Kang Liu, JunZhao, Yuguang Chen, and Weihua Peng. 2021.Knowledge-Enriched Event Causality Identificationvia Latent Structure Induction Networks.In Pro-ceedings of the 59th Annual Meeting of the Associa-tion for Computational Linguistics and the 11th In-ternational Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers), pages 48624872, Online. Association for Computational Lin-guistics. Meiqi Chen, Yixin Cao, Kunquan Deng, Mukai Li,Kun Wang, Jing Shao, and Yan Zhang. 2022.ERGO: Event Relational Graph Transformer forDocument-level Event Causality Identification. InProceedings of the 29th International Conferenceon Computational Linguistics, pages 21182128,Gyeongju, Republic of Korea. International Com-mittee on Computational Linguistics. Meiqi Chen,Yixin Cao,Yan Zhang,and Zhi-wei Liu. 2023.CHEER: Centrality-aware High-order Event Reasoning Network for Document-levelEvent Causality Identification. In Proceedings of the61st Annual Meeting of the Association for Com-putational Linguistics (Volume 1:Long Papers),pages 1080410816, Toronto, Canada. Associationfor Computational Linguistics.",
  "pages 41714186, Minneapolis, Minnesota. Associ-ation for Computational Linguistics": "Quang Do, Yee Seng Chan, and Dan Roth. 2011. Min-imally Supervised Event Causality Identification. InProceedings of the 2011 Conference on EmpiricalMethods in Natural Language Processing, pages294303, Edinburgh, Scotland, UK. Association forComputational Linguistics. Rotem Dror, Haoyu Wang, and Dan Roth. 2023. Zero-Shot On-the-Fly Event Schema Induction. In Find-ings of the Association for Computational Linguis-tics: EACL 2023, pages 705725, Dubrovnik, Croa-tia. Association for Computational Linguistics. Xinya Du, Zixuan Zhang, Sha Li, Pengfei Yu, Hong-wei Wang, Tuan Lai, Xudong Lin, Ziqi Wang, IrisLiu, Ben Zhou, Haoyang Wen, Manling Li, Dar-ryl Hannan, Jie Lei, Hyounghun Kim, Rotem Dror,Haoyu Wang, Michael Regan, Qi Zeng, Qing Lyu,Charles Yu, Carl Edwards, Xiaomeng Jin, YizhuJiao, Ghazaleh Kazeminejad, Zhenhailong Wang,Chris Callison-Burch, Mohit Bansal, Carl Vondrick,Jiawei Han, Dan Roth, Shih-Fu Chang, MarthaPalmer, and Heng Ji. 2022.RESIN-11: Schema-guided Event Prediction for 11 Newsworthy Sce-narios. In Proceedings of the 2022 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies: System Demonstrations, pages 5463, Hy-brid: Seattle, Washington + Online. Association forComputational Linguistics.",
  "Ronen Eldan and Yuanzhi Li. 2023. TinyStories: HowSmall Can Language Models Be and Still Speak Co-herent English?": "Christopher Hidey and Kathy McKeown. 2016. Iden-tifying Causal Relations Using Parallel WikipediaArticles. In Proceedings of the 54th Annual Meet-ing of the Association for Computational Linguistics(Volume 1: Long Papers), pages 14241433, Berlin,Germany. Association for Computational Linguis-tics. Daniel E Ho, Kosuke Imai, Gary King, and Elizabeth AStuart. 2007.Matching as nonparametric prepro-cessing for reducing model dependence in paramet-ric causal inference. Political analysis, 15(3):199236.",
  "Cheongwoong Kang and Jaesik Choi. 2023. Impact ofCo-occurrence on Factual Knowledge of Large Lan-guage Models. In The 2023 Conference on Empiri-cal Methods in Natural Language Processing": "Viet Dac Lai, Amir Pouran Ben Veyseh, Minh VanNguyen,Franck Dernoncourt,and Thien HuuNguyen. 2022. MECI: A Multilingual Dataset forEvent Causality Identification.In Proceedings ofthe 29th International Conference on ComputationalLinguistics, pages 23462356, Gyeongju, Repub-lic of Korea. International Committee on Computa-tional Linguistics. Manling Li, Qi Zeng, Ying Lin, Kyunghyun Cho,Heng Ji, Jonathan May, Nathanael Chambers, andClare Voss. 2020.Connecting the Dots:EventGraph Schema Induction with Path Language Mod-eling.In Proceedings of the 2020 Conference onEmpirical Methods in Natural Language Processing(EMNLP), pages 684695, Online. Association forComputational Linguistics.",
  "Jintao Liu, Zequn Zhang, Zhi Guo, Li Jin, Xiaoyu Li,Kaiwen Wei, and Xian Sun. 2023. Kept: Knowledgeenhanced prompt tuning for event causality identifi-cation. Knowledge-Based Systems, 259:110064": "Nick McKenna, Tianyi Li, Liang Cheng, MohammadHosseini, Mark Johnson, and Mark Steedman. 2023.Sources of Hallucination by Large Language Mod-els on Inference Tasks. In Findings of the Associa-tion for Computational Linguistics: EMNLP 2023,pages 27582774, Singapore. Association for Com-putational Linguistics. John Morris, Volodymyr Kuleshov, Vitaly Shmatikov,and Alexander Rush. 2023. Text Embeddings Re-veal (Almost) As Much As Text. In Proceedings ofthe 2023 Conference on Empirical Methods in Natu-ral Language Processing, pages 1244812460, Sin-gapore. Association for Computational Linguistics.",
  "John Xavier Morris, Wenting Zhao, Justin T Chiu, Vi-taly Shmatikov, and Alexander M Rush. 2024. Lan-guage Model Inversion.In The Twelfth Interna-tional Conference on Learning Representations": "Nasrin Mostafazadeh, Nathanael Chambers, XiaodongHe, Devi Parikh, Dhruv Batra, Lucy Vanderwende,Pushmeet Kohli, and James Allen. 2016. A Corpusand Cloze Evaluation for Deeper Understanding ofCommonsense Stories. In Proceedings of the 2016Conference of the North American Chapter of theAssociation for Computational Linguistics: HumanLanguage Technologies, pages 839849, San Diego,California. Association for Computational Linguis-tics.",
  "Alec Radford, Jeff Wu, Rewon Child, David Luan,Dario Amodei, and Ilya Sutskever. 2019. LanguageModels are Unsupervised Multitask Learners": "Ori Ram, Liat Bezalel, Adi Zicher, Yonatan Belinkov,Jonathan Berant, and Amir Globerson. 2023. WhatAre You Token About? Dense Retrieval as Distri-butions Over the Vocabulary. In Proceedings of the61st Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages24812498, Toronto, Canada. Association for Com-putational Linguistics. Vipula Rawte, Swagata Chakraborty, Agnibh Pathak,Anubhav Sarkar, S.M Towhidul Islam Tonmoy,Aman Chadha, Amit Sheth, and Amitava Das. 2023.The Troubling Emergence of Hallucination in LargeLanguage Models - An Extensive Definition, Quan-tification, and Prescriptive Remediations.In Pro-ceedings of the 2023 Conference on Empirical Meth-ods in Natural Language Processing, pages 25412573, Singapore. Association for ComputationalLinguistics.",
  "Harald Steck, Chaitanya Ekanadham, and NathanKallus. 2024. Is Cosine-Similarity of EmbeddingsReally About Similarity?In Companion Proceed-ings of the ACM on Web Conference 2024, WWW24. ACM": "Zhaowei Wang, Quyet V. Do, Hongming Zhang, JiayaoZhang, Weiqi Wang, Tianqing Fang, Yangqiu Song,Ginny Wong, and Simon See. 2023. COLA: Con-textualized Commonsense Causal Reasoning fromthe Causal Inference Perspective. In Proceedings ofthe 61st Annual Meeting of the Association for Com-putational Linguistics (Volume 1:Long Papers),pages 52535271, Toronto, Canada. Association forComputational Linguistics. Haoyang Wen, Ying Lin, Tuan Lai, Xiaoman Pan, ShaLi, Xudong Lin, Ben Zhou, Manling Li, HaoyuWang, Hongming Zhang, Xiaodong Yu, AlexanderDong, Zhenhailong Wang, Yi Fung, Piyush Mishra,Qing Lyu, Ddac Surs, Brian Chen, Susan WindischBrown, Martha Palmer, Chris Callison-Burch, CarlVondrick, Jiawei Han, Dan Roth, Shih-Fu Chang,and Heng Ji. 2021. RESIN: A Dockerized Schema-Guided Cross-document Cross-lingual Cross-mediaInformation Extraction and Event Tracking System.In Proceedings of the 2021 Conference of the NorthAmerican Chapter of the Association for Computa-tional Linguistics: Human Language Technologies:Demonstrations, pages 133143, Online. Associa-tion for Computational Linguistics.",
  "A.1Prompt for summarization": "You will be given a short story. Please help tosummarize the key events in the text to 5 or fewersentences of less than 15 words each. The eventsshould be in chronological order, and the eventsshould capture the key actors, location, causes,and effects of the event being described. Returnyour answer in JSON as a array of strings in thekey result.Here is an example: Text: Once upon a time,there was an ugly frog. The ugly frog lived in asmall pond. The frog liked to get things. He wouldget things from the bottom of the pond. One day,he saw a shiny weight. The ugly frog wanted theshiny weight. He tried to get it, but it was tooheavy. He tried and tried, but he could not getit. The ugly frog was sad. He wanted the shinyweight so much. Then, a big fish came. The bigfish saw the ugly frog and the shiny weight. Thebig fish wanted to help. The big fish and the uglyfrog worked together to get the shiny weight. Theywere happy to have the shiny weight. They be-came good friends. Answer: \"result\": [ \"An ugly frog who likedto get things lived in a small pond.\", \"One day, theugly frog saw a shiny weight, and wanted to getit, but could not.\", \"A big fish came, and the fishwanted to help the ugly frog get the shiny weight.\",\"The big fish worked together with the ugly frog toget the shiny weight.\", \"The fish and the frog werehappy to get the weight and became good friends.\"] Now your turn: Text: \"text\"",
  "A.3Prompt for anonymization": "You will be given a story. Your job is to anonymizethe names of persons, and replace them with ageneric term. If there is nothing to anonymize, re-turn the story as is.For example, \"Mary\" should be replaced by \"agirl\", and \"Tim\" should be replaced by \"a boy\".Return your result as a string in the key resultof a JSON object.Now your turn: Story: event",
  "A.4Prompt for counterfactual thinking": "Here is a story with five events: {story}.Your task is to tell if the {i}-th event {event 1}is the cause of the fifth event {event 2}.Please think step-by-step. You need to imaginea scenario where the {i}-th event {event 1} is in-tervened by some other event and then determineif the fifth event {event 2} would still happen. Ifthe fifth event would still happen, then answer no;else answer yes.Now tell me if there exists a causal relation be-tween the two events."
}