{
  "Abstract": "Interpretability and analysis (IA) research is agrowing subfield within NLP with the goal ofdeveloping a deeper understanding of the be-havior or inner workings of NLP systems andmethods. Despite growing interest in the sub-field, a criticism of this work is that it lacksactionable insights and therefore has little im-pact on NLP. In this paper, we seek to quantifythe impact of IA research on the broader field ofNLP. We approach this with a mixed-methodsanalysis1 of: (1) a citation graph of 185K+ pa-pers built from all papers published at ACLand EMNLP conferences from 2018 to 2023,and their references and citations, and (2) a sur-vey of 138 members of the NLP community.Our quantitative results show that IA work iswell-cited outside of IA, and central in the NLPcitation graph. Through qualitative analysis ofsurvey responses and manual annotation of 556papers, we find that NLP researchers build onfindings from IA work and perceive it as impor-tant for progress in NLP, multiple subfields, andrely on its findings and terminology for theirown work. Many novel methods are proposedbased on IA findings and highly influenced bythem, but highly influential non-IA work citesIA findings without being driven by them. Weend by summarizing what is missing in IA worktoday and provide a call to action, to pave theway for a more impactful future of IA research.",
  "Introduction": "The rapid progress made in the development oflarge language models (LLMs, Devlin et al. (2019);Radford et al. (2019); Raffel et al. (2020); Bom-masani et al. (2022); Touvron et al. (2023); OpenAIet al. (2024); Team et al. (2024)) has had a pro-found impact on the field of natural language pro-cessing (NLP) (Gururaja et al., 2023). While thesemodels demonstrate unprecedented performance",
  "Citations": "Information Extraction/RetrievalApplicationsMachine Translation andMultilinguality DialogueSemanticsInterpretability and Analysis : Interpretability and analysis (IA) is an in-creasingly popular subfield of NLP: (top) Number of IApapers in ACL/EMNLP in comparison to other tracksthat have existed since 2020. The number of IA papershas grown considerably, from 90 papers in 2020 to 160papers in 2023 (a growth rate of 77.8%). This is thehighest growth rate among these tracks. (bottom) Cita-tions to IA papers compared to other highly cited tracks. and novel capabilities (Brown et al., 2020; Weiet al., 2022), and are rapidly finding their way intoreal-world applications (OpenAI, 2022; Microsoft,2023; Google, 2024), they are also largely treatedas black boxes, which does not satisfy other ex-pectations for successful machine learning deploy-ment, such as trust, accountability, and explainabil-ity (Lipton, 2018; Goodman and Flaxman, 2017).In NLP research, these factors have motivated alarge body of work on interpretability and analysis(IA), which aims to understand the inner workingsof LLMs and explain their predictions (Belinkovand Glass, 2019; Rogers et al., 2020; Rauker et al.,2023, inter alia). Many researchers in this area be-lieve that better understanding LLMs is imperativeto improve their efficiency, robustness, and trust-worthiness, towards successful, safe deployment.IA research has thus witnessed rapid growth inrecent years and is now one of the biggest researchareas (in terms of number of publications andcitations) at major NLP conferences (see ). Despite the rapid growth of IA research (see also), a criticism of this work is that it of-ten lacks actionable insights, especially for howto improve models, and therefore has little im-pact on how new NLP models are designed andbuilt (Rauker et al., 2023; Rai et al., 2024). Thiscriticism raises questions about whether its currentform is the right path towards progress in NLP.In this work, we tackle these questions with asystematic, mixed-methods study of the impactof IA research on NLP in the past and the present,and use our findings to inform a vision for thefuture of IA. More specifically, we ask: how doesinterpretability and analysis research influenceNLP researchers in what they choose to workon, what they cite, and how they think aboutNLP altogether?We perform a bibliometric analysis of 185,384publications based on the two major NLP confer-ences, ACL and EMNLP, between 2018 and 2023,and solicit opinions from 138 members of the NLPcommunity via a survey. In addition to quantitativeresults, we perform qualitative analysis of surveyresponses and 556 papers. This approach gives us aholistic view of the impact of IA research on NLP.Our analysis reveals that (1) NLP researchersbuild on findings from IA work in their research,regardless of whether they work on IA themselvesor not (4), (2) NLP researchers and practitionersperceive IA work to be important for progress inNLP, multiple subfields, and their own work, forvarious reasons (5), and (3) many novel non-IAmethods are proposed based on IA findings andhighly influenced by them, for various areas, eventhough highly influential non-IA work is not drivenby IA findings despite citing them (6).While our findings show that IA work presentsinsightful observations, there are still opportuni-ties for greater impact on the rest of NLP. Thus,based on survey responses, we identify the key in-gredients that are missing in IA research today unification; actionable recommendations; human-centered, interdisciplinary work; and standardized,robust methods and close with a call to actionand recommendations (7). We hope our workpaves the way towards a more impactful future forIA research as the field continues to grow.",
  "Interpretability and analysis (IA) research": "Interpretability research has a long tradition inmachine learning as well adjacent fields likeNLP (Tishby and Zaslavsky, 2015; Karpathyet al., 2015; Kim et al., 2018, inter alia). Thereis no single agreed upon definition of the terminterpretability (see Lipton (2018) and Li et al.(2022) for a critical discussion), but two prominenttypes of interpretability research focus on post-hocexplainability or increasing the transparency ofmachine learning methods and models (Lipton,2018; Madsen et al., 2024). Analysis research isan even broader term and one might argue thatnearly every scientific paper contains some formof analysis. In NLP, however, many interpretabilityand analysis papers have in common that theirprimary contribution is an analysis that aims toadvance our understanding of NLP in some way,e.g., by analyzing methods, models, or algorithms(Belinkov and Glass, 2019; Rogers et al., 2020).Here, we adopt a broad definition of interpretabil-ity and analysis (IA) research in NLP that includesall papers that aim to develop a deeper under-standing of the behavior or inner workings ofNLP models, methods, or systems. This includeswork on explaining models predictions or inter-nal computations, investigating broader phenom-ena observed during pre-training or adaptation, andproviding a better understanding of the limitationsand robustness of existing models.",
  "Measuring impact": "Our goal is to measure the impact of IA work onNLP research, which is not trivial to define or quan-tify. For a holistic view of impact, we consider twocomplementary ways of measuring it a bibliomet-ric analysis, and a survey of the NLP community. Citational impactIn scientometrics research, ci-tation counts are used as a standard measure ofscientific impact (Nicolaisen, 2007; Bornmann andDaniel, 2008; Chacon et al., 2020, inter alia). Thus,we perform a bibliometric analysis to quantify thecitational impact of IA work on NLP research.2 Wenote that citation behavior is complex and there is agrowing consensus that citation statistics might notbe sufficient for measuring impact (Bornmann andDaniel, 2008; Zhu et al., 2015; Iqbal et al., 2021). 2This choice excludes other forms of impact such as in-creasing user trust, influencing policy and regulation, etc. Inaddition, even though IA work impacts other fields, this isbeyond the scope of our paper.",
  "/14/24, 5:10 AMcitation-graph": ": Diagram showing the process of constructing our citation graph. Starting from an initial set of ACL andEMNLP papers between 2018 and 2023, we collect their citations and references via the Semantic Scholar API andlabel the submission track of the papers with a classifier. Surveying the NLP communityTo incorporatea second dimension of impact beyond citationcounts, we survey NLP researchers and practition-ers on how they view the impact of IA research onthe field. Specifically, we ask respondents abouttheir perceptions of IA (its importance in general,for specific subfields, and its impact on progressin NLP), and their use of IA (how much they read,are influenced by, and use concepts from IA work).We also solicit opinions on what is missing in IAresearch and where it should go in the future.",
  "Citation graph construction": "As illustrates, we begin constructing ourcitation graph from an initial set of all papers pub-lished at ACL and EMNLP from 2018 to 2023. Wefocus on these two venues as they are leading NLPconferences with a dedicated track for interpretabil-ity and analysis research since 2020.3 We then usethe Semantic Scholar API (Kinney et al., 2023) toget all citations and references of these initial pa-pers, and add them to our citation graph. For papersoutside our initial set (where we have gold labels),we use a classifier to predict their submission track.More details on all these stages are provided below. Collecting ACL and EMNLP papersWe col-lect paper lists and track information from varioussources (see in Appendix A), as there is noone source of this data for ACL and EMNLP con-ferences. Between 2018 and 2023, official namesof submission tracks have changed substantially,so we standardize all data to 27 tracks. More de-tails on this process are provided in Appendix A,including summary statistics per track ().",
  "We discuss this decision in more detail in": "Building the citation graphWe collect thecitations and references of each paper in our initialset via the Semantic Scholar API (Kinney et al.,2023), resulting in a citation graph of 185,384papers (see in Appendix A for additionalstatistics). For each node (paper) in the graph,we store its title, abstract, and venue. For eachedge (citation), we store information on thecitation intent (binary labels for background, useof methods or comparing results), and citationinfluence (normal vs. highly influential), all ofwhich are provided by Semantic Scholar. Labeling the citation graphTo assign all pa-pers in the citation graph to our standardized set oftracks, we train a classifier based on the titles andabstracts from our initial set of papers. We find thatsome tracks are very hard to predict due to limitedtraining data and the inherent ambiguity of sub-mission tracks. We thus keep 11 well-performinglabels (including IA), and introduce an Other la-bel to group the remaining papers.Our final classifier achieves a test micro/macro-F1 score of 0.61/0.61. Although this appears low,we note that submission tracks have fuzzy bound-aries and papers can often be plausible submissionsto multiple tracks. Given that we care primarilyabout predicting IA compared to other tracks, weevaluate our classifier on two additional sets ofgold data, and obtain 78.1% and 87.8% accuracyon each set. We provide further details on classifierconstruction and evaluation, and we verify our find-ings with only gold labeled papers in Appendix A.",
  "Surveying the NLP community": "To solicit opinions from the NLP community onthe impact of IA research, we ran a survey fromMarch 19th to June 7th, 2024, advertising withinour networks, on social media, and on NLP mailinglists. The full survey is shown in Appendix B.To strike a balance between easy scoring and re-spondent expressivity, we included multiple-choice Phonology, Morphology and",
  "Large Language Models": "Interpretability and Analysis 0% 20% 40% 60% 80% Percentage of references to IA : Percentage of references to IA papers according to our classifiers prediction for different tracks. Thereare significant differences across tracks in how IA is cited. This is also true when only considering gold labels fortracks (see Appendix A.1).",
  "We begin by analyzing whether researchers usecontributions of IA research in their work. Weapproach this by analyzing citational use, as wellas survey-reported use beyond citations": "IA papers are cited more often than other tracksWhen comparing papers from different tracks,global counts of citations can be misleading, asa small number of papers can account for most ofthe citations in a field (Ioannidis et al., 2016). Toaccount for this, we compare citations based on theCitation Success Index (CSI; Milojevic et al., 2017)metric. Given two groups of papers A and B, theCSI score computes the probability that a randompaper from A is more cited than a random paper ofB. This score is not subject to biases from the skew-ness of the citation distribution, and it is clearly",
  ": Origin of citations to IA papers in our citationgraph. More citations come from non-IA work than IAwork, showing citational impact beyond the subfield": "interpretable; e.g., if we draw random IA and Ma-chine Translation papers from EMNLP or ACL in2023, there is a 57.1% chance that the IA paper ismore cited than the Machine Translation paper. shows that CSI scores for the IA trackare often favorable (CSI > 50%) when comparedto other tracks. In 2023, only the Ethics and theLarge Language Models tracks had favorable CSIscores when compared to IA. This shows that IA pa-pers have higher citational impact than other tracks. IA papers are well cited outside of IAWhilehigh CSI scores tell us that IA papers are citedwell, they do not tell us where these citations arecoming from, i.e., are IA papers mostly cited byother IA papers or by papers outside of IA? Toevaluate the impact of IA work outside of IA, wecompare citations within the same track, which wecall intra-track citations, to extra-track citations,i.e., citations from outside the track. shows that most citations to IA papersare predicted to be extra-track citations. The pro-portion of references to IA papers differs consid-erably by citing track, with papers about EfficientMethods, Machine Learning, and Large LanguageModels citing IA research more frequently than others (see ). While the IA track does notstand out in terms of its extra-track citations com-pared to other tracks (see ), these resultsstill demonstrate that the citational impact of IAresearch extends well beyond the IA track itself. IA papers are central in NLPNext, we assesswhether IA papers are impacting NLP as a wholerather than just specific tracks. We quantify thiswith the Betweenness Centrality (BC) metric, ameasure of interdisciplinarity (Leydesdorff, 2007;Barnett et al., 2011; Leydesdorff et al., 2018). BCquantifies the extent to which a node in the graphacts as a bridge along the shortest path between twoother nodes (Golbeck, 2015); nodes with higher BCare considered more important as more informationpasses through them.5 Therefore, we interpret pa-pers with a high BC as important papers that are es-sential for the connectivity of the citation network.We compute the BC for every paper in EMNLPand ACL since the IA track started (2020), and findthat the median BC of IA papers is higher than mostother tracks, at 1.23 107. Notably, IA ranks asthe second most central track overall, following theLarge Language Models track, which has a medianBC of 1.95 107. These results (shown in Fig-ure 10) provide further evidence that IA work playsa central role in the ACL/EMNLP citation network. IA influences the work of NLP researchersFora complementary view of impact beyond citations,we survey NLP community members on how oftenthey use concepts from IA in their day-to-day work,and more broadly, how IA influences their work.As shows, the median rating for use ofIA concepts by respondents who work on IA is of-ten, while even the median respondent who doesntwork on IA uses concepts from IA sometimes. Inboth groups of respondents, there are people whoalways use IA concepts in their day-to-day work.Beyond this, IA work influences respondents in dif-ferent ways: it provides respondents with researchideas (91% of respondents who work on IA; 60% ofrespondents who dont), changes mental models ofmodel capabilities and limitations (77%; 65%), andhelps ground explanations of respondents results(64%; 59%). Notably, only 9 (6.5%) respondentsstate that IA does not affect their work. These re-sults complement our citation-based findings byproviding further evidence that IA work impactsboth IA and non-IA researchers and their research.",
  "Researchers find IA work important": "We continue by surveying the perceived importanceof IA work by the NLP community. We considervarious perspectives, such as the perceived impor-tance of IA research on overall progress in NLPas well as on individual subfields. 133 out of 138respondents consider IA work important, and per-ceive it as important for progress in NLP, multiplesubfields, and for various reasons. Perceived importance for progress in NLPFig-ure 6 shows that most respondents agree that with-out IA findings, progress in NLP in the last 5 years(2019 to 2024) would have been slower, but not im-possible. Surprisingly, it appears that people whoare more deeply engaged with interpretability aremore critical of it. Respondents who read more IAwork than other topics in NLP, respondents who of-ten or always use concepts from IA literature, andrespondents who work on IA themselves all rate IAas having a lower impact on progress in NLP thanthose who read less IA, use related concepts lessfrequently, and who work on other topics.It is plausible that respondents who are moreengaged with IA work know it better and thusgive better-calibrated impressions of the field as awhole, which happen to be more critical. However,it is worth noting that they are perhaps formingtheir opinions from a different sample of papers(i.e., the average paper from a large body of work)than those who are less engaged with IA work,whose reading might be skewed towards IA workthat is more highly cited and influential. This alsoraises the question of how IA or indeed any sub-field should be evaluated by the average paper init, or by the ones that stand out? (Strongly disagree) (Strongly agree)",
  "Count": "progress w/o IA slowerimpossible :Survey responses (N=138) on whetherprogress in NLP in the last 5 years would have beenslower or impossible without findings from interpretabil-ity and analysis research. Respondents believe progressin NLP would be slower but not impossible without IA. There are many other factors that could also influ-ence the results we see, e.g., that respondents indifferent categories are reading IA papers that dealwith different topics, that they have different levelsof research experience, and that they have differ-ent definitions of progress in NLP. See 9 for adiscussion of these factors. Perceived importance for different subfields shows that the IA work is perceived asbeing important to differing extents for other sub-fields within NLP. The modal response is that IAwork is somewhat important for work on multilin-guality (52% of responses), multimodal learning(47%) and engineering for large language models(47%), and that it is very important for work on rea-soning (63%) and bias (72%). Of the five subfieldswe consider, engineering for LLMs is perceivedto be least impacted by IA work, with 31% of re-spondents indicating that they think IA work is notimportant for it. These findings are consistent withthe themes we find in papers that are highly influ-enced by IA research, where bias and reasoning arewell-represented, and pre-training and architecturaladvancements appear less frequently. Reasons for importanceWhen asked whetherthey thought IA work was important and if so,why, respondents overwhelmingly (133/138) con-sider it important, citing a variety of reasons, themost popular of which were: understanding modellimitations and capabilities (90% of respondents),explainability for users (66%), improving modeltrustworthiness (59%), and improving model capa-bilities (50%). While a small percentage (4.3%)of respondents indicated that they thought it wasnot important (possibly also due to selection biasin our survey), we found that they voice the sameconcerns as those who do find it important, e.g., a",
  "A closer look at influential papers": "So far we have discussed findings about IA as awhole, either by considering the role of IA papers inthe ACL/EMNLP citation graph or the perceptionof IA work within the community. In this section,we zoom in on specific influential papers sourcedfrom both our survey and citation graph. We seekto answer: What are these papers about? Whatkind of work are they impacting, and how?To this end, we inductively obtain the themes ofa total of 585 papers, through qualitative codingof their titles and abstracts by two authors (Sal-dana, 2021).The 585 papers include: (1) Allpapers mentioned more than once as having in-fluenced survey respondents work (N=29); (2)highly-cited IA papers from our citation graph(N=50); (3) highly-cited non-IA papers from our ci-tation graph (N=50); (4) non-IA papers that cite andare highly influenced by the top-10 most-cited IApapers (N=456). The resulting themes are mostlydescriptive, including topics (e.g., in-context learn-ing, training dynamics) and contribution types (e.g.,novel method, analysis). Percentage agreement onour coded themes is above 90% for each subset ofpapers. See Appendix C for more details.Our analysis reveals that beyond backgroundcitations, IA work influences the development ofmany novel models and metrics outside of IA work,and affects work in domains such as question an-swering (QA), reasoning, and bias. What are influential IA papers about?Ofthe papers that survey respondents submitted asexamples of work that has directly influencedtheir own work, representation analysis appearsin over a third of the papers, novel methods forinterpretability (e.g.,causality,interventions,steering, neuron/activation analysis, etc.)areproposed in nearly a quarter of them, and probingalso appears in 24% of these papers.In contrast, the top-50 most cited IA papers aremore often about the analysis component of IA(40%). Novel methods (for analysis, evaluation,linguistics, probing) are proposed in 26% ofpapers, and evaluation is a main contribution of32%. As expected, the most cited non-IA papersin our citation graph mostly consist of highlyinfluential datasets, models, and methods, e.g.,HotpotQA, BART, prefix-tuning (Yang et al., 2018;Lewis et al., 2020; Li and Liang, 2021). More topthemes are shown with the percentage of papersin in Appendix D.We also find evidence that many IA paperscreate novel metaphors to understand models e.g., seeing feed-forward layers as key-valuememories (Geva et al., 2021), or reading fromand writing to the residual stream (Elhage et al.,2021), and many analysis papers highlight thelimits of models.As survey respondents citedthese very reasons for why they perceive IA workas important, these themes corroborate why thesepapers would be particularly influential. In addi-tion, many of the qualities that survey respondentsfeel are currently lacking in IA research (see 7)appear in these papers, such as moving beyondtoy models (Wang et al., 2023), and providingactionable methods (Meng et al., 2022). Why are influential IA papers cited?Ascitations can have a variety of reasons (Zhuet al., 2015; Tahamtan and Bornmann, 2019),we examine three types of citational intent background, methods and results citations (see in Appendix D). Overall, we find thatinfluential IA papers are cited most often asbackground citations, then as methods citations,and least frequently when comparing results. Incomparison, highly cited papers that are not aboutIA tend to be cited most frequently for methods.This is expected, as many of these papers are aboutpopular datasets and models, as described above.",
  "What are the citing papers about?Despite thelarge number of background citations, however,": "there is plenty of workincluding non-IA workthat is highly influenced (according to SemanticScholar) by IA research. For a closer look at whatthese citing papers do, we analyze all 456 paperswith highly influential citations to one of the top10 most-cited IA papers, and annotate their themesbased on titles and abstracts.Unsurprisingly, many of the papers have themesin common with what they cite, e.g., papers thatanalyze multilingual models are frequently citedby papers on cross-lingual transfer. We thus fo-cus on the difference in themes between citing pa-pers and cited papers, and find that over 33% ofnon-IA papers that are highly influenced by IAwork propose novel methods, e.g., many novelICL methods cite analysis work on demonstrations(Min et al., 2022) and similarly, many novel meth-ods for bias mitigation cite datasets for stereotypeevaluation such as Nangia et al. (2020) and Nadeemet al. (2021). These provide concrete counterexam-ples to the claim that IA work does not influencemodeling improvements. Is IA work impacting highly cited non-IA work?Looking at the highly-cited non-IA papers, wefind that these too tend to cite IA work frequently.22 out of the top 50 most cited non-IA papers areeven highly influenced by some IA work, but 28are not highly influenced by any IA work. Theseresults show that while highly influential non-IAwork does acknowledge IA findings, it is likely notdriven by them.",
  "We end by discussing our main findings and recom-mendations on how to move IA research forward": "Main takeawaysIn 4, we saw that IA researchplays a central role in NLP and researchers build onfindings from IA work in their research, regardlessof whether or not they work on IA themselves. In5, we saw that NLP researchers and practitionersperceive IA work to be important for progress inNLP, and multiple subfields. They also find it im-portant for their own work for a variety of reasons,regardless of whether they work on IA themselves.Finally, we took a closer look at the most influentialIA papers in 6 and found that many novel methodsare proposed based on IA findings and highly in-fluenced by them, for various areasin particular,work on reasoning, factual knowledge, and bias.All these findings present a very positive view of",
  "IA research and its role within NLP in the past andthe present. In the remainder of this section, weturn to the future of IA research": "What is missing?To understand what the NLPcommunity believes to be important for the futureof IA work, we asked survey respondents what theyfeel is missing in current IA work and what shouldbe different going forward. 25% of the responsesto this question mentioned a lack of big picture andunified understanding in IA work. For example,one respondent said:",
  "I think the focus should be on climb-ing the right hill towards a higher levelunderstanding instead of focusing on in-teresting individual behaviors": "The next three most frequent concerns are a lack ofutility (i.e., not being useful in practice), modelingimprovements and actionabilityconcerns that arealso echoed by the respondents who do not find IAresearch useful for their own work. Interestingly, acommonly voiced opinion among these participantsis that they believe that scale and performance areall that is needed for good NLP models, and thatIA work only has importance for understandingmodels rather than for building them. Addition-ally, respondents mention that IA work could usemore interdisciplinary connections, through col-laboration with domain experts, user studies, andhuman-centered approaches to computing.Finally, we note another theme appearing in 10%of responses: as IA has a lack of consensus onreliable and trustworthy methods, it is unclear howsuch work should be evaluated. Although this isnot a new concern (Belinkov and Glass, 2019), itremains relevant for the impact of IA on NLP.",
  "Concretely, big-picture thinking (1) involvesworking towards general truths about model archi-tectures or behaviors, rather than model-specificresults.Future work should try to synthesize": "existing strands of research to unify their findingsand viewpoints. An example of what this mightlook like outside IA research is He et al. (2022).Actionable work (2) requires thinking abouthow an IA finding can propel new ways of build-ing/using NLP systems, rather than merely beingdescriptive. More specific examples of this includeresearch that uses interpretability findings to, e.g.,improve the fairness of NLP systems, or make NLPmodels more efficient and robust.Centering humans (3) entails evaluation with re-alistic, relevant data and tasks, and performing userstudies and human evaluation. Human-centeredIA work can also be enhanced through interdisci-plinary reading and collaboration. An example forresearch that falls under this category is Ivanovaet al. (2024), which proposes a cognition-inspiredframework for evaluating LLM world knowledge.Finally, we urgently need to build consensus onusing and evaluating IA methods (4). Rigorous,well-motivated methods (e.g., using causality) arecritical, rather than correlative evidence that maynot be correct or faithful. We believe that stan-dardized, robust and widely accepted methods willincrease trust in IA work, and lead to the easier andwider adoption of IA methods.Due to the constraints of space and time, we notethat it would be difficult for one work to address allthese points while still making a focused contribu-tion. Thus, we stress that our call to action is for IAresearch as a whole to revisit its priorities, ratherthan a checklist for individual papers to address. IA for its own sakeIn closing, we would like tohighlight a viewpoint that came up multiple timesin survey responses, which was to question thepremise of this paper, i.e., to measure the impact ofIA on NLP. Many respondents noted that they seeIA work as being a valuable scientific pursuit in itsown right, stating that Without it, were not doingscience, or Its cool! Thats enough for me. Re-spondents further criticized the often performance-focused definitions of utility, progress, and impact.One respondent noted that these definitions of util-ity have been determined by extrinsic sociologicalfactors in the broader field of AI. We sympathizewith this observation and note that the focus onperformance is a feature of NLP at this point intime. What we value might change going forward,especially as NLP systems are increasingly part ofour daily lives, and qualities such as robustness andfairness become even more important.",
  "Related work": "The increasing number of IA publications duringthe last few years has resulted in several surveyor position papers that critically discuss existingwork, identify common patterns, and providesuggestions for how to go forward. Lipton (2018)critically questions common motivations behindinterpretability and the lack of definitions in thefield. Following their recommendation, we providea definition of what we consider interpretabilityand analysis research in 2. Belinkov and Glass(2019) summarize trends in early IA work anddiscuss recommendations for how to overcomethe limitations of IA research.Similar to ourwork, they recommend that future work shouldthink about better ways to evaluate IA researchand findings.Rogers et al. (2020) survey andsynthesize IA work on BERTology, a subfield ofIA work that focuses on encoder-only languagemodels. Rauker et al. (2023) survey a large numberof papers that study the internals of languagemodels (transparency), and discuss key challengesin the field. Like us, they also argue for better waysof evaluating IA methods, as well as more action-ability and grounding in real-world applications.More recently, Madsen et al. (2024) discuss twoprominent trends in interpretability research (post-hoc explanations and intrinsic interpretability) andargue that interpretability (the study of explainingmodels in understandable terms to humans) needsa new paradigm centered around faithfulness.Several other works study citational patterns andtrends within the broader NLP community. Mo-hammad (2020) uses citations to measure the im-pact of NLP publications indexed by the ACL An-thology. Like us, they compare how well papersfrom different areas within NLP are cited, and usecitation statistics to draw conclusions about the im-pact of different subfields within NLP. Singh et al.(2023) use citations as an indicator for how widelythe community is reading. They demonstrate a re-cency bias in citation behavior with a study of tem-poral citation trends, i.e., a majority of cited papersfall within a five year time period before publica-tion of the citing work. Wahle et al. (2023) analyzethe influence between NLP and other fields over theyears. Also using Semantic Scholar, they rely oncitations to conclude that NLP has become moreinsular over time. Similarly, Subramonian et al.(2024) find low levels of extra-disciplinary citationwhen analyzing how NLP and ML researchers dis- cuss democracy. More specific to IA, Jacovi (2023)uses Semantic Scholar to curate a large number ofpapers focusing on explainability, studying citationtrends in the field based on this collection.Another set of related papers surveys the NLPcommunity for their perceptions and opinions, amethod we also use. Gururaja et al. (2023), for ex-ample, focus on paradigm shifts and study factorsthat shape NLP as a field. They conduct interviewswith NLP researchers and experts and gather theiropinions on critical trends and patterns that emergein the field. Pramanick et al. (2023) also focus onparadigm shifts and impact, but from a diachronicperspective. They provide a novel framework tostudy the evolution of research topics within a fieldto establish what drives research in NLP acrosstime, and they find that tasks and methods have abigger impact on the field than metrics do.Lastly, there are several papers in the scientomet-rics literature that study and compare the impactof research using the same metrics as we do: Cha-con et al. (2020) apply the citation success indexto compare sub-fields in physics, and Leydesdorff(2007) propose the use of Betweenness Centralityas a measure of the interdisciplinarity of journals.",
  "Conclusion": "We contribute a mixed-methods analysis of the im-pact of interpretability and analysis research onNLP. By analyzing a citation graph of 185K+ pa-pers built from all papers published at ACL andEMNLP from 2018 to 2023, surveying 138 respon-dents from the NLP community, and manually an-notating 556 papers, we found that IA work is well-cited in other subfields of NLP, central to the NLPcitation graph, and highly influential to many novelmethods. NLP researchers and practitioners per-ceive IA work as important for progress in NLP,multiple subfields (especially reasoning and fair-ness), and for their own work. In sum, even thoughhighly influential models, methods and datasets arenot driven by IA findings, IA work still has a greatimpact on NLP in the past and the present. We con-clude with a call to action based on what is missingin the subfield, to pave the way for IA work to beeven more impactful in the future.",
  "Focus on papers published at ACL and EMNLPAlthough ACL and EMNLP are the most cited*CL venues (Mohammad, 2020), our analysis ex-": "cludes several other big NLP venues, includingEACL, NAACL, AACL, TACL, and BlackboxNLP,a workshop which focuses on IA work. Addition-ally, given the growing interest in NLP, and in par-ticular, LLMs, from the broader machine learningcommunity, there is an increasing number of IApapers published at machine learning conferencessuch as ICLR, NeurIPS, and ICML, which we alsodo not consider in our analyses. Similarly, a vastamount of work on mechanistic interpretability hasbeen published as articles (e.g., on LessWrong6 and the AI Alignment Forum7), and blog posts(e.g., by Anthropic8). Therefore, there is a risk thatour analysis misses potentially influential IA workpublished at these venues.This is mitigated to an extent by our survey,where respondents mention some of these papersand blog posts, which we then discuss in our pa-per. In addition, the set of papers we consider forour analysis is very large (our initial set contains477 IA papers). This makes us confident that thefindings we draw from these papers (and those cit-ing them) are representative of broader trends inthe impact of IA research in NLP. We leave it tofuture work to investigate the impact of IA workpublished outside of established NLP venues. Focus on 2018 to 2024As our analysis focuseson papers published between 2018 and 2024, ourresults represent a snapshot in time on the scaleof research in NLP, where models and methodscome and go. The time period that we look at isdominated by transformer-based language models,and a paradigm of using large, general-purposepre-trained models for many tasks, and thus manyIA papers focus on studying these. Understandingthis as the context of our analysis and results isimportant, as they may look completely differentin a time period where the most popular modelsand IA methods are different. This also means thatour results cannot speak to the impact of todays IAwork, which will only become clear in the future. Not all citations are equalAlthough our useof citations is an important component of how wequantify impact in this paper, we do not consider ci-tational context or distinguish between types of cita-tions. However, papers can be cited for a number ofreasons (Bornmann and Daniel, 2008), not all posi-tive and not all having to do with the conventions of",
  "scholarly publishing (Bornmann and Daniel, 2008;Zhu et al., 2015; Bornmann and Marx, 2012)": "Limitations of this surveyAs with all surveys,our survey results might be subject to selectionbias. To mitigate this risk, we took the followingsteps: (1) We used public mailing lists such ascorpora-list to advertise our survey outside our per-sonal networks. (2) Our social media and academicnetworks are diverse as we are authors from fourdifferent institutions, covering four different conti-nents, and we are at various career stages (Mastersstudent, PhD candidate, postdoctoral researcher,assistant professor, and full professor). (3) We tar-geted 100+ survey responses (and received 138).Despite our efforts to get a large number and diver-sity of responses, they may not be representativeof the field as a whole. In particular, full profes-sors (N=5, at various career stages), and industrypractitioners who are not researchers (N=1) weresomewhat underrepresented in our responses, in-dicating that our results focus more on researchimpact rather than impact on industry applications,and are mostly shaped by PhD students (41.3% ofrespondents), whose interests, incentives, and as-sessment of impact are sure to be different fromrespondents at other career stages.As for survey content, some respondents broughtup the following concerns about our design choices:one respondent felt our definition of IA was toobroad for their taste, but our inclusion of inter-pretability and analysis was by design (see Sec-tion 3). Another respondent noted that we definedIA but not what we meant by progress, whichwas also by design, as we did not want to impose anormative definition of progress on our respondentsbut rather, get at their own intuitions, regardless ofhow they might define progress. Finally, one re-spondent complained that our questions about theusefulness of IA (to various subfields, on ones ownresearch, etc.) were framed in absolute rather thanrelative terms, and that just because IA research hassome positive impact on our understanding doesntmean that it is the best option to pursue given lim-ited time and resources. This paper presents viewsof absolute and relative impact via the survey andcitation graph analyses, for a holistic view of IAresearch that also allows for it to have value forits own sake. Ultimately, we believe that a viewof optimal impact compared to other options liesin the eye of the beholder, and is one (but not theonly) way of interpreting our results. We are grateful to Julian Schnitzler, Maor Ivgi, SivaReddy, Vlad Niculae, Yanai Elazar, and YonatanBelinkov for their feedback on the survey, as wellas Asma Ghandeharioun, Yanai Elazar, and Sab-rina Mielke for their feedback on the manuscript.We would like to thank Anna Rogers, David Chi-ang, Fei Xia, Henning Wachsmuth, Jordan LeeBoyd-Graber, Juan Pino, Naoaki Okazaki, RacheleSprugnoli, and Scott Yih, for their help in provid-ing us with ACL and EMNLP track data. Finally,we thank all our survey respondents, including,among others: AG, AW, Aaron Mueller, AengusLynch, Alessandro Stolfo, Alon Jacovi, AnubrataDas, Aryaman Arora, Avi Caciularu, BenjaminMinixhofer, Bhawna Paliwal, Christopher Potts,Chunyuan Deng, Daniel C.H. Tan, Daniel Scalena,Dashiell Stander, David Adelani, David Bau, DavidChanin, Diego Garcia-Olano, Emilio Villa-Cueva,Eran Hirsch, Eva Portelance, Felix Beierle, FlorianSchneider, Gabriele Sarti, Guanlin Li, Jaap Jumelet,Jack Merullo, Jiahao Huang, Jonathan Zea, JulianSchnitzler, Keshav Ramji, Leshem Choshen, Lu-cas E. Resck, Margarita Bugueo, Miaoran Zhang,Mircea Petrache, Natalie Shapira, Nils Feldhus,Noah Y. Siegel, Ori Ram, Paulina, Peter Hase, Qi-nan Yu, Ricardo Cuervo, Roma Patel, SebastianBreguel, Tian Yun, Tomasz Limisiewicz, VaidehiPatil, Victor Faraggi, Wentao Wang, Yeo Wei Jie,Yindong Wang, Yonathan Arbel, and Yuval Pinter.TVB was funded by the Centro Nacional deInteligencia Artificial, CENIA, FB210017, BasalANID, MM was supported by the Mila-Samsunggrant, and VG was funded by the BMBFs (GermanFederal Ministry of Education and Research) SLIKproject under the grant 01IS22015C.",
  "Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, RussAltman, Simran Arora, Sydney von Arx, Michael S": "Bernstein, Jeannette Bohg, Antoine Bosselut, EmmaBrunskill, Erik Brynjolfsson, Shyamal Buch, DallasCard, Rodrigo Castellon, Niladri Chatterji, AnnieChen, Kathleen Creel, Jared Quincy Davis, DoraDemszky, Chris Donahue, Moussa Doumbouya,Esin Durmus, Stefano Ermon, John Etchemendy,Kawin Ethayarajh, Li Fei-Fei, Chelsea Finn, TrevorGale, Lauren Gillespie, Karan Goel, Noah Goodman,Shelby Grossman, Neel Guha, Tatsunori Hashimoto,Peter Henderson, John Hewitt, Daniel E. Ho, JennyHong, Kyle Hsu, Jing Huang, Thomas Icard, SaahilJain, Dan Jurafsky, Pratyusha Kalluri, SiddharthKaramcheti, Geoff Keeling, Fereshte Khani, OmarKhattab, Pang Wei Koh, Mark Krass, Ranjay Kr-ishna, Rohith Kuditipudi, Ananya Kumar, Faisal Lad-hak, Mina Lee, Tony Lee, Jure Leskovec, IsabelleLevent, Xiang Lisa Li, Xuechen Li, Tengyu Ma,Ali Malik, Christopher D. Manning, Suvir Mirchan-dani, Eric Mitchell, Zanele Munyikwa, Suraj Nair,Avanika Narayan, Deepak Narayanan, Ben Newman,Allen Nie, Juan Carlos Niebles, Hamed Nilforoshan,Julian Nyarko, Giray Ogut, Laurel Orr, Isabel Pa-padimitriou, Joon Sung Park, Chris Piech, Eva Porte-lance, Christopher Potts, Aditi Raghunathan, RobReich, Hongyu Ren, Frieda Rong, Yusuf Roohani,Camilo Ruiz, Jack Ryan, Christopher R, DorsaSadigh, Shiori Sagawa, Keshav Santhanam, AndyShih, Krishnan Srinivasan, Alex Tamkin, RohanTaori, Armin W. Thomas, Florian Tramr, Rose E.Wang, William Wang, Bohan Wu, Jiajun Wu, YuhuaiWu, Sang Michael Xie, Michihiro Yasunaga, Jiax-uan You, Matei Zaharia, Michael Zhang, TianyiZhang, Xikun Zhang, Yuhui Zhang, Lucia Zheng,Kaitlyn Zhou, and Percy Liang. 2022. On the op-portunities and risks of foundation models. Preprint,arXiv:2108.07258.",
  "Lutz Bornmann and Werner Marx. 2012. The annakarenina principle: A way of thinking about successin science. Journal of the American Society for Infor-mation Science and Technology, 63(10):20372051": "Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, ClemensWinter, Chris Hesse, Mark Chen, Eric Sigler, Ma-teusz Litwin, Scott Gray, Benjamin Chess, JackClark, Christopher Berner, Sam McCandlish, AlecRadford, Ilya Sutskever, and Dario Amodei. 2020.Language models are few-shot learners.In Ad-vances in Neural Information Processing Systems,volume 33, pages 18771901. Curran Associates,Inc.",
  "Arman Cohan, Sergey Feldman, Iz Beltagy, DougDowney, and Daniel S Weld. 2020.Specter:Document-levelrepresentationlearningusingcitation-informed transformers.arXiv preprintarXiv:2004.07180": "Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. BERT: Pre-training ofdeep bidirectional transformers for language under-standing. In Proceedings of the 2019 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, Volume 1 (Long and Short Papers), pages41714186, Minneapolis, Minnesota. Association forComputational Linguistics. Nelson Elhage, Neel Nanda, Catherine Olsson, TomHenighan, Nicholas Joseph, Ben Mann, AmandaAskell, Yuntao Bai, Anna Chen, Tom Conerly,Nova DasSarma, Dawn Drain, Deep Ganguli, ZacHatfield-Dodds, Danny Hernandez, Andy Jones,Jackson Kernion, Liane Lovitt, Kamal Ndousse,Dario Amodei, Tom Brown, Jack Clark, Jared Ka-plan, Sam McCandlish, and Chris Olah. 2021. Amathematical framework for transformer circuits.Transformer Circuits Thread. Https://transformer-circuits.pub/2021/framework/index.html. Mor Geva, Roei Schuster, Jonathan Berant, and OmerLevy. 2021. Transformer feed-forward layers are key-value memories. In Proceedings of the 2021 Confer-ence on Empirical Methods in Natural Language Pro-cessing, pages 54845495, Online and Punta Cana,Dominican Republic. Association for ComputationalLinguistics.",
  "Google. 2024. Generative ai in search: Let google dothe searching for you": "Sireesh Gururaja, Amanda Bertsch, Clara Na, DavidWidder, and Emma Strubell. 2023.To build ourfuture, we must know our past: Contextualizingparadigm shifts in natural language processing. InProceedings of the 2023 Conference on EmpiricalMethods in Natural Language Processing, pages1331013325, Singapore. Association for Compu-tational Linguistics. Junxian He, Chunting Zhou, Xuezhe Ma, Taylor Berg-Kirkpatrick, and Graham Neubig. 2022. Towards aunified view of parameter-efficient transfer learning.In International Conference on Learning Representa-tions.",
  "John PA Ioannidis, Kevin Boyack, and Paul F Wouters.2016. Citation metrics: a primer on how (not) tonormalize. PLoS biology, 14(9):e1002542": "Sehrish Iqbal, Saeed-Ul Hassan, Naif Radi Aljohani,Salem Alelyani, Raheel Nawaz, and Lutz Bornmann.2021. A decade of in-text citation analysis based onnatural language processing and machine learningtechniques: an overview of empirical studies. Scien-tometrics, 126(8):65516599. Anna A. Ivanova, Aalok Sathe, Benjamin Lipkin, Un-nathi Kumar, Setayesh Radkani, Thomas H. Clark,Carina Kauf, Jennifer Hu, R. T. Pramod, GabrielGrand, Vivian Paulun, Maria Ryskina, Ekin Akyrek,Ethan Wilcox, Nafisa Rashid, Leshem Choshen,Roger Levy, Evelina Fedorenko, Joshua Tenenbaum,and Jacob Andreas. 2024. Elements of world knowl-edge (ewok): A cognition-inspired framework forevaluating basic world knowledge in language mod-els. Preprint, arXiv:2405.09605.",
  "Deep sparse coding for invariant multimodal halleberry neurons. Preprint, arXiv:1711.07998": "Rodney Michael Kinney, Chloe Anastasiades, Rus-sell Authur, Iz Beltagy, Jonathan Bragg, Alexan-dra Buraczynski, Isabel Cachola, Stefan Candra, Yo-ganand Chandrasekhar, Arman Cohan, Miles Craw-ford, Doug Downey, Jason Dunkelberger, Oren Et-zioni, Rob Evans, Sergey Feldman, Joseph Gorney,David W. Graham, F.Q. Hu, Regan Huff, Daniel King,Sebastian Kohlmeier, Bailey Kuehl, Michael Langan,Daniel Lin, Haokun Liu, Kyle Lo, Jaron Lochner,Kelsey MacMillan, Tyler C. Murray, ChristopherNewell, Smita R Rao, Shaurya Rohatgi, Paul Sayre,Zejiang Shen, Amanpreet Singh, Luca Soldaini, Shiv-ashankar Subramanian, A. Tanaka, Alex D Wade,Linda M. Wagner, Lucy Lu Wang, Christopher Wil-helm, Caroline Wu, Jiangjiang Yang, Angele Zamar-ron, Madeleine van Zuylen, and Daniel S. Weld. 2023.The semantic scholar open data platform. ArXiv,abs/2301.10140. Mike Lewis, Yinhan Liu, Naman Goyal, MarjanGhazvininejad, Abdelrahman Mohamed, Omer Levy,Veselin Stoyanov, and Luke Zettlemoyer. 2020.BART: Denoising sequence-to-sequence pre-trainingfor natural language generation, translation, and com-prehension. In Proceedings of the 58th Annual Meet-ing of the Association for Computational Linguistics,pages 78717880, Online. Association for Computa-tional Linguistics. Loet Leydesdorff. 2007. Betweenness centrality as anindicator of the interdisciplinarity of scientific jour-nals. Journal of the American Society for InformationScience and Technology, 58(9):13031319. Loet Leydesdorff, Caroline S Wagner, and Lutz Born-mann. 2018. Betweenness and diversity in journal ci-tation networks as measures of interdisciplinarityatribute to eugene garfield. Scientometrics, 114:567592. Xiang Lisa Li and Percy Liang. 2021. Prefix-tuning:Optimizing continuous prompts for generation. InProceedings of the 59th Annual Meeting of the Asso-ciation for Computational Linguistics and the 11thInternational Joint Conference on Natural LanguageProcessing (Volume 1: Long Papers), pages 45824597, Online. Association for Computational Lin-guistics. Xuhong Li, Haoyi Xiong, Xingjian Li, Xuanyu Wu,Xiao Zhang, Ji Liu, Jiang Bian, and Dejing Dou.2022. Interpretable deep learning: interpretation,interpretability, trustworthiness, and beyond. Knowl.Inf. Syst., 64(12):31973234.",
  "Stasa Milojevic, Filippo Radicchi, and Judit Bar-Ilan.2017. Citation success index - an intuitive pair-wisejournal comparison metric. Journal of Informetrics,11(1):223231": "Sewon Min, Xinxi Lyu, Ari Holtzman, Mikel Artetxe,Mike Lewis, Hannaneh Hajishirzi, and Luke Zettle-moyer. 2022. Rethinking the role of demonstrations:What makes in-context learning work? In Proceed-ings of the 2022 Conference on Empirical Methods inNatural Language Processing, pages 1104811064,Abu Dhabi, United Arab Emirates. Association forComputational Linguistics. Saif M. Mohammad. 2020. Examining citations of nat-ural language processing literature. In Proceedingsof the 58th Annual Meeting of the Association forComputational Linguistics, pages 51995209, On-line. Association for Computational Linguistics.",
  "Moin Nadeem, Anna Bethke, and Siva Reddy. 2021": "StereoSet: Measuring stereotypical bias in pretrainedlanguage models. In Proceedings of the 59th AnnualMeeting of the Association for Computational Lin-guistics and the 11th International Joint Conferenceon Natural Language Processing (Volume 1: LongPapers), pages 53565371, Online. Association forComputational Linguistics. Nikita Nangia, Clara Vania, Rasika Bhalerao, andSamuel R. Bowman. 2020. CrowS-pairs: A chal-lenge dataset for measuring social biases in maskedlanguage models. In Proceedings of the 2020 Con-ference on Empirical Methods in Natural LanguageProcessing (EMNLP), pages 19531967, Online. As-sociation for Computational Linguistics.",
  "OpenAI. 2022. Introducing chatgpt": "OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal,Lama Ahmad, Ilge Akkaya, Florencia Leoni Ale-man, Diogo Almeida, Janko Altenschmidt, Sam Alt-man, Shyamal Anadkat, Red Avila, Igor Babuschkin,Suchir Balaji, Valerie Balcom, Paul Baltescu, Haim-ing Bao, Mohammad Bavarian, Jeff Belgum, Ir-wan Bello, Jake Berdine, Gabriel Bernadett-Shapiro,Christopher Berner, Lenny Bogdonoff, Oleg Boiko,Madelaine Boyd, Anna-Luisa Brakman, Greg Brock-man, Tim Brooks, Miles Brundage, Kevin Button,Trevor Cai, Rosie Campbell, Andrew Cann, BrittanyCarey, Chelsea Carlson, Rory Carmichael, BrookeChan, Che Chang, Fotis Chantzis, Derek Chen, SullyChen, Ruby Chen, Jason Chen, Mark Chen, BenChess, Chester Cho, Casey Chu, Hyung Won Chung,Dave Cummings, Jeremiah Currier, Yunxing Dai,Cory Decareaux, Thomas Degry, Noah Deutsch,Damien Deville, Arka Dhar, David Dohan, SteveDowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti,Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix,Simn Posada Fishman, Juston Forte, Isabella Ful-ford, Leo Gao, Elie Georges, Christian Gibson, VikGoel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, ScottGray, Ryan Greene, Joshua Gross, Shixiang ShaneGu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris,Yuchen He, Mike Heaton, Johannes Heidecke, ChrisHesse, Alan Hickey, Wade Hickey, Peter Hoeschele,Brandon Houghton, Kenny Hsu, Shengli Hu, XinHu, Joost Huizinga, Shantanu Jain, Shawn Jain,Joanne Jang, Angela Jiang, Roger Jiang, HaozhunJin, Denny Jin, Shino Jomoto, Billie Jonn, Hee-woo Jun, Tomer Kaftan, ukasz Kaiser, Ali Ka-mali, Ingmar Kanitscheider, Nitish Shirish Keskar,Tabarak Khan, Logan Kilpatrick, Jong Wook Kim,Christina Kim, Yongjik Kim, Jan Hendrik Kirch-ner, Jamie Kiros, Matt Knight, Daniel Kokotajlo,ukasz Kondraciuk, Andrew Kondrich, Aris Kon-stantinidis, Kyle Kosic, Gretchen Krueger, VishalKuo, Michael Lampe, Ikai Lan, Teddy Lee, JanLeike, Jade Leung, Daniel Levy, Chak Ming Li,Rachel Lim, Molly Lin, Stephanie Lin, MateuszLitwin, Theresa Lopez, Ryan Lowe, Patricia Lue,Anna Makanju, Kim Malfacini, Sam Manning, TodorMarkov, Yaniv Markovski, Bianca Martin, KatieMayer, Andrew Mayne, Bob McGrew, Scott MayerMcKinney, Christine McLeavey, Paul McMillan,Jake McNeil, David Medina, Aalok Mehta, JacobMenick, Luke Metz, Andrey Mishchenko, PamelaMishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg Murk, DavidMly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak,Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh,Long Ouyang, Cullen OKeefe, Jakub Pachocki, AlexPaino, Joe Palermo, Ashley Pantuliano, Giambat-tista Parascandolo, Joel Parish, Emy Parparita, AlexPassos, Mikhail Pavlov, Andrew Peng, Adam Perel-man, Filipe de Avila Belbute Peres, Michael Petrov,Henrique Ponde de Oliveira Pinto, Michael, Poko-rny, Michelle Pokrass, Vitchyr H. Pong, Tolly Pow-ell, Alethea Power, Boris Power, Elizabeth Proehl,Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh,Cameron Raymond, Francis Real, Kendra Rimbach,Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-der, Mario Saltarelli, Ted Sanders, Shibani Santurkar,Girish Sastry, Heather Schmidt, David Schnurr, JohnSchulman, Daniel Selsam, Kyla Sheppard, TokiSherbakov, Jessica Shieh, Sarah Shoker, PranavShyam, Szymon Sidor, Eric Sigler, Maddie Simens,Jordan Sitkin, Katarina Slama, Ian Sohl, BenjaminSokolowsky, Yang Song, Natalie Staudacher, Fe-lipe Petroski Such, Natalie Summers, Ilya Sutskever,Jie Tang, Nikolas Tezak, Madeleine B. Thompson,Phil Tillet, Amin Tootoonchian, Elizabeth Tseng,Preston Tuggle, Nick Turley, Jerry Tworek, Juan Fe-lipe Cern Uribe, Andrea Vallone, Arun Vijayvergiya,Chelsea Voss, Carroll Wainwright, Justin Jay Wang,Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei,CJ Weinmann, Akila Welihinda, Peter Welinder, Ji-ayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner,Clemens Winter, Samuel Wolrich, Hannah Wong,Lauren Workman, Sherwin Wu, Jeff Wu, MichaelWu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qim-ing Yuan, Wojciech Zaremba, Rowan Zellers, ChongZhang, Marvin Zhang, Shengjia Zhao, TianhaoZheng, Juntang Zhuang, William Zhuk, and Bar-ret Zoph. 2024. Gpt-4 technical report. Preprint,arXiv:2303.08774.",
  "Arjun Subramonian, Vagrant Gautam, Dietrich Klakow,and Zeerak Talat. 2024.Understanding \"democ-ratization\" in NLP and ML research.Preprint,arXiv:2406.11598": "Iman Tahamtan and Lutz Bornmann. 2019. What do ci-tation counts measure? an updated review of studieson citations in scientific documents published be-tween 2006 and 2018. Scientometrics, 121(3):16351684. Gemini Team, Rohan Anil, Sebastian Borgeaud, Jean-Baptiste Alayrac, Jiahui Yu, Radu Soricut, JohanSchalkwyk, Andrew M. Dai, Anja Hauth, KatieMillican, David Silver, Melvin Johnson, IoannisAntonoglou, Julian Schrittwieser, Amelia Glaese,Jilin Chen, Emily Pitler, Timothy Lillicrap, Ange-liki Lazaridou, Orhan Firat, James Molloy, MichaelIsard, Paul R. Barham, Tom Hennigan, BenjaminLee, Fabio Viola, Malcolm Reynolds, YuanzhongXu, Ryan Doherty, Eli Collins, Clemens Meyer, ElizaRutherford, Erica Moreira, Kareem Ayoub, MeghaGoel, Jack Krawczyk, Cosmo Du, Ed Chi, Heng-Tze Cheng, Eric Ni, Purvi Shah, Patrick Kane, BettyChan, Manaal Faruqui, Aliaksei Severyn, HanzhaoLin, YaGuang Li, Yong Cheng, Abe Ittycheriah,Mahdis Mahdieh, Mia Chen, Pei Sun, Dustin Tran,Sumit Bagri, Balaji Lakshminarayanan, Jeremiah Liu, Andras Orban, Fabian Gra, Hao Zhou, Xiny-ing Song, Aurelien Boffy, Harish Ganapathy, StevenZheng, HyunJeong Choe, goston Weisz, Tao Zhu,Yifeng Lu, Siddharth Gopal, Jarrod Kahn, MaciejKula, Jeff Pitman, Rushin Shah, Emanuel Taropa,Majd Al Merey, Martin Baeuml, Zhifeng Chen, Lau-rent El Shafey, Yujing Zhang, Olcan Sercinoglu,George Tucker, Enrique Piqueras, Maxim Krikun,Iain Barr, Nikolay Savinov, Ivo Danihelka, BeccaRoelofs, Anas White, Anders Andreassen, Tamaravon Glehn, Lakshman Yagati, Mehran Kazemi, Lu-cas Gonzalez, Misha Khalman, Jakub Sygnowski,Alexandre Frechette, Charlotte Smith, Laura Culp,Lev Proleev, Yi Luan, Xi Chen, James Lottes, NathanSchucher, Federico Lebron, Alban Rrustemi, Na-talie Clay, Phil Crone, Tomas Kocisky, Jeffrey Zhao,Bartek Perz, Dian Yu, Heidi Howard, Adam Blo-niarz, Jack W. Rae, Han Lu, Laurent Sifre, Mar-cello Maggioni, Fred Alcober, Dan Garrette, MeganBarnes, Shantanu Thakoor, Jacob Austin, GabrielBarth-Maron, William Wong, Rishabh Joshi, RahmaChaabouni, Deeni Fatiha, Arun Ahuja, Gaurav SinghTomar, Evan Senter, Martin Chadwick, Ilya Kor-nakov, Nithya Attaluri, Iaki Iturrate, Ruibo Liu,Yunxuan Li, Sarah Cogan, Jeremy Chen, Chao Jia,Chenjie Gu, Qiao Zhang, Jordan Grimstad, Ale JakseHartman, Xavier Garcia, Thanumalayan Sankara-narayana Pillai, Jacob Devlin, Michael Laskin, Diegode Las Casas, Dasha Valter, Connie Tao, LorenzoBlanco, Adri Puigdomnech Badia, David Reitter,Mianna Chen, Jenny Brennan, Clara Rivera, SergeyBrin, Shariq Iqbal, Gabriela Surita, Jane Labanowski,Abhi Rao, Stephanie Winkler, Emilio Parisotto, Yim-ing Gu, Kate Olszewska, Ravi Addanki, AntoineMiech, Annie Louis, Denis Teplyashin, Geoff Brown,Elliot Catt, Jan Balaguer, Jackie Xiang, Pidong Wang,Zoe Ashwood, Anton Briukhov, Albert Webson, San-jay Ganapathy, Smit Sanghavi, Ajay Kannan, Ming-Wei Chang, Axel Stjerngren, Josip Djolonga, Yut-ing Sun, Ankur Bapna, Matthew Aitchison, PedramPejman, Henryk Michalewski, Tianhe Yu, CindyWang, Juliette Love, Junwhan Ahn, Dawn Bloxwich,Kehang Han, Peter Humphreys, Thibault Sellam,James Bradbury, Varun Godbole, Sina Samangooei,Bogdan Damoc, Alex Kaskasoli, Sbastien M. R.Arnold, Vijay Vasudevan, Shubham Agrawal, JasonRiesa, Dmitry Lepikhin, Richard Tanburn, Srivat-san Srinivasan, Hyeontaek Lim, Sarah Hodkinson,Pranav Shyam, Johan Ferret, Steven Hand, AnkushGarg, Tom Le Paine, Jian Li, Yujia Li, Minh Gi-ang, Alexander Neitz, Zaheer Abbas, Sarah York,Machel Reid, Elizabeth Cole, Aakanksha Chowdh-ery, Dipanjan Das, Dominika Rogozinska, VitaliyNikolaev, Pablo Sprechmann, Zachary Nado, LukasZilka, Flavien Prost, Luheng He, Marianne Mon-teiro, Gaurav Mishra, Chris Welty, Josh Newlan,Dawei Jia, Miltiadis Allamanis, Clara Huiyi Hu,Raoul de Liedekerke, Justin Gilmer, Carl Saroufim,Shruti Rijhwani, Shaobo Hou, Disha Shrivastava,Anirudh Baddepudi, Alex Goldin, Adnan Ozturel,Albin Cassirer, Yunhan Xu, Daniel Sohn, Deven-dra Sachan, Reinald Kim Amplayo, Craig Swan-son, Dessie Petrova, Shashi Narayan, Arthur Guez, Siddhartha Brahma, Jessica Landon, Miteyan Pa-tel, Ruizhe Zhao, Kevin Villela, Luyu Wang, Wen-hao Jia, Matthew Rahtz, Mai Gimnez, Legg Yeung,James Keeling, Petko Georgiev, Diana Mincu, BoxiWu, Salem Haykal, Rachel Saputro, Kiran Vodra-halli, James Qin, Zeynep Cankara, Abhanshu Sharma,Nick Fernando, Will Hawkins, Behnam Neyshabur,Solomon Kim, Adrian Hutter, Priyanka Agrawal,Alex Castro-Ros, George van den Driessche, TaoWang, Fan Yang, Shuo yiin Chang, Paul Komarek,Ross McIlroy, Mario Lucic, Guodong Zhang, WaelFarhan, Michael Sharman, Paul Natsev, Paul Michel,Yamini Bansal, Siyuan Qiao, Kris Cao, Siamak Shak-eri, Christina Butterfield, Justin Chung, Paul KishanRubenstein, Shivani Agrawal, Arthur Mensch, KedarSoparkar, Karel Lenc, Timothy Chung, Aedan Pope,Loren Maggiore, Jackie Kay, Priya Jhakra, ShiboWang, Joshua Maynez, Mary Phuong, Taylor Tobin,Andrea Tacchetti, Maja Trebacz, Kevin Robinson,Yash Katariya, Sebastian Riedel, Paige Bailey, KefanXiao, Nimesh Ghelani, Lora Aroyo, Ambrose Slone,Neil Houlsby, Xuehan Xiong, Zhen Yang, Elena Gri-bovskaya, Jonas Adler, Mateo Wirth, Lisa Lee, MusicLi, Thais Kagohara, Jay Pavagadhi, Sophie Bridgers,Anna Bortsova, Sanjay Ghemawat, Zafarali Ahmed,Tianqi Liu, Richard Powell, Vijay Bolina, MarikoIinuma, Polina Zablotskaia, James Besley, Da-WoonChung, Timothy Dozat, Ramona Comanescu, Xi-ance Si, Jeremy Greer, Guolong Su, Martin Polacek,Raphal Lopez Kaufman, Simon Tokumine, HexiangHu, Elena Buchatskaya, Yingjie Miao, MohamedElhawaty, Aditya Siddhant, Nenad Tomasev, Jin-wei Xing, Christina Greer, Helen Miller, ShereenAshraf, Aurko Roy, Zizhao Zhang, Ada Ma, Ange-los Filos, Milos Besta, Rory Blevins, Ted Klimenko,Chih-Kuan Yeh, Soravit Changpinyo, Jiaqi Mu, Os-car Chang, Mantas Pajarskas, Carrie Muir, VeredCohen, Charline Le Lan, Krishna Haridasan, AmitMarathe, Steven Hansen, Sholto Douglas, Rajku-mar Samuel, Mingqiu Wang, Sophia Austin, ChangLan, Jiepu Jiang, Justin Chiu, Jaime Alonso Lorenzo,Lars Lowe Sjsund, Sbastien Cevey, Zach Gle-icher, Thi Avrahami, Anudhyan Boral, Hansa Srini-vasan, Vittorio Selo, Rhys May, Konstantinos Aiso-pos, Lonard Hussenot, Livio Baldini Soares, KateBaumli, Michael B. Chang, Adri Recasens, BenCaine, Alexander Pritzel, Filip Pavetic, Fabio Pardo,Anita Gergely, Justin Frye, Vinay Ramasesh, DanHorgan, Kartikeya Badola, Nora Kassner, Subhra-jit Roy, Ethan Dyer, Vctor Campos Campos, AlexTomala, Yunhao Tang, Dalia El Badawy, ElspethWhite, Basil Mustafa, Oran Lang, Abhishek Jin-dal, Sharad Vikram, Zhitao Gong, Sergi Caelles,Ross Hemsley, Gregory Thornton, Fangxiaoyu Feng,Wojciech Stokowiec, Ce Zheng, Phoebe Thacker,aglar nl, Zhishuai Zhang, Mohammad Saleh,James Svensson, Max Bileschi, Piyush Patil, AnkeshAnand, Roman Ring, Katerina Tsihlas, Arpi Vezer,Marco Selvi, Toby Shevlane, Mikel Rodriguez, TomKwiatkowski, Samira Daruki, Keran Rong, AllanDafoe, Nicholas FitzGerald, Keren Gu-Lemberg,Mina Khan, Lisa Anne Hendricks, Marie Pellat,Vladimir Feinberg, James Cobon-Kerr, Tara Sainath,Maribeth Rauh, Sayed Hadi Hashemi, Richard Ives, Yana Hasson, Eric Noland, Yuan Cao, Nathan Byrd,Le Hou, Qingze Wang, Thibault Sottiaux, MichelaPaganini, Jean-Baptiste Lespiau, Alexandre Mou-farek, Samer Hassan, Kaushik Shivakumar, Joost vanAmersfoort, Amol Mandhane, Pratik Joshi, AnirudhGoyal, Matthew Tung, Andrew Brock, Hannah Shea-han, Vedant Misra, Cheng Li, Nemanja Rakicevic,Mostafa Dehghani, Fangyu Liu, Sid Mittal, Jun-hyuk Oh, Seb Noury, Eren Sezener, Fantine Huot,Matthew Lamm, Nicola De Cao, Charlie Chen, Sid-harth Mudgal, Romina Stella, Kevin Brooks, Gau-tam Vasudevan, Chenxi Liu, Mainak Chain, NiveditaMelinkeri, Aaron Cohen, Venus Wang, Kristie Sey-more, Sergey Zubkov, Rahul Goel, Summer Yue,Sai Krishnakumaran, Brian Albert, Nate Hurley,Motoki Sano, Anhad Mohananey, Jonah Joughin,Egor Filonov, Tomasz Kepa, Yomna Eldawy, Jiaw-ern Lim, Rahul Rishi, Shirin Badiezadegan, TaylorBos, Jerry Chang, Sanil Jain, Sri Gayatri SundaraPadmanabhan, Subha Puttagunta, Kalpesh Krishna,Leslie Baker, Norbert Kalb, Vamsi Bedapudi, AdamKurzrok, Shuntong Lei, Anthony Yu, Oren Litvin,Xiang Zhou, Zhichun Wu, Sam Sobell, Andrea Si-ciliano, Alan Papir, Robby Neale, Jonas Bragagnolo,Tej Toor, Tina Chen, Valentin Anklin, Feiran Wang,Richie Feng, Milad Gholami, Kevin Ling, LijuanLiu, Jules Walter, Hamid Moghaddam, Arun Kishore,Jakub Adamek, Tyler Mercado, Jonathan Mallinson,Siddhinita Wandekar, Stephen Cagle, Eran Ofek,Guillermo Garrido, Clemens Lombriser, MaksimMukha, Botu Sun, Hafeezul Rahman Mohammad,Josip Matak, Yadi Qian, Vikas Peswani, Pawel Janus,Quan Yuan, Leif Schelin, Oana David, Ankur Garg,Yifan He, Oleksii Duzhyi, Anton lgmyr, Timo-the Lottaz, Qi Li, Vikas Yadav, Luyao Xu, AlexChinien, Rakesh Shivanna, Aleksandr Chuklin, JosieLi, Carrie Spadine, Travis Wolfe, Kareem Mohamed,Subhabrata Das, Zihang Dai, Kyle He, Daniel vonDincklage, Shyam Upadhyay, Akanksha Maurya,Luyan Chi, Sebastian Krause, Khalid Salama, Pam GRabinovitch, Pavan Kumar Reddy M, Aarush Sel-van, Mikhail Dektiarev, Golnaz Ghiasi, Erdem Gu-ven, Himanshu Gupta, Boyi Liu, Deepak Sharma,Idan Heimlich Shtacher, Shachi Paul, Oscar Aker-lund, Franois-Xavier Aubet, Terry Huang, ChenZhu, Eric Zhu, Elico Teixeira, Matthew Fritze,Francesco Bertolini, Liana-Eleonora Marinescu, Mar-tin Blle, Dominik Paulus, Khyatti Gupta, TejasiLatkar, Max Chang, Jason Sanders, Roopa Wil-son, Xuewei Wu, Yi-Xuan Tan, Lam Nguyen Thiet,Tulsee Doshi, Sid Lall, Swaroop Mishra, WanmingChen, Thang Luong, Seth Benjamin, Jasmine Lee,Ewa Andrejczuk, Dominik Rabiej, Vipul Ranjan,Krzysztof Styrc, Pengcheng Yin, Jon Simon, Mal-colm Rose Harriott, Mudit Bansal, Alexei Robsky,Geoff Bacon, David Greene, Daniil Mirylenka, ChenZhou, Obaid Sarvana, Abhimanyu Goyal, SamuelAndermatt, Patrick Siegler, Ben Horn, Assaf Is-rael, Francesco Pongetti, Chih-Wei \"Louis\" Chen,Marco Selvatici, Pedro Silva, Kathie Wang, Jack-son Tolins, Kelvin Guu, Roey Yogev, Xiaochen Cai,Alessandro Agostini, Maulik Shah, Hung Nguyen,Noah Donnaile, Sbastien Pereira, Linda Friso, Adam Stambler, Adam Kurzrok, Chenkai Kuang,Yan Romanikhin, Mark Geller, ZJ Yan, Kane Jang,Cheng-Chun Lee, Wojciech Fica, Eric Malmi, Qi-jun Tan, Dan Banica, Daniel Balle, Ryan Pham,Yanping Huang, Diana Avram, Hongzhi Shi, JasjotSingh, Chris Hidey, Niharika Ahuja, Pranab Sax-ena, Dan Dooley, Srividya Pranavi Potharaju, EileenONeill, Anand Gokulchandran, Ryan Foley, KaiZhao, Mike Dusenberry, Yuan Liu, Pulkit Mehta,Ragha Kotikalapudi, Chalence Safranek-Shrader, An-drew Goodman, Joshua Kessinger, Eran Globen, Pra-teek Kolhar, Chris Gorgolewski, Ali Ibrahim, YangSong, Ali Eichenbaum, Thomas Brovelli, SahityaPotluri, Preethi Lahoti, Cip Baetu, Ali Ghorbani,Charles Chen, Andy Crawford, Shalini Pal, MukundSridhar, Petru Gurita, Asier Mujika, Igor Petrovski,Pierre-Louis Cedoz, Chenmei Li, Shiyuan Chen,Niccol Dal Santo, Siddharth Goyal, Jitesh Pun-jabi, Karthik Kappaganthu, Chester Kwak, PallaviLV, Sarmishta Velury, Himadri Choudhury, JamieHall, Premal Shah, Ricardo Figueira, Matt Thomas,Minjie Lu, Ting Zhou, Chintu Kumar, Thomas Ju-rdi, Sharat Chikkerur, Yenai Ma, Adams Yu, SooKwak, Victor hdel, Sujeevan Rajayogam, TravisChoma, Fei Liu, Aditya Barua, Colin Ji, Ji HoPark, Vincent Hellendoorn, Alex Bailey, Taylan Bi-lal, Huanjie Zhou, Mehrdad Khatir, Charles Sut-ton, Wojciech Rzadkowski, Fiona Macintosh, Kon-stantin Shagin, Paul Medina, Chen Liang, JinjingZhou, Pararth Shah, Yingying Bi, Attila Dankovics,Shipra Banga, Sabine Lehmann, Marissa Bredesen,Zifan Lin, John Eric Hoffmann, Jonathan Lai, Ray-nald Chung, Kai Yang, Nihal Balani, Arthur Brain-skas, Andrei Sozanschi, Matthew Hayes, Hctor Fer-nndez Alcalde, Peter Makarov, Will Chen, Anto-nio Stella, Liselotte Snijders, Michael Mandl, AnteKrrman, Pawe Nowak, Xinyi Wu, Alex Dyck, Kr-ishnan Vaidyanathan, Raghavender R, Jessica Mal-let, Mitch Rudominer, Eric Johnston, Sushil Mit-tal, Akhil Udathu, Janara Christensen, Vishal Verma,Zach Irving, Andreas Santucci, Gamaleldin Elsayed,Elnaz Davoodi, Marin Georgiev, Ian Tenney, NanHua, Geoffrey Cideron, Edouard Leurent, Mah-moud Alnahlawi, Ionut Georgescu, Nan Wei, IvyZheng, Dylan Scandinaro, Heinrich Jiang, JasperSnoek, Mukund Sundararajan, Xuezhi Wang, ZackOntiveros, Itay Karo, Jeremy Cole, Vinu Rajashekhar,Lara Tumeh, Eyal Ben-David, Rishub Jain, JonathanUesato, Romina Datta, Oskar Bunyan, Shimu Wu,John Zhang, Piotr Stanczyk, Ye Zhang, David Steiner,Subhajit Naskar, Michael Azzam, Matthew Johnson,Adam Paszke, Chung-Cheng Chiu, Jaume SanchezElias, Afroz Mohiuddin, Faizan Muhammad, JinMiao, Andrew Lee, Nino Vieillard, Jane Park, Ji-ageng Zhang, Jeff Stanway, Drew Garmon, AbhijitKarmarkar, Zhe Dong, Jong Lee, Aviral Kumar, Lu-owei Zhou, Jonathan Evens, William Isaac, GeoffreyIrving, Edward Loper, Michael Fink, Isha Arkatkar,Nanxin Chen, Izhak Shafran, Ivan Petrychenko,Zhe Chen, Johnson Jia, Anselm Levskaya, ZhenkaiZhu, Peter Grabowski, Yu Mao, Alberto Magni,Kaisheng Yao, Javier Snaider, Norman Casagrande,Evan Palmer, Paul Suganthan, Alfonso Castao,Irene Giannoumis, Wooyeol Kim, Mikoaj Rybinski, Ashwin Sreevatsa, Jennifer Prendki, David Soergel,Adrian Goedeckemeyer, Willi Gierke, Mohsen Jafari,Meenu Gaba, Jeremy Wiesner, Diana Gage Wright,Yawen Wei, Harsha Vashisht, Yana Kulizhskaya, JayHoover, Maigo Le, Lu Li, Chimezie Iwuanyanwu,Lu Liu, Kevin Ramirez, Andrey Khorlin, AlbertCui, Tian LIN, Marcus Wu, Ricardo Aguilar, KeithPallo, Abhishek Chakladar, Ginger Perng, Elena Al-lica Abellan, Mingyang Zhang, Ishita Dasgupta,Nate Kushman, Ivo Penchev, Alena Repina, XihuiWu, Tom van der Weide, Priya Ponnapalli, Car-oline Kaplan, Jiri Simsa, Shuangfeng Li, OlivierDousse, Fan Yang, Jeff Piper, Nathan Ie, Rama Pa-sumarthi, Nathan Lintz, Anitha Vijayakumar, DanielAndor, Pedro Valenzuela, Minnie Lui, Cosmin Padu-raru, Daiyi Peng, Katherine Lee, Shuyuan Zhang,Somer Greene, Duc Dung Nguyen, Paula Kurylow-icz, Cassidy Hardin, Lucas Dixon, Lili Janzer, KiamChoo, Ziqiang Feng, Biao Zhang, Achintya Sing-hal, Dayou Du, Dan McKinnon, Natasha Antropova,Tolga Bolukbasi, Orgad Keller, David Reid, DanielFinchelstein, Maria Abi Raad, Remi Crocker, Pe-ter Hawkins, Robert Dadashi, Colin Gaffney, KenFranko, Anna Bulanova, Rmi Leblond, ShirleyChung, Harry Askham, Luis C. Cobo, Kelvin Xu,Felix Fischer, Jun Xu, Christina Sorokin, Chris Al-berti, Chu-Cheng Lin, Colin Evans, Alek Dimitriev,Hannah Forbes, Dylan Banarse, Zora Tung, MarkOmernick, Colton Bishop, Rachel Sterneck, RohanJain, Jiawei Xia, Ehsan Amid, Francesco Piccinno,Xingyu Wang, Praseem Banzal, Daniel J. Mankowitz,Alex Polozov, Victoria Krakovna, Sasha Brown, Mo-hammadHossein Bateni, Dennis Duan, Vlad Firoiu,Meghana Thotakuri, Tom Natan, Matthieu Geist,Ser tan Girgin, Hui Li, Jiayu Ye, Ofir Roval, ReikoTojo, Michael Kwong, James Lee-Thorp, Christo-pher Yew, Danila Sinopalnikov, Sabela Ramos, JohnMellor, Abhishek Sharma, Kathy Wu, David Miller,Nicolas Sonnerat, Denis Vnukov, Rory Greig, Jen-nifer Beattie, Emily Caveness, Libin Bai, JulianEisenschlos, Alex Korchemniy, Tomy Tsai, MimiJasarevic, Weize Kong, Phuong Dao, Zeyu Zheng,Frederick Liu, Fan Yang, Rui Zhu, Tian Huey Teh,Jason Sanmiya, Evgeny Gladchenko, Nejc Trdin,Daniel Toyama, Evan Rosen, Sasan Tavakkol, Lint-ing Xue, Chen Elkind, Oliver Woodman, John Car-penter, George Papamakarios, Rupert Kemp, SushantKafle, Tanya Grunina, Rishika Sinha, Alice Tal-bert, Diane Wu, Denese Owusu-Afriyie, CosmoDu, Chloe Thornton, Jordi Pont-Tuset, PradyumnaNarayana, Jing Li, Saaber Fatehi, John Wieting,Omar Ajmeri, Benigno Uria, Yeongil Ko, LauraKnight, Amlie Hliou, Ning Niu, Shane Gu, ChenxiPang, Yeqing Li, Nir Levine, Ariel Stolovich, Re-beca Santamaria-Fernandez, Sonam Goenka, WennyYustalim, Robin Strudel, Ali Elqursh, Charlie Deck,Hyo Lee, Zonglin Li, Kyle Levin, Raphael Hoff-mann, Dan Holtmann-Rice, Olivier Bachem, ShoArora, Christy Koh, Soheil Hassas Yeganeh, SiimPder, Mukarram Tariq, Yanhua Sun, Lucian Ionita,Mojtaba Seyedhosseini, Pouya Tafti, Zhiyu Liu, An-mol Gulati, Jasmine Liu, Xinyu Ye, Bart Chrzaszcz,Lily Wang, Nikhil Sethi, Tianrun Li, Ben Brown,Shreya Singh, Wei Fan, Aaron Parisi, Joe Stan- ton, Vinod Koverkathu, Christopher A. Choquette-Choo, Yunjie Li, TJ Lu, Abe Ittycheriah, PrakashShroff, Mani Varadarajan, Sanaz Bahargam, RobWilloughby, David Gaddy, Guillaume Desjardins,Marco Cornero, Brona Robenek, Bhavishya Mit-tal, Ben Albrecht, Ashish Shenoy, Fedor Moiseev,Henrik Jacobsson, Alireza Ghaffarkhah, MorganeRivire, Alanna Walton, Clment Crepy, Alicia Par-rish, Zongwei Zhou, Clement Farabet, Carey Rade-baugh, Praveen Srinivasan, Claudia van der Salm,Andreas Fidjeland, Salvatore Scellato, Eri Latorre-Chimoto, Hanna Klimczak-Plucinska, David Bridson,Dario de Cesare, Tom Hudson, Piermaria Mendolic-chio, Lexi Walker, Alex Morris, Matthew Mauger,Alexey Guseynov, Alison Reid, Seth Odoom, Lu-cia Loher, Victor Cotruta, Madhavi Yenugula, Do-minik Grewe, Anastasia Petrushkina, Tom Duerig,Antonio Sanchez, Steve Yadlowsky, Amy Shen,Amir Globerson, Lynette Webb, Sahil Dua, DongLi, Surya Bhupatiraju, Dan Hurt, Haroon Qureshi,Ananth Agarwal, Tomer Shani, Matan Eyal, AnujKhare, Shreyas Rammohan Belle, Lei Wang, ChetanTekur, Mihir Sanjay Kale, Jinliang Wei, RuoxinSang, Brennan Saeta, Tyler Liechty, Yi Sun, YaoZhao, Stephan Lee, Pandu Nayak, Doug Fritz, Man-ish Reddy Vuyyuru, John Aslanides, Nidhi Vyas,Martin Wicke, Xiao Ma, Evgenii Eltyshev, Nina Mar-tin, Hardie Cate, James Manyika, Keyvan Amiri,Yelin Kim, Xi Xiong, Kai Kang, Florian Luisier,Nilesh Tripuraneni, David Madras, Mandy Guo,Austin Waters, Oliver Wang, Joshua Ainslie, JasonBaldridge, Han Zhang, Garima Pruthi, Jakob Bauer,Feng Yang, Riham Mansour, Jason Gelman, Yang Xu,George Polovets, Ji Liu, Honglong Cai, Warren Chen,XiangHai Sheng, Emily Xue, Sherjil Ozair, ChristofAngermueller, Xiaowei Li, Anoop Sinha, WeirenWang, Julia Wiesinger, Emmanouil Koukoumidis,Yuan Tian, Anand Iyer, Madhu Gurumurthy, MarkGoldenson, Parashar Shah, MK Blake, Hongkun Yu,Anthony Urbanowicz, Jennimaria Palomaki, Chrisan-tha Fernando, Ken Durden, Harsh Mehta, NikolaMomchev, Elahe Rahimtoroghi, Maria Georgaki,Amit Raul, Sebastian Ruder, Morgan Redshaw, Jin-hyuk Lee, Denny Zhou, Komal Jalan, Dinghua Li,Blake Hechtman, Parker Schuh, Milad Nasr, KieranMilan, Vladimir Mikulik, Juliana Franco, Tim Green,Nam Nguyen, Joe Kelley, Aroma Mahendru, AndreaHu, Joshua Howland, Ben Vargas, Jeffrey Hui, Kshi-tij Bansal, Vikram Rao, Rakesh Ghiya, Emma Wang,Ke Ye, Jean Michel Sarr, Melanie Moranski Preston,Madeleine Elish, Steve Li, Aakash Kaku, Jigar Gupta,Ice Pasupat, Da-Cheng Juan, Milan Someswar, TejviM., Xinyun Chen, Aida Amini, Alex Fabrikant, EricChu, Xuanyi Dong, Amruta Muthal, Senaka Buth-pitiya, Sarthak Jauhari, Nan Hua, Urvashi Khan-delwal, Ayal Hitron, Jie Ren, Larissa Rinaldi, Sha-har Drath, Avigail Dabush, Nan-Jiang Jiang, Har-shal Godhia, Uli Sachs, Anthony Chen, YichengFan, Hagai Taitelbaum, Hila Noga, Zhuyun Dai,James Wang, Chen Liang, Jenny Hamer, Chun-SungFerng, Chenel Elkind, Aviel Atias, Paulina Lee, VtListk, Mathias Carlen, Jan van de Kerkhof, MarcinPikus, Krunoslav Zaher, Paul Mller, Sasha Zykova,Richard Stefanec, Vitaly Gatsko, Christoph Hirn- schall, Ashwin Sethi, Xingyu Federico Xu, ChetanAhuja, Beth Tsai, Anca Stefanoiu, Bo Feng, Ke-shav Dhandhania, Manish Katyal, Akshay Gupta,Atharva Parulekar, Divya Pitta, Jing Zhao, VivaanBhatia, Yashodha Bhavnani, Omar Alhadlaq, XiaolinLi, Peter Danenberg, Dennis Tu, Alex Pine, VeraFilippova, Abhipso Ghosh, Ben Limonchik, Bhar-gava Urala, Chaitanya Krishna Lanka, Derik Clive,Yi Sun, Edward Li, Hao Wu, Kevin Hongtongsak,Ianna Li, Kalind Thakkar, Kuanysh Omarov, KushalMajmundar, Michael Alverson, Michael Kucharski,Mohak Patel, Mudit Jain, Maksim Zabelin, PaoloPelagatti, Rohan Kohli, Saurabh Kumar, Joseph Kim,Swetha Sankar, Vineet Shah, Lakshmi Ramachan-druni, Xiangkai Zeng, Ben Bariach, Laura Weidinger,Tu Vu, Amar Subramanya, Sissie Hsiao, Demis Hass-abis, Koray Kavukcuoglu, Adam Sadovsky, Quoc Le,Trevor Strohman, Yonghui Wu, Slav Petrov, JeffreyDean, and Oriol Vinyals. 2024. Gemini: A fam-ily of highly capable multimodal models. Preprint,arXiv:2312.11805.",
  "Naftali Tishby and Noga Zaslavsky. 2015. Deep learn-ing and the information bottleneck principle. In 2015IEEE Information Theory Workshop (ITW), pages15": "Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian CantonFerrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. 2023. Llama 2: Open foundation and fine-tuned chat models. Preprint, arXiv:2307.09288.",
  "identification in GPT-2 small. In The Eleventh Inter-national Conference on Learning Representations": "Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel,Barret Zoph, Sebastian Borgeaud, Dani Yogatama,Maarten Bosma, Denny Zhou, Donald Metzler, Ed H.Chi, Tatsunori Hashimoto, Oriol Vinyals, PercyLiang, Jeff Dean, and William Fedus. 2022. Emer-gent abilities of large language models. Transactionson Machine Learning Research. Survey Certifica-tion. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,William Cohen, Ruslan Salakhutdinov, and Christo-pher D. Manning. 2018. HotpotQA: A dataset fordiverse, explainable multi-hop question answering.In Proceedings of the 2018 Conference on Empiri-cal Methods in Natural Language Processing, pages23692380, Brussels, Belgium. Association for Com-putational Linguistics. Xiaodan Zhu, Peter Turney, Daniel Lemire, and AndrVellino. 2015. Measuring academic influence: Notall citations are equal. Journal of the Association forInformation Science and Technology, 66(2):408427.",
  "Summary statistics shows the number ofpapers per track in our initial collection. With 477papers, IA is the 6th largest track in the collection": "Standarizing submission tracksThe submis-sion tracks of ACL and EMNLP conferences havechanged considerably from 2018 to 2023. Sometracks were split into multiple tracks, some tracksappeared (and disappeared), and some were re-named. As we are mostly interested in compar-ing IA with other tracks, we decided to mergetracks in order to create a consistent set of tracksstarting from 2020 (when the IA track was estab-lished). This unification makes our analysis morefeasible. We manually assigned every track fromACL/EMNLP from 2020 to 2023 into 27 differentcategories: Information Extraction/RetrievalMachine Translation and MultilingualityMachine LearningApplicationsDialogueSemanticsInterpretability and AnalysisResources and EvaluationGenerationQuestion AnsweringMultimodality, Speech and GroundingSummarizationSentiment AnalysisThemeSocial ScienceEthicsLinguistic Theories and PsycholinguisticsSyntaxEfficient MethodsDiscourse and PragmaticsLarge Language ModelsPhonology, Morphology and Word Segmenta-tionIndustryCommonsense ReasoningHuman-Centered NLPUnsupervised and Weakly-Supervised Methodsin NLPTheory and Formalism in NLP",
  ": Statistics of the citation graph.As someEMNLP/ACL papers cite other EMNLP/ACL papers,the total number of edges is less than the sum of thereferences and citations": "Cleaning the collected dataSince the ACL An-thology does not provide information about thesubmission track, we obtain our data from a di-verse set of sources as listed in . Since thedata comes in very different formats, we performedthe following steps to clean it.We searched for paper titles in the ACL anthol-ogy to obtain their DOIs. As some papers were re-named, preventing us from finding the correspond-ing paper in the ACL Anthology, we queried theSemantic Scholar API for the closest match, witha minimum of 0.85 similarity using the Pythondifflib.SequenceMatcher class.Finally, wemanually searched for the remaining papers onSemantic Scholar. After this process, we were leftwith only 6 papers with no Semantic Scholar ID.We exclude these from our analysis. Finally, foreach paper, we queried its citations and its refer-ences using the Semantic Scholar API, and con-structed the citation graph based on the results. Citation intent and influenceFor each citation,the Semantic Scholar API provides a label of theintent (e.g. as background information, use of meth-ods, or comparing results) (Cohan et al., 2019), anda label on whether it is a highly influential cita-tion for the paper or not (Valenzuela et al., 2015).We rely on the latter label when analyzing the mostcited IA papers in . Track classifiers detailsWe are interested in an-alyzing how papers from different tracks cite eachother. However, as most of the nodes in our citationgraph are papers that are not in ACL and EMNLP,we have no ground truth information for the trackof these papers. Therefore, we built a classifierto predict the track of a paper, given its title andabstract. The classifier is based on the Specter2model (Cohan et al., 2020), which takes a title andan abstract of a paper, and outputs an embedding.We add and train a MLP layer on top of this model",
  "ConferenceData Source": "ACL 2018Conference schedule web pageACL 2019Conference schedule web pageACL 2020Virtual conference web pageACL 2021Conference schedule web pageACL 2022Provided by the program chairsACL 2023Github repository to generate webpageEMNLP 2018Provided by the program chairsEMNLP 2019Conference schedule web pageEMNLP 2020Github repository to generate webpageEMNLP 2021Provided by the program chairsEMNLP 2022Provided by the program chairsEMNLP 2023Provided by the program chairs",
  ": Data source for each conference": "to obtain our classifier.We split the data 80/20 using only papers fromACL and EMNLP from 2020 to 2023 (for whichwe have gold labels), and we trained the classifierfor 50 epochs using Adam and a cross entropy loss.We used a learning rate of 2 103 and a learningrate scheduler with exponential decay ( = 0.995).We perform upsampling as the number of papersin each track is imbalanced. Additionally, to get aneven more diverse set of papers for the interpretabil-ity and analysis track, we augment the training datawith papers accepted to the BlackboxNLP work-shop, which focuses on IA work.We find that some tracks are more difficult to pre-dict correctly than others (e.g., Efficient Methods).We attribute this to both the limited training dataand the ambiguity of submission tracks. We hencerestrict ourselves to the 11 tracks (including IA)with the highest classification accuracy, and intro-duced an Other category to group the remainingtracks, which we exclude from our classifier analy-ses. The final set of tracks in our classifier is:DialogueEthicsGenerationInformation Extraction/RetrievalInterpretability and AnalysisMachine LearningMachine Translation and MultilingualityMultimodality, Speech and GroundingQuestion AnsweringSocial ScienceSummarizationOtherOn this final set of tracks, our classifier achievesan F1 micro/macro score of 0.61/0.61. Given how noisy submission track labels can be (a paper canoften be a plausible candidate for multiple tracks),we find our classifiers performance to be reason-able. We additionally perform a manual error anal-ysis and expect the classification errors made onthe test set; most errors were cases where the papercould have been submitted to the predicted track.Finally, we label the citation graph using ourclassifier. We used Semantic Scholar and Ope-nAlex (Priem et al., 2022) (in accordance with theirterms of use) to obtain abstracts. 4.9% of the papershad no abstract in either source; we thus excludethese from our analysis.",
  "A.1Sanity checks": "Additional IA track classifier evaluationsAswe are mostly interested in the performance of de-tecting IA papers, we validate our classifier in 2different ways: using the IA papers suggested byour respondents in the survey, and manual annota-tion of 556 papers.For papers suggested by survey respondents (af-ter removing papers included in the training data),we run our classifier and get predicted tracks. Theclassifier obtained an accuracy of 78.1% (82/105).Considering that these papers are out-of-domainin comparison to the training data (some are evenIA papers outside of NLP), we believe this to be agood result.As for the 556 papers that were manually an-notated by two authors, our classifier is 87.8%(488/556) accurate. As this data is biased towardsnon-IA papers (506/556 papers), we also computeprecision, recall and F1 scores. The F1 score is0.60, precision is 1.0 and recall is 0.42. Since highprecision and low recall show that we underselectIA papers, we get a conservative estimate of ourpositive results rather than an overly generous esti-mate, which we find acceptable. Citation trends of IA exclusively inside ACLand EMNLPAs some of our findings depend onlabels from our classifier, which might be noisy, weverify these findings using a smaller subset of ourdata, consisting exclusively of ACL and EMNLPpapers. This subgraph of our citation graph hasgold labels for the submission track. Specifically,we verify that (1) IA work is primarily cited bytracks other than IA (see ), and that (2)there is significant variation in how frequentlydifferent tracks cite IA work (see ).In our gold labeled subgraph, there are 2,283 Citation Counts (103) 0.00 0.25 0.50 0.75 1.00 1.25 1.50 1.75 Centrality (103)",
  ":Betweenness centralities versus citationcounts for papers in ACL and EMNLP since 2020. Nocorrelation can be detected to the naked eye betweenthese metrics": "citations to IA papers, of which only 846 are fromother IA papers (37.1%). This shows that a largefraction of citations to IA papers do indeed comefrom outside IA research. This verifies our firstclassifier-based result. Next, when looking at the references of papersin each submission track within our gold subgraph,we find that the proportion of references to IA pa-pers does indeed differ considerably by track. Asan example, for the Large Language Models track,we find that 11.2% (N=723) of its references areto IA papers. In contrast, only 1.3% (N=1828) ofthe references of Sentiment Analysis track paperscorrespond to IA work. This confirms our secondclassifier-based finding. Correlation between betweenness centralitiesand citation countsLeydesdorff (2007) find thatbetweenness centrality can be highly correlated tocitation counts. Although this is expected (paperswith more citations can also act better as bridges),given that BC is being used as a proxy to mea-sure the interdisciplinarity\" of a field, we wouldwant this metric to be somewhat orthogonal to thecitation counts. We compute the the correlationbetween the citation counts and the BC of all nodesin our citation graph. At 0.328 (p < 0.001), it isconsiderably lower than the 0.509 reported by Ley-desdorff (2007). provides a visualizationof the correlation.",
  "B.1Ethical considerations": "Our survey involved research with human partic-ipants, thus we report the full text of the surveybelow, and information about recruitment in Sec-tion 3. We determined there to be a negligible riskof harms from participating in our survey, as it con-tains no offensive or harmful content. As shownin the full survey below, we describe our study ob-jectives and remind respondents that filling out thesurvey is completely voluntary. We then explic-itly ask for their consent to participate, and obtainconsent from all 138 survey respondents. For re-spondents who may not have completed the survey,no data was collected. In lieu of financial compen-sation, we offered survey respondents the optionalopportunity to provide their name or an alias thatwe would mention in the acknowledgements ofany future paper we write with the survey results.To protect respondent privacy and confidentiality,when we report disaggregated results in this pa-per, we ensured a minimum of 10 respondents perbucket. In addition, we will not release the originalsurvey responses in full, but only release high-levelstatistics, annotations from our qualitative coding,and select non-identifying examples in .",
  "B.2Participant demographics": "We collected demographic information (occupa-tions and research areas) from survey respondentsto consider factors that might affect the representa-tiveness of our results. presents the break-down of respondents per occupation.When collecting information on research areas,we allowed respondents to check multiple boxescorresponding to multiple research areas. Of partic-ular interest is the area labeled \"Science of LMs,\"which we used as an umbrella term to include anal-ysis and interpretability research. shows theresearch areas of our respondents. The next sectionprovides the expansions for each of the umbrellaterms that we list in the table.",
  "Research areaResponses": "Science of LMs54 (39%)Evaluation53 (38%)LM adaptation47 (34%)Data for LMs32 (23%)NLP applications32 (23%)Computational linguistics30 (22%)Mind, brain and LMs30 (22%)Neurosymbolic approaches26 (19%)Learning algorithms25 (18%)LMs for everyone24 (17%)LMs and the world21 (15%)Safety21 (15%)Societal implications20 (14%)Inference algorithms14 (10%)Multimodal and novel applications14 (10%)Compute-efficient LMs10 ( 7%) : Raw numbers and percentages of survey respon-dents who selected a certain research area. Respondentswere allowed to select multiple areas, which is why thenumbers add up to more than 138. Refer to the full sur-vey for details on what each umbrella term represents.",
  "By clicking \"Yes\" below, I am verifying that I haveread the description above and I consent to partici-pate in this research study. Yes No": "What do we mean by model analysis andinterpretability research?Model analysis and interpretability research innatural language processing (NLP) aims to developa deeper understanding of and explain the behaviorof NLP systems. This includes (but is not limited to) explainingmodelsinternalcomputations,investigatingbroader phenomena observed during pre-trainingor adaptation, and providing a better understandingof the limitations and robustness of existingmodels. Work on topics such as attribution methods, prob-ing, mechanistic interpretability, analysis of embed-ding spaces, explainability, analysis of training dy-namics, analyzing model bias, etc., are additionalexamples of model analysis and interpretability re-search.",
  "Other [fill in]": "2. What is your area of research?Feel free to select multiple options or add missingones.(The list below is adapted from the calls for papersof COLM and ARR.) LM adaptation: fine-tuning, instruction-tuning,reinforcement learning (with human feedback),prompt tuning, and in-context alignment Data for LMs: pre-training data, alignment data,and synthetic data via manual or algorithmicanalysis, curation, and generation Evaluation of LMs: benchmarks, simulationenvironments,scalableoversight,evaluationprotocols and metrics, human and/or machineevaluation Societal implications: bias, fairness, account-ability, transparency, equity, misuse, jobs, climatechange, and beyond Safety:security,privacy,misinformation,adversarial attacks and defenses Science of LMs: scaling laws, fundamentallimitations, emergent capabilities, demystification,interpretability, complexity, training dynamics,grokking, learning theory for LMs Compute efficient LMs:distillation, com-pression, quantization, sample efficient methods,memory efficient methods Engineering for large LMs: distributed trainingand inference on different hardware setups,training dynamics, optimization instability Learning algorithms:learning, unlearning,meta learning, model mixing methods, continuallearning Inference algorithms:decoding algorithms,reasoning algorithms, search algorithms, planningalgorithms Human mind, brain, philosophy, laws andLMs: cognitive science, neuroscience, linguistics,psycholinguistics, philosophical, or legal perspec-tives on LMs LMs for everyone: multilinguality, low-resourcelanguages, vernacular languages, multiculturalism,value pluralism LMs and the world:factuality, retrieval-augmented LMs, knowledge models, common-sense reasoning, theory of mind, social norms,pragmatics, and world models LMs and embodiment:perception, action,robotics, and multimodality LMs and interaction: conversation, interactive learning, and multi-agents learning LMs with tools and code: integration with toolsand APIs, LM-driven software engineering LMs on diverse modalities and novel applica-tions: visual LMs, code LMs, math LMs, and soforth, with extra encouragements for less studiedmodalities or applications such as chemistry,medicine, education, database and beyond NLP applications: sentiment analysis, summa-rization, question answering, etc. Computational linguistics: discourse, pragmat-ics, phonology, morphology, syntax, semantics Information extraction, information retrieval,text mining Neurosymbolic approaches Non-neural methods approaches for NLP Other [fill in]",
  "Your take on model analysis andinterpretability research": "Reminder: What do we mean by model analysisand interpretability research?Model analysis and interpretability research innatural language processing (NLP) aims to developa deeper understanding of and explain the behaviorof NLP systems. This includes (but is not limited to) explainingmodelsinternalcomputations,investigatingbroader phenomena observed during pre-trainingor adaptation, and providing a better understandingof the limitations and robustness of existingmodels. Work on topics such as attribution methods,probing, mechanistic interpretability, analysisof embedding spaces, explainability, analysis oftraining dynamics, analyzing model bias, etc.,are additional examples of model analysis andinterpretability research. 3. How much do you agree with the followingstatement?The progress in NLP in the last five years would nothave been possible without findings from modelanalysis and interpretability research. 1: strongly disagree",
  "3 4 5: strongly agree": "4. How much do you agree with the followingstatement?The progress in NLP in the last five years wouldhave been slower without findings from modelanalysis and interpretability research. 1: strongly disagree 2 3 4 5: strongly agree 5. How many model analysis and interpretabil-ity works do you read compared to other topics? I dont usually read model analysis and inter-pretability work, but I do read NLP works aboutother topics I do read some model analysis and interpretabilitywork, but much less than other topics I read model analysis and interpretability work inabout the same volume as other NLP-related topics I read model analysis and interpretability workmore than other NLP topics Most of the works I read are about model analysisand interpretability 6. How, if at all, does model analysis and inter-pretability work influence your own work? It provides me with new research ideas It changes my mental model of what thecapabilities and limitations of models are It helps me ground my explanations of my ownresults It adds useful tools for me to visual-ize/evaluate/understandthebehaviorofamodel It does not influence my work Other [fill in]",
  "tion heads, causal interventions, MLP layers askey-value memories, etc.)? Never Rarely Sometimes Often Always": "9.Do you think model analysis and inter-pretability research is important, and if so, why? Understanding model limitations and capabili-ties Making models more computationally efficient Developing safety mechanisms Improving model trustworthiness Explainability for users To fullfill legal requirements (e.g., GDPR) Improving model capabilities Developing novel architectures Developing novel architectures I do not think model analysis and interpretabilitywork is important Other [fill in]",
  "[OPTIONAL]11. In your opinion, how important is modelanalysis and interpretability research to workin the areas below?": "Work on multilinguality and low-resource lan-guages Model analysis and interpretability research isnot important for Model analysis and interpretability research issomewhat important for Model analysis and interpretability research isvery important for Work on multimodal learning, grounding, andembodiment Model analysis and interpretability research isnot important for Model analysis and interpretability research issomewhat important for Model analysis and interpretability research isvery important for Work on engineering for large language models Model analysis and interpretability research isnot important for Model analysis and interpretability research issomewhat important for Model analysis and interpretability research isvery important for Work on factuality, reasoning, world models Model analysis and interpretability research isnot important for Model analysis and interpretability research issomewhat important for Model analysis and interpretability research isvery important for Work on societal implications, bias, misuse, andbeyond Model analysis and interpretability research isnot important for Model analysis and interpretability research issomewhat important for Model analysis and interpretability research isvery important for",
  "CQualitative coding": "Qualitative coding is an inductive methodologyfrom the social sciences (Saldana, 2021), used tosystematically surface thematic patterns in datawith less structure In the context of this paper,we use qualitative coding to analyze open-endedsurvey responses, and paper titles and abstracts.Two authors performed qualitative analysis of all70 open-ended survey responses, and 556 papers(based on their titles and abstracts).We began by analyzing the survey responses:one round of independent coding was done, basedon which we reviewed our codes to normalize termsand resolve disagreements. After this, a secondround of annotation was performed.",
  ": Growth of accepted papers per track in com-paring ACL/EMNLP in 2020 vs. in 2023. This consid-ers the tracks that have consistently existed in ACL andEMNLP in both those years": "As for the paper annotations, the authors dida combination of independent coding (with dis-cussion and re-coding), and co-coding. Through-out the annotation process, the authors followedbest practices by working closely together to clar-ify the annotation procedure, discuss the emergingthemes, and re-annotate data that was coded earlyon (Bengtsson, 2016). We iteratively merged codes for related themes(e.g., pre-training trajectories and training dynam-ics), and to resolve inconsistencies from typos (e.g.,in-context learning instead of in-contex learning)and to normalize themes (e.g., interventions insteadof intervention), where applicable. All merging op-erations are released as part of our code.",
  "Data sourceInstancesThemes (total)Themes (per instance)Agreement": "Survey (whats missing?)42442.1291.01Survey (why not important?)691.5100.00Survey (additional thoughts)22291.95100.00Papers (survey)29594.28100.00Papers (top-50 IA)501155.3897.03Papers (top-50 non-IA)50994.4696.41Papers (non-IA papers highlyinfluenced by IA)4563274.9097.49 : Qualitative coding statistics. For each data source, we list the total number of data instances, the totalnumber of themes assigned, the number of themes per instance, and the percentage agreement between the codesassigned by two annotators.",
  "Industry": ": Betweenness centrality of ACL and EMNLP papers since 2020 by track. Lines at the middle of the box rep-resent the medians, but some tracks have their median at 0. IA papers are more central than papers from most tracks. Betweenness centrality shows the be-tweenness centralities for the different tracks weconsider. We note that for this analysis we only con-sider the portion of the citation graph for which wehave gold track labels. Our results show that IA hasthe second largest median centrality. This indicatesthat IA plays a central role in the ACL/EMNLPcitation graph, in the sense that IA papers often lieon the shortest path that connects to random papersof the graph.",
  "shows the top themes that appear in (1) the papersmentioned by survey participants; (2) the top-50most cited IA papers; (3) the top-50 most citednon-IA papers": "Citational intent shows the distribu-tion of citation intents for three groups: IA paperssuggested in our survey responses, the top cited IApapers in ACL/EMNLP, and the overall most citedpapers in ACL/EMNLP within our citation graph.Both the IA papers suggested in our survey and thetop cited IA papers in ACL/EMNLP are primarilycited as background information. In contrast, the",
  "SourceTop themes (% of papers in which the theme appears)": "Surveyrepresentation analysis (34%), novel method (24%), probing (24%), attention analysis(21%), interventions (17.2%), mechanistic interp (17.2%), attribution (17.2%)Top-50 IAanalysis (40%), novel method (36%), evaluation (32%), explainability (20%), lin-guistics (16%), probing (16%)Top-50 non-IAnovel model (34%), novel method (32%), novel dataset (24%), analysis (16%) : Top themes of highly influential IA papers (mentioned by survey respondents and top-50 most-cited IApapers from the citation graph), compared to the top themes of the top-50 most-cited non-IA papers. Themes arenot mutually exclusive.",
  "Year": "10% 15% 20% 25% 30% 35% 40% 45% 50% Ratio of Intra-track Citations Question AnsweringDialogueInformation Extraction/RetrievalMachine LearningSummarizationMultimodality, Speech andGroundingGenerationMachine Translation andMultilingualitySocial ScienceEthicsInterpretability and Analysis : Ratio of intra-track citations according to thepredictions of our classifier. It measures the percentageof citations to papers of track A from papers that arealso in track A. IA does not stand out in terms of thepercentage of citations which are made by other papersof its own track."
}