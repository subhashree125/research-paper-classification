{
  "Abstract": "Large language models (LLMs) are capable ofproducing documents, and retrieval augmentedgeneration (RAG) has shown itself to be a pow-erful method for improving accuracy withoutsacrificing fluency. However, not all informa-tion can be retrieved from text. We propose anapproach that uses the analysis of structureddata to generate fact sets that are used to guidegeneration in much the same way that retrieveddocuments are used in RAG. This analyticsaugmented generation (AAG) approach sup-ports the ability to utilize standard analytic tech-niques to generate facts that are then convertedto text and passed to an LLM. We present a neu-rosymbolic platform, SATYRN, that leveragesAAG to produce accurate, fluent, and coherentreports grounded in large scale databases. Inour experiments, we find that SATYRN gener-ates reports in which over 86% of claims areaccurate while maintaining high levels of flu-ency and coherence, even when using smallerlanguage models such as Mistral-7B, as com-pared to GPT-4 Code Interpreter in which just57% of claims are accurate.",
  "Introduction": "In recent times, large language models (LLMs)have seen a meteoric rise in popularity due to theirability to generate fluent and coherent language.However, these models often struggle to producetruthful outputs (Ji et al., 2022; Huang et al., 2023;Borji, 2023). Methods such as retrieval augmentedgeneration (RAG) (Lewis et al., 2021) have beendeveloped to address such concerns. Yet, they toohave an important limitation: they only work whenthe required information is present in textual form.For many sources of information, such as relationaldatabases, the sought after information must be de-rived via computation and analysis of those data.Performing this analysis and providing the resultsto an LLM is another way to augment their genera-tion with a far broader array of information. Such analytics augmented generation (AAG) supportsthe use of standard analytics techniques to generatefacts that are converted to text and used to guidethe generation of accurate responses.This has motivated the development of meth-ods in which an LLM invokes tools and externalcomputation engines for deriving information fromstructured data (Schick et al., 2024; Mastermanet al., 2024). This is also the approach of OpenAIsCode Interpreter1 which can be used for generat-ing reports that present information derived fromstructured data. However, these approaches let theLLMs decide when to call these tools and write thequeries required to derive the information, an inher-ently non-deterministic procedure that can makethem unreliable in producing the set of informationto communicate in a report.In this paper, we present SATYRN2, a neurosym-bolic platform which leverages AAG for produc-ing factual, fluent, and coherent reports. SATYRNseparates the analysis from the language genera-tion process in order to steer LLMs using factsderived from relational databases. It deterministi-cally produces the analysis plans required to satisfythe informational needs of a report, generates tem-plated language describing the results, and thenuses a language model to generate the final report.This separation of the analysis and generation stepsalong with the deterministic nature of the analysisplanning improves factual accuracy compared toexisting solutions like Code Interpreter. In our ex-periments on the report generation task, we see afactual accuracy of 86% using SATYRN comparedto 57% using Code Interpreter.One of SATYRNs highlights is its ability to effec-tively utilize small, off-the-shelf models to achievehighly accurate results. In our experiments, the twolocal models we used were Mistral-7B and 4-bit",
  "First,we propose SATYRN,a scalable,domain-agnostic, and neurosymbolic platformfor producing fluent and coherent reports thatadhere to the source data (2)": "Second, we demonstrate how SATYRN canbe used for producing reports and compareit with other methods (3).In our exper-iments, we generate 200 reports with over3200 claims, across 3 broadly applicable re-port types and 8 domains and evaluate thereports for accuracy, fluency, and coherence. Third, we provide an analysis of the factualaccuracy, fluency, and coherence of generatedreports (4). We find that reports producedby SATYRN strongly adhere to the data whilemaintaining high degrees of fluency and co-herence, even when using smaller models.",
  "Methods": "In this section, we present the components ofSATYRN that allow it to perform analytics on thedata, irrespective of its domain, in order to generateaccurate, fluent, and coherent reports grounded bythis data. The high level architecture of SATYRNis shown in . Beginning with the data in(1), we create a lightweight knowledge representa-tion, called a ring, that provides simple semantic labels that describe how the data can be analyzedby SATYRN. We introduce a new plan represen-tation language called Structured Question Repre-sentation (SQR) (pronounced seeker) that allowscomplex analyses to be specified according to thesemantic enhancements.The input to SATYRN is a structured informationrequest and the output is a report satisfying thisrequest with an answer and contextualizing infor-mation. This request is a JSON object describingthe type of report to generate, the subject of thereport, a metric to use when evaluating the subject,and any filters to apply to the data before analysis.Report blueprints (2) specify the information to bederived via analysis of the data and are used to pro-duce a set of executable plans. With the analysisengine (3), each of these plans is executed in orderto derive the information. The outputs are format-ted as statements and used as input to the LLM (4)which generates the final report.",
  "SATYRN Rings": "SATYRN requires knowledge of the objects the datadescribes in order to apply analytics and produceinformation regardless of a datasets domain.To achieve this, we define a lightweight labelingcalled a ring which specifies the entities in thedata, their attributes, and the relationships betweenthese entities. This labeling allows SATYRN torun analyses on the data without the need for anydomain information. New datasets can be utilizedwithin SATYRN by creating a ring and filling in thenecessary details described below. depicts",
  "Metric: values meant to be used as a measurefor ranking and comparing entities": "Rings also contain domain-specific information.We define nicenames for both attributes and entitiesto provide more descriptive labels than columnheaders. Units (e.g., dollars, acres) can also bedefined for attributes. This domain knowledge isused to help SATYRN better express the informationit derives in natural language.The knowledge encapsulated by a ring makes itsimple to specify and execute analytic operations.For instance, attributes of an entity can be present inmultiple underlying data tables necessitating joinsbetween these tables when retrieving these values.We define these joins inside the ring, abstractingaway the need to specify them at runtime whenperforming operations that span multiple databasetables. Similarly, when SATYRN performs an ana-lytic operation involving multiple entities, joins areneeded to connect the underlying database tables.For each pair of entities, relationships encapsulatethe required joins so these details can be abstractedaway during the specification of the analytics.",
  "Structured Question Representation(SQR)": "In order to leverage the knowledge in a ring andeffectively apply analytics, an expressive and com-positional plan representation in which plans canbe reused across datasets is required. To satisfythese representational needs, we define an analyticplan representation language, SQR, which abstractsaway specific implementation details of the under-lying query language. This simplifies the syntaxand makes it agnostic to the data storage formatand corresponding query language. SQR allowsfor the specification of plans in which the entities and attributes defined in the ring are retrieved andanalyzed using analytic operations.A SQR plan is represented as a directed acyclicgraph that specifies an ordered series of steps tocarry out, wherein operations are chained togetherin order to retrieve and analyze data. Each node ofthe graph represents an analytic operation whoseoutput is fed to later steps that require the result.The inputs and outputs of these analytic operationsutilize attribute types in order to determine howoperations can be chained together to form a com-plete SQR plan. Existing operations enable ag-gregation (e.g., average, count, sum), comparison(e.g., greater than, exact, not), and data manipula-tion (e.g., sort, groupby, limit). A full listing ofthe SQR operations that are currently implementedwithin SATYRN is provided in Appendix D. Newoperations can be added to incorporate new ana-lytic capabilities. Arbitrarily complex plans can becomposed to satisfy any information goal that canbe described with the available data and analytics.A SQR plan example can be seen in .Query languages like SQL require joins betweentables to be explicit in the query. However, joinsare not needed within SQR. Any required joinsare encoded within the ring and are used in thedefinition of relationships between entities. Suchjoins are automatically added to the final queryagainst the database when parsing SQR to SQL. |1| (retrieve_entity Business)|2| (retrieve_entity Review)|3| (retrieve_attribute |1| business_id)|4| (retrieve_attribute |2| stars)|5| (groupby |3|)|6| (average |4| |5|)|7| (retrieve_attribute |1| operating)|8| (exact |7| True)|9| (collect |3| |6|)|10| (return |9| |8|) |1| (retrieve_entity Business)|2| (retrieve_entity Review)|3| (retrieve_attribute |1| business_id)|4| (retrieve_attribute |2| stars)|5| (groupby |3|)|6| (average |4| |5|)|7| (retrieve_attribute |1| operating)|8| (exact |7| True)|9| (collect |3| |6|)|10| (return |9| |8|)",
  "SQR Plan Templates": "A SQR plan template is a SQR plan with slotsto be filled with entities, attributes, values, andoperations. All slots used within the SQR plantemplate correspond to the attribute types used in aring, making the plan templates domain-agnosticand thus reusable with any ring. We define a set ofSQR plan templates for use within SATYRN. EachSQR plan template has an associated statement template that describes the result of executing theplan template. These statement templates haveslots for the natural language expression of specificentities, attributes and values, that correspond tothe slots in the SQR plan templates.",
  "Analysis Engine": "SQR plans first need to be converted to a queryformat that is native to the data source (e.g., SQLfor relational databases) in order to be executed toderive results. We build an analysis engine that iscapable of parsing SQR plans, converting them tovalid SQL queries against the underlying data, andproducing the nicenames and units for all queryresults. Implementation details are provided inAppendix A. 2.4.1Generation of Factual StatementsThe output of the SQL query derived from a SQRplan is a set of raw result tuples that lack contex-tual information, making it difficult for an LLM toparse. To address this issue, the analysis engine canproduce statements in natural language by utilizingthe statement template associated with a SQR plantemplate and filling its slots with the values, nice-names, and units obtained by executing a SQR plan.Examples of generated statements can be seen in as the output of the Analysis Engine.",
  "Domain-Agnostic Report Blueprints": "For each kind of report, we create a report blueprintthat defines the information that should be includedin the report. Each blueprint comprises a collectionof SQR plan templates that define the core analyticsto perform in order to satisfy the information goalsof this type of report. Inputs to a blueprint includethe target entity, the metric of interest, and anyfilters that should be used to retrieve and filter thedata for analysis. Additional inputs can also bedefined as required.Blueprints provide three key elements requiredfor generating reports: (1) Rules for mapping inputs to SQR plans.Rules map the target entity and any associatedfilters provided by the user to SQR plans forretrieving and filtering the data. For the metric,there is a rule that produces the SQR plan forderiving the value of this metric from the data.",
  "SQR Plan:": "|1|: (retrieve_entity State)|2|: (retrieve_attribute |1| name)|3|: (retrieve_entity Wildfire)|4|: (retrieve_attribute |3| size)|5|: (groupby |2|)|6|: (average |4| |5|)|7|: (greaterthan |4| 5)|8|: (collect |2| |6|)|9|: (return |8| |7|)|10|: (retrieve_attribute |9| |2|)|11|: (retrieve_attribute |9| |6|)|12|: (sort |11| desc)|13|: (rownum |12|)|14|: (collect |13| |10|)|15|: (return |14| |12|)|16|: (retrieve_attribute |15| |13|)|17|: (retrieve_attribute |15| |10|)|18|: (exact |17| \"California\")|19|: (collect |16| |17|)|20|: (return |19| |18|)",
  "Ordering: descending order": "Prompt Template:Generate a report for California ranking it according to average wildfire size for wildfires greater than 5 acres.Higher values are considered better. The audience is educated, but may not understand technical terms. Please usenatural sounding language and try to find more natural terms for the groups that are mentioned. Use only the factsprovided in the context. Context: California is ranked {Result} according to average wildfire size for wildfiresgreater than 5 acres when ranked in descending order. ... : An instantiation of a report blueprint for ranking California against other states by average wildfire size.The resulting SQR plans will be executed and their results are inserted into the prompt to form the input to the LLM. plan template according to the requirements ofthat plan template and the information goalsof the report. Using these assignments, eachSQR plan template is filled with the properentities, attributes, and filters to produce anexecutable SQR plan.",
  "(3) A prompt template that is filled in based onthe blueprint inputs. This includes a descrip-tion of the report to be generated, and the setof factual statements generated by SATYRN": "An example blueprint which shows how thesethree key elements are used for a specific user in-put can be seen in . The blueprint rulesmake use of the attribute types defined in the ring.This allows inputs from the users to be mapped toplans irrespective of any domain specifics. As aresult, blueprints scope across any domain and arereusable for any ring which is provided to SATYRN.Implementation details for the blueprints are pro-vided in Appendix B.",
  "Execution of a Report Blueprint": "Blueprint execution requires an input of a targetentity, relevant metric information, and filters thatare to be applied. Using the defined rules, the plantemplates in the blueprint gets populated to provideexecutable SQR plans. The analysis engine exe-cutes these plans and generates language describingthe results using the statement templates associatedwith the plan templates. Finally, the prompt tem-plate defined in the blueprint gets populated withthe generated factual statements and is sent to thelanguage model to generate a coherent, fluent, andfactual report. Example report outputs can be seenin Appendix F.",
  "We evaluate the performance of SATYRN alongwith two baselines on the task of generating reportsfor a specific information request. Reports are eval-uated based on their accuracy, fluency, and coher-": "ence. We create three report blueprints: a Rankingreport that ranks an entitys performance amongstits cohort, a Time over Time report that comparesan entitys performance at two time periods, anda Comparative Benchmark report that comparesan entitys performance with a benchmark value.Further details on the specific information require-ments of each report type can be found in AppendixC.1. These three report blueprints are each usedacross eight domains: healthcare, environmentalsustainability, urban housing, criminal justice, edu-cation, legal and judicial, socioeconomic, and busi-ness. A summary of the datasets can be found inAppendix C.4. We create a ring for each dataset.",
  "Report Generation Modes": "SATYRN: This generation mode utilizes SATYRNfor generating the reports. It uses the factual state-ment generation detailed in .4.1 whenbuilding the prompt. We use three LLMs for gener-ation: Mistral-7B (Jiang et al., 2023), Mixtral-8x7B(Jiang et al., 2024), and GPT-4. Mixtral-8x7B wasquantized to 4-bits (Frantar et al., 2023).SATYRN-Table (ablation): This mode is thesame as SATYRN, except that factual statements arereplaced by tables containing the results of execut-ing the underlying SQL query. This is an ablationfor determining the utility of the factual statementsversus raw SQL results as prompting inputs.Unaugmented GPT-4 (baseline): The first base-line generation mode tests the models ability touse its parametric knowledge to generate a factualreport. Instead of augmenting the generation withinformation derived via analysis, we provide thetarget entity, metric and a description of the infor-mation to be included in the report.Code Interpreter (baseline): We also compareSATYRN with OpenAIs Code Interpreter whichcan take one or more data files, write code to extractinformation, and then generate natural languageoutputs. We provide the model with descriptionsof the information to present in the prompt. Giventhe data and the prompt, it must determine how toderive this information and generate a report. Wegive the tool direct access to the same data usedby SATYRN. However, due to limitations on thenumber of files and their sizes, we cannot generatereports for domains with larger datasets, namelythe legal and judicial, environmental sustainability,and business domains. Thus, we generate reportswith Code Interpreter for only five domains.",
  "Report Evaluation": "We use three metrics for evaluating reports: fluency,coherence, and accuracy. We evaluate the first twousing the summarization checkpoint of UniEval(Zhong et al., 2022). The source documents usedin the coherence scoring are the factual statementsassociated with that report. For determining theaccuracy, we manually examine each report to findthe percentage of claims made that are supported byfacts derived from the data. The ground truth factsare produced by SATYRN and used when evaluat-ing across all modes. Discrepancies in the reportsgenerated by the baselines and the facts generatedby SATYRN were manually checked by examiningthe data to ensure fairness. The accuracy evaluationwas carried out in two steps: claim identificationand claim classification. Each claim is classifiedas either factual (supported by the data), refuted(contradicted by the data), or confabulated (notinferrable from the data). For full class definitionsand the rubric used for identifying and classifyingclaims, see Appendix E. Each report was evaluatedby two of the authors, and we computed an inter-annotator agreement score with Krippendorffs (Hayes and Krippendorff, 2007) using the ratio offactual to total claims, resulting in an of 0.86.",
  "Factual Accuracy": "shows the difference in the fraction ofclaims that were classified as factual for each gen-eration mode. The two baselines, UnaugmentedGPT-4 and Code Interpreter, had 48% and 57% fac-tual accuracy respectively. The ablated SATYRN-Table mode was comparable with both of the base-lines, even with the smallest model, Mistral-7B. Inthis ablation study, we observed that larger mod-els were much better at processing informationstructured as tables. However, when we structurethe information in natural language statements andpass these to the LLMs instead, the differences inaccuracy between the small and large models van-ish entirely. Mistral-7B benefits the most with anincrease of 34 points from its performance in theablation. SATYRN outperforms the closest baseline",
  "Fluency and Coherence": "We find that reports produced by each generationmode exhibit high degrees of fluency as shown in. Reports generated by GPT-4 show slightlyhigher fluency scores than those generated by thesmaller models. This is expected behavior sinceLLMs trained on larger datasets with more parame-ters are found to exhibit improved generative capa-bilities (Kaplan et al., 2020; Hoffmann et al., 2022).A similar result is found for the coherence of thereports, with all generation modes demonstratinghigh levels of coherence as shown in .",
  "Claim Type Breakdown": "In , we normalize by the total number ofclaims, and present a breakdown of the fraction offactual, confabulated, and refuted claims. An inter-esting observation here is the distinction betweenthe types of unsupported claims made by Unaug-mented GPT-4 versus Code Interpreter. Unaug-mented GPT-4 makes a lot of confabulated claimssince it does not have access to any data or knowl-",
  ": The fraction of claims that were classified asfactual, confabulated, or refuted": "edge source. It also makes a lot of vague, but truestatements (e.g., \"This value is higher than the min-imum value but not quite at the maximum value.\").On the other hand, Code Interpreter is often un-able to correctly derive information from the data,resulting in refuted claims.We observe that the Unaugmented GPT-4 base-line has far fewer claims than other modes as seenin . This is due to many of the sentences inits reports containing placeholder values and fewconcrete claims of fact that can be evaluated (e.g.,\"In comparison with Y, Bond County ranks Z.\").",
  "SATYRN Platform": "SATYRN is a platform for enabling users to pro-duce fluent, coherent, and accurate reports that aregrounded by their data. SATYRNs capabilities canbe expanded with new datasets, new analytics, andnew report types.To utilize a new dataset, a ring can be created.Given a ring, all existing analyses can be appliedto the data and all report blueprints can be usedto generate reports with them. The only exceptionis when the data itself does not support a partic-ular kind of report. For example, the Time over",
  ": The average number of claims made for eachconfiguration across all domains": "Time report used in the experiments requires thedata be temporal so that analyses like change overtime can be computed. To enable new analyticswithin Satyrn, additional SQR plan templates canbe added to SATYRN. To enable a new reporttype to be generated, a report blueprint can be cre-ated. New blueprints can utilize any of the SQRplan templates available within SATYRN to deter-ministically guarantee the desired information isproduced when generating a report. This cross-compatibility of all components of the platformensures that SATYRN is scalable to new datasets,new analyses, and new report types.",
  "Related Work": "Domain and Analytics Representations Highlyspecialized ontologies have been developed fora diverse range of areas such as medicine (Sal-vadores et al., 2013), law (Casellas, 2011), food(Kamel Boulos et al., 2015), chemical engineer-ing (Marquardt et al., 2010), and biological envi-ronments (Buttigieg et al., 2013). However, theproduction of ontologies such as these requires ex-tensive expertise in ontology design and substantialamounts of time. (Patterson et al., 2019) have se-mantically enriched data science scripts with thegoal of successfully modeling computer programs.However, their work focuses more on supportingautomated reasoning about data science softwarerather than encoding core analytic knowledge andprocesses that can be used when mapping analyticsonto data in a domain-agnostic fashion.Knowledge Augmented Generation One keymethod to promote factual generation by an LLMis using an external knowledge source to augment the generation (Chen et al., 2017; Lewis et al.,2021; Shuster et al., 2021; Izacard et al., 2022; Siri-wardhana et al., 2023). Knowledge graphs (Minet al., 2020; Baek et al., 2023), textual documents(Paranjape et al., 2021; Trivedi et al., 2023), pre-processed vectors (Verga et al., 2021), search en-gines (Nakano et al., 2021), and even other LLMs(Shwartz et al., 2020) have all been used as exter-nal knowledge bases. External symbolic engineshave also been used to perform computation or rea-soning, the results of which are used to augmentan LLMs generation (Schick et al., 2024; Zhuanget al., 2023; Peng et al., 2023). While our work alsoutilizes a symbolic engine, we enhance relationaldatabases with lightweight semantics in order tomap the data to the operations of this engine andobtain results in natural language.Data-to-Text Generation A related task of data-to-text generation where the goal is to generatedescriptions of structured data organized in tableshas been studied for a long time (Kukich, 1983;Reiter and Dale, 2000). Traditionally, templatebased algorithms were used to build data-to-textsystems (Oh and Rudnicky, 2000; Stent et al., 2004;Kondadadi et al., 2013), while recent approacheshave adopted a plan-then-generate procedure (Suet al., 2021). Currently, the most popular method isto use end-to-end neural pipelines where the modelis fine-tuned to produce text from data (Puduppullyet al., 2019; Yang et al., 2021; Ghosal et al., 2023;Zhao et al., 2023). Our approach differs in three keyways: 1) we target large scale databases rather thansmall tabular data, 2) we use an LLM for generationwith no fine-tuning, and 3) our approach enablesinformation not already present in the data to becomputed at run-time for use in generation.",
  "Conclusion": "We present SATYRN, a system that leverages AAGto produce highly accurate, fluent, and coherent re-ports that adhere to information derived from data.We find that SATYRN generates reports that containover 86% accurate claims as compared to GPT-4Code Interpreter in which just 57% of claims areaccurate. Notably, this is accomplished using afar smaller model, while preserving high levels offluency and coherence. In the future, we plan todevelop automatic validation methods to furtherimprove the accuracy of generated reports. Addi-tionally, we plan to allow language to be used asinput rather than structured information requests.",
  "Limitations": "In this section, we discuss limitations and futuredirections for this work.Input to SATYRN is not language: The inputto SATYRN is currently a structured informationrequest containing the type of report to generate,the subject of the report, a metric to use when eval-uating the subject, and any filters to apply to thedata before analysis. While this structure guar-antees SATYRN will generate the correct kind ofreport, it is also more cumbersome to specify thana request in natural language. We plan to addressthis limitation by utilizing SATYRNs knowledgeof the questions it can answer based on the avail-able analytics to build a dataset question and SQRplans pairs in order to train a model for convertingquestions to SQR plans.Report structure is encoded by model: Oneaspect of our report generation method that makesit somewhat limited is our reliance on the LLMto encode the structure of the report type ratherthan controlling for this ourselves. While we doconsider this somewhat desirable, as it prevents usfrom having to define an explicit structure for eachnew type of report we wish the system to generate,it also means that we have little control over thedocument structure and as such, the quality andcoherence of the structure depends on how well itis encoded in the LLM.Report validation: Our approach has anotherlimitation that it shares with RAG approaches: val-idation. Automatic fact extraction and claim verifi-cation is an active area of research (Min et al., 2023;Wei et al., 2024; Song et al., 2024). Measuring thefactual accuracy of the reports generated in ourexperiments involved us manually labeling eachclaim as factual, confabulated or refuted. Furtherresearch in the direction will greatly help in evalu-ating systems like ours, and other natural languagegeneration methods, at a larger scale.",
  "Ethics Statement": "In this work we present a system that automates theprocess of generating documents from data. Whilethe aim of SATYRN is to ground generated reportsin truth, particularly as compared to an unguidedLLM, the system does not preclude the generationof reports from factually flawed data. As such,it is contingent on the systems user to verify theaccuracy and validity of raw datasets fed to thesystem. Additionally, we rely on an LLM to generate thelanguage of a report. Such models have encodedbiases that could crop up in the final report andcould result in biases or other undesirable language.It is conceivable that bad faith actors could workto manipulate the presentation of information toultimately misinform people with a highly skewedversion of the truth. This remains a challenge forany approach which uses an LLM for generating adocument. We would like to thank the Center for Advancingthe Safety of Machine Intelligence (CASMI) forfunding this work. We also thank Mohammed A.Alam, David Demeter, Alexander Einarsson, andSergio Servantez for providing constructive feed-back as well as the ACL ARR reviewers for theirvaluable comments.",
  "Andrew F Hayes and Klaus Krippendorff. 2007. An-swering the call for a standard reliability measure forcoding data. Communication methods and measures,1(1):7789": "Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch,Elena Buchatskaya, Trevor Cai, Eliza Rutherford,Diego de Las Casas, Lisa Anne Hendricks, JohannesWelbl, Aidan Clark, et al. 2022. An empirical analy-sis of compute-optimal large language model training.Advances in Neural Information Processing Systems,35:3001630030. Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong,Zhangyin Feng, Haotian Wang, Qianglong Chen,Weihua Peng, Xiaocheng Feng, Bing Qin, et al. 2023.A survey on hallucination in large language models:Principles, taxonomy, challenges, and open questions.arXiv preprint arXiv:2311.05232.",
  "IllinoisStateBoardofEducation.2022.2022reportcardpublicdataset": "Gautier Izacard, Patrick Lewis, Maria Lomeli, LucasHosseini, Fabio Petroni, Timo Schick, Jane Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and EdouardGrave. 2022. Atlas: Few-shot learning with retrievalaugmented language models. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, DanSu, Yan Xu, Etsuko Ishii, Yejin Bang, Delong Chen,Wenliang Dai, Andrea Madotto, and Pascale Fung.2022. Survey of hallucination in natural languagegeneration. ACM Computing Surveys, 55:1 38. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, et al. 2023. Mistral7b. arXiv preprint arXiv:2310.06825. Albert Q Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, Chris Bam-ford, Devendra Singh Chaplot, Diego de las Casas,Emma Bou Hanna, Florian Bressand, et al. 2024.Mixtral of experts. arXiv preprint arXiv:2401.04088.",
  "Alistair Johnson, Lucas Bulgarelli, Tom Pollard,Leo Anthony Celi, Steven Horng, Roger Mark, andMassachusetts Institute of Technology [MIT]. 2023.Mimic-iv-ed demo v2.2": "Maged N Kamel Boulos, Abdulslam Yassine, ShervinShirmohammadi, Chakkrit Snae Namahoot, andMichael Brckner. 2015. Towards an internet offood: food ontologies for the internet of things. Fu-ture Internet, 7(4):372392. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom BBrown, Benjamin Chess, Rewon Child, Scott Gray,Alec Radford, Jeffrey Wu, and Dario Amodei. 2020.Scaling laws for neural language models.arXivpreprint arXiv:2001.08361. Ravi Kondadadi, Blake Howald, and Frank Schilder.2013. A statistical NLG framework for aggregatedplanning and realization. In Proceedings of the 51stAnnual Meeting of the Association for ComputationalLinguistics (Volume 1: Long Papers), pages 14061415, Sofia, Bulgaria. Association for ComputationalLinguistics. Karen Kukich. 1983. Design of a knowledge-basedreport generator. In 21st Annual Meeting of the As-sociation for Computational Linguistics, pages 145150, Cambridge, Massachusetts, USA. Associationfor Computational Linguistics. Patrick Lewis, Ethan Perez, Aleksandra Piktus, FabioPetroni, Vladimir Karpukhin, Naman Goyal, Hein-rich Kttler, Mike Lewis, Wen tau Yih, Tim Rock-tschel, Sebastian Riedel, and Douwe Kiela. 2021.Retrieval-augmented generation for knowledge-intensive nlp tasks.",
  "Sewon Min, Danqi Chen, Luke Zettlemoyer, and Han-naneh Hajishirzi. 2020. Knowledge guided text re-trieval and reading for open domain question answer-ing": "Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis,Wen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettle-moyer, and Hannaneh Hajishirzi. 2023. FActScore:Fine-grained atomic evaluation of factual precisionin long form text generation. In Proceedings of the2023 Conference on Empirical Methods in NaturalLanguage Processing, pages 1207612100, Singa-pore. Association for Computational Linguistics. Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,Long Ouyang, Christina Kim, Christopher Hesse,Shantanu Jain, Vineet Kosaraju, William Saunders,et al. 2021.Webgpt: Browser-assisted question-answering with human feedback.arXiv preprintarXiv:2112.09332.",
  "Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela,and Jason Weston. 2021. Retrieval augmentationreduces hallucination in conversation": "Vered Shwartz, Peter West, Ronan Le Bras, ChandraBhagavatula, and Yejin Choi. 2020. Unsupervisedcommonsense question answering with self-talk. InProceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 46154629, Online. Association for Computa-tional Linguistics. Shamane Siriwardhana, Rivindu Weerasekera, ElliottWen, Tharindu Kaluarachchi, Rajib Rana, andSuranga Nanayakkara. 2023. Improving the domainadaptation of retrieval augmented generation (rag)models for open domain question answering. Trans-actions of the Association for Computational Linguis-tics, 11:117.",
  "U.S. Census Bureau. 2022c. Estimate of people of allages in poverty in cook county, il": "Pat Verga, Haitian Sun, Livio Baldini Soares, andWilliam Cohen. 2021. Adaptable and interpretableneural MemoryOver symbolic knowledge. In Pro-ceedings of the 2021 Conference of the North Amer-ican Chapter of the Association for ComputationalLinguistics: Human Language Technologies, pages36783691, Online. Association for ComputationalLinguistics. Jerry Wei, Chengrun Yang, Xinying Song, Yifeng Lu,Nathan Hu, Dustin Tran, Daiyi Peng, Ruibo Liu,Da Huang, Cosmo Du, et al. 2024. Long-form fac-tuality in large language models.arXiv preprintarXiv:2403.18802.",
  "Yelp Inc. 2023. Yelp open dataset": "Yilun Zhao, Boyu Mi, Zhenting Qi, Linyong Nan, Ming-hao Guo, Arman Cohan, and Dragomir Radev. 2023.OpenRT: An open-source framework for reasoningover tabular data. In Proceedings of the 61st AnnualMeeting of the Association for Computational Lin-guistics (Volume 3: System Demonstrations), pages336347, Toronto, Canada. Association for Compu-tational Linguistics. Ming Zhong, Yang Liu, Da Yin, Yuning Mao, YizhuJiao, Pengfei Liu, Chenguang Zhu, Heng Ji, andJiawei Han. 2022.Towards a unified multi-dimensional evaluator for text generation. In Pro-ceedings of the 2022 Conference on Empirical Meth-ods in Natural Language Processing, pages 20232038, Abu Dhabi, United Arab Emirates. Associationfor Computational Linguistics.",
  "A.1Plan Parsing and Execution": "Conversion of the graph-structured SQR plan intoSQL is done by first breaking the graph into \"sub-plans\", where the result of one subplan functionsas a data source for subsequent subplans. Fromeach subplan, the necessary information to form anexecutable query, including entities, their attributes,analytics operations, and filters, is then identified.For example, in the plan in , the attributessize and year are retrieved from the Wildfire entitywhile name is retrieved from the State entity. Theaverage operation is applied to size, grouped byname. A filter is constructed such that each Wild-fire considered are from the year 2000. From thisinformation, the query is constructed using a queryabstraction library. For relational databases we usethe SQLAlchemy Python package (Bayer, 2012).In this last step, the ring is leveraged to convert theentity and relationship abstractions to the propertables and joins.",
  "A.2SQL Object Relational Mapping": "While SATYRNs analysis engine is designed tobe extendable to a variety of data source types,it is currently only configured to execute queriesagainst relational databases. Upon initialization,for each selected ring, a corresponding object rela-tional mapping (ORM) is built using SQLAlchemy.The ORM provides a programmatic interface be-tween the information defined in the ring, and thedata stored in a relational database.The ORM is constructed using configurationmappings defined in the ring, specifically, the ta-bles, columns, and joins between tables. Unlikeobjects defined in the ring, the ORM objects hold adirect one-to-one correspondence with database ob-jects; ORM entities correspond to tables, attributescorrespond to columns, and relationships corre-spond to groups of joins.Implicit Joins A major benefit provided by theabstractions of the ring is that, for a given domain,joins between tables need only be defined once in the configuration mapping of the ring. Nojoin information of any kind is required in plandefinitions. Instead, the system leverages the joinsand relationships defined in the ring to determinewhich SQL joins to use when attributes are selectedcorresponding to columns of different tables.All necessary joins between tables within an en-tity are identified. These intra-entity joins are nec-essary when multiple attributes are specified asbelonging to the same entity, but correspond tocolumns from different tables. Then, for each pairof entities, relationships are defined by collectingjoins along the shortest path connecting the tablesof the two entities.",
  "BReport Blueprint Implementation": "SATYRN provides a platform for defining new typesof reports that scope across any domain and dataset.These report types are encoded by a set of reportblueprints, and the report generation process usesthem to produce the information to be included inthe final report. The primary purpose of a reportblueprint is to provide the set of core informationrequirements, defined by a set of SQR plan tem-plates, and rules for retrieving or producing therequired access plans, filters, and language tem-plate fillers that will ultimately be composed witheach SQR plan template. This composition processresults in an executable SQR plan for each informa-tion requirement of the blueprint, and the execution",
  "B.1Attribute Access Plans": "When SATYRN loads a ring, it generates an accessplan for each of the attributes: a SQR plan thatspecifies how to retrieve this attribute from the data.SATYRN also automatically produces additionalattributes by applying analyses to the existing at-tributes. By combining the set of attributes definedwithin the ring with the set of available analyticsthat can be applied to each of them based on theirassociated attribute types, it is possible to automat-ically produce an additional set of attributes. Forexample, if \"population\" is present as an attributeand has type \"Arithmetic\", then \"average popula-tion\" would be created since SATYRN knows it canapply the average operation to attributes that are\"Arithmetic\". Each of these derived attributes hasan associated access plan as well.",
  "B.2SQR Plan Templates": "The SQR plan templates (previously described in2.3) serve as the base for defining the analyticsteps to perform given one or more access plansas input. These input access plans can have filtersinserted into them which constrain the retrieval ofthese data to particular subsets. Each SQR plantemplate also has a language template associatedwith it whose slots can be filled via the expressionof entities, attributes, and values specified in theSQR plan template.",
  "B.3Identifying Plan Composition Inputs": "The inputs to a report blueprint are provided bya user as a JSON object and vary depending onthe information requirements of that report. Anexample of the inputs for a ranking report blueprintcan be seen in . All currently implementedblueprints require a target entity instance, metric,and metric set filter as part of their input. The userinput specifying the target entity instance is usedto create an instance filter, which are SQR plansteps used to filter for data relating to this entityinstance. The blueprint uses its predefined rules tospecify that this filter should be added to particularaccess plans and designated as input to a SQR plantemplate.This is similarly true for the metric input for theblueprint. If an attribute in the ring has one of its attribute types defined as a Metric, then it is con-sidered a valid input for the blueprint. The metricspecified by the user is looked up in the ring, itsaccess plan is retrieved, and then is designated asinput to one or more SQR plan templates in theblueprint according to the blueprint rules. The un-derlying mechanics of how the metric gets mappedto inputs of the SQR plan templates in the blueprintare the same no matter the dataset which is used.There are corresponding rules within the blueprintdefining how metric set filters specified by the userare added to the designated SQR plan templates.Additional report-specific inputs from the user aremapped to the SQR plan templates in a similar fash-ion. These blueprints ensure SATYRNs productionof information from data is non-probabilistic, and areport blueprint is guaranteed to produce the sameexecutable plans for the same user inputs.",
  "B.4Executable Plans via SQR Composition": "Ultimately, the rules encoded by the reportblueprints, the retrieval of access plans from thering, the retrieval of SQR plan templates from theSQR plan template store, and the production offilters by the filter builder result in compositionspecifications. These provide the raw materialsfor building an executable plan for each of the in-formation requirements. The individual elementscomprising the composition specification can beseen as input to the SQR Composer in .Prior to composition, the SQR Composer en-sures that all the references of the access plans,SQR plan template, and filter are unique by ap-pending a unique string to the step references ofeach SQR plan, preventing conflicts when combin-ing them. Next, the SQR Composer updates theSQR plan template inputs with the correct accessplan references (e.g. changing |A| to |8A| in), and finally appends all the steps fromthe SQR plan template, access plan, and filters to-gether to form an executable plan. SATYRN carriesout this process for all information requirementsof the report blueprint in order to produce a set ofexecutable SQR plans that will be used for derivingthe information that should be communicated inthe report.",
  "Output": ": This figure shows the process SATYRN uses to generate a set of executable SQR plans to derive theinformation required for a report. First, the specified report type and its requirements are looked up in the setof report blueprints. The SQR plan template associated with each requirement is looked up from the SQR plantemplate store. Access plans are looked up in the attribute augmented ring. A filter plan is produced and all threecomponents are passed to the SQR composer which assembles them into a single executable plan.",
  "E.2Claim Classification": "Once a claim has been identified, we determinewhich of the following mutually exclusive cate-gories this claim belongs to based on the factualstatements generated for that kind of report.Factual: The claim is directly stated by a factin the context, or the claim can be directly inferredfrom the facts in the context via an unambiguousanalytic process.Refuted: The claim is directly refuted by a state-ment in the context, or the claim could be directlyinferred from the facts in the context via an unam-biguous analytic process, but is incorrect.Confabulation: The claim is not directly pulledfrom the facts in the prompt, or is not inferred fromthe facts in the prompt.",
  "Ranking": "The value of the metric for the target entityThe total number of entities being rankedThe rank of the entity instance according to the metricThe top three entity instances according to the metricHow much lower the target entity is than the highestThe average, minimum, and maximum value of the metric for all entitiesWhether or not the target entity is greater than the average value of the metric across all entities",
  "ComparativeBenchmark": "The value of the metric for the target entityWhether this value is greater than the target benchmark valueWhat the minimum, maximum, average, and median value of the metric is for all entitiesWhether or not the metric value for the target entity is greater than the average value of the metricfor all entitiesWhether or not the metric value for the target entity is greater than the median value of the metricfor all entitiesWhat the standard deviation of the metric is for all entities",
  "Time over Time": "The values of the metric at the start and end times for the target entityThe percent change in these valuesThe average, minimum, and maximum value of the metric for all entities at the start and endtimesThe percent change between of the average between the start and end time for all entitiesWhether or not the percent change was greater for the target entity instance or the average for allentities",
  "Criminal JusticeSchool ShootingIncidents": "The dataset (Center for Homeland Defense and Security, 2023) coverspublicly available data on shooting incidents from 1970 to June 2022,including any instance of gun brandishing, firing, or bullets hittingschool property, regardless of outcomes or timing. EducationIllinois Report CardThe Illinois Report Card (Illinois State Board of Education, 2022),issued by the Illinois State Board of Education, provides annual educa-tional progress data for the state, schools, and districts.",
  "SocioeconomicIncome Disparity": "The U.S. Bureau of Economic Analysis report (U.S. Bureau of Eco-nomic Analysis, 2022; U.S. Bureau of Labor Statistics, 2023; U.S.Census Bureau, 2022b,a,c) captures personal income data for variousregions, showing income received by residents in those areas based ontheir place of residence. BusinessYelp Open DatasetThe Yelp Open Dataset (Yelp Inc., 2023) comprises 5.9 million re-views, 188,593 businesses, and 280,992 pictures, provided by Yelp forpersonal, educational, and academic purposes.",
  ": The eight datasets used in our experiments": "subjective statements or conclusion (e.g.\"Weshould be doing...\", \"This should be done...\", etc.)and definitional statements that are not providedto the language model in the context. It is impor-tant to note that not all confabulations are bad. Ifthe model were to define standard deviation in thedocument, this can be a useful piece of informa- tion. However, we do not want to rely on the modelto present this, especially if these definitions areinadequate or imprecise. Rather, this is an indica-tion that we should seek to present this definitiondirectly to the model.",
  "We present an example of the domain-agnostic us-age of report blueprints. showcases the": "factual statements generated by the same Rankingreport blueprint, on three different domains: urbanhousing, criminal justice, and environmental sus-tainability. The information requirements of theRanking report blueprint remain unchanged across domains. The target entity information and the met-ric are specific to the domain and are provided asinputs to the blueprint. presents the corre-sponding reports generated by the language modelwhen prompted with the corresponding instructionand factual statements from .",
  "F.2Report from All Generation Modes": "We present examples of the same Time over Timereport in the Socioeconomics domain generatedwith various combinations of prompt types and lan-guage models. All examples shown in this sectionare generated for the same report. The target entityis Lake County, IL, the metric is average percent ofpeople in poverty, and the dataset is filtered to onlyinclude counties with resident populations greaterthan 100,000. This is a Time over Time report forthe time period ranging from 2010 to 2020.For each example, we provide the report and theprompt that was used to generate it. For clarity,we have color coordinated the facts provided inthe prompt with the corresponding text that wasgenerated as part of the reports to enable quick anddirect comparisons between the facts provided tothe model and its outputs.The first report, shown in , was gener-ated by SATYRN using GPT-4 and facts providedas natural language statements.The second report, shown in , was gen-erated with the Unaugmented GPT-4 baseline. Itwas observed that Unaugmented baseline reportshad a placeholder for the values which can be usedif correct data is provided.The third report, shown in , was gener-ated by Code Interpreter using GPT-4 with accessto the data. Notice that in the report, Code Inter-preter is able to come up with values for the desiredanalysis, but is not correct all the time.The fourth report, shown in , was gen-erated by SATYRN using GPT-4 with facts providedas tables rather than natural language statements.The prompt used to generate it is shown in .The fifth report, shown in , was gener-ated by SATYRN using Mistral-7B and facts pro-vided as tables rather than natural language state-ments. The prompt used to generate it is shownin . With Mistral-7B, we observed thatthe table format was not always understood by themodel and the language was sometimes confusing.Whereas Mistral-7B performed well in generatingreports when prompts included facts provided as natural language statements (.It is worth noting that, in general, the modelsgenerations presented the facts in the same orderin which they were provided within the prompt.This property could likely be exploited to improvethe structure of the reports by having a planningmodule determine what information is best seenfirst. We leave this for future work. Evaluation Rubric for Generated Reports Identifying a Claim A claim is any assertion of truth involving some retrieval or analytic processing of information from the data.",
  "Rules": "A claim has a subject and an object; the introduction of a subject in of itself is not a claim. A claim about a thing with multiple granularities (e.g. date, time, place, or range) is considered a singleclaim for each level of granularity. Date and time are considered distinct. If the granular components ofa thing are mentioned in separate sentences, those are distinct claims. Claims about dates and times should be separated into a claim for each. A claim is NOT interstitial writing that provides a transition between content or is just an introduction tothe report (e.g. a title). There may be multiple claims in a single sentence of the document. Meta claims (e.g. claims generated about the type of information mentioned in the report) are stillclaims. Ranges on their own will typically count as one claim. Suggestion of any kind of trend is one claim (but will need to be manually verified). For lists of facts, there is one claim per list item. Claims involving quantifiers (all, some, none, etc.) should be counted as a single claim, rather than aclaim for each instance. Indications of ordering and superlatives count as claims. Classifying a Claim Once a claim has been identified, we need to determine which of the following categories this claim belongs to.",
  "Confabulation": "The claim is NOT directly pulled from the facts in the prompt, or is NOT inferred from the facts in theprompt. This category includes subjective statements (opinions) or conclusions (e.g. We should be doing,This should be done, etc.) This category includes definitions that are not provided by us in the prompt/context (includes bothcorrect and incorrect definitions) Note that these categories are mutually exclusive: one claim cannot be part of two classes. We are ignoring subjective qualifiers (e.g. if the claim is The value greatly increased. we would ignore the greatlyand just verify if the The value increased against the available data.) In general, when in doubt, use your best judgment.",
  "Title: Los Angeles, CA Rental Market Report": "Los Angeles, California, known for its vibrant culture and bustling economy, has a maximum average monthly rent of$2,923.48. This places it 15th out of 538 regions in terms of rental costs, with lower costs being more desirable. To put this into perspective, the three regions with the highest average monthly rents are Glenwood Springs, Colorado, with a staggering $28,465.28, Key West, Florida, at $4,789.68, and Breckenridge, Colorado, at $4,000.00. This means that Los Angeles' maximum average monthly rent is $25,541.80 less than the most expensive region, Glenwood Springs, Colorado. When we look at the average maximum monthly rent across all regions, it comes to $1,525.17. This means that Los Angeles' rent is higher than the average. The region with the lowest maximum average monthly rent is at $650.00, while the region with the highest is at $28,465.28. In conclusion, while Los Angeles' maximum average monthly rent is higher than the average across all regions, it is significantly lower than the most expensive regions. This places Los Angeles in the middle range of rental costs, making it more affordable than some of the top-ranked regions.",
  "Report on Judge Young B Kim's Case Load Ranking": "In a comprehensive review of case loads among 2878 judges, Judge Young B Kim ranks impressively at 18th place. Thisranking is based on the unique case identification (UCID) count, a measure of the number of cases a judge has handled. Judge Kim has presided over a total of 7142 cases. This is a significant number, especially when compared to the averagecase load per judge, which stands at 334.80 cases. Judge Kim's case load is well above this average, demonstrating a highlevel of experience and dedication. However, there is still a considerable gap between Judge Kim and the judges with the highest case loads. The top threejudges in terms of case load are Judge Rebecca R Pallmeyer with 21678 cases, Judge Matthew F Kennelly with 16700 cases,and Judge Sidney I Schenkier with 14972 cases. Judge Kim's case load is 14536 cases lower than that of Judge Pallmeyer,the judge with the highest case load. It's important to note that the range of case loads among judges is quite wide. The judge with the fewest cases hashandled only one case, while Judge Pallmeyer, at the top of the list, has handled 21678 cases. In conclusion, Judge Young B Kim's case load is significantly higher than the average, placing him in the top 1% ofjudges in terms of case load. However, there is still room for growth when compared to the judges with the highest caseloads.",
  "Title: Oregon's Ranking in Median Fire Size: A Comparative Analysis": "Oregon, known for its diverse landscapes, ranks fourth in the nation when it comes to the median size of fires. Thisranking places Oregon among the top tier of states in the United States, which total 50 in number, for this particularcategory. The median size of these fires in Oregon is 280 acres, which is significantly larger than the national average of 158.82acres. This indicates that when fires do occur in Oregon, they tend to be larger than those in most other states. However, when compared to the states with the largest median fire sizes, Oregon's fires are smaller. The top three statesin this category are Alaska, Nevada, and Idaho, with median fire sizes of 969 acres, 427 acres, and 316.7 acresrespectively. Specifically, Oregon's median fire size is 689 acres less than that of Alaska, the state with the largestmedian fire size. The range of median fire sizes across all states is quite broad, with the smallest median fire size being 62 acres andthe largest being 969 acres. Despite this wide range, Oregon's median fire size of 280 acres is well above the nationalaverage, underscoring the state's higher propensity for larger fires. In conclusion, while Oregon's median fire size is not the largest in the nation, it is significantly larger than thenational average. This places Oregon in the upper echelon of states when it comes to the size of its fires. As such, itis crucial for Oregon to continue its efforts in fire prevention and management to mitigate the impact of these largerfires.",
  "Prompt": "Context:The average percent of people in poverty for Lake County, IL for 2010 is 8.74 percent for resident population greater than 100000.The average percent of people in poverty for Lake County, IL for 2020 is 6.58 percent for resident population greater than 100000.The percent change of average percent of people in poverty for Lake County, IL between 2010 and 2020 is -24.71% for residentpopulation greater than 100000.Average average percent of people in poverty grouped by county for 2010 is 12.28 percent for resident population greater than100000.Min of average percent of people in poverty grouped by county for 2010 is 4.63 percent for resident population greater than100000.Max of average percent of people in poverty grouped by county for 2010 is 18.03 percent for resident population greater than100000.Average average percent of people in poverty grouped by county for 2020 is 10.23 percent for resident population greater than100000.Min of average percent of people in poverty grouped by county for 2020 is 3.84 percent for resident population greater than100000.Max of average percent of people in poverty grouped by county for 2020 is 14.18 percent for resident population greater than100000.The percent change of average percent of people in poverty for all Countys between 2010 and 2020 is -16.69% for residentpopulation greater than 100000.The percent change of average percent of people in poverty between 2010 and 2020 for Lake County, IL is greater than for allother Countys for resident population greater than 100000. Generate a report for Lake County, IL describing how average percent of people in poverty has changed over time between 2010and 2020 for resident population greater than 100000. Lower values are considered better. Use only the facts provided in thecontext. The audience is educated, but may not understand technical terms. Please use natural sounding language and try to findmore natural terms for the groups that are mentioned. Mistral-7B Report Title: Poverty Rate Trends in Lake County, Illinois (2010-2020) for Population over 100,000 Lake County, Illinois, has seen a significant decrease in the average percentage of residents living in poverty between the years2010 and 2020. The average poverty rate for this period dropped from 8.74% in 2010 to 6.58% in 2020, representing a substantial24.71% reduction. To put this improvement into perspective, it is essential to note that the average poverty rate for all counties in the United Statesduring this timeframe also decreased, but at a lower rate. The overall decrease in poverty rate for all counties was 16.69%. LakeCounty's reduction, however, was more substantial than the average for all counties. In 2010, the average poverty rate for counties with a population greater than 100,000 was 12.28%. Lake County's initial povertyrate was above the average, but it still managed to make considerable progress towards reducing poverty. The minimum povertyrate among counties in 2010 was 4.63%, while the maximum was 18.03%. Lake County's initial poverty rate was closer to themaximum than the minimum. By 2020, the average poverty rate for counties with a population greater than 100,000 had dropped to 10.23%. Lake County'spoverty rate continued to improve, reaching 6.58%, which was below the new average for all counties. The minimum poverty rateamong counties in 2020 was 3.84%, and the maximum was 14.18%. In summary, Lake County, Illinois, experienced a more substantial decrease in poverty rate than the average for all countiesbetween 2010 and 2020. The poverty rate dropped from 8.74% to 6.58%, representing a 24.71% reduction. This improvementwas significant, as the initial poverty rate was above the average for all counties, and the county managed to move closer to thelower end of the poverty rate spectrum.",
  "Code Interpreter Report": "Here is the report for Bond County CUSD 2: According to the provided data, - Bond County CUSD 2 has a high school dropout rate of 4.1%.- Among a total of 274 distinct entities or districts, Bond County CUSD 2 is ranked 208th based on dropout rates, with lower ratesbeing better. From the top ranking, Bond County CUSD 2 is 207 places away. The three districts with the lowest dropout rates (the best performers) are:1. Lyons Township HSD 2042. Lincoln Way CHSD 2103. Township HSD 211 The average dropout rate for all districts is 6.31%. Bond County CUSD 2 performs better than this average with a dropout rate of4.1%. The lowest (best) dropout rate among all districts is 0.4%, while the highest (worst) is 55.2%. In conclusion, Bond County CUSD 2 is performing above average based on its dropout rate, but there is still room forimprovement when compared to the top-performing districts.",
  ": A prompt used for generating a Time over Time report with SATYRN where the facts are provided astables rather than natural language statements": "GPT-4 Report In Lake County, Illinois, there has been a significant decrease in the average percentage of people living in poverty over the pastdecade. In 2010, the average percentage of residents living in poverty was 8.74%. By 2020, this figure had dropped to 6.58%,representing a decrease of 24.71%. When we look at the broader picture, the average percentage of people in poverty across all counties with a population greaterthan 100,000 was 12.28% in 2010. This figure decreased to 10.23% in 2020, a reduction of 16.69%. Interestingly, the decrease in the average poverty rate in Lake County was greater than the average decrease across allsimilar-sized counties. This suggests that Lake County has been more successful in reducing poverty levels among its residentscompared to other counties with a population greater than 100,000. In 2010, the county with the lowest average poverty rate had a figure of 4.63%, while the highest was 18.03%. By 2020, thesefigures had changed to 3.84% and 14.18% respectively. This indicates that there has been a general trend towards lower povertyrates across all counties of similar size. In conclusion, Lake County has seen a substantial reduction in the average percentage of people living in poverty over the pastdecade, outperforming the average decrease seen across all similar-sized counties.",
  ": A Time over Time report generated with SATYRN using GPT-4 and facts provided as tables rather thannatural language statements": "Mistral-7B Report Report for Lake County, IL: Changes in Average Percentage of Residents Living in Poverty (Population over 100,000) Between the years 2010 and 2020, the average percentage of residents in Lake County, IL living in poverty has fluctuated. For thesake of clarity, we will refer to the two different average percentages as \"average percentage 2010\" and \"average percentage2020.\" The average percentage of residents living in poverty in Lake County in 2010 was 8.74%. In contrast, the average percentage in2020 was 6.58%. This represents a significant decrease of 24.71% in the percentage of residents living in poverty over this timeperiod. To put these numbers into perspective, the overall average percentage of residents living in poverty across all the years inquestion was 10.23%. The lowest recorded percentage was 3.84% in one of those years, while the highest was 14.18%. Comparing the changes between the overall average percentage and the average percentages for the specific years of 2010 and2020, we find that there was a decrease of 16.69% between the overall average and the average for 2020. This furtheremphasizes the improvement in the percentage of residents living in poverty in Lake County between these years. In summary, the average percentage of residents living in poverty in Lake County, IL has decreased from 8.74% in 2010 to 6.58%in 2020, representing a 24.71% reduction. This improvement is significant when compared to the overall average percentage of10.23% and the lowest and highest recorded percentages of 3.84% and 14.18%, respectively."
}