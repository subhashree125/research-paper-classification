{
  "Abstract": "In-context learning (ICL) is a few-shot learn-ing paradigm that involves learning mappingsthrough input-output pairs and appropriatelyapplying them to new instances.Despitethe remarkable ICL capabilities demonstratedby Large Language Models (LLMs), existingworks are highly dependent on large-scale la-beled support sets, not always feasible in prac-tical scenarios. To refine this approach, wefocus primarily on an innovative selective an-notation mechanism, which precedes the stan-dard demonstration retrieval. We introducethe Language Model-based Determinant PointProcess (LM-DPP) that simultaneously consid-ers the uncertainty and diversity of unlabeledinstances for optimal selection. Consequently,this yields a subset for annotation that strikesa trade-off between the two factors. We applyLM-DPP to various language models, includ-ing GPT-J, LlaMA, and GPT-3. Experimentalresults on 9 NLU and 2 Generation datasetsdemonstrate that LM-DPP can effectively se-lect canonical examples. Further analysis re-veals that LLMs benefit most significantly fromsubsets that are both low uncertainty and highdiversity.",
  "Introduction": "As large pre-trained language models (LLMs)(Brown et al., 2020; Chowdhery et al., 2022; Zhanget al., 2022a; Tay et al., 2023; Touvron et al., 2023;Workshop, 2023) grow in scale, they not only ex-hibit enhanced linguistic capabilities and expandedworld knowledge but also demonstrate a novel abil-ity for in-context learning. Specifically, LLMshave shown proficiency in learning from a limitedset of input-output examples (known as demon-strations (Brown et al., 2020)), and effectively ap-plying these learned mappings to new, unseen in-stances. This novel few-shot learning paradigm,",
  "xtest": ": Left (Step 1): Without assuming access toa large amount of labeled data, we employ active datacollection, selectively annotating demonstration exam-ples. Right (Step 2): Prompt construction and modelinference. which avoids parameter updates, has become a pop-ular and efficient method for utilizing LLMs (Liuet al., 2021b; Dong et al., 2023; Liu et al., 2021a).Previous studies have investigated which in-stances can serve as effective prompts for ICL(Liu et al., 2021a; Zhang et al., 2022b; Li and Qiu,2023). They have demonstrated that retrieving spe-cific similar contexts for individual test queriescan significantly improve performance (instancelevel) and ground truth matters for support ex-amples. To assign appropriate demonstrations toall test queries, support sets necessitate diversityand broad coverage, usually achieved through largelabeled data, following the principle that MonteCarlo estimation accuracy improves with largersamples. Nonetheless, these extensive datasets areoften impractical to obtain.We investigate the selection of demonstrationsfrom the perspective of Active Learning (AL)(Cohn et al., 1996; Settles, 2009). Based on thecore principle that not all data points are of equalvalue, AL aims to identify the most effective in-stances in an unlabeled data pool for annotation.Margatina et al. (2023) elucidates that high seman-tic similarity, low uncertainty, and high diversitycomprise an effective and efficient annotation strat-egy. Similarly, Gonen et al. (2022) demonstrates that lower prompt perplexity is closely associatedwith better performance. While Su et al. (2022)sVote-k framework adopts a data-centric perspective(i.e., selecting examples that balance diversity andrepresentativeness), it neglects the assessment ofuncertainty and the inter-relationship among con-text examples. In this paper, we pursue a moreuniversally applicable yet straightforward solution,incorporating confidence signals of LLMs to selectannotation instances that are maximally diverse andexhibit low uncertainty.To address this need, we introduce a generic ap-proach, LM-DPP, which jointly models uncertaintyand diversity within the support set through a con-ditional Determinantal Point Process. Specifically,we employ LLMs perplexity to score each candi-date instance in the support set, which serves as ameasure of the LLMs uncertainty. Then a Grammatrix is constructed to balance the uncertainty anddiversity of candidate instances and polynomial-time maximum a posteriori (MAP) inference (Chenet al., 2018) is applied to identify the most use-ful subset of instances to be annotated. From theperspective of selective annotation, we considerextremely low-resource ICL scenarios as those inwhich the available annotated examples are limitedto a few dozen instances. Our focus centers on iden-tifying which specific set of demonstrations canmost effectively harness the capabilities of LLMswithin this challenging context.We validate our method through extensive ex-periments on 9 NLU and 2 Generation datasets.We also demonstrate the versatility of LM-DPPby adapting it to the large language model GPT-3 (175B). The experimental results illustrate thatour approach can effectively balance two criticalfactors, uncertainty and diversity. In summary, ourcontributions are as follows. We revisit the setup of ICL from the perspec-tive of selective annotation. We introduce anovel approach, LM-DPP, to select instancesthat balance uncertainty and diversity for an-notation, aiming to reduce the human engi-neering workload. The experimental results indicate that the pro-posed method outperforms the previous best-performing selection methods by a large rela-tive improvement and exhibits commendablegeneralizability across model size (4.2) andannotation budget (4.3) scaling.",
  "Methodology": "In this section, we introduce technical details ofLM-DPP for selecting annotation instances ex-hibiting both high diversity and low uncertainty.Formally, given a set of unlabeled samples X ={xi}Ni=1, LM-DPP aims to select a subset L Xfor annotation, where |L| = M is the annotationbudget, such that the Language Models (LLMs)maintains high ICL performance on the test setDtest. As shown in , given a Pre-trainedLanguage Model (PLM) G, we first score candi-date instances xi using the perplexity of the LLMs(2.1). We then compute vector representationsfor the candidate instances, utilizing a conditionalkernel matrix to balance diversity and low uncer-tainty (2.2). Subsequently, we perform a greedyMAP inference algorithm to filter the candidateannotation set (2.3).",
  "Uncertainty": "As off-the-shelf LLMs do not contain a classifica-tion head fine-tuned for specific tasks, calculatingentropy, a common measure of uncertainty used inAL, across all possible outputs is challenging, ifnot unfeasible. Alternatively, we adopt the SPELLmethod proposed by (Gonen et al., 2022), usingthe perplexity of the LLMs, to score candidate ex-amples x. The scoring function r(x) is definedas:",
  "i=1log G(xi|x<i)": "(1)Recent research also delineates that LLMs are es-sentially a form of lossless data compression (Del-tang et al., 2023), and perplexity, serving as a proxyfor the occurrence of the prompt in some form inthe training data, inherently indicates the modelsexpectancy of the prompt. Therefore, perplexity-based demonstration selection can, to some extent,avoid LLM sampling from low-frequency distri-butions. We also conduct pilot experiments (Ap-pendix B) that select instances of high uncertainty,observing a substantial decrease in performance.",
  "Inference": "The solution to the MAP for DPP, which is to findthe set of examples with the highest probability, isa complex process and an NP-hard problem. (Chenet al., 2018) have proposed an improved greedy al-gorithm that can quickly solve it approximately. Inspecific, this algorithm greedily selects the demon-stration from the candidate set that maximizes themarginal gain to be added to the final result subset,until the stopping condition is satisfied. That is,each time an example j is chosen to be added tothe candidate set Smap, which is initialized as anempty set. The formalization is as follows:",
  "DPP Modeling": "We consider similarity as the primary qualitativefeature of the DPP diversification process. In thissection, we present the decomposition of DPP thatmore directly elucidates the tension between diver-sity and the uncertainty measure for each candi-date instance. Since the DPP kernel, L is typicallywritten as a Gram matrix, L = BT B, where thecolumns of B represent vectors from the candidateset X. We define Bi as the product of the LLMsuncertainty term ri R+ and the normalized di-versity feature vector i RD, with |i| = 1.The new DPP kernel matrix can now be written asKij = riTi jrj = rirjTi j (Ye et al., 2023).ri can be regarded as the intrinsic evaluation of theLLMs for the candidate instance and Ti j as themeasure of similarity between instances xi and xj.Therefore, we arrive at L = Diag(r) Diag(r),and the unnormalized log probability for the subsetS is log det(LS) = iS log(r2i ) + log det(S).To adjust the trade-off between uncertainty and di-versity, we introduce a balancing parameter , thusmodifying the log probability of LS to:",
  "iSri + (1 ) log det(LS)": "(2)This corresponds to a DPP with kernel L =Diag(exp(r)) Diag(exp(r)), where =/(2(1 )). In Equ. (2), the first term corre-sponds to the low perplexity of the selected in-stances, while the second term increases with thediversity of the selected instances. Without the di-versity model, we would choose examples of lowuncertainty, but the DPP would tend to repeatedlyselect similar examples. Without the low uncer-tainty model, although we could obtain a highlydiverse set, we might fail to include in S those ex-amples most favorable to the LLMs. By combining",
  "log det(LSmap)(3)": "By performing a Cholesky decomposition onLSmap, and incrementally updating the Choleskyfactor, the complexity of solving det(LSmap) canbe reduced from O(K3) to O(K). Therefore, thecomplexity of each iteration is O(NK). This im-plies that it is possible to return K annotation exam-ples within O(NK2) time. Once we have selectedand annotated a subset of examplesL from the un-labeled support set, following recent work (Liuet al., 2021a), we retrieve examples from L thatare semantically similar to the test query samples.We use Sentence-BERT (Reimers and Gurevych,2019) representations for L and Dtest again andemploy cosine similarity as the metric. The under-lying principle is that demonstrations most similarto the test example will best assist the model inanswering the query. For the order of demonstra-tions, we adhere to the configuration established bySu et al. (2022), where the order of the retrieved",
  "LM-DPP (ours)58.992.741.315.366.802.356.150.957.623.094.820.483.502.278.912.189.361.869.722.6": ": Results with GPT-J and LlaMA-2-7B on NLU task. We compare various selective annotation methodswith {100, 16} annotated examples. Bold numbers indicate the highest accuracy among all methods, while thoseunderlined indicate the second-best. The subscript denotes the standard deviation. examples is such that s(qi, x) s(qj, x) when-ever i < j. s(qi, x) denotes the similarity betweenthe retrieved example qi and the test example x.This setup potentially leverages the recency biasinherent in LLMs (Zhao et al., 2021).",
  "Experimental Settings": "DatasetsWe conduct experiments on 9 NLUand 2 Generation tasks involving different taskformulations, including Sentiment Classification:SST-5 (Socher et al., 2013); Natural LanguageInference: RTE (Bentivogli et al., 2009), MNLI(Williams et al., 2017), MRPC (Dolan et al., 2004),QNLI (Wang et al., 2018); Topic Classification:TREC (Hovy et al., 2001), DBpedia (Lehmannet al., 2015); Multiple-choice Question Answer-ing: Hellaswag (Zellers et al., 2019), COPA (Roem-mele et al., 2011); Abstractive Summarization:XSUM (Narayan et al., 2018) and Open DomainQA: NQ (Kwiatkowski et al., 2019). In the mainexperiment, the budget of annotation is set as({16, 100}). For datasets with publicly availabletest data, we use the test data for evaluation. Forothers, we follow previous work (Lan et al., 2019;Su et al., 2022) and use the dev set for evaluation.",
  "suzaki, 2021) and LlaMA-2-7B (Touvron et al.,2023) as scoring and inference language models,More details about baselines and implementationcan be found in Appendix A.3, A.2 respectively": "MetricsWe compare the predicted answers withthe true outcomes and report the accuracy (Acc.)for all NLU tasks and exact matching scores (Ra-jpurkar et al., 2016) for NQ. For summarizationtasks, we assess factual consistency using FactCC(Kryscinski et al., 2020) 1, a BERT-based (Devlinet al., 2019) metric for evaluating output faithful-ness. Simultaneously, for quality assessment, wereport the ROUGE-L F1 score (Lin, 2004) to eval-uate the summary against the reference.",
  "NLU TaskFrom , we can observe thatLM-DPP consistently improves the on-averageaccuracy across a variety of NLU tasks under": "different annotation budgets (|L| = 16, |L| =100). Specifically, with a larger budget, LM-DPPachieves an average absolute gain of 1.15% onGPT-J and 1.08% on LlaMA, compared to the best-performing baseline. This demonstrates that bal-ancing uncertainty and diversity ensures that thechosen demonstrations are more likely to containcomplementary information that enhances perfor-mance. On GPT-J, LM-DPP exhibits the lowest av-erage standard deviation (2.6, 2.0), and on LlaMA-2, it shows greater stability than the Random base-line, albeit marginally lower than Vote-k. Thisindicates that LM-DPP can maintain a relativelystable performance across different experimentalsetups, substantially increasing the reliability androbustness of contextual learning. Furthermore,we observe that as the annotation budget increases,performance fluctuations decrease across differentselection methods. Generation TaskExperiments on LlaMA-2 (asshown in ) reveal that LM-DPP achievesnotable improvement on the NQ task across var-ious annotation budgets, especially at L = 16,where it surpasses the best baseline by 1.04%. Inthe XSUM task, applying LM-DPP consistentlyenhances Rouge scores, particularly achieving a2.18% increase at L = 100. This underscores theefficacy of the proposed method in improving thegenerality and reference similarity of generatedtext. However, this improvement comes at the costof some degree of factual consistency with thereference, potentially due to the pursuit of diver-sity reducing the focus on task-specific relevance(see Appendix C.2 for a more detailed analysis).Overall, LM-DPP boosts the models generaliza-tion and accuracy and highlights the potential forperformance optimization with increased annota-tion budgets. Despite some variability in factualconsistency, these insights pave the way for fu-ture research on efficiently allocating annotationresources in NLG tasks (Dong et al., 2022). MRPC",
  ": The GPT-J performance of different trade-offfactors . ( = {0.0, 1.0}) correspond respectively tothe vanilla DPP and the Perplexity baseline (A.3)": "surpasses the other baselines in terms of accuracyand stability on MRPC and TREC but is slightlyinferior to Vote-k on DBpedia. Further analysissuggests that a well-balanced demonstration setdoes not always result in improved performanceor reduced variance (see Appendix C.3 for moredetails). In TREC, performance increases withmore labels, whereas in MRPC, demonstrationswith a single label (all being equivalent) lead tobetter performance than a balanced demonstrationset, with less variance.",
  "Impacts of the Trade-off BetweenUncertainty and Diversity": "We analyze to investigate how the trade-off be-tween diversity and uncertainty impacts the perfor-mance of downstream tasks. With an annotationbudget of 100, we test the performance under dif-ferent () values utilizing GPT-J as the inferencemodel. As evident from , a complete in-clination towards uncertainty ( = 1.0) generallyyields poorer outcomes across all tasks, likely dueto selective annotation excessively concentratingon a small portion of data, thereby diminishingICLs generalization capacity. Optimal effects areoften observed at () values of 0.5 or 0.6 (whichapproximate a balance between the two factors),suggesting that moderate uncertainty coupled witha degree of diversity is beneficial for the modelsdownstream task performance. Moreover, differ-ent tasks demonstrate varied sensitivities to the ()value. For instance, QNLI shows minor perfor-mance shifts (1.95%), whereas DBpedia exhibitssignificant performance variations at certain ()values (exceeding 10.00%), indicating that theoptimal selection of () may relate to the taskscharacteristics and difficulty levels. Despite such RTE RandomFast Vote-kVote-kLM-DPP",
  "Transferability across Different LMs": "Small model for scoringScoring every samplefrom the extensive unlabeled pool using a moreresource-intensive LLM could be computationallydemanding, particularly when the size of the un-labeled sample pool is substantial. Therefore, weattempt to use GPT2 (Radford et al., 2019) (117M,which possesses basic language modeling capa-bilities) as a surrogate for the source languagemodel GPT-J, while maintaining GPT-J for the in-ference model. Across 9 NLU tasks (annotationsize=100), the average accuracy was 64.76 (detailsin Appendix C.1). This indicates that LM-DPPexhibits strong transferability across different infer-ence LMs, which means that the selected demon-strations can be reused.",
  "Transfer to LLMsTo gain some intuition onthe effect of model size, we endeavor to transferthe proposed method to LLMs that are aligned": "with human expectations (gpt-3.5-turbo-instruct)(Ouyang et al., 2022).In specific, we take the logprobs returned by theofficial API as a reference for measuring uncer-tainty, from which we calculate r(xi) and performstandard LM-DPP. As depicted in , wereport the experimental results of GPT-3.5-Turbo(175B) with LM-DPP on several datasets and com-pare them with the Random and Fast Vote-k base-line. In comparison to random selection, our resultsindicate that LM-DPP can significantly enhance theperformance of GPT-3.5, as evidenced by the 5.6%improvement in TREC accuracy, 1.8% in MNLI,0.2% in SST-5, and 0.6% in COPA. The proposedLM-DPP approach surpasses Fast Vote-k by anaverage of 3.25%, indicating that considering rep-resentativeness alone is not sufficient to extract ahigh-quality demonstration subset.",
  "Varying budget of annotated examples": "We further investigate how the size of the annota-tion set affects the performance of in-context learn-ing. Under annotation sizes of ({16, 100, 300,800}), we compare LM-DPP with Random selec-tion, Fast Vote-k, and Vote-k, and report the resultsin . It is observable that with increasingannotation budgets, most selective methods gener-ally show a consistent overall improvement trend.This is in line with the expectation that more la-beled data is more likely to retrieve relevant ex-amples to assist LLMs in accurately answering,thereby improving the performance of in-contextlearning. The proposed approach, LM-DPP, out-performs other methods at an annotation size of16 on RTE, Hellaswag, and QNLI, suggesting thateven with extremely low annotation budgets, LM-DPP can ensure the effectiveness and diversity ofcontext. Additionally, with a sufficient annotationbudget (L = 800), LM-DPP exhibits commend-able performance, achieving the best results on two Seconds (s)",
  "Time Efficiency": "We explore the execution efficiency of both thebaseline methods and LM-DPP. As illustrated in, the LM-Free approach significantly re-duces the time required to select demonstrationscompared to methods that require scoring by LM.Selecting 300 samples takes 4039.1s with Vote-k,382.6s with LM-DPP, and only 0.3s with randomselection. Since LM-DPP only requires a singleforward pass per sample, we can optimize time effi-ciency in two ways: (1) preemptively compute per-plexity for data samples in practical scenarios anddevise methods to reset or update cached demon-stration samples periodically. (2) using smaller-parameter scoring models (see 4.2) can achievemore than tenfold acceleration (24.4s).",
  "Case Study": "We compare demonstrations selected via LM-DPPagainst Random in CosmosQA dataset (Huanget al., 2019). It reveals that demonstrations se-lected by the LM-DPP exhibit greater diversity incontent, covering 16 distinct topics such as naturaldisasters, personal emotions, political views, so-cial interactions, and school life, compared to only8 topics covered by random selection ().The selected demonstrations not only span a broadrange of subjects but also offer a variety in style,",
  "Does annotation benefit from gold labels?": "Min et al. (2022) observed that random substitutionof labels in demonstrations minimally impacts theperformance across a suite of tasks, while Yoo et al.(2022) highlighted that the integrity of input labelmapping is a crucial factor. In this section, we ex-plore whether Gold Labels (i.e., providing correctlabels) are essential for achieving high performancein ICL.Specifically, we divide the selective annotationprocess into several steps. Step 1: Annotate 50 in-stances to construct an in-domain dev set Di (con-taining gold labels). Step 2: For the unannotatedinstances, we pair each input xi with every possi-ble label y C (C is the label set) to construct atrain set D carrying pseudo-labels. Step 3: Giventhe prompts Z D, the ICL accuracy on the in-domain dev set Di is denoted as Acc(Z). We selectthe Top-50 Z, represented as Du. Therefore, thefinal annotation set (|L| = 100) comprises twoparts: Di with gold labels, and Du selected post-hoc. This process is referred to as UN-LM-DPP,followed by conducting standard ICL experiments.As shown in , we observe that UN-LM-DPP, compared to LM-DPP with gold annotations,exhibits a certain performance decline in most tasks but still surpasses Random selection in somedatasets. The performance fluctuation varies sig-nificantly across different tasks, depending on thespecific characteristics of the datasets, as evidencedby a decrease of -6.74% in TREC, yet only -2.88%in MNLI.",
  ": The proportion of golden-labeled examplesidentified within an unlabeled setting in UN-LM-DPP": "This suggests that, to a certain extent, ICL gener-ally benefits from gold demonstrations. In addition,we report the proportion of gold demonstrationswithin the constructed Du during Step 2, with theresults presented in . In QNLI, there is a52.30% gold label ratio, and surprisingly, we ob-serve a slight performance improvement comparedto LM-DPP. It is evident that within similar tasks,a higher ratio of gold-standard examples correlateswith a smaller decline in ICL performance. How-ever, this is not a generalized finding across theboard, and we consider annotation-free ICL as adirection for future work.",
  "Related Work and Background": "Determinantal Point ProcessThe Determinan-tal Point Process (DPP) is an elegant probabilisticmodel that captures negative correlations and al-lows for efficient algorithms in sampling, marginal-ization, and conditioning (Kulesza, 2012). For-mally, a point process P is a probability measureon the power set of V, that is, the set of all discreteitems 2V. If Y is a random subset drawn accordingto P, then for every S Y :",
  "P(S Y ) = det(LS)(4)": "for some kernel matrix L Rnn that is symmet-ric, real and positive semidefinite. LS denotes thesubmatrix of L obtained by restricting to the rowsand columns indexed by S. The operator det()represents the determinant of a matrix. Typically,the DPP kernel L can be written as a Gram matrix,Lij = K(ai, aj), where K(, ) is the kernel asso-ciated with the determinantal point process, oftenexpressed as (ai)T (aj), is the feature map ofa reproducing kernel (Ye et al., 2023).Under distribution P, our objective is maximuma posteriori (MAP) inference, which is to find the",
  "Smap = arg maxSY det(LS)(5)": "Although finding the mode of a DPP is NP-hard,pioneering works (Kulesza, 2012; Lee et al., 2009;Chen et al., 2018; Gillenwater et al., 2012) havelargely relied on greedy algorithms or samplingmethods, and have succeeded in performing greedyMAP inference within polynomial time. In-context LearningThe capacity for in-contextlearning has been observed in large-scale Pre-trained Language Models (PLMs) such as GPT-3, representing a few-shot learning paradigm thatdoes not require any parameter updates. It involvespre-pending a small number of demonstrations asprompts before the test input, allowing LLMs todiscern patterns and learn to predict.Formally, let x be the test query to be addressed,and s(, ) be the cosine similarity. Standard ICLprompts the language model G with a set of exam-ple input-output pairs {(x1, y1) . . . (xm, ym)} andpredicts the answer y for the query. Typically, thepairs (xi, yi) are retrieved from a train set D withinthe same domain through similarity.",
  "C =TopK(xi,yi)D(s(x, xi))": "Recent works have aimed to enhance ICL by se-lecting valuable demonstrations (Liu et al., 2021a;Rubin et al., 2022), optimizing the order of demon-strations (Lu et al., 2022), etc. Su et al. (2022)utilize selective annotation to significantly reduceannotation costs while ensuring high ICL perfor-mance. Yang et al. (2023) explore the corpus-levelin-context learning via DPP and mention the needto use gold labels to score candidate samples. CEIL(Ye et al., 2023) train the demonstration retrieverwith a learnable conditional DPP. However, theseexisting works are highly dependent on large anno-tated support sets.",
  "The proposed work still has some limitations": "Selection Method.Previous studies have eluci-dated that low uncertainty ensures familiarity of theLLMs with the demonstrations (Gonen et al., 2022),while diversity ensures that the selected demonstra-tions may encompass a broad range of information,thereby enhancing the overall effectiveness of ICL(Margatina et al., 2023). However, we still lack pi-lot experiments tailored to these factors to examinetheir impact on ICL performance thoroughly. RetrievalMethod.Wehaveimplementedprompt retrieval based on similarity (TopK). How-ever, it is currently unclear whether the proposedmethod applies to other prompt retrieval methods,such as Random Retrieval,Coverage-basedRetrieval (Gupta et al., 2023), and Retrieval basedon Mutual Information (Sorensen et al., 2022). Weplan to extend our work to cover more scenarios. Retriever.Retriever is indeed one of the vari-ables in our experiments. However, we have solelyemployed a retriever based on the SentenceBert ar-chitecture. Validating our experimental results ona more diverse array of retrievers constitutes futureextension work.",
  "Potential Risk": "Previous works have shown Large language mod-els contain rich biased data (Bender et al., 2021).Since we use LLMs like LlaMA, GPT-J, and GPT-3, the proposed LM-DPP approach may elicit somecontent with offensive language or discrimination. Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On thedangers of stochastic parrots: Can language mod-els be too big?In Proceedings of the 2021 ACMConference on Fairness, Accountability, and Trans-parency, FAccT 21, page 610623, New York, NY,USA. Association for Computing Machinery.",
  "Luisa Bentivogli, Peter Clark, Ido Dagan, and DaniloGiampiccolo. 2009. The fifth pascal recognizingtextual entailment challenge. TAC, 7:8": "Tom B. Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, Sandhini Agarwal, Ariel Herbert-Voss,Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,Clemens Winter, Christopher Hesse, Mark Chen, EricSigler, Mateusz Litwin, Scott Gray, Benjamin Chess,Jack Clark, Christopher Berner, Sam McCandlish,Alec Radford, Ilya Sutskever, and Dario Amodei.2020. Language models are few-shot learners.",
  "Fast greedy map inference for determinantal pointprocess to improve recommendation diversity": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,Maarten Bosma, Gaurav Mishra, Adam Roberts,Paul Barham, Hyung Won Chung, Charles Sutton,Sebastian Gehrmann, Parker Schuh, Kensen Shi,Sasha Tsvyashchenko, Joshua Maynez, AbhishekRao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-odkumar Prabhakaran, Emily Reif, Nan Du, BenHutchinson, Reiner Pope, James Bradbury, JacobAustin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,Toju Duke, Anselm Levskaya, Sanjay Ghemawat,Sunipa Dev, Henryk Michalewski, Xavier Garcia,Vedant Misra, Kevin Robinson, Liam Fedus, DennyZhou, Daphne Ippolito, David Luan, Hyeontaek Lim,Barret Zoph, Alexander Spiridonov, Ryan Sepassi,David Dohan, Shivani Agrawal, Mark Omernick, An-drew M. Dai, Thanumalayan Sankaranarayana Pil-lai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,Rewon Child, Oleksandr Polozov, Katherine Lee,Zongwei Zhou, Xuezhi Wang, Brennan Saeta, MarkDiaz, Orhan Firat, Michele Catasta, Jason Wei, KathyMeier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,and Noah Fiedel. 2022. Palm: Scaling language mod-eling with pathways.",
  "Active learning with statistical models": "Grgoire Deltang, Anian Ruoss, Paul-AmbroiseDuquenne, Elliot Catt, Tim Genewein, Christo-pher Mattern, Jordi Grau-Moya, Li Kevin Wenliang,Matthew Aitchison, Laurent Orseau, et al. 2023.Language modeling is compression. arXiv preprintarXiv:2309.10668. Jacob Devlin, Ming-Wei Chang, Kenton Lee, andKristina Toutanova. 2019. BERT: Pre-training ofdeep bidirectional transformers for language under-standing. In Proceedings of the 2019 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies, Volume 1 (Long and Short Papers), pages41714186, Minneapolis, Minnesota. Association forComputational Linguistics.",
  "Shivanshu Gupta, Matt Gardner, and Sameer Singh.2023.Coverage-based example selection for in-context learning": "Eduard Hovy, Laurie Gerber, Ulf Hermjakob, Chin-Yew Lin, and Deepak Ravichandran. 2001. Towardsemantics-based answer pinpointing. In Proceedingsof the first international conference on Human lan-guage technology research. Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, andYejin Choi. 2019. Cosmos QA: Machine readingcomprehension with contextual commonsense rea-soning. In Proceedings of the 2019 Conference onEmpirical Methods in Natural Language Processingand the 9th International Joint Conference on Natu-ral Language Processing (EMNLP-IJCNLP), pages23912401, Hong Kong, China. Association for Com-putational Linguistics. Wojciech Kryscinski, Bryan McCann, Caiming Xiong,and Richard Socher. 2020. Evaluating the factualconsistency of abstractive text summarization. InProceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing (EMNLP),pages 93329346, Online. Association for Computa-tional Linguistics.",
  "Alex Kulesza. 2012. Determinantal point processesfor machine learning. Foundations and Trends inMachine Learning, 5(23):123286": "Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-field, Michael Collins, Ankur Parikh, Chris Alberti,Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-ton Lee, Kristina Toutanova, Llion Jones, MatthewKelcey, Ming-Wei Chang, Andrew M. Dai, JakobUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-ral questions: A benchmark for question answeringresearch. Transactions of the Association for Compu-tational Linguistics, 7:452466. Zhenzhong Lan, Mingda Chen, Sebastian Goodman,Kevin Gimpel, Piyush Sharma, and Radu Soricut.2019. Albert: A lite bert for self-supervised learn-ing of language representations.arXiv preprintarXiv:1909.11942.",
  "Burr Settles. 2009. Active learning literature survey": "Richard Socher, Alex Perelygin, Jean Wu, JasonChuang, Christopher D. Manning, Andrew Ng, andChristopher Potts. 2013. Recursive deep models forsemantic compositionality over a sentiment treebank.In Proceedings of the 2013 Conference on Empiri-cal Methods in Natural Language Processing, pages16311642, Seattle, Washington, USA. Associationfor Computational Linguistics. Taylor Sorensen, Joshua Robinson, Christopher MichaelRytting, Alexander Glenn Shaw, Kyle JeffreyRogers, Alexia Pauline Delorey, Mahmoud Khalil,Nancy Fulda, and David Wingate. 2022.Aninformation-theoretic approach to prompt engineer-ing without ground truth labels.arXiv preprintarXiv:2203.11364. Hongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi,Tianlu Wang, Jiayi Xin, Rui Zhang, Mari Ostendorf,Luke Zettlemoyer, Noah A. Smith, and Tao Yu. 2022.Selective annotation makes language models betterfew-shot learners. Yi Tay, Mostafa Dehghani, Vinh Q. Tran, XavierGarcia, Jason Wei, Xuezhi Wang, Hyung WonChung, Siamak Shakeri, Dara Bahri, Tal Schuster,Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby,and Donald Metzler. 2023. Ul2: Unifying languagelearning paradigms. Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-bert, Amjad Almahairi, Yasmine Babaei, NikolayBashlykov, Soumya Batra, Prajjwal Bhargava, ShrutiBhosale, Dan Bikel, Lukas Blecher, Cristian CantonFerrer, Moya Chen, Guillem Cucurull, David Esiobu,Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-thony Hartshorn, Saghar Hosseini, Rui Hou, HakanInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,Isabel Kloumann, Artem Korenev, Punit Singh Koura,Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-stein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subrama-nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,Melanie Kambadur, Sharan Narang, Aurelien Ro-driguez, Robert Stojnic, Sergey Edunov, and ThomasScialom. 2023. Llama 2: Open foundation and fine-tuned chat models. Alex Wang, Amanpreet Singh, Julian Michael, FelixHill, Omer Levy, and Samuel R Bowman. 2018.Glue: A multi-task benchmark and analysis platformfor natural language understanding. arXiv preprintarXiv:1804.07461.",
  ": Annotation Set (selected by Vote-k) PerplexityStatistics": "We report the perplexity of annotated instanceswhen (|L| = {16, 100}) (as shown in ). Itsobserved that as the annotation cost increases to100, there is a corresponding significant rise in per-plexity. For instance, in COPA, the Perplexityavg in-creases by 4.01, and Perplexitymax rises by 125.70.A similar phenomenon is also observed in DBpe-dia. This indicates to some extent that introducingdemonstrations with high perplexity can lead to adecrease in ICL performance.",
  "A.2Implementation Details": "The inference method we employed is direct (aregular inference used in (Brown et al., 2020)),which involves presenting demonstrations and can-didate answers to the LLMs to select the candidatewith the highest likelihood. For each test dataset,a specific prompt template () is used forscoring and inference. For each test instance, weinclude as many retrieved samples as possible inthe preceding prompt, up until the maximum to-ken length was reached (e.g., 2048 for GPTJ, 4096for LlaMA-2-7B). Sentence-BERT (Reimers andGurevych, 2019) is used as the demonstration re-triever. Following (Rubin et al., 2022), we adoptthe paraphrase-mpnet-base-v2 to encode the test in-put xtest and the inputs of the train set. All experi-ments are conducted on a single Tesla V100 GPUwith 32GB of memory. Empirically, obtaining em-beddings for unlabeled examples using SentenceBERT as described in .1 varies between0.2 to 2 hours, contingent upon the dataset size. In.2, our approach requires approximately6 seconds to generate the annotation set on a singleCPU. Notably, ICL obviates the need for modeltraining.",
  ": Dataset Statistics in the Experiments": "We also acknowledge that acquiring unlabelledsamples in practice is a process marked by signifi-cant variance(Su et al., 2022). To simulate this real-istic scenario, we randomly sample 3K instancesfrom the training set multiple times to serve as thepool of samples awaiting annotation. In all the ex-perimental setups described in this paper, we utilizefour distinct seeds (0, 1, 42, 123), and the valuespresented in the tables (figures) reflect the aver-age across four runs. Additionally, we provide thecorresponding standard deviations for these values.",
  "A.3Baselines": "RandomA randomly selected annotation base-line is necessary, as it directly picks unlabeledtraining instances at random. Ideally, data pointsselected by any heuristic algorithm should yieldbetter performance compared to it. Perplexity(Gonen et al., 2022) reported thatlower perplexity correlates with better performance.We rank candidate instances by their perplexity andselect the top |L| instances with the lowest perplex-ity as our annotation set. K-meansAs a representative selection methodin the series of diversity approaches, we employclustering techniques. Following (Yu et al., 2022),we first encode all data points using an Encoder,then perform k-means clustering with |L| clustersand select instances accordingly. Vote-k(Su et al., 2022) selects |L|/10 samplesthrough a graph-based voting mechanism, afterwhich the |L|/10 labeled samples are used as con-text for the LLMs, to calculate confidence scoresfor the other unlabeled candidate instances. Finally,the instances are grouped according to percentile",
  "KPMG and the Recruitment and Employment Confederation (REC) reported that the rate of expansion in hiring employees sank to a four-month low": "The number of job vacancies made available also fell to their slowest in 2015. Although starting salaries for permanent employees continued to grow, the pace of growth sank to its lowest since April's nine-month high. Recruitment agencies reported that the pay of temporary and contracted staff also continued to grow, although at its slowest since January. The availability of temporary staff saw its fastest drop in seven months, leading recruitment consultants to report difficulties in hiring suitable people. KPMG partner Bernard Brown said: \"The UK job market saw a slight slowdown in May, as those on boards took time to digest the election result and work out the ramifications for their business. The public sector continues to suffer, with pay growth rising by just 0.2% in the last reported quarter.\"",
  ": In MRPC, the four demonstration label exam-ples selected by Random and LM-DPP": "consistent. For example, while the source text em-phasizes a \"The UK job market saw a slight slow-down in May,\" the LM-DPP generated summarymentions \"fell in May,\" shifting the focal point ofthe information and potentially misleading readersto interpret a deterioration in actual employmentconditions rather than a deceleration in growth rate.This discrepancy is also reflected in the contextevidence cited by LM-DPP, which notes \"the avail-ability of temporary staff saw its fastest drop inseven months,\" further reinforcing a negative por-trayal of employment circumstances, despite notfully reflecting the sources focus or theme.We further observe that balancing the Rougescores with FactCC scores, ensuring factual consis-tency while maintaining high levels of abstractive-ness and textual similarity, presents a significantchallenge for LM-DPP. This observation suggeststhat future research might need to explore morenuanced demonstration selection strategies or intro-duce stronger fact-checking and correction mecha-nisms to mitigate the potential risks to factual con-sistency arising from the pursuit of diversity anduncertainty. This provides valuable insights on howto further optimize the method moving forward.",
  "C.3Impact of label coverage": "At L = 4, the Acc. of Random and LM-DPP onMRPC and TREC are respectively (47.30, 40.63)and (61.36, 49.64). Combined with Tables 10 and11, it can be seen that as the label coverage in-creases, performance on MRPC decreases, whileTREC shows an expected pattern. This may berelated to the difficulty of the task; moreover, fromthe perspective of data, an imbalanced label dis-tribution might more closely approximate the sta-tistical characteristics of real-world data. In cer-tain cases, imbalanced examples could reflect keysignals of specific categories, aiding the model inlearning effective decision boundaries more swiftly.We look forward to further research in this area."
}