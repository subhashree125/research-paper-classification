{
  "Abstract": "Large Language Models (LLMs) have emergedas powerful tools for Text-to-SQL tasks, ex-hibiting remarkable reasoning capabilities. Dif-ferent from tasks such as math word problemsand commonsense reasoning, SQL solutionshave a relatively fixed pattern.This facili-tates the investigation of whether LLMs canbenefit from categorical thinking, mirroringhow humans acquire knowledge through in-ductive reasoning based on comparable exam-ples. In this study, we propose that employ-ing query group partitioning allows LLMs tofocus on learning the thought processes spe-cific to a single problem type, consequentlyenhancing their reasoning abilities across di-verse difficulty levels and problem categories.Our experiments reveal that multiple advancedLLMs, when equipped with PTD-SQL, caneither surpass or match previous state-of-the-art (SOTA) methods on the Spider and BIRDdatasets. Intriguingly, models with varying ini-tial performances have exhibited significant im-provements, mainly at the boundary of theircapabilities after targeted drilling, suggesting aparallel with human progress. Code is availableat",
  "Introduction": "The Text-to-SQL task involves the automatic gen-eration of SQL statements from natural languageand has attracted much attention (Qin et al., 2022;Qu et al., 2024; Jo et al., 2024). Prior research pri-marily focused on training encoder-decoder modelson text corpora and database schemas to capturegeneration patterns (Xu et al., 2021). Given theimpressive capabilities of Large Language Mod-els (LLMs) in various Natural Language Process-ing (NLP) tasks, numerous studies have endeavoredto apply LLMs to this task (Li et al., 2024a; Zhanget al., 2024; Askari et al., 2024; Lee et al., 2024).",
  ": Demonstration of targeted drilling prompt onmulti-set problems": "Recent investigations have proposed enhanc-ing the reasoning capabilities of LLMs in theText-to-SQL task, yielding substantial progress.Diverse methods such as the few-shot Chain-of-Thought (CoT) (Wei et al., 2022),self-consistency (Wang et al., 2022), and the decom-position prompt that emphasizes dissecting com-plex problems and solving them sequentially (Khotet al., 2022) have been introduced.A leadingmethod, DIN-SQL (Pourreza and Rafiei, 2024),breaks down the task into several subtasks, clas-sifies the complexity based on the nested logic ofthe problem, and applies different prompt strate-gies accordingly. However, like other studies, itoverlooks the unique characteristics of SQL state-ments, which differ from math word problems andother code tasks. For calculations involving multi-ple sets, keywords like INTERSECT or UNIONare often used to combine statements of several sub-problems, making these queries naturally suitablefor decomposition. Counting and sorting problemstypically rely on GROUP BY operations to iden- tify objects to be aggregated and use ORDER BYto sort other objects. Just like during a test withvarious question types, the knowledge points andproblem-solving experiences that emerge in ourminds are different.Motivated by the brief overview of SQL ques-tion types above, we consider whether it is feasibleto guide LLMs, akin to training human students forspecific question types to master key concepts, byfocusing on type-related examples during reason-ing (Zhou et al., 2024b). Accordingly, we randomlyselect 100 multi-set operation questions from thetraining set, which require the use of keywordslike INTERSECT or EXCEPT. We adopt twodifferent prompt strategies: one from DIN-SQL,where these questions are classified as nested-levelquestions, providing samples of various questiontypes under this complexity level, and another, asdepicted in , where we only provide LLMmulti-set question examples with the same num-ber. With these strategies, we achieve executionaccuracy rates of 39.0 and 55.0 using ChatGPT,respectively. The former exhibits more sub-queryerrors and logical confusion.Drawing on the above observation, we proposethe Partitioning and Targeted Drilling (PTD-SQL)framework to enhance LLMs reasoning capabili-ties in Text-to-SQL tasks. This strategy mirrors thehuman learning process, where students typicallyfirst identify the group of questions and then searchfor the most relevant knowledge points to answerthem. Initially, we categorize the types of textualqueries in the training set based on the keywordsin the ground-truth SQL statements. Informed byprevious studies, we opt not to rely solely on theLLMs few-shot discrimination ability but insteaddelegate a small LLM with fine-tuning for thistask (Juneja et al., 2023; Zhuang et al., 2023). Inthe second step, we design prompts with differ-ent emphases for various categories of problems inthe training set and automatically generate problemsets and reference answers the areas that the LLMneeds to learn. Both of these operations are per-formed offline and avoid invoking GPT during test-ing, thus achieving cost efficiency. Finally, duringthe inference stage, we classify the original textualquery and design an automatic selection module tocompose a few-shot prompt in the correspondinggroup of the problem set (An et al., 2023a).We extensively validate the effectiveness of PTD-SQL on the Spider-dev, Spider-realistic, and BIRD-dev datasets using three powerful LLMs, where",
  ": Some samples of proposed partition": "it outperforms state-of-the-art frameworks suchas DIN-SQL and DAIL-SQL. We also find thatthe model becomes more capable of achievingbreakthroughs at the capability boundaries whenequipped with PTD-SQL, which may potentiallyextend to other reasoning tasks. Furthermore, ourapproach adheres to a one-time query paradigm,showing advantages in terms of token consumptionand inference time, also allowing many methodstargeting schema linking or database content align-ment to be seamlessly integrated, thereby anticipat-ing even higher performance.",
  "Related Work": "LLM ReasoningNowadays, the developmentof reasoning models based on LLM has become apopular and critical field. (Shi et al., 2023) Manyefficient prompting methods have been proposed,such as Chain-of-Thought (Wei et al., 2022), whichguides LLM in step-by-step thinking; Least-to-Most (Zhou et al., 2022), which makes the modeladapt to the difficulty gradient; and Decomposition-based prompting (Khot et al., 2022; Ye et al., 2023),which breaks down difficult problems to solve themseparately. In addition, Self-Consistency (Wanget al., 2022) demonstrates the overall tendencyof LLM towards the correct answer through vot-ing, Self-discover (Zhou et al., 2024b) allows themodel to make different problem-solving plans ac-cording to different types of questions, and Self-refine (Madaan et al., 2024) enables LLM to learnfrom the feedback of its problem-solving pro-cess. Besides, many works also strengthen theweaker aspects of LLM at the code level, suchas PAL (Gao et al., 2023b) and PoT (Chen et al.,2022). MAD (Liang et al., 2023) stimulates diversethinking in LLMs through group debate. Modelcritic (Gou et al., 2023; Lin et al., 2024) enhancesthe reasoning ability of LLMs by self-criticism, analogous to human critical and corrective behav-iors. Besides, Mixture-of-Experts (MOE) architec-ture has also become one of the key research di-rections for stimulating model performance (Zhaoet al., 2024; Shi et al., 2024). LLM-based Text-to-SQLNowadays,manystudies are focusing on utilizing LLMs to com-plete Text-to-SQL tasks, primarily involving moreefficient prompt design and advanced process de-ployment. Strategies that have proven effectivein common sense reasoning and mathematical rea-soning, such as CoT and self-consistency, havealso been applied to enhance Text-to-SQL reason-ing. C3 (Dong et al., 2023) and StructGPT (Jianget al., 2023) have introduced effective zero-shotstrategies based on GPT, along with meticulousinterface settings. DIN-SQL (Pourreza and Rafiei,2024) divides the Text-to-SQL task into phasedsubtasks and assigns different LLMs to special-ize in completing each stage, as well as catego-rizes the difficulty of questions to provide varyingprompt strategies. DAIL-SQL (Gao et al., 2023a)has conducted a comprehensive evaluation of manyprompt-based methods and proposed a more pre-cise samples matching approach to improve results.Recent approaches have also concentrated on ad-dressing issues not yet considered in the data itself.For instance, PET-SQL (Li et al., 2024b) focuseson leveraging prior knowledge within databasesto enhance the accuracy of responses at the tokenlevel, which shows benefit on Text-to-SQL. SQL-CRAFT (Xia et al., 2024) suggests allowing mod-els to engage in interactive refinement to improvereasoning accuracy. DEA-SQL (Xie et al., 2024)and MAC-SQL (Wang et al., 2023) integrate mul-tiple optimization techniques to propose workflowagents. Recently, many new benchmarks have beenproposed for the development of this field to accom-modate more enterprise-level applications (Sapa-rina and Lapata, 2024; Zhou et al., 2024a).",
  "In this section, we first provide the definition of theQGP sub-task and then describe the process of fine-tuning the small LLM using PEFT to accomplishthe QGP task": "Problem FormulationSQL queries differ frommath word problems and other code problems,such as Python, as their textual labels often con-tain highly characteristic expressions, making prob-lem group identification convenient. We clusterthem based on label keywords: multi-set, combi-nation, filter, and other simple problems. Multi-setproblems frequently involve two or more layersof logic and require keywords like INTERSECT,UNION, and EXCEPT for connection. Combi-nation problems necessitate the use of a GROUPBY operation to group data, followed by sorting,taking extreme values, and other purposeful opera-tions. Filter problems involve constructing condi-tional statements and using them for target screen-ing. The remaining problems are classified as othersimple problems, as depicted in . Consid-ering that some queries may have implicit labelsof other types, we provide prioritized classifica-tion criteria in the prompt to alleviate the impactof model bias. Specific examples are shown in theAppendix E.3. The task objective is explicitly de-fined as follows: given a text query q, we need tooutput its problem group g. It is formulated as:",
  "where f( | ) can present a model with parameters. We randomly select the training set ST for theQGP task on the original training set and separatethe validation set SV": "Fine-tuned LLM ClassifierInspired by previ-ous works (Juneja et al., 2023; Zhuang et al., 2023),we consider delegating the ability to determine cat-egories to the fine-tuning process of the small LLMrather than directly trusting the discrimination ca-pability of LLM. With the rapid advancement ofPEFT technology, we choose Low-Rank Adap-tation (LoRA) (Hu et al., 2021) to fine-tune theLlama-2-7b model to solve the QGP problem. Fora pre-trained weight matrix W0 Rdk, LoRAadds a bypass using two decomposition matricesA Rdr and B Rrk, where r min(d, k).The forward process of single weight matrix ismodified to:",
  "Let's think step by step": "<1> Operation: The query requires the city that has hosted greatest number of competitions, so we should apply the 'count' operation to table 'farm_competition', and sort it in descending order. Since the unit to which the competitions being counted in the query belong is city and only table 'farm_competition' has column 'Host_city_ID', so we should apply the 'group by'operation to column 'Host_city_ID' in table 'farm_competition.",
  "<2> Schema Linking: To complete the first subproblem, we need to use tables ['drivers', 'pitStops']. To complete the second subproblem, we need to use tables ['drivers', 'results]": "<3> Operation: For the first subproblem, we need to perform a 'GROUP BY' operation on the column 'driverId' and filter by performing 'HAVING COUNT()' on the column 'stop'. For the second subproblem, we need to perform a 'GROUP BY' operation on the column 'driverId' and filter by performing 'HAVING COUNT()' on the column 'raceId.",
  "<4> SQL Generation: Use 'union' operation to connect the queries of subproblems to form the final SQL statement": "SQL query: SELECT T1.forename , T1.surname , T1.driverid FROM drivers AS T1 JOIN pitstops AS T2 ON T1.driverid = T2.driverid GROUP BY T1.driverid HAVING count(*) > 8 UNION SELECT T1.forename , T1.surname , T1.driverid FROM drivers AS T1 JOIN results AS T2 ON T1.driverid = T2.driverid GROUP BY T1.driverid HAVING count(*) > 5",
  "<2> Schema Linking: Due to the direct foreign key connection between table 'city' and 'farm_competition'. We need to use tables ['city', 'farm_competition]": "<3> SQL Generation: The query requires the status of the city that has hosted the greatest number of competitions, so we should select the 'Status' column in the 'city' table. The query does not require the count of most competitions, so it is only used for filtering and not selected.",
  "Targeted Drilling Bank Auto-construction": "In this section, we explain how to construct tar-geted drilling banks for different question groupsin PTD-SQL, which can be compared to the spe-cialized training and reference ideas and answersdesigned by teachers for students before examina-tions. Previous works grade the difficulty based on whether the problem requires nesting and design-ing corresponding prompt templates. However, thisapproach only focuses on the surface logic of SQLqueries and does not consider the distinct thinkingpaths required by the essence of different questiongroups for LLM. Given that selecting irrelevant ex-amples may also be detrimental to LLMs thinking,in PTD-SQL, we can benefit from the proposedQGP. That is, for test queries of specific questiongroups, we can directly and accurately locate theproblem banks with similar thinking paths. Multi-set problems often require breaking downa complex problem into multiple subqueries andintegrating the different results through connectingkeywords. For filtering problems, we can oftenprompt LLM to first propose the organization offiltering conditions and then process the selectiontarget. Therefore, these two types of problemsare naturally suitable for the design inspirationof decomposed prompting. We show an exam-ple of prompt construction for a multi-set prob-lem, as depicted in . For filtering prob-lems, our decomposition focuses on the division ofconditional statements and the extraction of targetcolumns, and the specific prompts are shown inAppendix E.1. It is worth mentioning that we treatschema linking as a byproduct of LLMs thinkingprocess, thereby achieving the purpose of one-timegeneration, which reduces the query cost.",
  "## queryWhat are the names and ids of all stations that have more than 14 bikes available on average or had bikes installed in December?": "Lets think step by step.<1> Question Decomposition: 1. names and ids of all stations that have more than 14 bikes available on average; 2. names and ids of all stations that had bikes installed in December. <2> Schema Linking: <3> Operation: GROUP BY, HAVING AVG(), UNION SQL: SELECT T1.name, T1.id FROM station AS T1 JOIN status AS T2 ON T1.id = T2.station_id GROUP BY T1.id HAVING avg(T2.bikes_available) > 14 UNION SELECT name, id FROM station WHERE installation_date LIKE '12/%'",
  ": Overflow of PTD-SQL. (a) QGP sub-task. (b) Targeted drilling bank auto-construction. (c) Reasoningstep": "problems, we construct concise CoT templates. Forthe former, the model is required to distinguish theobjects that need to be counted (sorted or takingextreme values) and the groups they belong to, thusimproving the ability to organize answers underthis question type. An example is shown in Fig-ure 3. For the remaining simple problems, wechoose to use the ground truth SQL query directlyas the composition of the few-shot prompt withoutintroducing other thinking processes.After creating four different types of few-shotprompts, we apply them separately to their respec-tive problem groups in the training set to generatethe thinking process and the final SQL query. Weselect the samples with correct execution resultsof the SQL query to form four targeted drillingbanks because we believe that the thinking paths inthe examples with correct final answers are highlylikely to be reasonable and enlightening. Theseare the sources of the examples that LLM refers toduring the inference phase. The specific statisticsof different targeted drilling banks are shown inAppendix A.1.",
  "Few-shot Selection": "Few-shot example construction is a crucial step inprompt engineering because LLMs are sensitive tofew-shot samples. In PTD-SQL, we perform QGPon each textual query and then automatically selectshots in the corresponding targeted drilling bank. Semantic matchingPrevious work has verifiedthe effectiveness of methods based on semantic vec-tor matching (An et al., 2023b). We calculate andstore sentence embeddings for all textual queriesin the targeted drilling bank using OpenAI text-embedding-ada-0021, resulting in an offline bankmatrix M. For test queries, we encode them withtext-embedding-ada-002 and calculate the cosinesimilarity with M to measure the degree of seman-tic matching as some previous works do.",
  "Mix-of-matchingSimilar to the idea of multi-way recall, we mix an equal amount of examplesselected by the two strategies above, for instance,choosing the top 2 most relevant examples from": "each in a 4-shot scenario, in order to provide as richand relevant samples as possible within the sameproblem group, thus guiding effective thinking.For other methods, such as Skill-based KNN (Anet al., 2023b), they generally incorporate additionalstages like rewriting, we primarily emphasize thatwithin the widely used test sets currently, the rel-atively simpler mix-of-matching strategy we pro-pose can effectively cooperate with previous mod-ules, thereby accomplishing the task at a low cost.Mix-of-matching is consistent with the core ideaof the previously designed QGP, both focusing onleveraging the explicit structural information of theSQL language.",
  "Experimental Setup": "DatasetsSpider (Yu et al., 2018) is the mostwidely used cross-domain dataset. This datasethas 7,000 training data in the training set and 1,034data in the development set, covering 200 differ-ent databases and spanning 138 domains. Spider-realistic (Deng et al., 2020) is a more challengingdataset containing 508 test data points, which man-ually mask the specific column selections in thetext query. BIRD (Li et al., 2024a) dataset contains95 large-scale real databases covering 37 profes-sional domains. More details and usage of the datacan be found in Appendix A.2. EvaluationMost previous work adheres to twocommon evaluation metrics: 1) Exact Match Accu-racy (EM): It requires that each subcomponent ofthe SQL query generated by the model matches thegold SQL query provided in the dataset. 2) Execu-tion Accuracy (EX): EX judges correctness basedon whether the answer returned by executing thepredicted SQL query in the database is consistentwith the gold query. Since a textual query maycorrespond to several correct but stylistically differ-ent SQL query formulations, it is a more accuratemeasure of Text-to-SQL methods. Besides, ValidEfficiency Score (VES) is used to demonstrate theefficiency of valid SQLs provided by models. BaselinesWe compare three different path Text-to-SQL methods, including fine-tuning, zero-shot,and few-shot prompting methods. Among them,the fine-tuning method includes PICARD (Scholaket al., 2021) and the current SOTA RESD-SQL+NatSQL (Li et al., 2023). The zero-shotmethod C3 (Dong et al., 2023) focuses on schema",
  ": EX on Spider-realistic dataset": "linking filtering and removing GPTs inherent biasfor SQL generation.DIN-SQL (Pourreza andRafiei, 2024), which breaks down the textual queryinto multiple staged questions. DAIL-SQL (Gaoet al., 2023a) considers optimizing sample selec-tion and organization to further enhance LLMsreasoning ability in Text-to-SQL. Implementation DetailsIn order to compre-hensively evaluate the performance of the frame-work on closed-source and open-source modelsand demonstrate its effectiveness, we employ threeLLMs for comparison purposes: OpenAI GPT-3.5-turbo-0613 for ChatGPT, GPT-4-0613, andDeepseek-coder-6.7b-instruct2 (Guo et al., 2024).The latter is pretrained on high-quality code cor-pora and has attained the current state-of-the-artperformance among open-source code models inthe realm of code generation. Maximum contextlength is limited to 4096 for OpenAI LLMs and2048 for open-source LLMs.",
  "Main Results": "As shown in , PTD-SQL + GPT4 achievesthe best EX metric on the Spider-dev dataset. Addi-tionally, PTD-SQL surpasses DIN-SQL and DAIL-SQL when using ChatGPT and Deepseek-coder-6.7b-instruct as base models. Compared to themore advanced DAIL-SQL framework, PTD-SQLachieves relative increases of 1.5%, 3.1%, and1.3% on ChatGPT, GPT-4 and Deepseek-coder-6.7b-instruct, respectively. When compared withprevious fine-tuning and prompting methods, PTD-SQL also attains a comparative performance. Be-sides, as shown in , ChatGPT-equippedPTD-SQL also outperforms previous methods andGPT-4 using zero-shot. Furthermore, the resultsshown in indicate that all three power-ful models equipped with PTD-SQL demonstratestronger EX. In terms of VES indicators, PTD-SQLalso has a certain competitiveness. A case studyon Spider is given in Appendix B.6. Furthermore,we discuss the advantages of PTD-SQL in termsof token consumption and inference time in Ap-pendix D.",
  ": Under different difficulty levels, the per-centage gain (%) in EX metric on Spider (left) andBIRD (right) obtained by the three models using PTD-SQL compared to DIN-SQL": "by the database itself (RQ1) and the performanceacross various problem groups (RQ2). Concur-rently, we delve into the insights that PTD-SQLcontributes to the LLM-based Text-to-SQL domain.Furthermore, we perform ablation studies on theemployed modules, primarily focusing on the ef-fectiveness of introduced QGP task (RQ3), andthe influence of shot selection strategies within thesame targeted drilling bank (RQ4).",
  "RQ1: Performance from a Difficulty-level": "In this subsection, we evaluate the superiorityof PTD-SQL over existing state-of-the-art frame-works based on the difficulty levels defined by thedatabase, respectively. As depicted in ,PTD-SQL outperforms DIN-SQL and DAIL-SQLacross different base LLMs, particularly at hardand extra difficulty levels, indicating that LLM canspecialize in a problem group and demonstrate en-hanced targeted reasoning ability after imitatingand delving into problems within the same group.Moreover, we illustrate the performance vari-ations of PTD-SQL in comparison to DIN-SQLacross different problem types, thereby discerningthe disparities between problem group partition-ing strategies and difficulty grading strategies. Asinferred from , LLMs have made greatprogress at their respective capacity limits underPTD-SQL. For instance, ChatGPT, akin to a dili-gent student, achieves a 29.8% improvement inhard difficulty by focusing on similar problems butfails to progress in extra difficulty, possibly due toinherent model limitations. The deepseek-coder-6.7b-instruct model, with capabilities comparableto ChatGPT, also shows the most significant im-provement in hard difficulty (25.3% vs 17.2% onextra). However, GPT-4, resembling an elite stu-dent, achieves the most substantial breakthroughin extra difficulty and refines its responses acrossother difficulty levels through referencing and ab-",
  ": EX performance based on partition with differ-ent accuracy levels on the Spider-dev dataset": "sorption. The results on the BIRD dataset showthat GPT-4 achieves the largest increase in perfor-mance in the challenging group, while the othertwo models focus on simple and moderate difficul-ties. This suggests that LLMs with different levelsof reasoning capability can guarantee their upperlimit by practicing questions. Detailed results onBIRD are depicted in Appendix B.1.",
  "RQ2: Performance under ProblemGroups": "As depicted in , PTD-SQL demonstrates amore pronounced advantage in multi-set problemsand combination problems when employing threedifferent baseline models. These problem typesentail more intricate reasoning and perplexing con-ditions. Apart from when using GPT-4, the othertwo models yield very similar results in the filteringproblem across the three methods. This suggeststhat this category of problem relies more on theinherent ability of the model to effectively organizethe filtering conditions rather than emphasizing thelogical level. Besides, we consider the detailedperformance of queries with multiple question typefeatures in Appendix B.5, and propose findings anddirections for further improvement.",
  "RQ3: Effectiveness of QGP": "In this section, we examine the impact of the QGPsubtask. As shown in , the Few-shot methoddoes not align well within a specific context, re-sulting in weaker performance compared to thefine-tuned model. To further investigate this, weconduct additional experiments involving problemgroups classified by ChatGPT, as well as experi-ments that eliminate the QGP stage and directlyrecall shots from all targeted drilling banks. Thefindings presented in indicate that a de-cline in QGP accuracy adversely affects the finaloutcomes, with a relative decrease of 5.0% whentesting on ChatGPT. Besides, ChatGPT exhibits aslight reduction in extra difficulty, while Deepseekdemonstrates tolerance for classification accuracyat medium to easy difficulty levels. However, upon",
  "RQ4: Ablation on Few-shot Selection": "In this section, ablation experiments are conductedfor three distinct shot selection strategies within thesame problem group. As illustrated in , thehybrid strategy demonstrates a favorable integra-tion effect beyond the easy category, resulting inan overall improvement. This finding suggests thatconsidering both query keywords and semantic sim-ilarity can yield a more comprehensive promptingeffect.",
  ": EX on different numbers of few-shot samplesw.r.t problem groups": "As a few-shot prompting method, we believe thatthe number of examples is also an important factoraffecting the results. Due to the context limitationswe mentioned, we conduct ablation experimentswith 4 shots or fewer. For the 1-shot scenario, weselected the single most similar example based onsemantic similarity. The performance of PTD-SQLunder different numbers of examples, different dif-ficulty levels, and different question types is shownin and , respectively.Our results show that when the number of exam-ples is small, it has a greater impact on the finalresults, and the EX indicator generally shows agrowing trend with the increase of examples. Thissuggests that more examples can stimulate morediverse thinking abilities under relatively limited",
  "Conclusion": "In this article, a novel method called PTD-SQL isproposed for LLMs to conduct targeted drilling onspecific groups of questions after partitioning. Thisapproach addresses the category tendency of SQLqueries, which has been overlooked in previouswork. By focusing on the thinking logic of spe-cific types, LLM can effectively enhance its reason-ing capabilities. Empirical observations from ourcomprehensive ablation studies reveal that PTD-SQL significantly reduces the likelihood of LLMmaking errors within its distinct capability rangewhile demonstrating substantial gains across vari-ous question groups. Furthermore, it is posited thatthis approach can be extended to other domains,such as math word problems and different types ofcode problems, paving the way for future research.",
  "Limitations": "The limitations of this article lie in the explorationof its effectiveness on larger-scale databases with abroader domain span. Moreover, even SQL state-ments with strong structural characteristics mayhave different types of divisions. Therefore, a moredetailed investigation of performance under thesedifferent divisions can be further improved and op-timized. Besides, as stated in Appendix B.5, forqueries with multiple question types, we can alsorecall example questions from multiple shot banksto comprehensively consider the model and im-prove the fault tolerance of QGP subtasks. Thismay be an interesting topic that can be improvedin the future. In addition, due to space constraints,this article doesnt optimize for more detailed is-sues such as schema linking and database contentalignment. However, the optimization methods forthese issues can be relatively easily integrated intoPTD-SQL as a downstream optimization method.Due to our greater focus on the improvement ofLLMs reasoning ability for the question answeringitself in this article, we are confident that we canachieve better results by adding the aforementionedsub-optimization methods.",
  "Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun,Yichen Qian, Bolin Ding, and Jingren Zhou. 2023a.Text-to-sql empowered by large language mod-els:A benchmark evaluation.arXiv preprintarXiv:2308.15363": "Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon,Pengfei Liu, Yiming Yang, Jamie Callan, and Gra-ham Neubig. 2023b. Pal: Program-aided languagemodels. In International Conference on MachineLearning, pages 1076410799. PMLR. Zhibin Gou, Zhihong Shao, Yeyun Gong, YelongShen, Yujiu Yang, Nan Duan, and Weizhu Chen.2023. Critic: Large language models can self-correctwith tool-interactive critiquing.arXiv preprintarXiv:2305.11738. Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, KaiDong, Wentao Zhang, Guanting Chen, Xiao Bi,Y Wu, YK Li, et al. 2024. Deepseek-coder: When thelarge language model meets programmingthe rise ofcode intelligence. arXiv preprint arXiv:2401.14196.",
  "Edward J Hu, Yelong Shen, Phillip Wallis, ZeyuanAllen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,and Weizhu Chen. 2021.Lora: Low-rank adap-tation of large language models.arXiv preprintarXiv:2106.09685": "Jinhao Jiang, Kun Zhou, Zican Dong, Keming Ye,Wayne Xin Zhao, and Ji-Rong Wen. 2023. Struct-gpt: A general framework for large language modelto reason over structured data.arXiv preprintarXiv:2305.09645. Yongrae Jo, Seongyun Lee, Minju Seo, Sung Ju Hwang,and Moontae Lee. 2024. Lg ai research & kaist atehrsql 2024: Self-training large language modelswith pseudo-labeled unanswerable questions for areliable text-to-sql system on ehrs. arXiv preprintarXiv:2405.11162. Gurusha Juneja, Subhabrata Dutta, Soumen Chakrabarti,Sunny Manchanda, and Tanmoy Chakraborty. 2023.Small language models fine-tuned to coordinatelarger language models improve complex reasoning.arXiv preprint arXiv:2310.18338. Tushar Khot, Harsh Trivedi, Matthew Finlayson, YaoFu, Kyle Richardson, Peter Clark, and Ashish Sab-harwal. 2022. Decomposed prompting: A modularapproach for solving complex tasks. arXiv preprintarXiv:2210.02406.",
  "Dongjun Lee, Choongwon Park, Jaehyuk Kim, andHeesoo Park. 2024. Mcs-sql: Leveraging multipleprompts and multiple-choice selection for text-to-sqlgeneration. arXiv preprint arXiv:2405.07467": "Haoyang Li, Jing Zhang, Cuiping Li, and Hong Chen.2023.Resdsql: Decoupling schema linking andskeleton parsing for text-to-sql. In Proceedings ofthe AAAI Conference on Artificial Intelligence, vol-ume 37, pages 1306713075. Jinyang Li, Binyuan Hui, Ge Qu, Jiaxi Yang, BinhuaLi, Bowen Li, Bailin Wang, Bowen Qin, RuiyingGeng, Nan Huo, et al. 2024a. Can llm already serveas a database interface? a big bench for large-scaledatabase grounded text-to-sqls. Advances in NeuralInformation Processing Systems, 36. Zhishuai Li, Xiang Wang, Jingjing Zhao, Sun Yang,Guoqing Du, Xiaoru Hu, Bin Zhang, Yuxiao Ye,Ziyue Li, Rui Zhao, et al. 2024b. Pet-sql: A prompt-enhanced two-stage text-to-sql framework with cross-consistency. arXiv preprint arXiv:2403.09732. Tian Liang, Zhiwei He, Wenxiang Jiao, Xing Wang,Yan Wang, Rui Wang, Yujiu Yang, Zhaopeng Tu, andShuming Shi. 2023. Encouraging divergent thinkingin large language models through multi-agent debate.arXiv preprint arXiv:2305.19118.",
  "Mohammadreza Pourreza and Davood Rafiei. 2024.Din-sql: Decomposed in-context learning of text-to-sql with self-correction. Advances in Neural Infor-mation Processing Systems, 36": "Bowen Qin, Binyuan Hui, Lihan Wang, Min Yang,Jinyang Li, Binhua Li, Ruiying Geng, Rongyu Cao,Jian Sun, Luo Si, et al. 2022. A survey on text-to-sqlparsing: Concepts, methods, and future directions.arXiv preprint arXiv:2208.13629. Ge Qu, Jinyang Li, Bowen Li, Bowen Qin, Nan Huo,Chenhao Ma, and Reynold Cheng. 2024. Beforegeneration, align it! a novel and effective strategyfor mitigating hallucinations in text-to-sql generation.arXiv preprint arXiv:2405.15307.",
  "Bing Wang, Changyu Ren, Jian Yang, Xinnian Liang,Jiaqi Bai, Qian-Wen Zhang, Zhao Yan, and ZhoujunLi. 2023. Mac-sql: Multi-agent collaboration fortext-to-sql. arXiv preprint arXiv:2312.11242": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,Ed Chi, Sharan Narang, Aakanksha Chowdhery, andDenny Zhou. 2022. Self-consistency improves chainof thought reasoning in language models.arXivpreprint arXiv:2203.11171. Jason Wei, Xuezhi Wang, Dale Schuurmans, MaartenBosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou,et al. 2022. Chain-of-thought prompting elicits rea-soning in large language models. Advances in neuralinformation processing systems, 35:2482424837. Hanchen Xia, Feng Jiang, Naihao Deng, CunxiangWang, Guojiang Zhao, Rada Mihalcea, and YueZhang. 2024. Sql-craft: Text-to-sql through inter-active refinement and enhanced reasoning. arXivpreprint arXiv:2402.14851. Yuanzhen Xie, Xinzhou Jin, Tao Xie, MingXiong Lin,Liang Chen, Chenyun Yu, Lei Cheng, ChengXiangZhuo, Bo Hu, and Zang Li. 2024. Decompositionfor enhancing attention: Improving llm-based text-to-sql through workflow paradigm. arXiv preprintarXiv:2402.10671.",
  "Kuan Xu, Yongbo Wang, Yongliang Wang, Zujie Wen,and Yang Dong. 2021. Sead: End-to-end text-to-sql generation with schema-aware denoising. arXivpreprint arXiv:2105.07911": "Yunhu Ye, Binyuan Hui, Min Yang, Binhua Li, FeiHuang, and Yongbin Li. 2023.Large languagemodels are versatile decomposers: Decompose evi-dence and questions for table-based reasoning. arXivpreprint arXiv:2301.13808. Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga,Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingn-ing Yao, Shanelle Roman, et al. 2018. Spider: Alarge-scale human-labeled dataset for complex andcross-domain semantic parsing and text-to-sql task.arXiv preprint arXiv:1809.08887. Bin Zhang, Yuxiao Ye, Guoqing Du, Xiaoru Hu,Zhishuai Li, Sun Yang, Chi Harold Liu, Rui Zhao,Ziyue Li, and Hangyu Mao. 2024.Benchmark-ing the text-to-sql capability of large language mod-els: A comprehensive evaluation. arXiv preprintarXiv:2403.02951.",
  "Hao Zhao, Zihan Qiu, Huijia Wu, Zili Wang, ZhaofengHe, and Jie Fu. 2024. Hypermoe: Towards bettermixture of experts via transferring among experts.arXiv preprint arXiv:2402.12656": "Ruiqi Zhong, Tao Yu, and Dan Klein. 2020. Seman-tic evaluation for text-to-sql with distilled test suite.In The 2020 Conference on Empirical Methods inNatural Language Processing. Association for Com-putational Linguistics. Denny Zhou, Nathanael Schrli, Le Hou, Jason Wei,Nathan Scales, Xuezhi Wang, Dale Schuurmans,Claire Cui, Olivier Bousquet, Quoc Le, et al. 2022.Least-to-most prompting enables complex reason-ing in large language models.arXiv preprintarXiv:2205.10625. Fan Zhou, Siqiao Xue, Danrui Qi, Wenhui Shi, WangZhao, Ganglin Wei, Hongyang Zhang, Caigai Jiang,Gangwei Jiang, Zhixuan Chu, et al. 2024a. Db-gpt-hub: Towards open benchmarking text-to-sql em-powered by large language models. arXiv preprintarXiv:2406.11434. Pei Zhou, Jay Pujara, Xiang Ren, Xinyun Chen, Heng-Tze Cheng, Quoc V Le, Ed H Chi, Denny Zhou, Swa-roop Mishra, and Huaixiu Steven Zheng. 2024b. Self-discover: Large language models self-compose rea-soning structures. arXiv preprint arXiv:2402.03620. Yan Zhuang, Qi Liu, Yuting Ning, Weizhe Huang, RuiLv, Zhenya Huang, Guanhao Zhao, Zheng Zhang,Qingyang Mao, Shijin Wang, et al. 2023.Ef-ficiently measuring the cognitive ability of llms:An adaptive testing perspective.arXiv preprintarXiv:2306.10512.",
  "A.1Statistics of Targeted Drilling Banks": "On Spider-dev and Spider-realistic datasets, the samples from the four different targeted drilling banksall come from random selections within their respective categories after automated classification in thetraining set, as shown in .However, the BIRD dataset does not provide a training set with regular attributes for generatingcandidate question banks. Our testing criterion is to randomly divide the Spider-dev dataset into 20% fortraining and the remaining 80% as a testing benchmark at three different difficulty levels. The trainingset is used for fine-tuning the classifier and building the targeted drilling bank. The statistical data ofthe targeted drilling bank on the BIRD-dev dataset is shown in Table A. Additionally, due to the lackof clearly defined multi-set operation queries in the BIRD-dev dataset, we only need to investigate theremaining three question types.",
  ": Detailed EX accuracy of three methods on Spider-dev dataset split by problem groups": "The effects presented are quite similar. Upon sample observation, the content retrieved by the model isalso similar, which may be related to the dataset. It could also be due to the fact that SQL text queries areessentially composed of purpose statements and database-related items, thus leading to a high degree ofdifferentiation. As for embedding model, text-embedding-ada-002 demonstrates good performance onbenchmarks like BEIR, and due to its low cost, it is a very economical choice.",
  ": Ablation study on different few-shot auto-selection strategies on Spider-dev dataset. We employ GPT-4 asreasoning LLM": ".1 applied to the training set, we can directly apply this to the test set to derive a potential set ofquestion groups. For instance, the ground-truth SQL query SELECT Country FROM singer WHEREAge > 40 INTERSECT SELECT Country FROM singer WHERE Age < 30 is categorized as (Multi-set,Filtering).We define the set of multiple categories to which each query should belong as X and the single grouplabel Y obtained after the fine-tuned Llama-2-7b model completes the QGP. In and , wepresent the EX for all possible partition sets when using ChatGPT and GPT-4, respectively.Initially, a generally accurate classification can yield relatively satisfactory results. For instance, queriesfeaturing combination problem and filtering problem characteristics exhibit a commendable EX whenthey are divided into these two subclasses, given a sufficiently large number of samples. Similarly, querieswith multi-set and filtering problem features can also attain comparable and favorable EX indicatorswhen they are divided into their respective groups. This suggests that in most instances, a question withmultiple types of tendencies can draw insights from a single question bank and make reasonably accurateinferences.Nonetheless, certain observations also highlight specific limitations of PTD-SQL. For example, inthe case of combination-type questions, superior overall results were achieved when they were directlyclassified as simple problems. This is because these questions, in contrast to those classified as combinationproblems, contain a greater number of easy and medium-difficulty problems, thus directly benefiting fromthe simplicity of CoT. Consequently, for future optimization of PTD-SQL, it could be considered, assuggested in the DIN-SQL method, to incorporate the difficulty of the query, thereby preventing somesimple questions from being disrupted by complex thought processes.When comparing the data between and , we can find that GPT-4s stronger fundamentalreasoning ability allows for a greater tolerance for misclassification risks. At the same time, the gap inperformance between Combination-type questions classified as simple questions and those classified asCombination itself is also reduced.",
  "B.6Case Study": "In this section, we give some detailed cases to show how PTD-SQL assists LLMs in Text-to-SQL. Asshown in , the output of DIN-SQL shows that DIN-SQL doesnt properly handle multi-setqueries. Simply using OR for connection may cause conflict issues in multi-table queries. However,PTD-SQL successfully solves the problem by properly learning the decomposition of the problem andusing corresponding keywords to connect subqueries correctly. In addition, as shown in , thesentences generated by DIN-SQL may have the risk of confusing filtering phrases, while PTD-SQLteaches LLM to think hierarchically about filtering logic and answer organization, thus leading to thecorrect results.",
  "DIN-SQL outputSELECT Airline FROM airlines JOIN flights ON airlines.uid = flights.AirlineWHERE flights.SourceAirport = APG OR flights.SourceAirport = CVO": "PTD-SQL outputSELECT Airline FROM airlines WHERE EXISTS (SELECT * FROM flightsJOIN airports ON flights.SourceAirport = airports.AirportCode WHERE air-ports.AirportCode = APG AND airlines.uid = flights.Airline) INTERSECTSELECT Airline FROM airlines WHERE EXISTS (SELECT * FROM flightsJOIN airports ON flights.SourceAirport = airports.AirportCode WHERE air-ports.AirportCode = CVO AND airlines.uid = flights.Airline) Reasoning<1> Question Decomposition: In this step, we contemplate how to decompose thequery. The query emphasizes the intersection set logic, so we can decompose thequestion into two subproblems: 1. find all airlines that have flights from airportAPG; 2. find all airlines that have flights from airport CVO. <2> SchemaLinking: In this step, we identify the tables and columns that should be used basedon the requirements of the query and the foreign key relationships. To completeboth subproblems, we need to use tables [airlines, flights, airports]. <3>Operation: Use where to filter using column SourceAirport in table flightsand column AirportCode in table airports. <4> SQL Generation: Use theintersect operation to connect the queries of subproblems to form the final SQLstatement.",
  "DIN-SQL outputSELECT CountryName FROM countries WHERE Continent = Europe ANDCountryId IN (SELECT Country FROM car_makers GROUP BY Country HAV-ING COUNT(*) >= 3)": "PTD-SQL outputSELECTCountryNameFROMcar_makersJOINcountriesONcar_makers.Country=countries.CountryIdJOINcontinentsONcoun-tries.Continent = continents.ContId GROUP BY Country HAVING COUNT(*)>= 3 AND continents.Continent = Europe Reasoning<1> Operation: The query requires the countries in Europe that have at least 3car manufacturers. So we should apply the count operation to the Id columnin the car_makers table and find the countries with a count of at least 3. Sincethe unit to which the car manufacturers are being counted in the query belongs inthe country, we should apply the group by operation to the Country columnin the car_makers table.<2> Schema Linking: In this step, we identify thetables and columns that should be used based on the first step and the foreign keyrelationships. In this question, we need to use tables [car_makers, countries,continents].<3> SQL Generation: The query requires the countries in Europethat have at least 3 car manufacturers, so we should select the CountryNamecolumn from the countries table. We also need to join the car_makers tablewith the countries table and the continents table to ensure that we are onlyconsidering countries in Europe.",
  "DTime and Token cost": "In this section, we highlight the comparative benefits of PTD-SQL over alternative frameworks concerningtime and token usage. Owing to our approach necessitating only a single query, we gain a considerableedge in token efficiency while simultaneously ensuring effective time management and exceptionaloutcomes. Although certain optimizations aimed at addressing difficulty granularity and schema linkingcould potentially enhance PTD-SQLs performance, they would unavoidably result in increased time andtoken expenditures. The detailed comparison is demonstrated in Table. 23. Data of previous methods arefrom (Xie et al., 2024).",
  "Shots Generation Prompt of Multi-set Problem": "You are a powerful text-to-SQL reasoner. Currently, I am seeking to transform intricate text queriesinto analytical statements that simplify the creation of SQL statements, leading to the generation of thefinal SQL query. Our current focus lies in the category of multi-set operations. Please learn from theprovided examples, design a detailed plan for the text query, and present the resulting SQL query. Example 1:## Tables:Table aircraft, columns = [*,aid,name,distance]Table certificate, columns = [*,eid,aid]Table employee, columns = [*,eid,name,salary]Table flight, columns = [*,flno,origin,destination,distance,departure_date,arrival_date,price,aid]## Foreign_keys:[flight.aid = aircraft.aid,certificate.aid = aircraft.aid,certificate.eid = employee.eid]## Query:Show names for all employees who have certificates on both Boeing 737-800 and Airbus A340-300.Lets think step by step.<1> Question Decomposition: In this step, we contemplate how to decompose the query. The queryemphasizes intersection logic, so we can decompose the question into two subproblems: 1. what arethe names of employees who have certificates on Boeing 737-800; 2. what are the names of employeeswho have certificates on Airbus A340-300.<2> Schema Linking: In this step, we identify the tables and columns that should be used based on therequirements of the query and the foreign key relationships. To complete the first subproblem, we needto use tables employee and aircraft. since table employee and table aircraft do not have a directforeign key connection, we need to use tables [employee, certificate, aircraft]. To complete thesecond subproblem, we need to use tables [employee, certificate, aircraft] for the same reason.<3> Operation: Use where to filter using column name in table aircraft.<4> SQL Generation: Use the intersect operation to connect the queries of subproblems to form thefinal SQL statement.SQL query: SELECT T1.name FROM Employee AS T1 JOIN Certificate AS T2 ON T1.eid = T2.eidJOIN Aircraft AS T3 ON T3.aid = T2.aid WHERE T3.name = \"Boeing 737-800\" INTERSECTSELECT T1.name FROM Employee AS T1 JOIN Certificate AS T2 ON T1.eid = T2.eid JOIN AircraftAS T3 ON T3.aid = T2.aid WHERE T3.name = \"Airbus A340-300\" Example 2:## Tables:Table station, columns = [*,id,name,lat,long,dock_count,city,installation_date]Table status, columns = [*,station_id,bikes_available,docks_available,time]Table trip, columns = [*,id,duration,start_date,start_station_name,start_station_id,end_date,end_station_name,end_station_id,bike_id,subscription_type,zip_code]Table weather, columns = [*,date,max_temperature_f,mean_temperature_f,min_temperature_f, max_dew_point_f,mean_dew_point_f,min_dew_point_f,max_humidity,mean_humidity,min_humidity,max_sea_level_pressure_inches,mean_sea_level_pressure_inches,min_sea_level_pressure_inches,max_visibility_miles,mean_visibility_miles,min_visibility_miles,max_wind_Speed_mph,mean_wind_speed_mph,max_gust_speed_mph,precipitation_inches,cloud_cover,events,wind_dir_degrees,zip_code] ## Foreign_keys:[status.station_id = station.id]## Query:What are the names of stations that have average bike availability above 10 and are not located in SanJose city?Lets think step by step.<1> Question Decomposition: In this step, we contemplate how to decompose the query. The queryemphasizes difference set logic, so we can decompose the question into two subproblems: 1. what arethe names of stations that have average bike availability above 10; 2. what are the names of stationsthat are located in San Jose city.<2> Schema Linking: In this step, we identify the tables and columns that should be used based on therequirements of the query and the foreign key relationships. To complete the first subproblem, we needto use tables [station, status]. To complete the second subproblem, we need to use table [station].<3> Operation: Due to the need for calculating the average bike availability for different stations, weneed to perform a GROUP BY operation on the column station_id, filter by performing HAVINGAVG() on the column bikes_available.<4> SQL Generation: Use the except operation to connect the queries of subproblems to form thefinal SQL statement.SQL query: SELECT T1.name FROM station AS T1 JOIN status AS T2 ON T1.id = T2.station_idGROUP BY T2.station_id HAVING avg(bikes_available) > 10 EXCEPT SELECT name FROM stationWHERE city = \"San Jose\" Example 3:## Tables:Table aircraft, columns = [*,aid,name,distance]Table certificate, columns = [*,eid,aid]Table employee, columns = [*,eid,name,salary]Table flight, columns = [*,flno,origin,destination,distance,departure_date,arrival_date,price,aid]## Foreign_keys:[flight.aid = aircraft.aid,certificate.aid = aircraft.aid,certificate.eid = employee.eid]## Query:Show ids for all employees who dont have a certificate.Lets think step by step.<1> Question Decomposition: In this step, we contemplate how to decompose the query. The queryemphasizes difference set logic, so we can decompose the question into two subproblems: 1. what arethe ids of employees who have certificates; 2. what are the ids of all employees.<2> Schema Linking: In this step, we identify the tables and columns that should be used based on therequirements of the query and the foreign key relationships. To complete the first subproblem, we needto use tables [employee, certificate]. To complete the second subproblem, we only need to use thetable employee.<3> Operation: Use where to filter out the employees who have certificates.<4> SQL Generation: Use the except operation to connect the queries of subproblems to form thefinal SQL statement.SQL query: SELECT eid FROM employee EXCEPT SELECT eid FROM certificate",
  "Example 4:## Tables:Table Campuses, columns = [*, Id, Campus, Location, County, Year]": "Table csu_fees, columns = [*,Campus,Year,CampusFee]Table degrees, columns = [*,Year,Campus,Degrees]Table discipline_enrollments, columns = [*, Campus,Discipline,Year, Undergraduate,Graduate]Table enrollments, columns = [*,Campus,Year,TotalEnrollment_AY,FTE_AY]Table faculty, columns = [*,Campus,Year,Faculty]## Foreign_keys:[csu_fees.Campus = Campuses.Id, degrees.Campus = Campuses.Id,discipline_enrollments.Campus =Campuses.Id, enrollments.Campus = Campuses.Id, faculty.Campus = Campuses.Id]## Query:Find the name of the campuses that is in Northridge, Los Angeles or in San Francisco, San Francisco.Lets think step by step.<1> Question Decomposition: In this step, we contemplate how to decompose the query. The queryemphasizes union logic, so we can decompose the question into two subproblems: 1. what are thenames of the campuses that are in Northridge, Los Angeles; 2. what are the names of the campuses thatare in San Francisco, San Francisco.<2> Schema Linking: In this step, we identify the tables and columns that should be used based on therequirements of the query and the foreign key relationships. To complete both subproblems, we need touse table Campuses.<3> Operation: Use where to filter using column Location in table Campuses.<4> SQL Generation: Use the union operation to connect the queries of subproblems to form thefinal SQL statement.SQL query: SELECT Campus FROM Campuses WHERE Location = \"Northridge, Los Angeles\"UNION SELECT Campus FROM Campuses WHERE Location = \"San Francisco, San Francisco\"",
  "Shots Generation Prompt of Combination Problem": "You are a powerful text-to-SQL reasoner. Currently, I am seeking to transform intricate text queriesinto analytical statements that simplify the creation of SQL statements, leading to the generation of thefinal SQL query. Our current focus lies in the category of combination problems. Please learn from theprovided examples, design a detailed plan for the text query, and present the resulting SQL query. Example 1:## Tables:Table badges, columns = [*,Id,UserId,Name,Date]Table comments, columns = [*,Id,PostId,Score,Text,CreationDate,UserId,UserDisplayName]Table postHistory, columns = [*,Id,PostHistoryTypeId,PostId,RevisionGUID,CreationDate,UserId,Text,Comment,UserDisplayName]Table postLinks, columns = [*,Id,CreationDate,PostId,RelatedPostId,LinkTypeId]Table posts, columns = [*,Id,PostTypeId,AcceptedAnswerId,CreaionDate,Score,ViewCount,Body,OwnerUserId,LasActivityDate,Title,Tags,AnswerCount,CommentCount,FavoriteCount,LastEditorUserId, LastEditDate,CommunityOwnedDate,ParentId,ClosedDate,OwnerDisplayName,LastEditorDisplayName]Tabletags,columns=[*,Id,TagName,Count,ExcerptPostId,WikiPostId]Table users, columns = [*,Id,Reputation,CreationDate,DisplayName,LastAccessDate,WebsiteUrl,Location, AboutMe,Views,UpVotes,DownVotes,AccountId,Age,ProfileImageUrl]Table votes, columns = [*,Id,PostId,VoteTypeId,CreationDate,UserId,BountyAmount]## Foreign_keys:[badges.UserId = users.Id,comments.UserId = users.Id,comments.PostId = posts.Id,postHistory.UserId= users.Id,postHistory.PostId = posts.Id,postLinks.RelatedPostId = posts.Id,postLinks.PostId= posts.Id,posts.ParentId = posts.Id,posts.OwnerUserId = users.Id,posts.LastEditorUserId =users.Id,tags.ExcerptPostId = posts.Id,votes.UserId = users.Id,votes.PostId = posts.Id]## Query:Which is the most valuable post in 2010? Please give its id and the owners display name.Lets think step by step.Firstly, the query requires the most valuable post, and the value is related to FavoriteCount column oftable posts, so we should apply order by to it.Secondly, we need to retrieve the ids and owners display name of posts selected from first step.Finally, based on the above analysis and requirements in user query, we only need to use tables usersand posts.SQL query: SELECT T2.OwnerUserId, T1.DisplayName FROM users AS T1 INNER JOIN posts AST2 ON T1.Id = T2.OwnerUserId WHERE STRFTIME(%Y, T1.CreationDate) = 2010 ORDER BYT2.FavoriteCount DESC LIMIT 1 Example 2:## Tables:Table customers, columns = [*,CustomerID,Segment,Currency]Table gasstations, columns = [*,GasStationID,ChainID,Country,Segment]Table products, columns = [*,ProductID,Description]Table transactions_1k, columns = [*,TransactionID,Date,Time,CustomerID,CardID,GasStationID,ProductID, Amount,Price]Table yearmonth, columns = [*,CustomerID,Date,Consumption]## Foreign_keys:[yearmonth.CustomerID = customers.CustomerID]## Query:Which year recorded the most consumption of gas paid in CZK?Lets think step by step. Firstly, the query requires the most consumption of gas paid in CZK, and the consumption is related tothe Consumption column of table yearmonth. Moreover, we need to consider the currency, which isin the table customers. So, we should join these two tables based on the CustomerID.Secondly, we need to filter the records where the currency is CZK. We can do this using a WHEREclause to filter records from the customers table.Thirdly, we need to group the results by year, which can be extracted from the Date column of theyearmonth table. We can use the SUBSTRING function to get the year from the Date and then useGROUP BY to group the records by year.Finally, we need to order the results by the sum of consumption in descending order and select the toprecord to get the year with the most consumption of gas paid in CZK.SQL query: SELECT SUBSTRING(T2.Date, 1, 4) as Year FROM customers AS T1 INNER JOINyearmonth AS T2 ON T1.CustomerID = T2.CustomerID WHERE T1.Currency = CZK GROUP BYYear ORDER BY SUM(T2.Consumption) DESC LIMIT 1 Example 3:## Tables:Table circuits, columns = [*,circuitId,circuitRef,name,location,country,lat,lng,alt,url]Table constructorResults, columns = [*,constructorResultsId,raceId,constructorId,points,status]Table constructorStandings, columns = [*,constructorStandingsId,raceId,constructorId,points,position,positionText,wins]Table constructors, columns = [*,constructorId,constructorRef,name,nationality,url]Table driverStandings, columns = [*,driverStandingsId,raceId,driverId,points,position,positionText,wins]Table drivers, columns = [*,driverId,driverRef,number,code,forename,surname,dob,nationality,url]Table lapTimes, columns = [*,raceId,driverId,lap,position,time,milliseconds]Table pitStops, columns = [*,raceId,driverId,stop,lap,time,duration,milliseconds]Table qualifying, columns = [*,qualifyId,raceId,driverId,constructorId,number,position,q1,q2,q3]Table races, columns = [*,raceId,year,round,circuitId,name,date,time,url]Table results, columns = [*,resultId,raceId,driverId,constructorId,number,grid,position,positionText,positionOrder,points,laps,time,milliseconds,fastestLap,rank,fastestLapTime,fastestLapSpeed,statusId]Table seasons, columns = [*,year,url]Table status, columns = [*,statusId,status]## Foreign_keys:[races.circuitId = circuits.circuitId,races.year = seasons.year,constructorResults.constructorId = con-structors.constructorId,constructorResults.raceId = races.raceId,constructorStandings.constructorId =constructors.constructorId,constructorStandings.raceId=races.raceId,driverStandings.driverId=drivers.driverId,driverStandings.raceId=races.raceId,lapTimes.driverId=drivers.driverId,lapTimes.raceId = races.raceId,pitStops.driverId = drivers.driverId,pitStops.raceId=races.raceId,qualifying.constructorId=constructors.constructorId,qualifying.driverId=drivers.driverId,qualifying.raceId = races.raceId,results.statusId = status.statusId,results.constructorId =constructors.constructorId,results.driverId = drivers.driverId,results.raceId = races.raceId]## Query:List out the top 10 Spanish drivers who were born before 1982 and have the latest lap time.Lets think step by step.Firstly, the query requires the top 10 Spanish drivers born before 1982. We need to consider the driversnationality and date of birth, which are in the table drivers. We can use a WHERE clause to filterrecords based on these conditions.Secondly, we need to find the latest lap time for these filtered drivers. The lap time information is inthe table pitStops. So, we should join the drivers and pitStops tables based on the driverId.Thirdly, we need to order the results by the lap time in descending order to get the latest lap time. Wecan use the ORDER BY clause for this purpose.Finally, we need to select the top 10 records to get the required result.",
  "SQL query: SELECT T2. Hometown, COUNT(*) FROM gymnast AS T1 JOIN people AS T2 ONT1.Gymnast_ID = T2.People_ID GROUP BY T2.Hometown": "Example 2:## Tables:Table county, columns = [*,County_Id,County_name,Population,Zip_code]Table selection, columns = [*,Election_ID,Counties_Represented,District,Delegate,Party,First_Elected,Committee]Table party, columns = [*,Party_ID,Year,Party,Governor,Lieutenant_Governor,Comptroller,Attorney_General,US_Senate]## Foreign_keys:[election.District = county.County_Id,election.Party = party.Party_ID]## Query:Show the name of each party and the corresponding number of delegates from that party.Lets think step by step.<1> Operation: The query requires the name of each party and the corresponding number of delegatesfrom that party, so we should apply the count operation to table election for the Delegate column,and it does not need sorting. Since the unit to which the delegates being counted in the query belong isthe party and only table party has the column Party, so we should apply the group by operation tocolumn Party in table party.<2> Schema Linking: In this step, we identify the tables and columns that should be used based onthe first step and the foreign key relationships. Due to the direct foreign key connection between tableelection and party. We need to use tables [election, party].<3> SQL Generation: The query requires the name of each party and the corresponding number ofdelegates from that party, so we should select the Party column in the party table and count theDelegate column in the election table.SQL query: SELECT T1.Party, COUNT(*) FROM party AS T1 JOIN election AS T2 ON T1.Party_ID= T2.Party GROUP BY T1.Party Example 3:## Tables:Table city, columns = [*,City_ID,Official_Name,Status,Area_km_2,Population,Census_Ranking]Table competition_record, columns = [*,Competition_ID,Farm_ID,Rank]Table farm, columns = [*,Farm_ID,Year,Total_Horses,Working_Horses,Total_Cattle,Oxen,Bulls,Cows,Pigs,Sheep_and_Goats]Table farm_competition, columns = [*,Competition_ID,Year,Theme,Host_city_ID,Hosts]## Foreign_keys:[farm_competition.Host_city_ID = city.City_ID,competition_record.Farm_ID= farm.Farm_ID,competition_record.Competition_ID = farm_competition.Competition_ID]## Query:Show the status of the city that has hosted the greatest number of competitions.Lets think step by step.<1> Operation: The query requires the name of each party and the corresponding number of delegatesfrom that party, so we should apply the count operation to table election for the Delegate column,and it does not need sorting. Since the unit to which the delegates being counted in the query belong isthe party and only table party has the column Party, so we should apply the group by operation tocolumn Party in table party.<2> Schema Linking: In this step, we identify the tables and columns that should be used based onthe first step and the foreign key relationships. Due to the direct foreign key connection between tableelection and party. We need to use tables [election, party]. <3> SQL Generation: The query requires the name of each party and the corresponding number ofdelegates from that party, so we should select the Party column in the party table and count theDelegate column in the election table.SQL query: SELECT T1.Party , COUNT(*) FROM party AS T1 JOIN election AS T2 ON T1.Party_ID= T2.Party GROUP BY T1.Party Example 4:## Tables:Table city, columns = [*,City_ID,Official_Name,Status,Area_km_2,Population,Census_Ranking]Table competition_record, columns = [*,Competition_ID,Farm_ID,Rank]Table farm, columns = [*,Farm_ID,Year,Total_Horses,Working_Horses,Total_Cattle,Oxen,Bulls,Cows,Pigs,Sheep_and_Goats]Table farm_competition, columns = [*,Competition_ID,Year,Theme,Host_city_ID,Hosts]## Foreign_keys:[farm_competition.Host_city_ID = city.City_ID,competition_record.Farm_ID= farm.Farm_ID,competition_record.Competition_ID = farm_competition.Competition_ID]## Query:Please show the different statuses, ordered by the number of cities that have each.Lets think step by step.<1> Operation: The query requires the different statuses ordered by the number of cities that have eachstatus, so we should apply the count operation to the city table for the Status column, and sort it inascending order. Since the unit to which the statuses being counted in the query belong is the city, weshould apply the group by operation to the Status column in the city table.<2> Schema Linking: In this step, we identify the tables and columns that should be used based on thefirst step and the foreign key relationships. In this question, we only need to use table [city].<3> SQL Generation: The query requires the different statuses ordered by the number of cities thathave each status, so we should select the Status column in the city table. The query does not requirethe count of cities so it is only used for filtering and not selected.SQL query: SELECT Status FROM city GROUP BY Status ORDER BY COUNT(*) ASC",
  "Shots Generation Prompt of Filtering Problem": "You are a powerful text-to-SQL reasoner. Currently, I am seeking to transform intricate text queriesinto analytical statements that simplify the creation of SQL statements, leading to the generation of thefinal SQL query. Our current focus lies in the category of filtering problems. Please learn from theprovided examples, design a detailed plan for the text query, and present the resulting SQL query. Example 1:## Tables:Table frpm, columns = [*,CDSCode,Academic Year,County Code,District Code,School Code,CountyName,District Name,School Name,District Type,School Type,Educational Option Type,NSLP Provi-sion Status,Charter School (Y/N),Charter School Number,Charter Funding Type,IRC,Low Grade,HighGrade,Enrollment (K-12),Free Meal Count (K-12),Percent (%) Eligible Free (K-12),FRPM Count (K-12),Percent (%) Eligible FRPM (K-12),Enrollment (Ages 5-17),Free Meal Count (Ages 5-17),Percent(%) Eligible Free (Ages 5-17),FRPM Count (Ages 5-17),Percent (%) Eligible FRPM (Ages 5-17),2013-14 CALPADS Fall 1 Certification Status]Table satscores, columns = [*,cds,rtype,sname,dname,cname,enroll12,NumTstTakr,AvgScrRead,AvgScrMath,AvgScrWrite,NumGE1500]Table schools, columns = [*,CDSCode,NCESDist,NCESSchool,StatusType,County,District,School,Street, StreetAbr,City,Zip,State,MailStreet,MailStrAbr,MailCity,MailZip,MailState,Phone,Ext,Website,OpenDate, ClosedDate,Charter,CharterNum,FundingType,DOC,DOCType,SOC,SOCType,EdOpsCode,EdOpsName, EILCode,EILName,GSoffered,GSserved,Virtual,Magnet,Latitude,Longitude,AdmFName1,AdmLName1, AdmEmail1,AdmFName2,AdmLName2,AdmEmail2,AdmFName3,AdmLName3,AdmEmail3,LastUpdate]## Foreign_keys:[frpm.CDSCode = schools.CDSCode,satscores.cds = schools.CDSCode]## Query:Which schools served a grade span of Kindergarten to 9th grade in the county of Los Angeles, andwhat is its Percent (%) Eligible FRPM (Ages 5-17)?Lets think step by step.<1> Decomposition: The query requires finding schools in Los Angeles County that serve a grade spanof Kindergarten to 9th grade and calculating their Percent (%) Eligible FRPM (Ages 5-17).<2> Schema Linking: In this step, we identify the tables and columns that should be used based on thefirst step and the foreign key relationships. We need to select School from table schools and filterby County and GSserved columns. Then, we need to calculate the Percent (%) Eligible FRPM (Ages5-17) using the FRPM Count (Ages 5-17) and Enrollment (Ages 5-17) columns from the frpm table.<3> SQL Generation: We can use an INNER JOIN to combine the frpm and schools tables on theCDSCode column. Then, we can filter the rows where the County is Los Angeles and GSserved isK-9. Finally, we can calculate the Percent (%) Eligible FRPM (Ages 5-17) by dividing the FRPMCount (Ages 5-17) by the Enrollment (Ages 5-17) and multiplying by 100.SQL query: SELECT T2.School, T1.FRPM Count (Ages 5-17) * 100 / T1.Enrollment (Ages 5-17) FROM frpm AS T1 INNER JOIN schools AS T2 ON T1.CDSCode = T2.CDSCode WHERET2.County = Los Angeles AND T2.GSserved = K-9 Example 2:## Tables:Table account, columns = [*,account_id,district_id,frequency,date]Table card, columns = [*,card_id,disp_id,type,issued]Table client, columns = [*,client_id,gender,birth_date,district_id]Table disp, columns = [*,disp_id,client_id,account_id,type]Table district, columns = [*,district_id,A2,A3,A4,A5,A6,A7,A8,A9,A10,A11,A12,A13,A14,A15,A16]Table loan, columns = [*,loan_id,account_id,date,amount,duration,payments,status]Table order, columns = [*,order_id,account_id,bank_to,account_to,amount,k_symbol] Table trans, columns = [*,trans_id,account_id,date,type,operation,amount,balance,k_symbol,bank,account]## Foreign_keys:[account.district_id=district.district_id,card.disp_id=disp.disp_id,client.district_id=dis-trict.district_id,disp.client_id = client.client_id,disp.account_id = account.account_id,loan.account_id= account.account_id,order.account_id = account.account_id,trans.account_id = account.account_id]## Query:For loan amount less than USD100,000, what is the percentage of accounts that is still running with noissue.Lets think step by step.<1> Decomposition: The query requires finding the percentage of accounts with loans less than USD100,000 that are still running with no issue.<2> Schema Linking: In this step, we identify the tables and columns that should be used based on thefirst step and the foreign key relationships. We need to filter the loan table by the amount columnand then calculate the percentage of accounts with a status of C, which means running with noissues.<3> SQL Generation: We can use the SELECT statement to filter the loan table by the amountcolumn, where the amount is less than 100,000. Then, we can calculate the percentage of accounts witha status of C by dividing the number of accounts with status C by the total number of accounts andmultiplying by 100.SQL query: SELECT CAST(SUM(status = C) AS REAL) * 100 / COUNT(amount) FROM loanWHERE amount < 100000 Example 3:## Tables:Table atom, columns = [*,atom_id,molecule_id,element]Table bond, columns = [*,bond_id,molecule_id,bond_type]Table connected, columns = [*,atom_id,atom_id2,bond_id]Table molecule, columns = [*,molecule_id,label]## Foreign_keys:[atom.molecule_id=molecule.molecule_id,bond.molecule_id=molecule.molecule_id,connected.bond_id=bond.bond_id,connected.atom_id2=atom.atom_id,connected.atom_id = atom.atom_id]## Query:What is the percentage of carcinogenic molecules in triple-type bonds?Lets think step by step.<1> Decomposition: The query requires finding the percentage of carcinogenic molecules (indicatedby +) in triple-type bonds (indicated by #).<2> Schema Linking: In this step, we identify the tables and columns that should be used based on thefirst step and the foreign key relationships. We need to select the label column from the moleculetable and the bond_type column from the bond table. We also need to use the molecule_id columnfrom the atom, molecule, and bond tables to join these tables together.<3> SQL Generation: We can use an INNER JOIN to combine the atom, molecule, and bondtables on the molecule_id column. Then, we can filter the rows where the bond_type is #. Finally, wecan calculate the percentage of carcinogenic molecules by dividing the number of distinct carcinogenicmolecules by the total number of distinct molecules and multiplying by 100.SQL query: SELECT CAST(COUNT(DISTINCT CASE WHEN T2.label = + THEN T2.molecule_idELSE NULL END) AS REAL) * 100 / COUNT(DISTINCT T2.molecule_id) FROM atom AS T1INNER JOIN molecule AS T2 ON T1.molecule_id = T2.molecule_id INNER JOIN bond AS T3 ONT2.molecule_id = T3.molecule_id WHERE T3.bond_type = #",
  "Shots Generation Prompt of Other Simple Problem": "You are a powerful text-to-SQL reasoner. Currently, I am seeking to transform intricate text queriesinto analytical statements that simplify the creation of SQL statements, leading to the generation of thefinal SQL query. Example 1:## Tables:Table department, columns = [*,Department_ID,Name,Creation,Ranking,Budget_in_Billions,Num_Employees]Table head, columns = [*,head_ID,name,born_state,age]Table management, columns = [*,department_ID,head_ID,temporary_acting]## Foreign_keys:[management.head_ID = head.head_ID,management.department_ID = department.Department_ID]## Query:List the name, born state and age of the heads of departments ordered by age.SQL query: SELECT name , born_state , age FROM head ORDER BY age Example 2:## Tables:Table department, columns = [*,Department_ID,Name,Creation,Ranking,Budget_in_Billions,Num_Employees]Table head, columns = [*,head_ID,name,born_state,age]Table management, columns = [*,department_ID,head_ID,temporary_acting]## Foreign_keys:[management.head_ID = head.head_ID,management.department_ID = department.Department_ID]## Query:List the creation year, name and budget of each department.SQL query: SELECT creation, name, budget_in_billions FROM department Example 3:## Tables:Table race, columns = [*,Race_ID,Name,Class,Date,Track_ID]Table track, columns = [*,Track_ID,Name,Location,Seating,Year_Opened]## Foreign_keys:[race.Track_ID = track.Track_ID]## Query:Show year where a track with a seating at least 5000 opened and a track with seating no more than4000 opened.SQL query: SELECT year_opened FROM track WHERE seating BETWEEN 4000 AND 5000 Example 4:## Tables:Table Available_Policies, columns = [*,Policy_ID,policy_type_code,Customer_Phone]Table Claims, columns = [*,Claim_ID,FNOL_ID,Effective_Date]Table Customers, columns = [*,Customer_ID,Customer_name]Table Customers_Policies, columns = [*,Customer_ID,Policy_ID,Date_Opened,Date_Closed]Table First_Notification_of_Loss, columns = [*,FNOL_ID,Customer_ID,Policy_ID,Service_ID]Table Services, columns = [*,Service_ID,Service_name]Table Settlements, columns = [*,Settlement_ID,Claim_ID,Effective_Date,Settlement_Amount]## Foreign_keys:[Customers_Policies.Policy_ID = Available_Policies.Policy_ID,Customers_Policies.Customer_ID =Customers.Customer_ID,First_Notification_of_Loss.Customer_ID =Customers_Policies.Customer_ID,First_Notification_of_Loss.Policy_ID = Customers_Policies.Policy_ID,First_Notification_of_Loss.Service_ID = Services.Service_ID,Claims.FNOL_ID = First_Notification_of_Loss.FNOL_ID, Settlements.Claim_ID = Claims.Claim_ID]## Query:Which policy type has the most records in the database?SQL query: SELECT policy_type_code FROM available_policies GROUP BY policy_type_codeORDER BY count(*) DESC LIMIT 1",
  "Few-shot Prompt used in QGP sub-task": "You are a Text-to-SQL expert. Your task is to classify text-based queries. The types are defined asfollows: 1. Set operations, which require complex logical connections between multiple conditionsand often involve the use of intersect, except, union, and other operations; 2. Combination operations,which require grouping of specific objects and finding the maximum value or sorting, often achievedusing GROUP BY; 3. Filtering problems, which select targets based on specific judgment conditions,generally completed using where statements; 4. Other simple problems, including simple retrieval andsorting.Your task is to judge the query step by step to see if it belongs to a certain category. For example, ifyou think the query has the characteristics of the first type, then classify it as the first type withoutconsidering the subsequent types. If you think the query does not have the characteristics of the firsttype but has the second type, then classify it as the second type without considering the subsequenttypes. ## Example 1:What are the ids of the students who either registered or attended a course?Reason: We first consider Set operations. The query can be considered union logic which finds studentsthat registered or attended a course, so it is classified as Set operations.Type: Multi-set operations ## Example 2:List the states where both the Secretary of Treasury department and the Secretary of HomelandSecurity were born.Reason: We first consider Set operations. The query can be considered intersection logic which requiresthe intersection of states that Treasury and Homeland Security were born, so it is classified as Setoperations.Type: Multi-set operations ## Example 3:Find all the zip codes in which the max dew point has never reached 70.Reason: We first consider Set operations. The query can be seen as a difference logic, which removeszip codes that have reached a dew point of 70 from all zip codes, so it is classified as Set operations.Type: Multi-set operations ## Example 4:Find the name of customers who do not have an saving account.Reason: We first consider Set operations. The query can be consiederd difference logic, which removescustomers having an saving account from all customers, so it is classified as Set operations.Type: Multi-set operations",
  "## Example 5:Which origin has the most number of flights?": "Reason: We first consider Set operations. This query does not involve logical connection relationships.We secondly consider Combination operations. This query requires statistical counting of flights withindifferent origins, so it is classified as Combination operations.Type: Combination operations ## Example 6:Which course is enrolled in by most students? Give me the course name.Reason: We first consider Set operations. This query does not involve logical connection relationships.We secondly consider Combination operations. This query requires statistical counting of studentswithin different courses, so it is classified as Combination operations.Type: Combination operations ## Example 7:Find the name of the train whose route runs through the greatest number of stations.Reason: We first consider Set operations. This query does not involve logical connection relationships.We secondly consider Combination operations. This query requires statistical counting of runningstations of different trains, so it is classified as Combination operations.Type: Combination operations ## Example 8:What are the names of musicals with nominee \"Bob Fosse\"?Reason: We first consider Set operations. This query does not involve logical connection relationships.We secondly consider Combination operations. This query does not involve group count. We thirdlyconsider Filtering problems. This query needs to filter musicals based on the name of the nomenee, soit is classified as Filtering problems.Type: Filtering problems ## Example 9:How many distinct kinds of camera lenses are used to take photos of mountains in the countryEthiopia?Reason: We first consider Set operations. This query does not involve logical connection relationships.We secondly consider Combination operations. This query does not involve group count. We thirdlyconsider Filtering problems. This query needs to filter camera lenses based on the utilization onmountains in country Ethiopia, so it is classified as Filtering problems.Type: Filtering problems ## Example 10:How many products are there?Reason: We first consider Set operations. This query does not involve logical connection relationships.We secondly consider Combination operations. This query does not involve group count. We thirdlyconsider Filtering problems. This query does not involve filter criteria. So it is classified as Othersimple problems.Type: Other simple problems"
}