{
  "Abstract": "Despite the advances in large language mod-els (LLMs), how they use their knowledgefor reasoning is not yet well understood. Inthis study, we propose a method that decon-structs complex real-world questions into agraph, representing each question as a nodewith predecessors of background knowledgeneeded to solve the question.We developthe DEPTHQA dataset, deconstructing ques-tions into three depths: (i) recalling concep-tual knowledge, (ii) applying procedural knowl-edge, and (iii) analyzing strategic knowledge.Based on a hierarchical graph, we quantify for-ward discrepancy, discrepancies in LLMs per-formance on simpler sub-problems versus com-plex questions. We also measure backward dis-crepancy, where LLMs answer complex ques-tions but struggle with simpler ones. Our analy-sis shows that smaller models exhibit more dis-crepancies than larger models. Distinct patternsof discrepancies are observed across model ca-pacity and possibility of training data memo-rization. Additionally, guiding models fromsimpler to complex questions through multi-turn interactions improves performance acrossmodel sizes, highlighting the importance ofstructured intermediate steps in knowledge rea-soning. This work enhances our understandingof LLM reasoning and suggests ways to im-prove their problem-solving abilities.",
  "Introduction": "With the rapid advancement of Large LanguageModels (LLMs), research interest has increasinglycentered on their reasoning capabilities, particu-larly in solving complex questions. While manystudies have assessed the general reasoning capabil-ities of LLMs (Wei et al., 2022a; Qin et al., 2023;Srivastava et al., 2023), the specific aspect of howthese models recall and then utilize factual knowl-",
  "*Equal contribution.Equal advising": "[Target Q] Why does ReLU training take less time than sigmoid or tanh training? [Q2] How is the speed of neural network training measured? [Q1] What does the gradient of a function represent? [Q14] What is the vanishing gradient problem? [Q4] What is backpropagation in the context of neural networks? [Q3] What role does an activation function play in neural network training? : Strategic Knowledge (i.e., Why can it be used?) : Procedural Knowledge (i.e., How can it be used?) [Q1] How do the gradients of activation functions affect the speed of neural network training? : Conceptual Knowledge (i.e., What is it?) : Example of reasoning across depths, showinga sequence of questions from D1 (conceptual knowl-edge) to D3 (strategic knowledge). Questions that askdeeper levels of knowledge require reasoning from mul-tiple areas of shallower knowledge, which are repre-sented as sub-questions. edge during reasoning has not been thoroughly ex-plored. Some research (Dziri et al., 2023; Presset al., 2023; Wang et al., 2024) concentrate onstraightforward reasoning tasks such as combin-ing and comparing simple biographical facts toinvestigate the implicit reasoning skills of LLMs.However, real-world questions often demand moreintricate reasoning processes that cannot be eas-ily broken down into simple factual units. For in-stance, as presented in , to answer Whydoes ReLU training take less time than sigmoid ortanh training?, one must not only recall what anactivation function is but also compare the charac-teristics of activation functions and understand thecausal relationship between gradients and trainingspeed. This type of reasoning requires drawingconclusions beyond simply aggregating facts. To analyze the reasoning ability of LLMs in solv-ing real-world questions, we propose a deconstruc-tion of complex questions into a graph structure. Inthis structure, each node is represented by a ques-tion that signifies a specific level of knowledge. We ... Q1 Q",
  "Target Node": ": Hierarchical structure of a deconstructed D3,illustrating forward and backward discrepancies. Tran-sition to deeper nodes requires acquiring and reasoningwith knowledge from the connected shallower nodes. adopt Webbs Depth of Knowledge (Webb, 1997,1999, 2002), which assesses both the content andthe depth of understanding required. Webbs Depthof Knowledge categorizes questions into three lev-els: mere recall of information (D1), applicationof knowledge (D2), and strategic thinking (D3).The transition from shallower to deeper nodes in-volves applying the knowledge gained from shal-lower nodes and performing reasoning to tackleharder problems. This approach emphasizes thegradual accumulation and integration of knowledgeto address real-world problems effectively. We introduce the resulting DEPTHQA, a collec-tion of deconstructed questions and answers de-rived from human-written, scientific D3 questionsin the TutorEval dataset (Chevalier et al., 2024).The target complex questions are in D3, and weexamine the utilization of multiple layers of knowl-edge and reasoning in the sequence of D1, D2,and D3. illustrates how the deconstruc-tion process results in a hierarchical graph connect-ing D1 to D3 questions. Based on the hierarchi-cal structure, we first measure forward reasoninggaps, denoted as forward discrepancy, which aredifferences in LLM performance on simpler sub-problems compared to more complex questionsrequiring advanced reasoning. Additionally, we in-troduce backward discrepancy, which quantifies in-consistencies where LLMs can successfully answercomplex inquiries but struggle with simpler ones.This dual assessment provides a comprehensiveevaluation of the models reasoning capabilitiesacross different levels of complexity.Using DEPTHQA, we investigate the knowl-edge reasoning ability of various instruction-tunedLLMs in the LLaMA 2 (Touvron et al., 2023),LLaMA 3 (AI@Meta, 2024), Mistral (Jiang et al., 2023), and Mixtral (Jiang et al., 2024) family, vary-ing in size from 7B to 70B. We compare the rela-tionship between model capacities and depthwisediscrepancies, showing that smaller models exhibitlarger discrepancies in both directions. We furtheranalyze how reliance on memorization of trainingdata affects discrepancy, revealing that forward andbackward discrepancies in large models originatefrom distinct types of failures. Finally, to examinethe importance of structured intermediate steps inreasoning, we gradually guide models from sim-pler to more advanced questions through multi-turninteractions, consistently improving performanceacross various model sizes.The contributions of our work are threefold:",
  "We propose to connect complex questions withsimpler sub-questions by deconstructing ques-tions based on depth of knowledge": "We design the DEPTHQA dataset to evaluateLLMs capability to form complex knowledgethrough reasoning. We measure forward andbackward reasoning discrepancies across differ-ent levels of question complexity.1 We investigate the reasoning abilities of LLMswith various capacities, analyzing the impactof model size and training data memorizationon discrepancies. We demonstrate the benefitsof structured, multi-turn interactions to performcomplex reasoning.",
  "Related Work": "Recent advancements have highlighted the impres-sive reasoning abilities of transformer languagemodels across a wide range of tasks (Wei et al.,2022a; Zhao et al., 2023). Despite the success,numerous studies have found that these models of-ten struggle with various types of reasoning, suchas commonsense and logical reasoning (Qin et al.,2023; Srivastava et al., 2023). Even advanced mod-els like GPT-4 (Achiam et al., 2023) have beennoted to struggle with implicit reasoning over theirinternal knowledge, especially when it comes toeffectively combining multiple steps to solve com-positionally complex problems (Talmor et al., 2020;Rogers et al., 2020; Allen-Zhu and Li, 2023; Yanget al., 2024; Wang et al., 2024).To address these challenges, several studies havefocused on better Chain-of-Thought-style prompt-",
  "github.com/kaistAI/knowledge-reasoning": "ing or fine-tuning LLMs to verbalize the intermedi-ate steps of knowledge and reasoning during infer-ence (Nye et al., 2021; Wei et al., 2022b; Kojimaet al., 2022; Wang et al., 2022; Sun et al., 2023;Wang et al., 2023b; Liu et al., 2023). This approachhas significantly improved performance, especiallyin larger models with strong generalization capa-bilities. Theoretical and empirical studies investi-gate the advantages of verbalizations, highlightingtheir role in enhancing the reasoning capabilitiesof language models (Feng et al., 2023; Wang et al.,2023a; Li et al., 2024). The analysis of step-by-stepreasoning abilities has matured further based on on-tological (Saparov and He, 2023) and mechanisticperspectives (Hou et al., 2023a; Dutta et al., 2024).In our proposed dataset, the most complex ques-tions often necessitate implicit intermediate stepsto reach a conclusion, which can be benefited fromexplicit verbalized reasoning. However, unlike pre-vious works, our setup does not induce detailedstep-by-step explanation contained in an answerto a complex question. Instead, we represent inter-mediate steps for a complex question in the formof sub-questions and gather answers to every sub-question, testing a models understanding of inter-mediate knowledge individually. Our approach issimilar to strategic question answering with inter-mediate answers (Geva et al., 2021; Press et al.,2023), but we further ensure a hierarchy of decom-positions based on knowledge complexity. Thisallows examining discrepancies between questionsof varying complexities, providing a distinct assess-ment of multi-step reasoning abilities.Another line of work focuses on understandingtransformers knowledge and reasoning throughcontrolled experiments (Chan et al., 2022; Akyreket al., 2023; Dai et al., 2023; von Oswald et al.,2022; Prystawski et al., 2023; Feng and Steinhardt,2024). Numerous studies on implicit reasoning of-ten aim to identify latent reasoning pathways, butmost have focused on simple synthetic tasks or toymodels (Nanda et al., 2023; Conmy et al., 2023;Hou et al., 2023b), or evaluating through binaryaccuracy of short-form model predictions withoutconsidering intermediate steps (Yang et al., 2024;Wang et al., 2024). Our DEPTHQA, in contrast,challenges a model to answer complex real-worldquestions that require diverse reasoning types inlong-form text. DEPTHQA further requires diversetypes of reasoning across different depths, suchas inductive and procedural reasoning, in additionto the comparative and compositional reasoning",
  "Knowledge Depth in Nodes": "We represent each node as a question tied to aspecific layer of knowledge. As our approach toaddressing real-world problems emphasizes thegradual accumulation of knowledge similar toeducational goals, we adopt the Webbs Depthof Knowledge (DOK) (Webb, 1997, 1999, 2002)widely used in education settings to categorize thelevel of questions. The depth of knowledge lev-els Dk(k {1, 2, 3})2 in questions are defined asfollows:",
  "D3. Strategic knowledge: The question demandsanalysis, decision-making, or justification toaddress non-routine problems, emphasizingwhy the knowledge is applicable": "The levels can be viewed as ceilings that estab-lish the extent or depth of an assessees understand-ing (Hess, 2006), a concept recognized as a valu-able assessment tool in educational contexts (Hesset al., 2009). Accordingly, we associate simplerquestions with shallower depths and more complexquestions with deeper depths. 2We exclude the highest level in the original Webbs DOK,D4, as this level often includes interactive or creative activ-ities and is rare or even absent in most standardized assess-ment (Webb, 2002; Hess, 2006).",
  "Criteria for Reasoning in Edges": "To conceptualize how simpler knowledge con-tributes to the development of complex knowledge,we define edges in our framework as transitionsfrom a node at Dk to at least one direct succes-sor node at Dk+13. We perceive that advancingto deeper knowledge often requires synthesizingmultiple aspects of simpler knowledge. Thus, a Dknode should connect to multiple direct predecessorDk1 nodes. This configuration establishes hierar-chical dependencies among D1, D2, and D3 ques-tions, effectively modeling the progression neededto deepen understanding and engage with higher-order knowledge (See graph in ). Addition-ally, we establish three criteria to ensure that edgesaccurately represent the reasoning processes fromshallower questions. C1. Comprehensiveness: Questions at lower lev-els should aim to cover all foundational con-cepts necessary to answer a question at higherlevels. This ensures that no critical knowledgegaps exist as the complexity increases. C2. Implicitness:Questions at lower levelsshould avoid directly revealing answers orheavily hinting at solutions for higher-levelquestions. This encourages independent rea-soning relying on the synthesis of implicit con-nections between nodes rather than straight-forward clues. C3. Non-binary questioning: Questions shouldelicit detailed, exploratory responses insteadof simple yes/no answers. Given that LLMsmay have an inherent positivity bias whichleads them to prefer affirmative responses (Au-gustine et al., 2011; Dodds et al., 2015; Pa-padatos and Freedman, 2023), this helps inevaluating deep reasoning abilities beyond su-perficial or biased reasoning.",
  "questions while meeting our three criteria for rea-soning transition representation": "D3 question curationWe select real-worldquestions from the TutorEval (Chevalier et al.,2024) dataset, which contains human-craftedqueries based on college-level mathematical andscientific content from textbooks4 available onlibretexts.org. Note that while these textbooksmay be part of models pre-training data due to on-line availability, TutorEvals human-written ques-tions challenge models to generalize familiar con-cepts beyond direct training examples. We procureonly complex D3 questions from TutorEval, sort-ing them out using GPT-4 Turbo5 (Achiam et al.,2023) with guidance on depth of knowledge levels.From an initial set of 834 questions, we manu-ally refine our selection to 91 self-contained D3questions, ensuring clarity. We use GPT-4 Turboto generate reference answers for each TutorEvalquestion6, based on the original context and themodels self-annotated depth of knowledge. Thesereference answers are guided by the ground-truthkey points provided by the author of each question. Question deconstructionFor each Dk question,we use GPT-4 Turbo to generate up to four Dk1questions. The prompt includes definitions for allthree knowledge depths and decomposition exam-ples to guide the deconstruction process. We pro-vide Dk with its reference answer to ensure ex-tracted knowledge remains relevant for more chal-lenging questions, adhering to C1 (Comprehen-siveness). We decide the optimal number of de-compositions to four based on qualitative analy-sis, balancing comprehensiveness and implicitness:outlining every implicit reasoning step enhancescomprehensiveness but may reduce implicitness, 4Textbooks are designed with a scaffolding approach toknowledge development.5We use the gpt-4-0125-preview version for GPT-4Turbo throughout this work, including data construction, veri-fication, and experiments.6Chevalier et al. (2024) reports that GPT-4 excels in solv-ing TutorEval problems with 92% correctness.",
  "and vice versa. Our prompt instructions carefullyaddress this tradeoff to satisfy C2 (Implicitness)": "Deduplication and question augmentationWeidentified redundancies in knowledge and reason-ing processes, where similar content appearedacross different D1 nodes linked to the sameD2 node, or between unconnected D1 and D2nodes (example in ).To address this,we utilize a Sentence Transformers embeddingmodel7 (Reimers and Gurevych, 2019) to detectand remove near-duplicate questions based on co-sine similarity of their embeddings. We then em-ploy GPT-4 Turbo to generate new, targeted ques-tions and answers, filling any gaps in knowledgecoverage. This approach has reduced misclassifi-cation of D1 questions as D2 by 88%, markedlyenhancing C2 (Implicitness). It has also decreasedthe total number of near-duplicates by decreased by88%, further improving C1 (Comprehensiveness).We subsequently update our graph data structurewith these modifications. Question debiasingLastly, we undertake thetask of manually rewriting 53 questions that origi-nally invoke binary yes or no answers, ensur-ing C3 (Non-binary Questioning). For example,a question that begins with If I understand cor-rectly... is transformed into Clarify my under-standing that..., prompting the model to directlyengage in analytical thinking rather than relying onsimple affirmations or negations of the correctness. Verification of hierarchyWe conduct humanannotation to verify the three criteria that shapesthe reasoning hierarchy, reporting positive resultsin Appendix B. On 27.5% of DEPTHQA, an aver-age of 83.5% of relations are fully comprehensiveand 89.5% of sub-questions are fully implicit, with",
  "Diversity of Reasoning Processes": "Using a sample of 20 D3 questions along with theirinterconnected 80 D2 and 320 D1 questions, weexamine the types of reasoning needed to progressfrom basic to complex knowledge levels. We dis-cover that nearly all questions necessitate the identi-fication and extraction of several pieces of relevantinformation to synthesize comprehensive answers. displays examples of questions requiringadvanced reasoning skills, such as interpreting rela-tionships between concepts, applying specific con-ditions, and handling assumptions, demonstratingthat basic knowledge manipulation is insufficient.This diversity in reasoning types within our datasetrobustly challenges LLMs to demonstrate sophisti-cated cognitive abilities. Detailed statistics and ad-ditional examples of reasoning types are providedin Appendix D.",
  "Experiments": "In this section,we present experiments onthe depthwise reasoning ability of LLMs usingDEPTHQA. We first explain the evaluation metricsand models (.1). Experimental results thatfollow are overall depthwise and discrepancy evalu-ation results (.2), the impact of memoriza-tion in knowledge reasoning (.3), and theeffect of enforcing knowledge-enhanced reasoningvia multi-turn inputs or prompt inputs (.5).",
  "D1D2D3OverallD2 D3D1 D2OverallD2 D3D1 D2Overall": "LLaMA 2 7B Chat3.8283.3203.1653.6730.1300.1810.1760.2190.1100.134LLaMA 2 13B Chat4.2893.8723.6154.1550.1520.1580.1570.1260.0780.088LLaMA 2 70B Chat4.4954.1534.0224.3900.1260.1360.1340.1360.0630.079Mistral 7B Instruct v0.24.2803.8974.0004.1760.0920.1570.1470.1440.0700.088Mixtral 8x7B Instruct v0.14.5994.5324.4294.5740.0870.0790.0810.0630.0630.063LLaMA 3 8B Instruct4.4824.3514.2864.4400.0830.0960.0930.0880.0720.075LLaMA 3 70B Instruct4.7644.7494.6484.7540.0650.0500.0530.0430.0440.044GPT-3.5 Turbo4.2694.2514.0114.2500.1000.0720.0780.0460.0670.063 : Depthwise reasoning performance of large language models. Bold indicates the best-performing model,and underline represents the second best performance. A darker color indicates a higher discrepancy. employ the LLM-as-a-Judge approach, which cor-relates highly with human judgments in scoringlong-form responses (Zheng et al., 2024; Kim et al.,2024a; Lee et al., 2024; Kim et al., 2024b). Specifi-cally, we utilize GPT-4 Turbo (Achiam et al., 2023)for absolute scoring. Following Kim et al. (2024a)and Lee et al. (2024), the model generates a scoreand detailed feedback for each question, referenceanswer, and prediction based on a defined scoringrubric. Further details on the evaluation process areprovided in Appendix E. The exact input promptfor the LLM judge including the accuracy scorerubric is in Appendix J.3. The reliability of theLLM evaluation results in our setting is evidencedby high annotation agreement with human eval-uations, as explained in Appendix F. We reportaverage accuracy at Dk, the averaged factual cor-rectness of questions at depth k. Discrepancy evaluationAs we deconstruct com-plex questions into a hierarchical graph, we canmeasure forward discrepancy and backward dis-crepancy between neighboring questions.For-ward discrepancy measures the differences in per-formance on sub-problems compared to deeperquestions requiring advanced reasoning. Given aquestion qk at Dk {2, 3}, let DP(qk) representsa set of direct predecessor questions at Dk1. Thenforward discrepancy for qk is defined as follows:",
  "avgqDS(qk)[f(q)] f(qk).(2)": "Both forward discrepancy and backward discrep-ancy are normalized to the range by dividingby the maximum possible score gap, which is 4at our scoring range from 1 to 5. To highlightgaps across depths, we set a strict accuracy thresh-old of 4 and report the average discrepancies onlyfor examples where the mean score for DP(qk)and DS(qk) exceeds this threshold. This excludescases where models perform poorly at both depths. ModelsWe mainly probe into the depthwiseknowledge reasoning ability of open-source LLMs.We test representative open-source models basedon the LLaMA (Touvron et al., 2023) architecture,including LLaMA 2 {7B, 13B, 70B} Chat (Tou-vron et al., 2023), Mistral 7B Instruct v0.2 (Jianget al., 2023), Mixtral 8x7B Instruct v0.1 (Jianget al., 2024), and LLaMA 3 {8B, 70B} In-struct (AI@Meta, 2024). Additionally, we includethe latest GPT-3.5 Turbo8 (OpenAI, 2022) to com-pare the performance of these open-source modelsagainst a proprietary model.",
  "(g) LLaMA 3 70B Instruct": ": Memorization analysis with Min-K% probability. (a)-(d) show the distribution of average Min-K%probabilities at each depth. (e)-(g) present the distribution of score differences between neighboring questions,whose Min-K% probability is in the bottom 25% or top 75%. A positive gap indicates backward discrepancy, whilea negative gap represents forward discrepancy. 70B Instruct also exhibits the lowest discrepanciesfor both forward and backward discrepancy metrics,effectively answering questions at all depths withminimal discrepancies. Conversely, the least capa-ble model, LLaMA 2 7B Chat, shows the lowestaverage accuracy along with the highest forwardand backward discrepancies. Note that the rela-tively low forward discrepancy from D1 D2 forLLaMA 2 7B Chat is due to its low performance atD2. This observation highlights the varying capa-bilities of different LLMs in handling questions atdifferent depths and the inconsistencies in reason-ing across depths. Contrasting patterns of discrepanciesWe ob-serve distinct patterns when analyzing forward andbackward discrepancies separately. These discrep-ancies can be understood as a product of intensity(the magnitude of the discrepancies) and frequency(the proportion of questions showing a positivediscrepancy). Frequency indicates how often for-ward discrepancy or backward discrepancy occurs,while intensity reflects the strength of the discrep-ancy when it happens. Our analysis shows that for-ward discrepancy tends to occur more frequentlybut with lower intensity. For example, LLaMA 38B Instruct exhibits an intensity of 0.225 with afrequency of 41.44%. In contrast, backward dis-crepancy is less common but has a higher intensitywhen they appear. Specifically, LLaMA 3 8B In-struct shows an intensity of 0.323 with a frequency",
  "Memorization in Depthwise KnowledgeReasoning": "4.3.1Depthwise MemorizationTo determine whether solving complex questionsrequires reasoning rather than memorization oftraining data, we use a pre-training data detectionmethod to approximate potential aspects of memo-rization. Following Shi et al. (2023), we comparethe Min-K% probability within models. Highervalues suggest a smaller possibility of predictionsdirectly existing in the training data. To elaborate,Min-K% probability is calculated by averaging thenegative log-likelihood of the K% least probable to-kens in the models predictions. In the case wherea given prediction was seen during training, out-lier words with low probabilities would appear lessfrequently, resulting in high probabilities for theK% tokens. Since Min-K% probability is the av-erage negative log-likelihood of such tokens, theresulting value would be lower in this case. 9",
  "For our calculations, we set k to 20 and use a sequencelength of 128": "the Min-K% probability also increases for all mod-els. This indicates that answering questions basedon simple conceptual knowledge corresponding toD1 is more likely to be solved by recalling train-ing data. While shallow questions (D1) can beaddressed through memorization, solving deeperquestions (D3) requires more than just recalling asingle piece of memorized knowledge, indicating aneed for genuine reasoning capabilities.",
  "Memorization Gap between Depths": "Further analysis of questions in the bottom 25%and top 75% quantiles of the Min-K% probabil-ity distribution provides additional insights. Notethat questions in the top 75% quantile are morelikely to appear in the training data, while thosein the bottom 25% are less likely. (e)-(g)shows the score difference between neighboringquestions (D2 D3) whose Min-K% probabilityis in the bottom 25% or top 75%. We calculate thememorization gap as the difference between thefactual correctness of D3 and D2, normalized bythe maximum gap of 4. A positive value indicateshigher factual accuracy for the deeper questions,signifying backward discrepancy, while a negativevalue indicates higher accuracy for the shallowerquestion, representing forward discrepancy. Variance of gapsWe observe that the model withthe smallest capacity, LLaMA 2 7B Chat, exhibitslarge variances in both positive and negative direc-tions, showing significant forward and backwarddiscrepancies. In contrast, models with larger ca-pacities, such as LLaMA 2 70B Chat and LLaMA3 70B Instruct, demonstrate smaller variances. Potential causes of discrepanciesAdditionally,models with larger capacities tend to show rela-tively higher forward discrepanciesdistributionconcentrated on the negative sidefor the top 75%examples, which rely less on memorization. Onthe other hand, the bottom 25% distribution is con-centrated on positive values, indicating relativelymore backward discrepancies. This suggests thatas model capacity increases, failures in knowledgereasoning result in forward discrepancies, whilefailures due to reliance on memorization may leadto backward discrepancies. The depthwise Min-K% probability and score difference for other mod-els are provided in Appendix H.",
  "Qualitative Analysis of BackwardDiscrepancy": "To better understand how the more abnor-mal inconsistencybackward discrepancycanemerge, we qualitatively analyze backward discrep-ancy cases from the weakest model in our experi-ments, LLaMA 2 7B chat, and the strongest modelin our experiments, LLaMA 3 70B Instruct. Theexamples we refer to in the following paragraphsare listed in Appendix I.We observe that backward discrepancies oftenstem from the models ability to articulate high-level concepts but struggle with translating this un-derstanding into precise, step-by-step procedures,particularly when mathematical operations are in-volved. This is illustrated in Example 1, where bothmodels explain the importance of continued frac-tion representation for tangle numbers well (D3)but fail to accurately describe the process of con-structing a tangle for a given number (D2).In backward discrepancy cases, answers todeeper questions are more likely to be text-basedand conceptual, making them easier for models tomemorize that data. In contrast, shallower ques-tions require execution of mathematical or logicaloperations, where the variability in the elementsmakes answers harder to memorize verbatim. Thiselucidates memorization effects on backward dis-crepancy analyzed in .3.2.Interestingly, we also observe how the degreeof memorization contributing to backward discrep-ancy can vary with model capacity. Example 2shows LLaMA 2 7B Chat accurately reasoningabout time complexity (D3) but introducing non-standard terminology for specific operations (D2),suggesting the models struggle with precise recallof basic concepts. Conversely, Example 3 demon-strates LLaMA 3 70B Instruct correctly recalling acomplex formula (D3) but failing to apply it practi-cally (D2). This indicates that the model can exten-sively memorize information but still struggle withits flexible application. This observation exempli-fies why variance of memorization gaps can differby model capacity, as described in .3.2.",
  ": Performance change after providing shallowerquestions. Note that D1 is not reported for promptinputs, as D1 does not have shallower questions": "that enforcing LLMs to reason through interme-diate steps explicitly can improve their reasoningability. We investigate whether explicitly providingthese reasoning processes to the model can aid insolving complex questions.We encourage the model to reason by provid-ing shallower questions in three ways: (i) Multi-turn, where shallower questions are providedas user queries in a multi-turn conversation; (ii)Prompt (Gold), where shallower questions andtheir gold answers are provided in prompts; (iii)Prompt (Pred.), where shallower questions withthe models predictions are given in prompts. Notethat prompt-based approaches require shallowerQA pairs as inputs, which cannot be applied to D1questions. The prompt template for each approachis provided in Appendix J.2. Explicitly providing shallower solutions is ben-eficial for small models and complex questions. illustrates the depthwise performancechanges after incorporating deconstructed ques-tion information. Providing shallower questionsbenefits models with smaller capacities, such asLLaMA 2 7B Chat and Mistral 7B Instruct v0.2.For relatively simpler questions (D2), the benefitis less pronounced or may even decrease the per- formance of more capable models (>7B). However,intermediate questions (D2) are beneficial for com-plex questions (D3), except for models with largecapacities ( 56B). These findings align with re-cent research on decomposing a complex questioninto simpler sub-tasks and solving sub-tasks priorto the final answer (Juneja et al., 2023; Khot et al.,2023), which have shown high performance im-provements for solving complex problems acrossdifferent model sizes. Implicitly guiding reasoning via multi-turn in-teractions best improves performance.Whencomparing the two prompt-based inputs, smallermodels tend to perform better with gold answers(Gold.), while more capable models favor self-prediction results (Pred.). This preference likelyarises because more capable models align betterwith their own generated outputs, which reflecttheir advanced internal reasoning processes. Themulti-turn approach provides the most stable re-sults across all depths, enhancing the performanceof smaller models while causing minimal perfor-mance drops for larger models. Additionally, themulti-turn approach improves D1 performance byproviding context or domain information as part ofthe interaction history.",
  "Conclusion": "In this study, we explore the reasoning capabilitiesof LLMs by deconstructing real-world questionsinto a graph. We introduce DEPTHQA, a set of de-constructed D3 questions mapped into a hierarchi-cal graph, requiring utilization of muliple layers ofknowledge in the sequence of D1, D2 to D3. Thishierarchical approach provides a comprehensiveassessment of LLM performance by measuring for-ward and backward discrepancies between simplerand complex questions. Our comparative analy-sis of LLMs with different capacities reveals aninverse relationship between model capacities anddiscrepancies. Memorization analysis suggests thatthe sources of forward and backward discrepanciesin large models stem from different types of fail-ures. Lastly, we demonstrate that guiding modelsfrom shallower to deeper questions through multi-turn interactions stabilizes performance across themajority of models. These findings emphasize theimportance of intermediate knowledge extractionin understanding LLM reasoning capabilities.",
  "Limitations": "Small sample sizeOur dataset, DEPTHQA, con-sists of 91 complex (D3) questions from the Tu-torEval dataset, along with 1,480 derived shallower(D2, D1) questions. Despite the diversity in reason-ing types explored (.4) and the hierarchi-cal structuring of subquestions, the limited numberof complex questions and the narrow content scoperestrict the generalizability of our findings. Theselection of TutorEval as our primary source isbased on the challenge of manually developing oreven sourcing intricate questions that necessitateadvanced reasoning skills; such questions require(1) maintaining real-world relevance, (2) elicitinglong-form answers, and (3) having minimal riskof test set contamination. Within TutorEval, com-plex D3 questions represent only 33.6% of its 834questions, which further reduces to 10.9% whenexcluding questions that require external knowl-edge retrieval. We encourage future research tobuild larger, more diverse datasets to more robustlyassess knowledge reasoning capabilities of LLMs. GPT-4 data generation and evaluationAllquestions except for D3 and reference answers inDEPTHQA are generated by GPT-4 Turbo. Toensure the quality of these questions, we have es-tablished strict decomposition criteria (.2)and implemented rigorous procedures includingdetailed instructions, question augmentation, man-ual rewriting and verification by human annotators(.3). The reliability of the answers is sup-ported by findings from Chevalier et al. (2024),which demonstrate GPT-4s high accuracy of 92%on TutorEval problems as assessed by human eval-uators. However, there may exist inaccuracies dueto unseen errors in the decomposition process orunverified knowledge produced by the model.Furthermore, we utilize GPT-4 Turbo to assessthe correctness of model predictions.Follow-ing protocols from previous studies (Kim et al.,2024a,b) which highlight GPT-4s strong correla-tion with human judgments on long-form content,we provide detailed instructions and specific scor-ing rubrics to the evaluator to ensure that the evalu-ation process aligns closely with our objectives. Inaddition, we conduct human evaluations and com-pare with GPT-4 Turbo evaluations, and measuresufficiently high inter-annotator agreement (Ap-pendix F). Still, the evaluation method is subject tobias inherent in LLM judges.",
  "Acknowledgement": "We thank Hyeonbin Hwang, Sohee Yang, and Sung-dong Kim for constructive feedback and discus-sions. This work was partly supported by KAIST-NAVER Hypercreative AI Center and Institute forInformation & communications Technology Pro-motion (IITP) grant funded by the Korea govern-ment (MSIT) (RS-2024-00398115, Research onthe reliability and coherence of outcomes producedby Generative AI, 30%).",
  "Santiago Castro. 2017. Fast Krippendorff: Fast com-putation of Krippendorffs alpha agreement measure": "Stephanie Chan, Adam Santoro, Andrew Lampinen,Jane Wang, Aaditya Singh, Pierre Richemond, JamesMcClelland, and Felix Hill. 2022. Data distributionalproperties drive emergent in-context learning in trans-formers. In NeurIPS, pages 1887818891. Alexis Chevalier, Jiayi Geng, Alexander Wettig,Howard Chen, Sebastian Mizera, Toni Annala,Max Jameson Aragon, Arturo Rodrguez Fanlo, Si-mon Frieder, Simon Machado, et al. 2024. Languagemodels as science tutors. arXiv. Arthur Conmy, Augustine Mavor-Parker, Aengus Lynch,Stefan Heimersheim, and Adri Garriga-Alonso.2023. Towards automated circuit discovery for mech-anistic interpretability. In NeurIPS. Curran Asso-ciates, Inc. Damai Dai, Yutao Sun, Li Dong, Yaru Hao, ShumingMa, Zhifang Sui, and Furu Wei. 2023. Why can GPTlearn in-context? language models secretly performgradient descent as meta-optimizers. In Findings ofACL. Peter Sheridan Dodds, Eric M Clark, Suma Desu,Morgan R Frank, Andrew J Reagan, Jake RylandWilliams, Lewis Mitchell, Kameron Decker Harris,Isabel M Kloumann, James P Bagrow, et al. 2015.Human language reveals a universal positivity bias.Proceedings of the national academy of sciences,112(8):23892394.",
  "K Hess. 2006. Applying webbs depth-of-knowledge(dok) levels in science. Accessed November, 10": "Karin Hess, Ben Jones, Dennis Carlock, and John RWalkup. 2009.Cognitive rigor:Blending thestrengths of blooms taxonomy and webbs depthof knowledge to enhance classroom-level processes.ERIC Document (Online Database). Yifan Hou, Jiaoda Li, Yu Fei, Alessandro Stolfo,Wangchunshu Zhou, Guangtao Zeng, Antoine Bosse-lut, and Mrinmaya Sachan. 2023a. Towards a mecha-nistic interpretation of multi-step reasoning capabili-ties of language models. In EMNLP. Yifan Hou, Jiaoda Li, Yu Fei, Alessandro Stolfo,Wangchunshu Zhou, Guangtao Zeng, Antoine Bosse-lut, and Mrinmaya Sachan. 2023b. Towards a mech-anistic interpretation of multi-step reasoning capabil-ities of language models. In EMNLP. Albert Q Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, et al. 2023. Mistral7b. arXiv. Albert Q Jiang, Alexandre Sablayrolles, AntoineRoux, Arthur Mensch, Blanche Savary, Chris Bam-ford, Devendra Singh Chaplot, Diego de las Casas,Emma Bou Hanna, Florian Bressand, et al. 2024.Mixtral of experts. arXiv. Gurusha Juneja, Subhabrata Dutta, Soumen Chakrabarti,Sunny Manchanda, and Tanmoy Chakraborty. 2023.Small language models fine-tuned to coordinatelarger language models improve complex reasoning.In EMNLP.",
  "Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu,Kyle Richardson, Peter Clark, and Ashish Sabharwal.2023. Decomposed prompting: A modular approachfor solving complex tasks. In ICLR": "Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang,Shayne Longpre,Hwaran Lee,Sangdoo Yun,Seongjin Shin, Sungdong Kim, James Thorne, andMinjoon Seo. 2024a. Prometheus: Inducing evalua-tion capability in language models. In ICLR. Seungone Kim,Juyoung Suk,Shayne Longpre,Bill Yuchen Lin, Jamin Shin, Sean Welleck, GrahamNeubig, Moontae Lee, Kyungjae Lee, and MinjoonSeo. 2024b. Prometheus 2: An open source languagemodel specialized in evaluating other language mod-els. arXiv.",
  "Sohee Yang, Elena Gribovskaya, Nora Kassner, MorGeva, and Sebastian Riedel. 2024. Do large languagemodels latently perform multi-hop reasoning? arXiv": "Seonghyeon Ye, Doyoung Kim, Sungdong Kim, Hyeon-bin Hwang, Seungone Kim, Yongrae Jo, JamesThorne, Juho Kim, and Minjoon Seo. 2024. FLASK:Fine-grained language model evaluation based onalignment skill sets. In ICLR. Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,Xiaolei Wang, Yupeng Hou, Yingqian Min, BeichenZhang, Junjie Zhang, Zican Dong, Yifan Du, ChenYang, Yushuo Chen, Z. Chen, Jinhao Jiang, RuiyangRen, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu,Jianyun Nie, and Ji rong Wen. 2023. A survey oflarge language models. ArXiv. Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, SiyuanZhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,Zhuohan Li, Dacheng Li, Eric Xing, et al. 2024.Judging llm-as-a-judge with mt-bench and chatbotarena. NeurIPS, 36. Denny Zhou, Nathanael Schrli, Le Hou, Jason Wei,Nathan Scales, Xuezhi Wang, Dale Schuurmans,Claire Cui, Olivier Bousquet, Quoc V Le, and Ed H.Chi. 2023. Least-to-most prompting enables com-plexz reasoning in large language models. In ICLR.",
  "ADetails in Dataset Construction": "Classifying questions based on depth of knowl-edgeTo categorize questions from the TutorEvaldataset (Chevalier et al., 2024), we use GPT-4Turbo set at a temperature of 0.7, following thespecific prompt detailed in . We evaluatethe models classification accuracy using a valida-tion set of 50 questions, which we have previouslyannotated with their respective depth of knowledgelevels. Our optimal prompting strategy involvesincorporating key points from each question pro-vided in the original dataset and instructing themodel to provide a step-by-step explanation of itsclassification reasoning. This approach achieves aprecision of 0.67 and a recall of 0.77, with a lowrate of false positives. Analysis of the entire setof 834 questions reveals the distribution of depthlevels: 43% at D2, 33.6% at D3, 23.3% at D1, andonly one question at D4. D3question filtering and disambiguationFrom the 280 D3 questions initially identified,we manually exclude questions that are not self-contained, meaning they refer to specific contextsor excerpts in textbook passages that cannot beseamlessly integrated into our input. Examples in-clude questions like, I dont understand the pointof Theorems 4.3.2 and 4.3.3. Why do we careabout these statements? and Please tell me thecommon conceptual points between the Weinrichand Wise 1928 study and the Roland et al. 1980paper. Additionally, we disambiguate questionsto ensure clarity and context accuracy. For exam-ple, the question Why is branching unstructured?And is it a bad design choice? was initially vagueabout its reference to branching. Upon review,we identify the context as computer programmingrather than database systems and revise the ques-tion to: In the context of computer programming,why is branching considered unstructured, and is itconsidered a poor design choice?. Question deduplication and augmentationAsexplained in .3, we leverage cosine simi-larity of question embeddings produced by a Sen-tence Transformers embedding model10 (Reimersand Gurevych, 2019) to identify near-duplicatequestions. Specifically, within the same depth 1or 2, we apply a similarity threshold of 0.9 to iden-tify duplicates and eliminate them. For questionsacross D1 and D2, we remove D2 questions with a",
  "What is the modulo operation in mathematics?": ": The original 4th shallower question (red) is ask-ing redundant knowledge addressed in the 3rd question.We remove the duplicate question and replace it with aquestion asking a different concept (blue). similarity score 0.9 to D1 questions and removeD1 questions with a similarity score between 0.8and 0.9 to D1 questions, under the rationale thatthe D2 question is effectively at D1 level and viceversa. The similarity threshold and the candidateto remove was determined through qualitative anal-ysis. We analyze that the false positive rate of D1questions misclassified as D2 decreases from 60%to 7% (reduction rate of 88%). comparestop-1 similar question pairs between D2 and D1 be-fore and after deduplication. We further use GPT-4Turbo with temperature 0.7 (prompt in and 26) to augment questions filling the gap ofknowledge. illustrates how an augmentedquestion successfully replaces a previously redun-dant question, enhancing comprehensiveness. Motivation of question debiasingIn our prelim-inary study, we found that models tend to favoryes over no at the beginning of the response toa question that can be answered in binary format,as exemplified in . We recognize that theinherent positivity bias in models (Augustine et al.,2011; Dodds et al., 2015; Papadatos and Freedman,2023) has the potential to skew the models rea-",
  "Predicted answer:Predicted answer:": "Yes, there is a connection between the two notions. In mathe-matics, when we say that two integers are congruent modulon, it means that they have the same remainder when dividedby n. For example, 3 and 6 are congruent modulo 3 becausewhen we divide 3 by 3, the remainder is 0, and when wedivide 6 by 3, the remainder is also 0. [... ] Yes, the concepts of being congruent modulo an ideal and twonumbers being congruent modulo another number are distinct.When we say that two numbers a and b are congruent modulon, we mean that their difference a - b is a multiple of n. Thisis written as a b (mod n). [... ]",
  "BHuman Verification on Data Quality": "2 of the authors and one graduate student who vol-unteered annotate 27.5% of DEPTHQA, verifyingthe three criteria we hold in .2: Com-prehensiveness (C1), Implicitness (C2), and Non-binary questioning (C3). Comprehensiveness andImplicitness are especially crucial criteria for sub-questions to ensure the hierarchy in the reasoningprocess, as Comprehensiveness ensures no criticalknowledge gaps with increasing depth, while Im-plicitness ensures no straightforward clues, encour-aging implicit reasoning between sub-questions.To set up the procedure, we randomly sample 5D3 questions from each of the 5 domains in ourdataset and use all questions derived from the se-lected D3 questions, totaling 25 D3, 100 D2, and396 D1 questions. Given 25 D3 D2 and 100",
  ": Human annotation on Implicitness of a subsetof DEPTHQA sub-questions": "D2 D1 relations, the relations are divided into40, 40, 45 and are assigned to the three workers.For each relation, the main question and the sub-questions (predecessors) are provided along withtheir gold answers. Then the labeler is asked tocheck whether the relation is conceptually com-prehensive and whether each question is implicitor non-binary. The labeler can choose from threevarying degrees of comprehensiveness and implic-itness due to the subjective nature of the criteria.The annotation interface is shown in ., 9, and 10 reports the annotation statis-tics. shows that the decompositionsinto shallower questions are fully comprehensive(C1) in 88% of D3 D2 relations and 79% ofD2 D1 relations, reaching 100% and 97% whentaking partially comprehensive relations as well, re-spectively. Also, shows that 87% of D2and 91.9% of D1 questions do not hint at solutionsfor more complex questions (C2), with similarlylow failure rates. We also find in that",
  "DReasoning Type Analysis": "In , we report the distribution of reasoningtypes annotated by the authors on a sample of 20D3 questions and D2 and D2 related to them. Ta-ble 15 outlines the definition of each reasoning typeand a representative example set of questions thatbest elicits such reasoning. We provide questiondeconstructions examples in and where each showcases distinct reasoning types andknowledge.",
  "E.1Model Inference": "To inference LLMs used in our experimental setup(.1), we use a standardized API fromOpenRouter11 to access LLMs and use the comple-mentary LiteLLM12 interface to call model genera-tions. An exception is LLaMA 7B Chat, which isnot hosted in OpenRouter; we use the HuggingFacemodel and the vLLM (Kwon et al., 2023) inferenceengine for this particular model, performing lo-cal inference with mixed precision on 1 NVIDIAA6000 40GB GPU. We use the default samplingparameters suited for each model. The specificprompt templates used to induce reasoning pathsare organized in Appendix J.2. The inference onthe whole pass of DEPTHQA finishes within 10minutes. We report single-run results.",
  "E.2LLM-as-a-Judge Evaluation": "When prompting GPT-4 Turbo to evaluate modelresponses, we use a temperature of 1.0, nucleussampling with top_p of 0.9, and maximum numberof generation tokens of 1,024, following previousworks (Ye et al., 2024; Kim et al., 2024a,b; Leeet al., 2024). The prompt template including thescore rubric is in . We report single-run re-sults. See for example output format. Un-like prior works that emphasize the use of instance-specific scoring rubrics (Kim et al., 2024a,b; Leeet al., 2024), our initial experiments comparingevaluations given a common rubric and instance-specific rubric showed that instance-specific rubricsincrease noise in evaluation and decrease the qual-ity of evaluation. We speculate that it is because thefocus of our evaluation is on a common factor of fac-tual correctness, i.e., whether the model accuratelyuses knowledge in the reasoning process, differentfrom conventional benchmark evaluations.",
  "FReliability of LLM-as-a-Judge": "To assess the reliability of LLM evaluations in ouranalysis, we conduct human evaluation of LLM re-sponses and calculate the agreement between anno-tations. We randomly sample 20 model responsesfor each score level (1 to 5) as evaluated by GPT-4Turbo, with the question and response model beingrandom as well. 2 of the authors and one graduatestudent who volunteered evaluate 46, 46, and 48",
  "Overall0.57300.7797(n = 20)(n = 100)": ": Krippendorfs Alpha between human-humanand human-GPT-4 ratings on model responses toDEPTHQA questions. For human-GPT agreement, thescores of predictions rated by the three human raters areaveraged. The number of responses in each measure-ment is reported below the Krippendorfs Alpha value. unique responses, respectively, and all 3 workerslabel the remaining 20 responses set aside for inter-annotator agreement. The human raters are givenonly 1 instance at a time and individually scoreit on a scale of 1 to 5, under the exact setting ofour LLM-as-a-Judge experiments. The evaluationinterface is shown in . Following Ye et al.(2024), we measure Krippendorfs Alpha (Krippen-dorff, 2018; Castro, 2017) with an ordinal metric toreliability between three human raters and betweenhumans and GPT-4 Turbo. reports the agreement results. The re-sults show that the human-GPT agreement is sub-stantially high, approaching 0.80, the commonlyaccepted reliability threshold (Krippendorff, 2018).While the sample size is smaller, there is also mod-",
  "GDiscrepancy Results": "To separately observe how frequently each discrep-ancy occurs and its intensity when it happens, Ta-ble 12 and show the average intensity andfrequency of each forward and backward discrep-ancy. Note that the average discrepancy is calcu-lated as the product of the value and frequency.Overall, forward discrepancies appeared more fre-quently, although their intensity was relatively low(between 0.14 and 0.26). In contrast, backwarddiscrepancies appeared less than 25%, except forLLaMA 2 7B, which exhibited high intensity (be-tween 0.26 and 0.37).",
  "General Instructions": "You are a fair judge assistant tasked with providing clear, objective feedback based on specic criteria, ensuring eachassessment reects the absolute standards set for performance.If the question eld is named 'undened', you do not need to check anything for that question.Criteria Descriptions C1. Comprehensiveness: This criterion assesses whether the lower-level questions cover all the foundationalconcepts necessary to answer the higher-level question.C2. Implicitess: This criterion evaluates whether the lower-level questions avoid directly revealing answers or heavilyhinting at solutions for the higher-level question.C3. Non-binary Questioning: This criterion assesses whether the questions elicit detailed, exploratory responsesinstead of simple yes/no answers.",
  "Assess how well each lower-level question encourages independent reasoning without providing obvious clues to thehigher-level question's answer": "[Main! Anhedonia seems to be a common feature of both depression and schizophrenia. Explain whether it is valid to statethat schizophrenic people have depression.(Sub-1] How can anhedonia be observed or identied in aclinical setting?Explicit(4)Partially Implicitis Fully Implicit(6) [Sub-2] What are the primary diagnostic criteria forschizophrenia and how do they differ from those ofdepression?[Sub-31 Explain the presence of symptoms that are commonto more than one mental health disorder, if possible, and howthis is addressed in diagnosis.[Sub-4] What role does symptom overlap play in thediagnosis and treatment of mental health disorders?",
  "Response to Evaluate": "When attention is described as \"visual,\" it means that it is focused on visualstimuli, such as sights, images, or objects, and is processed through the visualsystem of the brain. In other words, visual attention involves the detection,orientation, and processing of visual information, often in the form of recognizingshapes, patterns, colors, and objects. In this sense, visual attention is distinct from other types of attention, such asauditory, tactile, or cognitive attention, which focus on sounds, touch, or mentaltasks, respectively. Visual attention is often the most dominant and natural type ofattention for humans, as our brains are wired to rely heavily on visual informationfor processing and understanding the world around us.",
  "Examples of visual attention include:": "1. Rapidly scanning a room to take in the surroundings.2. Focusing on a specic detail in an image or object.3. Recognizing a familiar face or object.4. Following a moving object or person with your gaze. In various situations, such as in daily life, learning, or even creative activities, visualattention plays a crucial role in processing and interpreting visual information,guiding actions, and forming connections to our surroundings.",
  "Answer (Score 5)": "Visual attention refers to the brain's ability to selectively process visualinformation while ignoring irrelevant details. It involves the focusing of awarenesson specic elements in the visual eld, enabling us to concentrate on certainaspects in our environment while diminishing the importance of others. It is acognitive process used in tasks like reading, driving, and any other activities that",
  "D2 How can you determine if a square matrix is diagonalizable?": "D1 What is the definition of a square matrix?D1 What are the characteristics of a diagonal matrix?D1 What is meant by the eigenvalues of a matrix?D1 How is the characteristic equation of a matrix defined? D2 What is the process for finding the eigenvalues of a matrix?D2 Explain how to compute eigenvectors from a given set of eigenvalues.D2 Describe the method to perform a similarity transformation on a matrix. : Snippet of hierarchical question deconstruction for analyzing matrix diagonalizability. The topmostcomplex question, D3, requires developing criteria of whether the statement holds or not. The first D2 questionidentifies the key property to help determine the case. The D1 child questions addresses relevant definitions,characteristics, and formula in order to synthesize the foundational concepts.",
  "Predicted answer:In engineering thermodynamics, its common to work with ideal and real gases, and temperature plays a crucial role incharacterizing their behavior": "Actually, you can measure temperature in Fahrenheit, but not in the context of the ideal gas law or ideal gas equations. Theissue lies in the definition and scaling of the Fahrenheit and Celsius temperature scales. Celsius is the preferred choice for scientific and engineering applications because its based on the concept of absolute zero,which is the theoretically lowest possible temperature. Its defined as 0 K (kelvin). This allows for a coherent and consistentframework for discussing temperature and thermodynamic quantities. Fahrenheit, on the other hand, has a different zero point (32F) and relies on arbitrary reference points to define its scale.Although its still used for everyday applications, it doesnt provide the same theoretical foundation as Celsius.",
  "The ideal gas law and the equations of state for gases are typically expressed in terms of absolute temperature (K or R), andCelsius is the most compatible scale for these applications": "So, while you could measure temperature in Fahrenheit if needed, its essential to understand the underlying scienceand choose the most relevant and consistent temperature scale when working with ideal and real gases in engineeringthermodynamics. Feedback:Feedback: The response provides an accurate explanation regarding the use of Fahrenheit versus Celsius (and indirectlyKelvin) in the context of thermodynamics and ideal gases. It correctly identifies the reasons why Celsius and Kelvin arepreferred for scientific studies, focusing on the relevance of absolute zero and the uniformity in scientific communication.However, it slightly misleads by stating that Celsius is based on the concept of absolute zero, when in fact, it is Kelvin that isbased on this concept. Celsius is indeed more aligned with Kelvin compared to Fahrenheit but it is not based on absolute zero;rather, it is defined by the melting point of ice and the boiling point of water at one atmosphere of pressure, which are thenused to extrapolate its relation to Kelvin. The response demonstrates a strong understanding but includes a minor inaccuracyregarding the basis of the Celsius scale. This inaccuracy does not significantly detract from the overall quality and factualcorrectness of the explanation but is worth noting for precision.",
  "LLaMA 2 7B Chat Predicted Answer (Score: 4)": "(...) The continued fraction representation of a tangle number allows us to represent thetangle as a rational number, which can be easily manipulated and analyzed. This can beparticularly useful when studying the properties of tangles, such as their convergence prop-erties, their behavior under certain operations, and their relationship to other mathematicalstructures. (...)",
  "LLaMA 2 7B Chat Predicted Answer (Score: 1)": "(...) Choose a base: There are many different bases that you can use to construct a tangle fora rational number. Some common bases include the golden ratio, the Fibonacci sequence,and the square root of 2. Choose a base that you feel comfortable working with and thatwill help you visualize the tangle. (...)",
  "LLaMA 3 70B Instruct Predicted Answer (Score: 2)": "(...) Draw p arcs: Draw p arcs from the top of the circle to the bottom, each crossing thecircle at a single point. These arcs will form the strands of the tangle.Twist the arcs: Twist the arcs around each other according to the following rule: for each ofthe q crossings, take the upper strand and pass it over or under the lower strand (it doesntmatter which) to create a twist. (...) Feedback: Describes a process that diverges from the correct method of using continued fractionsto construct a tangle. It also omits the critical step of expressing the rational number as a continuedfraction and constructing the tangle diagram based on the continued fractions terms.",
  "LLaMA 2 7B Chat Predicted Answer (Score: 5)": "(...) just because node operations have a constant time complexity doesnt necessarilymean that all operations in data structures using nodes will also have O(1) complexity.The reason for this is that the time complexity of an operation can depend on many factorsbeyond just the size of the input, such as the data structures internal organization, thealgorithms used, and the hardware on which the data structure is running. (...)",
  "LLaMA 2 7B Chat Predicted Answer (Score: 2)": "(...) Here are the common ways to perform insertion in a linked list:1. Linear Insertion: (...) This approach has a time complexity of O(1) because we only needto traverse the list once to find the correct position. 2. Shift-Insertion: (...) This approachhas a time complexity of O(n) because we need to traverse the entire list to shift all thenodes. 3. Rotate-Insertion: (...) This approach has a time complexity of O(n) because weneed to traverse the entire list to rotate all the nodes. (...) Feedback: Introduces non-standard terms (Linear Insertion, Shift-Insertion, Rotate-Insertion)that are not typically used in describing linked list operations. Incorrectly states that insertion at aspecific position has O(1) time complexity, when it should be O(n) in the worst case.",
  "LLaMA 3 70B Instruct Predicted Answer (Score: 5)": "(...) For cubic equations of the form ax3 + bx2 + cx + d = 0, there is a formula knownas Cardanos Formula (or Cardanos Method). (...) For quartic equations of the formax4 + bx3 + cx2 + dx + e = 0, there is a formula known as Ferraris Method (or FerrarisSolution). (...) For equations of degree 5 or higher, there is no general formula that can bewritten using only addition, subtraction, multiplication, division, and nth roots (like thequadratic formula). This was proven by Niels Henrik Abel in 1824, and later independentlyby variste Galois in 1832. (...)",
  "LLaMA 3 70B Instruct Predicted Answer (Score: 1)": "The quartic formula! While its not as well-known as the quadratic formula, its a powerfultool for solving quartic equations of the form ax4 + bx3 + cx2 + dx + e = 0. Here are thesteps to solve quartic equations using the quartic formula:Steps to Solve Quartic Equations:1. Write down the quartic equation in standard form: ax4 + bx3 + cx2 + dx + e = 0,where a, b, c, d, and e are constants.2. Rearrange the equation to have a = 1: Divide both sides of the equation by a, so that thecoefficient of x4 is 1. This simplifies the formula.3. Calculate the values of p, q, and r:- p = b2 3c- q = bc 4d a- r = c2 3bd + 12ae4. Calculate the value of u: u = (r/2",
  "w2 4u)/2": "Feedback: Introduces an incorrect formula for solving quartic equations, which does not align withestablished methods like Ferraris solution. The provided steps and calculations do not correspondto the correct procedure for solving quartic equations using the quartic formula or any otherrecognized method. System prompt:You are an excellent question classifier. You will be given (1) a question and (2) key points that a good response wouldaddress when answering the question. You have to classify at which Depth of Knowledge (DOK) level the question is located.DOK is a framework that focuses on the context which knowledge will be demonstrated. Here is the definition of each DOKlevel: 1. DOK-1 (Basic Knowledge and Recall): This level addresses What is the knowledge?. It evaluates the ability toremember, explain, or pinpoint fundamental facts, terms, principles, and procedures. Its about recognizing or recollectingbasic information and performing simple, direct tasks.2. DOK-2 (Application of Knowledge and Skills): This level explores How can the knowledge be used?. It tests theability to employ knowledge and concepts in practical situations, which involves choosing appropriate methods, solvingstraightforward problems, or interpreting data. This level acts as an intermediary step between fundamental understandingand more advanced reasoning.3. DOK-3 (Analytical and Strategic Thinking): This level questions Why can the knowledge be used?. It challenges one touse strategic thought, logic, and problem-solving in intricate, abstract situations that might have more than one solution. Thisstage demands critical thinking, rationale, and conceptualization of theoretical scenarios.4. DOK-4 (Extended and Integrative Knowledge): This level examines How else can the knowledge be applied?. It assessesthe ability to conduct thorough research, apply concepts and skills in real-world scenarios, and integrate knowledge acrossdifferent disciplines or sources. It involves developing original ideas, conducting experiments, and synthesizing informationfrom various fields. Note that in the science domain, this level may be constrained to designing studies, experiments, andprojects and is thus rare or even absent in most standardized assessment. User prompt:Please classify the following question into DOK-1, 2, 3, or 4. Refer to the key points to help your judgment. Thinkstep-by-step and provide an explanation of your judgment. After providing your explanation, output the DOK level that is aninteger of 1, 2, 3, or 4. The output format should looks as follows: {explanation for reaching the DOK decision} [RESULT]{DOK level that is an integer in the range 1 to 4}.",
  "User prompt:## Chapter{chapter}": "## InstructionAnswer the question below.- You may refer to the contents in the chapter text above if necessary, but do NOT expose in your answer that you are referringto the provided source.- Ensure that the answer is complete, fully satisfying the key points to answer the question.- The answer must also match the level of cognitive complexity required, incorporating the context which the depth ofknowledge will be demonstrated.",
  ": Prompt for generating reference answer for a D1 or D2 question": "System prompt:You are an excellent question generator. You will be given a question and a gold answer to the question. You have to generateshallower questions from the given question. Here is the definition of the depth of knowledge a question requires: 1. Depth-1 (Basic Knowledge and Recall): This level addresses What is the knowledge?. It evaluates the ability toremember, explain, or pinpoint fundamental facts, terms, principles, and procedures. Its about recognizing or recollectingbasic information and performing simple, direct tasks.2. Depth-2 (Application of Knowledge and Skills): This level explores How can the knowledge be used?. It tests theability to employ knowledge and concepts in practical situations, which involves choosing appropriate methods, solvingstraightforward problems, or interpreting data. This level acts as an intermediary step between fundamental understandingand more advanced reasoning.3. Depth-3 (Analytical and Strategic Thinking): This level questions Why can the knowledge be used?. It challenges one touse strategic thought, logic, and problem-solving in intricate, abstract situations that might have more than one solution. Thisstage demands critical thinking, rationale, and conceptualization of theoretical scenarios.",
  ": System prompt for generating or augmenting D1 or D2 questions": "User prompt:## InstructionCreate maximum of 4 Depth-2 questions that are necessary to answer the provided Depth-3 question correctly.- Remember that Depth-2 questions are centered on application of procedural knowledge and skills and Depth-3 questions arecentered on analysis and strategic knowledge.- Take into consideration the level of cognitive complexity required to solve the Depth-3 question, so that your generatedquestions fall under the description of Depth-2 appropriately.- Ensure that your collection of generated Depth-2 questions adequately and comprehensively covers ALL the necessaryfactual or conceptual knowledge required to answer the given Depth-3 question.- Ensure that all of your generated Depth-2 questions do not directly answer to the given Depth-3 question.- The number of generated Depth-2 questions should not exceed 4.- The generated Depth-2 questions should be in JSON format: {Depth-2_questions: [list of Depth-2 question strings ]} ## Example 1### Depth-3 questionWhat is the intuition behind the Gram - Schmidt procedure?### Generated Depth-2 questions{Depth-2_questions: [How do you project one vector onto another vector?, What does it mean for two vectors to beorthogonal, and how can you verify this property?, Describe the process of normalizing a vector., Explain how subtractingthe projection of one vector from another results in orthogonality., Given a set of vectors, how can you determine if they arelinearly independent?, How can the concept of linear independence be used to form a basis for a vector space? ]} ## Example 2### Depth-3 questionWhy couldnt we test general relativity effects using the Eotvos experiment?### Generated Depth-2 questions{Depth-2_questions: [How does the Etvs experiment determine the equivalence between inertial mass and gravitationalmass?, Describe the Equivalence Principle and its significance in the theory of General Relativity., Identify experimentsor observations that could directly test the predictions of General Relativity, such as time dilation or the bending of light.,How do experiments measuring time dilation differ in design and scope from those measuring mass equivalence? ]} ## Example 3### Depth-3 questionWhy are aldehydes more readily oxidized to carboxylic acids compared to ketones, and how does this difference in reactivityinfluence their identification in the laboratory?### Generated Depth-2 questions{Depth-2_questions: [How can you identify an aldehyde using Tollens reagent?, Why does the carbonyl carbon inaldehydes have a significant partial positive charge?, How does the structure of ketones differ from that of aldehydes, andhow does this affect their reactivity towards oxidation? ]} ## Example 4### Depth-3 questionIn the context of computer programming, why is branching unstructured? And is it a bad design choice?### Generated Depth-2 questions{Depth-2_questions: [What are the key differences between structured and unstructured branching in programming?,How does the goto statement work in computer programming?, What are the potential risks involved with usingunstructured branching in large software projects?, How does the structure of a program affect its maintainability?, Howcan the flow of execution in a program influence its debuggability? ]}",
  ": User prompt for generating D2 questions": "User prompt:## InstructionCreate maximum of 4 Depth-1 questions that are necessary to answer the provided Depth-2 question correctly.- Remember that Depth-1 questions are centered on basic recall of factual and conceptual knowledge. Depth-2 questions arecentered on application of procedural knowledge and skills.- Take into consideration the level of cognitive complexity required to solve the Depth-2 question, so that your generatedquestions fall under the description of Depth-1 appropriately.- Ensure that your collection of generated Depth-1 questions adequately and comprehensively covers ALL the necessaryfactual or conceptual knowledge required to answer the given Depth-2 question.- Ensure that all of your generated Depth-1 questions do not directly answer to the given Depth-2 question.- Try to exclude Depth-1 questions that ask too generic or commonsense knowledge.- The number of generated DOK-2 questions should not exceed 4.- The generated Depth-1 questions should be in JSON format: {Depth-1_questions: [list of Depth-1 question strings]} ## Example 1### Depth-2 questionHow can the concept of algebraic closure be demonstrated using polynomial equations with complex roots?### Generated Depth-1 questions{Depth-1_questions: [What is the definition of algebraic closure?, What is a polynomial equation?, What are complexroots in the context of polynomial equations?, How can complex roots be represented?]} ## Example 2### Depth-2 questionHow do you perform a convolution operation between two random variables?### Generated Depth-1 questions{Depth-1_questions: [What is a convolution operation?, What is a random variable?, How is the product of twofunctions calculated?, What does it mean to integrate a function?]} ## Example 3### Depth-2 questionIn what ways can a decision trees structure be represented programmatically?### Generated Depth-1 questions{Depth-1_questions: [What is a decision tree in the context of programming?, What are the basic components of adecision tree?, What is a data structure in programming?, What does represented programmatically mean?]} ## Example 4### Depth-2 questionHow do neutrinos differ from other subatomic particles, and why are they considered potential candidates for dark matter?### Generated Depth-1 questions{Depth-1_questions: [What are neutrinos?, What are subatomic particles?, What is dark matter?, What characteristicsdo particles need to be considered candidates for dark matter?]}",
  ": User prompt for generating D1 questions": "User prompt:## InstructionCreate {count} Depth-2 question(s) that complement current Depth-2 questions, which are necessary to correctly answer theprovided Depth-3 question.- Remember that Depth-2 questions are centered on application of procedural knowledge and skills and Depth-3 questions arecentered on analysis and strategic knowledge.- Take into consideration the level of cognitive complexity required to solve the Depth-3 question, so that your generatedquestions fall under the description of Depth-2 appropriately.- Complement the existing Depth-2 questions with additional questions to ensure they collectively cover all necessaryprocedural knowledge and skills required to answer the Depth-3 question effectively.- Ensure that all of your generated Depth-2 questions do not directly answer to the given Depth-3 question.- The number of all Depth-2 questions should not exceed 4.- The generated Depth-2 questions should be in JSON format: {Depth-2_questions: [list of Depth-2 question strings ]} ## Example 1### Depth-3 question and current Depth-2 questionsWhat is the intuition behind the Gram - Schmidt procedure?{current_Depth-2_questions: [How do you project one vector onto another vector?, What does it mean for two vectorsto be orthogonal, and how can you verify this property?, Describe the process of normalizing a vector., Explain howsubtracting the projection of one vector from another results in orthogonality., Given a set of vectors, how can you determineif they are linearly independent? ]}### Generated complementary Depth-2 questions{complementary_Depth-2_questions: [How can the concept of linear independence be used to form a basis for a vectorspace? ]} ## Example 2### Depth-3 question and current Depth-2 questionsWhy couldnt we test general relativity effects using the Eotvos experiment?{current_Depth-2_questions: [How does the Etvs experiment determine the equivalence between inertial mass andgravitational mass?, Describe the Equivalence Principle and its significance in the theory of General Relativity., Identifyexperiments or observations that could directly test the predictions of General Relativity, such as time dilation or the bendingof light. ]}### Generated complementary Depth-2 questions{complementary_Depth-2_questions: [How do experiments measuring time dilation differ in design and scope from thosemeasuring mass equivalence? ]} ## Example 3### Depth-3 question and current Depth-2 questionsWhy are aldehydes more readily oxidized to carboxylic acids compared to ketones, and how does this difference in reactivityinfluence their identification in the laboratory?{current_Depth-2_questions: [How can you identify an aldehyde using Tollens reagent?, Why does the carbonyl carbonin aldehydes have a significant partial positive charge? ]}### Generated complementary Depth-2 questions{complementary_Depth-2_questions: [How does the structure of ketones differ from that of aldehydes, and how does thisaffect their reactivity towards oxidation? ]} ## Example 4### Depth-3 question and current Depth-2 questionsIn the context of computer programming, why is branching unstructured? And is it a bad design choice?{current_Depth-2_questions: [What are the key differences between structured and unstructured branching in program-ming?, How does the goto statement work in computer programming? ]}### Generated complementary Depth-2 questions{complementary_Depth-2_questions: [What are the potential risks involved with using unstructured branching in largesoftware projects?, How does the structure of a program affect its maintainability?, How can the flow of execution in aprogram influence its debuggability? ]}",
  ": User prompt for augmenting D2 questions": "User prompt:## InstructionCreate {count} Depth-1 question(s) that complement current Depth-1 questions, which are necessary to correctly answer theprovided Depth-2 question.- Remember that Depth-1 questions are centered on basic recall of factual and conceptual knowledge. Depth-2 questions arecentered on application of procedural knowledge and skills.- Take into consideration the level of cognitive complexity required to solve the Depth-2 question, so that your generatedquestions fall under the description of Depth-1 appropriately.- Complement the existing Depth-1 questions with additional questions to ensure they collectively cover all necessaryprocedural knowledge and skills required to answer the Depth-2 question effectively.- Ensure that all of your generated Depth-1 questions do not directly answer to the given Depth-2 question.- Try to exclude Depth-1 questions that ask too generic or commonsense knowledge.- The number of all Depth-1 questions should not exceed 4.- The generated Depth-1 questions should be in JSON format: {complementary_Depth-1_questions: [list of Depth-1question strings]} ## Example 1### Depth-2 question and current Depth-1 questionsHow can the concept of algebraic closure be demonstrated using polynomial equations with complex roots?{current_Depth-1_questions: [What is the definition of algebraic closure?, What is a polynomial equation?, What arecomplex roots in the context of polynomial equations?]}### Generated complementary Depth-1 questions{complementary_Depth-1_questions: [How can complex roots be represented?]} ## Example 2### Depth-2 question and current Depth-1 questionsHow do you perform a convolution operation between two random variables?{current_Depth-1_questions: [What is a convolution operation?, What is a random variable?, How is the product oftwo functions calculated?]}### Generated complementary Depth-1 questions{complementary_Depth-1_questions: [What does it mean to integrate a function?]} ## Example 3### Depth-2 question and current Depth-1 questionsIn what ways can a decision trees structure be represented programmatically?{current_Depth-1_questions: [What is a decision tree in the context of programming?, What are the basic components ofa decision tree?]}### Generated complementary Depth-1 questions{complementary_Depth-1_questions: [What is a data structure in programming?, What does represented programmati-cally mean?]} ## Example 4### Depth-2 question and current Depth-1 questionsHow do neutrinos differ from other subatomic particles, and why are they considered potential candidates for dark matter?{current_Depth-1_questions: [What are neutrinos?, What are subatomic particles?]}### Generated complementary Depth-1 questions{complementary_Depth-1_questions: [What is dark matter?, What characteristics do particles need to be consideredcandidates for dark matter?]}",
  "System prompt:You are a fair judge assistant tasked with providing clear, objective feedback based on specific criteria, ensuring eachassessment reflects the absolute standards set for performance": "User prompt:###Task Description:An instruction (might include an Input inside it), a response to evaluate, and a score rubric representing a evaluation criteriaare given.1. Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating ingeneral.2. After writing a feedback, write a score that is an integer between 1 and 5. You should refer to the score rubric.3. The output format should look as follows: Feedback: (write a feedback for criteria) [RESULT ](an integer numberbetween 1 and 5)4. Please do not generate any other opening, closing, and explanations.",
  "###Reference Answer (Score 5):{reference_answer}": "###Score Rubrics:[Is the response correct, accurate, and factual? ]Score 1: The response is largely incorrect, inaccurate, and not factual. It demonstrates a fundamental misunderstanding of thequery or topic, leading to irrelevant or completely erroneous information.Score 2: The response is partially correct but contains significant inaccuracies or factual errors. It shows some understandingof the query or topic but fails to provide a fully accurate or reliable answer.Score 3: The response is generally correct and factual but may include minor inaccuracies or lack of detail. It shows a goodunderstanding of the query or topic but may miss some nuances or specific information.Score 4: The response is mostly correct, accurate, and factual. It demonstrates a strong understanding of the query or topic,with only minimal inaccuracies or omissions that do not significantly detract from the overall quality of the response.Score 5: The response is consistently correct, accurate, and entirely factual. It reflects a comprehensive understanding of thequery or topic, providing detailed, precise, and fully reliable information without any inaccuracies or omissions."
}