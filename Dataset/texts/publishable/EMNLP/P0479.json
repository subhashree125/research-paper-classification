{
  "Abstract": "Social intelligence is essential for understand-ing complex human expressions and social in-teractions.While large multimodal models(LMMs) have demonstrated remarkable perfor-mance in social intelligence question answer-ing (SIQA), they are still inclined to generateresponses relying on language priors and ig-noring the relevant context due to the domi-nant prevalence of text-based data in the pre-training stage. To interpret the aforementionedlanguage bias of LMMs, we employ a struc-ture causal model and posit that counterfactualreasoning can mitigate the bias by avoidingspurious correlations between LMMs internalcommonsense knowledge and the given con-text. However, it is costly and challenging toconstruct multimodal counterfactual samples.To tackle the above challenges, we propose anoutput Distribution Calibration network withVirtual Counterfactual (DCVC) data augmen-tation framework. DCVC devises a novel out-put distribution calibration network to mitigatethe impact of negative language biases whilepreserving beneficial priors. Perturbations areintroduced to the output distributions of LMMsto simulate the distribution shifts from coun-terfactual manipulations of the context, whichis employed to construct counterfactual aug-mented data virtually. Experiments on multipledatasets demonstrate the effectiveness and gen-eralizability of our proposed method.",
  "*Corresponding authors": ": An example in the Social-IQ-2.0 dataset. Theinput includes videos along with corresponding audioand subtitles. G.T. stands for the Ground-Truth answer.LMMs tend to select the incorrect answer (option Bin red) based on their social commonsense knowledgeobtained during pre-training. 2019a; Zadeh et al., 2019), including Social-IQ-2.0(Wilf et al., 2023), a multiple-choice QA datasetwith multimodal inputs(videos, audio and subti-tles). However, existing works often utilize andoptimize small models via modality feature align-ment and/or leveraging external knowledge (Xieand Park, 2023). Research on social intelligenceemploying Large Multimodal Models(LMMs) re-mains under-explored.To bridge this gap, we evaluate the performanceof two powerful LMMs, Video-LLaVA (Lin et al.,2023) and CREMA (Yu et al., 2024), on the Social-IQ-2.0 dataset. Experimental results () showthat LMMs demonstrate remarkable performanceunder the zero-shot setting due to their exceptionalcross-modal understanding and reasoning capabil-ities, achieving accuracy of 61.06% for Video-LLaVA and 63.33% for CREMA. Nevertheless,LMMs are prone to generating content frequentlyseen during their pre-training stage (correspondingto social commonsense knowledge in the LMMs)due to the different data scales between text-based pre-training and multimodal alignment (Pi et al.,2024). As shown in , despite the womanin the video laughed (G.T.) in response to hernot knowing the route, Video-LLaVA selected theincorrect answer based on the social commonsenseacquired during the text-based pre-training stage,which suggests that not knowing the route canmake her confused. Extra examples are shownin in Appendix B. To further assess thelanguage biases inherent in LMMs, we statisticallyanalyzed the mean output distributions of Video-LLaVA when responding to emotion-related ques-tions: the top 15 words with the highest outputprobabilities are shown in . It is evidentthat the output distributions with multimodal inputsclosely resemble those without context, yet theysignificantly differ from the answer proportions. Tomitigate such biases, Zhang et al. (2024) proposedto detach the output distribution of video-free in-puts to ensure that the LMMs generate responsesbased solely on the visual context. However, ben-eficial language priors have also been inevitablyremoved.To mitigate undesirable language biases whilepreserving beneficial priors, we propose an out-put Distribution Calibration network with VirtualCounterfactual data augmentation (DCVC). Specif-ically, we first employ a Structural Causal Model(SCM) (Pearl, 2009) to characterize the causal ef-fect for social intelligence QA, which denotes thatthe spurious correlation between LMMs and con-text can be avoided by counterfactual reasoning.Then, an output distribution calibration networkis employed to calibrate the output distribution ofLMMs adaptively. Furthermore, We expect furtherto mitigate the language bias of LMMs with coun-terfactual data augmentation. However, construct-ing multimodal counterfactual samples is challeng-ing and costly, especially for the complex videomodality. To efficiently construct counterfactualsamples, we propose a Virtual Counterfactual DataAugmentation (VCDA) framework to construct vir-tual counterfactual samples with flipped labels andfilter out the high-quality data. Perturbations areintroduced to the output distribution of LMMs tosimulate the shifts in distributions resulting fromcounterfactual manipulations of the context.Overall, our main contributions are as follows:",
  "Related works": "Multimodal Question Answering. MultimodalQuestion Answering aims to answer natural lan-guage questions given multiple input modalities,which requires multimodal understanding and com-monsense reasoning skills. Previous benchmarks(Antol et al., 2015; Xu et al., 2017; Jang et al.,2017) focus on visual facts such as location and ob-jects/attributes. In recent years, more benchmarks(Lei et al., 2018; Zellers et al., 2019; Sap et al.,2019b; Chen et al., 2024) have tended to tacklecommonsense and causal reasoning questions. Re-garding the existing methods, while earlier works(Cheng et al., 2023; Yu et al., 2021; Ye et al., 2023)concentrate on multimodal representation learn-ing and modality fusion, large vision-and-languagemodels align the multimodal feature to LLMs byinstruction tuning (Ko et al., 2023; Liu et al., 2023;Yu et al., 2024). Different from these works, wefurther examine the impact of language biases in LMMs and promote the performance of existingLMMs by adaptively calibrating such biases.Social Intelligence Learning. Social intelligenceis a long-standing research area within sociologyand psychology (Andreou, 2006; Daniel Goleman,2007). In recent years, the study of social intel-ligence has gained increasing momentum withinthe machine learning communities. Zadeh et al.(2019) propose a multimodal QA benchmark thatrequires understanding and reasoning skills of so-cial commonsense and human interaction. Bosse-lut et al. (2019) conduct an extensive investigationon the automated construction of social common-sense knowledge bases. Furthermore, Xie and Park(2023) propose to leverage emotional cues in so-cial interaction through contrastive learning. Whileprevious work on Social Intelligence has primar-ily focused on small, fine-tuned models, Our workconcentrates on evaluating and enhancing LMMs.Mitigating Biases in Large Language Models.Studies have been conducted to measure and miti-gate political and societal biases of machine learn-ing methods (Zhao et al., 2018; Bender et al., 2021).Recently, with the growing prevalence of large lan-guage models, multiple works have examined thebiases within these models (Zhou et al., 2023; Liet al., 2024). Zhang et al. (2024) have demonstratedthat the outputs of LMMs are primarily influencedby language priors, enabling them to provide con-fident answers even without visual input. Chenet al. (2024) initially employ fine-tuning based andchain-of-thought based methods to mitigate suchbias. Zhang et al. (2024) introduce Visual DebiasDecoding (VDD) strategies to redirect the modelsfocus toward vision information. Our work alsoadvances existing visual decoding strategies, adap-tively mitigating language biases in LMMs throughcalibrated adjustments to the output distribution.",
  "Method": "In this section, we describe our proposed DCVCframework for mitigating language bias of LMMs.In section 3.1, we introduce the Social Intelligencequestion-answering task (SIQA). In .2, aStructural Causal Model (SCM) (Pearl, 2009) isemployed to interpret the causal effect for socialintelligence QA, which demonstrates that counter-factual reasoning can mitigate the biases by avoid-ing the spurious correlations between LMMs andcontext. The next two sections show the specificdesign of our output distribution-based counterfac- tual reasoning approach, namely DCVC. In .3, we introduce a novel calibration network tocalibrate output distributions of LMMs adaptively.In .4, we describe the virtual counterfac-tual data augmentation method employed to trainthe calibration network to rectify language biases.",
  "Language Bias Analysis": "We formalize the causal effect for the Social Intelli-gence QA task via a Structure Causal Model (SCM)(Pearl, 2009). In , an SCM is depictedthrough a directed acyclic graph G = (V, E), whereedges in E represent the causal relationships be-tween key factors in SIQA, which are representedas nodes in V. The key factors include contextualfeatures X (i.e., the content of the input video),knowledge embodied in Large Multimodal ModelT, mediator variable M and the prediction Y. Thedetails of SCM are shown as follows:",
  "T X. The directed edge between T and Xindicates that X is encoded by LMM, and therepresentation of X inevitably integrates priorsderived from T": "X M T.M is a mediator variableblended with prior knowledge from LMM Tand contextual feature X. The paths among thevariables above denote that LMM encodes thecontextual feature and integrates prior knowl-edge of LMM (such as grammar rules or com-monsense knowledge) to generate responses. X Y M. The directed path X Y de-notes that the causal effect between X and Y isnot fully represented by the path X M Y . Because the existing LMMs cannot fullyrepresent all information contained in X. In-stead, LMM is inclined to generate responsesby utilizing social commonsense knowledge,rather than responding faithfully based on thecontext X. The mediation path Y M is alsoinevitable due to the aforementioned mecha-nism of existing LMM. : The overall architecture of our proposed output Distribution Calibration network with VirtualCounterfactual data augmentation (DCVC). The DC adaptively calibrates the output distribution of the LMM tomitigate undesirable language biases while preserving beneficial priors. Furthermore, virtual counterfactual dataaugmentation is employed to decouple spurious correlations between the LMM and the context.",
  ": (a) Causal graph for social intelligence QA. (b)Intervene on context X to mitigate spurious correlationrelated to LMM T": "Considering the SCM, it is hard for LMMs tocomprehensively capture the true causality betweenX and Y, as spurious correlation exits in these twopaths: T X and T M Y. Specifically,LLMs incorporate prior knowledge while encod-ing contextual features (T X) and generatingresponses (T M Y). While language priorsare essential for generating responses, excessiveincorporation of prior knowledge when encodingX is prone to lead to misunderstandings or neglectof the context. We propose that the spurious corre-lations can be avoided by blocking the back-doorpath X T M via the do() operation:",
  "Output Distribution Calibration Network": "To mitigate undesirable language biases while pre-serving beneficial priors, we propose an Output Dis-tribution Calibration Network (DC) to calibrate theoutput distribution of LMMs adaptively. As shownin , DC controls the output distributionof LMMs p(y|q, s, v, a) given the representationof q and language priors p(y|q). Specifically, thequestion and options q are fed into the pre-trainedmodel for encoding: hq = Encoder(q). Then,we calculate the element-wise product of the rep-resentation for each option with its correspondingoutput distribution and language priors to obtainthe weighted representations for each option:",
  "hq = Concat(hq p(y|q, v, s, a), hq p(y|q))(2)": "where hq denotes the weighted representations foreach option, p(y|q, v, s, a) denotes the output dis-tribution of LMM while p(y|q) denotes languagepriors. Finally, hq is fed into an MLP classifierwith softmax for output distribution calibration:fCal = softmax(hq W + b), where W and b arelearnable parameters.Through supervised training, DC is capable ofassessing the impact of language priors and adap-",
  "Virtual Counterfactual Augmentation": "To reiterate, the causal intervention operation canblock the back-door path X T M and encour-age causal inference. Inspired by previous works(Dong et al., 2023; Li et al., 2024), we propose toconstruct counterfactual augmented data to realizecausal intervention, i.e., inverting causal featuresthrough slight modifications to reverse the label.Specifically, we would like to construct counter-factual samples by slightly perturbing the inputvideo v, audio a, subtitle s in which way the labelis reversed.However, compared to text-based perturbations,it is exceedingly challenging and costly to constructmultimodal counterfactual samples for complexvideos. While there have been multiple prior worksin data augmentation for videos (Yun et al., 2020;Ding et al., 2022), they focus on the replacementand simple modification of image regions withinvideos, which is hard to be employed to performprecise adjustments to social interaction in videos.As a result, it remains to be explored how to pre-cisely modify videos for generating counterfactualdata.Inspired by the Virtual Data Augmentation(VDA) technique proposed by Zhou et al. (2021),we propose a Virtual Counterfactual Data Augmen-tation (VCDA) framework, as shown in ,to construct virtual counterfactual samples with flipped labels and filter for high-quality data. In-stead of being directly introduced to the input con-text, perturbations are introduced to the output dis-tributions p(y|q, v, s, a) and language biases p(y|q)of LMMs to simulate the shifts in distributions re-sulting from counterfactual manipulations of thecontext. This serves as an indirect and virtual coun-terfactual data augmentation. The augmented datawill be employed to train the calibration network topromote the calibration performance of the modelfurther.",
  "where is the location parameter and is the scaleparameter": "We sample a random variable with the same di-mension as p(y|q, v, s, a) from the Gumbel distri-bution, denoted as Zoutput Gumbel(, = 1).Similarly, Zpriors Gumbel(, = 0.1) with thesame dimension as p(y|q) is sampled. Then, thesignificantly perturbed distribution p(y|q, v, s, a)is obtained by shifting the original distributionp(y|q, v, s, a) by Zoutput, where denotes signifi-cant perturbation. To obtain the slightly perturbeddistribution p(y|q), where denotes minor pertur-bation, we shift the original distribution p(y|q) byZpriors with minor scale parameter. Intuitively,p(y|q) denotes minor perturbations to the questionand options q, namely p(y|q). Since the simul-taneous perturbation to q is minor, p(y|q, v, s, a)simulates the effect of applying significant pertur-bations to the video v, audio a and the subtitle s,namely p(y|q, v, s, a). As the Virtual Counterfactual Augmentation isunsupervised, we employed FlipDA proposed byZhou et al. (2022) to filter and retain high-qualityaugmented data. Specifically, we first train the cal-ibration network with original data. Then, virtualaugmented data will be generated with the afore-mentioned method. Next, we apply the trainedcalibration network as the data filter and select aug-mented samples with the highest probabilities forflipped labels. Finally, we retrain the DC with theoriginal and counterfactual augmented samples.",
  "Datasets": "To validate the language bias mitigation perfor-mance of our proposed DCVC method, we con-duct experiments on two social intelligence under-standing QA datasets: Social-IQ-2.0 (Wilf et al.,2023) and DeSIQ-2.0 (Guo et al., 2023). Addition-ally, NExT-QA (Xiao et al., 2021), a more general-purpose video QA dataset is employed to evaluatethe generalizability of DCVC.Social-IQ-2.0 is an improved version of Social-IQ (Zadeh et al., 2019) with multimodal, multiple-choice questions designed to evaluate the socialintelligence understanding capability of machinelearning models. The original video about humaninteractions, the corresponding extracted audio,and automatically generated transcripts are pro-vided. Guo et al. (2023) reveals that Social-IQ,as well as Social-IQ-2.0, contain significant biasin which the distinction between the representa-tions of correct and incorrect choices is readilydiscernible, regardless of the specific questions orcontexts. They introduce DeSIQ and DeSIQ-2.0,two corresponding debiased datasets constructedby applying simple but effective perturbations tothe original datasets. Detailed dataset statistics areshown in Appendix A in .NExT-QA (Xiao et al., 2021) is a rigorously de-signed video question answering (VideoQA) bench-mark to advance video understanding from the de-scription to the explanation of temporal actions andcausal reasoning. Causal questions account for ap-proximately half (48%) of the whole dataset whiletemporal questions compose 29% of the dataset.Detailed dataset statistics are shown in AppendixA in .",
  "Baselines": "We compare DCVC with both small and large mul-timodal language models (LMMs). The fine-tunedsmall models include RoBERTa-large (Liu et al.,2019), T5-small (Guo et al., 2023) and MMTC-ESC (Xie and Park, 2023). MMTC-ESC proposesto leverage emotional cues in social interactionsthrough contrastive learning and applies the cross-modal attention module to align multimodal repre-sentations, which achieves state-of-the-art (SOTA)performance. For video-capable LMMs, we em-ploy two recent, strong models: Video-LLaVA(Lin et al., 2023) and CREMA (Yu et al., 2024)in a zero-shot setting. Video-LLaVA (Lin et al., 2023) unifies visual representation into the lan-guage feature space to advance the foundationalLLM towards a unified LMM and achieves su-perior performances on a broad range of 9 mul-timodal benchmarks. CREMA (Yu et al., 2024)is an efficient and modular modality-fusion frame-work for injecting any new modality into video rea-soning and achieves better/equivalent performanceagainst strong LMMs with significantly fewer train-able parameters. Additionally, we also fine-tuneCREMA as a control. Visual Debias Decoding(VDD) Zhang et al. (2024) is a decoding strategythat introduces a calibration step to adjust the out-put distribution with that of the image-free input.We adapted VDD to make it applicable for socialintelligence QA and employed it as a baseline.",
  "Implementation Details": "We utilize the same instructions as Video-LLaVA toobtain output distributions. We set the temperatureto 0.1 for Video-LLaVA and set the beam size to5 for CREMA. For fine-tuning CREMA, Learningrate is set to 5e-5, and max training epoch is set to10. For our proposed DCVC, we employ RoBERTa-base (Liu et al., 2019) to encode q. The learningrate is set to 1e-5, and the weight decay is set to1e-2. We apply AdamW as an optimizer with abatch size of 16. Our experiments show optimalresults are achieved when is set to 0.1. For virtualcounterfactual data augmentation, we generate tensamples for each original sample. All experimentsare conducted on the 2 NVIDIA 4090 GPUs.",
  "Results and Analysis": "In this section, we validate the effectiveness of ourproposed DCVC through multiple experiments andconduct further analyses. In .1, the overallperformance of DCVC is compared against multi-ple baselines in Social-IQ-2.0 dataset and DeSIQ-2.0 dataset. In .2, ablation study is con-ducted to evaluate the effectiveness of each com-ponent. Afterward, we analyze the impact of thetype of noise for virtual counterfactual data aug-mentation in .3. Finally, we validate thegeneralizability of the output distribution calibra-tion network in .4.",
  ": Accuracy on the Social-IQ-2.0 and DeSIQ-2.0 development sets. The content in denotes the modalitiesof the model (q: question and answer options, s: subtitle, v: video, a: audio)": "Social-IQ-2.0 and 11.35 points on DeSIQ-2.0) andCREMA (by 14.45 points on Social-IQ-2.0 and9.65 points on DeSIQ-2.0). Moreover, CREMA, inthe zero-shot setting, when coupled with DCVC,achieves comparable performance with dataset-specific fine-tuned results.As previously mentioned, language biases inher-ent in the pre-training phase of language modelsnegatively impact LLMs performance on SIQA.To mitigate the biases, Visual Debias Decoding(VDD) directly detaches the output distribution ofvideo-free inputs to ensure that the LMMs generateresponses based solely on the visual context. Whileexcelling in mitigating hallucinations, the rathersimplistic calibration of VDD removes not only lan-guage biases but also the linguistic priors beneficialfor social intelligence reasoning (e.g., basic socialcommonsense). Consequently, the performance ofVDD, when applied to Video-LLaVA, exhibits amoderate decline compared with the baseline. Incomparison, our proposed DCVC framework mea-sures the extent of language bias based on the out-put probabilities. It employs an adaptive calibrationnetwork enhanced with virtual counterfactual aug-mentation, which achieves state-of-the-art (SOTA)performance (78.32% for Video-LLava and 77.78%for CREMA on Social-IQ-2.0).Surprisingly, Video-LLaVA achieved an accu-racy 85.69% on the DeSIQ-2.0 dataset, which issignificantly higher than the Social-IQ-2.0 dataset.This experimental result can be attributed to thefact that DeSIQ-2.0 directly replaces the options ofthe original samples with others from the dataset,rendering the option representations no longer dis-cernible. However, LMMs can easily distinguish : The performance of DCVC under varyingproportions of training data (30%, 60%, 90%, 100%) onthe Social-IQ-2.0 dataset. The orange segment in the barchart denotes the performance improvement achievedby incorporating VCDA. the substitute options based on the semantics of thequestion and options, as the new options, whichoriginate from other samples, often have a lowersemantic relevance to the question. Nonetheless,DCVC still demonstrates an improvement of 11.35points. We leave the construction of an unbiasedand more challenging dataset for evaluating LMMssocial intelligence understanding to future work.",
  "Ablation Study": "An ablation study of Video-LLaVA on the Social-IQ-2.0 and DeSIQ-2.0 dataset is conducted to val-idate the effectiveness of each component. Theresults are shown in . The tested modulesinclude: (1) VCDA: the virtual counterfactual dataaugmentation introduced in our work, (2) MSELoss: employed to mitigate the bias of primitiverepresentation of question and options, and (3) Cal-ibration Network: our proposed output Distribu-tion Calibration network. As can be seen in thetable, with the removal of each component, there",
  ": Ablation study (Accuracy) on the Social-IQ-2.0 and DeSIQ-2.0 dataset": "is a drop in model performance, demonstrating theeffectiveness of each component.From another perspective, The components areclosely interconnected and build upon each other.MSE loss alleviates the inherent biases present inthe calibration network. Virtual counterfactual dataaugmentation, a critical component for mitigatingthe language biases of LMMs, generates probabilis-tic augmented data that simulates perturbations inthe context. As it is exceedingly difficult to performactual data augmentation directly on video-relatedcontext, our virtual data augmentation approachprovides an efficient way to further optimize thecalibration network, resulting in better calibrationperformance.We also evaluate the performance of DCVC un-der varying proportions of training data (30%, 60%,90%, 100%) on the Social-IQ-2.0 dataset.Asdepicted in , the performance of Video-LLaVA with DCVC improved further with increas-ing training data. Notably, virtual counterfactualdata augmentation is more effective with less train-ing data. When only 30% of the training datawas utilized, the VCDA module achieved a perfor-mance enhancement of 2.48 points. Thus, DCVCis especially beneficial in the low-resource setting.",
  "Noise Selection Study": "We further investigated the impact of differenttypes of noise on the performance of our frame-work. The tested noise was sampled from threedistinct distributions, namely: (1) Gumbel, (2) Lo-gistic, and (3) Gaussian. As depicted in , allthree noises yield comparable performance, withGumbel noise demonstrating slightly better per-formance, which could be attributed to its bettersuitability for sampling from discrete distributions.",
  ": Generalizability analysis of the calibrationnetwork on the NExT-QA dataset. The evaluation metricis accuracy": "ibration network consistently yields performanceimprovements over the original LMMs. Whilefine-tuned CREMA already achieves a respectable71.6% accuracy, the calibration network still resultsin a 1-point increase. The performance gain is evenmore pronounced in the zero-shot setting, wherethe original model performance is lower. Com-pared to Social-IQ-2.0, the improvements offeredby the calibration network are relatively limited onNExT-QA. This experimental result can be partlyattributed to the fact that NExT-QA encompassesa more diverse range of question types, makingit more challenging for the calibration network toperform uniform calibration.",
  "Limitations": "We have only validated the effectiveness of the pro-posed method on multiple LMMs with 7b parame-ter scales. Experiments on LMMs of 13b and 33bare expected to be conducted in the future work.In addition, we have analyzed the causal effectsof language biases in LMMs through a structuralcausal model. However, the internal reasons forthe existence of biases and other biases in LMMsremain to be explored.",
  "Eleni Andreou. 2006. Social preference, perceived pop-ularity and social intelligence: Relations to overt andrelational aggression. In School Psychology Interna-tional, page 27(3):339351": "Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Mar-garet Mitchell, Dhruv Batra, C. Lawrence Zitnick,and Devi Parikh. 2015. VQA: visual question an-swering. In 2015 IEEE International Conferenceon Computer Vision, ICCV 2015, Santiago, Chile,December 7-13, 2015, pages 24252433. IEEE Com-puter Society. Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, and Shmargaret Shmitchell. 2021. On thedangers of stochastic parrots: Can language modelsbe too big? In FAccT 21: 2021 ACM Conference onFairness, Accountability, and Transparency, Virtual",
  "Daniel Goleman. 2007. Social intelligence. Randomhouse": "Shuangrui Ding, Maomao Li, Tianyu Yang, Rui Qian,Haohang Xu, Qingyi Chen, Jue Wang, and HongkaiXiong. 2022. Motion-aware contrastive video repre-sentation learning via foreground-background merg-ing. In IEEE/CVF Conference on Computer Visionand Pattern Recognition, CVPR 2022, New Orleans,LA, USA, June 18-24, 2022, pages 97069716. IEEE. Xiangjue Dong, Ziwei Zhu, Zhuoer Wang, Maria Teleki,and James Caverlee. 2023. Co2pt: Mitigating bias inpre-trained language models through counterfactualcontrastive prompt tuning. In Findings of the Associ-ation for Computational Linguistics: EMNLP 2023,Singapore, December 6-10, 2023, pages 58595871.Association for Computational Linguistics. Xiaoyu Guo, Yuan-Fang Li, and Reza Haf. 2023. Desiq:Towards an unbiased, challenging benchmark for so-cial intelligence understanding. In Proceedings ofthe 2023 Conference on Empirical Methods in Natu-ral Language Processing, EMNLP 2023, Singapore,December 6-10, 2023, pages 31693180. Associationfor Computational Linguistics. Yunseok Jang, Yale Song, Youngjae Yu, Youngjin Kim,and Gunhee Kim. 2017. TGIF-QA: toward spatio-temporal reasoning in visual question answering. In2017 IEEE Conference on Computer Vision and Pat-tern Recognition, CVPR 2017, Honolulu, HI, USA,July 21-26, 2017, pages 13591367. IEEE ComputerSociety. Dohwan Ko, Ji Soo Lee, Woo-Young Kang, ByungseokRoh, and Hyunwoo Kim. 2023. Large language mod-els are temporal and causal reasoners for video ques-tion answering. In Proceedings of the 2023 Confer-ence on Empirical Methods in Natural Language Pro-cessing, EMNLP 2023, Singapore, December 6-10,",
  "Bin Lin, Yang Ye, Bin Zhu, Jiaxi Cui, Munan Ning,Peng Jin, and Li Yuan. 2023. Video-llava: Learn-ing united visual representation by alignment beforeprojection. CoRR, abs/2311.10122": "Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong JaeLee. 2023. Visual instruction tuning. In Advances inNeural Information Processing Systems 36: AnnualConference on Neural Information Processing Sys-tems 2023, NeurIPS 2023, New Orleans, LA, USA,December 10 - 16, 2023. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,Luke Zettlemoyer, and Veselin Stoyanov. 2019.Roberta: A robustly optimized BERT pretrainingapproach. CoRR, abs/1907.11692.",
  "Renjie Pi, Tianyang Han, Wei Xiong, Jipeng Zhang,Runtao Liu, Rui Pan, and Tong Zhang. 2024.Strengthening multimodal large language modelwith bootstrapped preference optimization. CoRR,abs/2403.08730": "Maarten Sap, Hannah Rashkin, Derek Chen, Ronan LeBras, and Yejin Choi. 2019a. Social iqa: Common-sense reasoning about social interactions. In Proceed-ings of the 2019 Conference on Empirical Methodsin Natural Language Processing and the 9th Inter-national Joint Conference on Natural Language Pro-cessing, EMNLP-IJCNLP 2019, Hong Kong, China,November 3-7, 2019, pages 44624472. Associationfor Computational Linguistics.",
  "Conference on Computer Vision and Pattern Recog-nition, CVPR 2021, virtual, June 19-25, 2021, pages97779786. Computer Vision Foundation / IEEE": "Baijun Xie and Chung Hyuk Park. 2023. Multi-modalcorrelated network with emotional reasoning knowl-edge for social intelligence question-answering. InIEEE/CVF International Conference on ComputerVision, ICCV 2023 - Workshops, Paris, France, Octo-ber 2-6, 2023, pages 30673073. IEEE. Dejing Xu, Zhou Zhao, Jun Xiao, Fei Wu, HanwangZhang, Xiangnan He, and Yueting Zhuang. 2017.Video question answering via gradually refined at-tention over appearance and motion. In Proceedingsof the 2017 ACM on Multimedia Conference, MM2017, Mountain View, CA, USA, October 23-27, 2017,pages 16451653. ACM. Qinghao Ye, Guohai Xu, Ming Yan, Haiyang Xu,Qi Qian, Ji Zhang, and Fei Huang. 2023. Hitea: Hier-archical temporal-aware video-language pre-training.In IEEE/CVF International Conference on ComputerVision, ICCV 2023, Paris, France, October 1-6, 2023,pages 1535915370. IEEE. Fei Yu, Jiji Tang, Weichong Yin, Yu Sun, Hao Tian, HuaWu, and Haifeng Wang. 2021. Ernie-vil: Knowledgeenhanced vision-language representations throughscene graphs. In Thirty-Fifth AAAI Conference onArtificial Intelligence, AAAI 2021, Thirty-Third Con-ference on Innovative Applications of Artificial In-telligence, IAAI 2021, The Eleventh Symposium onEducational Advances in Artificial Intelligence, EAAI2021, Virtual Event, February 2-9, 2021, pages 32083216. AAAI Press.",
  "Sangdoo Yun, Seong Joon Oh, Byeongho Heo, Dongy-oon Han, and Jinhyung Kim. 2020. Videomix: Re-thinking data augmentation for video classification.CoRR, abs/2012.03457": "Amir Zadeh, Michael Chan, Paul Pu Liang, EdmundTong, and Louis-Philippe Morency. 2019. Social-iq: A question answering benchmark for artificialsocial intelligence. In IEEE Conference on Com-puter Vision and Pattern Recognition, CVPR 2019,Long Beach, CA, USA, June 16-20, 2019, pages 88078817. Computer Vision Foundation / IEEE. Rowan Zellers, Yonatan Bisk, Ali Farhadi, and YejinChoi. 2019. From recognition to cognition: Visualcommonsense reasoning. In IEEE Conference onComputer Vision and Pattern Recognition, CVPR2019, Long Beach, CA, USA, June 16-20, 2019, pages67206731. Computer Vision Foundation / IEEE.",
  "Yi-Fan Zhang, Weichen Yu, Qingsong Wen, Xue Wang,Zhang Zhang, Liang Wang, Rong Jin, and Tieniu Tan.2024. Debiasing multimodal large language models.CoRR, abs/2403.05262": "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Or-donez, and Kai-Wei Chang. 2018. Gender bias incoreference resolution: Evaluation and debiasingmethods. In Proceedings of the 2018 Conferenceof the North American Chapter of the Associationfor Computational Linguistics: Human LanguageTechnologies, NAACL-HLT, New Orleans, Louisiana,USA, June 1-6, 2018, Volume 2 (Short Papers), pages1520. Association for Computational Linguistics. Jing Zhou, Yanan Zheng, Jie Tang, Li Jian, and ZhilinYang. 2022. Flipda: Effective and robust data aug-mentation for few-shot learning. In Proceedings ofthe 60th Annual Meeting of the Association for Com-putational Linguistics (Volume 1: Long Papers), ACL2022, Dublin, Ireland, May 22-27, 2022, pages 86468665. Association for Computational Linguistics. Kun Zhou, Wayne Xin Zhao, Sirui Wang, FuzhengZhang, Wei Wu, and Ji-Rong Wen. 2021. Virtualdata augmentation: A robust and general frameworkfor fine-tuning pre-trained models. In Proceedingsof the 2021 Conference on Empirical Methods inNatural Language Processing, EMNLP 2021, Vir-tual Event / Punta Cana, Dominican Republic, 7-11November, 2021, pages 38753887. Association forComputational Linguistics."
}