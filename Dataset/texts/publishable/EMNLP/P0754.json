{
  "Abstract": "Entity matching is the task of linking recordsfrom different sources that refer to the samereal-world entity.Past work has primarilytreated entity linking as a standard supervisedlearning problem. However, supervised entitymatching models often do not generalize wellto new data, and collecting exhaustive labeledtraining data is often cost prohibitive. Further,recent efforts have adopted LLMs for this taskin few/zero-shot settings, exploiting their gen-eral knowledge. But LLMs are prohibitivelyexpensive for performing inference at scale forreal-world entity matching tasks. As an efficient alternative, we re-cast entitymatching as a conditional generation task as op-posed to binary classification. This enables usto distill LLM reasoning into smaller entitymatching models via natural language expla-nations. This approach achieves strong perfor-mance, especially on out-of-domain generaliza-tion tests (10.85% F-1) where standalone gen-erative methods struggle. We perform ablationsthat highlight the importance of explanations,both for performance and model robustness.",
  "Introduction": "Entity matching, also known as record linkage ordata deduplication, refers to matching records fromdifferent sources which refer to the same underly-ing entity, in the absence of unique identifiers. Thisis a practically important task across a diverse setof domains, e.g., database management, healthcare,customer relationship management, and financialservices; in such applications, normalizing entitiesto realize a unified view of data is imperative.Most prior work on entity matching has adoptedsupervised techniques, training a model to linkentities within a particular domain. Performingpair-wise comparison on all record pairs is com-putationally prohibitive, especially on large scale",
  ": An example of the generalization problem inentity matching: A model trained on a dataset of com-puters (e.g., WDC-Computers) is tested on instancestaken from a corpus comprising shoes (WDC-Shoes)": "datasets; typical entity resolution pipelines there-fore perform blocking followed by matching (Liet al., 2020; Wang et al., 2023a). The former stepentails identifying candidate record pairs whichmay reference the same entity, while in the latterone attempts to infer whether this candidate is in-deed a match.Assuming a supervised setting for this task islimiting in a few key ways. First, collecting hu-man supervision is inherently expensive. Secondand relatedly, training an entity matching model inone domain (in this work, a domain is a prod-uct category) via explicit supervision will yield amodel which is unlikely to readily transfer to otherdomains. For example, a model trained to matchcamera models based on descriptions is unlikely togeneralize well to linking laptops (nevermind non-electronics). But collecting annotations linkingproducts in all possible categories is not feasible. This has motivated work on transferable modelsfor entity matching across domains (Trabelsi et al.,2022; Tu et al., 2022c,a; Chai et al., 2023).One way to address the generalization prob-lem may be to use general-purpose LLMs zero-shot, via prompting and/or lightweight fine-tuning.Given the generality of such models, it is intuitivethat they may be more robust to domain shifts whenmatching entities. Moreover, an as-yet unexploredpotential benefit of LLMs for this task is their abil-ity to provide (natural language) reasoning fortheir outputs; this may permit fast manual verifica-tion of linkages, and therefore instill confidence inmodel outputs. Aside from this, we later show thatthe richer signal in generated label rationales (orexplanations) allows for improved model distilla-tion, consistent with recent findings on other tasks(Ho et al., 2022).A downside of LLMs is inference cost; applyingsuch models to very large datasetsand contin-uously to new data as it is producedis expen-sive. A comparatively tiny database with just one-thousand entities can yields a million (1k 1k)candidate pairs, translating to thousands of dollarsin inference costs.1 We therefore explore model dis-tillation for entity matching. In particular, we elicitreasoning alongside outputs for entity matchingtasks from massive LLMs, and use this to traina modestly sized LM for entity matching suchthat it can also provide supporting rationales.2 Weshow that despite its small size, the resultant modelachieves strong performance. Moreover, our abla-tions highlight the importance of rationalization forrobust entity matching, i.e., generalization.Our contributions are as follows. (1) We frameentity matching as a conditional generation task andshow that relatively small seq2seq models performcomparably to non-generative models when testedon in-domain instances. However, both approachessuffer significant loss in performance when testedon out-of-domain instances. (2) We show howaugmenting entity matching training datasets withchain-of-thought style reasoning (explanations) ob-tained from larger models results in significantgains on out-of-domain instances. (3) We performcomprehensive ablations on LLM-generated ex-planations to tease out which aspects of these ex-planations affect downstream model performance. 1openai.com/pricing2This is a type of distillation, but differs from traditionalapproaches (Hinton et al., 2015) in that we are distilling onlyreasoning abilities, and not capabilities on the task itself.",
  "Data": "We use 9 publicly available entity matchingdatasets (Kpcke et al., 2010; Konda et al., 2016)used for evaluation in similar prior work (Li et al.,2020; Peeters and Bizer, 2023a). These datasetsspan several domains, allowing us to assess out-of-domain performance by testing a model trainedon one type of data on examples from a another.Each dataset contains entity pairs from structuredtables. We follow the input linearization strategyand train/validation/test splits from Li et al. (2020).Under this linearization scheme each input can-didate entity pair is serialized as a sequence oftokens:",
  "Training Data": ": We propose augmenting binary labeled (BL) training data of entity matching datasets with Chain-of-Thought style natural language explanations from large models before fine-tuning smaller, more robust generativemodels. We use the time needed to generate explanation-augmented (EA) training data on a typical Amazon EC2P3 instance as a proxy for cost in case of Mistral (Jiang et al., 2023) and Alpaca (Taori et al., 2023) models, and thetotal cost of OpenAIs API usage in case of GPT-* models. Using this approach, we realize significant performancegains in a variety of out-of-domain test settings.",
  "DITTO (Li et al., 2020) follows a non-generative ap-proach and therefore does not require linearized strings asoutput targets": "from zero/ICL few-shot experiments using muchlarger generative models (1B+ parameters) in Ap-pendix E. However, deploying such large models atscale would be prohibitively expensive. Therefore,we focus on smaller models in this work.To quantify performance on out-of-domain data,we consider three experimental settings represen-tative of practical conditions under which entitymatching models may be deployed.Cross Domain Train the model on entity pairsbelonging to one domain (e.g., consumer electron-ics products) and test its performance on anotherdomain (e.g., shoes). Training on the Amazon-Google dataset and testing model performance onWDC-Shoes is one example of this setting.Cross Schema Entities in the test data may havedifferent attributes, not seen in training, even if thedata is from the same domain and derived from thesame source. Datasets used to test cross-schema ro-bustness are not mutually exclusive from (and mayoverlap with) cross-domain train-test data pairs.",
  "WDC-AllAbt-Buy69.1676.5876.447.28Amazon-Google46.1256.1259.1313.01Walmart-Amazon64.0975.5576.3712.28": ": Comparison of FlanT5-base performance when trained without (BL) and with explanation-augmented(EA) training data. Broadly, we observe significant gain in model performance when trained with chain-of-thoughtstyle explanations elicited from large language models. Cross Distribution Train and test the model on thesame domain (e.g., consumer electronics products)but on entity pairs derived from different sources.For example: Train on Walmart-Amazon dataset,test on the entity pairs of Abt-Buy data. In every setting we observe, unsurprisingly,degraded model performance (F-1(BL) in ) compared to in-domain test sets ().For instance, a model trained on a dataset ofWDC-Cameras suffers a drop of 15 points whentested on a dataset of WDC-Computers. We pro-vide additional results in Appendix D for non-generative models under this cross testing frame-work. Broadly, consistent with prior work (Tu et al.,2022b), we find that non-generative models farepoorly when tested on out-of-domain data.We emphasize here that the aforementioned set-tings frequently occur and are a representative ofthe practical use-cases of entity matching models.It is often cost-prohibitive to collect and annotatedata in large volumes for training domain, distribu-",
  "Eliciting explanations from LLMs toimprove smaller LMs": "To improve out-of-domain model performance un-der our testing framework, we propose augment-ing the binary labeled training data (BL) used tofine-tune small generative models with Chain-of-Thought (CoT) style reasoning explanations (Weiet al., 2022) elicited from much larger languagemodels Mistral-Instruct (Jiang et al., 2023) and Al-paca (Taori et al., 2023). We call this explanation-augmented training data (EA).We use ICL few-shot prompting strategy to elicitmeaningful generalizable CoT-style explanationsgiven a pair of input entities and their correspond-ing matching label. Consider the following illustra-tive example from the WDC-Shoes dataset used asa prompt to elicit a CoT-explanation.",
  "Input [entitya] [COL] <Title> [VAL] Nike AirJordans 2007 ... [entityb] [COL] <Title> Air": "Jordans by Nike [COL] <MANUF_YEAR> [VAL] 2007...TargetMatch [explanation] Both entities referto Nike Air Jordans from 2007, therefore theyrea match.Input [entitya] [COL] <Title> [VAL] New Balance1080 Running [COL] <MANUF_YEAR> [VAL] 2016 ...[entityb] [COL] <Title> NB Fresh Foam X 1080v13[COL] <MANUF_YEAR> [VAL] 2016 ...TargetMatch [explanation] The actual prompts we use consist of two ICLexamples (one for each target label type), in ad-dition to the new instance for which we want themodel to generate an explanation. An author ofthis paper wrote the explanations for the two ICLexamples used in the prompt. We reproduce theseprompts in their entirety in Appendix C. For gen-erating CoT-style explanations we used publiclyavailable checkpoints for both Mistral-7B-Instruct4 and Alpaca.5 We generated explanations with amaximum length of 128 tokens (minimum of 5 to-kens) with topk sampling (k = 50) and nucleussampling (p = 0.95). For every dataset, we foundthat generating explanations took approximately2-5 seconds for Mistral-7B-Instruct, and 7-12 sec-onds on Alpaca-based models.We consider these model generated CoT-styleexplanations analogous to summaries generatedby a model given entity text and a correspondingmatching label. We then use these explanations tofine-tune a smaller model (FlanT5-base in our case)and observe considerable gains in cross-domain,cross-schema, and cross-distribution performance(). We find on average the F-1 score un-der cross-schema setting increases by 22.32, whilefor cross-domain and cross-distribution setting theaverage F-1 score increases by 14.47 and 13.67 re-spectively. In some instances (e.g., a model trainedon WDC-Computers tested on WDC-Cameras),we observe that augmenting the training set withCoT-style explanations enables OOD performancecomparable to in-domain performance6.",
  "Substituted: contour fix nap egregious textnimble perhaps": "The aim is to assess whether it is the presence ofmeaningful text (rather than any text) that leads toperformance gains under the above settings. Aggre-gate performance under Ablation A drops 28.17%,and this is consistent across train-test pairs. B. Random Token-DropWe alter the LLM-generated explanations by reducing their length.We start by removing all stop-words from the ex-planation, then randomly drop tokens to furtherreduce its length until we reduce the total lengthby half (50%). In the running example, the LLM-generated explanation might be replaced by thefollowing text",
  "Aggregate comparison against F-1 (EAMistral)26.995.575.6914.354.98": ": Comparison of FlanT5-base performance when LLM-generated explanations used during model trainingare ablated under various conditions A. Junk text substitution, B. Random reduction in length, C. TF-IDF reductionin length, D. Substitution with non-instance specific explanation, E. Random corruption of tokens in explanation. as documents, and LLM-generated explanationsas a summary of these. We then sample tokensfrom the explanation based on the TF-IDF scoresof individual tokens until we retain 50% of theoriginal length of the explanation. In the runningexample, the LLM-generated explanation might bereplaced by the following text:",
  "use the following manually written explanations:": "WDC-Cameras Based on the description of twocameras in Entity A and Entity B, they are (orare not) a match.WDC-ShoesBased on the color, brand, size andmake of the two shoes in Entity A and Entity Brespectively, they are (or are not) a match.iTunes-AmazonBased on the artist, genre andsong titles, the two entities here are (or arenot) a match.",
  "tion is modified to:": "Substituted: While <unk> <unk> <unk> to<unk> <unk> <unk> <unk> hard drive, <unk><unk> A specifically refers <unk> 3 <unk>SATA III <unk> 3.5 <unk> <unk> <unk> <unk>ity B refers <unk> <unk> drive <unk> <unk><unk> <unk> <unk> Network <unk> <unk> d<unk> (NAS) <unk> therefore <unk> are not<unk> <unk> match <unk> While we observe a performance difference on av-erage (), these differences are inconsistentacross settings, contrary to our other ablation re-sults. For instance, under cross-domain settingfor WDC-Cameras WDC-Computers, we observethat Ablation E outperforms both Ablations B andC and is comparable to using unaltered explana-tions. However, under a cross-schema setting foriTunes-Amazon Walmart-Amazon, ablation Eperforms substantially worse than using unalteredexplanations. We leave a more comprehensive anal-ysis of this behavior for future work.In addition to ablations AE, we conduct twoadditional experiments with human-interventionsto test (1) robustness of models trained with aug-mented data; and (2) faithfulness of the generatedreasoning explanations themselves. Because wegenerate tens of thousands of explanations (i.e., in-stance specific explanations for the entire trainingset for every dataset), collecting human annota-tions on all instances is cost prohibitive. Instead,we manually select 300 instances from the Abt-Buydataset to conduct the following two tests.",
  "H1 Test of RobustnessFirst, we test robust-ness by randomly selecting 300 entity pairs with a": "match label from the test set. We then make mini-mal changes to the entity data (descriptions) to con-vert a matched to a non-matched pair. Thesechanges are quite minimal, often involving only atoken or two (e.g., NikeAdidas) while retaininga majority of token overlap between the entity pairdescriptions. This intervention is motivated by thefact that matching models may over-rely on tokenoverlap to classify whether or not the entity pairis match, and whether a trained model is robust tominor perturbations when tested on in-domain data.Consider the following example:",
  "Edited: [entitya] Kingston 128GB DataTraveler G3USB 3.1 Flash drive [entityb] Kingston 32G DT G3USB 3.1 Flash DriveCorrected LabelNot a Match": "Here we have minimally changed the storage ca-pacity of two USB Flash Drives manufactured bythe same company, under the same brand/model.We then run these substituted instances throughour models trained both with and without LLM-augmented explanations. Our goal here is was totest what percentage of labels correctly flip frommatch to no-match in both instances. Weremotivated to test this aspect of robustness to deter-mine the degree to which smaller trained modelsrely on raw token overlap vs the reasoning in LLM-generated explanations.For the models trained without explanations, wefind that 71/300 (23%) of labels flip, while for themodels trained with LLM-augmented explanations,we find that 164/300 (54%) labels successfully flipto a non-match; this indicates that augmented rea-soning in training data makes smaller models morerobust to subtle but critical input perturbations. H2 Test of FactualityFinally, we investigate theextent to which LLM-generated explanations relateto the underlying entity pair descriptions. To thisend we consider generated explanations as analo-gous to document summaries, i.e., we consider theinput entity pair descriptions and their matchinglabel as a document, and treat the model generatedexplanation of the summary. We then annotatethese explanations for inconsistencies.Three authors of this paper serve as human an-notators and we use the Amazon Mechanical Turk(MTurk) sandbox as our preferred annotation plat-form. For every instance, we ask annotators the",
  "Extrinsic ErrorsDoes the explanationcontain information in excess of theentity descriptions and theircorresponding matching labels? Theseinconsistencies are often calledhallucinations": "We collected three annotations per instance andtake the majority vote as reference where thereis not unanimous agreement. We find that 10.9%of instances contain instrinsic errors, and 15.1%of explanations contain elements unsupported byinputs (hallucinations). We observe an inter-rateragreement (Fleisss ) of 0.75 for the question oninstrinsic errors and an agreement of 0.86 on thequestion of extrinsic errors. We provide details onthe annotation interface in Appendix F.",
  "Deep learning in Entity Resolution": "With respect to entity resolution, the core processinvolves pairwise comparisons to ascertain match-ing entities. Recent efforts have capitalized on neu-ral methods (including LLMs), including DeepER(Ebraheem et al., 2018), a deep learning-basedframework, and DeepMatcher (Mudgal et al.,2018), which exemplifies the integration of deeplearning in entity matching. Additionally, activelearning strategies have been adapted for entity res-olution as detailed in (Kasai et al., 2019).OthersignificantcontributionsincludeSeq2SeqMatcher (Nie et al., 2019; Wang andZhang, 2024), focusing on sequence-to-sequencematching, and HierMatcher (Fu et al., 2021),which adopts a hierarchical approach. The useof pre-trained language models has also gainedtraction, as evidenced by methods such as R-SupCon, Ditto, Rotom, and Sudowoodo, discussedin various studies (Brunner and Stockinger, 2020;Peeters et al., 2020; Li et al., 2021; Miao et al.,2021; Wang et al., 2023b, 2024; Zeakis et al., 2023;Genossar et al., 2023). These methods collectivelyrepresent the cutting-edge techniques in the realmof entity matching.",
  "Reasoning in LLMs": "Most recently, Entity Matching via LLMs hasshown promising results (Peeters and Bizer,2023c,b; Fan et al., 2024). In these works, bothzero-shot and fine-tuning approaches have been ex-plored. Beyond entity matching, in-context learn-ing (ICL) with LLMs has become a dominant strat-egy, enabling these models to perform tasks withtask conditioning and minimal task demonstrations(Brown et al., 2020; Xie et al., 2021). This ap-proach has demonstrated strong performance (Zhaoet al., 2021; Liu et al., 2021) and streamlined ex-perimentation with LLMs, as it eliminates the needfor model training. However, the adoption of ICLhas highlighted the sensitivity of LLMs to promptselection (Lu et al., 2021; Margatina et al., 2023),making prompt engineering for various tasks a chal-lenging and time-consuming process. Nonetheless,data-driven signals, such as selecting semanticallysimilar demonstrations using text retrievers, haveproven to be effective (Lu et al., 2021; Margatinaet al., 2023), offering a more systematic approachto prompt engineering.Chain-of-Thought (CoT) reasoning (Wang et al., 2022; Hoffmann et al., 2022; Chowdhery et al.,2022) has lately emerged as a means to allow LLMsto better perform certain tasks. This approachwhich can be elicited via prompting few-shot ex-amples (Kojima et al., 2022)involves guidingLLMs to generate a sequence of intermediate rea-soning steps. Recent efforts have demonstratedthe benefits of distilling reasoning capabilities insmaller LMs (Shridhar et al., 2023; Wadhwa et al.,2023); our results contribute to this line of work.",
  "Conclusions": "We proposed a novel model distillation approach totrain a small, more-robust model for generalizableentity matching. Eliciting target label rationalesfrom LLMs enables transfer of grounded reason-ing to the smaller models. Our experiments showthis translates to strong performance in diverse set-tings, outperforming existing models designed fordomain adaptation that struggle to generalize. Ab-lation studies provide insight into the importance ofexplanation generation for achieving robust match-",
  "Limitations": "We have shown that augmenting training data usedto train smaller models with natural language expla-nations elicited from much larger models can yieldsubstantial improvements in out-of-domain test set-tings. We then assessed the quality and usefulnessof said explanations through automated ablations.Finally, we conducted human annotations on a sam-ple of these explanations to quantify error they maycontain.There are some important limitations to thesefindings.First, we have considered training amodel on one domain (or distribution/schema), andthen testing it on a set of N 1 datasets to eval-uate model performance in an OOD setting. This(somewhat extreme) setting sharply exemplifies thesort of domain shift we are interested in studying.But we have not comprehensively considered themore traditional OOD setting of training on N 1datasets, and testing on the held out domain (distri-bution/schema), except while training on WDC-Alland testing on Abt-Buy,Amazon-Google, andWalmart-Amazon. However, even under the lim-ited circumstances we considered, we saw substan-tial gains in OOD performance (10.86 F-1).Second, we rely on LLM-generated reasoningexplanations to augment our training data. Thisdependence on externally hosted, proprietary largemodels could be problematic in certain sensitivedomains, for example when working with entitydescriptions that contain personally identifiable in-formation (PII) since there is an extensive bodyof prior research (Hossain et al., 2023; Prakashand Lee, 2023) documenting social biases inher-ent to LLMs. That said, this dependence is onlyfor training data, and one could conceivably useopen source LLMs, like we have, capable of CoTin place of proprietary models (e.g. OpenAI).Third, while we find that distilling CoT-styleexplanations meaningfully improves small LM per-formance, our attempts to evaluating the usefulnessof said explanations (if any) will require substantialfuture work. Our ablations do not provide a clearanswer as to which aspects of these explanationsare useful for downstream performance improve-ments. For instance, in ablation D we use a con-stant non-instance specific explanation appendedto all target outputs (as opposed to instance spe-cific explanation generated from a LLM). In theory, this provides no meaningful ability to classify agiven instance over say, junk text. However, westill observe some gains in downstream OOD testperformance.Lastly, we only experiment with datasets curated(and sourced) in English and therefore we do nothave any insight into the issues that may result inother languages.",
  "Ethical Considerations": "Statement of Intended UseOur work broadlyrelies on open-source datasets derived from e-commerce platforms, where entity attributes con-sist of heterogeneous descriptive sentences of com-mon everyday consumer products. However, incertain applications of entity resolution like cus-tomer profile de-duplication, where entity descrip-tors involve human population-level attributes, theunderlying data must be appropriately de-identified(i.e. anonymized) in the interest of individual pri-vacy. As stated in limitations, we make no attemptto manually edit/oversee the LLM-generated expla-nations before using them to train smaller LMs, andtherefore there is a downstream risk of propagatinglarge model biases. Ebtesam Almazrouei, Hamza Alobeidli, Abdulaziz Al-shamsi, Alessandro Cappelli, Ruxandra Cojocaru,Merouane Debbah, Etienne Goffinet, Daniel Hes-low, Julien Launay, Quentin Malartic, BadreddineNoune, Baptiste Pannier, and Guilherme Penedo.2023. Falcon-40B: an open large language modelwith state-of-the-art performance. Tom Brown, Benjamin Mann, Nick Ryder, MelanieSubbiah, Jared D Kaplan, Prafulla Dhariwal, ArvindNeelakantan, Pranav Shyam, Girish Sastry, AmandaAskell, et al. 2020. Language models are few-shotlearners. Advances in neural information processingsystems, 33:18771901.",
  "Chengliang Chai, Nan Tang, Ju Fan, and Yuyu Luo.2023. Demystifying artificial intelligence for datapreparation. In Companion of the 2023 InternationalConference on Management of Data, pages 1320": "Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,Maarten Bosma, Gaurav Mishra, Adam Roberts,Paul Barham, Hyung Won Chung, Charles Sutton,Sebastian Gehrmann, et al. 2022. Palm: Scalinglanguage modeling with pathways. arXiv preprintarXiv:2204.02311. Hyung Won Chung, Le Hou, Shayne Longpre, BarretZoph, Yi Tay, William Fedus, Yunxuan Li, XuezhiWang, Mostafa Dehghani, Siddhartha Brahma, Al-bert Webson, Shixiang Shane Gu, Zhuyun Dai,Mirac Suzgun, Xinyun Chen, Aakanksha Chowdh-ery, Alex Castro-Ros, Marie Pellat, Kevin Robinson,Dasha Valter, Sharan Narang, Gaurav Mishra, AdamsYu, Vincent Zhao, Yanping Huang, Andrew Dai,Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Ja-cob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le,and Jason Wei. 2022. Scaling instruction-finetunedlanguage models.",
  "Tamanna Hossain, Sunipa Dev, and Sameer Singh. 2023": "MISGENDERED: Limits of large language modelsin understanding pronouns. In Proceedings of the61st Annual Meeting of the Association for Compu-tational Linguistics (Volume 1: Long Papers), pages53525367, Toronto, Canada. Association for Com-putational Linguistics. Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-sch, Chris Bamford, Devendra Singh Chaplot, Diegode las Casas, Florian Bressand, Gianna Lengyel, Guil-laume Lample, Lucile Saulnier, Llio Renard Lavaud,Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,Thibaut Lavril, Thomas Wang, Timothe Lacroix,and William El Sayed. 2023. Mistral 7b.",
  "Jungo Kasai, Kun Qian, Sairam Gurajada, Yunyao Li,and Lucian Popa. 2019. Low-resource deep entityresolution with transfer and active learning. In ACL": "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-taka Matsuo, and Yusuke Iwasawa. 2022. Large lan-guage models are zero-shot reasoners. Advances inneural information processing systems, 35:2219922213. Pradap Konda, Sanjib Das, Paul Suganthan G. C., An-Hai Doan, Adel Ardalan, Jeffrey R. Ballard, HanLi, Fatemah Panahi, Haojun Zhang, Jeff Naughton,Shishir Prasad, Ganesh Krishnan, Rohit Deep, and Vi-jay Raghavendra. 2016. Magellan: Toward buildingentity matching management systems. Proc. VLDBEndow., 9(12):11971208.",
  "Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, YannDubois, Xuechen Li, Carlos Guestrin, Percy Liang,and Tatsunori B. Hashimoto. 2023. Stanford alpaca:An instruction-following llama model": "Yi Tay, Mostafa Dehghani, Vinh Q. Tran, XavierGarcia, Jason Wei, Xuezhi Wang, Hyung WonChung, Siamak Shakeri, Dara Bahri, Tal Schuster,Huaixiu Steven Zheng, Denny Zhou, Neil Houlsby,and Donald Metzler. 2023. Ul2: Unifying languagelearning paradigms. Mohamed Trabelsi, Jeff Heflin, and Jin Cao. 2022.Dame: Domain adaptation for matching entities. InProceedings of the Fifteenth ACM International Con-ference on Web Search and Data Mining, pages 10161024. Jianhong Tu, Ju Fan, Nan Tang, Peng Wang, ChengliangChai, Guoliang Li, Ruixue Fan, and Xiaoyong Du.2022a. Domain adaptation for deep entity resolution.In Proceedings of the 2022 International Conferenceon Management of Data, pages 443457. Jianhong Tu, Ju Fan, Nan Tang, Peng Wang, ChengliangChai, Guoliang Li, Ruixue Fan, and Xiaoyong Du.2022b. Domain adaptation for deep entity resolu-tion. In Proceedings of the 2022 International Con-ference on Management of Data, SIGMOD 22, page443457, New York, NY, USA. Association for Com-puting Machinery. Jianhong Tu, Xiaoyue Han, Ju Fan, Nan Tang,Chengliang Chai, Guoliang Li, and Xiaoyong Du.2022c. Dader: hands-off entity resolution with do-main adaptation. Proceedings of the VLDB Endow-ment, 15(12):36663669.",
  "Somin Wadhwa, Silvio Amir, and Byron Wallace. 2023": "Revisiting relation extraction in the era of large lan-guage models. In Proceedings of the 61st AnnualMeeting of the Association for Computational Lin-guistics (Volume 1: Long Papers), pages 1556615589, Toronto, Canada. Association for Computa-tional Linguistics. Runhui Wang, Luyang Kong, Yefan Tao, Andrew Borth-wick, Davor Golac, Henrik Johnson, Shadie Hijazi,Dong Deng, and Yongfeng Zhang. 2024. Neurallocality sensitive hashing for entity blocking. In Pro-ceedings of the 2024 SIAM International Conferenceon Data Mining (SDM), pages 887895. SIAM. Runhui Wang, Yuliang Li, and Jin Wang. 2023a. Su-dowoodo: Contrastive self-supervised learning formulti-purpose data integration and preparation. In2023 IEEE 39th International Conference on DataEngineering (ICDE), pages 15021515. IEEE.",
  "Runhui Wang, Yuliang Li, and Jin Wang. 2023b.Sudowoodo: Contrastive self-supervised learningfor multi-purpose data integration and preparation.ICDE": "Runhui Wang and Yongfeng Zhang. 2024. Pre-trainedlanguage models for entity blocking: A reproducibil-ity study. In Proceedings of the 2024 Conference ofthe North American Chapter of the Association forComputational Linguistics: Human Language Tech-nologies (Volume 1: Long Papers), pages 87128722. Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le,Ed Chi, Sharan Narang, Aakanksha Chowdhery, andDenny Zhou. 2022. Self-consistency improves chainof thought reasoning in language models.arXivpreprint arXiv:2203.11171. Jason Wei, Xuezhi Wang, Dale Schuurmans, MaartenBosma, Ed Huai hsin Chi, F. Xia, Quoc Le, andDenny Zhou. 2022. Chain of thought promptingelicits reasoning in large language models. ArXiv,abs/2201.11903. Thomas Wolf, Lysandre Debut, Victor Sanh, JulienChaumond, Clement Delangue, Anthony Moi, Pier-ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-icz, Joe Davison, Sam Shleifer, Patrick von Platen,Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Trans-formers: State-of-the-art natural language processing.In Proceedings of the 2020 Conference on EmpiricalMethods in Natural Language Processing: SystemDemonstrations, pages 3845, Online. Associationfor Computational Linguistics.",
  "AExperimental settings andreproducibility": "We performed all of our experiments on two AWSEC2 P3 instances, each containing 8 NVIDIAV100 (16GB) GPUs. We used the Huggingfacelibrary (v4.26.1; Wolf et al. 2020) and publiclyavailable checkpoints of models we used in our ex-periments. On all datasets except for WDC our bestperforming models were trained with batch size16, while for WDC datasets we used a batch sizeof 8. We use default hyperparameters8 for modelfine-tuning except for learning rate (102 106),which we vary through hyperparameter tuning. Weused the Adam optimizer and set the max epochsto 100 with an early stopping patience of 10 anda validation set F-1 score increase threshhold of0.02. None of the trained models in any of ourexperiments required more than 60 epochs.",
  "BDatasets": "We select commonly used entity matching datasetsin our work. Each dataset is split into training, val-idation, and test sets using the ratio 3:1:1 samesplits as Li et al. (2020) to provide direct compar-isons in our OOD baselines (): Abt-BuyThis dataset contains product descrip-tions from e-commerce platforms Abt.com andBuy.com. A majority of products on either plat-form can be categorized as consumer electronics.There are a total of 9, 575 instances in the Abt-Buydataset. Amazon-GoogleThe Amazon-Google datasetconsists mainly of software product offerings e.g.MS Office/Windows. The relevant entity attributesin Amazon-Google include brand, title and price.There are a total of 11, 460 product pairs. Walmart-AmazonThis is a structured bench-mark entity matching dataset in the general con-sumer products domain containing textual productattributes like brand, title, model number, and price.Walmart-Amazon consists of 10, 242 product pairs.",
  "album year, and title. iTunes-Amazon is a relativelysmall dataset made up of 539 instance pairs": "BeerThis dataset contains structured textual at-tributes of beers from BeerAdvocate and RateBeer.We use the processed version9 of this dataset withthe same train-dev-test splits as Li et al. (2020).There are only 450 pairs in the Beer dataset. WDC ProductsThe Web Data Commonsdatasets span a variety of product categories likeelectronics, apparel, and accessories. WDC pro-vides 4400 manually annotated gold labels fromfour categories: computers (68, 461), cameras(42, 277),watches(61, 569), and shoes(42, 989). Each category contains 800 negativeand 300 positive test pairs. Each instance in allWDC datasets consists of four attributes - title, de-scription, brand, and specTable.",
  "Consumer Electronic ProductsWe use the fol-lowing prompt for all of the following datasets Abt-Buy, Amazon-Google, Walmart-Amazon,WDC-Computers, and WDC-Cameras": "<s>[INST] Given the following two examples,provide an explanation for the third example forwhy the two entities do or do not match. [\\INST]Entity A: [NAME] samsung dlp tv stand in blacktr72bx [DESCRIPTION] samsung dlp tv stand inblack tr72bx designed to fit samsung hlt7288hlt7288 , hl72a650 , and hl67a650 television setstempered 6mm tinted glass shelves wide audiostorage shelves to accommodate 4 or morecomponents wire management system easy toassemble high gloss black finish [PRICE] 369.0Entity B: [NAME] samsung tr72b tv stand[DESCRIPTION] glass black [PRICE] 232.14Label: MATCHExplanation: Both entities refer to samsung TVstand in black and therefore have substantiallysimilar specifications, therefore theyre amatch. </s>Entity A: [NAME] canon high capacity color inkcartridge color ink cl51 [DESCRIPTION] canon highcapacity color ink cartridge cl51 compatible withpixma ip6210d , ip6220d , mp150 , mp170 and mp450printers [PRICE] 35.0",
  "ShoesWe use the following prompt for WDC-Shoes. The examples here are randomly selectedfrom the WDC-Shoes training data": "<s> [INST]Given the following two examples,provide an explanation for the third example forwhy the two entities do or do not match.[/INST]Entity A: [NAME] Nike Sportswear Air Force 1 -Midnight Navyen Mens Shoes Nike Navy 488298-436enEntity B: [NAME] \"Nike Air Force 1 07 Lowmidnight navy / white (488298-436)\"eu(488298-436) | Bludshop.com\" euLabel: MATCHExplanation: Both entities refer to Nike AirForce shoes, navy in color with the same modelnumber 488298-436, therefore theyre amatch.</s>Entity A: [NAME] \"Air Jordan 14 Retro Low LaneyVarsity Royal/Varsity Maize-Black-White ForSale\"en-US Sale | Cheap Jordans 2017\"en-USEntity B: [NAME] \"Cheap Air Jordan 4 RetroMotorsports White/Varsity Blue-Black Sale\"en-USSale | Cheap Jordans 2017\"en-USLabel: NOT A MATCHExplanation: While both entities refer to cheapAir Jordan shoes, Entity A is a Laney versionwhich is Maize-Black-White in color, while EntityB is a Motorsports version which is Blue-Black incolor, therefore they are not a match.</s>",
  "MusicWe use the following prompt for iTunes-Amazon. The examples here are randomly selectedfrom the iTunes-Amazon training data": "<s> [INST] Given the following two examples, provide anexplanation for the third example for why the two entities door do not match. [\\INST]Entity A: [SONG_NAME] Extra Extra Credit[ARTIST_NAME] Wiz Khalifa [ALBUM_NAME] FlightSchool [GENRE] Hip-Hop/Rap , Music [PRICE] 0.99[COPYRIGHT] 2009 Rostrum Records [TIME] 4:03[RELEASED] 17-Apr-09Entity B: [SONG_NAME] Extra Extra Credit [Explicit ] [ARTIST_NAME] Wiz Khalifa[ALBUM_NAME] Flight School [ Explicit ] [GENRE]Rap & Hip-Hop [PRICE] 0.99 [COPYRIGHT] 2013 MadDecent [TIME] 4:03 [RELEASED] April 17 , 2009Label: MATCHExplanation: Both entities are songs with thesame name, artist and album.</s>Entity A: [SONG_NAME] Illusion ( feat . Echosmith )[ARTIST_NAME] Zedd [ALBUM_NAME] True Colors[GENRE] Dance , Music, Electronic [PRICE] 1.29[COPYRIGHT] 2015 Interscope Records [TIME] 6:30[RELEASED] 18-May-15Entity B: [SONG_NAME] Papercut [ feat . TroyeSivan ] [ARTIST_NAME] Zedd [ALBUM_NAME] TrueColors [GENRE] Dance & Electronic [PRICE] 1.29[COPYRIGHT] ( C ) 2015 Interscope Records [TIME]7:23 [RELEASED] May 18 , 2015Label: NOT A MATCH",
  "BeerWe use the following prompt for Beerdataset": "<s> [INST] Given the following two examples, provide anexplanation for the third example for why the two entities door do not match.[\\INST]Entity A: [NAME] Honey Basil Amber [MANUFACTURER]Rude Hippo Brewing Company [STYLE] American Amber/ Red Ale [ABV] 7.40Entity B: [NAME] Rude Hippo Honey Basil Amber[MANUFACTURER] 18th Street Brewery [STYLE] AmberAle [ABV] 7.40Label: MATCHExplanation: Both entities refer to Honey BasilAmber beer with the same ABV, therefore theyre amatch.</s>Entity A: [NAME] Brew Kahuna NW Red Ale[MANUFACTURER] Sky High Brewing [STYLE] AmericanAmber / Red Ale [ABV] 5.20Entity B: [NAME] Brew Bus Detour Series : RollinDirty Red Ale - Wood Aged [MANUFACTURER] CigarCity Brewing [STYLE] Irish Ale [ABV] 5Label: NOT A MATCHExplanation: Entity A refers to Beer manufacturedby Sky High Brewing while Entity B refers to Beermanufactured by Cigar City Brewing, and they havedifferent names, therefore they are not amatch.</s>",
  "DOOD Performance in Neural EntityMatching": "We conduct baseline experiments using our test-ing framework (cross-domain, cross-distribution,and cross-schema) on both generative (FlanT5)and non-generative (DITTO based on RoBERTa)methods. summarizes our results. We ob-serve significant decline in performance under bothmethods, with RoBERTa-based DITTO (Avg F-1:55.28) faring slightly worse than FlanT5 (Avg F-1:59.28).Our results on non-generative models likeDITTO are in-line with prior work in the areawhere Tu et al. (2022b) first highlight the issueof domain adaptation and the challenge of reusinglabeled source data where there might be a changein distribution or domain at test time.",
  "WDC-AllAbt-Buy69.1667.22Amazon-Google46.1241.37Walmart-Amazon64.0964.88": ": Comparison of OOD test performance under our framework for FlanT5-base (Chung et al., 2022) andnon-generative DITTO (Li et al., 2020) when trained on binary labeled (BL) training data. Broadly, we observesignificant degradation in model performance under both models. product catalog of 1, 000 products can, in worstcase scenario, lead to 1, 000, 000 pair comparisons this requires efficiency and, as a practical matter,low deployment costs. Nevertheless, we feel it isimportant to contextualize our work under ICL few-shot settings on LLMs given their current relevance.We use the same prompts as provided in AppendixC, with one example of each class and test five(Taori et al., 2023; Jiang et al., 2023; Almazroueiet al., 2023; Chung et al., 2022; Tay et al., 2023)instruction tuned models. summarizes these results. Generally,we find that all the models we test under-performtrained smaller LMs. We also observe certain be-haviors while prompting LLMs where in somecases (see Alpaca tested on the Beer dataset) we getunusually high recall while getting very low pre-cision measurements, indicating that models mayexcessively rely on token overlap as a proxy for en-tity matches. This is in line with prior work wherePeeters and Bizer (2023d) use ChatGPT for Entity",
  "FHuman Evaluation (H2)": "We conduct Test of Factuality evaluation on Ama-zon Mechanical Turk (AMT) a popular platformfor workers (both experts and non-experts) to per-form micro-tasks (in our case, instance annota-tions) on explanations generated by the Mistral-7Bmodel on 300 instances of the Abt-Buy dataset. illustrates the interface provided to anno-tators where theyre asked the two factuality-relatedquestions and are presented with binary choices."
}