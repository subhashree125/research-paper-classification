{
  "Abstract": "We construct a surrogate loss to directly optimise the significance metric used inparticle physics. We evaluate our loss function for a simple event classificationtask using a linear model and show that it produces decision boundaries thatchange according to the cross sections of the processes involved. We find that themodels trained with the new loss have higher signal efficiency for similar values ofestimated signal significance compared to ones trained with a cross-entropy loss,showing promise to improve sensitivity of particle physics searches at colliders.",
  "Introduction": "Particle physics experiments at the Large Hadron Collider (LHC) rely heavily on multivariateclassifiers to isolate signals from backgrounds. These investigations are generally of two types: 1)measuring known processes/properties with improving precision and checking for anomalies [i.e.,departures from the predictions of the Standard Model] and 2) looking for new processes (like lookingfor hypothetical particles). In most cases, the need for multivariate classifiers comes from the sporadicnature of the signal compared to the background. Generally, the signal plus background hypothesis(H1) is tested against the null or background-only hypothesis (H0), and the disagreement betweenthem is expressed in terms of a p value. An equivalent interpretation of the p value is the significancescore (Z) defined such that a Gaussian-distributed variable found Z standard deviations away fromits mean has a tail-distribution probability equal to p . Most sensitivity studies commonly use asimple approximation of the median Z score as a measure of the estimated signal significance,",
  "where Ns and Nb are the estimated numbers of signal and background events, respectively. (In therest of the paper, we shall refer to the med[Z] score as just the Z score.)": "In this paper, we attempt to construct a loss function whose minimisation can directly enhance theexperimental sensitivity. Our motivation comes from two observations. First, not all event ratesare equal; some scattering processes have higher probabilities [parameterised as cross sections (),calculable from theory. The number of events from a process (Ns,b) is calculated as Ns,b = s,bL,where L is the experimental luminosity] than others. Since a basic binary cross-entropy (BCE) loss",
  "arXiv:2412.09500v1 [hep-ph] 12 Dec 2024": "treats all events equally, it might wrongly classify events of some types which is more detrimentalto the classifier performance than the other. Second, a loss that optimises the signal-to-backgroundratio (r = Ns/Nb) may not necessarily maximise the significance as the Z score depends on the ratioand the absolute number (i.e., set size) of signal or background events (Z Ns r = rNb).Hence we ask, can we derive a loss function that maximises the Z score directly? The Z scoredescribed in Eq. (1) is a set function. Therefore, we define a surrogate loss function using the Lovszextension to maximise it directly. We evaluate this loss with pseudo-data mimicking a typicalevent classification task using a linear model and compare the decision boundaries to that modeltrained on a BCE loss. We also compare the performance of models trained on a BCE loss.",
  "Constructing the loss: submodularity and Lovszs extension": "We must consider some points before constructing a loss function based on the Z score. First, sincethe Z score is not a differentiable function (it depends upon discrete quantities), it needs a smoothinterpolation. Second, the metric operates on datasets instead of individual samplesparticularly,count data. Therefore, we must either develop a method to directly optimise the set function or assigncontributions to specific samples within the set to optimise. We look for a smooth submodular function. A submodular function is a function that captures theconcept of diminishing returns. It is defined on sets and has a property similar to concavity. Formally,submodularity can be defined as:",
  "i=1mi gi(m)(4)": "where m Rp+ is the vector of errors (which we discuss in the next section), gi(m) =({1, . . . , i}) ({i, . . . , i1}) and is a permutation ordering the components of m indecreasing order, i.e., x1 x2 xp . For the Lovsz extension to be applicable, the setfunction must be submodular. Additionally, the Lovsz extension of a submodular function preserves submodularity, i.e., the exten-sion evaluated at the points of the hypercube still follows submodularity. Using the Lovsz extension,we can directly compute the tight convex closure of a submodular function within polynomial time[O(p log(p)) time complexity]. This convex extension is amenable to a host of efficient optimisationmethods, especially gradient-based approaches.",
  "iBpivi iL(5)": "where y stands for the ground-truth labels of a set of events and y for the labels predicted by amodel on the set; Py and Py represent the set of positive labels and positive predictions and vi is thenumber of events of process type i where i S B, where S, B are the set of signal and backgroundprocesses. The constant term iS iL/is added to ensure Z() = 0. The function Zis submodular on the set of mispredictions (n, p), where n is the number of false negatives, and pis the number of false positives (which can be calculated from Py and Py). The proof is presentedin Appendix A. Even though here we consider only one signal process, the proof can be triviallygeneralised to the cases with multiple signal processes (n1, n2, . . . , nr) as well. From Eq. (4), we seethat for Z to be a loss function, the vector m must be the error vector in the prediction; Z, thennaturally emerges as the surrogate loss to optimise the Z score. Choice of m error:There are a few choices in the literature for modelling the error vector m. Toillustrate the working of the Z-score loss for this paper, we pick a hinge (Max Margin) error similarto Ref. . The labels are considered signed (yi {1, 1}). The model outputs a score Fi(x) foreach sample x. The error is given by the hinge loss,",
  "mi = max(1 Fi(x)yi, 0),yi {1, 1}.(6)": "The vector m could also be modelled as a sigmoid error or cross-entropy error, for example. We plotthe Z-score loss landscape for all these errors in the appendix for the toy problem (described below)in Appendix B. There is only one free parameter in our loss: . Other quantities like i and L are set by the processunder consideration (i.e., the particular classification task) and the collider experiment. Assumingwe perform the classification for rare signals, we set = sL, the theoretically predicted numberof signal events (which is also the maximum number of estimated signal events) for testing the loss.Algorithm 1 provides a simple pseudocode to calculate the gradient g(m) from Eq. (4) using Eq. (5)as the loss.",
  ": end if9: return g": "We analyse the loss function with asimple toy problem which can be eas-ily mapped to the problem of eventclassification at the LHC. Our goal isto separate the signal (s) from back-ground events using a linear classifierin the presence of multiple (say, two,b1 and b2) dominant background pro-cesses, as is usually the case. Thedatasets are modelled as normal dis-tributions in two features, x1 and x2which can be thought of as the kine-matic features of the actual events. We generated roughly 50000 points for each process and theoptimisation was done in batches using RAdam optimiser. We train the linear classifier using the BCEloss and Z with the hinge error for the following two test cases:",
  "Case 1: b1 = 1 fb, b2 = 100 fb; s = 0.1 fb.Case 2: b1 = 100 fb, b2 = 1 fb; s = 0.1 fb": "with L = 3000 fb1. We show the data distributions in . Since Z has the event rate (thetrue probabilities) information, we expect the decision boundaries to be different for the two testcaseseliminating more events from the larger background will give better significance scores,which Z is designed to optimise. confirms this. Performance:To compare the performance of the BCE- and Z-trained models, we show theresults of some scans in Case 1 in : the estimated Z score value for different model thresholds(u, varying which essentially translates the decision boundaries in along the axes) and thevariation of the estimated Z score with the signal efficiency ((u), the fraction of signal eventsretained for the threshold u) against the Z score obtained. For the scan, we demand (u) 0.05 and",
  "(c)": ": (a) The estimated Z score for the entire range of the linear model threshold, u. (b) Thedistribution of the Z score with signal efficiency, the fraction of signal events retained. Both quantitiesare functions of u. The model trained with Z reaches the maximum Z score for higher values ofsignal efficiency than that with the BCE loss. (c) Class efficiencies vs. u when trained with the Zloss with the hinge error. With increasing u, the larger background is eliminated first. For very highu the drop in the subdominant background is less steeper than the signal, leading to the drop in Z(u)in (a) for higher thresholds. the number of background events beyond the threshold to be at least 5. Similar plots are obtained forCase 2 also. From the figure, we see that z maximises the Z score for a higher signal efficiencythan the BCE, i.e., where the estimated Z score peaks, the model retains more signal events than theBCE-trained model. (For the z model, the estimated Z score drops for high values of u becausethere, for the datasets we consider, the major background is almost eliminated and further shifting thedecision boundary reduces the minor background slower than the signal).",
  "Conclusions and Outlook": "In this article, we showed how a loss function for directly optimising the signal significance canbe constructed. We obtained a surrogate for the median Z score, proved that it is a submodular setfunction and derived a loss function that can be used to train a multivariate model in batches using theLovsz extension. We showed that models trained with such a loss can cut the heavy background(s)more than the ones trained on the BCE loss while retaining more signal events (and thus showing thepromise of enhancing experimental sensitivities). Limitations and scope:While our results are promising, further tests are needed to fully charac-terise and understand the benefits and limitations of Z. Here, our choice of using a linear classifieron simple datasets was motivated by its simplicity and interpretability. However, for realistic charac-terisations, one has to look beyond the linear classifier (e.g., use a deep neural network) and considera range of benchmark (new-physics) scenarios with different kinematics (features). For example,there could be multiple (more than two) major backgrounds with highly overlapping features or thesignal size could be much smaller than the backgrounds (more than what we considered, as is thecase in some heavy particle searches). Finally, we note that while it is possible to introduce rate-dependent weights directly in the BCE loss,tuning them is an empirical task. The weights that yield the best performance need not be simply therates of the processes. In contrast, Z presents a natural way to include the rates (cross sections) asit is derived from the significance score used in collider searches.",
  "AProof of sub-modularity of the Z score": "For the proof, we take the scenario with a single signal process (|S| = 1, n = n1 = n) and a singlebackground process (|P| = 1, p = p1 = p) to simplify the expressions. But the result can be easilyextended to incorporate multiple signal and background processes due to the linearity of additionalsignal processes and background processes. We will also drop the luminosity term as that will notaffect the core derivation.",
  "BError Functions": "We require a loss function to handle any vector of errors m Rp+ since we are working withcontinuous predictions, not only to discrete vectors of misclassifications in {0, 1}p. We consider fourcases for defining the vector of errors m to construct the surrogate losses using the Lovasz extension. 1. Hinge (Max Margin) Loss: Following Ref. , we implement a hinge loss to compute theerror in the prediction. The labels are considered signed (yi {1, 1}). The model outputsa score Fi(x) for each sample x. The error is given by the hinge loss,",
  "mi =1 Fi(x),if yi = 1,Fi(x),otherwise.(28)": "3. Cross Entropy Error: We also experiment with the BCE loss to measure the error mi. Thisis similar to taking the logarithm of the error calculated in the Sigmoid Error. One could alsointerpret this as a form of weighted cross entropy where the weights are calculated based onthe specific composition of the batch of events and misclassifications on that batch.",
  "CROC Curves for Case 1": "We plot the ROC curves for experiments for Case 1 in . Case 2 gives similar results. LetNB1, NB2 represent the total number of BG1 and BG2 events generated in the dataset. Let nB1, nB2represent the number of BG1 and BG2 events remaining after the threshold respectively. Let B1, B2represent the cross sections of process BG1 and BG2 respectively. The total background efficiency isgiven by,nB1 + nB2NB1 + NB2,",
  "(b)": ": (a) ROC Curve for dataset (total) background efficiency vs signal efficiency. (b) ROC Curvefor true background efficiency vs signal efficiency. The true background efficiency differs from thetotal background efficiency in that it accounts for the cross sections of the background processes. Weobserve that our loss performs better at removing background at a higher signal efficiency."
}