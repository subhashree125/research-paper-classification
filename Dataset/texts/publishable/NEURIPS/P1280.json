{
  "ABSTRACT": "Diffusion models have demonstrated remarkable success in image generation, but they are computa-tionally intensive and time-consuming to train. In this paper, we introduce a novel diffusion modelthat benefits from quantum computing techniques in order to mitigate computational challenges andenhance generative performance within high energy physics data. The fully quantum diffusion modelreplaces Gaussian noise with random unitary matrices in the forward process and incorporates avariational quantum circuit within the U-Net in the denoising architecture. We run evaluations onthe structurally complex quark and gluon jets dataset from the Large Hadron Collider. The resultsdemonstrate that the fully quantum and hybrid models are competitive with a similar classical modelfor jet generation, highlighting the potential of using quantum techniques for machine learningproblems.",
  "Introduction": "Denoising diffusion models (DDMs) have revolutionized the field of generative artificial intelligence (GenAI) bydemonstrating their ability to generate high-quality images . They overcome the drawbacks of generative adversarialnetworks (GANs), which are prone to mode collapse, becoming a new state-of-the-art architecture for image generation. Consequently, DDMs have been applied in many generative tasks for science from molecular biology to medicalimage synthesis to gravitational lensing . Despite their successes, DDMs face significant challenges concerning the extensive computational resources requiredfor training . New compute paradigms must be employed in order to overcome the computational bottleneck.Quantum machine learning (QML) offers a promising solution . By cleverly incorporating quantum componentsinto classical algorithms, quantum computers can efficiently solve problems that are difficult for classical computerswith accelerated computations . This paradigm shift has the potential to surpass current limitations and unlock thefull potential of DDMs.",
  "Qubit States and Measurement": "Quantum bits, or qubits, can exist in superpositions of states, allowing them to represent more information and process itmore efficiently than classical bits . Unlike a classical bit that can be either 0 or 1, a qubit can be in a superpositionof both states simultaneously. Mathematically, the state of a qubit can be written as:",
  "When a measurement is made on a qubit, the superposition collapses to one of the basis states. The probability ofmeasuring the state |0 is ||2, and the probability of measuring the state |1 is ||2": "One method of measurement relevant in quantum computing and QML is the Haar measurement. Haar measurementinvolves sampling unitary operations uniformly according to the Haar measure, which is the unique, invariant measureon the group of unitary matrices. This type of measurement is useful in QML because it provides a way to generaterandom quantum states and operations, which is important for algorithms that require randomization .",
  "where U() is a unitary operation that depends on the parameters": "In the context of machine learning, these parameters are optimized using classical optimization techniques to minimizethe cost function that measures the performance of the circuit throughout training. The power of VQCs in machinelearning arises from their ability to exploit superposition and entanglement to potentially represent and solve problemsmore efficiently than classical algorithms .",
  "Quark-Gluon Data Description": "In this work, we generate quark and gluon jet data from the open-source LHC Compact Muon Solenoid (CMS) detectordata. The data contains two classes that follow different distributions: hits from quark and gluon jets. Each sampleis captured by three CMS subdetectors: electromagnetic calorimeter (ECAL), hadronic calorimeter (HCAL), and thereconstructed tracks as described in . The dataset is preprocessed to crop a subset of 1,000 ECAL-detected jets of125x125 pixels to 16x16 pixels for faster inference.",
  "Related Work": "Multiple works have combined the classical DDM and quantum algorithms. The paper in proposed a fully quantumDDPM (QuDDPM) for generating an unknown quantum state distribution. Their method consists of applying randomunitaries to quantum states, thus scrambling them into noise, and summing three error functions to optimize duringtraining. The QuDDPM performed best compared to a quantum GAN and a quantum direct transport model. Another work in proposed a hybrid quantum-classical DDM. The algorithm involved a quantum denoising U-Netand classical noising and optimization. Good results were achieved on the MNIST dataset. However, tests on MNISTare not generalizable to other data, and a physics-conscious approach is required for the more complex Quark-Gluondata.",
  ": The pipeline that the data goes through with all the possible classical-quantum combinations of the forwardand backward diffusion process": "impact model performance, as the authors in have shown, an arbitrary noising transformation can be used. Wechose to use the Haar measure for the quantum model as it allows for the unitary matrix transforms to scale withincreasing resolution and dataset size. The final unitary is applied to each encoded channel, avoiding costly calculationsassociated with each timestep.",
  "Denoising Quantum U-Net": "Similar to classical DDMs, the denoising neural network is trained on learned parameters with the MSE loss function.The hybrid model uses a quantum strongly entangling layer surrounded by fully convolutional layers, and the fullyquantum model relies only on the quantum layers. The circuit in the quantum layer, consisting of rotation and stronglyentangling gates, is kept uniform across all models, with the number of layers treated as a tunable parameter.",
  ": Haar noise applied to one encoded sample of four channels": ": The losses and FID graphs of fully classical (a), hybrid (b), and fully quantum (c) models. For all models,MSE and Adam optimizer was used to reach convergence, and the FID function remained the same. where x and g are the mean feature vectors of the real and generated images, respectively, and x and g are theircorresponding covariance matrices. Though we do not currently have access to quantum computers, we can simulatethe behavior of quantum systems using simulators like Pennylane and compare the results to classical models.",
  "similar classical model. This implies that all or some parts of deep neural network computations can be offloaded tofaster quantum processors to reduce training time without a performance trade-off": "A potential reason for the plateau in FID scores across all models could be the sparsity of the data, where each samplecontains only a few non-zero points. This sparsity may prevent the complete removal of noise in some of the encodedchannels. A possible solution is a post-processing step where only the most prominent values are retained in the decodeddata, increasing the confidence in jet locations. As a result, the generated samples would align more closely with theoriginals, as shown in .",
  "Conclusion and Future Direction": "This work marks significant progress in leveraging quantum computing for machine learning applications, specificallyfor a generative DDM. In the future, our aim is to extend the models to generate all three jet channels for everysample. Additionally, experimenting with different parametric circuits and forward scrambling, such as using Gaussiantransformations instead of Haar unitaries, may provide further insight into the impact that the architecture has onquantum generative learning. Finally, testing the quantum model on hardware with a limited number of qubits underpractical constraints will be crucial in evaluating its scalability, real-world performance, and resilience to quantumnoise.",
  "Thecodeisopensourceandcanbefoundhere:": "Hanqun Cao, Cheng Tan, Zhangyang Gao, Yilun Xu, Guangyong Chen, Pheng-Ann Heng, and Stan Z. Li. A surveyon generative diffusion models. In IEEE Transactions on Knowledge and Data Engineering, volume 36, number 7,pages 28142830, 2024. Prafulla Dhariwal and Alexander Nichol. Diffusion models beat gans on image synthesis. In Advances in NeuralInformation Processing Systems, volume 34, pages 87808794, 2021. Micha Stypukowski, Konstantinos Vougioukas, Sen He, Maciej Zieba, Stavros Petridis, and Maja Pantic. Diffusedheads: Diffusion models beat gans on talking-face generation. In Proceedings of the IEEE/CVF Winter Conferenceon Applications of Computer Vision (WACV), pages 50915100, 2024. Duo Xu, Jonathan C. Tan, Chia-Jung Hsu, and Ye Zhu. Denoising diffusion probabilistic models to predict thedensity of molecular clouds. In The Astrophysical Journal, volume 950, number 2, pages 146, 2023. Shaoyan Pan, Tonghe Wang, Richard L.J. Qiu, Marian Axente, Chih-Wei Chang, Junbo Peng, Ashish B. Patel,Joseph Shelton, Sagar A. Patel, Justin Roper, and others. 2D medical image synthesis using transformer-baseddenoising diffusion probabilistic model. In Physics in Medicine & Biology, volume 68, number 10, pages 105004,2023. Kai Yi, Bingxin Zhou, Yiqing Shen, Pietro Li, and Yuguang Wang. Graph denoising diffusion for inverse proteinfolding. In Advances in Neural Information Processing Systems, volume 36, 2024. Pranath Reddy, Michael W. Toomey, Hanna Parul, and Sergei Gleyzer. A conditional diffusion model for super-resolution of gravitational lensing data. In arXiv preprint arXiv:2406.08442, 2024. Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In InternationalConference on Machine Learning, pages 81628171, 2021. Jiaming Song, Chenlin Meng, and Stefano Ermon. Denoising diffusion implicit models. In arXiv preprintarXiv:2010.02502, 2020. Bahjat Kawar, Michael Elad, Stefano Ermon, and Jiaming Song. Denoising diffusion restoration models. InAdvances in Neural Information Processing Systems, volume 35, pages 2359323606, 2022. Ville Bergholm, Josh Izaac, Maria Schuld, Christian Gogolin, Shahnawaz Ahmed, Vishnu Ajith, M. Sohaib Alam,Guillermo Alonso-Linaje, B. AkashNarayanan, Ali Asadi, and others. Pennylane: Automatic differentiation ofhybrid quantum-classical computations. In arXiv preprint arXiv:1811.04968, 2018. Carlo Ciliberto, Mark Herbster, Alessandro Davide Ialongo, Massimiliano Pontil, Andrea Rocchetto, SimoneSeverini, and Leonard Wossnig. Quantum machine learning: a classical perspective. In Proceedings of the RoyalSociety A: Mathematical, Physical and Engineering Sciences, volume 474, number 2209, pages 20170551, 2018. Maria Schuld, Ilya Sinayskiy, and Francesco Petruccione. An introduction to quantum machine learning. InContemporary Physics, volume 56, number 2, pages 172185, 2015. Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising diffusion probabilistic models. In Advances in NeuralInformation Processing Systems, volume 33, pages 68406851, 2020. Bingzhi Zhang, Peng Xu, Xiaohui Chen, and Quntao Zhuang. Generative quantum machine learning via denoisingdiffusion probabilistic models. In Physical Review Letters, volume 132, number 10, pages 100602, 2024.",
  "Quantum Diffusion Model for Quark and Gluon Jet GenerationA PREPRINT": "Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning usingnonequilibrium thermodynamics. In International Conference on Machine Learning, pages 22562265, 2015. Alfred Haar. Der massbegriff in der theorie der kontinuierlichen gruppen. In Annals of Mathematics, volume 34,number 1, pages 147169, 1933. Jacob Biamonte, Peter Wittek, Nicola Pancotti, Patrick Rebentrost, Nathan Wiebe, and Seth Lloyd. Quantummachine learning. In Nature, volume 549, number 7671, pages 195202, 2017. Michael A. Nielsen and Isaac L. Chuang. Quantum Computation and Quantum Information. Cambridge UniversityPress, 2002. Samuel Yen-Chi Chen, Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Xiaoli Ma, and Hsi-Sheng Goan. Variationalquantum circuits for deep reinforcement learning. In IEEE access, volume 8, pages 141007141024, 2020. Israel Griol-Barres, Sergio Milla, Antonio Cebrin, Yashar Mansoori, and Jos Millet. Variational quantumcircuits for machine learning. an application for the detection of weak signals. In Applied Sciences, volume 11,number 14, pages 6427, 2021. Jonathan Romero and Aln Aspuru-Guzik. Variational quantum generators: Generative adversarial quantummachine learning for continuous distributions. In Advanced Quantum Technologies, volume 4, number 1, pages2000003, 2021. Runqiu Shu, Xusheng Xu, Man-Hong Yung, and Wei Cui. Variational Quantum Circuits Enhanced GenerativeAdversarial Network. In arXiv preprint arXiv:2402.01791, 2024. Marcal Comajoan Cara, Gopal Ramesh Dahale, Zhongtian Dong, Roy T Forestano, Sergei Gleyzer, DanielJustice, Kyoungchul Kong, Tom Magorsch, Konstantin T Matchev, Katia Matcheva, and others. Quantum VisionTransformers for QuarkGluon Classification. In Axioms, volume 13, number 5, pages 323, 2024. Michael Andrews, John Alison, Sitong An, B. Burkle, S. Gleyzer, M. Narain, M. Paulini, B. Poczos, and E. Usai.End-to-end jet classification of quarks and gluons with the CMS Open Data. In Nuclear Instruments and Methodsin Physics Research Section A: Accelerators, Spectrometers, Detectors and Associated Equipment, volume 977,pages 164304. Elsevier, 2020. Mariia Baidachna, Haneen Fatima, Rahaf Omran, Nour Ghadban, Muhammad Ali Imran, Ahmad Taha, andLina Mohjazi. Mirror, Mirror on the Wall: Automating Dental Smile Analysis with AI in Smart Mirrors. InComputing&AI Connect, volume 1, number 1, pages 110. Scifiniti, 2024. Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. GANs trained bya two time-scale update rule converge to a local Nash equilibrium. In Advances in Neural Information ProcessingSystems, volume 30, 2017. Francesca De Falco, Andrea Ceschini, Alessandro Sebastianelli, Bertrand Le Saux, and Massimo Panella. TowardsEfficient Quantum Hybrid Diffusion Models. In arXiv preprint arXiv:2402.16147, 2024. Arpit Bansal, Eitan Borgnia, Hong-Min Chu, Jie Li, Hamid Kazemi, Furong Huang, Micah Goldblum, JonasGeiping, and Tom Goldstein. Cold diffusion: Inverting arbitrary image transforms without noise. In Advances inNeural Information Processing Systems, volume 36, 2024."
}