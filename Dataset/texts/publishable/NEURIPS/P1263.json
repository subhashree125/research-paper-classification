{
  "ABSTRACT": "In this work, we study the experts problem in the distributed setting where an experts cost needsto be aggregated across multiple servers. Our study considers various communication models suchas the message-passing model and the broadcast model, along with multiple aggregation functions,such as summing and taking the p norm of an experts cost across servers. We propose the rstcommunication-efcient protocols that achieve near-optimal regret in these settings, even against astrong adversary who can choose the inputs adaptively. Additionally, we give a conditional lowerbound showing that the communication of our protocols is nearly optimal. Finally, we implementour protocols and demonstrate empirical savings on the HPO-B benchmarks.",
  "Introduction": "Online prediction with expert advice is an indispensable task in many elds, including bandit learning (Auer et al.,2002; Lattimore & Szepesvri, 2020), online optimization (Shalev-Shwartz et al., 2012; Hazan et al., 2016), robot con-trol (Doyle et al., 2013), and nancial decision making (Dixon et al., 2020). The problem involves n experts makingindividual predictions and receiving corresponding costs on each of T days. On each day, we choose an expert basedon the historical costs of the experts on previous days, and we receive the cost of the selected expert on that day. Theobjective is to compete with the best single expert in hindsight, i.e., to minimize the average regret, dened as theadditional cost the algorithm incurs against the best expert in a horizon of T days. It is known that the Exponential",
  "T) inthe adversarial bandit setup, where only the cost of one expert is observed on a single day": "For a large number of experts and days, it may not be feasible to run classical low-regret algorithms. Motivatedby this, recent work (Srinivas et al., 2022; Peng & Zhang, 2022; Woodruff et al., 2023; Peng & Rubinstein, 2023;Aamand et al., 2023) considers the experts problem in the data stream model, where the expert predictions are typ-ically streamed through main memory, and a small summary of historical information is stored. In this paper, we consider an alternative model in the big data setting, namely, the distributed model, where expertcosts are split across s servers, and there is a central coordinator who can run a low-regret algorithm. However, com-municating with different servers is expensive, and the goal is to design a low communication protocol that achieveslow regret.",
  "---": "A motivating example is a distributed online optimization problem, where different servers hold different samples, andeach expert could correspond to a different model in an optimization problem over the union of the samples as in theHPO-B real-world benchmark (Arango et al., 2021). In this case, it is natural for the cost of an expert to be the sumof the costs of the expert across all servers. The goal is thus to minimize the cumulative costs in an online fashion bychoosing models on a daily basis. Another example of an aggregation function could be the maximum across servers;indeed, this could be useful if there is a maximum tolerable cost on the servers, which we would like not to exceed.For our lower bounds, we also ask the protocol to be able to tell at least if the cost of the expert it chose on a givenday is non-zero; this is a minimal requirement of all existing algorithms, such as MWU or Exp3, which update theirdata structure based on such a cost. It is also desirable in applications such as the experts problem where one wants toknow if the prediction was right or wrong. In our setting, a coordinator needs to choose an expert based on historical interactions with s servers each day. We focuson two widely studied communication models, namely, the message-passing model with two-way communicationchannels and the broadcast model with a broadcast channel. In the message-passing model, the coordinator initiatesa round of interaction with a given server, and the messages exchanged are only seen by the coordinator and thatparticular server. The coordinator then decides who speaks next and repeats this process. The broadcast model isalso commonly studied in practice and theory. It can be viewed as a model for single-hop wireless networks. In thebroadcast model, each message exchanged is seen by all servers and the coordinator. We note that the broadcast modelwas a central communication model studied for clustering in Chen et al. (2016). As in the distributed online learning setup, we can view each server as a database, where it possibly receives new datadaily. The costs of the n experts on a day then correspond to n possibly different functions of the data on that day. Wenote that the costs may be explicitly given or implicit functions of the data, and if the latter, they may only need to becomputed as required by the protocol. We aim to achieve a near-optimal regret versus communication tradeoff in this setting over a horizon of T days. Giventhe memory-efcient streaming algorithms of Srinivas et al. (2022); Peng & Zhang (2022) and the close connectionbetween streaming algorithms and communication-efcient protocols, one might think that implementing a streamingalgorithm in our settings is optimal. While we could run a streaming algorithm, a critical difference here is that thecoordinator is not memory-bounded and thus can afford to store a weight for each expert. While it cannot run EWAor MWU, which would require (sn) communication per day, it can run a distributed Exp3 algorithm, which samplesa single expert and thus has low communication, but maintains a weight locally for all n experts using (n) memory.We stress this is not possible in the streaming model.",
  "n log n": "beT ). We can boost the success probability using the same trickas in Algorithm 2 by initiating log (poly(T )) copies of DEWA-M as meta-experts and running EWA on top of them.We refer to the high-probability version as DEWA-M-P . We thus have the following theorem (see detailed proof inSection B.2):",
  "Related Work": "Online learning with expert advice. The Multiplicative Weights Update (MWU) methods rst appearance datesback to the early 1950s in the context of game theory Brown & Von Neumann (1950); Brown (1951); Robinson (1951).The exact form of MWU is carried out by adding randomness, which efciently solves two-player zero-sum games(Grigoriadis & Khachiyan, 1995). Ordentlich & Cover (1998) further proves the optimality of such algorithms undervarious scenarios. The algorithm has later been adopted in a wide range of applications (Cesa-Bianchi & Lugosi, 2006;Freund & Schapire, 1997; Christiano et al., 2011; Garber & Hazan, 2016; Klivans & Meka, 2017; Hopkins et al.,2020; Ahmadian et al., 2022), including the experts problem. See the comprehensive survey on MWU by Arora et al.(2012). Multi-armed bandits. Similar to the experts problem, Multi-armed bandits (MAB) is another fundamental formu-lation in sequential optimization since its appearance in Thompson 1933; Robbins 1952. Unlike the experts prob-lem, where each experts cost is revealed each day, MAB limits players to observing only the cost of one expert(arm) each day. Both stochastic and adversarial MAB problems have been studied extensively (Audibert et al., 2009;Garivier & Capp, 2011; Korda et al., 2013; Degenne & Perchet, 2016; Agrawal & Goyal, 2017; Kaufmann, 2018;Lattimore & Szepesvri, 2020; Auer et al., 2002; Auer, 2002). As we mainly consider adversarial cost streams, theExponential-weightalgorithm for Exploration and Exploitation (Exp3) and its Upper Condence Bound (UCB) variantare most relevant due to their effectiveness in achieving near-optimal regret in the presence of adversaries (Auer et al.,2002). Distributed learning with expert advice. Kanade et al. 2012 also study the expert problem under a coordinator-servermodel. However, the results are incomparable as Kanade et al. 2012 only considers the special case where the cost isallocated to one server rather than an arbitrary number of servers, which makes their setup a special case under ourmore general scheme. Also, our lower-bound proof is against oblivious adversaries rather than adaptive adversaries,as in Kanade et al. (2012), which is more challenging to prove. Detailed comparisons with Kanade et al. (2012) aredescribed in Section C. Hillel et al. 2013; Szorenyi et al. 2013 give a distributed MAB setting where arms on each server share the samecost distribution, and the goal is to nd the best arm cooperatively. Shahrampour et al. 2017; Landgren et al. 2016;Bistritz & Leshem 2018, on the other hand, assume the costs on each server are i.i.d. across days while being differentfor different servers. Cesa-Bianchi et al. 2016 considers a setup where servers are nodes on a connected graph and canonly talk to neighboring nodes while restricting the cost for each arm on the servers to be the same within one day.Korda et al. 2016 studies the multi-agent linear bandit problem in a peer-to-peer network where agents share the samegroup of arms with i.i.d. costs across days. Some works also consider the setup where servers need to compete againsteach other, which is outside of our scope (Anandkumar et al., 2011; Besson & Kaufmann, 2018; Bubeck et al., 2020;Wang et al., 2020). Unlike most of these setups, we make no assumptions about the costs across days and servers. Distributed functional monitoring. The coordinator-server communication model is also commonly seen in thedistributed functional monitoring literature (Cormode et al., 2011; Woodruff & Zhang, 2012; Arackaparambil et al.,2009; Cormode et al., 2012; Chan et al., 2012), where the goal is to approximate function values, e.g., frequencymoments, across streams with minimal communication. We note that the goal of the distributed experts problem isdifferent in that the focus is on expert selection rather than value estimation, and the algorithms in the distributedfunctional monitoring literature, to the best of our knowledge, are not directly useful here.",
  "Preliminaries and Notation": "We use T to denote the total number of days, n the number of experts, and s the number of servers. lti,j representsthe cost observed at step t for expert i on the j-th server. l denotes an estimate to l and [n] denotes {1, 2, . . ., n}. Aword of memory is represented as O(log (nT )) bits and we use O() to suppress logO(1) (nT s) factors. We refer tothe Exponential Weight Algorithm (EWA) and Multiplicative Weights Update (MWU) method interchangeably.",
  "TTt=1 ltA(t) mini Tt=1 lti": "In the distributed setting, we have s servers and one coordinator where the cost lti now depends on costs lti,j observedlocally across all the servers. The coordinator selects the expert for the next day based on any algorithm A of its choice.For each j [s], the j-th server can receive or compute its cost lti,j, i [n] for the i-th expert on day t. The actual costfor the i-th expert on day t is dened as lti = f(lti,1, lti,2, , lti,s), where f() is an aggregation function. We assumethe costs lti,j are non-negative. We consider three natural choices of f(): 1. the summation function lti = sj=1 lti,jand an integer power of the sum function lti =sj=1 lti,jq2. the maximum/minimum function lti = maxj[s] lti,j",
  "p , p > 1. In the distributed setting, regret is dened as in the single": "server setup with lti = f(lti,1, lti,2, , lti,s). Without loss of generality, we normalize lti , lti,j 0. In practice, iflti , the regret will increase by a factor of accordingly, which only affects the scale of the regret and preservesoptimality. Note that the cost vector for all the experts is observed by the corresponding local server. Furthermore, weexplore the distributed experts problem in two different communication models: Message-passing model. For the message-passing model, the coordinator can initiate a two-way private channel witha specic server to exchange messages. Messages can only be seen by the coordinator and the selected server. Thecoordinator then decides which server to speak to next and repeats based on the protocol.",
  "Broadcast model. In the broadcast model, the coordinator communicates with all servers using a broadcast channel.Again, the communication channel can only be initiated by the coordinator": "We further assume local servers have a memory bound of M in what they can store from previous days, which isa more practical scenario as discussed in Srinivas et al. (2022); Peng & Zhang (2022). We leave the denition anddescription of strong adaptive adversaries and the EWA algorithm in Denition A.1 and Appendix A.2 accordingly.",
  "T be ) regret with constant probability using O(T (be + s)) total communication": "when the aggregation function is the summation function or an integer power of sum function. The intuition for thebaseline algorithm is to get an unbiased estimation of the experts underlying cost by sending a signal to the coordina-tor with a probability that is proportional to the local cost, which is simple yet effective. We further introduce the fullalgorithm DEWA-S-P that achieves O(",
  "poly(T ) and": "using only O(T (be + s)) overall communication when the aggregation function is the maximum function. Besides thesummation aggregation function, we leverage a random-walk-based communication protocol to nd out the aggregatedcost with a minimal communication cost. Since all of our protocols use (and require) at least T s communication, thecoordinator can gure out the exact cost for the selected expert on each day by querying each of the s servers for",
  "probability 1 1": "poly(T ) and using only O(T (be + s)) overall communication when the aggregation function is thep-norm function for any xed constant 0 < 1 such that 1 + < p. The algorithm employs the idea of embeddingp into , thus efciently estimating the aggregated cost using the previously introduced DEWA-M-P . For all ourbounds, be [n] is a hyperparameter that trades off the communication with the optimal regret we can get. For",
  "besj=1belti,j": "n= lti.The same sampling technique can be used to obtain an unbiased estimator of lti when the aggregation function isan integer power of the sum over local costs, where each monomial in the expansion of the aggregation function isunbiasedly estimated by taking the product of sampled local costs. On each day, we only incur communication costO(s + ni=1be",
  "Algorithm 1 DEWA-S": "Input: learning rate , sampling budget be;Initialize L0i = 0, i [n];for t = 1 to T doCoordinator chooses expert i with probability p(i) exp ( Lt1i);for j = 1 to s doCoordinator initiates private channel with server j;for i = 1 to n doServer j observes cost lti,j and samples ti,j Bernoulli( be",
  "DEWA-S-P": "As we are using unbiased estimators instead of actual costs, we only obtain the desired regret with constant probability.In order to achieve near-optimal regret with high probability, we propose DEWA-S-P in Algorithm 2. The idea is to runmultiple baseline algorithms in parallel to boost the success probability, where we regard each baseline algorithm asa meta-expert. As each meta-expert has constant success probability, the probability that they all fail is exponentiallysmall in the number of meta-experts. Thus, by running EWA on the meta-experts, we can follow the advice of the bestmeta-expert and achieve near-optimal regret with high probability.",
  "More precisely, to obtain 1 1": "poly(T ) success probability, we initiate log (poly(T )) meta-experts Ak, k[log (poly(T ))] at the start of the algorithm. Each meta-expert runs its own DEWA-S independently across T days.The cost of the k-th meta-expert on day t is dened to be the cost the expert Ak selects on the same day, which isdenoted as ltAk(t). With the denition of the cost for the meta-experts, we can then run EWA on the meta-experts.",
  "Algorithm 2 DEWA-S-P": "Input: learning rate meta, sampling budget be, failure rate 1/poly(T );Let K = log (poly(T )), initialize K baseline algorithms Ak and let L0k = 0, k [K];for t = 1 to T doCoordinator chooses expert according to Ak(t) with probability p(k) exp (metaLt1k);Coordinator updates memory states for all Ak according to Algorithm 1;Coordinator receives cost ltAk(t) = sj=1 ltAk(t),j;Update all Lk by Ltk = Lt1k+ ltAk(t);",
  "Algorithm 3 DEWA-M": "Input: learning rate , sampling budget be;Coordinator initializes L0i = 0, i [n];for t = 1 to T doCoordinator chooses expert i with probability p(i) exp ( Lt1i);Coordinator randomly chooses be experts with corresponding IDs Be = {t(1), t(2), , t(be)};Coordinator initializes lti = 0, i [n];Coordinator permutes [s] randomly and denotes the resulting sequence as Stfor j in St doCoordinator initiates channel with server j;for i = 1 to n doServer j observes cost lti,j and sends lti,j to the coordinator if lti,j > lti and i Be;Server j cleans memory buffer;Coordinator updates lti with received lti,j;Update Li by Lti = Lt1i+ lti, i [n]; The intuition of DEWA-M is that for each expert, if we walk through the servers in a random order and only update ltiif we encounter lti,j > lti, then with high probability, we only need a small number of updates per expert. This cannotbe achieved in the message-passing model due to the fact that broadcasting lti requires (s) communication per expert.In contrast, no communication is required for broadcasting lti in the broadcast model. In fact, with probability 1 ,each expert will update at most O(log(s/)) times. By setting =1",
  "Algorithm 4 DEWA-L": "Input: learning rate , sampling budget be;Coordinator initializes L0i = 0, i [n];for t = 1 to T doCoordinator chooses expert i with probability p(i) exp ( Lt1i);Coordinator randomly chooses be experts with corresponding IDs Be = {t(1), t(2), , t(be)};Coordinator initializes lti = 0, i [n];Coordinator permutes [s] randomly and denotes the resulting sequence as Stfor j in St doCoordinator initiates channel with server j;Server j samples Ej Exponential(1);for i = 1 to n doServer j observes cost lti,j and computes cti,j = (lti,j)p",
  "poly(T ) for any xed constant 0 < 1 such that 1 + < p": "We then give a communication lower bound, which holds even in the broadcast model, for both summation and max-imum aggregation functions with a memory bound on the individual servers. It holds for oblivious adversarial coststreams, and thus also for strong adversarial cost streams and the message-passing model. We use the communi-cation lower bound for the -DIFFDIST problem Srinivas et al. (2022) but adapt it to our setting. By reducing the-DIFFDIST problem to the distributed experts problem, we prove that any protocol for achieving R regret with con-stant probability requires total communication at least ( n",
  "poly(T ) for the distributedexperts problem in the message passing model with the summation aggregation function and for strong adaptiveadversarial cost streams": "Notice that the total communication cost for DEWA-S-P is O(T (be + s)). Thus DEWA-S-P can achieve the sameregret as EWA with a high probability guarantee when be = n, but requires only O(T (n + s)) communication insteadof O(nT s) communication. DEWA-S-P further generalizes to the case when be < n.",
  "be a xed constant that is independent of the other input parameters, and suppose M =O(n": "sT R2 + 1) is an upper bound on the total memory a server can store from previous days. Any algorithm A thatsolves the distributed experts problem in the broadcast model with the p(1 p ) norm aggregation functionwith regret R and with probability at least 1 p, needs at least ( n R2 ) bits of communication. If the algorithm canalso determine, with probability at least 1 p, if the cost of the selected expert on each day is non-zero, then it alsoneeds (T s) bits of communication. These lower bounds hold even for oblivious adversarial cost streams. We present the proof of Theorem 5.5 in Section B.7. Additionally, we present an (ns) communication lowerbound proof below for achieving sub-constant regret with the maximum aggregation function in the message-passing model, which is optimal for T O(poly(log (ns))). This indicates that we cannot do better than naveEWA in this case, which achieves optimal regret with communication O(ns). Note that within the optimal regret",
  "Experiments": "In this section, we demonstrate the effectiveness of our algorithms on the HPO-B benchmark (Arango et al., 2021)under two setups: 1. Message-passing model with summation aggregation function and 2. Broadcast model withmaximum aggregation function. As a black-box hyperparameter optimization benchmark, we can regard differentmodels in the HPO-B benchmark as different experts in the distributed experts problem, and different datasets aredistributed across different servers. We further regard each search step, which is random search for all model classes,as one day in our distributed experts problem. The cost vector is then the normalized negative accuracy of models ondifferent datasets for a search step. Thus, minimizing regret directly corresponds to optimizing the overall accuracyacross all search steps. For both DEWA-S and DEWA-M , we set be = 1 to compare against Exp3 and be = n tocompare against EWA. The results in , and show that our algorithms achieve similar regret as the optimal algorithms(Exp3 and EWA) while having less communication cost. We further use two synthetic datasets to evaluate our algo-rithms under various scenarios, including dense-cost and sparse-cost. We present the results in Section D, which show",
  "Agrawal, S. and Goyal, N. Near-optimal regret bounds for thompson sampling. Journal of the ACM (JACM), 64(5):124, 2017": "Ahmadian, S., Esfandiari, H., Mirrokni, V., and Peng, B. Robust load balancing with machine learned advice. InProceedings of the 2022 Annual ACM-SIAM Symposium on Discrete Algorithms (SODA), pp. 2034. SIAM, 2022. Anandkumar, A., Michael, N., Tang, A. K., and Swami, A. Distributed algorithms for learning and cognitive mediumaccess with logarithmic regret. IEEE Journal on Selected Areas in Communications, 29(4):731745, 2011. Arackaparambil, C., Brody, J., and Chakrabarti, A. Functional monitoring without monotonicity. In Automata, Lan-guages and Programming: 36th International Colloquium, ICALP 2009, Rhodes, Greece, July 5-12, 2009, Proceed-ings, Part I 36, pp. 95106. Springer, 2009.",
  "Besson, L. and Kaufmann, E. Multi-player bandits revisited. In Algorithmic Learning Theory, pp. 5692. PMLR,2018": "Bistritz, I. and Leshem, A.Distributed multi-player bandits - a game of thrones approach.In Ben-gio,S.,Wallach,H.,Larochelle,H.,Grauman,K.,Cesa-Bianchi,N.,and Garnett,R. (eds.),Ad-vances in Neural Information Processing Systems, volume 31. Curran Associates, Inc., 2018.URL Braverman, M., Ellen, F., Oshman, R., Pitassi, T., and Vaikuntanathan, V. A tight bound for set disjointness in themessage-passing model. In 2013 IEEE 54th Annual Symposium on Foundations of Computer Science, pp. 668677.IEEE, 2013.",
  "Shalev-Shwartz, S. et al. Online learning and online convex optimization. Foundations and Trends in MachineLearning, 4(2):107194, 2012": "Srinivas, V., Woodruff, D. P., Xu, Z., and Zhou, S. Memory bounds for the experts problem. In Proceedings ofthe 54th Annual ACM SIGACT Symposium on Theory of Computing, STOC 2022, pp. 11581171, New York, NY,USA, 2022. Association for Computing Machinery. ISBN 9781450392648. doi: 10.1145/3519935.3520069. URL Szorenyi, B., Busa-Fekete, R., Hegedus, I., Ormndi, R., Jelasity, M., and Kgl, B. Gossip-based distributed stochasticbandit algorithms. In International Conference on Machine Learning, pp. 1927. PMLR, 2013.",
  "Denition A.1. (Distributed experts problem with a strong adversary). An algorithm A run by the coordinator makespredictions for T days. On day t:": "1. A commits to a distribution pt over n experts based on the memory contents of the coordinator on day t.2. The adversary selects the cost lti,j on each server after observing pt.3. A selects an expert according to pt and incurs the corresponding cost.4. The coordinator updates its memory contents by communicating with servers according to the protocol de-ned by A. We refer to adversaries that can arbitrarily dene the lti,j with no knowledge of the internal randomness or state ofA, as oblivious adversaries. Notice that if we send each of the servers local information to the coordinator each",
  "B.1Theorem 4.1": "In order to prove the communication bounds, we need the following lemma:Lemma B.1. Welzl (2000). With a randomly permuted sequence S = {a1, a2, , an} and = 0, if we read fromleft to right and update = ai whenever we encounter ai > , dene random variable X as the number of times has is updated during the process. We have the following results:E2X= n + 1",
  "Given Lemma B.1, we can then prove our statement": "Proof. For any expert on any day, we will rst prove that with probability at least 1 , the servers only need to sendthe corresponding cost to the coordinator at most O(log (s/)) times. By Lemma B.1 with n = s in our setup, for anyg 0, we have:Pr (X > g)=Pr2X > 2g",
  "which completes the proof": "In addition, in cases where the coordinator does not need to initiate communication, we can achieve an O(be log (s/))communication cost per time step with the following protocol: Initialization: each individual server initializes a hti torecord the maximum cost for each expert. 1. For each server who has a cost larger than the current maximum, sendits value to the broadcast channel after a i,j time delay, where i,j is randomly sampled from . 2. Once thebroadcast channel has been occupied, all other servers stop the sending action and update their corresponding hti, i,jinstead. Then we can repeat this process and use the maximum value collected after s unit time steps as an estimateto the maximum value. In this protocol, we assume that the broadcast channel can only be occupied by one server.The random ordering is guaranteed by the random delay and the expected number of communication rounds to get themaximum value is given in Lemma B.1. Additionally, notice that for each time step the protocol is guaranteed to endwithin s time steps as the worst case delay is 1 unit time step for each server. By using this protocol, we can still obtaina near optimal communication cost of O(be log s/).",
  "B.7Lower Bound Proof": "The communication lower bound proof for the maximum aggregation function in the message-passing model followsusing the multi-player number-in-hand communication lower bound for set disjointness in Braverman et al. (2013).To solve the multi-player set disjointness problem with s players, where each player has n bits of information cji {0, 1}, i [n], j [s], the communication lower bound is (ns) for the message-passing model. In our problem, in the rst case, all experts have at least one server that has a cost of 1, i.e., j [s], i [n], cji = 1.In the second case, we have one expert whose cost on every server is 0 while the other experts all have at leastone server that has a cost of 1. Then, in the rst case, the sets (cost vectors on each server) are disjoint for allcoordinates (experts) while in the second case, there exists one coordinate (expert) whose intersection over all sets isnon-empty. In the second case, this expert has a maximum cost of 0 while all other experts incur a maximum costof 1. If we can decide which case we are in, then we solve the set disjointness problem, and thus there is an (ns)communication bound. By copying the same hard instance over T days, it follows that if there exists an algorithmthat can achieve sub-constant regret for this distributed experts problem, then the algorithm also solves the above setdisjointness problem. We have thus obtained an (ns) communication bound for the maximum aggregation functionin the message-passing model. Note that EWA can achieve the optimal regret with O(ns) communication if we assumeT O(poly(log (ns))), and therefore, we cannot do better than EWA up to logarithmic factors with the maximumaggregation function in the message-passing model. To give the lower bound proof, we rst dene the -DIFFDISTproblem.Denition B.4. (-DIFFDIST problem, Srinivas et al. (2022)). There are T players, and each has n bits of informationindexed from 1 to n. Let 0 = Bernoulli( 1",
  "(Case A). Each index for each player is drawn i.i.d. from 0": "(Case B). An index i [n] is randomly chosen, then the i-th indexed bit of each player is drawn i.i.d. from 1 whileother bits of players are all drawn i.i.d. from 0.Lemma B.5. (-DIFFDIST communication bound, Srinivas et al. (2022)). The communication complexity of solvingthe -DIFFDIST problem with a constant 1 p probability under the broadcast model, for any p [0, 0.5), is ( n",
  ")": "Note that a lower bound for the broadcast model is also a lower bound for the message-passing model. By regardingdifferent days as servers and bits as cost streams of experts, if we generate bits from either case A or case B, thenthe algorithm needs to distinguish between case A and case B to obtain regret at most . We design Algorithm 6 to",
  ";Let c =": "2 ln (24), = R(c + 1) < 1/2;Cost denition: For day t, we randomly sample a server j and dene ltj = Xj and ltj = 0, j [s]/{j};Initialize M0 as the initial memory state on the coordinator for A, counter C = 0;for t = 1 to T doObtain the actual cost l(t) = A(Mt1) incurred by A;C += l(t);Update memory state to Mt by communicating with downstream servers according to A;Let C = C",
  "2thenReturn Case A;elseReturn Case B;": "connect the -DIFFDIST with the distributed experts problem. Algorithm 6 gives a reduction from -DIFFDIST, andthus we obtain our lower bound in Theorem 5.5. The additional T s factor is from our requirement that we obtain anapproximation to the actual cost for the selected expert on each day. We present the complete proof as follows:",
  "The proof follows Srinivas et al. (2022) with a different model and objective": "Lemma B.5. In addition, if we need to know the cost of the selected expert, we need to pay an extra (s) commu-nication per day. Indeed, we need (s) communication even if we just want to verify whether the selected expertincurs zero cost or not with probability larger than9 10. This is due to the fact that we can choose our distribution sothat on each day, we choose a random server and with probability 1/2 make the cost 0 on that server, while with theremaining probability 1/2 we make the cost 1 on that server. All other servers have cost 0. Thus, if the protocol probeso(s) servers on each day, it only has a 1/2 + o(1) probability to know if the cost is non-zero or not. Thus, we needto at least probe (s) servers to succeed with constant probability on a single day, and since the days are independent,(sT ) communication in total. Thus, we overall have a communication lower bound of ( n",
  "CComparison with Kanade et al. (2012)": "Although we address a similar topic with Kanade et al. (2012), we would like to stress that our setup differs quitesignicantly. In our setup, the ground truth costs for experts are aggregated across all servers. In contrast, the setupof Kanade et al. (2012) restricts the ground truth costs for each expert to be allocated to exactly one server per day.Consequently, our setup is more general since instead of nding out the only server that carries the cost on each day,we also incur additional costs from other servers as well. In addition, Kanade et al. (2012) only proves their lowerbound for n = 2 while we handle general n. On the other hand, for n = 2, they show a lower bound for adaptiveadversaries rather than oblivious adversaries, which is our setting. However, we also make an assumption on the servermemory budget for proving lower bounds. In fact, our lower bound directly matches that of Kanade et al. (2012) whenn = 2 if we do not require the coordinator or current transcript to dictate who speaks next as the additive T s termis no longer needed. More specically, we compare in for the case when only the coordinator can initiateconversation and in for the case when both the coordinator and servers can initiate conversation.",
  "Not applicable": "Note that we can remove the T s term if the servers are allowed to spontaneously initiate conversation, in which casesynchronization between servers on each day is not required. We note that Kanade et al. (2012)s upper bound is notapplicable in our setting as it assumes the cost (payoff vector) to be distributed to only one server. At the same time,we allow the cost to be distributed to any number of servers. Thus, their setup is a special case of ours. We notethat our bounds also match those of Kanade et al. (2012) in this special case, e.g., our upper bound is also O( n R2 ). Inshort, our results are incomparable as we allow: 1. Costs to be distributed to any number of servers 2. Any n for thelower-bound proof against oblivious adversaries rather than adaptive adversaries.",
  "DSimulated Experiments": "Evaluation setup. In this section, we evaluate the performance of DEWA-S and DEWA-S-P with the summationaggregation function, and DEWA-M and DEWA-M-P with the maximum aggregation function. We measure theaverage regrets over the days and total communication costs and compare the performance with EWA when be =n, and with Exp3 when be = 1. We further evaluate two cost distributions, namely, the Gaussian and Bernoullidistributions. On each server, the costs of the experts are randomly sampled from these distributions. For the bestexpert, the costs are sampled from N(0.2, 1) or Bernoulli(0.25), and for the other experts, the costs are sampledfrom N(0.6, 1) or Bernoulli(0.5). For the summation aggregation, all of the costs are truncated to the range and then divided by the number of servers s. To show the robustness of our protocols under extreme cost conditions,we also evaluate a scenario where the costs are sparsely distributed across the servers, i.e., the cost of an expert is heldby one server, and other servers receive zero cost for that expert. To further emphasize the effectiveness of our protocoldesign in such sparse scenarios, we implement and evaluate the performance of the simplied DEWA-S and DEWA-Mand we treat them as BASE-S and BASE-M along with their high probability versions BASE-S-P and BASE-M-P .We describe the detail of the baseline algorithms in the following section. We set the learning rate = 0.1, the numberof servers to be s = 50, the number of experts to be n = 100, and the total days to be T = 105 for be = 1 and to beT = 104 for be = n. We set the sampling budget bs = 2 for BASE-S and BASE-S-P . The experiments are run on anUbuntu 22.04 LTS server equipped with a 12 Intel Core i7-12700K Processor and 32GB RAM.",
  "n ), ti,j Bernoulli( 1": "s). This is a good baseline to compare with since lti is also an unbiasedestimator. However, due to the uniform sampling strategy, BASE-S will fail in the sparse setting and require anadditional factor of s in the regret while DEWA-S does not suffer from this. For BASE-M , we uniformly sample among servers and take the maximum cost encountered as the estimate of theactual cost lti. To illustrate the effectiveness of DEWA-M , we enforce that the overall communication cost for BASE-M is close to DEWA-M when be = 1 or be = n.",
  "D.2Results of Gaussian Distribution Cost": "In , we rst present the regrets of DEWA-S and DEWA-S-P on the Gaussian distribution with the summationaggregation function in the non-sparse setting. As we can see in a, with sampling budget be = 1, DEWA-S achieves much smaller regrets than Exp3. And the protocols average regrets over t are converging to 0 withincreasing t. The regrets of all the protocols are comparable to that of EWA when the sampling budget be = n, asshown in b. However, for the sparse scenario, as shown in , the regrets of DEWA-S and DEWA-S-Pare much better than BASE-S and BASE-S-P . When be = 100, DEWA-S and DEWA-S-P can still achieve comparableperformance to EWA in the sparse setting. The results further illustrate that our design is effective and can handle suchextremely sparse cost conditions. As expected, the high-probability versions of the protocols consistently achievelower regret than their constant-probability versions. For the maximum aggregation function, we observe similar results as shown in and . The regrets ofDEWA-M and DEWA-M-P are close to EWA when be = n, and their performance is much better than Exp3 whenbe = 1. We also observe that the regrets of BASE-M and BASE-M-P are close to that of DEWA-M and DEWA-M-Pin the non-sparse setting. However, their communication costs are much higher than DEWA-M and DEWA-M-P whenbe = n, as shown in and . Consistent with our ndings for the summation aggregation function, in thesparse setting, the regrets of BASE-M and BASE-M-P are much higher than DEWA-M and DEWA-M-P . The resultsillustrate that DEWA-M and DEWA-M-P are not restricted to i.i.d. costs among the servers, and they work well inextremely sparse settings. Thus, we conclude that DEWA-M and DEWA-M-P have wider application scopes. We report our communication costs for constant a probability guarantee in and for a high probability guaranteein . We use the communication cost of EWA as the baseline (1), which is O(nT s + T s). According to ourresults, for be = 1 and be = n, DEWA-S and DEWA-S-P use much smaller communication than Exp3 and EWArespectively. We also notice that, in the sparse setting, DEWA-M and DEWA-M-P use much smaller communicationto achieve near-optimal regret, since DEWA-M and DEWA-M-P can quickly identify the server holding large costs.Although the BASE counterparts achieve comparable communication costs to DEWA-S , DEWA-S-P , DEWA-M ,and DEWA-M-P , considering their much larger regret in the sparse setting, DEWA-S , DEWA-S-P , DEWA-M , andDEWA-M-P are more consistent across settings. By increasing be, the protocols achieve lower regret at the cost ofmore communication. Users can choose be according to their regret requirements and communication budget. Even ifwe set be = n, the communication costs are still much smaller than that of EWA, but the regret of our algorithms isvery close to optimal.",
  "D.4Evaluation Results under Different be": "To further study the inuence of be on our algorithms, we evaluate the regret and communication cost of DEWA-S-P and DEWA-M-P under different be, ranging from 1 to n = 100. The results on the regret results can be foundin . As expected, using a larger be makes the regret converge faster. We observe that using a reasonably largevalue (0.25n in our experiments) is sufcient to achieve good regret. The resulting communication cost using differentbe can be found in . As expected, the cost generally grows linearly with respect to increasing be."
}