{
  "Abstract": "Recent AI-driven step-function advances in several longstanding problems inmusic technology are opening up new avenues to create the next generation ofmusic education tools. Creating personalized, engaging, and effective learningexperiences is a continuously evolving challenge in music education. Here wepresent two case studies using such advances in music technology to addressthese challenges. In our first case study we showcase an application that usesAutomatic Chord Recognition to generate personalized exercises from audio tracks,connecting traditional ear training with real-world musical contexts. In the secondcase study we prototype adaptive piano method books that use Automatic MusicTranscription to generate exercises at different skill levels while retaining a closeconnection to musical interests. These applications demonstrate how recent AIdevelopments can democratize access to high-quality music education and promoterich interaction with music in the age of generative AI. We hope this work inspiresother efforts in the community, aimed at removing barriers to access to high-qualitymusic education and fostering human participation in musical expression.",
  "Introduction": "Music holds a unique power to evoke emotions, foster creativity, and build cross-cultural connections.However, traditional music education often adopts a one-size-fits-all approach, emphasizing classicalrepertoires or mainstream genres that may not resonate with the diverse musical preferences ofmodern students. Rigid pedagogical methodology risks alienating learners whose tastes lie beyondthe confines of the selected curriculum, hindering engagement and enthusiasm. Advances in AIresearch can be used to offer transformative solutions in this regard personalized music educationtailored to each students unique musical identity. By curating lessons around an individuals favoriteartists, genres, and songs, we can create inclusive environments where students can fulfill theirmusical potential. AI music generation has garnered significant attention and made immense progress in recent years . We share the opinion that the practice of music is valuable far beyond just the final output. Using generative AI beyond music synthesis, towards analysis of musical concepts from audiodata to personalize and support music education remains an under-explored and exciting area for thecommunity. In the following sections, we first explore the importance of leveraging students individual musicalpreferences to enhance motivation and improve learning outcomes. We then present two case studiesthat showcase the potential of AI-driven music technology in education. One is an ear trainingapplication (app) that generates customized exercises based on students favorite songs. The other isan AI-powered piano method book prototype that adapts to students skill levels and musical interests.",
  "Need for personalization": "Conventional music curricula tend to prioritize mastery of Western classical music, folk traditions,and works of renowned composers. While this canonical approach provides a solid foundation, itcan fail to captivate students whose musical interests lie in contemporary, non-Western, or nichegenres . The lack of representation of personal tastes in educational content can disengage learners,limiting their motivation and ability to connect with the material . As an example, a student drawninto picking up the practice of music through their interest in electronic dance music may find itchallenging to engage with a curriculum focused on Baroque-era compositions . Extensive research highlights the benefits of personalized learning experiences . Self determina-tion theory suggests that relatedness and autonomy are key components to sustain intrinsic motivationin the pursuit of achievement and performance . Incorporating the students preferred music anddesigning ways to interact with it can enhance agency and connection, supporting the educationalendeavor . Moreover, the emotional resonance of music is thought to play a pivotal role in its educational efficacy. Personalization in music education directly impacts skill acquisition, as engaged students aremore likely to practice consistently and persevere through challenges . For an individual student, the limitations of traditional music education can be circumvented byworking with an exceptional music teacher. Such teachers could incorporate the students preferredgenres with a deep understanding those genres, and with the dedication to create a highly personalizedlearning experience . From the teachers perspective, creating such experiences requiressubstantial time and effort towards transcribing songs, arranging them to suit the students currentskill level, and designing targeted exercises to develop specific abilities, such as ear training andpiano technique. Tools can help ease this burden and enable better teaching of personalized content;even something as simple as automated harmonic analysis of symbolic music, like ChordNamer 1.Given the demands on music teachers, this is uncommon and inaccessible to the majority of musicstudents .",
  "AI powered solutions": "We can build digital systems to serve as adaptive learning environments that cater to each studentsunique musical interests and learning needs, at scale . Through the analysis of audio tracks ineach students listening history, AI could enable creation of dynamic lesson plans and exercisestailored to individual interests as has been explored in language learning settings . Moreover,these adaptive learning systems could monitor student progress, adjusting the content and difficultyof lessons to maintain challenge and interest through the learning process.",
  "The particular technologies we use for our case studies are Automatic Chord Recognition (ACR),beat detection, and Automatic Music Transcription (AMT)": "Automatic Chord Recognition (ACR) has evolved considerably from early knowledge-based systemstowards data-driven machine learning approaches . Current tools like ChordAI 2, Chordify 3, andlibraries like crema 4, as well as data-sets like Chord-Annotations 5 are some of the resources thatare available at present. Beat detection is often performed as a step on the way to chord recognition,although dedicated open-source tools such as BeatNet also exist. Automatic Music Transcription (AMT) is the process of converting audio recordings into symbolicmusical representations such as sheet music . Researchers have explored options ranging fromsignal processing techniques to machine learning algorithms for AMT. In recent years, deeplearning models have demonstrated remarkable progress in accurately transcribing polyphonic music, and may soon be application-ready. Some of the main tools available at this time are",
  "Piano Cover Generation (PiCoGen) , Pop2Piano , piano-transcription 6 , Piano2Notes7, and Audio to sheet music converter 8": "While it is clear that the underlying music technologies required for music education systems havebeen researched for some time now, their practical deployment has been limited by accuracy concerns.Students must be able to trust the system, which requires the underlying technologies to have verylow error rates. With AI approaches these technologies are now approaching expert level performanceand crossing over to a regime where they can effectively be deployed in educational contexts.",
  "Ear Training App": ": Overview of RealEarTrainer. (a) The student can select custom audio tracks. AI modulesdetect beats and identify chords within these tracks. The app generates personalized exercises usingsnippets sourced from the selected audio tracks. Calibrating exercises based on learning history, goalspecification, and current performance could be achieved with another AI module. (b) RealEarTrainerinterface to select preferred music from a list of available tracks. (c) During the exercise, the appplays a snippet from one of the selected tracks and prompts the student to identify the chords beingplayed. The sound icon on each chord in the options plays a synthesized piano version that can beused by the student to make the harmonic content salient. Traditional ear training tools have relied on the use of piano sounds or the students primary instrumentto facilitate the development of aural skills. In real-world musical contexts, students must contendwith a myriad of textures, timbres, and parts distributed across multiple instruments. To address thischallenge, some students resort to training without the aid of dedicated tools, relying solely on theirability to listen to music and reproduce it on their instrument. This approach, while valuable, canbe time-consuming and may not always provide targeted feedback for improvement. Weve foundapp-based tools, such as our personal favorite Chet 9, to be effective and helpful not only for building",
  "foundational ear training skills but also for bridging the gap between learning environments andreal-world musical contexts": "We developed an ear training application that uses beat detection and ACR to analyze student-provided audio files, and generate a personalized ear training curriculum that features snippets andexamples drawn directly from the students preferred music. This app is called RealEarTrainer[ and is available for download for iOS. a-c shows anoverview of the app and interface, that we also describe below: The student begins by selecting their preferred audio tracks within the app. AI modules identifychords and align them with the beats of each track. This analysis is used to generate a series of tailoredexercises. In each exercise, the student listens to a short snippet sourced from one of their chosentracks and attempts to identify the chords being played. The app optionally provides synthesizedpiano chords aligned with chord changes in the audio snippet. This feature is designed to highlightthe harmonic content, assisting students until they can confidently identify chords from the originalaudio alone. While the core experience of connecting ear training quizzes to the students preferred music isalready functional in the app, we recognize that there is a lot of room in refining how this contentis presented to the student. In particular, tuning exercise difficulty based on past performance andspecific goals (e.g. distinguishing between specific chord families) could be achieved by a calibratormodule in future versions.",
  "Personalized piano method book": "Aspiring musicians often find their initial spark of inspiration in a beloved song or piece of music.This passion serves as a driving force behind their decision to learn an instrument, towards the goalof being able to play that piece. Often, a first step is to pick up a method book for the instrument. For piano, method books have a rich pedagogical history and intended to teach essential theoreticalknowledge and technical skills. However, they are limited from a personalization point of view.Consequently, students may find themselves with pieces and exercises that, while valuable from aneducational perspective, lack the personal resonance and emotional connection that initially drewthem to the instrument. This opens up the prospect of AI-powered piano method books that adapt toeach students musical interests and preferences. We think personalization can be achieved throughtwo primary approaches. First, AI can be employed to analyze songs chosen by the student and generate custom arrange-ments that align with their current skill level and learning objectives. This can be achieved throughadapting and simplifying the original compositions. It could, for instance, remove complex ornamen-tations, simplify arpeggio patterns and left-hand accompaniment to block chords, among many othersimplifications. Second, AI can be used to create exercises that address technical demands specific to the studentschosen music. As opposed to providing a fixed suite of drills, a next generation method bookwould analyze chord progressions, rhythmic patterns, and melodic elements in the selected songs toconstruct exercises that directly build the skills necessary to play those specific pieces. For example,if a particular song features a complex syncopated rhythm in the left-hand accompaniment, thegenerated exercises target development of coordination and timing required to execute that specificrhythm accurately. These targeted exercises would be presented alongside the simplified arrangementof the song, allowing the student to develop the necessary skills in a focused and purposeful manner. We demonstrate this concept with a short excerpt from Yann Tiersens \"Comptine Dun Autre tLaprs\". We focus on measures 30 - 34 of the piece and prototype an AI system that can simplify thearrangement and generate targeted exercises for a beginner. Our prototype simplifies the left hand part to block chords using the notes present in each measure,and removes the 16th note ornaments in the right hand, b. This maintains the overall structureand melody of the original piece while being more accessible for a beginner to play. This simplifiedarrangement serves as an achievable milestone on the path to mastering the original composition.",
  "In addition to the simplified arrangement, our prototype generates targeted exercises to help thestudent develop specific skills required to play this excerpt. c shows an example exercise": ": Re-imagined piano method books. (a) We obtain the score for bars 30 - 34 of ComptineDun Autre t Laprs using Piano2Notes as our transcriber. (b) A mix of procedural and ACR AImodules is used to distill the piece by removing ornamentations and providing block chords thatmake the core idea easy to follow and play on the piano. (c) Modules to suggest scales over the blockchord changes serve to build the related skills while maintaining a connection to the original piece.",
  "focused on learning relevant scales over the chord changes. This exercise focuses on playing thescale of the piece, while transitioning between chord changes found in the original excerpt": "Further exercises could target specific skills such as playing the melodic rhythm with the right hand,mastering the rhythm interplay between both hands, and mastering the left-hand accompanimentpattern. Breaking down the original piece into manageable components supports the studentsprogress towards confidently learning the entire piece and these can now be created using theoriginal audio file!",
  "Discussion": "AI is poised to enable a paradigm shift in music education, away from rigid curricula prevalent intraditional approaches towards those where personalization take center stage. In our opinion, theimpact of personalized approaches such as those showcased here for ear training and method books,extends far beyond simple convenience or novelty. By directly linking effort and practice to animproved ability to understand, appreciate, and play the music the student loves, such applicationscan support the learning process for skills that have much broader utility. Access to skilled teachers is usually limited, and it tends to be expensive as well. Through applicationslike ours, students can receive tailored instruction at a fraction of the cost of private lessons. However,wed like to note that AI-powered music education is not intended to replace human teachers. Rather,it can serve as a powerful tool to augment and enhance the work of music educators. AI systems canhandle the time-consuming tasks of content creation and adaptation, freeing up teachers to focus onhigher-level skills such as musical expression, creativity, and collaboration. While our case studies demonstrate the potential of AI-powered personalization in music education,we acknowledge that comprehensive assessment of these approaches effectiveness remains as futurework. Rigorous evaluation through controlled studies comparing traditional and AI-enhanced learningmethods, along with longitudinal studies tracking student progress and engagement over time, will becrucial to validate these approaches. Here we have demonstrated an engaging ear training experience, and a conceptual approach totailoring method books at various difficulty levels, both enabled by AI. These efforts are directedtowards lowering barriers, increasing personalization, and we present it with a hope that it inspiresother attempts in music education. We are grateful to Stochastic Labs for their support and for fostering an innovative environment thathas been instrumental in developing RealEarTrainer. Their commitment to exploring the intersectionof AI and human creativity aligns with our vision for transforming music education.",
  "We would like to express our sincere gratitude to Vivien Seguy, creator of ChordAI, for his remarkableon Automatic Chord Recognition (ACR), which has been crucial inspiration for these ideas": "Koray Tahiroglu, Shenran Wang, Eduard Tampu, and Jackie Lin. Deep learning with audio:An explorative syllabus for music composition and production. In AIMC 2023 Proceedings:Conference on AI and Music Creativity 2023, 2023. Conference on AI and Music Creativity. Jade Copet, Felix Kreuk, Itai Gat, Tal Remez, David Kant, Gabriel Synnaeve, Yossi Adi, andAlexandre Dfossez. Simple and controllable music generation. Advances in Neural InformationProcessing Systems, 36, 2024.",
  "Locky Law. Application of generative artificial intelligence (genai) in language teaching andlearning: A scoping literature review. Computers and Education Open, page 100174, 2024": "Johan Pauwels, Ken OHanlon, Emilia Gmez, Mark Sandler, et al. 20 years of automatic chordrecognition from audio. In Proceedings of the 20th International Society for Music InformationRetrieval Conference (ISMIR), 2019. Mojtaba Heydari, Frank Cwitkowitz, and Zhiyao Duan. Beatnet: Crnn and particle filtering foronline joint beat downbeat and meter tracking. In Proceedings of the 22nd International Societyfor Music Information Retrieval Conference (ISMIR), 2021.",
  "Josh Gardner, Ian Simon, Ethan Manilow, Curtis Hawthorne, and Jesse Engel. Mt3: Multi-taskmultitrack music transcription. arXiv preprint arXiv:2111.03017, 2021": "Hayato Sumino, Adrien Bitton, Lisa Kawai, Philippe Esling, and Tatsuya Harada. Automaticmusic transcription and instrument transposition with differentiable rendering. In Proceedingsof the 2020 Joint Conference on AI Music Creativity, 2020. Qiuqiang Kong, Bochen Li, Xuchen Song, Yuan Wan, and Yuxuan Wang. High-resolutionpiano transcription with pedals by regressing onset and offset times. IEEE/ACM Transactionson Audio, Speech, and Language Processing, 29:37073717, 2021. Chih-Pin Tan, Shuen-Huei Guan, and Yi-Hsuan Yang. Picogen: Generate piano covers witha two-stage approach. In Proceedings of the 2024 International Conference on MultimediaRetrieval, pages 11801184, 2024. Chih-Pin Tan, Hsin Ai, Yi-Hsin Chang, Shuen-Huei Guan, and Yi-Hsuan Yang. Picogen2:Piano cover generation with transfer learning approach and weakly aligned data. arXiv preprintarXiv:2408.01551, 2024.",
  "ASupplementary material": "simplify.py is a python script that accepts a MusicXML file as input, replaces the left hand pianopart with one consisting only of block chords and the right hand part by modifying 16th note pairswith an 8th note of the first pitch. Also included are the output from the Piano2Notes service, and aMusicXML file corresponding to the 4 bars mentioned in the main text.",
  "Cultural Bias: The AI models used in these applications are likely trained on datasets that may notrepresent the full diversity of global musical traditions": "Limited Assessment: While we present promising applications, this work does not include com-prehensive assessment of their effectiveness. Controlled studies comparing these AI-enhancedapproaches with traditional methods are needed. Additionally, while personalization can increaseengagement, the long-term effects of these AI-powered approaches on music skill development andretention have not been thoroughly studied. Future work should include: Comparative studies between traditional and AI-enhanced curricula. Quantitative metrics for learning outcomes and skill development. User experience studies with diverse student populations. Longitudinal research to validate effectiveness over time. Technical Barriers: The proposed solutions require access to devices capable of running sophisti-cated AI models, which may not be available to all students, potentially exacerbating educationalinequalities.",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-perimental results of the paper to the extent that it affects the main claims and/or conclusionsof the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justification: We have added outputs from the services used, and the scripts used to manipu-late them. As well, links to all the software products, libraries and papers used.Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible is important, regardless ofwhether the code and data are provided or not.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  ". Experimental Setting/Details": "Question: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand theresults?Answer: [NA]Justification: There are no experiments presented in the paper.Guidelines: The answer NA means that the paper does not include experiments. The experimental setting should be presented in the core of the paper to a level of detailthat is necessary to appreciate the results and make sense of them.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [NA]Justification: There are no experiments presented in the paper.Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
  ". Experiments Compute Resources": "Question: For each experiment, does the paper provide sufficient information on the com-puter resources (type of compute workers, memory, time of execution) needed to reproducethe experiments?Answer: [NA]Justification: There are no experiments presented in the paper.Guidelines: The answer NA means that the paper does not include experiments. The paper should indicate the type of compute workers CPU or GPU, internal cluster,or cloud provider, including relevant memory and storage.",
  ". Code Of Ethics": "Question: Does the research conducted in the paper conform, in every respect, with theNeurIPS Code of Ethics [Yes]Justification: Reviewed and confirmed that the paper conforms to the Ethics Guidelines.Guidelines: The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. If the authors answer No, they should explain the special circumstances that require adeviation from the Code of Ethics.",
  "Justification: The paper outlines the positive social impact of making music education moreaccessible, as well as highlight the potential negative impact on music teachers.Guidelines:": "The answer NA means that there is no societal impact of the work performed. If the authors answer NA or No, they should explain why their work has no societalimpact or why the paper does not address societal impact. Examples of negative societal impacts include potential malicious or unintended uses(e.g., disinformation, generating fake profiles, surveillance), fairness considerations(e.g., deployment of technologies that could make decisions that unfairly impact specificgroups), privacy considerations, and security considerations. The conference expects that many papers will be foundational research and not tiedto particular applications, let alone deployments. However, if there is a direct path toany negative applications, the authors should point it out. For example, it is legitimateto point out that an improvement in the quality of generative models could be used togenerate deepfakes for disinformation. On the other hand, it is not needed to point outthat a generic algorithm for optimizing neural networks could enable people to trainmodels that generate Deepfakes faster. The authors should consider possible harms that could arise when the technology isbeing used as intended and functioning correctly, harms that could arise when thetechnology is being used as intended but gives incorrect results, and harms followingfrom (intentional or unintentional) misuse of the technology. If there are negative societal impacts, the authors could also discuss possible mitigationstrategies (e.g., gated release of models, providing defenses in addition to attacks,mechanisms for monitoring misuse, mechanisms to monitor how a system learns fromfeedback over time, improving the efficiency and accessibility of ML).",
  "Guidelines:": "The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  "According to the NeurIPS Code of Ethics, workers involved in data collection, curation,or other labor should be paid at least the minimum wage in the country of the datacollector": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA]Justification: No crowdsourcing or research with human subjects used in the paper.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}