{
  "Abstract": "Climate change is increasing the frequency of extreme precipitation events, makingweather disasters such as flooding and landslides more likely. The ability to accu-rately nowcast precipitation is therefore becoming more critical for safeguardingsociety by providing immediate, accurate information to decision makers. Mo-tivated by the recent success of generative models at precipitation nowcasting,this paper: extends the DYffusion framework to this task and evaluates its perfor-mance at forecasting IMERG satellite precipitation data up to a 4-hour horizon;modifies the DYffusion framework to improve its ability to model rainfall data;and introduces a novel loss function that combines MSE, MAE and the LPIPSperceptual score. In a quantitative evaluation of forecasts up to a 4-hour horizon,the modified DYffusion framework trained with the novel loss outperforms fourcompetitor models. It has the highest CSI scores for weak, moderate, and heavyrain thresholds and retains an LPIPS score < 0.2 for the entire roll-out, degradingthe least as lead-time increases. The proposed nowcasting model demonstratesvisually stable and sharp forecasts up to a 2-hour horizon on a heavy rain casestudy1.",
  "Introduction": "The ability to accurately nowcast (predict up to 6 hours in advance ) precipitation, is a vital taskthat can help mitigate hazards such as flooding or landslides . Globally, heavy precipitation eventsare becoming more common due to climate change , causing large human displacement,human fatalities , and economic cost. Accurate precipitation forecasts are therefore becoming moreinstrumental in providing critical information required for weather-dependent decision making thatcan safeguard society. The absence of effective precipitation models especially impacts countries thatlack access to freely available ground-based radar systems and experience vulnerability in resourcemanagement, agriculture, disaster preparedness, and climate adaptation. This work evaluates the applicability of a novel probabilistic, spatio-temporal forecasting framework,DYffusion , to precipitation nowcasting. This research is motivated by the recent success ofgenerative modelling at this task and, DYffusions skilful forecasts over long horizons on Navier-Stokes flows and sea surface temperatures (SST); two systems that exhibit complex dynamicscomparable to that of precipitation. In this study, the focus is on how well DYffusion can forecast up",
  "Data": "This research uses the publicly available satellite precipitation product, IMERG. In particular, it usesthe latest version (V07B ) of the half-hourly, Early Run product with a 0.1o spatial resolution andprecipitation rates in mm h1. The dataset is created from four 128128 grid boxes that cover theSouth American countries: Colombia, Ecuador and Per. These are regions that are susceptible toincreased flooding and have limited availability of weather radar2. The four 128128 grid boxes arestacked into dimensions: (N, S, C, H, W) where N is the number of samples, S is the sequence length(input and target) and C is the number of channels (1 for IMERG). The data is preprocessed to using linear normalisation, log(1 + X) transform and min-max normalisation. For this research, a4-hour horizon or 81128128 images, was chosen to match the latency of the Early-Run IMERGproduct and avoid any discontinuity of real-time data.",
  "The DYffusion framework is outlined in . It consists of an Interpolator network, I and aForecastor network, F": "Training. I is trained to interpolate any timestep of the sequence xt+in, given the initial and finalstates, x0 and xt+h, respectively. F is trained to forecast the horizon xt+h given the initial conditionx0 and an intermediate state xt+in. This two-stage training has a constant memory footprint as afunction of h, only requiring x0 and xt+h (plus xt+in during the Interpolator training). Inference. Given an initial condition, x0, the entire sequence x = [xt+in]hn=1 is generated overN (or h) auto-regressive steps. At step s = 0 (n = s + 1), F predicts the horizon xs=0t+h using onlyx0. I then interpolates xt+i1 using x0 and xs=0t+h. At the next step (s = 1), F predicts the horizonagain xs=1t+h, using x0 and xt+i1. xs=1t+h and x0 are then used to interpolate, xt+i2. This process isrepeated until F predicts xs=N1t+h(N times), using the nearest intermediate value, xt+iN1. Thisiterative process is analogous to the iterative denoising in standard diffusion models and underpinsthe time-coupled, DYnamics informed nature of the DYffusion framework. The final forecast is themean of an ensemble of X members. The probabilistic nature of DYffusion occurs through Monte Carlo dropout. I is trained with dropoutrates that are enabled during the training (and inference) of F. Enabling dropout during trainingis analogous to I interpolating xt+in by sampling it from the conditional probability distributionP(xt+in|x0, xt+h).",
  "According to the World Meteorological Organisations (WMO) radar database, South America has roughly1/4 of North Americas or Europes radar": ": An illustration of DYffusion sampling: DYffusion forecasts a sequence of N (or h)timesteps xt+i1 , xt+i2 , ... , xt+h given the initial condition x0. xt+h is forecasted at each step usingx0 and the nearest intermediate value xt+in. 1. Loss Function. Replaced the L1 loss with a novel loss function (referred to as LCB),combining the Learned Perceptual Image Patch Similarity (LPIPS) score with the class-weighted Mean Squared Error (MSE) and Mean Absolute Error (MAE) loss proposed in (referred to as CBLoss in ). LCB was constructed as follows:",
  "LCB = (1 ) LPIPS + CBLoss()(1)": "Based on experimental results during Interpolator training, was set to 0.6, optimising forMSE, LPIPS and Critical Success Index (CSI) at varying thresholds. This value slightlybiases the CBLoss towards spatial accuracy, while the perceptual component prevents large-scale features from dominating and improves image detail. Lower values (< 0.6) led tobackground artefacts and magnitude errors. For the CBLoss, the scaling term was set to1.0 to equally weight the MSE and MAE components, and the rainfall classes (in mm h1)and their associated weights were:",
  "(2)": "2. Forecastor Training. Removed any exposure to the horizon xt+h during Forecastor trainingto better emulate the sampling process. Referring to Algorithm 1, Stage 2, Step 2 in theoriginal DYffusion paper, the intermediate values xt+in are now interpolated using theinitial condition x0 and an initial forecast xinitalt+hinstead of the target xt+h. This initialforecast is generated using only the initial conditions (F(x0, x0) = xinitialt+h) to directlyreplicate the sampling procedure. A separate loss term for the initial forecast is added to theexisting loss in Stage 2, Step 3 of Algorithm 1 in the original DYffusion paper. The updatedloss function (including the one-step-ahead loss) becomes:",
  "Loss = Linitial + (1 )[1Lforecast + 2Lonestepahead](3)": "Where L represents the loss function and is used to balance the different terms. Fortraining, a linear schedule is used to calculate , starting at = 1 (decaying to 0 over 20epochs) to place more emphasis on the initial forecast at the start of training. 1 and 2 areboth set to 0.5, inherited from the original DYffusion implementation.",
  "We compare DYffusion to auto-regressive implementations of both deterministic and statisticalmethods to align more closely with DYffusions roll-out inference:": "ConvLSTM : implemented the same 2-layer architecture used on the Radar Echodataset, but with increased hidden states (128 vs 64), larger kernels (55 vs 33), and addi-tional pixel-wise dropout (either 0.15 or 0.4) after each ConvLSTM cell for regularisation.The ConvLSTM was trained to predict the next timestep from the previous 41128128images (2 hours). Short-Term Ensemble Prediction System (STEPS): implemented in PySteps following the STEPS example on the PySTEPS website3. The previous 41128128images (2 hours) were used as input and the units were transformed from mm h1 to dBRbefore estimating the motion field and forecasting the next timestep.",
  "Results": ": The 4-hour averaged results on the test dataset for each of the evaluated models. The bestmetric score is highlighted in black and the second best score is highlighted in blue. The CRPS iscalculated on the transformed data ( ), explaining the lower magnitude. The CRPS and SSRmetrics for the deterministic ConvLSTM models are zeroed. CSI thresholds were evaluated at 2,10 and 18 (in mm h1) to cover weak, moderate and heavy rain classifications respectively. Thesampling times were recorded using an NVIDIA L4 GPU.",
  "Model MSE LPIPS CSI2 CSI10 CSI18 CRPS SSRTime [s]": "DYffusionLCB0.00200.1450.2700.1120.0640.0130.1313DYffusionL10.00150.3230.2270.0680.0230.0100.0503ConvLSTMLCB0.00850.2720.1390.0270.0101.2ConvLSTMBCE0.00520.3350.1650.0380.0161.2STEPS2.41020.3420.1400.0300.0110.0130.2192.1 shows the 4-hour averaged forecast evaluation metrics for each of the models on the testdataset. For both DYffusion and the baseline ConvLSTM , two models were trained. One modelwas trained using the LCB loss and a second model was trained using the models native loss function:L1 loss for DYffusion and binary cross-entropy (BCE) loss for ConvLSTM. The DYffusion andSTEPS models are evaluated by taking the mean prediction from a 10-member ensemble. demonstrates each models nowcasting ability on the heavy precipitation event, Cyclone Yaku. The forecasts clearly show the improved sharpness, detail and stability of DYffusionLCB,especially up to a 2-hour horizon. This is supported by its outperforming CSI and LPIPS scores in. DYffusionLCB can distinguish between heavy rain intensities in the band of rain movingtoward the coast, and it tracks the split at the top of the rain-band forming at around t + 120 min.The ConvLSTMLCB also demonstrates improved sharpness (at earlier timesteps) compared to theConvLSTMBCE, indicating the effectiveness of the LCB loss function at capturing the small-scalefeatures. DYffusionLCB more accurately forecasts Cyclone Yakus spatial expansion compared toSTEPS. However, shows that optical flow methods remain effective at earlier timesteps,before chaotic behaviour emerges. Computational Resources.DYffusion was trained on an NVIDIA L4 GPU, which is readilyaccessible through cloud computing vendors at reasonable costs. Training took 20 minutes per epochfor the Interpolator (60 epochs, 20 hours total) and 1.5 hours per epoch for DYffusion with a10-member ensemble (25-30 epochs, 40 hours total). The IMERG dataset requires 18GB of storage.",
  "Conclusion": "In this study, DYffusion has been extended to the task of precipitation nowcasting. The task wasto forecast IMERG precipitation data at 30-minute intervals up to a 4-hour horizon, generatinga total of 81128128 images. By applying key modifications to the DYffusion frameworkand introducing a novel loss function, the modified framework outperforms both deterministic(ConvLSTM) and statistical (STEPS) baselines. Overall, the initial results of DYffusionLCB suggest",
  ": The evolution of Cyclone Yaku over 4 hours beginning at 03:00 UTC on March 9, 2023.The hourly forecast values (undersampled) are shown for each of the five evaluated models": "that with some improvements, the DYffusion framework is a potential candidate for operationalprecipitation nowcasting. The constant memory footprint associated with the forecast-interpolateprocess makes it an attractive alternative to single-pass generative networks. Limitations.Nowcasting precipitation is more challenging than SST or Navier-Stokes. The initialtask of forecasting the 4-hour horizon from a single timestep is difficult. The implemented U-Netbackbone struggles to not forecast xinitialt+has an expansion or reduction of the initial conditionx0. This ultimately constrains the problem to the spatial domain of x0, contributing to the limitedvariability in the ensemble forecasts. Future Work.The results of demonstrate the importance of high SSR scores for more skilfulprecipitation nowcasts. Conditioning the initial forecast xinitialt+hwith atmospheric information, suchas divergence at 925 hPa and wind speed, is an interesting avenue to explore. The additional physicalcontext should help the model capture the non-linear chaotic evolution of the rainfall, especially atearlier timesteps, similar to the motion field in STEPS. This should improve xinitialt+hand, therefore,the overall stochasticity by allowing the framework to sufficiently explore P(xt+i1:t+h|x0).",
  "Shi X, Chen Z, Wang H, Yeung D, Wong W, Woo W. Convolutional LSTM Network: A MachineLearning Approach for Precipitation Nowcasting. CoRR. 2015;abs/1506.04214. Availablefrom:": "Bowler NE, Pierce CE, Seed AW. STEPS: A probabilistic precipitation forecasting schemewhich merges an extrapolation nowcast with downscaled NWP. Quarterly Journal of the RoyalMeteorological Society. 2006;132:2127-55. Available from: Pulkkinen S, Nerini D, Prez Hortal AA, Velasco-Forero C, Seed A, Germann U, et al. Pysteps:An open-source Python library for probabilistic precipitation nowcasting (v1. 0). GeoscientificModel Development. 2019;12(10):4185-219."
}