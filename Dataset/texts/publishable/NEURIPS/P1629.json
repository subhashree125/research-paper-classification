{
  "Abstract": "Recent development in Artificial Intelligence (AI) models has propelled their ap-plication in scientific discovery, but the validation and exploration of these discov-eries require subsequent empirical experimentation. The concept of self-drivinglaboratories promises to automate and thus boost the experimental process fol-lowing AI-driven discoveries. However, the transition of experimental protocols,originally crafted for human comprehension, into formats interpretable by ma-chines presents significant challenges, which, within the context of specific expertdomain, encompass the necessity for structured as opposed to natural language,the imperative for explicit rather than tacit knowledge, and the preservation ofcausality and consistency throughout protocol steps. Presently, the task of proto-col translation predominantly requires the manual and labor-intensive involvementof domain experts and information technology specialists, rendering the processtime-intensive. To address these issues, we propose a framework that automatesthe protocol translation process through a three-stage workflow, which incremen-tally constructs Protocol Dependence Graphs (PDGs) that approach structured onthe syntax level, completed on the semantics level, and linked on the executionlevel. Quantitative and qualitative evaluations have demonstrated its performanceat par with that of human experts, underscoring its potential to significantly expe-dite and democratize the process of scientific discovery by elevating the automa-tion capabilities within self-driving laboratories.",
  "Introduction": "The evolution of AI techniques has significantly accelerated the processes inherent to scientific dis-covery, with a notable impact observed within the domain of experimental sciences (Wang et al.,2023b). This influence is manifested through a variety of avenues: the generation of hypothesisspaces informed by extensive literature analysis (Jablonka et al., 2022; Kim et al., 2024), the inter-pretation of observational data via the identification of high-dimensional correlations (Jumper et al.,2021; Abramson et al., 2024), the engineering of novel structures that meet predefined specifica-tions (Grisoni et al., 2021; Park et al., 2023), and the implementation of comprehensive simulationsto ascertain the characteristics of potential products (Hie et al., 2021; Singh et al., 2023). However, the findings facilitated by AI-driven research require further validation and exploration viaempirical experiments, and may even entail a cyclical process where AI-generated hypotheses arerefined based on the outcomes of real-world experiments, which demands the assembly of a sizablecohort of experienced experimenters to carry out these investigations in accordance with establishedprotocols (McNutt, 2014). Unfortunately, the formation and sustenance of such a dedicated exper-imental cadre are fraught with considerable financial demands, and the collaborative engagementbetween people oriented towards AI methodologies and those grounded in experimental sciences isfrequently encumbered by the communication gaps between distinct intellectual paradigms (Baker,2016; Freedman et al., 2015; Munaf et al., 2017; Baker, 2021; Shi et al., 2023a).",
  "Syntax": "Structured protocolNL-based protocol ExecutionSemantics Completed protocolLinked protocol add_constraint add_constraint splitslotbranch_numcontainer checkcheckheatslotcontainertemperatureheaterdurationstirring wait coolslottemperature add_constraint add_constraint addslot1slot2volumecontainer (.); (.); ( = , = , = ); , = .,.; (() () ) ( = , = , = , = , = , = ); (); ( = , = ); (.); (.); ( = , = , = , = ); flask1 volflask2 vol mixture flask1flask2 T1T2flask1 temperature flask2 temperatureT1T2 mixture1mixture2flask1flask2 oil bathoil bath mixture1mixture2 flask3 volflask4 vol ice waterice watermixture1mixture2 flask3flask4 >=>= while==&&==",
  "True False": "[... E9 Split the mixture equally into 2 separate round-bottom flasks for the next steps9 9 Heat the first flask to 85C and maintain this temperature while stirring for 1 hour. Check the temperature every 10 minutes. Maintain the second flask at 75C9 69 Allow the mixture to cool to room temperature9 ;9 Add 20 mL of ice water into the flask. [...] 25C25C 25C25C ice waterice water oil bathoil bath oil bathoil bath : Illustration of the protocol translation problem. An NL-based protocol is translated to a struc-tured protocol, then to a completed protocol, and finally to a linked protocol that is ready for self-drivinglaboratories along with a corresponding PDG, after being processed through the syntax, semantics, and execu-tion levels. The three colors of arrows and text/ code highlights indicate the three translation steps respectively. To bridge the aforementioned gap, the paradigm of self-driving laboratories has garnered attention,which automates experimental protocols via robotic systems, potentially revolutionizing the way ex-periments are conducted (Bdard et al., 2018; Steiner et al., 2019; Mehr et al., 2020; Rohrbach et al.,2022; Burger et al., 2020; Szymanski et al., 2023). Despite the promising outlook, designing suchlabs relies largely on the translation of protocols, primarily designed for human experimenters, intomachine-readable instructions. This translation process necessitates extensive collaboration betweendomain experts, who possess the requisite scientific knowledge; and information technology special-ists, who encode this knowledge into software and hardware systems. The inherently labor-intensivenature of such translation significantly prolongs the development of self-driving laboratories. Theprimary challenges are rooted in the discrepancies across three critical aspects (see ): SyntaxHuman experimenters can effortlessly comprehend protocols articulated in Natural Lan-guage (NL), whereas automated systems frequently necessitate dedicated syntax parsers to con-vert these protocols into a sequence of actionable steps. Consider the protocol: Split the mixtureequally into 2 separate 50 mL round-bottom flasks for the next steps. This example highlights themeticulous control over experimental procedures, explicitly directing the split of the mixture intoprecisely measured volumes a crucial factor for achieving uniform outcomes in subsequent reac-tions. It is imperative at this level to uphold a structured representation of the mapping of operationconditions and the control flows of operations. SemanticsHuman experimenters can infer implicit knowledge and context relying on the flexibil-ity and adaptability of human understanding. In contrast, machine instructions necessitate a level ofprecision and rigidity that human communication does not inherently require. For instance, considerthe protocol: Stir the mixture at room temperature for 5 minutes. While a human expert mightinherently understand that room temperature denotes a temperature range of 20-25 C drawingon their prior knowledge, an automation system necessitates explicit information regarding suchimplicit details, which therefore need to be completed before execution. ExecutionHuman experimenters can simulate possible intermediate states and outcomes by con-sidering the cumulative effects of a sequence of actions. For instance, given the two instructionsadjacently: Add 35 mL water to the flask and Add 25 mL water to the flask, an experimentercan deduce that the flasks minimal capacity comes over 60 mL to prevent errors. For an automatedsystem to perform a similar function, the actions need to be linked along their execution order. Great efforts have been made on such translation tasks, among which Chemputer is representa-tive (Mehr et al., 2020). This algorithm parses the NL-based protocol into XDL, a Domain-SpecificLanguage (DSL) specially designed to describe chemical synthesis reactions. The completeness and linkages are constructed with a set of manually-written constraints, with which the correctness ofprotocols can be further checked. This methodology has gained widespread acceptance in automatedchemical synthesis, as a testament to the intensive efforts by domain and IT experts in developingXDL and the corresponding constraints. However, the application of a similar framework in otherdomains of experimental sciences, such as Genetics, Medicine, Ecology, and Bioengineering, wouldnecessitate repeating these labor-intensive tasks on a case-by-case basis, thus underscoring the crit-ical need for a more generally applicable, human-free protocol translator. In this work, we propose a novel framework of human-free translator, designed to potentially facil-itate applications across diverse experimental science domains without requiring extensive manualintervention. This framework decomposes the translation challenge into three hierarchical stages:structured on the syntax level, completed on the semantics level, and linked on the execution level,mirroring the cognitive steps undertaken by human experts in similar translation tasks. In the pro-posed work, the DSL, its constraints, and linkages are generated automatically, based on protocolstailored for human experimenters, thereby eliminating the need for labor-intensive manual processes. Our contributions are threefold: (i) We conduct a systematic analysis of the existing discrepanciesin protocol translation between human experimenters and automated systems in self-driving labo-ratories. From this analysis, we derive design principles that emulate human cognitive processesinvolved in protocol translation (Sec. 2). (ii) We devise an autonomous protocol translator through atripartite framework that incrementally constructs PDGs, encapsulating the spatial-temporal dynam-ics of protocol execution across syntax, semantics, and execution levels (Sec. 3). (iii) Through bothquantitative and qualitative evaluations in various experimental science domains, we demonstratethat our translator, when integrated as an auxiliary module for Large Language Models (LLMs),approaches the efficacy of skilled human experimenters and substantially surpasses the performanceof purely LLMs-based alternatives in protocol translation tasks (Sec. 4).",
  "Protocol translation for self-driving laboratories": "In this section, we explore the translation of protocols for human experimenters to those suitablefor self-driving laboratories. We analyze the task requirements across syntax (Sec. 2.1), semantics(Sec. 2.2), and execution (Sec. 2.3) levels. We pinpoint challenges at each level for both humans andmachines, delving into systematic methods for addressing these issues. Leveraging expert insights,we delineate fundamental design principles for achieving effective protocol translation (Sec. 2.4).",
  "Syntax level": "Operation-condition mappingIn NL-based protocols, operations and their corresponding pa-rameters such as input reagents and conditions, are entangled with each other. For example, Dis-solve 10 g of sodium chloride in 100 mL of distilled water at 80C, the entanglements of actionsand conditions highlight the complexity machines face in parsing such protocols. Human experi-menters can recognize them without information loss thanks to the internalized language for parsingNL (Chomsky, 1956, 2007). In contrast, protocols for machines must be represented precisely, withproper extraction of keys and values, and matching between them with appropriate data structures. Operation control flowsIn NL-based protocols, both linear and non-linear control flows are im-plicitly embedded in the text. While linear control flows, i.e., workflows in sequential executionorder, can be straightforward, non-linear control flows such as iterative loops and parallel operationscan be hard to detect because the signal and the operational domain can be separated. Consider theprotocol: Repeat the titration until the endpoint is reached, then record the volume of titrant used.These steps embody a non-linear control flow, challenging machines to correctly interpret the iter-ative process involved. Even human experts have to read the protocols carefully to understand thelocal and global structures to match the signals with operational domains, let alone machines.",
  "Semantics level": "Latent semantics of known unknownsSome assigned values of parameters are regarded as com-mon sense knowledge of domain experts by default, thus the values are omitted for simplicity orreferred to via a proxy name following the domains conventions. For example, the protocol instruc-tion Dry the purified product at room temperature relies on the experimenters understanding Split the mixture equally into 2 separate flasks. Check the temperature every 10 minutes. Allow the mixture to cool to room temperature. Add 20 mL of ice water into the flask. split split 2flasks equallymixture add add 20mL flaskice water check 10mins everytemperature ... split slotbranch_numcontainer ( : , : , : ) /*equally split*/ reagentintresource split slotvolscontainer ( : , : (), : ) /*specified split*/ reagentarray intresource add slot1vol1slot2 ( : , : , : ,... ) /*external add*/ reagentintreagent add slot1slot2vol ( : , : , : ,... ) /*internal add*/ reagentreagentint",
  "Joint Optimization": "DSL program hypothesis spaceOperation dependence graph heataddcool mixture1mixture1mixture+... mixture1; mixture1; r T: 85Cqr container: flask1qr duration: 10min; precon: postcon: conditions: mixture1; mixture1; r T: >25Cqr container: flask1; precon: postcon: conditions: [ice water, mixture1]; mixture+; r T: <25Cqr container: flask1; precon: postcon: conditions: mixture | split mixture1 | split mixture1 | cool ice water | add Pushdown Automaton for reagent flowReagents lifecyclesReagent flow graph mixture; T: 85C; Vol: 20mL; component: mixture; T:25C; Vol: 20mL; component: mixture+; T: >0C, <25C; Vol: 40mL; component: water; T: 0C; Vol: 20mL; component: mixture 1 mixture 1 mixture+ ice water cooladd... add ice water cool add ... split heat/checkcooladd mixture+ ice water mixture1 mixture2 mixture Semantics level Execution level Completed protocol Linked protocol Syntax levelStructured protocol precon postcon conditions precon postcon conditions precon postcon conditions heatcool... component TVol component TVol20 mL component TVol?mL mixture 1 mixture+ T<85C T>25C ice water precon postcon conditions precon postcon conditions precon postcon conditions heataddcool... component TVol component TVol component TVol component TVol mixture 1 mixture 1 mixture+ T<25C T>0C ice water Protocol dependence graph at step tProtocol dependence graph at step t+1Spatial-temporal dynamics of execution Additional spatial constraint Additional temporal constraint mixture1.Vol(20mL) and ice_water.Vol(20mL) := add_constraint(add.conditions.container.Vol > 60mL) cool.T > 25C and add.T < 25C := add_constraint(add.conditions.pace < 1mL/min) 40 mL StaticDynamic StaticDynamic StaticDynamic Context-freeContext-aware Context-freeContext-aware Context-freeContext-aware add component TVol20 mL mixture 1 : The design principles and the resulting pipeline of our translator. (Syntax level) Operationdependence synthesis on the syntax level, through the joint optimization of DSL program syntax space andthe parsing tree of the NL-based protocols. This process is static and context-free. (Semantics level) Reagentflow analysis on the semantics level, through an automaton scheme maintaining the lifecycles of reagents andintermediate products. This process is static and context-free. (Execution level) Spatial-temporal dynamicsanalysis on the execution level, through the partial execution trace model based on the spatial-temporal dualconstraint representation. This process is dynamic and context-aware.",
  "of what constitutes room temperature. However, machines substantially suffer from such latentsemantics, implying that every value of parameters should be made explicit": "Latent semantics of unknown unknownsSometimes, even required parameters for a specificoperation are omitted from the protocols either or not intentionally, causing unknown unknownsthat one may even be not aware of the absence of such information. For instance, the protocolinstruction Centrifuge the sample after adding the enzyme does not specify the key controllingparameter, speed or duration, for the centrifuge operation, before describing its specific value.Both human and machines require every parameter of operations to be grounded.",
  "Execution level": "Capacity of resourcesProtocols often omit explicit specifications of resource capacities, lead-ing to potential execution errors like exceeding a devices maximum capacity. This issue, inherentin the execution sequence, is undetectable by analyzing single operations alone. For example, theinstruction Transfer the mixture to a beaker requires choosing a beaker with adequate capac-ity, a decision based on the cumulative volume from previous steps. Humans intuitively managethis through a mental simulation of the experimental process (Gallese and Goldman, 1998). Ma-chines, therefore, need a pre-execution verification mechanism to ensure resource capacities are notexceeded, highlighting the need for an integrated understanding of the experimental sequence. Safety of operationsIn addition to managing resource capacities, another source of runtime errorsstems from operations that, while semantically valid, may lead to adverse or dangerous outcomesin certain execution contexts. Such scenarios necessitate a dual-constraint approach, where experi-menters are mindful not only of the actions required what I should do but also of potential misstepsto avoid what I must not do. For instance, the instruction Heat the reaction mixture to 70C canbe appropriate or hazardous, depending on the mixtures composition safe with a heat-stable cat-alyst, but risky with a heat-sensitive component due to potential decomposition. To navigate thesecomplexities, human experts effectively run mental simulations, conducting \"What if?\" queries andcounterfactual reasoning (Hoch, 1985) to anticipate the consequences of their actions. Similarly,machines need a system to draw upon domain-specific knowledge and historical context to assessthe safety of each operation, ensuring that all actions are contextually appropriate and safe.",
  "Design principles inspired by human experimenters": "Human experts cognitive capabilities on the translation of protocols serve two key roles: under-standing protocols for in-hand experiments and manually developing translators for self-drivinglaboratories. Inspired by these practices, we outlined design principles for our translator and as-sessed the strengths and weaknesses of current DSLs for NL-based protocols, such as XDL (Steineret al., 2019), ULSA (Wang et al., 2022), ORD (Kearnes et al., 2021), Biocoder (Ananthanarayananand Thies, 2010), Autoprotocol (Strateos, 2023), and the family of DSLs (hereinafter called ADSL)which are automatically designed by the AutoDSL tool driven by domain corpora (Shi et al., 2024a). Operation dependence synthesis for the syntax levelTo precisely comprehend the complicatedoperation-condition mappings and non-linear control flows, machines should equip with an exter-nalized language in parallel with humans internalized language (Chomsky, 2007). A machine-recognizable language commonly possesses a Context-Free Grammar (CFG) which externally de-fines the key-value structures on different hierarchies: (i) operation as key, reagents and conditionsas values; (ii) condition as key, the corresponding parameters as values; and (iii) signal of controlflow as key, the corresponding operational domains as values. If a protocol can be parsed into anAbstract Syntax Tree (AST) with the CFG, it is verified on the syntax level (Hopcroft et al., 1996),resulting in the dependency structures of the operation flow (see Top). All DSLs mentionedbefore are context-free languages with CFGs (Fowler, 2010), echoing this design principle. Reagent flow analysis for the semantics levelDespite the merits of DSLs based on CFGs, thecontext-free nature hinders verification on the semantics level, which is pivotal in protocols es-sentially describing procedures, where the preconditions and postconditions between temporallyadjacent operations can be end-to-end connected. To be specific, although a CFG defines a struc-tural space with hierarchies of operations, conditions, parameters, and control flows, i.e., Theremust be several parameters corresponding to a condition, it does not constrain the mappings underthe context of domain-specific knowledge, i.e., There are parameters controlling the Temperature,Duration, and Acidity of the condition. If the exact mapping between keys and values cannot bespecified, the self-driving laboratories can hardly be aware of the loss of completeness, i.e., beingaware of the omitted conditions given an operation or the missing value given a parameter, due tothe extremely large search space over all symbols given by the corresponding DSLs (Gulwani et al.,2017). The design choices of DSLs diverge on this level, where Autoprotocol only supports ver-ification on the syntax level and does not possess any domain knowledge, ORD and ULSA offerthe relations between operations and conditions without more fine-grained parameters, while XDL,Biocoder, and ADSL offer the find-grained key-value relation below the hierarchy of operationswithout more constraints about the values, e.g., suggested values of specific parameters. Hence, werequire a mechanism for completing the structures of reagent flow (see Middle), while thecompleteness of the fine-grained parameters is guaranteed by the DSLs. Spatial-temporal dynamics analysis for the execution levelCompletion on the semantics levelis conducted statically because the semantics of operations are viewed individually rather than con-textualized in the execution sequence. Regrettably, such effort cannot guarantee that the protocolscan be executed successfully without any errors in the run time, which is unacceptable by self-driving laboratories (Christensen et al., 2021; Seifrid et al., 2022). One way is to have domainexperts write down all of the potential bad cases as constraints and use them for verification. How-ever, run-time errors raised in the dynamic context of operations are heavily long-tail distributed.This makes it extremely hard to predict such errors from statistical hindsight (Pearl, 2019), i.e., theset of collected post-hoc bad cases. Thus, we leverage the powerful foresight based on simulation,which spans the full probabilistic worlds of each operation by its semantic constraints, both on thespatial dimension, e.g., capacity of resources captured by the reagent dependency, and the tempo-ral dimension, e.g., safety of operations captured by the operation dependency. The simulation isconducted along the topological order of the corresponding execution flow graph. At each opera-tion unit, both historical operations in the same protocols and similar operations in other protocolsare recalled dynamically, checking and refining the dual-constraint spaces accordingly (see Bottom). Interestingly, none of the DSLs in our discussion take this feature as part of language de-sign and only XDL employs an external compiler with hand-crafted rules for error detection. Suchconsideration is reasonable because in mainstream DSL design, verification on the execution levelis not guaranteed by the DSLs themselves for design simplicity and user convenience (Mernik et al.,2005). Consequently, we require an environment to dynamically check the correctness of executionboth spatially and temporally, through synthesizing operation and reagent dependencies.",
  "The framework of protocol translation": "In this section, we introduce the three-stage framework for human-free protocol translation, whichgradually constructs a structural representation of protocols, called the Protocol Dependence Graph(PDG). The PDG makes explicit both the operation and reagent dependencies for a protocol. Opera-tion dependence echoes the concept of program control flow, which derives the condition of sequen-tial, branch, or loop execution of protocol operations (Sec. 3.1). Reagent flow provides an explicitrepresentation of the reagent instantiate-exploit relationships implicitly in the protocol (Sec. 3.2).Additionally, we simulate the protocol execution process using the PDG, checking and refining op-eration sequences under the spatial and temporal dynamics of execution (Sec. 3.3).",
  "Operation dependence synthesis for the syntax level": "The operation dependence models the topological order for executing operations in a protocol. Theprocedure is executed sequentially from the first operation in the protocol to the last, unless theexperimenter encounters structures that change the execution flow, such as branches and loops. Inpractice, we extract the operation dependence by compiling the protocol to DSL programs. InputThe compilation process is conducted based on the corresponding DSL L tS, u.The CFG-based syntax S pS, V, , Rq includes (i) the start symbol S; (ii) the variable setV tVctrl, Vop, Vcond, Vparu with placeholders for control flow signals Vctrl, operations Vop,conditions Vcond, and parameters Vpar; (iii) the set of terminals , which are the grounded valuesof parameters; (iv) the set of production rules R defining the structural space between the four vari-able sets. The semantics pTctrl, Top, Tcond, Tpar, TRq constrains the variables and productionrules, assigning the placeholders with substantial meanings. To note, according to the design choicediscussed in Sec. 2.4, the DSL used here should be one of XDL, Biocoder, and ADSL, i.e. the DSLswith the most fine-grained structural representation compared with their counterparts. Pre-processingGiven an input protocol c for translation, we first parse the NL sentences by anoff-the-shelf tool and extract the actions accordingly. Then, the extracted actions are matched withthe operations o P Top of the DSL, according to both exact match score and semantic similarity.Afterwards, we extract the arrays of entities related to the extracted action et P E by an off-the-shelftool, where we regard the output labels to the entities and relations as pseudo-labels because theycan possibly be noisy. Please refer to Appx. C.1 for implementation details. DSL program synthesisSynthesizing structural representation given unstructured signal is chal-lenging (Billard, 2000, 2006). Specifically, the one-to-many mappings of many DSL operationsbring uncertainty into the matching. For example, the operation add possesses distinct patterns:two or three input slots. This further distorts the matching of reagents, conditions, and parametersbecause off-the-shelf tools can hardly detect the exact categories of these entities deeply rooted indomain-specific knowledge. Since the observation and hypothesis spaces are both noisy, we proposeto jointly optimize the patterns of operations and the pseudo-labels. We denote the set of all possibleprogram patterns generated by operation o as o tp|o p, TR p, p P T ctrl Y T op YT cond Y T paru. A synthesized DSL program is defined as ppcq xppo1q, ppo2q, . . . , ppo|ppcq|qy,where ppotq is the program of an operation assembled with its corresponding conditions and param-eters under the selected pattern in o. Let spcq xe1, e2, . . . , e|spcq|y represent the sequence ofoperation-related entities, the objective of optimization can be",
  "D`ppcqspcq,(1)": "where Dp}q is a divergence function with three indicators: (i) the selected pattern examples shouldbe as close as possible to the text span; (ii) the selected pattern should be as similar as possible withthe extracted subject-verb-object structure; and (iii) as many labeled entities as possible should bemapped to the parameter space (see B). Though |o| is not a large value, the whole sequenceof operations can yield an exponential complexity. Hence, to make the joint optimization tractable,we separate the search of solution into two steps in the spirit of Expectation Maximization (EM):(i) Expectation: sampling programs from the legal space defined by the corresponding DSL, with aprogram-size-sensitive prior |ppotq|1; (ii) Maximization: randomly alternating symbols in spcq bymatching them with those in ppcq and greedily select the edits that decrease the objective function.",
  "TRANSITION(M, Mpqq)": "The DSL programs are further contextualizedby associating operations with reagent flow.Reagent flow indicates the transfer of reagentsamong operations, reflecting how one opera-tion impacts the subsequent ones. We definethe reagent flow following the reaching defi-nitions schema (Alfred et al., 2007), which iscommonly used to capture the life cycle of avariable in compiler design. This schema de-termines a set of reagents reachable at eachpoint in a protocol, and subsequently tracksthe kills and defines of an operation, i.e.,whether a reachable reagent is consumed, ora new reagent is yielded, in an operation. InputWe denote the reagents consumed and the intermediate products yielded by each op-eration o as INpoq and OUTpoq respectively.The objective is to find a set of operation pairst xoi, ojy | OUTpoiq X INpojq u such that OUTpoiq is required as input by INpoiq. The reaching definitions schemaWe determine the availability of a reagent at each step by locat-ing where it is defined in a protocol when execution reaches each operation. A reagent r reaches anoperation o, if there is a path from the point following r to o, such that r is not killed, i.e., consumed,along that path. Any reagent r that reaches an operation o might be killed at that point, and o mayyield new intermediate products r1 that reach future operations. Notably, according to statistics oncorpora of protocols (Vaucher et al., 2020), for about 90% operations of a target DSL, if oi oj aretwo adjacent operations, OUTpoiq X INpojq holds. This implies that the reagent generated bypreceding operation is likely to be used and then be killed instantly by the following operation. Reagent flow analysis via operation flow traversalWe traverse the DSL program in executionorder to leverage the reagent locality revealed from statistical results, determining the reachabilityand life cycle of reagents. A Pushdown Automaton (PDA) with a random access memory is adoptedto record reachable reagents as operation context, defining and killing reagents at each operationpoint along the computation1. A PDA is formally defined as a 7-tuple M pQ, , , , q0, Z, Fq,where Q Top indicates the set of states, Top represents the domain of inputs, Tpar de-notes possible memory elements, Q Q is the transition procedure (TRANSITIONin Alg. 1), q0 o1 defines the initial state, Z is the initial memory element, and F denotes theset of accepting states. The reagent dependence construction process (FLOW in Alg. 1) traverses theDSL program in execution order by leveraging the NEXTOPS utility, which evaluates to subsequentoperations. In every transition step with input, the killed reagents are removed from the memory,and the defined reagents are added to the memory. After a reagent is killed, the pair of the operationsthat defined it and killed it will be added to the set of reagent flow constraints. The accepting stateis reached if the memory is empty at the end of execution, i.e., all reagents defined in operations arekilled by other operations. We employ state-of-the-art LLMs to extract reagent entities from NL-based protocol descriptions for the two utilities KILLS and DEFINES through instruction-followingin-context learning (Wei et al., 2021; Brown et al., 2020) (refer to Appx. C.2 for details).",
  "Spatial-temporal dynamics for the execution level": "While the pre-specified PDG analysis indicates the things should be done to follow operation andreagent flow, we still need to care about the things must not be done by describing the activitiesthat may be performed and the constraints prohibiting undesired execution behavior. Therefore,we introduce a constrained-based execution model to support dynamic protocol simulation, gettinggrounded in the theories of process modeling and execution (Dourish et al., 1996; Pesic et al., 2007). A constraint-based protocol execution modelWe extend the DSL program ppcq by a constraintset C Cop Y Creg Y Cs Y Ct to construct a constraint-based execution model S pppcq, Cq.The execution of a program is represented by a trace xpo1, c1q, po2, c2q, . . . , po|ppcq|, c|ppcq|qy, 1It is worth noting that this extended PDA with random access can be shown to be in the same computationclass as Turing machines (Aho and Ullman, 1972), and we employ this extended PDA due to its simplicity. where the order of oi reflects the temporal sequence. The execution context ci defines the spatialenvironment in which each operation is performed. Each constraint c P SpCq is a predicate thatmaps the execution trace to a binary condition denoting satisfy or not. An execution trace is saidto satisfy the program constraint if and only if || |ppcq| and cpq holds for all c P C. Leveraging partial execution trace for spatial and temporal constraintsExplicit constraints,namely operation and reagent flow, are easy to satisfy. Unfortunately, deriving implicit constraints,e.g., the capacity of resources and safety of operations, is case-by-case for each protocol, requiringexpert efforts. We propose profiling the context through execution to derive implicit spatial and tem-poral constraints that meet domain-specific requirements. An execution trace is defined as partiallysatisfying the constraints C if it follows the operation and reagent flow; that is, for any xoi, ojiy intrace , there exists at least a pair of valid operation flow path and reagent flow path from oi to oj.",
  "Experimental setting": "MaterialsWe select 75 complicated experiments with 1,166 steps in total as the testing set, fromthe domains of Chemical Synthesis (235 steps in 10 experiments; 235 in 10 for simplicity; Synthe-sis for abbreviation), Genetics (396 in 34), Medical and Clinical Research (307 in 23, Medical),Bioengineering (218 in 17), and Ecology (10 in 1). Please refer to Appx. D for details. Expert-created protocol translationWe recruited five groups of experienced experimenters,each specializing in a different domain, with seven participants in each group. Every participat-ing experimenter holds at least a Masters degree related to the corresponding domain, has obtainedat least six years experience in manually conducting pre-designed experiments of the domain, hasacquired elementary programming skills, and has at least heard of self-driving laboratories. Thesehuman experts are asked to translate the original NL-based protocols for their domains into thosesuitable for self-driving laboratories. Their outputs are subjected to DSL-based representations andcomplete PDGs to evaluate machines behaviors, which are clearly demonstrated by a running exam-ple and the examples in the DSL documentation. Outputs from experts are carefully cross-validatedand the individual divergence between them is minimized through an expert-panel-driven workshopdiscussion following the established workflow (Reilly et al., 2023). Translation results of humanexperts and machines are serialized and are compared through ROUGE and BLEU metrics (Lin,2004; Papineni et al., 2002). Please refer to Appx. B for ethics considerations. Alternative methodsWe compare our translator with alternative methods on the first two levels,to investigate the effects of early stages on the overall translation result. On the syntax level, wecompare the syntactic synthesis method (referred to as Ours-SY) with ConDec-SY (Wang et al.,2023a), which synthesizes DSL programs by LLMs with external DSL grammars as constraint,and a baseline DSL-LLM-SY leveraging the minimal realization used in Shi et al. (2024a). Onthe semantics level, we compare the deductive verification method (referred to as Ours-SE) withNL-RAG-LLM-SE, which retrieves on the embedded vector database of original NL-based proto-cols, and a baseline NL-LLM-SE implemented by pure prompt-engineering on LLMs. Since theI/Oes of all stages are unified in the pipeline, we implement an overall baseline Best-Baselinethat combines the strongest alternative methods within the evaluation of the first two stages.",
  "Overall assessment on expert-created protocol translation": "ResultComparing the overall output of our translator and ideal human experimenters, we find thatour translator approaches the level of experts with average performance higher than 85% across allindicators. Our translator significantly outperforms the alternative pipeline Best-Baseline onthe (tp148q 17.71, d 0, p .0005; see C). DiscussionWe find that our translator demonstrates similar performance to human experts intranslating protocols with complete parameters and clear descriptions (see A). However, incases where the linear description of the experimental protocol is lacking, our translator and human CorporaDSL BioEngEcologyGeneticsMedicalSynthesis BioEngEcologyGeneticsMedicalSynthesis BioEng",
  "Expert": ": Results of experiment. (A) Distinctions between various domains regarding domain-specific cor-pora and the corresponding DSLs. (B) Convergence of the three indicators in the objective function for programsynthesis. (C) Our translator significantly outperforms the best baseline and approaches human-level perfor-mance. (D) Our translator significantly outperforms alternative methods on the syntax level. (E) Our translatorsignificantly outperforms alternative methods on the semantics level. experts diverge. Specifically, our translator tends to translate based on the information within thesentence or between adjacent sentences, while human experts tend to consider the overall experi-mental process comprehensively. Though there are minor gaps, these observations suggest that ourtranslator is approaching the level of performance of experienced human experimenters. Please referto Appx. E.3 for case studies on the distinctions between the behaviors of experts and machines.",
  "Comparison between alternative models": "ResultOn the syntax level, our Ours-SY significantly outperforms alternative approaches(tp148q 17.07, d 0, p .0005 for ConDec-SY; tp148q 15.47, d 0, p .0005for DSL-LLM-SY; see D). On the semantics level, our Ours-SE significantly outperformsalternative approaches (tp148q 2.52, d 0, p .05 for NL-RAG-LLM-SE; tp148q 3.07, d 0, p .005 for NL-LLM-SE; see E). DiscussionCompared with alternative methods on the syntax level, our translator excels in en-suring the accuracy of translations across different protocols thanks to the PDG representation, asshown in B. On the semantics level, our translator performs better in translating incompleteprotocols with missing information than other baselines, as shown in C. We explain thesemerits with the properties of structural representation, which defines a representation space with",
  "Ours": "Best-Baseline incubatecoolincubatewashwash EDTA 50 min, 95 C HO3% HO 5 min, Room Temperature TBS Repeat=2 20min, Room Temperature slidesslidesslidesslidesslides incubatecoolincubatewashwash 50 min, 95 CHO3% HOTBS20min, Room Temperature slidesslidesslidesslidesslides EDTAcomponent: EDTAcomponent: EDTA/watercomponent: EDTAcomponent: EDTA/3% HOcomponent: incubatecoolincubatewashwash slidesslidesslidesslides slides; slides; T: 95 C container: heating bath duration: 50 min; precon: conditions: postcon: slides; slides; T: 25 C container: staining dish duration: 20 min; precon: conditions: postcon: slides; slides; T: 25 C container: staining dish; precon: conditions: postcon: slides; slides; T: 25 C container: staining dish duration: 5 min; precon: conditions: postcon: slides; slides; T: 25 C container: staining dish repeat: 2 times; precon: conditions: postcon: slides : Showcases of the results. (A) Examples of the final PDGs generated by our translator, the alternativemethod, and human experts. (B) Examples of structured protocols output by our translator and alternativemethods. (C) Examples of completed protocols output by our translator and alternative methods. high expressive power (Felleisen, 1991; Lloyd, 2012), capturing information along the spectrum ofgranularity, from local details like fine-grained parameter-value relations to global-structure of con-trol flows. By contrast, the original NL representation and its embedding space may not possesssuch extent of expressive power (Zhang et al., 2021). Consequently, mapping the protocols into astructural latent space for query or retrieval should be more suitable than directly operating on theoriginal space. Please refer to Appxs. E.1 and E.2 for details on the utilities of different approaches.",
  "General discussions": "In this work, we study the problem of translating protocols for human experimenters into thoseproper for self-driving laboratories. We design a human-free protocol translator under the inspirationof human experts cognitive processes in protocol translation. Results suggest that our translatoris comparable with experienced human experimenters in protocol translation, further implying itspotential to serve as a plug-and-play module for fully automated scientific discovery. Closing the loop of automatic scientific discoveryThe realization of automatic protocol trans-lation closes the last-mile of closed-loop scientific discovery. Integrating the translator with othercutting-edge techniques, we can expect such a pipeline in the future: after AI models for scien-tific discovery have output insights from initial observations, there is a self-driving laboratory readyfor producing and testing the designs. The creation of this laboratory is also automatic (Shi et al.,2024c). In the conventional creation process, we must employ a cohort of experienced domainexperts to hand-craft a DSL tailored for representing protocols of the target domain, and then hand-craft a translator with pre-defined production rules and constraints to translate the protocols intomachine executables. Hence, the status quo has been changed: we can exploit the AutoDSL toolto obtain the DSL based on a corpus of the target domain (Shi et al., 2024a), and then set up ourautomatic translator for final execution; we can also integrate the DSLs and our translator into LLM-based scientist agents for a more reliable and flexible domain specification (Boiko et al., 2023;Bran et al., 2023). The integration of these approaches facilitates the grounding of AI for scientificdiscovery, which helps AI researchers test, produce and deploy their discoveries more seamlessly. Valuing domain expertsOne might worry that the full realization of closed-loop scientific dis-covery would pose a severe impact on conventional experimental scientists. Indeed, AI for scientificdiscovery and self-driving laboratories do not compete with conventional scientific discovery. Asinterdisciplinary methodologies, they still demand the supervision of scientists for tacit knowledge,creativity, and integrity (Shi et al., 2024b). Also, such techniques free domain experts from thosetime-consuming and labor-intensive low-level workloads and focus them on high-level thinking.",
  "Acknowledgements": "This work was partially supported by the National Natural Science Foundation of China underGrants 91948302 and 52475001. Part of the authors are visiting students at Peking University duringthis work. In particular, Z. Bi is visiting from Huazhong University of Science and Technology andQ. Xu is visiting from University of Science and Technology of China. The authors would also liketo thank Jiawen Liu for her assistance in figure drawings. Abramson, J., Adler, J., Dunger, J., Evans, R., Green, T., Pritzel, A., Ronneberger, O., Willmore,L., Ballard, A. J., Bambrick, J., et al. (2024). Accurate structure prediction of biomolecularinteractions with alphafold 3. Nature, pages 13.",
  "Jablonka, K. M., Patiny, L., and Smit, B. (2022). Making the collective knowledge of chemistryopen and machine actionable. Nature Chemistry, 14(4):365376": "Jumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., Tunyasuvunakool, K.,Bates, R., dek, A., Potapenko, A., et al. (2021). Highly accurate protein structure predictionwith alphafold. Nature, 596(7873):583589. Kearnes, S. M., Maser, M. R., Wleklinski, M., Kast, A., Doyle, A. G., Dreher, S. D., Hawkins, J. M.,Jensen, K. F., and Coley, C. W. (2021). The open reaction database. Journal of the AmericanChemical Society, 143(45):1882018826. Kim, C., Gadgil, S. U., DeGrave, A. J., Omiye, J. A., Cai, Z. R., Daneshjou, R., and Lee, S.-I.(2024). Transparent medical image ai via an imagetext foundation model grounded in medicalliterature. Nature Medicine, pages 112.",
  "Mernik, M., Heering, J., and Sloane, A. M. (2005). When and how to develop domain-specificlanguages. ACM Computing Surveys (CSUR), 37(4):316344": "Munaf, M. R., Nosek, B. A., Bishop, D. V., Button, K. S., Chambers, C. D., Percie du Sert,N., Simonsohn, U., Wagenmakers, E.-J., Ware, J. J., and Ioannidis, J. (2017). A manifesto forreproducible science. Nature Human Behaviour, 1(1):19. Papineni, K., Roukos, S., Ward, T., and Zhu, W.-J. (2002). Bleu: a method for automatic evalu-ation of machine translation. In Proceedings of the 40th annual meeting of the Association forComputational Linguistics. Park, N. H., Manica, M., Born, J., Hedrick, J. L., Erdmann, T., Zubarev, D. Y., Adell-Mill, N., andArrechea, P. L. (2023). Artificial intelligence driven design of catalysts and materials for ringopening polymerization using a domain-specific language. Nature Communications, 14(1):3686.",
  "Pearl, J. (2019). The seven tools of causal inference, with reflections on machine learning. Commu-nications of the ACM, 62(3):5460": "Pesic, M., Schonenberg, M., Sidorova, N., and van der Aalst, W. M. (2007). Constraint-basedworkflow models: Change made easy. In OTM Confederated International Conferences\" On theMove to Meaningful Internet Systems\". Reilly, J., Shain, C., Borghesani, V., Kuhnke, P., Vigliocco, G., Peelle, J., Mahon, B., Buxbaum,L., Majid, A., Brysbaert, M., et al. (2023). What we mean when we say semantic: A consensusstatement on the nomenclature of semantic memory. OSF preprint. Rohrbach, S., iauciulis, M., Chisholm, G., Pirvan, P.-A., Saleeb, M., Mehr, S. H. M., Trushina,E., Leonov, A. I., Keenan, G., Khan, A., et al. (2022). Digitization and validation of a chemicalsynthesis literature database in the chempu. Science, 377(6602):172180. Seifrid, M., Pollice, R., Aguilar-Granda, A., Morgan Chan, Z., Hotta, K., Ser, C. T., Vestfrid, J.,Wu, T. C., and Aspuru-Guzik, A. (2022). Autonomous chemical experiments: Challenges andperspectives on establishing a self-driving lab. Accounts of Chemical Research, 55(17):24542466. Shi, Y.-Z., Hou, H., Bi, Z., Meng, F., Wei, X., Ruan, L., and Wang, Q. (2024a). AutoDSL: Au-tomated domain-specific language design for structural representation of procedures with con-straints. In Annual Meeting of the Association for Computational Linguistics.",
  "Shi, Y.-Z., Li, H., Ruan, L., and Qu, H. (2024b). Constraint representation towards precise data-driven storytelling. In IEEE Visualization and Visual Analytics Gen4DS": "Shi, Y.-Z., Li, S., Niu, X., Xu, Q., Liu, J., Xu, Y., Gu, S., He, B., Li, X., Zhao, X., et al. (2023a).PersLEARN: Research training through the lens of perspective cultivation. In Annual Meeting ofthe Association for Computational Linguistics. Shi, Y.-Z., Xu, M., Hopcroft, J. E., He, K., Tenenbaum, J. B., Zhu, S.-C., Wu, Y. N., Han, W., andZhu, Y. (2023b). On the complexity of Bayesian generalization. In International Conference onMachine Learning. Shi, Y.-Z., Xu, Q., Meng, F., Ruan, L., and Wang, Q. (2024c).Abstract Hardware Groundingtowards the Automated Design of Automation Systems. In International Conference on IntelligentRobotics and Applications.",
  "Strateos (2023). Autoprotocol specification": "Szymanski, N. J., Rendy, B., Fei, Y., Kumar, R. E., He, T., Milsted, D., McDermott, M. J., Gallant,M., Cubuk, E. D., Merchant, A., et al. (2023). An autonomous laboratory for the acceleratedsynthesis of novel materials. Nature, 624(7990):8691. Vaucher, A. C., Zipoli, F., Geluykens, J., Nair, V. H., Schwaller, P., and Laino, T. (2020). Automatedextraction of chemical synthesis actions from experimental procedures. Nature Communications,11(1):3601. Wang, B., Wang, Z., Wang, X., Cao, Y., A Saurous, R., and Kim, Y. (2023a). Grammar promptingfor domain-specific language generation with large language models. In Advances in NeuralInformation Processing Systems. Wang, H., Fu, T., Du, Y., Gao, W., Huang, K., Liu, Z., Chandak, P., Liu, S., Van Katwyk, P., Deac,A., et al. (2023b). Scientific discovery in the age of artificial intelligence. Nature, 620(7972):4760. Wang, Z., Cruse, K., Fei, Y., Chia, A., Zeng, Y., Huo, H., He, T., Deng, B., Kononova, O., andCeder, G. (2022). ULSA: Unified language of synthesis actions for the representation of inorganicsynthesis protocols. Digital Discovery, 1(3):313324.",
  "A.1Rationale for the evaluation metrics": "Direct comparisons across entire sentences under BLEU and ROUGE scores would indeed pose aproblem it may be problematic considering instructions that look similar could have very differentsemantics. Therefore, to circumvent this issue, we convert all results into a standardized JSON-styleformat for data representation, and comparisons are made between key-value pairs rather than entiresentences, effectively resolving the metric concern.",
  "}": "The comparison between the two sentences is then transformed into a comparison between twoJSON code blocks. We calculate the similarity score cumulatively based on the similarity betweenthe values of matched pairs of keys. For instance, for the key temperature, the values hot andcold yield a low similarity score under the ROUGE, BLEU, and even the Exact Match metrics.As temperature is one of the major keys within configuration parameters, a high penalty in thisdimension significantly affects the cumulative similarity score. With this fine-grained comparisonmetric, we can comprehensively track the distinctions and commonalities between results withoutlosing expressivity regarding the quantities. We also acknowledge that there are advanced evaluation metrics, especially in the recent workswhere LLMs are leveraged as external judges and achieve considerable performance in generaltesting cases. Our choice of less advanced metrics is driven by the intention to focus specifically ondomain-specific knowledge, which constitutes the primary scope of this paper and may be relativelysparse in general LLMs. Nonetheless, the exploration of more sophisticated evaluation metricsrepresents a promising avenue for future research.",
  "A.2Insight behind the design of PDG": "We have constructed the operation dependence graph on the syntax level and the reagent flow graphon the semantics level. Indeed, the two analytical results come with a duality. In the operationdependence graph, vertices represent operations and edges represent reagents passed between them.In contrast, the reagent flow graph uses vertices for reagent states and edges for operations causingstate transitions. Interestingly, the vertices of one of the two graphs can be one-to-one mapped tothe edges of another, echoing the duality. On a higher level, we say that the former provides anexperimenter-centered view while the latter offers a reagent-centered view. These two perspectivesare complementary on encoding both the information of the interventions to the environment andthe status of the environment itself. Consequently, by leveraging such duality, we are able to trackspatial dynamics, e.g., the variance of required resources, and temporal dynamics, e.g., the contextof sequential operations, simultaneously on the PDG.",
  "A.3Computational complexity of the framework": "Let us consider a new coming protocol with k steps, with each step configured by a constant numberof parameters, denoted as c. On the syntax level, the primary computation bottleneck arises duringDSL program synthesis, where the EM Algorithm exhibits a worst-case complexity of Opckq. Thisis a highly conservative estimate, as mainstream optimization approaches can solve the EM muchmore efficiently. On the semantics level, the bottleneck occurs during reagent flow analysis, whichconsumes Opk2q complexity. Notably, only approximately 10% of the steps are included in thenested loop for reagent flow construction, as about 90% of the steps are linearly connected. On theexecution level, the protocol execution model also exhibits Opk2q complexity, encompassing bothforward and backward tracing. This can be optimized by replacing the full tracing strategy with asliding window built upon the topological dependencies between steps. Although the complexitiesof the algorithms at these three levels are tractable, there is substantial room for improving theefficiency of the framework. Investigating methods to speed up the translation process for protocolswith extremely high complexity would be a valuable area of research.",
  "A.4Generality of the framework": "The general applicability of our proposed framework beyond experimental sciences can indeed bea common concern. The core value of translating NL-based protocols into formats suitable for ma-chine execution substantially lies in facilitating experiments in self-driving laboratories, thereby ac-celerating scientific discovery. Experimental protocols come with unique properties and challenges,such as the fine-grained incorporation of domain-specific knowledge, the non-trivial dependencytopologies between operations, the long-horizon lifecycles of intermediate productions, and the ne-cessity for precise execution without run-time errors. These factors shape the scope of our researchproblem, emphasizing the need to handle protocols with stringent terminology and formatting. Despite the specific scope of this paper, we are open to exploring the potential for generalizingour framework to other domains with similar properties and challenges as those found in scientificexperiments such as cooking. Imagine a self-driving kitchen that automatically prepares allingredients and executes all procedures for cooking a meal according to NL-based recipes. Suchself-driving kitchens would also benefit significantly from translating human-oriented recipes intoformats suitable for machine execution. In the following, we present a running example of such atranslation, adapted from a use case of the Corel1 DSL.",
  "simmer(target = mixture_4, temperature = 211F, duration = 7.5mins);": "In this example, we observe that the NL-based recipe possesses ambiguities and omissions. Ourtranslation framework addresses these challenges by structuring the recipe on the syntax level, com-pleting the latent information on the semantics level, and linking the programs with necessary re-sources, such as the usage of plates, on the execution level. Due to the modularity of DSLs, althoughCorels distribution of syntactic and semantic features differs significantly from those of DSLs usedfor representing experimental protocols, our translator can generalize to this new target domainthrough the structure of rules, namely rule-based generalization (Shi et al., 2023b).",
  "A.5The motivations behind this work": "In this work, we study the problem of translating experimental protocols designed for human ex-perimenters into formats suitable for machine execution. Our primary motivation is to bridge theexisting gap between machine learning algorithms in the field of AI for science, such as moleculardesign, and the grounded experimental verification facilitated by self-driving laboratories. Con-ventional workflows for setting up self-driving laboratories and conducting physical experimentsnecessitate deep integration with domain experts, significantly impeding the progress of machinelearning researchers in verifying and iterating their findings. Consequently, our framework aims toprovide an infrastructure that enables these researchers to advance their machine learning algorithmsand seamlessly validate their findings, thereby closing the loop of automatic scientific discovery. To meet the requirements of such infrastructure, we conduct a systematic study to identify existinggaps in protocol translation between human experimenters and automatic translators in self-drivinglaboratories. From the study, we derive design principles that emulate human cognitive processesinvolved in protocol translation. Under the guidance of these design principles, we develop thethree-stage framework that integrates cognitive insights from human experts with approaches fromprogram synthesis, automaton construction, and counterfactual analysis. On the syntax level, wesynthesize the operation dependence graph to transform NL-based protocols into structured repre-sentations, thereby making explicit the operation-condition mappings and the control flows. Onthe semantics level, we analyze the reagent flow graph to reconstruct the complete lifecycles ofintermediate products, addressing the latent, missing, or omitted properties and values. On the ex-ecution level, we contextualize both the operation dependence graph and the reagent flow graphwithin spatial and temporal dynamics, resulting in the protocol dependence graph. This graph con-ducts counterfactual reasoning to detect potential conflicts or shortages of execution resources andto identify inappropriate combinations of operations in execution sequences.",
  "conducting this study and ensuring the protection of the rights and welfare of all participants. Wepaid the domain experts a wage of $22.5/h, which is significantly higher than the standard wage": "We have obtained informed consent from all participants, including clear and comprehensive infor-mation about the purpose of the study, the procedures involved, the risks and benefits, and the rightto withdraw at any time without penalty. Participants were also assured of the confidentiality oftheir information. Any personal data collected (including name, age, and gender) was handled inaccordance with applicable laws and regulations.",
  "B.2Corpora collection": "We carefully ensure that all experimental protocols incorporated into our corpora strictly adhere toopen access policies, governed by the Creative Commons license. This approach guarantees fullcompliance with copyright and intellectual property laws, eliminating any potential infringement orunauthorized use of protected materials. By exclusively utilizing resources that are freely availableand legally distributable, we uphold the highest standards of ethical conduct in research, fosteringan environment of transparency and respect for the intellectual property rights of others. This com-mitment ensures that our work not only advances the frontiers of knowledge but does so in a mannerthat is both legally sound and ethically responsible.",
  "C.1Details of pre-processing": "We employ the SpaCy Dependency Parser to analyze the syntactic structure of protocol c, whichallows for the extraction of verbs and the identification of associated objects and modifiers (Honnibaland Johnson, 2015). After parsing, these verbs are aligned with corresponding operational actionso P Top in the DSLs by maximizing the cosine similarity between their word2vec representationsand those of the DSL operations. Furthermore, we utilize an advanced few-shot Named EntityRecognition (NER) algorithm, based on large language models, to accurately identify and classifyentities et P E within the text (Xie et al., 2024). The rationale of integrating LLMs with classicalparsing techniques lies in leveraging the advanced natural language processing capabilities of LLMswhile mitigating their inherent uncertainties.",
  "C.2Details of reagent flow analysis": "We extract reagents from the natural language descriptions of protocols using two utility functions,KILLS and DEFINES. KILLS identifies the reagent consumed in an operation, while DEFINES iden-tifies the reagent introduced in an operation. Due to the potential for a single chemical substanceto have multiple names among other factors, it is impractical to rely solely on string matching todetermine if a reagent is killed in a given operation. Instead, we employ a method based on promptengineering with LLMs for this analysis.",
  "C.3Cost of the implementation": "The computational cost of our algorithm primarily arises from the expenses associated with APIcalls to LLMs.We selected OpenAIs gpt-3.5-turbo-0125 model for our experiments.Across 75 test protocols, we executed 1816 queries to achieve syntax-level translation, resultingin structured protocols. At the semantic level, we conducted 4062 queries for completion tasks (in-cluding translating protocols retrieved from training dataset). During these experiments, the costmodel charged US$0.50 per million tokens for inputs and US$1.50 per million tokens for outputs.Consequently, our expenditures were approximately US$10. Additionally, we utilized OpenAIstext-embedding-ada-002 model to embed the training dataset and build a vector database,which incurred a cost of about US$7.",
  "spin down on microfuge 20,000 x g, 15 min at 4C. Discard": "supernatant. Suck out the liquid droplets in the tube. The white RNApellet will turn clear when it dries out. Add 30-50 L ddH2O (DEPC)immediately after it becomes clear. Do not let the RNA over-dry,which will make it difficult to dissolve. If RNA pellet is over-dry,dissolve RNA at 37C for 30 min. Store RNAs at -80C for more than",
  "E.2Running cases of our translator handling specific challenges": "Ensuring the safety and correctness of translated protocols is an exceptionally challenging task. Sev-eral factors contribute to these challenges, including accurately mapping operations to their corre-sponding configuration parameters (Tab. A2), precisely parsing control flows from natural language(Tab. A3), completing latent semantics with domain-specific knowledge (Tab. A4), inferring miss-ing or omitted key information (Tab. A5), tracking resource capacities (Tab. A6), and verifying thesafety of run-time execution of experiments (Tab. A7). Consequently, we have made specific effortsin response to these challenges, resulting in our design of translator. Here we provide several runningexamples to demonstrate our translators capability on handling the challenging factors respectively.",
  "We present a detailed analysis of the errors made by our proposed automatic translator compared tohuman experts. We discuss the potential improvements of the translator accordingly": "Distinctions on the syntax levelDifference between the translation results of our system and thoseof experts is subtle, with the biggest difference being in the analysis of long sentences in naturallanguage. For human experts, it is natural and easy to analyze the parameters of events/actions ormultiple actions in long sentences, while for our approach, there are sometimes problems with thecorrespondence between action and parameter, which need to be improved in future work.",
  "A17": "Distinctions on the semantics levelWhen supplementing known unknowns, human experts tendto rely on contextual reasoning. Since experts are not familiar with protocols from all fields, theyoften infer parameters based on context for protocols outside their expertise. The primary sourceof their errors is a lack of understanding of protocols in specific domains, which is fundamentallyconsistent with the approach of our system. When supplementing unknown unknowns, human ex-perts tend to transfer their knowledge from familiar domains, such as instruments used or commonparameters, to protocols in various fields, using this as a basis for parameter supplementation. Oursystem, however, completes parameters based on all collected protocols, which is essentially theopposite of the transfer process used by human experts. The example presents as follows the completion of two types of parameters at the semantic levelis included: for instance, determining the configuration parameter for an operation, where humanexperts rely on personal experimental experience; and inferring the required reagents for one step,where human experts use contextual reasoning. When the context is not sufficiently clear, humanexperts cannot infer the known unknowns within a single sentence.",
  "As a systematic study with a proof-of-concept framework, the design and evaluation of the pipelinecome with limitations, leading to further investigations:": "We majorly exploit the approaches of empirical study to observe the behavior of DSLs and humanexperts for extracting design principles. Can we draw theories from information theory to rigor-ously prove the expression capacity of DSLs and other structural knowledge representations, toadvance our design choice? We majorly consider the imperative programming DSLs as the vehicle of PDGs in this work.This raises the question of whether incorporating alternative programming paradigms, such asfunctional and object-oriented models, could enhance the representation of complex entities withinprotocols, particularly the properties of reagents.",
  ". Claims": "Question: Do the main claims made in the abstract and introduction accurately reflect thepapers contributions and scope?Answer: [Yes]Justification: In this paper, we systematically study the problem of translating protocols forhuman experimenters into those suitable for self-driving laboratories, in order to standard-ize and automate the translation process. Further, we propose the initial proof-of-conceptframework that fully frees domain experts from hand-crafting protocol translators.Guidelines:",
  "The answer NA means that the paper has no limitation while the answer No meansthat the paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The au-thors should reflect on how these assumptions might be violated in practice and whatthe implications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the ap-proach. For example, a facial recognition algorithm may perform poorly when imageresolution is low or images are taken in low lighting. Or a speech-to-text system mightnot be used reliably to provide closed captions for online lectures because it fails tohandle technical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach to ad-dress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the mainexperimental results of the paper to the extent that it affects the main claims and/or conclu-sions of the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justification: We have provided them with the implementation details at Appx. C. We willalso release our codes upon acceptance.Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible is important, regardless ofwhether the code and data are provided or not.",
  "If the contribution is a dataset and/or model, the authors should describe the stepstaken to make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecturefully might suffice, or if the contribution is a specific model and empirical evaluation,it may be necessary to either make it possible for others to replicate the model withthe same dataset, or provide access to the model. In general. releasing code and datais often one good way to accomplish this, but reproducibility can also be provided viadetailed instructions for how to replicate the results, access to a hosted model (e.g., inthe case of a large language model), releasing of a model checkpoint, or other meansthat are appropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all sub-missions to provide some reasonable avenue for reproducibility, which may dependon the nature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clearhow to reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to re-produce the model (e.g., with an open-source dataset or instructions for how toconstruct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case au-thors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  "Guidelines:": "The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided.For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can helpdetermine the license of a dataset.",
  ". Experiments Compute Resources": "Question: For each experiment, does the paper provide sufficient information on the com-puter resources (type of compute workers, memory, time of execution) needed to reproducethe experiments?Answer: [Yes]Justification: Please refer to Appx. C.3.Guidelines: The answer NA means that the paper does not include experiments. The paper should indicate the type of compute workers CPU or GPU, internal cluster,or cloud provider, including relevant memory and storage.",
  ". Broader Impacts": "Question: Does the paper discuss both potential positive societal impacts and negativesocietal impacts of the work performed?Answer: [Yes]Justification: Please refer to the general discussions at Sec. 5.Guidelines: The answer NA means that there is no societal impact of the work performed. If the authors answer NA or No, they should explain why their work has no societalimpact or why the paper does not address societal impact. Examples of negative societal impacts include potential malicious or unintended uses(e.g., disinformation, generating fake profiles, surveillance), fairness considerations(e.g., deployment of technologies that could make decisions that unfairly impact spe-cific groups), privacy considerations, and security considerations.",
  "A26": "The conference expects that many papers will be foundational research and not tiedto particular applications, let alone deployments. However, if there is a direct path toany negative applications, the authors should point it out. For example, it is legitimateto point out that an improvement in the quality of generative models could be used togenerate deepfakes for disinformation. On the other hand, it is not needed to point outthat a generic algorithm for optimizing neural networks could enable people to trainmodels that generate Deepfakes faster. The authors should consider possible harms that could arise when the technology isbeing used as intended and functioning correctly, harms that could arise when thetechnology is being used as intended but gives incorrect results, and harms followingfrom (intentional or unintentional) misuse of the technology. If there are negative societal impacts, the authors could also discuss possible mitiga-tion strategies (e.g., gated release of models, providing defenses in addition to attacks,mechanisms for monitoring misuse, mechanisms to monitor how a system learns fromfeedback over time, improving the efficiency and accessibility of ML).",
  "According to the NeurIPS Code of Ethics, workers involved in data collection, cura-tion, or other labor should be paid at least the minimum wage in the country of thedata collector": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [Yes]Justification: We have obtained an approved IRB in advance. Please refer to Appx. B.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor researchwith human subjects": "Depending on the country in which research is conducted, IRB approval (or equiva-lent) may be required for any human subjects research. If you obtained IRB approval,you should clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}