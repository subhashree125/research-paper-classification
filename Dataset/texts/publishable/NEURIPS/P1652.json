{
  "Abstract": "The accurate prediction of geometric state evolution in complex systems is criticalfor advancing scientic domains such as quantum chemistry and material model-ing. Traditional experimental and computational methods face challenges in termsof environmental constraints and computational demands, while current deeplearning approaches still fall short in terms of precision and generality. In thiswork, we introduce the Geometric Diffusion Bridge (GDB), a novel generativemodeling framework that accurately bridges initial and target geometric states.GDB leverages a probabilistic approach to evolve geometric state distributions,employing an equivariant diffusion bridge derived by a modied version ofDoobs h-transform for connecting geometric states.This tailored diffusionprocess is anchored by initial and target geometric states as xed endpoints andgoverned by equivariant transition kernels.Moreover, trajectory data can beseamlessly leveraged in our GDB framework by using a chain of equivariantdiffusion bridges, providing a more detailed and accurate characterization ofevolution dynamics.Theoretically, we conduct a thorough examination toconrm our frameworks ability to preserve joint distributions of geometric statesand capability to completely model the underlying dynamics inducing trajectorydistributions with negligible error. Experimental evaluations across various real-world scenarios show that GDB surpasses existing state-of-the-art approaches,opening up a new pathway for accurately bridging geometric states and tacklingcrucial scientic challenges with improved accuracy and applicability.",
  "Introduction": "Predicting the evolution of the geometric state of a system is essential across various scienticdomains , offering valuable insights into difcult tasks such as drug dis-covery , reaction modeling , and catalyst analysis . Despite its criticalimportance, accurately predicting future geometric states of interest is challenging. Experimen-tal approaches often face obstacles due to strict environmental requirements and physical limits ofinstruments . Computational approaches seek to solve the problem by simulating thedynamics based on underlying equations . Though providing greater exibility, such calcu-lations are typically driven by rst-principle methods or empirical laws, either requiring extensivecomputational costs or sacricing accuracy .",
  "38th Conference on Neural Information Processing Systems (NeurIPS 2024)": "In recent years, deep learning has emerged as a pivotal tool in scientic discovery for manyelds , offering new avenues for tackling this problem. One line of approachaims to train models to predict target geometric states (e.g., equilibrium states) from initial statesdirectly and develop neural network architectures that respect inherent symmetries of geometricstates, such as the equivariance of rotation and translation . However, thisparadigm requires encoding the iterative evolution into a single-step prediction model, which lacksthe ability to fully capture the systems underlying dynamics and potentially leading to reducedaccuracy. Another line of research trains machine learning force elds (MLFFs) to simulate thetrajectory of geometric states over time , showing a better efciency-accuracybalance . Nevertheless, MLFFs are typically trained to predict intermediate labels,such as the force of the (local) current state. During inference, states are iteratively updated stepby step. Since small local errors can accumulate, reliable predictions over long trajectories highlydepend on the quality of intermediate labels, which cannot be guaranteed . Therefore,an ideal solution that can precisely bridge initial and target geometric states and effectively leveragetrajectory data (if available) as guidance is in great demand. In this work, we introduce Geometric Diffusion Bridge (GDB), a general framework for bridginggeometric states through generative modeling. From a probabilistic perspective, predicting targetgeometric states from initial states requires modeling the joint state distribution across differenttime steps. The diffusion models are standard choices to achieve this goal. However, thesemethods ideally generate data by denoising samples drawn from a Gaussian prior distribution, whichmakes it challenging to bridge pre-given geometric states or leverage trajectories in a unied man-ner. To address the issue, we establish a novel equivariant diffusion bridge by developing a modiedversion of Doobs h-transform . The proposed stochastic differential equation (SDE) isanchored by initial and target geometric states to simultaneously model the joint state distributionand is governed by equivariant transition kernels to satisfy symmetry constraints. Intriguingly, wefurther demonstrate that this framework can seamlessly leverage trajectory data to improve predic-tion. With available trajectory data, we can construct chains of equivariant diffusion bridges, eachmodeling one segment in the trajectory. The segments are interconnected by properly setting theboundary conditions, allowing complete modeling of trajectory data. For model training, we de-rive a scalable and simulation-free matching objective similar to , which requires nocomputational overhead when trajectory data is leveraged. Overall, our GDB framework offers a unied solution that precisely bridges geometric states by mod-eling the joint state distribution and comprehensively leverages available trajectories as ne-graineddepiction of dynamics for enhanced performance. Mathematically, we prove that the joint distribu-tion of geometric states across different time steps can be completely preserved by our (chains of)equivariant diffusion bridge technique, conrming its expressiveness in bridging geometric statesand underscoring the necessity of design choices in our framework. Furthermore, under mild andpractical assumptions, we prove that our framework can approximate the underlying dynamics gov-erning the evolution of geometric state trajectories with negligible error in convergence, remarkingon the completeness and usefulness of our framework in different scenarios. These advantages showthe superiority of our framework over existing approaches. Practically, we provide a comprehensive guidance for implementing our GDB framework in real-world applications. To verify its effectiveness and generality, we conduct extensive experimentscovering diverse data modalities (simple molecules & adsorbate-catalyst complex), scales (small,medium and large scales) and scenarios (with & without trajectory guidance). Numerical resultsshow that our GDB framework consistently outperforms existing state-of-the-art machine learningapproaches by a large margin. In particular, our method even surpasses strong MLFF baselinesthat are trained on 10 more data in the challenging structure relaxation task of OC22 , andtrajectory guidance can further enhance our performance. The superior performance demonstratesthe high capacity of our framework to capture the complex evolution dynamics of geometric statesand determine valuable and crucial geometric states of interest in critical real-world challenges.",
  "Our task of interest is to capture the evolution of geometric states, i.e., predicting future statesfrom initial states. Formally, let S denote a system consisting of a set of objects located in the": "three-dimensional Euclidean space. We use H Rnd to denote the objects with features, wheren is the number of objects, and d is the feature dimension. For object i, let ri R3 denoteits Cartesian coordinate. We dene the system as S = (H, R), where R = {r1, ..., rn}. Thisdata structure ubiquitously corresponds to various real-world systems such as molecules andproteins . In practice, the geometric state is governed by physical laws and evolvesover time, and we denote the geometric state at a given time t as Rt = {rt1, ..., rtn}. Given a systemSt0 = (H, Rt0) at time t0, our goal is to predict St1 = (H, Rt1) at a future time t1. As an example,in a molecular system, Rt1 can be the equilibrium state of interest evolved from the initial state Rt0. In this problem, inherent symmetries in geometric states should be considered. For example, arotation that is applied to the coordinate system at time t0 should also be applied to subsequent timesteps. These symmetries are related to the concept of equivariance in group theory .Formally, let : X Y denote a function mapping between two spaces. Given a group G, letX and Y denote its group representations, which describe how the group elements act on thesespaces. A function : X Y is said to be equivariant if it satises the following condition:Y(g)[(x)] = X (g)[x], g G, x X. When Y = IY (identity transformation), it is alsoknown as invariance. SE(3) group, which pertains to translations (T(3)) and rotations (SO(3)) in3D Euclidean space, is one of the most widely used groups and is employed in our framework.",
  "Diffusion Models": "Diffusion models have emerged as the state-of-the-art generative modeling approachesacross various domains . The main idea of this method is to constructa diffusion process that maps data to noise, and train models to reverse such process by using atractable objective. Formally, to model the data distribution qdata(X), where X Rd, we construct a diffusion process(Xt)t[0,T ], which is represented as a sequence of random variables indexed by time steps. We setX0 qdata(X) and XT pprior(X), where pprior(X) has a tractable form to generate samples ef-ciently, e.g. standard Gaussian distribution. Mathematically, we model (Xt)t[0,T ] as the solutionto the following stochastic differential equation (SDE):",
  "dXt = f(Xt, t)dt + (t)dBt,(1)": "where f(, ) : Rd [0, T ] Rd is a vector-valued function called the drift coefcient, () :[0, T ] R is a scalar function known as the diffusion coefcient, and (Bt)t[0,T ] is the standardWiener process (a.k.a., Brownian motion) . We hereafter denote by pt(X) the marginal distri-bution of Xt. Let p(x, t|x, t) denote the transition density function such that P(Xt A|Xt =x) = A p(x, t|x, t)dx for any Borel set A. By simulating this diffusion process forward in time,the distribution of Xt will become pprior(X) at the nal time T . In the literature, there exist variousdesign choices of the SDE formulation in Eqn. (1) such that it transports the data distribution intothe xed prior distribution . In order to sample X0 p0(X) := qdata(X), an intriguing fact can be leveraged: the reverse of adiffusion process is also a diffusion process . This reverse process runs backward in time and canbe formulated by the following time-reversal SDE:",
  "dXt =f(Xt, t) 2(t)Xt log pt(Xt)dt + (t)dBt,(2)": "where X log pt(X) denote the score of the marginal distribution at time t. If the score is known forall time, then we can derive the reverse diffusion process from Eqn. (2), sample from pprior(X), andsimulate this process to generate samples from the data distribution qdata(X). In particular, the scoreX log pt(X) can be estimated by training a parameterized model s(X, t) with a denoising scorematching objective . In theory, the minimizer of this objective approximates the ground-truthscore and this objective is tractable.",
  "As discussed in the introduction, effectively capturing the evolution of geometric states is crucial,for which three desiderata should be carefully considered:": "Coupling Preservation: From a probabilistic perspective, the evolution of geometric statestransports their distribution from qdata(St0) to qdata(St1), and we are interested in modelingthe distribution of target geometric states given the initial states, i.e., qdata(St1|St0) :=qdata(Rt1|H, Rt0), which can be achieved by preserving the coupling of geometric states,i.e., qdata(Rt0, Rt1|H). For brevity, we hereafter omit the condition of H because it keepsthe same along the evolution and can be easily incorporated into the models. Symmetry Constraints: Since the law governing the evolution is unchanged regardless ofhow the system is rotated or translated, the distribution of the geometric states shouldsatisfy symmetry constraints, i.e., qdata(R(g)[Rt1]|R(g)[Rt0]) = qdata(Rt1|Rt0) andqdata(R(g)[Rt0], R(g)[Rt1]) = qdata(Rt0, Rt1) for all g SE(3), Rt R. Trajectory Guidance: Trajectories of geometric states are sometimes accessible and pro-vide ne-grained descriptions of the evolution dynamics. For completeness, it is crucial todevelop a unied framework that can characterize and leverage trajectory data as guidancefor better bridging geometric states and capturing the evolution. However, existing approaches typically have their limitations for this task, which we thoroughlydiscuss in Sec. 5 and summarize into . In this section, we introduce Geometric DiffusionBridge (GDB), a general framework for bridging geometric states through generative modeling. Wewill elaborate on key techniques for completely preserving couping under symmetry constraints(Sec. 3.1), and demonstrate how our framework can be seamlessly extended to leverage trajectorydata (Sec. 3.2). Theoretically, we conduct a thorough analysis on the capability of our unied frame-work, showing its completeness and superiority. All proofs of theorems are presented in Appendix B.A detailed guidance of practical implementing our framework is further provided (Sec. 3.3).",
  "Equivariant Diffusion Bridge": "Our key design lies in the construction of equivariant diffusion bridge, a tailored diffusionprocess (Rt)t[0,T ] for bridging initial states R0qdata(Rt0) and target states RT qdata(Rt1|Rt0),completely preserving coupling of geometric states and satisfying symmetry constraints. Firstly, weinvestigate necessary conditions for a diffusion process on geometric states to meet the symmetricconstraints:Proposition 3.1. Let R denote the space of geometric states and fR(, ) : R [0, T ] R denote the drift coefcient on R.Let (Wt)t[0,T ] denote the Wiener process on R.Given an SDE on geometric states dRt=fR(Rt, t)dt + (t)dWt, R0q(R0), itstransition density pR(z, t|z, t), z, zR is SE(3)-equivariant, i.e., pR(Rt, t|Rt, t)=pR(R(g)[Rt], t|R(g)[Rt], t), g SE(3), 0 t, t T, if these conditions are satised: (1)q(R0) is SE(3)-invariant; (2) fR(, t) is SO(3)-equivariant and T(3)-invariant; (3) the transitiondensity of (Wt)t[0,T ] is SE(3)-equivariant. Using Proposition 3.1, we can obtain a diffusion process that respect symmetry constraints by prop-erly considering conditions for key components. Next, we modify a useful tool in probability theorycalled Doobs h-transform , which plays an essential role in the construction of ourequivariant diffusion bridge for preserving coupling of geometric states:Proposition 3.2. Let pR(z, t|z, t) be the transition density of the SDE in Proposition 3.1. LethR(, ) : R [0, T ] R>0 be a smooth function satisfying: (1) hR(, t) is SE(3)-invariant; (2)hR(z, t) =pR(z, t|z, t)hR(z, t)dz. Then we can derive the following hR-transformed SDEon geometric states:dRt =fR(Rt, t) + 2(t)Rt log hR(Rt, t)dt + (t)dWt,(3)",
  "hR(z,t)": "Proposition 3.2 provides an equivariant version of Doobs h-transform, which can be used to guidea free SDE on geometric states to hit an event almost surely. For example, if we set hR(, t) =pR(z, T |, t), z R, i.e., the transition density of the original SDE evaluated at RT = z, then thehR-transformed SDE in Eqn. (3) arrives at the specic geometric state z almost surely at the naltime (see Proposition B.7 in the appendix for more details). Therefore, if we derive a proper hR(, )function under the symmetry constraints, our target process (Rt)t[0,T ] can be constructed:Theorem 3.3 (Equivariant Diffusion Bridge). Let dRt = fR(Rt, t)dt + (t)dWt be an SDEon geometric states with transition density pR(z, t|z, t), z, z R satisfying the conditions inProposition 3.1. Let hR(z, t; z0) =pR(z, T |z, t)qdata(z|z0)",
  "We call the tailored diffusion process (Rt)t[0,T ] an equivariant diffusion bridge": "According to Theorem 3.3,given an initial geometric state Rt0,we can predict tar-getgeometricstatesRt1bysimulatingtheequivariantdiffusionbridge(Rt)t[0,T ]from R0=Rt0,which arrives at RTqdata(Rt1|Rt0).However,the scoreEqR(RT ,T |Rt,t;R0,0)[Rt log pR(RT , T |Rt, t)|R0, Rt] in Eqn. (4) is not tractable in general.Inspired by the score matching objective in diffusion models , we use a parameterized modelv(Rt, t; R0) to estimate the score by using the following training objective:",
  "L() = E(z0,z1)qdata(Rt0 ,Rt1 ),RtqR(Rt,t|z1,T ;z0,0)(t)v(Rt, t; z0)Rt log pR(z1, T |Rt, t)2,(5)": "where t U(0, T ) (the uniform distribution on [0, T ]), and () : [0, T ] R0 is a positiveweighting function. Theoretically, we prove that the minimizer of Eqn. (5) approximates the ground-truth score (see Appendix B.5 for more details). Moreover, this objective is tractable because thetransition density pR and qR can be designed to have simple and explicit forms such as Gaussian,which we will elaborate on in Sec. 3.3.",
  "Chain of Equivariant Diffusion Bridges for Leveraging Trajectory Guidance": "In this subsection, we elaborate on how to leverage trajectories of geometric states as a ne-grainedguidance in our framework. Let ( Ri)i[N] denote a trajectory of N + 1 geometric states andqtraj( R0, ..., RN) denote the joint probability density function of geometric states in a trajectory.In practice, the markov property of trajectories typically holds . Under this assumption,qtraj( R0, ..., RN) can be equivalently reformulated into q0traj( R0) Ni=1 qitraj( Ri| Ri1) by the chainrule of probability. If qitraj( Ri| Ri1) can be well modeled, we can capture the distribution of trajec-tories of geometric states completely. According to Theorem 3.3, given R0 q0traj( R0), an equivariant diffusion bridge (Rt)t[0,T ] can beconstructed to model the joint distribution qtraj( R0, R1) and hence q1traj( R1| R0) is preserved. There-fore, if we construct a series of interconnected equivariant diffusion bridges, the distribution oftrajectories can be modeled:Theorem 3.4 (Chain of Equivariant Diffusion Bridges). Let {(Rti)t[0,T ]}i[N1] denote a seriesof N equivaraint diffusion bridges dened in Theorem 3.3. For the i-th bridge (Rti)t[0,T ], if we set",
  "(1) hiR(z, t; z0) =pR(z, T |z, t)qi+1traj (z|z0)": "pR(z,T |z0,0)dz; (2) R00 q0traj( R0), R0i = RTi1, 0 < i < N,then the joint distribution qR(R00, RT0 , RT1 , , RTN1) induced by {(Rti)t[0,T ]}i[N1] equals toqtraj( R0, ..., RN). We call this process a chain of equivariant diffusion bridges. In this way, a chain of equivariant diffusion bridge can be used to model prior trajectory data, andsimulating this chain not only bridges initial and target geometric states but also yields intermediateevolving states. Similarly, we can also use a parameterized model to estimate the scores of bridgesin this chain. Instead of having only one objective in all time steps, we now have N bridges in total,which categorize the time span into N groups with different time-dependent objectives. Therefore,by properly specifying time steps and initial conditions, the objective in Eqn. (5) can be seamlesslyextended (see Appendix B.7 for more details on its provable guarantee):",
  "Lastly, we provide the following theoretical result, which further characterizes our frameworksexpressiveness to completely model the underlying dynamics that induce the trajectory distributions:": "Theorem 3.5. Assume ( Ri)i[N] is sampled by simulating a prior SDE on geometric states d Rt =HR( Rt)dt + d Wt. Let i denote the path measure of this prior SDE when t [iT, (i + 1)T ].Building upon ( Ri)i[N], let {iR}i[N1] denote the path measure of our chain of equivariantdiffusion bridges. Under mild assumptions, we have limN maxiKL(i ||iR) = 0. It is noteworthy that the assumption of the prior SDE existence holds in various real-world applica-tions. For example, in geometry optimization, we can formulate the iterative updating process of amolecular system as dRt = RtV (Rt)dt + dWt, where V (Rt) denotes the potential energyat Rt and , are step sizes . From Theorem 3.5, such prior SDE serves as the underlying lawgoverning the evolution dynamic, and our chain of equivariant diffusion bridges constructed fromempirical trajectory data can well approximate it, showing the completeness of our framework.",
  "T 2I)": "Symmetry constraints.In proposition 3.1, we have several conditions that should be satisedto meet the symmetry constraints. Firstly, since a parameterized model v(Rt, t; R0) is used toestimate the score of our equivariant diffusion bridge, it should be SO(3)-equivariant and T(3)-invariant. Besides, we follow to consider CoM-free systems: given R = {r1, ..., rn}, wedene r =1 nni=1 ri and the CoM-free version of R = {r1 r, ..., rn r}. To sample fromN(z0, 2I) with z0 R consisting of n objects, we (1) sample = {i}ni=1 by i.i.d. drawingi N(0, I3); (2) calculate the CoM-free of ; (3) obtain z0 + . Trajectory guidance.According to Eqn. (6), both piR and qiR for all i[N1] should bedetermined.Similarly, we set piR(zi+1, T |Rt, t)=N(Rt, 2i (T t)I), which further inducesqiR(Rt, t|zi+1, T ; zi, 0) = N( t",
  "Combining all the above design choices, we have the following algorithms for training our Geo-metric Diffusion Bridge (Alg. 3) and leveraging trajectory guidance if available (Alg. 4). After the": "model is well trained, we leverage ODE numerical solvers to simulate the bridge process byusing its equivalent probability ow ODE . In this way, we can effectively and deterministicallypredict future geometric states of interest from initial states in an efcient iterative process. Lastly, itis also noteworthy that our framework is general to be implemented by using other advanced designstrategies , which we leave as future work.",
  "Equilibrium State Prediction": "Task.Equilibrium states typically represent local minima on the Born-Oppenheimer potentialenergy surface of a molecular system , which correspond to its most stable geometric state andplay an essential role in determining its properties in various aspects . In this task, our goalis to accurately predict the equilibrium state from the initial geometric state of a molecular system. Dataset.Two popular datasets are used: (1) QM9 is a medium-scale dataset that has beenwidely used for molecular modeling, consisting of 130,000 organic molecules. In convention, 110k,10k, and 11k molecules are used for train/valid/test sets respectively; (2) Molecule3D is a large-scale dataset curated from the PubChemQC project , consisting of 3,899,647 molecules intotal and its train/valid/test splitting ratio is 6 : 2 : 2. In particular, both random and scaffold splittingmethods are adopted to thoroughly evaluate the in-distribution and out-of-distribution performance.For each molecule, an initial geometric state is generated by using fast and coarse force eld and geometry optimization is conducted to obtain DFT-calculated equilibrium geometric structure. Setting.In this task, we parameterize v(Rt, t; R0) by extending a Graph-Transformer basedequivariant network to encode both time steps and initial geometric states as conditions.For inference, we use 10 time steps with the Euler solver . Following , we choose severalstrong baselines for a comprehensive comparison, and use three metrics for measuring the error be-tween predicted target states and ground-truth states: C-RMSD, D-MAE and D-RMSE. The detaileddescriptions of the baselines, evaluation metrics and training settings are presented in Appendix D.1.",
  "Structure Relaxation": "Task.Catalyst discovery is crucial for various applications. Adsorbate candidates are placedon catalyst surfaces and evolve through structure relaxation to adsorption states, in which theadsorption structures can be determined for measuring catalyst activity and selectivity. Our goal isthus to accurately predict adsorption states from initial states of adsorbate-catalyst complexes. Dataset.We adopt Open Catalyst 2022 (OC22) dataset , which has great signicance forthe development of Oxygen Evolution Reaction (OER) catalysts.Each data is in the form ofthe adsorbate-catalyst complex.Both initial and adsorption states with trajectories connectingthem are provided. The training set consists of 45,890 catalyst-adsorbate complexes. To betterevaluate the models performance, the validation and test sets consider the in-distribution (ID) andout-of-distribution (OOD) settings which use unseen catalysts, containing approximately 2,624 and2,780 complexes respectively. Setting.Following , we use the Average Distance within Threshold (ADwT) as theevaluation metric, which reects the percentage of structures with an atom position MAE belowthresholds. We parameterize v(Rt, t; R0) by using GemNet-OC , which also serves as a : Results on the OC22 IS2RS Validation set. \"OC20+OC22\" denotes using both OC20 and OC22 data; \"OC20OC22\" means pre-training on OC20 data then ne-tuning on OC22 data;\"OC22-only\" means only using OC22 data. We report the ofcial results of baselines from",
  "GDB (ours)63.0155.7859.39 trajectory guidance62.1454.9458.54 R0 condition60.1749.2654.71": "verication that our framework is compatible with different backbone models. For inference, wealso use 10 time steps with the Euler solver. Following , we choose strong MLFF baselinestrained on force eld data for a challenging comparison. The detailed descriptions of baselines andsettings are presented in Appendix D.2. Results.In , our GDB signicantly outperforms the best baseline, e.g., 3.3%/3.6%/3.4%relative improvement on the ADwT metric of ID, OOD and Avg respectively. It is noteworthy thatthe best baseline is the GemNet-OC force eld trained on both OC20 and OC22 data, which is 10times more than OC22 data only. Nevertheless, our framework still achieves better performanceon predicting the adsorption geometric states.Moreover, our framework without using anytrajectory data still can achieve better performance compared to the best baseline, e.g., 58.54 v.s.57.42 Avg[%]. All the results on this challenging task further demonstrate the superiority andcompleteness of our framework. Ablation study.Furthermore, we conduct ablation studies to examine key designs of our frame-work in . Firstly, we can see that using trajectory guidance indeed improves the performanceof our framework, e.g., 1.4% relative improvement on Avg ADwT. Moreover, we also investigate theimpact of R0 condition in v(Rt, t; R0), which plays an essential role in preserving the joint distri-bution of geometric states. Without this condition, we can see a signicant drop, e.g., 6.5%/10.3%relative ADwT drop on Avg/OOD respectively. Overall, these ablation studies serve as strong sup-ports on the necessity of developing a unied framework that can precisely bridge geometric statesby preserving their joint distributions and effectively leverage trajectory data as guidance for en-hanced performance.",
  "Related Works": "Direct Prediction.One line of approach for bridging geometric states is direct prediction, i.e.,training a model to directly predict target geometric states given initial states as input. Models thatcarefully respect symmetry constraints such as the equivariance to 3D rotations and translationsare typically used, which are called Geometric Equivariant Networks . Differenttechniques have been explored to encode such priors, which mainly include vector operationssuch as scalar and vector product , e.g., the scalar-vector product usedin EGNN , and tensor product based operations . Despite its simplicityand efciency, direct prediction requires encoding the iterative evolution of geometric states into asingle-step prediction model, which lacks the ability to capture the underlying dynamics and cannotleverage trajectories of geometric states.",
  "Machine Learning Force Field.Another line of approach is called machine learning force eld(MLFF) , which are trained to predict intermediate labels, such as the po-": "tential energy or force of the (local) current geometric state instead. After training, MLFFs canbe used to simulate the trajectory of geometric states over time based on underlying equations.Using Geometric Equivariant Networks as the backbone, MLFFs typically satisfy the symmetryconstraints. Besides, trajectory data with additional energy or force labels can directly be used fortraining MLFFs. However, this paradigm highly depends on the existence and quality of intermedi-ate labels since small local errors in energy or force prediction can accumulate along the simulationprocess . Moreover, there exists no guarantee that MLFFs can completely model jointstate distributions, which is another limitation for bridging geometric states. Geometric Diffusion Models.In recent years, diffusion models have emerged with state-of-the-art generative modeling performance across various domains . In geometricdomain, diffusion models are typically used for molecule conformation generation and protein design . By properly design the noising process and model architectures,symmetry constraints on the transition kernel and prior distribution can be satised, which guar-antees the generated data is sampled from roto-translational invariant distributions . Inaddition to the score-based formulation, recent advances further extend new techniques such as owmatching to satisfy symmetry constraints for these generation tasks . Never-theless, there exists no guaratee that these approaches can model the joint distribution of geometricstates . And how to leverage trajectory data as guidance for bridging geometric states is alsochallenging. Other techniques.MoreRed trains a diffusion model on equilibrium molecule conformationswith a time step predictor, and directly use it for bridging any conformations to their equilibriumstates. GTMGC instead develop a Graph Transformer to directly predict equilibrium confor-mations from their 2D graph forms. Both of them are limited to the equilibrium conformation pre-diction task, cannot preserve the joint state distribution and leverage trajectory data. EGNO isa concurrent work that develops a neural operator based approach to model dynamics of trajectories.By carefully designing temporal convolution in fourier spaces, EGNO can learn from trajectory data.However, this tailored approach cannot be directly used without trajectory guidance. To preservejoint data distributions, coincide with us to leverage Doobs h-transform to repurposingstandard diffusion processes, but they do not respect symmetry constraints and cannot leveragetrajectories.There also exist recent works that study the diffusion bridge framework and apply it to various domains such as images and graphs . Compared to all aboveapproaches, our GDB framework stands out as a unique and ideal solution that can precisely bridgegeometric states and effectively leverage trajectory data (if available) in a unied manner.",
  "Conclusion": "In this work, we introduce Geometric Diffusion Bridge (GDB), a general framework for bridging ge-ometric states through generative modeling. We leverage a modied version of Doobs h-transformto constructe an equivariant diffusion bridge for bridging initial and target geometric states. Trajec-tory data can further be seamlessly leveraged as guidance by using a chain of equivariant diffusionbridges, allowing complete modeling of trajectory data. Mathematically, we conduct a comprehen-sive theoretical analysis showing our frameworks ability to preserve joint distributions of geometricstates and capability to completely model the evolution dynamics. Empirical comparisons on dif-ferent settings show that our GDB signicantly surpasses existing state-of-the-art approaches andablation studies further underscore the necessity of several key designs in our framework. In thefuture, it is worth exploring better implementation strategies of our framework for enhanced perfor-mance, and applying our GDB to other critical challenges involving bringing geometric states.",
  "Broader Impacts and Limitations": "This work newly proposes a general framework to bridge geometric states, which has great signif-icance in various scientic domains. Our experimental results have also demonstrated considerablepositive potential for various applications, such as catalyst discovery and molecule optimization,which can signicantly contribute to the advancement of renewable energy processes and chemistrydiscovery. However, it is essential to acknowledge the potential negative impacts including thedevelopment of toxic drugs and materials. Thus, stringent measures should be implemented tomitigate these risks. There also exist some limitations to our work. For the sake of generality, we do not experimentwith advanced implementation strategies of training objectives and sampling algorithms, whichleave room for further improvement.Besides, the employment of Transformer-based architec-tures may also limit the efciency of our framework. This has also become a common issue intransformer-based diffusion models, which we have earmarked for future research.",
  "Acknowledgements": "We thank all the anonymous reviewers for the very careful and detailed reviews as well as thevaluable suggestions. Their help has further enhanced our work. Liwei Wang is supported byNational Science and Technology Major Project (2022ZD0114902) and National Science Foun-dation of China (NSFC62276005). Di He is supported by National Science Foundation of China(NSFC62376007).",
  "Muratahan Aykol, Joseph H Montoya, and Jens Hummelshj. Rational solid-state synthesisroutes for inorganic materials. Journal of the American Chemical Society, 143(24):92449259, 2021": "Keld L Bak, Jrgen Gauss, Poul Jrgensen, Jeppe Olsen, Trygve Helgaker, and John F Stan-ton. The accurate determination of molecular equilibrium structures. The Journal of ChemicalPhysics, 114(15):65486556, 2001. Ilyes Batatia, David P Kovacs, Gregor Simm, Christoph Ortner, and Gbor Csnyi. Mace:Higher order equivariant message passing neural networks for fast and accurate force elds.Advances in Neural Information Processing Systems, 35:1142311436, 2022. Simon Batzner, Albert Musaelian, Lixin Sun, Mario Geiger, Jonathan P Mailoa, MordechaiKornbluth, Nicola Molinari, Tess E Smidt, and Boris Kozinsky. E (3)-equivariant graph neu-ral networks for data-efcient and accurate interatomic potentials. Nature communications,13(1):2453, 2022.",
  "Jorg Behler. Perspective: Machine learning potentials for atomistic simulations. The Journalof chemical physics, 145(17), 2016": "Johannes Brandstetter, Rob Hesselink, Elise van der Pol, Erik J Bekkers, and Max Welling.Geometric and physical quantities improve e(3) equivariant message passing. In InternationalConference on Learning Representations, 2022. Linda J Broadbelt, Scott M Stark, and Michael T Klein. Computer generated pyrolysis mod-eling: on-the-y generation of species, reactions, and rates. Industrial & Engineering Chem-istry Research, 33(4):790799, 1994.",
  "John Charles Butcher. Numerical methods for ordinary differential equations. John Wiley &Sons, 2016": "Lowik Chanussot, Abhishek Das, Siddharth Goyal, Thibaut Lavril, Muhammed Shuaibi, Mor-gane Riviere, Kevin Tran, Javier Heras-Domingo, Caleb Ho, Weihua Hu, et al. Open catalyst2020 (oc20) dataset and community challenges. Acs Catalysis, 11(10):60596072, 2021. Tianlang Chen, Shengjie Luo, Di He, Shuxin Zheng, Tie-Yan Liu, and Liwei Wang. GeoM-Former: A general architecture for geometric molecular representation learning. In Forty-rstInternational Conference on Machine Learning, 2024. Stefan Chmiela, Alexandre Tkatchenko, Huziel E Sauceda, Igor Poltavsky, Kristof T Schtt,and Klaus-Robert Mller. Machine learning of accurate energy-conserving molecular forceelds. Science advances, 3(5):e1603015, 2017.",
  "Valentin De Bortoli, Guan-Horng Liu, Tianrong Chen, Evangelos A Theodorou, and WeilieNie. Augmented bridge matching. arXiv preprint arXiv:2311.06978, 2023": "Jonas Degrave, Federico Felici, Jonas Buchli, Michael Neunert, Brendan Tracey, FrancescoCarpanese, Timo Ewalds, Roland Hafner, Abbas Abdolmaleki, Diego de Las Casas, et al.Magnetic control of tokamak plasmas through deep reinforcement learning.Nature,602(7897):414419, 2022. Amanda L Dewyer, Alonso J Argelles, and Paul M Zimmerman. Methods for exploring reac-tion space in molecular systems. Wiley Interdisciplinary Reviews: Computational MolecularScience, 8(2):e1354, 2018.",
  "Ferran Feixas, Steffen Lindert, William Sinko, and J Andrew McCammon. Exploring the roleof receptor exibility in structure-based drug discovery. Biophysical chemistry, 186:3145,2014": "Xiang Fu, Zhenghao Wu, Wujie Wang, Tian Xie, Sinan Keten, Rafael Gomez-Bombarelli,and Tommi S. Jaakkola. Forces are not enough: Benchmark and critical evaluation for ma-chine learning force elds with molecular simulations. Transactions on Machine LearningResearch, 2023. Survey Certication. Fabian Fuchs, Daniel Worrall, Volker Fischer, and Max Welling. Se (3)-transformers: 3droto-translation equivariant attention networks. Advances in neural information processingsystems, 33:19701981, 2020.",
  "Johannes Gasteiger, Janek Gro, and Stephan Gnnemann. Directional message passing formolecular graphs. arXiv preprint arXiv:2003.03123, 2020": "JohannesGasteiger,MuhammedShuaibi,AnuroopSriram,StephanGnnemann,Zachary Ward Ulissi, C. Lawrence Zitnick, and Abhishek Das. Gemnet-OC: Developinggraph neural networks for large and diverse molecular simulation datasets. Transactions onMachine Learning Research, 2022. Mojtaba Haghighatlari, Jie Li, Xingyi Guan, Oufan Zhang, Akshaya Das, Christopher J Stein,Farnaz Heidar-Zadeh, Meili Liu, Martin Head-Gordon, Luke Bertels, et al. Newtonnet: Anewtonian message passing network for deep learning of interatomic potentials and forces.Digital Discovery, 1(3):333343, 2022.",
  "Jaehyeong Jo, Dongki Kim, and Sung Ju Hwang.Graph generation with destination-predicting diffusion mixture, 2024": "John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ron-neberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin dek, Anna Potapenko, et al.Highly accurate protein structure prediction with alphafold.Nature, 596(7873):583589,2021. Wolfgang Kabsch. A discussion of the solution for the best rotation to relate two sets ofvectors. Acta Crystallographica Section A: Crystal Physics, Diffraction, Theoretical andGeneral Crystallography, 34(5):827828, 1978. Khaled Kahouli, Stefaan Simon Pierre Hessmann, Klaus-Robert Mller, Shinichi Nakajima,Stefan Gugler, and Niklas Wolf Andreas Gebauer. Molecular relaxation by reverse diffusionwith time step prediction. arXiv preprint arXiv:2404.10935, 2024.",
  "Shuqi Lu, Zhifeng Gao, Di He, Linfeng Zhang, and Guolin Ke. Highly accurate quantumchemical property prediction with uni-mol+. arXiv preprint arXiv:2303.16982, 2023": "Shengjie Luo, Tianlang Chen, and Aditi S. Krishnapriyan. Enabling efcient equivariant oper-ations in the fourier basis via gaunt tensor products. In The Twelfth International Conferenceon Learning Representations, 2024. Shengjie Luo, Tianlang Chen, Yixian Xu, Shuxin Zheng, Tie-Yan Liu, Liwei Wang, andDi He. One transformer can understand both 2d & 3d molecular data. In The EleventhInternational Conference on Learning Representations, 2023. Shengjie Luo, Shanda Li, Shuxin Zheng, Tie-Yan Liu, Liwei Wang, and Di He. Your trans-former may not be as powerful as you expect. In Alice H. Oh, Alekh Agarwal, DanielleBelgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems,2022.",
  "L Chris G Rogers and David Williams. Diffusions, Markov processes and martingales: Vol-ume 2, It calculus, volume 2. Cambridge university press, 2000": "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjorn Om-mer. High-resolution image synthesis with latent diffusion models. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 1068410695, June 2022. David Rosenberger, Justin S Smith, and Angel E Garcia. Modeling of peptides with classicaland novel machine learning force elds: A comparison. The Journal of Physical ChemistryB, 125(14):35983612, 2021. Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily L Denton,Kamyar Ghasemipour, Raphael Gontijo Lopes, Burcu Karagol Ayan, Tim Salimans, et al.Photorealistic text-to-image diffusion models with deep language understanding. Advancesin neural information processing systems, 35:3647936494, 2022.",
  "Yuyang Shi, Valentin De Bortoli, Andrew Campbell, and Arnaud Doucet.Diffusionschrdinger bridge matching. In Thirty-seventh Conference on Neural Information Process-ing Systems, 2023": "Muhammed Shuaibi, Adeesh Kolluru, Abhishek Das, Aditya Grover, Anuroop Sriram,Zachary Ulissi, and C Lawrence Zitnick. Rotation invariant graph neural networks usingspin convolutions. arXiv preprint arXiv:2106.09575, 2021. Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsu-pervised learning using nonequilibrium thermodynamics. In Francis Bach and David Blei,editors, Proceedings of the 32nd International Conference on Machine Learning, volume 37of Proceedings of Machine Learning Research, pages 22562265, Lille, France, 0709 Jul2015. PMLR. Vignesh Ram Somnath, Matteo Pariset, Ya-Ping Hsieh, Maria Rodriguez Martinez, AndreasKrause, and Charlotte Bunne.Aligned diffusion schrdinger bridges.In Uncertainty inArticial Intelligence, pages 19851995. PMLR, 2023.",
  "Yang Song and Stefano Ermon. Generative modeling by estimating gradients of the datadistribution. Advances in neural information processing systems, 32, 2019": "Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon,and Ben Poole. Score-based generative modeling through stochastic differential equations.In International Conference on Learning Representations, 2021. Yuxuan Song, Jingjing Gong, Minkai Xu, Ziyao Cao, Yanyan Lan, Stefano Ermon, HaoZhou, and Wei-Ying Ma. Equivariant ow matching with hybrid probability transport for 3dmolecule generation. Advances in Neural Information Processing Systems, 36, 2024.",
  "Philipp Thlke and Gianni De Fabritiis. Equivariant transformers for neural network basedmolecular potentials. In International Conference on Learning Representations, 2022": "Nathaniel Thomas, Tess Smidt, Steven Kearnes, Lusann Yang, Li Li, Kai Kohlhoff, andPatrick Riley. Tensor eld networks: Rotation-and translation-equivariant neural networksfor 3d point clouds. arXiv preprint arXiv:1802.08219, 2018. Richard Tran, Janice Lan, Muhammed Shuaibi, Brandon M Wood, Siddharth Goyal, Ab-hishek Das, Javier Heras-Domingo, Adeesh Kolluru, Ammar Rizvi, Nima Shoghi, et al. Theopen catalyst 2022 (oc22) dataset and challenges for oxide electrocatalysts. ACS Catalysis,13(5):30663084, 2023. Oliver T Unke, Stefan Chmiela, Huziel E Sauceda, Michael Gastegger, Igor Poltavsky,Kristof T Schutt, Alexandre Tkatchenko, and Klaus-Robert Muller. Machine learning forceelds. Chemical Reviews, 121(16):1014210186, 2021. Hanchen Wang, Tianfan Fu, Yuanqi Du, Wenhao Gao, Kexin Huang, Ziming Liu, PayalChandak, Shengchao Liu, Peter Van Katwyk, Andreea Deac, et al. Scientic discovery in theage of articial intelligence. Nature, 620(7972):4760, 2023. Joseph L Watson, David Juergens, Nathaniel R Bennett, Brian L Trippe, Jason Yim, Helen EEisenach, Woody Ahern, Andrew J Borst, Robert J Ragotte, Lukas F Milles, et al. De novo de-sign of protein structure and function with rfdiffusion. Nature, 620(7976):10891100, 2023.",
  "E Weinan and Eric Vanden-Eijnden. Transition-path theory and path-nding algorithms forthe study of rare events. Annual review of physical chemistry, 61(2010):391420, 2010": "Lemeng Wu, Chengyue Gong, Xingchao Liu, Mao Ye, and qiang liu.Diffusion-basedmolecule generation with informative prior bridges. In Alice H. Oh, Alekh Agarwal, DanielleBelgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems,2022. Guikun Xu, Yongquan Jiang, PengChuan Lei, Yan Yang, and Jim Chen. Gtmgc: Using graphtransformer to predict molecules ground-state conformation. In The Twelfth InternationalConference on Learning Representations, 2023. Minkai Xu, Jiaqi Han, Aaron Lou, Jean Kossai, Arvind Ramanathan, Kamyar Azizzade-nesheli, Jure Leskovec, Stefano Ermon, and Anima Anandkumar. Equivariant graph neuraloperator for modeling 3d dynamics. arXiv preprint arXiv:2401.11037, 2024. Minkai Xu, Alexander S Powers, Ron O. Dror, Stefano Ermon, and Jure Leskovec. Geomet-ric latent diffusion models for 3D molecule generation. In Andreas Krause, Emma Brunskill,Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and Jonathan Scarlett, editors, Proceed-ings of the 40th International Conference on Machine Learning, volume 202 of Proceedingsof Machine Learning Research, pages 3859238610. PMLR, 2329 Jul 2023. Minkai Xu, Alexander S Powers, Ron O Dror, Stefano Ermon, and Jure Leskovec. Geometriclatent diffusion models for 3d molecule generation. In International Conference on MachineLearning, pages 3859238610. PMLR, 2023. Minkai Xu, Lantao Yu, Yang Song, Chence Shi, Stefano Ermon, and Jian Tang. Geodiff: Ageometric diffusion model for molecular conformation generation. In International Confer-ence on Learning Representations, 2022. Zhao Xu, Youzhi Luo, Xuan Zhang, Xinyi Xu, Yaochen Xie, Meng Liu, Kaleb Dickerson,Cheng Deng, Maho Nakata, and Shuiwang Ji. Molecule3d: A benchmark for predicting 3dgeometries from molecular graphs. arXiv preprint arXiv:2110.01717, 2021. Jason Yim, Brian L. Trippe, Valentin De Bortoli, Emile Mathieu, Arnaud Doucet, ReginaBarzilay, and Tommi Jaakkola. SE(3) diffusion model with application to protein backbonegeneration. In Andreas Krause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, SivanSabato, and Jonathan Scarlett, editors, Proceedings of the 40th International Conference onMachine Learning, volume 202 of Proceedings of Machine Learning Research, pages 4000140039. PMLR, 2329 Jul 2023. Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, YanmingShen, and Tie-Yan Liu. Do transformers really perform badly for graph representation? InA. Beygelzimer, Y. Dauphin, P. Liang, and J. Wortman Vaughan, editors, Advances in NeuralInformation Processing Systems, 2021.",
  "AOrganization of the Appendix": "The supplementary material is organized as follows. In Appendix B, we rst recall some denitionsand tools from stochastic calculus and then give the proofs of all theorems. In Appendix C, wegive the derivation of our practical objective function and our sampling algorithms. In AppendixD, we give some details of our experiments, including a comprehensive introduction to the datasets,baselines, metrics and settings.",
  "for any Borel set A, where t1< t2< < tn.If (Xt)t[0,T ] is a Markov process,p(x, t|x1, t1; x2, t2; . . . ; xn, tn) = p(x, t|xn, tn), which is also called a transition density func-tion": "One of the most important results of stochastic calculus is the Itos formula. The precise statementsare as follows.Theorem B.1 (Itos formula for Brownian Motion). Let Bt be the ddimensional Brownian Motion.Assume f is a bounded real valued function with continuous second-order partial derivatives, i.e.f C2b (Rd). Then the Itos formula is given by",
  "x2i.(10)": "The Fokker-Plancks Equation is an useful tool to track the evolution of the transition density func-tion associated with an SDE. The precise statements are as follows.Proposition B.3. (Fokker-Plancks Equation) Let p(x, t|x, t) be the transition density function ofthe SDE dXt = f(Xt, t)dt + (t)dBt. Then p(x, t|x, t) satises the Fokker-Plancks Equation",
  "x2i.(13)": "When the terminal is xed, the evolution of the transition density function can also given by a PDE,which is called the Backward Kolmogorov Equation. We give the precise statement as follows.Proposition B.4. (Backward Kolmogorov Equation) Let p(x, t|x, t) be the transition density func-tion of the SDE dXt = f(Xt, t)dt+(t)dBt. Then p(x, t|x, t) satises the Backward KolmogorovEquation",
  "B.2Proof of Proposition 3.1": "Proposition B.5. Let R denote the space of geometric states and fR(, ) : R [0, T ] R denote the drift coefcient on R.Let (Wt)t[0,T ] denote the Wiener process on R.Given an SDE on geometric states dRt=fR(Rt, t)dt + (t)dWt, R0q(R0), itstransition density pR(z, t|z, t), z, zR is SE(3)-equivariant, i.e., pR(Rt, t|Rt, t)=pR(R(g)[Rt], t|R(g)[Rt], t), g SE(3), 0 t < t T, if the following conditions aresatised: (1) q(R0) is SE(3)-invariant; (2) fR(, t) is SO(3)-equivariant and T(3)-invariant; (3)the transition density of (Wt)t[0,T ] is SE(3)-equivariant. Proof. In this section, we view R = {r1, ..., rn} R as r1 r2 rn R3n, which is theconcatenation of ri. So from this perspective, the space R is isomorphic to the Euclidean space R3n.Then (Wt)t[0,T ] is the Wiener process with dimension d = 3n. For any g SE(3), R(g) can be characterized by an orthogonal matrix O(g) R33, satisfyingdet(O(g)) = 1, and a translation vector t R3. Then the representation of SE(3) on R3n is givenbyR(g)[R] = OR(g)R + tR,(16)where OR(g) = diag{O(g), O(g), . . . , O(g)}, tR = t t t R3n. Its obvious that OR(g)is also an orthogonal matrix in R3n3n, satisfying O1R (g) = OTR(g).",
  "(xj)2,(30)": "which is same as Eqn.(17). Since the boundary condition pR(y, 0|y0, t0) = (y y0) = (x x0) = pR(x, 0|x0, 0), then pR(y, t|y0, t0) = pR(x, t|x0, t0), t [0, T ]. Thus we have proved thatpR(Rt, t|Rt, t) = pR(R(g)[Rt], t|R(g)[Rt], t), g SE(3), 0 t < t T .",
  "B.3Proof of Proposition 3.2": "Proposition B.6 (Doobs h-transform). Let pR(z, t|z, t) be the transition density of the SDE inProposition 3.1. Let hR(, ) : R [0, T ] R>0 be a smooth function satisfying: (1) hR(, t)is SE(3)-invariant; (2) hR(z, t) =pR(z, t|z, t)hR(z, t)dz. We can derive the following hR-transformed SDE on geometric states:",
  "dRt =fR(Rt, t) + 2(t)Rt log hR(Rt, t)dt + (t)dWt.(49)": "Additionally, we need to show that the h-transformed transition density function satises the symmet-ric constraints. First, we show that if h(, t0) is SE(3)-invariant, then h(, t) is also SE(3)-invariantt [0, T ]. For any g SE(3), assume R(g)[z] = OR(g)z + tR, where OR(g) is an orthogonalmatrix and det(OR(g)) = 1. Since hR(z, t) satises",
  "which implies that phR(z, t|z, t) preserves the symmetric constraints for any g SE(3). So theproof is completed": "Next, we show how to construct a SDE with a xed terminal point as an simple application of theDoobs h-transform. The result of this example is very useful to construct diffusion bridge.Proposition B.7. Assume the original SDE is given by dXt = f(Xt, t)dt + (t)dWt. LethR(x, t) = pR(y, T |x, t) which is the transition density function of the original SDE evaluatedat XT = y. Then the h-transformed SDE",
  "where t U(0, N T ), i = t": "T , t = t i T, Rti qiR(Rt, t|zi+1, T ; zi, 0).Thenby Lemma B.9, v(Rti , t; zi) = EqiR(RTi ,T |Rti ,t;R0i )[Rti log piR(RTi , T |Rti, t)|R0i , Rti] minimizeLt(), t [0, NT ]. Since (t) 0, so the optimal parameter = arg minL() satises",
  "< .(132)": "For more discussions and applications of the Girsanovs theorem, please see . Now wecan give the precise assumptions and proof of Theorem 3.5 using the properties of Brownian Bridgeand Theorem B.14.Theorem B.15. Assume ( Ri)i[N] is sampled by simulating a prior SDE on geometric states d Rt =HR( Rt)dt + d Wt. Let i denote the path measure of this prior SDE when t [iT, (i + 1)T ].Building upon ( Ri)i[N], let {iR}i[N1] denote the path measure of our chain of equivariantdiffusion bridges. Assume {iR}i[N1] is composed of chain of the Brownian Bridge. Assume thetotal time is NT = 1. Under the following assumptions:",
  "then we have limN maxiKL(i ||iR) = 0": "Proof. Let p be the probability density function associated with the ground truth SDE d Rt =f R( Rt, t)dt + d Wt, R0 = R0. Let {(Rti)t[0,T ]}i[N1] denote a series of N equivaraint dif-fusion bridges dened in Theorem 3.4. Then by theorem 3.4, qR(R00, RT0 , RT1 , , RTN1) in-duced by {(Rt)t[0,T ]}i[N1] equals to pR(R00, RT0 , RT1 , , RTN1). Additionally, the condi-tional probability density function qR(Rti|RTi , R0i ) , for iT t < (i + 1)T , is associated with theBrownian bridge",
  "N , i.e. i = Ni": "N , where is a hyperpa-rameter. Again, in training stage, we set qiR(R0i , 0|z1, 1; z0, 0) = N(z0, 2i I) as initial distribution,and the terminal distribution is qiR(R0i , 0|z1, 1; z0, 0) = N(z1, 2i+1I), which is same as the initialdistribution of the next bridge. Sampling Algorithm We use the ODE-based method to generate samples at inference time. Afterthe training process, the neural network v is trained as described in Algorithm 3 and Algorithm 4.When the network is trained without trajectory guidance, we simulate the following ODE to generatesamples:d Rt",
  "D.1Equilibrium State Prediction": "Dataset.QM9 is a quantum chemistry benchmark consisting of 134k stable small organicmolecules, which has been widely used for molecular modeling. These molecules correspond to thesubset of all 133,885 species out of the GDB-17 chemical universe of 166 billion organic molecules.In convention, 110k, 10k, and 11k molecules are used for train/valid/test sets respectively. Thegeometric conformations that are minimal in energy are provided in the QM9 dataset. The equilib-rium conformation and its relative properties are all calculated at the B3LYP/6-31G(2df,p) level ofquantum chemistry. Molecule3D is a large-scale dataset curated from the PubChemQC project , consistingof 3,899,647 molecules in total, 2,339,788 molecules in training set, 779,929 molecules in the valida-tion set, 779,930 molecules in the test set, and its train/valid/test splitting ratio is 6 : 2 : 2. For eachmolecule, the 2D atom graph, the 3D equilibrium geometric conformation, and four extra propertiesare provided. In particular, both random and scaffold splitting methods are adopted to thoroughlyevaluate the in-distribution and out-of-distribution performance.For each molecule, an initialgeometric state is generated by using fast and coarse force eld and geometry optimizationis conducted to obtain B3LYP/6-31G* level DFT-calculated equilibrium geometric structure. Baselines. We comprehensively compare our GDB framework with previous equilibrium confor-mation prediction methods. Following , we use DG and ETKDG algorithms implementedby RDkit as our fundamental baselines. The benchmark used the DeeperGCN-DAGNNframework which proposed a deep graph neural network architecture to predict 3D geometricconformation of the molecule based on its 2D graph structure, and got impressive performanceon the Molecule3D dataset. GINE proposed a method for pretraining GNN to improve theperformance and capacity of GNN. GATv2 proposed a dynamic graph attention mechanismand improved the performance of the graph attention network on several tasks. GPS proposeda general framework that supported multiple types of encodings with efciency and scalabilityguarantees in both small and large graph prediction tasks.GTMGC proposed a novelneural network based on Graph-Transformer (GT) to predict the equilibriumconformation of the molecule in 3D based on its 2D graph structure. Metric. Following , three metrics are adopted to evaluate predictions of equilibrium states: (1)C-RMSD: given prediction R = {ri}Ni=1 which is rigidly aligned to the ground-truth R = {ri }Ni=1by the Kabsch algorithm , Root Mean Square Deviation between their atoms is calculated,",
  "N Ni=1 |di di |": "Settings.In this task, we parameterize v(Rt, t; R0) by extending a Graph-Transformer basedequivariant network to encode both time steps and initial geometric states as conditions.For training, we use AdamW as the optimizer, and set the hyper-parameter to 1e-8 and (1, 2) to(0.9,0.999). The gradient clip norm is set to 5.0. The peak learning rate is set to 1e-4. The batch sizeis set to 512. The weight decay is set to 0.0. The model is trained for 500k steps with a 30k-stepwarm-up stage. After the warm-up stage, the learning rate decays linearly to zero. The noise scale is set to 0.5. For inference, we use 10 time steps with the Euler solver . All models are trainedon 16 NVIDIA V100 GPU.",
  "D.2Structure Relaxation": "Dataset. Open Catalyst 2022 (OC22) dataset is a widely used dasaset, which has greatsignicance for the development of Oxygen Evolution Reaction (OER) catalysts. Each data in thedataset is in the form of the adsorbate-catalyst complex. Both initial and adsorption states withtrajectories connecting them are provided. The dataset consists of 62,331 Density Functional Theory(DFT) relaxations trajectories, and about 9,854,504 single-point DFT calculations across a rangeof oxide materials, coverages, and adsorbates.The training set consists of 45,890 catalyst-adsorbatecomplexes. To better evaluate the models performance, the validation and test sets consider thein-distribution (ID) and out-of-distribution (OOD) settings which use unseen catalysts, containingapproximately 2,624 and 2,780 complexes respectively. Baselines. Following , we choose strong MLFF baselines trained on force eld data for a chal-lenging comparison. Spinconv introduced a novel approach called spin convolution to modelangular information between sets of neighboring atoms in a graph neural network and got impressiveperformance in molecular simulation tasks. Gemnet proposed multiple structural improvementsfor geometric GNN with theoretical insights, which signicantly improved the experimental perfor-mance as well. Based on Gemnets framework, Gemnet-OC modied the architecture of thenetwork and improved the experimental performance on more diverse tasks. In , there are still other baseline setting. introduce a large-scale dataset Open Cata-lyst 2020 (OC20), which consists of 1,281,040 Density Functional Theory (DFT) relaxations and264,890,000 single point evaluations to help training the baseline model. presented base-lines using both OC20 and OC22 data in training stage and baselines using only OC20/OC22 forcomparison. Metric. Following , we use the Average Distance within Threshold (ADwT) as the evaluationmetric, which reects the percentage of structures with an atom position MAE below thresholds.To be more precise, the ADWT metric across thresholds ranging from = 0.01 A to = 0.5 A inincrements of 0.001 A. The computation of ADwT metric is to count the percentage of structureswith an atom position MAE below the threshold. Settings. In this task, We parameterize v(Rt, t; R0) by using GemNet-OC , which also servesas a verication that our framework is compatible with different backbone models. For training, weuse AdamW as the optimizer, and set the hyper-parameter to 1e-8 and (1, 2) to (0.9,0.999). Thegradient clip norm is set to 10.0. The peak learning rate is set to 5e-4. The batch size is set to 64.The weight decay is set to 0.0. The model is trained for 200k steps. After the warm-up stage, thelearning rate decays linearly to zero. The noise scale is set to 0.5. The trajectory length is set toN = 10. For inference, we also use 10 time steps with the Euler solver . All models are trainedon 8 NVIDIA A100 GPU."
}