{
  "Abstract": "Large-scale pre-trained models (PTMs) provide remarkable zero-shot classificationcapability covering a wide variety of object classes. However, practical applicationsdo not always require the classification of all kinds of objects, and leaving the modelcapable of recognizing unnecessary classes not only degrades overall accuracybut also leads to operational disadvantages. To mitigate this issue, we explore theselective forgetting problem for PTMs, where the task is to make the model unableto recognize only the specified classes while maintaining accuracy for the rest.All the existing methods assume white-box settings, where model informationsuch as architectures, parameters, and gradients is available for training. However,PTMs are often black-box, where information on such models is unavailable forcommercial reasons or social responsibilities. In this paper, we address a novelproblem of selective forgetting for black-box models, named Black-Box Forgetting,and propose an approach to the problem. Given that information on the model isunavailable, we optimize the input prompt to decrease the accuracy of specifiedclasses through derivative-free optimization. To avoid difficult high-dimensionaloptimization while ensuring high forgetting performance, we propose Latent Con-text Sharing, which introduces common low-dimensional latent components amongmultiple tokens for the prompt. Experiments on four standard benchmark datasetsdemonstrate the superiority of our method with reasonable baselines. The code isavailable at",
  "Introduction": "Large-scale pre-trained models (PTMs) such as CLIP [Radford et al., 2021] and ALIGN [Jia et al.,2021] have strong capabilities of zero-shot classification for everyday objects. Nevertheless, inpractical applications, the classification of all kinds of object classes is rarely required. For example,in an autonomous driving system, it would be sufficient to recognize limited classes of objects such ascars, pedestrians, and traffic signs. We would not need to recognize food, furniture, or animal species.Retaining the classes that do not need to be recognized may decrease overall classification accuracy,as well as cause operational disadvantages such as the waste of computational resources and the riskof information leakage. In this paper, we address the problem of selective forgetting of specifiedclasses [Shibata et al., 2021, Graves et al., 2021, Ye et al., 2022, Tarun et al., 2023], i.e., tuning a pre-trained model to reduce the classification accuracy for only the specified classes without affecting theaccuracy for the others1. While selective forgetting of specified classes has long been overlooked [Ye 1Note that the problem focused on in this paper is closely related to but different from the typical machineunlearning problem, which is the task of removing an arbitrary sample from a pre-trained model, i.e., obtaininga model that is identical to the model trained from scratch without that sample [Cao and Yang, 2015, Golatkaret al., 2020a, Sekhari et al., 2021, Bourtoule et al., 2021, Golatkar et al., 2021, Kurmanji et al., 2023].",
  "minimization": "+ : Overview of our black-box forgetting framework. The confidence of each class is computed as thesimilarity with the image and class (text) embeddings from the black-box pre-trained vision-languagemodel (e.g., CLIP). The obtained confidence is used to compute the respective loss functions for theclasses to be forgotten and the classes to be memorized. (a) For the classes to be forgotten, maximizethe entropy of the confidence so that the accuracy is reduced. (b) For the classes to be memorized,minimize the cross-entropy loss to retain the accuracy. These two objective are jointly optimized totune the learnable text prompt. The gradients of the objective are not available when the model isblack-box. We therefore use CMA-ES [Hansen et al., 2003], a derivative-free optimizer, to learn thetext prompt. Instead of directly optimizing the original high-dimensional context (token) embeddingsfor the prompt, our method learns lower-dimensional latent contexts for mitigating the difficulty ofhigh-dimensional optimization. et al., 2022], a few existing methods have been proposed very recently [Shibata et al., 2021, Ye et al.,2022, Tarun et al., 2023]. The seminal work is Learning with Selective Forgetting (LSF) [Shibata et al.,2021], which has been proposed in the context of continual learning [Kirkpatrick et al., 2017, Li andHoiem, 2017, Aljundi et al., 2018] and uses a special random code called mnemonic code to controlthe class-wise memorization and forgetting. A similar idea has been proposed to achieve forgettingby learning noise that maximizes the classification error for the classes to be forgotten [Tarun et al.,2023]. An extended version of LSF [Ye et al., 2022] allows forgetting of specified classes as well asrecovery of them by temporarily transferring the knowledge of the classes to be forgotten to anothernetwork called deposit module. Overall, all the existing methods assume the white-box setting, where the complete informationof the target model is available for training/tuning, including the model architecture, its parameters,and their gradients. However, major PTMs such as GPT-4V [OpenAI, 2023] are often black-box,where the model itself or its information is often fully or partially private due to commercial reasonsor considerations of social impact. Since the parameters and their gradients are not accessible in sucha model, all the existing methods are inapplicable. To the best of our knowledge, selective forgettingmethods for black-box models have never been studied to date. In this paper, we address Black-Box Forgetting, i.e., the selective forgetting problem for black-boxPTMs, and propose a novel approach to the problem. Given the unavailability of model information,our method, unlike the existing selective forgetting methods, does not optimize network parametersnor utilize the gradients of the parameters; we instead optimize the input textual prompt to decrease theclassification accuracy of specified classes to be forgotten in a derivative-free optimization framework.One disadvantage of derivative-free optimization would be that it is not effective nor efficient forhigh-dimensional problems due to the low convergence rate in high-dimensional spaces [Qian et al.,2016], and unfortunately, the textual prompt is typically parameterized as a set of high-dimensionalvectors in PTMs, e.g., 512-D for each context (i.e., learnable token in the prompt) in CLIP ViT-B/16 [Dosovitskiy et al., 2021]. To mitigate this issue, we propose Latent Context Sharing (LCS),a novel parametrization method of the contexts. The core of LCS is to parameterize each contextwith low-dimensional latent components, which consist of token-specific components and commoncomponents among multiple tokens for the prompt. Experimental results on four standard benchmark",
  "Related Work": "Machine UnlearningMachine unlearning aims to remove an arbitrary sample from a pre-trainedmodel, i.e., obtaining a model that is identical to the one trained from scratch without that sample [Caoand Yang, 2015, Golatkar et al., 2021, Sekhari et al., 2021, Bourtoule et al., 2021, Kurmanji et al., 2023,Guo et al., 2020, Chen et al., 2019]. Many methods have been proposed, for example, to construct aforgettable model by transforming the learning algorithm into a sum of the training samples [Caoand Yang, 2015], to achieve forgetting by linear approximation of a nonlinear model [Golatkar et al.,2021], and to update the model to be closer to / farther from the original model in the retain / forgetsamples [Kurmanji et al., 2023]. Methods specific to certain learning algorithms such as LDA [Guoet al., 2020] and SVM [Chen et al., 2019] have also been explored. Machine unlearning and Black-Box Forgetting are closely related but different; Machine unlearning aims to remove the influence ofspecified training samples on the training model, whereas Black-Box Forgetting aims to prevent therecognition of specified classes. Forgetting specified classes has attracted much attention recently invarious contexts [Heng and Soh, 2023, Lu et al., 2024, Zhang et al., 2024, Shibata et al., 2021, Yeet al., 2022]. We in this paper address the black-box setting, which has not yet been explored. Selective Forgetting.Shibata et al. proposed Learning with Selective Forgetting (LSF),which updates the model for a new task by forgetting only certain classes from the previous taskwhile memorizing the rest of the classes. Golatkar et al. [2020a] introduced a scrubbing method thatinvolves a shift in weight space and addition of noise to the weights to remove information fromnetwork weights. They also proposed a forgetting mechanism to linearly approximate the weightsthat would have been obtained by unlearning [Golatkar et al., 2020b, 2021]. Tarun et al. proposed an error-maximization-based method to learn a noise matrix for the class to forget, and themodel is updated by training on this noise. Then, fine-tuning on the classes to be memorized to adjustthe model weights. Since these methods require the model weights or the gradient of the model parameters, they cannotbe applied to black-box models. In this paper, we introduce a new selective forgetting method forblack-box models that does not require the model weights or the gradient of the model parameters. Black-Box Learning.Black-Box Tuning (BBT) [Sun et al., 2022b] is a black-box prompt tuningmethod for large language models. BBTv2 [Sun et al., 2022a] improves BBT with deep prompttuning. They achieve accuracy comparable to white-box learning methods in various natural languagetasks. BDPL [Diao et al., 2023] fine-tunes a collection of discrete prompts for language models bytreating the word choice in the prompt as a reinforcement learning policy. BlackVIP [Oh et al., 2023], the first black-box learning method for vision-language models, optimizesa generative model that generates visual prompts embedded in images by zeroth-order optimization.LFA [Ouali et al., 2023] extends the capabilities of black-box models by assuming access to pre-computed features from pre-trained backbones. Through a multi-stage procedure, it optimizes aprojection layer to enhance alignment between pre-computed image features and class prototypes.Guo et al. introduced a collaborative black-box tuning (CBBT) for optimizing both the textualprompt and adapting output visual features in black-box vision-language models. The textual promptis optimized by estimated gradients and the visual adapter is trained through direct supervised learningfrom the output features.",
  "(c) LCS": ": Comparison of context parametrization.(a)Vanilla prompt tuning optimizes the textual promptdirectly. This approach requires high-dimensionaloptimization. (b) BBT [Sun et al., 2022b] optimizesa lower-dimensional latent context instead of directlyoptimizing textual prompt to mitigate high dimen-sionality. (c) In our LCS, for more effective opti-mization, a latent context is composed of uniquecomponents and common components among multi-ple latent contexts, and each component is optimizedindependently. The overview of the proposed method isillustrated in . We use the vision-language model CLIP [Radford et al.,2021] as the base model and optimize aninput prompt for the CLIP text encoderbased on the loss that requests reduced ac-curacy of selected classes. The derivative-free optimization method must be used tooptimize a textual prompt for the black-box model where the gradients of its pa-rameters are unavailable.We employCMA-ES, a widely used evolutionary al-gorithm for black-box optimization in con-tinuous, because a textual prompt to be op-timized is a continuous variable. CMA-ESis a multi-point search algorithm based ona multivariate normal distribution and pro-ceeds the search by iterating (i) samplingcandidate solutions, (ii) evaluating the lossvalues of the candidates, (iii) weightingthe candidates based on the loss values,and (iv) updating the mean and covari-ance matrix of the distribution by usingthe weighted candidates. Due to the natureof multi-point search, the performance ofCMA-ES degrades in high-dimensionalproblems, typically ten or more dimen-sions [Ros and Hansen, 2008, Akimotoand Hansen, 2016].While several ex-tensions have been proposed, e.g., [Rosand Hansen, 2008, Akimoto and Hansen,2016], these methods require knowledgeof independence among variables, whichis not always known. In this paper, wepropose a customized extension of CMA-ES to Black-Box Forgetting. In general,when applied to high-dimensional black-box continuous optimization by CMA-ES,the computational complexity can becomea hindrance. The key is reducing the di-mensions of the latent variables in the tex-tual prompt while preserving their contextrepresentations.",
  "Context Parametrization": "We discuss two types of context parametrizations: i) Latent Representation with Random Projectionfor Black-Box Tuning (BBT) [Sun et al., 2022b] as preliminary; ii) Latent Context Sharing (LCS) forour method, a more effective context parametrization approach for the black-box forgetting. i) Preliminary: Latent Representation with Random Projection.The dimension D of a contextin the prompt is extremely large, which makes derivative-free optimization difficult. To mitigate thishigh dimensionality, BBT introduces a low-dimensional latent context [zall] Rdm, where d is the dimension of a latent context and m is the number of latent contexts. Then, BBT divides [zall] into[zi] Rd and generates contexts for the prompt by projecting them to the original context dimensionby a random projection A RDd (see b) sampled from a normal distribution N(0, ), where is the standard deviation of the context (token) embeddings. The dimension of variables to beoptimized is suppressed more than optimizing a context directly because d is a lower dimension thanthe original context dimension (d D). ii) Latent Context Sharing.As empirically shown later in Sec. 4.2, the effectiveness of the contextparametrization for BBT described above is limited for selective forgetting settings. We proposelatent context sharing (LCS), a more efficient context parametrization. c shows the overview of LCS. The key idea is to assume shared parameters among differentlatent contexts. This inspiration comes from successful word embedding methods; most wordembedding methods are trained on the assumption that locally co-occurring words have semanticcorrelations between them (e.g., [Milkolov et al., 2013, Pennington et al., 2014, Devlin et al., 2019]).This inspires the idea of explicitly modeling semantic correlations between words in a prompt asshared components. We assume that each latent context is composed of unique components (UniqueLatent Contexts (ULC)) and common components (Shared Latent Context (SLC)) among multiplelatent contexts 2. Then, we optimize each ULC and SLC independently. Each latent context [zi] isobtained by concatenating SLC [zs] Rds and ULC [zu]i Rdu(i = 1, , m), where m is thenumber of latent contexts, ds and du are the dimension of SLC and ULC, respectively. Despite thenumber of parameters prepared for BBT and LCS is the same (m d = ds + m du), LCS ispossible to significantly reduce the number of optimization dimensions compared to BBT3, becauseLCS optimizes each ULC and SLC independently. Compared to assuming that each latent context iscompletely independent (i.e., using only ULC), providing common components has the substantialadvantage of not losing dependencies among multiple tokens for the prompt. Note that, CoCoOp [Zhou et al., 2022a] also introduces an approach that incorporates a sharedcomponent in the context of the prompt to improve the generalization in the white-box setting. WhileCoCoOp learns the network that generates a shared component based on image features, our methoddirectly learns the shared component. The optimization for our black-box forgetting using our methodbecomes simpler because the number of dimensions for optimization is minimal. As shown in theexperimental results in Sec. 4, introducing a shared component is effective, which suggests thatoptimization of shared components has a impact in our problem settings.",
  "i=0ti log pi,(1)": "where C is the total number of classes, p is confidence of each class obtained by applying the Softmaxfunction to the similarity of each class, which is the output of CLIP, and t is the one-hot vector of thelabel of an input image. A naive approach to ensuring that selected target classes are forgotten is to reduce the confidenceof that class in the input images of the class. In general, however, this naive approach leads toundesirable behavior in the model. For example, if we force the model to forget the class dog,it may lead to the model always classifying images of dog as the class with features similar todog, e.g., cat. Moreover, such an unintentional bias may provide sufficient clues to identify theforgotten classes, and consequently may lead to the risk of information leakage. We, therefore, wantto make the classification results for images with the forgotten classes close to random and excludeinformation about the classes. To this end, we maximize the entropy of confidence for each image of",
  "Derivative-Free Optimization: CMA-ES": "Since backpropagation cannot be applied to black-box models, we adopt the CMA-ES (CovarianceMatrix Adaptation Evolution Strategy) [Hansen et al., 2003], which is a derivative-free optimizer forcontinuous optimization. In the t-th iteration, the CMA-ES samples the candidate solutions from amultivariate normal distribution N(mt, 2t Ct), where mt Rd is the mean vector of the searchdistribution, t R+ is the step-size, Ct Rdd is a covariance matrix. The solutions should beevaluated on an objective function f, then the CMA-ES updates the parameters Ct, mt and t byranking the solutions by function value (cf. [Hansen, 2016]).",
  "Setup": "Datasets.We use four benchmark datasets, i.e., CIFAR-10, CIFAR-100, CUB-200-2011, andImageNet30. CIFAR-104 and CIFAR-1005 comprise of a total of 50,000 training images and 10,000test images [Krizhevsky et al., 2009]. These datasets have 10 and 100 classes, respectively. CUB-200-2011 [Wah et al., 2011] comprises of images of 200 distinct bird species, with 5,994 trainingimages and 5,794 test images. ImageNet30 [Hendrycks et al., 2019] is a 30-class subset of the originalImageNet-1k dataset [Deng et al., 2009] (The results on the original ImageNet-1k dataset can also befound in Appendix A.2). It consists of 39,000 training images and 3,000 test images. We conductexperiments in the few-shot condition. We randomly select different k samples of each class fromthe original training images to construct a k-shot training set and a k-shot validation set. We set k to16 for CIFAR-10 and ImageNet30, 4 for CIFAR-100, 1 for CUB-200-2011. For testing, we use theoriginal test set. Unless otherwise noted, the first 40% of classes are to be forgotten, while the otherclasses are to be memorized. Baselines.Black-Box Forgetting has never been studied before, and there is no existing methoddirectly applicable to this problem. So we compare the proposed method with zero-shot CLIP [Rad-ford et al., 2021], BBT [Sun et al., 2022b] and CBBT [Guo et al., 2023], which are the reasonablebaselines as it is for black-box prompt tuning. We apply the same loss functions as our method toBBT and CBBT (w/o adapter) for comparison. CBBT introduces a method that combines textualprompt tuning and adapting output visual features for black-box vision-language models. However, inthis paper, the conditions are such that visual features cannot be obtained, and only the final inferenceresults can be used. So we compared the proposed method with CBBT without using any adapter. Wealso apply the same loss functions as our method to CoOp [Zhou et al., 2022b], a white-box method,and use the results as reference values under conditions where information on the target model isavailable. Implementation Details.We use ViT-B/16 [Dosovitskiy et al., 2021] as our CLIP image encoder.We set the number of latent contexts m = 4 for CIFAR-10, and m = 16 for CIFAR-100, CUB-200-2011 and ImageNet30, respectively. The dimension of a latent context in BBT d, Shared Latent",
  ",5~kriz/cifar.html": ": Comparisons with the baselines. The best value is shown in bold. BBT [Sun et al., 2022b] and CBBT(w/o adapter) [Guo et al., 2023] are the reasonable baselines as these are for black-box prompt tuning.CoOp [Zhou et al., 2022b] is a white-box method and is included for a reference. Performance isevaluated using the three metrics: the error Errfor for the classes to be forgotten, the accuracy Accmemfor the classes to be memorized, the harmonic mean H of Errfor and Accmem. Higher values meanbetter performance.",
  "CoOp (White-Box)63.200.02 98.090.02 46.620.0299.300.01 99.720.00 98.890.01": "Context (SLC) ds, and Unique Latent Contexts (ULC) du are set to d = 10, ds = 20, du = 5 forCIFAR-10, and d = 125, ds = 400, du = 100 for CIFAR-100, CUB-200-2011 and ImageNet30,respectively. For optimization, CMA-ES with the population size of 20 is applied in all the conditions,as done in [Sun et al., 2022b]. We optimize the latent contexts for 400 iterations for CIFAR-10 andImageNet30, and 800 iterations for CIFAR-100 and CUB-200-2011. All the hyperparameters aretuned on the validation sets, which are distinct from the training and test sets. Evaluation Metrics.We use the following three evaluation metrics: (i) Errfor is the error for theclasses to be forgotten; (ii) Accmem is the accuracy of the classes to be memorized; (iii) H is theharmonic mean of Errfor and Accmem as in [Shibata et al., 2021]. H gives the overall selectiveforgetting performance as it is a balance between the forgetting rate for the classes to be forgottenand the classification accuracy for the classes to be memorized. Higher values for all these metricsare desirable. For all the experimental results, including those in the Appendix sections, we reportthe average performance of the three runs with different random seeds, as well as their standarddeviations.",
  "shows the main comparative results with the baseline methods. Our method improveszero-shot CLIP and outperforms all the baselines on all the datasets": "Comparing our method with BBT, these two are comparable in Accmem. However, ours is significantlybetter than BBT in Errfor and consequently clearly outperforms BBT in H as well for all the datasets;in particular, ours is better than BBT by 9.38% on CIFAR-10. These results suggest that our LCScan optimize the learnable latent contexts more effectively in the black-box setting than BBT, whichoptimizes all the latent contexts independently. When comparing our method with CBBT, which is the state-of-the-art black-box tuning method, wecan see that ours outperforms CBBT on all the datasets. While ours is slightly inferior in Accmem,it is significantly better in Errfor on all the datasets. These results demonstrate that our methodachieves higher selective forgetting performance than CBBT and is a more suitable for the black-boxforgetting task. To clarify the impact of our context parametrization method, LCS, we also evaluate the performanceof Ours (w/o LCS), i.e., the case without LCS where each latent context is optimized independently.Although these two are highly comparable in Accmem, Ours (with LCS) clearly outperforms Ours(w/o LCS) by large margins and consequently shows distinct superiority in H as well. These results m 0.65 0.70 0.75 0.80 0.85 0.90 0.95 1.00 H OursBBT m 0.5 0.6 0.7 0.8 0.9 1.0",
  "Accmem": "OursBBT : Sensitivity to the number of latent contexts. Results of BBT [Sun et al., 2022b] and Ours forvarying number of the latent contexts. We can see that our method shows stable performance within awide range of the number of latent contexts in contrast BBT. 36:128:320:512:74:90:10 d s : d u 0.70 0.75 0.80 0.85 0.90 0.95 1.00 H OursBBT 36:128:320:512:74:90:10 d s : d u 0.5 0.6 0.7 0.8 0.9 1.0",
  "(c) CUB-200-2011": ": Sensitivity to the dimensionality of SLC and ULC. Results of BBT [Sun et al., 2022b] and Ours forvarying number of dimensions of SLC ds and ULC du. We can see the effectiveness of our method inthe wide range of ds : du. prove that adequate selective forgetting performance cannot be achieved without LCS. Interestingly,these evaluations clearly suggest that each latent context is not inherently independent and that theidea of LCS to model dependencies among latent contexts by introducing a common latent componentis valid. Finally, we compare our method with the white-box method based on CoOp [Zhou et al., 2022b],where the latent contexts are optimized by minimizing the same loss functions as ours through thestandard backpropagation process. Although CoOp is better able to increase Errfor than Ours, thedifferences are within the acceptable ranges. For example, the difference in Errfor is less than 1%and that in H is less than 2% on CIFAR-10. These results show that even though our method isblack-box, it can perform as well as white-box approaches.",
  "Sensitivity to The Number of Latent Contexts": "We investigate the sensitivity of the performance of our method to the number of latent contexts m. shows Errfor, Accmem and H when the number of latent contexts m is varied on CIFAR-10.As the number of latent contexts m increases, the performance in all the metrics tends to improve.This is natural behavior, as the performance improves as the number of trainable parameters increases.Comparing Ours and BBT, we see that Ours for m = 4 and BBT for m = 16 are almost comparable.This means that BBT needs to optimize about four times the number of dimensions to compete withour LCS, indicating that our LCS provides excellent trade-offs. Furthermore, while BBT suffers asharp drop in accuracy with decreasing m, our method shows only a small decrease from m = 16even when m = 1. This suggests that our LCS is robust to the decrease in the number of latentcontexts and its significant superiority to BBT for latent context representation.",
  "Sensitivity to The Dimensionality of SLC and ULC": "We investigate the sensitivity of our method to ds and du, which are the number of dimensionsof SLC and ULC, respectively. In our LCS, the total number of dimensions d to be optimized isdetermined as d = ds + m du (see Sec. 3.1); we evaluate the performance when we change theratio ds : du under the condition where d = 40 and m = 4 for CIFAR-10, and d = 2000 and m = 16for CIFAR-100 and CUB-200-2011. shows the results on the three datasets. First, we cansee that for all the datasets, the performance in Errfor and H significantly degrades for ds = 0 (i.e.,when no SLC is used) than for the other cases, which supports the validity of the core idea of ourLCS that introduces the shared components. As expected, the performance is substantially improvedby setting the appropriate ratio. This is a natural trade-off: if ds (i.e., the number of dimensionsof SLC) is too large, the ability to represent the context is reduced and performance deteriorates;conversely, if du (i.e., the number of dimensions of ULC) is too large, optimization becomes difficultand performance deteriorates. Meanwhile, our method achieves satisfactory performance in the widerange of ds : du. Second, when we compare Ours with BBT, Ours is superior to BBT in the widerange of ds : du. These results justify the strong robustness of our method to ds and du.",
  "Ours vs. BBT with Modified CMA-ES": "CMA-ES [Hansen et al., 2003] is widely used in black-box optimization, but when applied tohigh-dimensional black-box continuous optimization, the computational complexity can becomea hindrance. To apply CMA-ES to high-dimensional optimization, modified versions such as Sep-CMA-ES (Sep) [Ros and Hansen, 2008] and VkD-CMA-ES (VkD) [Akimoto and Hansen, 2016]have been developed. Sep-CMA-ES realizes the computational complexity O(d) that is linear withrespect to the number of dimensions by restricting the covariance matrix to a diagonal matrix. Inother words, the solution generation distribution of Sep-CMA-ES does not consider the covariancebetween variables, but only the variance of each variable. In VkD-CMA-ES, the covariance matrix isexpressed as C = D(Id + VVT )D, where D is a diagonal matrix, V is a d k-dimensional realmatrix in which each column is orthogonal, and k is a hyperparameter that determines the degree offreedom of the covariance matrix model. Given the availability of these modified CMA-ESs, onequestion would be that, can our method still perform better than BBT, even when it is combined 0.10.20.30.40.50.60.70.80.9 rfor 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 H 0.10.20.30.40.50.60.70.80.9 rfor 0.0 0.2 0.4 0.6 0.8 1.0",
  "Errfor": "Zero-Shot CLIPBBTCBBTOurs (w/o LCS)OursCoOp (white-box) : Sensitivity to the ratio of the classes to be forgotten. Results on CIFAR-10 when changing the ratioof the classes to be forgotten. Our method is robust to the ratio of the classes to be forgotten comparedto baselines. with these modified CMA-ESs? shows the comparisons between Ours and BBTs with theabove two variants of CMA-ES. Ours achieves the best performance in terms of H and Errfor forall the datasets. In particular, the two BBT variants show Errfor more than 10% lower than ourmethod on CIFAR-100 and ImageNet30. These results show that our LCS surpasses Sep-CMA-ESand VkD-CMA-ES as a context parametrization method in the black-box forgetting task.",
  "Sensitivity to The Ratio of The Classes To Be Forgotten": "shows Errfor and H when changing the ratio of the classes to be forgotten rfor on CIFAR-10.For BBT, we see a decreasing trend in Errfor as the number of classes to be forgotten increases. Thissuggests that the context representation of BBT is inefficient, making it difficult to forget multipleclasses at a time. CBBT shows some robustness, but as with BBT, we see that Errfor tends todecrease as the number of classes to be forgotten increases. In contrast, our method does not decreaseErrfor even if the number of classes to be forgotten increases, which confirms the strong performanceof our LCS. In terms of H, compared to the baselines, our method shows high robustness independentof the number of classes to be forgotten and achieves high selective forgetting performance.",
  "Limitations": "Our method optimizes the context (token) embeddings of the model through a derivative-free opti-mization, CMA-ES. That is, we assume that we have access to the context embeddings of the targetmodel. This is a common black-box setting, as similar assumptions have also been made in most ofthe existing studies [Sun et al., 2022b,a, Guo et al., 2023]. However, there should be models in thereal world with a higher level of \"black boxness,\" i.e., models in which even access to contextualembeddedness is prohibited. Addressing such a case is a subject for future research.",
  "Conclusion": "We proposed Black-Box Forgetting, a novel problem of selective forgetting for black-box models.We introduced Latent Context Sharing (LCS), an efficient and effective parametrization method ofprompt, which is suitable for derivative-free optimization. Experimental results demonstrated thatour method outperforms the reasonable baselines with significant margins. In addition, the sensitivityanalyses showed the effectiveness of our LCS.",
  "Alvin Heng and Harold Soh. Selective amnesia: A continual learning approach to forgetting in deepgenerative models. In Proc. NeurIPS, 2023": "Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, Hieu Pham, Quoc Le, Yun-Hsuan Sung,Zhen Li, and Tom Duerig. Scaling up visual and vision-language representation learning withnoisy text supervision. In Proc. ICML, pages 49044916, 2021. James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins, Andrei ARusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al. Overcomingcatastrophic forgetting in neural networks. PNAS, 114(13):35213526, 2017.",
  "A.1Broader Impacts": "In this paper, we introduced the novel problem called Black-Box Forgetting, i.e., the task of selectiveforgetting for large-scale and black-box pre-trained models, and demonstrated the potential effective-ness of parametrizing the latent contexts in the text prompts into unique and shared components. Wehere would like to emphasize several potential benefits of our work. 1. Toward addressing the Right to be Forgotten: It should comply with the request that if aservice provider is asked to remove information so that their model cannot recognize certaininformation. This can be accomplished by training the model from scratch by removingsamples of that class from the training data. However, retraining a large-scale modelconsumes an enormous amount of energy, which should be avoided. Selective forgettingmay provide an efficient solution to this problem. 2. Toward efficient large-scale pre-trained models: Improving the efficiency of large-scale pre-trained models is of current interest to many researchers. Various attempts have been madesuch as model compression and architecture optimization (e.g., Meanwhile, as the scaling law indicates, the reasonablesize of a model correlates with the amount of knowledge it memorizes. Therefore, if thenumber of classes (amount of knowledge) that can be recognized by the model is limited,the model can be scaled down accordingly, thereby improving the efficiency of the model.This contributes to expanding the applicability of large-scale pre-trained models. 3. Toward better control over text-to-image generation: While diffusion-based text-to-imagegeneration can generate diverse types of high-quality images, controlling the content ofimages remains a challenge. Recent research has focused on forgetting visual concepts inorder to avoid generating undesirable content [Graves et al., 2021, Lu et al., 2024, Zhanget al., 2024]. These methods forget certain classes by directly fine-tuning the diffusionmodel, but tuning the diffusion model itself is often costly. In contrast, given that typicalgenerative models use a text encoder of a pre-trained VLM (e.g., CLIP) for conditioning,our method may provide an efficient approach to class forgetting by fine-tuning only theprompts of the text encoder.",
  "A.2Comparative Results on ImageNet-1k": "We conduct experiments on ImageNet-1k [Deng et al., 2009] to verify the effectiveness of our methodon a larger-scale dataset. The setup is the same as the cases for CIFAR-100 and CUB-200-2011 (seeSec. 4.1). The results are shown in . Our method outperforms all the baselines in terms of Hand Errfor, which supports the effectiveness of our method further.",
  "A.3Trade-off between Errfor and Accmem": "Tables 1 and 3 shows that our method performs poorly in Accmem than the baseline methods. Thisis because Errfor and Accmem are in a trade-off relationship, with Accmem tending to decreaseas Errfor is increased. This is presumably because features between classes are not completely disentangled in the feature space, so forgetting one class may negatively affect other classes (just asdog and cat share some common features). To provide justification for this, we report the results ofusing a loss more prioritized (weighted) for Accmem in our method in as Ours (Acc prio.).We can see that Ours (Acc prio.) outperforms all the other methods in Accmem, with sacrificingErrfor. Notably, both Ours and Ours (Acc prio.) outperform BBT and CBBT in H, indicating thatour method achieves a better trade-off than BBT and CBBT.",
  "CoOp63.200.0298.090.0246.620.02": "Furthermore, the results on CUB-200-2011 in show that the white-box method CoOp [Zhouet al., 2022b] only improves Accmem by 0.2% from zero-shot and our method even hurts Accmem.Our problem is to achieve forgetting only specified classes while maintaining the accuracy of theother classes to be memorized, i.e., to improve Errfor while maintaining Accmem. Achieving both ofthese is more challenging than merely improving Accmem alone. To verify our argument here, wereport an analysis in . CoOp (White-Box w/ only memorization) shows the results whenwhite-box tuning by CoOp is performed to minimize the cross-entropy loss over only the classes tobe memorized, i.e., forgetting is not performed. We can see a significant improvement in Accmem.This result proves that, even in a white-box setting, achieving both improving Accmem and Errfor ismore difficult than merely improving Accmem alone. Since the black-box setting is generally morechallenging than the white-box setting, it is not at all surprising that our method leads to a slightdegradation in Accmem.",
  "A.4On Zero-shot Approach to Forgetting": "In this paper, we consider a few-shot learning scenario, i.e., we can access a small number of trainingexamples for tuning the latent contexts. However, in some practical cases, one might be faced with azero-shot scenario, i.e., a situation where no sample is available. We here consider a simple zero-shottuning approach to the black-box forgetting task by only using the class names (i.e., class embeddings).Specifically, let zc and z denote the class embeddings before and after prompt tuning for the classto be forgotten, respectively. We assume only z is trainable and aim to tune z by minimizing thefollowing negative NT-Xent loss:",
  "i exp(zi z/),(3)": "where zi is the class embedding for the i-th class to be kept memorized. This loss requires z to beorthogonal to zc as well as be similar to the embeddings of the other classes {zi}. By minimizing theloss, we can expect that the embedding of the class to be forgotten zc is placed equidistant from theembeddings of all the other classes {zi}. The results are shown in . We found that the zero-shot approach (C-Emb.) performssignificantly poorly compared to our few-shot learning approach. A closer look at each evaluationmetric shows a slight advantage of C-Emb. over Ours in Errfor, but C-Emb. is far lower than Ours inAccmem. This is probably due to the nature of the negative NT-Xent loss, whereby the embedding of the class to be forgotten is closer to the embeddings of the other classes to be memorized, resultingin more misclassifications. These results prove that tuning with only the class embeddings does notprovide satisfactory performance.",
  "C-Emb.51.830.0599.790.0035.130.0467.470.1890.720.1358.040.22Ours59.670.0189.290.0144.810.0197.280.0195.940.0198.670.01": "The above results give us further inspiration; If training samples are available for some classes andnot for the rest, would there be a benefit from combining the two approaches? We experimentedunder conditions in which half of the classes to be forgotten had training samples available and therest did not. We use Ours for the classes for which the training samples are available and C-Emb.for the classes with no training samples. The result on ImageNet30 are shown in . WhileOurs performed forgetting for only the classes with the training samples based on the loss given inSec. 3.2, Ours + C-Emb. performed forgetting for all the classes by incorporating Eq. 3. We seethat Ours + C-Emb. could outperform Ours in all the metrics, which proves the effectiveness of thecombination.",
  "A.5Forgetting vs. Learning from Scratch": "An obvious alternative to forgetting that produces a model that can recognize only the classes tobe memorized while preventing the recognition of only the classes to be forgotten is to learn themodel from scratch for only the classes to be memorized. To clarify the benefit of forgetting, weevaluate the accuracy of ResNet-18 and ViT-B/16 trained from scratch over only the classes to bememorized. The results are shown in . As can be seen, both models cause severe overfitting tothe training data. That is, while these models achieve reasonable accuracy on the training data, theyexhibit severely poor performance on the test data. We also tested both models when initialized withImageNet pre-trained weights. While the results are improved to some extent for ResNet-18, theseare still far behind our forgetting method. The reason for this is that, following the common protocolin context optimization [Zhou et al., 2022b], we conducted our experiments in few-shot scenariosas explained in Sec. 4.1, which overwhelmingly lacks the number of training samples to learn theweights for even ResNet-18 and Vit-B/16. These results demonstrate the superiority of our forgettingapproach, which achieves effective tuning with a small sample size.",
  "A.6Forgetting vs. Fine-tuning over The Classes To Be Memorized": "Another alternative approach to forgetting would be to only fine-tuning the model over the classes tobe memorized. That is, do nothing to the classes to be forgotten and cause catastrophic forgetting.We test the performance of fine-tuned CLIP over only the classes to be memorized (Fine-tune CLIP).The results are shown in . Compared to our method, which explicitly facilitates forgettingof the classes to be forgotten, catastrophic forgetting alone (Fine-tune CLIP) is not sufficient toachieve satisfactory forgetting performance. Also, our method is comparable to the Fine-tune CLIPin Accmem except for CUB-200-2011, which does not significantly impair the classification accuracyfor the classes to be memorized. These results support the validity of our forgetting approach.",
  "A.7CoOp with Model Parameter Update": "We evaluate another white-box forgetting approach that learns latent contexts through CoOp whilealso updating the model parameters. The results are shown in . We see that simultaneouslyupdating the model parameters does not improve performance, but rather hurts it. This is notsurprising, as it is known that straightforward fine-tuning of the zero-shot CLIP does not improveperformance [Wortsman et al., 2022].",
  "A.8Impact of Sampling Distribution for Random Projection": "As explained in Sec 3.1, each of the (du +ds)-dimensional latent context is projected into the originalD-dimensional context by a random projection A RD(du+ds) sampled from a normal distributionN(0, ), where is the standard deviation of the context embeddings. We analyze the impact of thechoice of on the final performance. shows the results on CIFAR-10 when is fixed to",
  "A.9Performance for Different Choices of The Classes To Be Forgotten": "In the experiments in the main paper (Sec. 4), 40% of the classes in each dataset were selected asthe classes to be forgotten, in ascending order of the class index, starting with the 0-th class. Wehere investigate the performance of our method when using different selections of the classes tobe forgotten. The results are in . We see that our method achieves satisfactory selectiveforgetting performance regardless of the choice of the classes to be forgotten.",
  "Class indices to be forgottenHErrforAccmem": "{1}94.250.0198.330.0290.490.01{2}92.160.0493.100.0791.240.01{0, 8}94.010.0097.670.0190.610.00{2, 5}94.480.0196.450.0392.580.00{2, 3, 4}94.410.0195.900.0192.970.00{4, 5, 6}95.530.0196.890.0294.210.01{1, 2, 3, 4}93.270.0492.740.0993.790.02{4, 5, 6, 7}96.450.0199.520.0093.570.01{3, 4, 5, 6, 7}95.430.0298.330.0092.690.03{4, 5, 6, 7, 8}96.170.0197.420.0294.950.01{3, 4, 5, 6, 7, 8}95.150.0196.970.0393.400.02{4, 5, 6, 7, 8, 9}95.570.0295.220.0395.920.01{1, 2, 3, 4, 5, 6, 7}94.040.0292.400.0595.740.01{2, 3, 4, 5, 6, 7, 8}97.160.0098.780.0195.600.00{1, 2, 3, 4, 5, 6, 7, 8}97.500.0097.690.0297.320.02{2, 3, 4, 5, 6, 7, 8, 9}97.940.0197.760.0198.120.02{1, 2, 3, 4, 5, 6, 7, 8, 9}99.510.0099.090.0199.930.00{0, 2, 3, 4, 5, 6, 7, 8, 9}98.830.0298.550.0299.100.01"
}