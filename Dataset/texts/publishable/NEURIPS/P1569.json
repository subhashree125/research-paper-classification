{
  "Abstract": "Prediction is a fundamental capability of all living organisms, and has been pro-posed as an objective for learning sensory representations. Recent work demon-strates that in primate visual systems, prediction is facilitated by neural represen-tations that follow straighter temporal trajectories than their initial photoreceptorencoding, which allows for prediction by linear extrapolation. Inspired by theseexperimental findings, we develop a self-supervised learning (SSL) objective thatexplicitly quantifies and promotes straightening. We demonstrate the power ofthis objective in training deep feedforward neural networks on smoothly-renderedsynthetic image sequences that mimic commonly-occurring properties of naturalvideos. The learned model contains neural embeddings that are predictive, butalso factorize the geometric, photometric, and semantic attributes of objects. Therepresentations also prove more robust to noise and adversarial attacks comparedto previous SSL methods that optimize for invariance to random augmentations.Moreover, these beneficial properties can be transferred to other training proceduresby using the straightening objective as a regularizer, suggesting a broader utilityfor straightening as a principle for robust unsupervised learning.",
  "Introduction": "All organisms make predictions, and their survival generally depends on the accuracy of thesepredictions. In simple organisms, these predictions are reflexive and operate over short time scales(e.g., moving toward or away from light, heat, or food sources). In more complex organisms,they involve internal state (memories, plans, emotions) and operate over much longer timescales.Prediction has the potential to provide an organizing principle for overall brain function, and asource of inspiration for learning representations in artificial systems. However, natural visual scenesevolve according to highly nonlinear dynamics that make prediction difficult. Recent experiments both perceptual (in humans) and neurophysiological (in macaques) indicate that the visual systemtransforms these complex pixel dynamics into straighter temporal trajectories . As analternative to full temporal prediction, straight representations facilitate predictability through linearextrapolations (A, red arrows). Yet, the utility of straightening as a learning principle fororganizing representations remains underexplored.",
  "B": ": Augmentation of other SSL objectives with a straightening regularizer. A. Straightnessof representations learned by four different SSL objectives (gray), and their augmentation with astraightening regularizer (blue). B. CIFAR-10 classification accuracy as a function of adversarialattack budget, for the original and straightening-regularized version, for the same four SSL objectives. hand gesture recognition. For simplicity, we used the depth channel as input, which circumvents theneed for modeling the background. To preserve the motion structure we did not apply any frameaugmentations. For this dataset, we found that the straightened representations were more robustthan invariance-based solutions across a wide range of corruptions. See Appendix for results andimplementation details. Straightening improves robustness in other SSL models.In principle, straightening can beincorporated into any SSL learning objectives as long as the inputs are a temporal sequence of at leastthree frames. Can straightening robustify representations when combined with other SSL losses?To answer this question, we regularized several existing SSL objectives using our straightening loss(1), trained the models on sequential CIFAR-10, and tested their recognition performance underadversarial attacks. In all cases, the straightening loss was added to the outputs of the projectoras well as the first ResNet block, with the weight chosen from a parameter sweep that optimizesrecognition performance. Other hyperparameters of the SSL models, including weights of other termsin the objective, and the architecture of the projector, were kept to their original values/setup. None of the original SSL models demonstrate straightening in their representations (A, gray),but a slight straightening regularization can significantly improve straightness beyond the pixel level(blue). B compares adversarial robustness under the original SSL loss and thecorresponding variant regularized by straightening. For all objectives tested, straightening was shownto systematically improve representational robustness, even though the original training was alreadyheavily tuned to optimize performance. We repeated the same robustness test on pixel-level whitenoise (see Appendix) and observed the same benefits of adding the straightening loss. This suggeststhat the idea of representational straightening and the use of temporally smooth image augmentationsmay prove of general practical utility for robust recognition, and makes straightening an importantnew tool in the SSL toolkit.",
  "Related work": "Temporal invariance.Many successful SSL methods aim to learn representations that are invariantto simple transformations, with additional regularization incorporated to prevent representationalcollapse (e.g., constant response independent of input). Depending on the exact implementationof these components, three categories of SSL objectives are identified in review : 1) contrastiveSSL , which encourages representation similarity between two augmented views of the sameimage (positive pairs) and dissimilarity of different images (negative pairs); 2) self-distillation , which uses two different encoders to process two views of the same image, and maps thetwo representations by a predictive projection; and 3) canonical correlation analysis that aims to whiten the cross-correlation matrix of neural representations estimated over augmentedpairs of the same image. Most of the invariance-based methods subserve tasks that operate onstatic images rather than spatio-temporal inputs. This is because invariance is a strict constraintand equating representations over time necessarily means losing the time-varying features in theinputs. For example, for a video that contains moving objects, learning invariant representations across frames may help to encode the identity of the object but not its location or relative size. Incontrast, straightening is designed to not only capture all predictable features in the spatio-temporalinputs, static and dynamic alike, but also predict their future states using a predefined operator. Temporal prediction.Temporal prediction as a fundamental goal for learning visual representationsdates back to . Many theories rooted in predictability have been successful in characterizingthe properties of early visual areas . Invariance is the simplest form of prediction. Linearpredictions have been extensively studied. Notably, achieved great success in unsupervisedobject recognition by learning a linear predictor that maps current states to future states for each stepinto the future. In , this paradigm was extended to allow a context-dependent, dynamic selectionof linear predictors. Straightening differs from these methods in that straightening is parameter-freeand the prediction can adapt to different contexts, while previous methods rely on parametrizationthat scales quadratically with the feature dimension. The work most similar to ours is , whichuses auxiliary architectural elements such as phase-pooling and further relies on an autoencoderstructure and a pixel-level prediction loss to prevent information collapse. Our solution uses a muchsimpler architecture, and we also provide a more extensive quantitative evaluation of the resultingstraightened representations. Straightening and robustness. Although straightening has been documented in human perceptionand macaque physiology, it is not an inherent property of deep neural networks , includingsupervised and self-supervised recognition networks, and video prediction networks . Somenon-parametric formulations of early visual processes demonstrate a degree of straightness, but theeffect does not seem to survive to downstream layers . Recently, demonstrated thatstraightening can be an emerging property of robustified networks: if networks are trained to tolerateGaussian noise or adversarial perturbations, they would generate straightened responses withoutbeing explicitly trained to do so. In this work, we provide the complementary observation: if networksare trained to straighten, the representation is robust to corruptions including Gaussian noise andadversarial perturbations. Apart from straightening, other learning objectives that exploit the temporal structures of natural videostatistics have also been shown to improve adversarial robustness, such as temporal classification(classifying frames to the episode they belong to) and temporal contrastive learning (temporallyadjacent frames are used as positive examples) in .",
  "Straightening videos": "Objective function.We aim to learn a representation of video frames that follows a straighttrajectory over time by transforming each frame, xt, into network response zt = f(xt), where fdenotes the learned transformation. We measure straightness of an output sequence {zt}Tt=1 as theaverage cosine similarity (normalized dot product) between the two successive difference vectors ofany three temporally adjacent points. Our goal is to train f to maximize straightness, or minimizethe loss:",
  ".(1)": "where the expectation is taken over sequences and time, t. This objective is scale-invariant, andbounded within . By default, the straightness loss is applied to the output layer, but it can beapplied to any (or several) layer(s) of a network.1 Once straightness is established, one-step predictiontakes the form of linear extrapolation: zt+2 = 2zt+1 zt. Straightness alone is not sufficient to learn meaningful representations because it can be minimizedby trivial solutions (zt = ct or zt = c for t). To avoid this form of collapse, we incorporate a formof regularization borrowed from , which essentially aims to statistically whiten the outputs usingtwo terms. First, a variance term for each output dimension, essentially preventing different inputsfrom collapsing to the same output, Lvariance = E1ddi=1 max0, 1 Szit, , where S(x, ) =",
  ",(3)": "where F denotes the Frobenius norm, t0 is randomly chosen from {1, 2, . . . , T} and independent oft. As in the straightening case, additional regularization is necessary to prevent collapse. For a faircomparison, we use the same variance and covariance terms as in the straightening model, and thusthe total loss is identical to that used in ,",
  "L = Linvariance + Lvariance + Lcovariance.(4)": "Creating synthetic video sequences from images.For training data, we generated artificial videosby applying temporally structured augmentations, intended to mimic natural transformations, tostatic images in common image datasets. The reasons for this choice, as opposed to using a datasetof natural videos, are multifaceted. First, we want to match other image-based SSL models interms of training data and evaluation pipeline for a direct comparison. Second, models trained onnatural videos are known to struggle with image recognition tasks because typical video datasetslack sufficient object class variety (for example, object-centric natural video datasets such asImageNet VID or Objectron contain only 30 and 9 object classes, respectively). Efforts arebeing made to align the data distribution of the two domains, but well-accepted benchmarks have notbeen established yet. Finally, while data augmentation is widely used for generating distinct views ofthe same image , it is uncommon to introduce temporal correlations in the applied transformations(since the goal is to maximize the richness of the training set). This however allows us to create imagesequences that have predictable temporal structure that the straightened representation can latch onto. To create temporally consistent geometric transformations, we can do either of the following: 1)construct a cropping window of a pre-determined size, then gradually move the window in onedirection (translation), akin to smooth gaze changes; 2) fix the center location of a cropping window,then monotonically increase or decrease its size (rescaling), akin to approaching or receding objects;3) fix the location and size of a cropping window, and rotate the window (rotation). We combinethese with appearance transformations, in which we linearly adjust the photometric parameters(brightness, contrast, saturation, and hue) across frames within a sequence. This mimics gradualchanges in lighting conditions over time. The rate of these geometric and photometric transformationsis held constant within each sequence, but varies across sequences. For the first set of experiments, we created a sequential MNIST dataset, in which images of singledigits are transformed according to one of the three geometric transformations (A). Each framecontains one digit, randomly selected from the MNIST dataset, moving inside a 64 64 patch. Eachvideo is 20 frames in duration. For translations, the digits were placed at random locations initially;for rescaling and rotation, the digits are always at the center of the patch. Transformations ramplinearly over time with two exceptions: for translations, digits bounce off of the edges, abruptlychanging direction, while for rescaling the direction of enlargement or contraction reverses if thesize exceeds a preset range. These special cases generate motion discontinuities, where prediction isexpected to fail. For a second set of experiments, we generated a sequential CIFAR-10 dataset, each with a duration ofthree frames (A). We eliminated the rotational transformation, as it tends to create boundaryartifacts on the nonzero background. Following standard practice in self-supervised learning ,we also included random horizontal flips, grayscale, and solarization to increase dataset diversity.Horizontal flips, if present, were applied to all frames in the sequence to preserve the frame-to-framespatial relationships, while the other transformations were applied independently to each frame.",
  "network stages": ": Straightening and its benefits, evaluated on a network trained on sequential MNIST.A. Three example sequences, illustrating the three geometric transformations. B. Emergence ofstraightness throughout layers of network computation. C. Accuracy in decoding various (untrained)variables from the network responses (top). Accuracy in predicting/decoding variables at the nexttime step (bottom). Identitity not considered for prediction as it is constant over the sequence.D. Prediction capabilities of the network. Top: example sequence, with dilating/contracting digit.Middle: reconstructions from simultaneous representation. Bottom: predictions (linear extrapolation)based on the representation at the previous two time steps. nonlinearities and no skip connections. For sequential CIFAR-10 we used ResNet-18 as themodel backbone and attached to the end a projector with 3 fully-connected layers, following thestandard practice in . Throughout the experiments we used the same model architecture for thestraightening objective (2) and the invariance objective (4); the hyperparameters were optimizedseparately for each loss so that both models achieve their best recognition performance.",
  "Straightening learns meaningful representations": "How straight can the representations become, and how is straightening achieved? To answer thisquestion, we trained f on sequential MNIST and measured the straightness of embeddings alongevery transformation of the network (B). Embeddings learned by the straightening objective (2)are progressively straighter throughout the network, with the largest increases occurring near the lastlayer (on which the loss function is imposed). In contrast, those learned by the invariance objective(4) initially increase in straightness but then fall, ending at a value slightly more curved than thepixel-domain input, consistent with observations in . All linear operations (convolutions, spatialblurring, and fully-connected linear projections) contribute to increasing straightness, whereas therectifying non-linearities usually reduce it. Geometrically, this is because the rectifiers project theembeddings onto the positive orthant, bending temporal trajectories that cross rectifier boundaries. To better understand the nature of the representations, we visualized the temporal trajectories of digitsequences using a 2D t-SNE embedding . B shows 200 trajectories from the translationsubset, in both the pixel domain (left) and the learned representation (right). Even in this non-linear,low-dimensional projection space, the individual representation trajectories are noticeably straighterthan their pixel-domain counterparts. Furthermore, the representations clearly separate the digitclasses, despite the fact that training was unsupervised, with no explicit knowledge of digit identity. Decoding untrained visual features.Ideally, straightened representations should encode allpredictable information in the input video and nothing more. Explicit predictions can be made in therepresentation space by linear extrapolations. The design of our dataset ensures that visual features such as location, size, and orientation of the digits are predictable, and therefore, should be preservedin straightened representations. On the contrary, representations learned by the invariance objectiveshould be agnostic to any temporally-varying information, including these features. To test thishypothesis, we trained a support vector machine (SVM) regressor with radial basis kernels (RBF)to read out those attributes from the learned representations. We also trained a linear classifier todecode digit identity. C shows that digit identity can be read out from both models, whileonly the straightened representations maintain the dynamic features of the inputs. Notice thatrespecting temporal order is critical for straightening to learn anything meaningful training the sameobjective on temporally shuffled frames gives poor decoding performance. This demonstrates anotherdistinction between straightening and invariance: the latter is, by definition, agnostic to temporalordering. To test predictability, we used the same decoder to read out location, size, and orientation in thenext frame from the linearly extrapolated (predicted) representations. We compared this predictionperformance against a naive control that simply uses representations of the last frame. The perfor-mance of the straightening predictor is found to be substantially better than the control, and closeto the decodability of the current frame. To further examine the image information contained in thestraightened representations, we froze the representations and trained a decoder network (another7-layer convolutional neural network) to reconstruct frames at the pixel level. We then used thesame decoder to visualize the predicted responses given by linear extrapolation. We found that thisenables accurate prediction of future frames (D, bottom; additional examples in Appendix),despite the fact that our learning objective did not explicitly optimize for such reconstruction error.Exceptions occur when transformations change direction: switching between expansion/contraction;or bouncing off of boundaries. In particular, the predicted 7 continued to expand when the actualinputs suddenly began to contract. This shows that the representation is able to capture smoothtransformations in the input, but not the macro-structure of the transformation statistics.",
  "The geometry of straight representations": "To understand how straightening enables class identification, we analyzed the representation geometryinduced by the straightening loss. The t-SNE embedding in B implies that the temporaltrajectories of images with the same digit and transformation type are more parallel than expected bychance. To verify this intuition, we computed the cosine similarity of velocity (difference) vectorsdrawn from trajectories of the same digit and the same transformation (A). This is comparedto the equivalent measure for the representation obtained via the invariance objective, and to thedistribution expected for random vectors in the output space (d = 128). For comparison, we also measured the cosine similarity of trajectories from different classes. Com-pared with the random distribution, and the values computed from the invariant representations, thestraightened representations showed a substantial bias toward parallelism for trajectories within thesame [digit, transformation] class, and toward orthogonality for trajectories across different classes.We hypothesize that trajectories from the same [digit, transformation] class are more likely to havesamples that are close to each other in the representation space; these proximal points may havesimilar local gradients since the model architecture is composed of locally affine operations. Whenthe straightening loss stretches the trajectories into straight lines, they end up being stretched intosimilar directions, resulting in a larger cosine similarity. On the other hand, the whitening regularizertries to fill the output space, causing trajectories from different classes to be pushed into orthogonaldirections in order to achieve a high variance in every output dimension. This leads to a cosinesimilarity for across-class vectors that is more concentrated at zero than expected by chance.",
  "cosine similarity": ": Geometric properties of the straightened repre-sentation. Panels A-E show histograms of cosine similarity(normalized dot product) between pairs of difference vectors,zt zt1. Insets show example trajectories in each scenario,where color indicates digit identity. A. same digit and trans-formation type; B. same digit and different transformation; C.different digit and same transformation; D. different digit andtransformation; E. all difference vectors vs. digit classifiervectors. F. Average effective dimensionality, measured withparticipation ratio, of the set of responses zt in each group. How can this geometry give rise toclass separation? Here we use digitidentity as an example. We hypoth-esized that since outputs from thesame class take up fewer dimensions,if classifiers (wi R10128, where10 is the number of possible classes)are chosen to be orthogonal to thatsubspace, then all the within-classvariations can be projected out. Thiswould make classification a mucheasier task. To test this hypothesis,we computed the cosine similarity ofthe classifiers decision axis and thetrajectory velocities (E). Com-pared with the distribution of randomvectors and the invariance case, thestraightened trajectories are more or-thogonal to the classifiers, confirm-ing our intuitions. Thus, informa-tion about other visual features is pre-served in the null space of the deci-sion axis for digit identity.",
  "Straightening increasesrecognition robustness": "While typical recognition models donot naturally yield straight represen-tations, explicitly training such mod-els for noise robustness can increasestraightness as a by-product .Here, we show that the converse isalso true: straightening makes recog-nition models more immune to noise.Unless specified otherwise, for theseexperiments we focused on the sequential CIFAR-10 data (A) and used ResNet-18 as thebackbone representation network. Following the standard practice in , we attached to the end ofthe backbone a projector with the training loss applied to its output. The outputs of the backbone weretaken as the primary representations and used for the downstream recognition task. Representationswere learned using the self-supervised learning objectives applied to clean image sequences. Afterlearning, we froze the network parameters then trained linear classifiers on the representational layerto determine the corresponding image class. Hyperparameters were chosen to yield the best cleanimage recognition performance, individually for each objective. We used an adapted version of thesolo-learn library to train all models in this section . As a variation of the original learning setup, we added a second straightening loss, Eq. (1), to theoutputs of the first ResNet block. The two straightening losses were equally weighted and averaged,while the whitening regularizer was only applied at the last layer. We empirically found that usingstraightening at multiple stages of the processing hierarchy can further improve robustness. B shows the straightness level of embeddings across every transformation of the network.Similar to the sequential MNIST case, straightness increased sharply near the layer where thestraightening loss was applied, and gradually elsewhere under convolution, spatial pooling, and fully-connected linear layers. In contrast, representations optimized for invariance were not straightenedacross processing stages. Examples of image sequences that produced the straightest trajectories(C, left) show clearly identifiable object contours and temporal transformations, while thosethat had the most curved trajectories (C, right) appear fuzzy with little identifiable structure andare inherently less predictable.",
  "straighteninginvariance": ": Effect of straightening on representational robustness. A. Two example synthetic sequencesfrom on sequential CIFAR-10 dataset. Top: translation and color shift. Bottom: rescaling (contraction)and color shift, last frame randomly grayscaled. B. Emergence of straightness throughout layers ofnetwork computation. Top arrows mark the stages of representation directly targeted for straightening(blue) and invariance (orange). C. Example sequences illustrating successes (left) and failures (right)of straightening. Numbers indicate straightness level . D. Noise robustness: classificationaccuracy as a function of the amplitude of additive Gaussian noise injected in the input. E. Adversarialrobustness: classification accuracy as a function of attack budget (see text). F. Relative classificationaccuracy of straightened network compared to invariance-trained network for various degradations.Color indicates the objective with better performance. Straightening is more robust than invariance.First, we assessed network robustness by evaluatingrecognition performance for images with increasingly larger levels of i.i.d. gaussian noise addedto the pixels (D). We found that the straightened representations proved substantially morerobust for a wide range of noise levels with negligible cost for the no-noise recognition performance.Second, we tested robustness to adversarial perturbations, which are considered one of the hallmarkfailures of artificial vision models . Not only are artificial models highly susceptible to smallamounts of adversarial noise, but the adversarial examples are barely visible to humans, a notablediscrepancy between artificial and biological perception. Therefore, adversarial robustness is animportant metric of how brain-like the representations are. Specifically, we used untargeted projectedgradient descent (PGD) with the L2 norm constraint to generate adversarial perturbations . Forall attack budgets, we chose a step size that is 1/10 of the budget and set the number of PGD stepsto be 500 to ensure that the attack optimization procedure had fully converged. We found that thestraightening objective substantially increased the robustness to white box attacks over all attackbudgets without degrading performance on clean images, as shown in E. We also tested recognition robustness on a composite of corruptions. We used the CIFAR-C dataset, which defines 18 types of corruptions coarsely grouped into noise, blur, weather anddigital categories and evaluated the models on corruptions of the highest intensity. F showsthe relative performance of straightening versus invariance. Straightened representations wereagain more robust than those optimized for invariance for many forms of image corruption, mostnotably those in the noise category. All corruption types for which invariance proved superior tostraightening were directly (brightness, saturate, and contrast) or indirectly (fog, as a specific formof contrast degradation) included as augmentations in the training set, and thus their robustnesswas a natural consequence of the invariance objective. Overall, these results demonstrate thatlearning by straightening brings with it a systematic benefit in robustness to a wide variety of inputdegradations, without the computational costs and complexity associated with directly optimizing forsuch robustness.",
  "Discussion": "We have shown that a biologically-inspired SSL objective which promotes straightening in therepresentation of image sequences leads to predictive neural representations that factorize geometric,photometric, and semantic attributes of the input. These embeddings also prove more robust to variousforms of noise and other degradations, compared to SSL methods that optimize for augmentationinvariance. Moreover, incorporating straightening as a regularizer extends these benefits to other SSL",
  "training procedures, suggesting a broader utility for straightening as a cost-effective mechanism forrobust unsupervised learning": "Directly improving robustness to adversarial attacks via optimization is difficult and computationallycostly . In contrast, our solution achieves similar results in an easy and computationally lessdemanding manner. The key ingredient for its success is having meaningful temporal structure in theinput sequences. This could either come naturally through the use of video (although good datasetsfor that are scarce ) or, more practically, can be artificially enforced by temporally correlatedimage augmentations. Thus, our results highlight a new useful form of data augmentation in supportof learning predictive representations. In contrast to invariance, which aims to map all elements of a semantic class into unique pointsin representational space, discarding all within-category variability, straightening strives to encodeall structured across-frame variations in the input. In doing so, it produces rich image embeddingscontaining structured information about class identity, as well as various transformations whichare represented in different subspaces, and thus easy to decode. Geometrically, this means thatstraightening leads to overall higher dimensional embedding spaces but the individual semanticcomponents (image class, or class transformation) are much lower dimensional. This jointincrease in embedding dimension and reduction in manifold dimensionality increases the modelsrepresentational capacity , which may explain its increased robustness. We have advocated for the replacement of hand-selected augmentations with the readily availabletemporal structure of natural visual experience . However, the predictable structure of naturalvideos evolves at multiple timescales. It is not clear whether a feedforward architecture that takes inone frame at a time and makes predictions at a single temporal scale is enough to fully take advantageof such structure. As the predictable horizon of different elements in our visual input varies acrosslevels of abstraction, a natural extension would be to enforce straightening at multiple time scales andin multiple network stages. More work is needed to determine how to best incorporate a hierarchicaltemporal structure in the straightening loss to accommodate long horizon predictions, but we expectthis type of hierarchical prediction to play a central role in developing models for both biological andmachine vision. Adel Ahmadyan et al. Objectron: A large scale dataset of object-centric videos in the wildwith pose annotations. In: Proceedings of the IEEE/CVF conference on computer vision andpattern recognition. 2021, pp. 78227831.",
  "APretraining details for sequential MNIST": "To find the optimal weights in the loss function (2), we used a parameter sweep to choose the(, ) pair that gives the best clean image recognition performance, with resulting choices = 1.0, = 0.25. For the invariance objective, a similar parameter search yields = 0.125, = 0.5. Thedetailed architecture of the encoder is described by the sequence of transformations in B.",
  "and = 1": "9. For the invariance objective, we used the reportedweight parameters from . When straightening was added to the main SSL objective as a regularizer,we kept the default optimal weight parameters taken from solo-learn in the main objective andonly tuned the weight of the straightening loss. We set this weight to 3 for barlow twins, 0.1 forSimCLR, 0.2 for W-MSE, 0.005 for DINO. We used the LARS optimizer with learning rate 0.3, weight decay 1e 4, batch size 256 totrain our straightening model. For all other models we used the default setting given in the solo-learnlibrary. All pretraining was run for 1000 epochs, which takes roughly 5 hours on 4 A100 NvidiaGPUs.",
  "EStraightening natural temporal transformations": "Pretraining detailsWe used ResNet-18 as the backbone architecture together with a projectorwith 3 fully-connected layers, but modified the first convolution to accept the single channel input.We applied either the straightening objective (2) or the invariance objective (4) to the outputs of theprojector. The models are trained from scratch with no pretrained weights. No data augmentation isapplied, so models can only rely on the natural frame-to-frame variations. We choose 6 frames with afixed interval (4t) from each gesture clip. While this might not be the optimal setting if the goal isto optimize performance on gesture recognition, our purpose is to compare the straightening and theinvariance learning objective in exactly the same setup. Evaluation pipelineFor gesture classification we freeze the model and concatenate the outputsof the backbone of all 6 frames to train the linear classifier. To test robustness we add gaussiannoise of various levels to pixels. The straightened representations are more noise robust than theinvariance-based solutions."
}