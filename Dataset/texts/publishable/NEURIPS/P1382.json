{
  "Abstract": "Recent advances in self-supervised models for natural language, vision, and proteinsequences have catalyzed the development of genomic DNA language models(DNALMs). These models aim to learn generalizable representations of diverseDNA elements, potentially enabling various downstream genomic prediction, inter-pretation and design tasks. However, existing benchmarks do not adequately assessthe capabilities of DNALMs on an important class of non-coding DNA elementscritical for regulating gene activity. Here, we introduce DART-Eval, a suite ofrepresentative benchmarks focused on regulatory DNA to evaluate performance ofDNALMs across zero-shot, probed, and fine-tuned settings against contemporaryab initio models as baselines. DART-Eval addresses biologically relevant tasksincluding sequence motif discovery, cell-type specific regulatory activity predic-tion, and counterfactual prediction of regulatory genetic variants. Our systematicevaluations reveal that current annotation-agnostic DNALMs exhibit inconsistentperformance and do not offer compelling gains over alternative baseline modelsfor most tasks, despite requiring significantly more computational resources. Wediscuss potentially promising modeling, data curation, and evaluation strategiesfor the next generation of DNALMs. Our benchmark datasets and evaluationframework are available at",
  "Introduction": "Large Language Models (LLMs) have revolutionized natural language processing by learningcomplex patterns, contextual relationships, and hierarchical structure within text in a self-supervisedmanner. In the biological domain, self-supervised language models trained on protein sequences haveenabled high-performance tools for protein structure prediction and design . Building onthese advances, analogous DNA Language Models (DNALMs) have been recently developed to learnrich representations of genomic DNA sequences from one or more species, aiming to enhance DNAsequence design, functional syntax discovery, and evolutionary analyses . The human genome is 3 billion base pairs of DNA and encodes two main classes of functionalelements (See Appendix B for biological background). Protein coding sequences of approximately20,000 genes span around 1.5% of the genome. These sequences encode a dense, information-richsyntax and serve as templates for transcription to RNA and translation to proteins. In contrast, millionsof non-coding regulatory control elements, estimated to collectively span 5 to 20% of the genome,orchestrate complex programs of gene transcription and translation that define cell state, fate, andresponse . The DNA sequence of transcriptional regulatory elements typically encode cell-type",
  ": An overview of DART-Eval tasks and settings": "specific, sparse, combinatorial syntax involving short, fuzzy DNA motifs bound by regulatory DNAbinding proteins (transcription factors, or TFs). The stark contrasts between coding and regulatorysequences, in their syntax, cell-type specificity, and genomic coverage, pose significant challengesfor DNALMs to learn optimal representations for diverse downstream applications, necessitating awide array of benchmarks and evaluation criteria.",
  ". Outperform alternative ab initio models on biologically relevant tasks, either by themselvesor as foundations for a supervised model": "The most biologically relevant applications of regulatory sequence models include interpretingand discovering functional regulatory sequences, predicting the effects of sequence perturbationsincluding genetic variants, and designing sequences with desired properties. However, contemporaryDNALMs have not been rigorously evaluated against state-of-the-art ab initio models for their abilityto learn representations of regulatory DNA that enhance performance on these important downstreamapplications. To address this gap, we introduce DART-Eval (DNA RegulaTory Evaluations), a suite of benchmarksto assess the utility of regulatory DNA representations learned by DNALMs (). We evaluatethe performance of contemporary large DNALMs, trained genome-wide without leveraging genomicannotations, across five sets of downstream tasks of increasing difficulty, comparing their zero-shot,probed and fine-tuned performance against state-of-the-art, ab initio models.",
  "DNA language models of the human genome": "In this work, we specifically evaluate contemporary DNALMs that are trained in an annotation-agnostic manner across the entire human genome and in some cases, additional species. We evaluateCaduceus, DNABERT-2, GENA-LM, HyenaDNA, Mistral-DNA, and Nucleotide Transformer, sum-marized in . We select the most capable version of each model family,with resource requirements summarized in Table S5. These models employ diverse approaches.Pre-training objectives include BERT-style masking and autoregressive next-token-prediction. To-kenization strategies include single-nucleotide, non-overlapping fixed-size k-mers, and byte-pairencodings. Model architectures include Transformers (self-attention), Hyena (sub-quadratic-timeimplicit long convolutions), Mamba (selective state space), and differ in maximum context lengths. Our current study does not include some other classes of DNALMs, such as those modeling evolution-arily distant organisms , annotation-aware models trained on pre-specified classes of genomicregions , and models that incorporate additional features like multiple sequence alignments .Our benchmarks can be readily adapted to these models as well, and we aim to include these in futureextensions.",
  "Previous DNALM benchmarks": "Several DNALM benchmarks have been proposed , including evaluationsfocused on regulatory DNA. However, existing evaluations face three critical limitations. First, theyfocus on surrogate prediction tasks that do not directly address the main downstream applications(interpretation, counterfactual predictions, design). Second, fundamental flaws in benchmark datasetdesign undermine evaluations. Lastly, reliance on oversimplified or flawed baseline approaches oftenexaggerates the relative benefits of DNALMs (summarized in ).",
  "Includes distal regulatory elementsNumber of TFs individually analyzed310---101443Regression tasks for quantitative assaysCompositionally-controlled negativesAccounts for LD among variants---": "For each evaluation, we consider only tasks for non-coding regulation in mammalian species. We find that current evaluations focus on surrogatetasks, often draw biological conclusions using incorrect approaches, and compare with flawed baselines.(), (), and () indicate that a criterion is met, not met, and partially met (i.e. for only certain tasks) respectively.(-) indicates that an evaluation has no relevant tasks for the given criterion. Models were fine-tuned on ChIP-Seq data from 160 TFs. However, reported statistics on individual TFs were more limited or absent. Current benchmarks often rely on surrogate predictive tasks that do not directly address key down-stream applications. For example, DNALMs are often fine-tuned to classify different classes ofregulatory elements like promoters or enhancers and evaluated on the same task .However, the practical value of these models lies in their ability to reveal predictive sequence featuresor design synthetic sequences for each class, capabilities that most existing benchmarks fail toevaluate. Dataset design issues, such as the lack of rigorous controls, further compromise evaluations. Regu-latory DNA sequences typically have higher G/C nucleotide content than the genomic background.Without compositionally matched background sequences, classifiers may perform well withoutlearning biologically relevant regulatory DNA sequence features . Confounders alsoaffect counterfactual variant effect prediction tasks, where the goal is to use variant effect scores todiscriminate functional genetic variants from other background variants. Many evaluations incorrectlyuse trait-associated variants to define functional variant sets, overlooking that most such associationsare correlative rather than causal due to linkage disequilibrium (LD) . Benchmarking datasetsmust therefore be carefully curated to control for such confounders. The rapid progress in regulatory genomics in terms of data generation and modeling has renderedmany previous cutting-edge resources obsolete. However, many benchmarks often use outdateddatasets and baseline models. The latest ab initio supervised models are trained on quantitative, high-resolution molecular readouts of regulatory activity across multiple cell types and vastly improve uponprevious generation binary classification models . Effective benchmarks must incorporatethese state-of-the-art models as baselines. Recent benchmarks have begun addressing these limitations by incorporating high-quality regulatoryprofiling experiments across diverse cellular contexts and experimentally validated regulatorygenetic variants . Our work complements these efforts with carefully curated benchmark datasetsthat (1) carefully control for biological confounders, (2) enable evaluation of the models ability todiscover a comprehensive set of regulatory sequence features across diverse cell types, and (3) utilizepanels of high-confidence causal variants affecting regulatory activity.",
  "Ab initio Probing-head-like-----0.8460.932": "The best-performing model in each setting is bolded. Here, we evaluate the models abilities to prioritize curated regulatory elementsagainst matched control sequences. Zero-shot accuracy and supervised paired accuracy quantify the fraction of positives prioritized over theircorresponding negatives. Supervised absolute accuracy quantifies the fraction of labels assigned correctly. For this task, (1) DNALMs wereeffective in a zero-shot setting, (2) final-layer DNALM embeddings offered little additional signal over the raw sequence, and (3) fine-tunedDNALMs offered a moderate improvement over ab initio models.",
  "This section describes the different types of zero-shot, probed, and fine-tuned DNALM evaluationapproaches as well as the baseline models": "Zero-Shot Analyses We used two broad strategies to evaluate pre-trained DNALMs in a zero-shotmanner without task-specific tuning. First, embedding-based evaluations utilize the mean last-layerembeddings across tokens. Second, likelihood-based evaluations are derived from the cross-entropyloss as the input (interpreted as a negative log-likelihood and closely related to perplexity scores). Forautoregressive models, the likelihood is computed from the overall loss of the next-token predictions.For masked models, the quasi-likelihood for a single token is defined as the likelihood of that token,given an input masked at that token. These quasi-likelihoods are then summed across tokens. Supervision via probing or fine-tuning We implemented two efficient approaches for supervisedtuning of the pre-trained DNALMs. First, final-layer probing involves training a CNN classifier on thefinal hidden layer outputs of the DNALM, with the base model frozen. Second, parameter-efficientfine-tuning uses LoRA to train low-rank adapters on all linear and convolutional layers in thebase model. The specific architectures used are detailed in Appendix D.2. Ab Initio Baselines We compared the DNALMs to supervised baseline models that were trained abinitio. First, we used ChromBPNet as the baseline model for regression tasks (.1) involvingchromatin accessibility (a measure of regulatory activity). ChromBPNet is a dilated CNN architecturewith a 2 Kb local receptive field that predicts base-resolution signal profiles of chromatin accessibilityfrom regulatory DNA sequence . Second, for the other tasks (Sections 4.2 - 4.5), we used asimple CNN classifier architecturally similar to our probing CNN architecture but with one additionallayer. Lastly, for the cell-type-specific sequence classification task (.3), we used a CNNmodel similar to ChromBPNet but trained on binary labels. Further details are provided in AppendixD.3.",
  "Prediction tasks and evaluation results": "4.1Distinguishing regulatory DNA from background sequencesFirst, we designed a relatively easy prediction task that evaluates a models ability to distinguish high-confidence regulatory element sequences from compositionally matched synthetic control sequences.The positive element set was derived from 2.3 million candidate cis-regulatory elements (cCREs)curated by the ENCODE consortium based on experimental profiling of biochemical regulatoryactivity . Negative set sequences were generated by shuffling each sequence while maintainingdinucleotide frequencies, thereby destroying syntactic information but preserving key compositionalproperties . Data The dataset for this task consists of 2.3 million cCREs of length 350 bp (Appendix C.1) and anequivalent number of synthetic dinucleotide-shuffled negatives. See Appendix E.1 for preprocessingdetails. : Distributions of zero-shot accuracies across 1443 transcription factor motifs, testing theability to distinguish motif instances from background sequences. Vertical and horizontal linesrepresent 70% accuracy thresholds. In the likelihood setting, models identify most but not all motifs.In the embedding settings, models fail to distinguish motifs from background sequences. Metrics In the zero-shot setting, DNALM model likelihoods were obtained for each pair of cCREand shuffled negative, with a \"correct\" prediction assigning a greater likelihood to the cCRE thanthe negative. In supervised settings, the models predict whether a given element is a cCRE or anegative. We define \"absolute accuracy\" as the fraction of elements and controls classified correctly,and \"paired accuracy\" as the fraction of pairs where the model assigns a greater probability to cCREsin the positive set than the synthetic controls in the negative set. Results All DNALMs prioritized cCREs over synthetic negative control sequences in a zero-shotsetting (), suggesting that the models are likely learning at least some regulatory sequencefeatures beyond compositional biases. Probing models demonstrated similar absolute accuraciesand improved paired accuracies, compared to the zero-shot setting. Fine-tuning yielded a furtherimprovement in prioritization, with paired accuracies approaching 1. The ab initio CNN baselinemodel, in comparison, demonstrated similar performance to the probed models.",
  "Assessing sensitivity to known regulatory sequence motifs": "Next, we evaluated whether the DNALMs had learned sequence features that are known to driveregulatory activity. Transcriptional regulatory elements encode one or more short sequence motifsthat recruit sequence-specific regulatory DNA binding proteins called transcription factors (TFs).Here, we assess the models abilities to distinguish known TF binding motifs from matched shufflednegative control motifs. Data We individually tested known consensus binding motifs of 1443 TFs from the HOCOMOCOv12 database , further described in Appendix C.2. We derived 100 neutral backgrounds fromdinucleotide-shuffled ENCODE cCRE sequences. Positive sequences were constructed by insertingTF motifs at the center of each background sequence. Negative sequences were similarly constructedby inserting shuffled motifs. Both forward and reverse complements of each positive and negativesequence were scored through the models and used for evaluation. Metrics We evaluated the DNALMs in a zero-shot setting by calculating likelihoods and embeddings.For the likelihood-based approach, we considered a prediction to be \"correct\" if the model assigned ahigher likelihood to a positive sequence than its corresponding negative sequence. For the embedding-based approach, we defined a correct prediction as one where the cosine embedding distance from theneutral background sequence to its corresponding positive sequence was greater than the distance fromthe neutral sequence to a corresponding negative sequence. Accuracies were computed individuallyfor each TF motif (Appendix E.2). Results In the likelihood setting, all DNALMs were able to prioritize positive sequences containingTF motifs over negative controls (). However, accuracies varied substantially across motifs,suggesting that some motifs are likely not encoded in the internal representations learned by theDNALMs (Table S7). Notably, motif likelihood scores were highly correlated between models, : UMAP of model embeddings for sequences with experimentally identified cell-type-specificactivity, colored by the true labels. The baseline embedding is a vector of canonical motif instancesidentified by FIMO. Numerical values are adjusted mutual information scores between true labelsand a k-means clustering with k = 50, along with a 95% confidence interval across clustering seeds,measuring the clustering quality w.r.t. the true labels. Only the baseline model yielded a usefulembedding space for distinguishing sequence features for cell-type-specific activity. suggesting a strong influence of the underlying pre-training data distribution on performance (FiguresS2, S3). These trends were also preserved when motifs were aggregated over TFs belonging to thesame families based on the similarity of their DNA binding domains and motifs (Figures S4, S5).In contrast, no model reliably prioritized motifs in the embedding setting, with the vast majority ofaccuracies falling between 40% and 60% (). These results indicate that final-layer averagedembeddings and cosine distance measurements do not fully capture the models expressivity. Lastly,motif discovery performance (this task) was nearly always lower than performance for discriminatingregulatory elements (.1). We hypothesize that this discrepancy stems from two key factors.First, DNALMs learn only a subset of TF motifs, primarily capturing those that appear frequentlyacross the genome. Second, regulatory elements contain multiple TF binding sites, allowing successfuldiscrimination even with an incomplete repertoire of learned motifs.",
  "Learning cell-type-specific regulatory sequence features": "Cell-type identity emerges from distinct patterns of regulatory element activity across a sharedgenome. Hence, we evaluated whether representations learned by DNALMs encode cell-type specificregulatory sequence features. Data We curated cell-type specific regulatory elements across five diverse cell lines based onATAC-seq chromatin accessibility experiments that highlight regulatory regions bound by TFs(). Specifically, we used regions with strong ATAC-seq accessibility signal (peaks) as candidateregulatory elements in each cell line C.3. We then used DESeq2 for differential analysis to identifycell-type specific elements that showed significantly higher chromatin accessibility in exactly onecell type relative to the others (Appendix E.3). Metrics We evaluated models in zero-shot and supervised settings. For zero-shot evaluation, weclustered model embeddings of the cell-type specific regulatory sequences using k-means andquantified label separation using the adjusted Mutual Information Score across labels . In thesupervised setting, we evaluate the performance of classification of the cell-type specific regulatorysequences using overall accuracy and binary classification metrics (accuracy, AUROC, AUPRC) foreach cell type versus the others (Appendix E.3). Results In the zero-shot setting, all DNALMs showed poor cell-type separation in their embeddingswhen compared to a simple baseline approach that used k-means on the sequences represented usingmotif counts of known motifs () (Appendix E.3). In the supervised setting, the ab initio CNNbaseline generally matched or outperformed all other models. Fine-tuned models outperform probedmodels, which performed comparably to a smaller ab initio CNN baseline (Tables 4, S8 - S13).",
  "Ab initioProbing-head-like0.4740.7540.8360.7570.8070.741ChromBPNet-like0.6670.9030.9290.8940.9210.848": "We underline the best-performing model for each setting and bold the best-performing model across all settings. For each model, we evaluatedoverall accuracy across all classes and AUROC between each class and the remainder. We see that ab initio sequence models performedcomparably to the best fine-tuned DNALMs and substantially outperformed all probed DNALMs.",
  "Predicting quantitative measures of regulatory activity from sequence": "ATAC-seq and DNase-seq experiments performed in a cell type of interest provide genome-widequantitative measurements of chromatin accessibility . The quantitative chromatin accessi-bility signal of a regulatory element is dictated by the repertoire of TFs that bind specific syntax ofsequence motifs encoded in its sequence. We therefore evaluated whether representations learned byDNALMs enable accurate prediction of quantitative chromatin accessibility. Data We trained sequence-to-activity (S2A) regression models to predict quantitative DNase-seqsignal (measured as log(counts of sequencing reads)) over 2 Kb genomic sequences. The inputsequences included DNase-seq peaks (regions with a strong, statistically significant signal) and otherG/C-content-matched background genomic regions. Models were trained and evaluated separately onDNase-seq data from five cell types as in .3 (Appendix C.3). Metrics We assessed regression performance using Pearson and Spearman correlation betweenpredicted and observed signal, evaluated across peak regions only and across a union of peak andbackground regions. Additionally, we computed binary classification metrics (AUROC and AUPRC),using a positive set of high-confidence, reproducible peaks and a negative set of background regions(Appendix E.4). Results Fine-tuned DNALM S2A models showed strong performance, with the strongest mod-els matching or moderately outperforming the ab-initio baseline CNN (ChromBPNet) model onregression and classification metrics (Tables 5, S14 - S18). In contrast, probed models substan-tially underperformed ChromBPNet, indicating that frozen last-layer embeddings lack sufficientexpressivity for accurate prediction of quantitative accessibility.",
  "Predicting counterfactual effects of regulatory genetic variants": "A critical challenge in human genetics is predicting how genetic variants affect gene regulationthrough changes in chromatin accessibility. Models trained to predict regulatory activity fromsequence (S2A models) (such as those in .4) are typically used in a counterfactual setting topredict the effects of genetic variants on regulatory activity. This is a particularly challenging tasksince the S2A models are never directly trained on genetic variation data. We evaluated the ability ofDNALMs to prioritize and predict the quantitative effects of regulatory genetic variants that impactchromatin accessibility. Data We utilized data from two quantitative trait locus (QTL) mapping studies that associate geneticvariation with variation of chromatin accessibility from ATAC-seq or DNase-seq experiments acrossa large cohort of lymphoblastoid cell lines (LCLs) from individuals of African ancestry (Appendix C.4). These datasets identify genetic variants with statistically significant effects onchromatin accessibility as caQTLs (for ATAC-seq) and dsQTLs (for DNase-seq). We enrich for likely",
  "Ab initioChromBPNet0.5400.7540.5340.5490.5740.9400.9520.9100.9750.917": "We underline the best-performing model for each setting and bold the best-performing model across all settings. For each model, we evaluatedthe correlation between predicted and true signals across peak regions. Additionally, we evaluated classification performance against a positiveset of high-confidence peak regions and a negative set of background sequences. We see that DNALM-derived models do not offer a consistentadvantage over the ab initio baseline models. causal caQTLs and dsQTLs by restricting to those that fall within accessible regulatory elements(peak regions). These variants form the positive set. The negative set consists of other backgroundgenetic variants in peak regions that do not exhibit statistically significant associations with chromatinaccessibility. Each genetic variant consists of a pair of alleles (two different nucleotides) {A, C, G,T} and a label y {0,1} with 0 = background and 1 = significant. Metrics We extracted the 2 Kb genomic sequence context of each variant and scored two versions ofthe sequence that contain each of the alleles of the variant with different models. We scored variantsin both zero-shot and supervised settings. For embedding-based zero-shot scoring, we computed thecosine distance between the two variant allele sequences. For likelihood-based zero-shot scoring, wecomputed the log-likelihood difference using an input sequence with the variant-containing tokenmasked and taking the loss with respect to the two alleles. The likelihood-based evaluations were onlyconducted for models with fixed encodings (Nucleotide Transformer and HyenaDNA) since changinga single base can affect the entirety of a byte-pair encoding. For supervised scoring, we used thechromatin accessibility S2A models from .4 trained on a single LCL sample (GM12878).We computed the absolute difference in predicted accessibility between the two alleles. For eachdataset and variant effect score, we computed the AUROC and AUPRC with respect to the positiveand negative variant sets. In addition, we computed the Pearson correlation between the reportedeffect size of association from the QTL study and the predicted activity difference for the supervisedmodels (Appendix E.5). Results In the zero-shot setting, Nucleotide Transformer achieved the best performance for bothembedding and likelihood-based approaches (). In supervised evaluation, fine-tuned sequence-to-activity models substantially outperformed their probed counterparts. However, despite matchingChromBPNets performance in chromatin accessibility prediction (.4), fine-tuned modelsunderperformed the ab-initio baseline ChromBPNet in variant effect prediction. This discrepancyhighlights the critical importance of including counterfactual tasks in evaluations alongside observa-tional assessments (Tables 6, S19, and S20).",
  "Discussion": "In this study, we present DART-Eval, a suite of representative benchmark datasets for evaluatingregulatory DNA representations learned by DNALMs. Our evaluations spans five tasks, comparingstate-of-the-art DNALMs in zero-shot, probed, and fine-tuned settings against strong ab initio baselinemodels. The tasks increase in difficulty from detecting regulatory sequences, to regulatory motifdiscovery, quantitative prediction of regulatory activity, and finally counterfactual prediction ofregulatory genetic variants. While DNALMs excel at simpler tasks, their performance deteriorateswith increasing task complexity, highlighting the need for rigorous evaluations to accurately assessthe capabilities of these models.",
  "Yoruban": "Caduceus0.4430.5080.0170.4900.5130.666DNABERT-2-0.5050.0240.4760.4730.631--GENA-LM-0.5010.0590.4660.4140.628--HyenaDNA0.4360.515-0.0420.4670.5030.573--Mistral-DNA-0.475-0.0030.4320.0530.504NT0.4690.6130.1290.5160.5070.670--ChromBPNet------0.7380.892 We underline the best-performing model for each setting and bold the best-performing model across all settings. In zero-shot settings, alleliceffects of variants were scored by measuring the difference in model-derived embeddings or likelihoods of for sequences containing eachallele of the variant. We computed classification metrics between positive and control variant sets, expecting positive variants to have largerpredicted allelic effects. Here, unlike the other zero-shot tasks, the likelihood setting did not substantially outperform the embedding setting. Insupervised settings, for the positive variants, we computed the correlation between measured and predicted allelic effects. We also computedclassification metrics (AUROC and AUPRC) relative to the positive and negativevariant sets. The ab-initio baseline CNN (ChromBPNet)substantially outperformed DNALM-based methods. Although DNALMs successfully discriminate regulatory DNA from background sequences, theyappear to learn incomplete repertoires of regulatory sequence features. This limitation likely stemsfrom the sparsity and the uneven distribution of regulatory features; regulatory elements constituteonly 10-20% of the human genome, and certain classes of regulatory features occur at substantiallydifferent frequencies. Potential strategies to address this challenge include balanced sampling oftraining examples across different classes of functional elements, incorporating regulatory annotationsas tokens, or training on subsets of the genome that are functionally related (e.g., sets of candidateregulatory elements) rather than across the entire genome. Our analysis reveals several critical insights about DNALM architecture and modeling choices.Consistent with previous studies, we observe that embedding-derived approaches (e.g. embeddingdistance, final-layer probing) generally underperform methods that leverage models full expressivity(e.g. likelihoods, fine-tuning) . For likelihood-based methods, masked objectives appear tobe less efficient than autoregressive objectives due to required iterative token masking. Byte-pairencodings pose a particular challenge for variant effect prediction, as single-base changes can altermultiple tokens in unpredictable ways, making it difficult to compare sequence likelihoods. Whilefine-tuning generally achieves superior performance relative to probing, it demands significantlymore computational resources, requiring gradient backpropagation through the entire model. While DART-Eval offers a rigorous framework for the evaluation of regulatory DNA representationslearned by DNALMs, future extensions could enhance its scope. Our current evaluations arelimited to tasks involving short, local sequence contexts, and do not encompass tasks that requirelong-range context, such as the prediction of distal regulatory interactions, gene expression, or 3Dgenome architecture. With continued improvement in functional annotation of genomes of othermodel organisms, benchmarking DNALMs on diverse species will become increasingly relevantfor assessing the generalizability of learned representations. Expanding task diversity to cover amore comprehensive range of regulatory elements (e.g. 5-UTRs, 3-UTRs, and splice sites), andincorporating evaluations related to transcriptional and post-transcriptional regulatory mechanismswould enable a more complete assessment of regulatory function coverage.",
  "and Disclosure of Funding": "The authors acknowledge funding support from NIH grants 5U24HG007234, U01HG009431, andU01HG012069 to AK. AS is supported in part by the National Science Foundation Graduate ResearchFellowship (NSF GRFP). AW and A Pampari are supported by the Stanford BioX Fellowship. Wethank Alex Tseng for providing a dinucleotide shuffling algorithm, Salil Deshpande for providing analgorithm for constructing consensus peak sets across multiple experiments, and Jacob Schreiber forproviding a reference PyTorch implementation of ChromBPNet.",
  "Mistral-DNA: Mistral model for genomics |by raphael mourad |medium": "Z. Avsec, V. Agarwal, D. Visentin, J. R. Ledsam, A. Grabska-Barwinska, K. R. Taylor, Y. Assael,J. Jumper, P. Kohli, and D. R. Kelley. Effective gene expression prediction from sequence byintegrating long-range interactions. Nature Methods, 18(10):11961203, oct 2021. Z. Avsec, M. Weilert, A. Shrikumar, S. Krueger, A. Alexandari, K. Dalal, R. Fropf, C. McAnany,J. Gagneur, A. Kundaje, and J. Zeitlinger. Base-resolution models of transcription-factor bindingreveal soft motif syntax. Nature Genetics, 53(3):354366, mar 2021.",
  "E. P. Consortium. An integrated encyclopedia of DNA elements in the human genome. Nature,489(7414):5774, sep 2012": "E. P. Consortium, J. E. Moore, M. J. Purcaro, H. E. Pratt, C. B. Epstein, N. Shoresh, J. Adrian,T. Kawli, C. A. Davis, A. Dobin, R. Kaul, J. Halow, E. L. Van Nostrand, P. Freese, D. U. Gorkin,Y. Shen, Y. He, M. Mackiewicz, F. Pauli-Behn, B. A. Williams, A. Mortazavi, C. A. Keller,X.-O. Zhang, S. I. Elhajjajy, J. Huey, D. E. Dickel, V. Snetkova, X. Wei, X. Wang, J. C. Rivera-Mulia, J. Rozowsky, J. Zhang, S. B. Chhetri, J. Zhang, A. Victorsen, K. P. White, A. Visel,G. W. Yeo, C. B. Burge, E. Lcuyer, D. M. Gilbert, J. Dekker, J. Rinn, E. M. Mendenhall,J. R. Ecker, M. Kellis, R. J. Klein, W. S. Noble, A. Kundaje, R. Guig, P. J. Farnham, J. M.Cherry, R. M. Myers, B. Ren, B. R. Graveley, M. B. Gerstein, L. A. Pennacchio, M. P. Snyder,B. E. Bernstein, B. Wold, R. C. Hardison, T. R. Gingeras, J. A. Stamatoyannopoulos, andZ. Weng. Expanded encyclopaedias of DNA elements in the human and mouse genomes.Nature, 583(7818):699710, jul 2020. H. Dalla-Torre, L. Gonzalez, J. Mendoza Revilla, N. Lopez Carranza, A. Henryk Grywaczewski,F. Oteri, C. Dallago, E. Trop, H. Sirelkhatim, G. Richard, M. Skwark, K. Beguir, M. Lopez, andT. Pierrot. The nucleotide transformer: building and evaluating robust foundation models forhuman genomics. BioRxiv, jan 2023. J. F. Degner, A. A. Pai, R. Pique-Regi, J.-B. Veyrieras, D. J. Gaffney, J. K. Pickrell, S. De Leon,K. Michelini, N. Lewellen, G. E. Crawford, M. Stephens, Y. Gilad, and J. K. Pritchard. DNase isensitivity QTLs are a major determinant of human expression variation. Nature, 482(7385):390394, feb 2012. M. K. DeGorter, P. C. Goddard, E. Karakoc, S. Kundu, S. M. Yan, D. Nachun, N. Abell,M. Aguirre, T. Carstensen, Z. Chen, M. Durrant, V. R. Dwaracherla, K. Feng, M. J. Gloudemans,N. Hunter, M. P. S. Moorthy, C. Pomilla, K. B. Rodrigues, C. J. Smith, K. S. Smith, R. A. Ungar,B. Balliu, J. Fellay, P. Flicek, P. J. McLaren, B. Henn, R. C. McCoy, L. Sugden, A. Kundaje, M. S.Sandhu, D. Gurdasani, and S. B. Montgomery. Transcriptomics and chromatin accessibility inmultiple african population samples. BioRxiv, nov 2023.",
  "V. Fishman, Y. Kuratov, M. Petrov, A. Shmelev, D. Shepelin, N. Chekanov, O. Kardymon, andM. Burtsev. GENA-LM: A family of open-source foundational models for long DNA sequences.BioRxiv, jun 2023": "O. Fornes, J. A. Castro-Mondragon, A. Khan, R. van der Lee, X. Zhang, P. A. Richmond,B. P. Modi, S. Correard, M. Gheorghe, D. Baranaic, W. Santana-Garcia, G. Tan, J. Chneby,B. Ballester, F. Parcy, A. Sandelin, B. Lenhard, W. W. Wasserman, and A. Mathelier. JASPAR2020: update of the open-access database of transcription factor binding profiles. Nucleic AcidsResearch, 48(D1):D87D92, jan 2020.",
  "E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. LoRA:Low-rank adaptation of large language models. arXiv, 2021": "K. Jaganathan, S. Kyriazopoulou Panagiotopoulou, J. F. McRae, S. F. Darbandi, D. Knowles,Y. I. Li, J. A. Kosmicki, J. Arbelaez, W. Cui, G. B. Schwartz, E. D. Chow, E. Kanterakis, H. Gao,A. Kia, S. Batzoglou, S. J. Sanders, and K. K.-H. Farh. Predicting splicing from primarysequence with deep learning. Cell, 176(3):535548.e24, jan 2019. J. Jumper, R. Evans, A. Pritzel, T. Green, M. Figurnov, O. Ronneberger, K. Tunyasuvunakool,R. Bates, A. dek, A. Potapenko, A. Bridgland, C. Meyer, S. A. A. Kohl, A. J. Ballard,A. Cowie, B. Romera-Paredes, S. Nikolov, R. Jain, J. Adler, T. Back, S. Petersen, D. Reiman,E. Clancy, M. Zielinski, M. Steinegger, M. Pacholska, T. Berghammer, S. Bodenstein, D. Silver,O. Vinyals, A. W. Senior, K. Kavukcuoglu, P. Kohli, and D. Hassabis. Highly accurate proteinstructure prediction with AlphaFold. Nature, 596(7873):583589, aug 2021.",
  "A. Karollus, J. Hingerl, D. Gankin, M. Grosshauser, K. Klemon, and J. Gagneur. Species-awareDNA language models capture regulatory elements and their evolution. Genome Biology,25(1):83, apr 2024": "J. K. Leman, B. D. Weitzner, S. M. Lewis, J. Adolf-Bryfogle, N. Alam, R. F. Alford, M. Apra-hamian, D. Baker, K. A. Barlow, P. Barth, B. Basanta, B. J. Bender, K. Blacklock, J. Bonet,S. E. Boyken, P. Bradley, C. Bystroff, P. Conway, S. Cooper, B. E. Correia, B. Coventry, R. Das,R. M. De Jong, F. DiMaio, L. Dsilva, R. Dunbrack, A. S. Ford, B. Frenz, D. Y. Fu, C. Geniesse,L. Goldschmidt, R. Gowthaman, J. J. Gray, D. Gront, S. Guffy, S. Horowitz, P.-S. Huang, T. Hu-ber, T. M. Jacobs, J. R. Jeliazkov, D. K. Johnson, K. Kappel, J. Karanicolas, H. Khakzad, K. R.Khar, S. D. Khare, F. Khatib, A. Khramushin, I. C. King, R. Kleffner, B. Koepnick, T. Kortemme,G. Kuenze, B. Kuhlman, D. Kuroda, J. W. Labonte, J. K. Lai, G. Lapidoth, A. Leaver-Fay,S. Lindert, T. Linsky, N. London, J. H. Lubin, S. Lyskov, J. Maguire, L. Malmstrm, E. Marcos,O. Marcu, N. A. Marze, J. Meiler, R. Moretti, V. K. Mulligan, S. Nerli, C. Norn, S. Conchir,N. Ollikainen, S. Ovchinnikov, M. S. Pacella, X. Pan, H. Park, R. E. Pavlovicz, M. Pethe, B. G.Pierce, K. B. Pilla, B. Raveh, P. D. Renfrew, S. S. R. Burman, A. Rubenstein, M. F. Sauer,A. Scheck, W. Schief, O. Schueler-Furman, Y. Sedan, A. M. Sevy, N. G. Sgourakis, L. Shi, J. B.Siegel, D.-A. Silva, S. Smith, Y. Song, A. Stein, M. Szegedy, F. D. Teets, S. B. Thyme, R. Y.-R.Wang, A. Watkins, L. Zimmerman, and R. Bonneau. Macromolecular modeling and design inrosetta: recent methods and frameworks. Nature Methods, 17(7):665680, jul 2020.",
  "N. NaderiAlizadeh and R. Singh. Aggregating residue-level protein language model embeddingswith optimal transport. BioRxiv, jan 2024": "E. Nguyen, M. Poli, M. G. Durrant, A. W. Thomas, B. Kang, J. Sullivan, M. Y. Ng, A. Lewis,A. Patel, A. Lou, S. Ermon, S. A. Baccus, T. Hernandez-Boussard, C. Re, P. D. Hsu, and B. L.Hie. Sequence modeling and design from molecular to genome scale with evo. bioRxiv, jan2024. E. Nguyen, M. Poli, M. Faizi, A. Thomas, C. Birch-Sykes, M. Wornow, A. Patel, C. Rabideau,S. Massaroli, Y. Bengio, S. Ermon, S. A. Baccus, and C. R. HyenaDNA: Long-range genomicsequence modeling at single nucleotide resolution. arXiv, nov 2023. A. Pampari, A. Shcherbina, S. Nair, A. Wang, A. Patel, K. Mualim, S. Kundu, and A. Kundaje.Bias factorized, base-resolution deep learning models of chromatin accessibility reveal cis-regulatory sequence syntax, transcription factor footprints and regulatory variants. Biorxiv( 2024.",
  "A. R. Quinlan and I. M. Hall. BEDTools: a flexible suite of utilities for comparing genomicfeatures. Bioinformatics (Oxford, England), 26(6):8412, mar 2010": "I. Rauluseviciute, R. Riudavets-Puig, R. Blanc-Mathieu, J. A. Castro-Mondragon, K. Ferenc,V. Kumar, R. B. Lemma, J. Lucas, J. Chneby, D. Baranasic, A. Khan, O. Fornes, S. Gundersen,M. Johansen, E. Hovig, B. Lenhard, A. Sandelin, W. W. Wasserman, F. Parcy, and A. Mathelier.JASPAR 2024: 20th anniversary of the open-access database of transcription factor bindingprofiles. Nucleic Acids Research, 52(D1):D174D182, jan 2024.",
  "A. E. Vinogradov. DNA helix: the importance of being GC-rich. Nucleic Acids Research,31(7):18381844, apr 2003": "I. E. Vorontsov, I. A. Eliseeva, A. Zinkevich, M. Nikonov, S. Abramov, A. Boytsov, V. Kamenets,A. Kasianova, S. Kolmykov, I. S. Yevshin, A. Favorov, Y. A. Medvedeva, A. Jolma, F. Kolpakov,V. J. Makeev, and I. V. Kulakovskiy. HOCOMOCO in 2024: a rebuild of the curated collec-tion of binding models for human and mouse transcription factors. Nucleic Acids Research,52(D1):D154D163, jan 2024.",
  "(b) Did you specify all the training details (e.g., data splits, hyperparameters, how theywere chosen)? [Yes] All information is provided in either the Modeling section or inthe Appendix": "(c) Did you report error bars (e.g., with respect to the random seed after running experi-ments multiple times)? [Yes] Most of our experiments are of sufficiently high samplesize, but we provide full confidence intervals for our transcription factor binding motifsensitivity task on our Synapse site, and we provide error bar values for our clusteringtask in the paper.",
  "B.1The Genome and Non-Coding Regulation": "DNA, present in every cell, stores the complete set of instructions essential for life. It consists ofa chain of nucleotidesadenine (A), thymine (T), guanine (G), and cytosine (C)whose specificsequences encode functional elements. While genes, which code for proteins, are the most recognizedof these elements, they constitute only a fraction of the genome. The complete DNA sequence of anorganism is referred to as its genome. Within genes, coding sequences specify the amino acid composition of proteins. Through theprocesses of transcription and translation, nucleotide triplets (codons) in these sequences are translatedinto amino acids, which form the building blocks of proteins. However, in humans, coding sequences account for just around 1.5% of the genome. The remaining98.5% includes vast regions of non-coding DNA, some of which play essential roles in regulatingwhen, where, and to what extent genes are expressed. In multicellular organisms, gene activationand suppression are highly context-specific, enabling a single genome to support the development ofdiverse cell types across tissues and organs, each responding dynamically to internal and externalsignals. Among the non-coding regions, regulatory elements play a crucial role in controlling gene expressionaccording to cellular context. Unlike coding regions that directly produce proteins, these regulatorysequences contain nucleotide patterns that interact with specific DNA-binding proteins known astranscription factors (TFs). These interactions can alter the 3D structure of DNA, recruiting themolecular machinery required to activate or repress nearby genes. Understanding non-coding regulatory elements remains challenging due to their sparse, combinatorial,and context-dependent nature. DNA-binding proteins vary in presence and behavior across differentcell types, making the syntax of non-coding regulatory elements highly cell-type-specific. In thisway, each gene is regulated by an array of elements, such as promoters and enhancers, each withdistinct properties. Promoters are located close to the transcription start site, directly adjacent to thegenes they regulate, while enhancers can reside thousands of base pairs away yet still regulate geneexpression. In summary, although non-coding regulatory elements do not produce proteins, they govern thespatiotemporal patterns of gene expression, enabling the complex regulatory landscapes that underpincellular diversity and adaptive responses in multicellular organisms.",
  "B.2Deep learning models of DNA elements": "In recent years, several deep learning models have been developed to learn representations of differentclasses of DNA elements and predict their context-specific properties and activity. These modelsgenerally fall into two categories: supervised models, which are explicitly trained to map DNAsequence to associated properties or experimental measurements of biochemical activity, and self-supervised models, which learn representations of DNA sequences without any labeled data. Supervised deep learning models have shown impressive results in modeling various types ofbiological sequences. For example, they have been successfully used to predict RNA splicing,a key post-transcriptional regulatory process , to predict protein structure from amino acidsequences and to predict chromatin and transcriptional activity from regulatory sequences in",
  "diverse cell types . These models rely on labeled data to learn mappings from sequence tostructure or functional activity": "In contrast, self-supervised learning has shown great success in training protein language models.These models capture the complex syntax of protein-coding sequences by training on massiveprotein sequence datasets without requiring explicit functional labels. Due to the high informationdensity and conserved syntax of protein-coding DNA across species, these models have provenespecially adept at learning generalized protein representations that can be fine-tuned for downstreamapplications such as prediction of structure, interactions and even functional properties. Recently, self-supervised DNA language models (DNALMs) have emerged as a novel approach,extending beyond protein-coding sequences to learn representations of entire genomes .Unlike protein language models, DNALMs are trained to capture the syntax across all classes ofDNA elements, including diverse types of non-coding functional elements that often encode comlexand context-dependent syntax. By modeling the full spectrum of genomic sequences, DNALMs aimto capture both coding and non-coding syntax, potentially serving as foundation models for a widearray of downstream prediction tasks, potentially reducing the need for training specialized modelsfrom scratch.",
  "C.1ENCODE candidate cis-regulatory elements": "This dataset consists of a set of approximately 2.3 million high-confidence regulatory regions ascurated by the ENCODE consortium. These regions are mainly enhancers or promoters, and theyare active in at least one of a wide variety of cell types. Candidate regions were first identified byintegrating cell type-specific DNAse-seq chromatin accessibility data with ChIP-seq data for theH3K27ac and H3K4me3 histone marks, which are biochemical markers associated with enhancersand promoters respectively. The final set of regions, available online on the ENCODE project website,is capped at a maximum length of 350 bp. We specifically used the cCRE list produced as part ofphase IV of ENCODE, which provides an over-two-fold increase in identified cCREs from phaseIII. This extensive dataset serves as an ideal benchmark for evaluating language models abilityto capture essential regulatory DNA features. The dataset was downloaded from All ENCODE data is available for unrestricted use.",
  "C.2HOCOMOCO transcription factor binding motifs": "Each transcription factor recognizes specific DNA sequence motifs. To evaluate the models ability toidentify regulatory sequence features, we analyzed each motif independently. Among available motifdatabases, HOCOMOCO is widely used in the research community. It compiles motifs derived fromChIP-seq and HT-SELEX data, which measure protein-DNA binding, and uses the ChIPMunk motifdiscovery method to generate motif sequences. Version 12 of HOCOMOCO provides position-weightmatrices (PWMs) for 949 human transcription factors, encompassing 1,443 unique motifs whenaccounting for subtypes. Each PWM provides nucleotide probabilities at each motif position, fromwhich we derive consensus sequences by selecting the most probable nucleotide per position. TheHOCOMOCO database also groups transcription factors into families, facilitating higher-level analy-ses. The database was downloaded from HOCOMOCO datais available under the WTFPL license.",
  "The peak sets are summarized in Table S1 and Table S2. The cell-type-specific peak sets, identifiedby DESeq2, can be visualized in Figure S1": "ATAC-seq peaks and DNase-seq peaks are defined as regions of high chromatin accessibility in thegenome. These datasets were downloaded from ENCODE. The GM12878 ATAC-seq peaks wereobtained from ENCFF748UZH. The H1ESC ATAC-seq peaks were obtained from . The HEPG2ATAC-seq peaks were obtained from ENCSR291GJU. The IMR90 ATAC-seq peaks were obtainedfrom ENCFF243NTP. The K562 ATAC-seq peaks were obtained from ENCFF333TAT. Amongst the",
  "ATAC-seq datasets, there are a total of 277999 GM12878 peaks, 104250 H1ESC peaks, 279739HEPG2 peaks, 265247 IMR90 peaks, and 269800 K562 peaks. All ENCODE data is available forunrestricted use": "The final set of DNase-seq peaks for all cell lines was obtained from . The raw files wereobtained from ENCODE and processed according to . The GM12878 raw files were obtainedfrom ENCSR000EMT. The H1ESC raw files were obtained from ENCSR000EMU. The HEPG2 raw fileswere obtained from ENCSR149XIL. The IMR90 raw files were obtained from ENCSR477RTP. TheK562 raw files were obtained from ENCSR000EOT.",
  "Chromatin QTLs in African LCLs219,3826,82177,999syn59449898DNase QTLs in Yoruban LCLs28,30956026,813syn59449898": "are genetic variants associated with variation in chromatin accessibility measured using ATAC-seqexperiments. Genomic elements with strong ATAC-seq or DNase-seq signal are typically regulatoryelements bound by TFs. We used two QTL datasets to evaluate all the models (Table S4). Wedownloaded the processed CaQTLs from (File variant_effect_benchmarking.tsv.gzfrom Synapse repository syn59449898). caQTLs in African LCLs. The first dataset consists of 219,382 variants and their effect sizes andstatistical significance of association with variation of ATAC-seq signal across 100 lymphoblastoidcell-lines from individuals 6 African ancestry subpopulations (ESN, GWD, LWK, MSL, YRI, andMKK) . After filtering the variants using the procedure described in , we were left with77,999 control variants and 6,821 statistically significant caQTLs. Variants are restricted to fall withinATAC-seq peaks identified in the entire cohort in order to enrich for likely causal caQTLs. The datais available under the Creative Commons Attribution 4.0 International License. DNase QTLs in African LCLs. We obtained a dataset from , which comprises 560 statisticallysignificanct DNase I sensitivity QTL (dsQTL) variants and 26,813 control variants. We filtered thevariants using the procedure described in . Variants are restricted to fall within DNase-seq peaksidentified in the entire cohort in order to enrich for likely causal caQTLs",
  "All pre-trained models used in this study were obtained from HuggingFace using the documentationprovided in each models README": "For all models, sequence embeddings were derived from the output of the last hidden layer whenperforming inference on the input sequence. Embeddings for auxiliary tokens like <CLS>, <start>,and <end> were removed, and the remaining embeddings were averaged to produce an overallsequence representation. For models using byte-pair encodings, where tokens represent variablenumbers of nucleotides, this average is weighted by the number of nucleotides in each token. Thisembedding process is used in all embedding comparison tasks in this study. To calculate model (pseudo-)likelihoods for an input sequence, obtain the predicted logits for eachtoken. For autoregressive models, this can be done with a single forward pass, where each tokenis conditioned on preceding tokens. For masked models, we successively masked each token andcompute predicted logits at the masked position conditioned on all other tokens. Unscaled logits were then converted into log-likelihoods using log softmax, and the log-likelihood for the true tokenchoice at each position is isolated. These token-level log-likelihoods were then summed acrosstokens (multiplied in log space) to produce the overall sequence likelihood. This sequence-levellog-likelihood methodology was used for all likelihood-based comparisons in this study.",
  "D.2Probed and Fine-Tuned Models": "For final-layer probing, the base pre-trained model weights were frozen. Outputs from the finalhidden layer were passed to an additional CNN-based probing head. Embeddings were convertedfrom token space to sequence space by repeating each token embedding by the number of nucleotidesspanned by the token, as in and . The probing head consists of a linear projection to 32dimensions, two convolutional layers of width 8 and 32 filters, a sum pooling layer, and a linear layerto produce the final output. ReLU activations are applied after each intermediate layer. Probing headswere trained using Adam with a learning rate of 2e3. Fine-tuning utilized LoRA, a widely-used parameter-efficient fine-tuning method that performslow-rank updates to model parameters . For consistency across multiple architectures, we appliedfine-tuning to all linear and convolutional layers. We used each models included classifier head,trained from scratch. LoRA parameters included a rank of 8, an of 16, and a dropout of 0.05.Optimization used AdamW with a learning rate of 1e4 and a weight decay of 0.01. We used a consistent train, validation, and test split across all experiments, at an approximate 4:1train and validation to test split, and an approximate 9:1 train to validation split. Our test set consistsof chromosomes 5, 10, 14, 18, 20, 22. Our validation set consists of chromosomes 6 and 21, and ourtraining set consists of all other chromosomes. For all models, we evaluated the checkpoint with thelowest validation loss. All reported numbers were computed on the test set unless otherwise stated.",
  "D.3Ab initio Models": "For the chromatin accessibility regression models - which were also used in the variant interpretationtask - our Ab initio baseline was ChromBPNet, a convolutional neural network that can predict themagnitude and shape of chromatin accessibility profiles at base-pair resolution from an input DNAsequence. ChromBPNet takes as input a one-hot encoded DNA sequence of length 2,114, passingit through a single convolutional layer followed by 8 dilated residual layers of increasing kernelsize. The output of these layers is used to make two predictions. First, a Global Average Pooling(GAP) layer is applied, followed by a linear layer to predict the total ATAC-seq or DNase-seq readcounts within the central 1,000 bp of the input. Only this prediction was used to compare withthe probed and fine-tuned language models. Second, the convolutional output is passed throughanother convolutional layer with a large kernel and only one channel, producing a predicted base-levelprobability profile of reads over the output region. By multiplying both model outputs together, onecan obtain the predicted read counts at each position in the output region. The count prediction wastrained using mean squared error loss, while the profile head was trained using log-likelihood lossbased on a multinomial distribution. Separate ChromBPNet models are trained on each chromatinaccessibility dataset. We utilized already trained ChromBPNet models from the ENCODE project foreach dataset in this study. For all tasks except chromatin accessibility regression and variant effect prediction, we comparedagainst a small custom-trained CNN resembling the probing head we use, as it has a similar modelcapacity. This model consists of two parts: an embedding block - designed to produce simplesequence embeddings of similar dimensionality to DNALM embeddings - followed by an output head.The architecture of the output head is identical to the head used for probing. The embedding blocktakes in a one-hot encoded DNA sequence as input and applies a single convolutional layer of width41 and 256 channels. This output is summed with a learned single-channel positional embedding,up-projected to 256 channels. The resulting embeddings then serve as the input to the output head.Models were trained using Adam with a learning rate of 1e3. For the cell type-specific regulatory DNA task, we implemented an additional larger Ab initio baselineresembling the ChromBPNet architecture. Differences from ChromBPNet are (1) 7 dilated residualconvolutional layers instead of 8, (2) removal of the base-pair-resolution prediction head, and (3) theaddition of a single-channel learned positional encoding, incorporated after the initial convolutionallayer. Models were trained using Adam with a learning rate of 1e4.",
  "E.1Distinguishing regulatory DNA from background sequences": "Our first task tests whether models could discriminate regulatory elements from synthetic backgroundsequences. For our positive set of regulatory elements, we used the ENCODE cCRE list of approxi-mately 2.3 million high-confidence regulatory regions. We then performed dinucleotide shuffling oneach cCRE sequence to produce a matched set of synthetic negative background sequences, in whichnegative sequences retain the same sequence composition as their positive counterparts but lack thebinding motifs that promote activity. To ensure reproducibility of the shuffling process, the algorithmwas seeded by the SHA-256 hash of the input regions genomic coordinates. We then tested the models binary classification performance in zero-shot, probed, and fine-tunedsettings. In the zero-shot setting, we calculated the likelihood for each cCRE and backgroundsequence, with a correct prediction defined as a higher likelihood for a cCRE than its correspondingbackground sequence. For both the probing and fine-tuned settings, we trained classifiers to predictwhich category a sequence belongs to. For the zero-shot evaluation, performance metrics included accuracy and a one-sided WilcoxonRank-Sum Test between the cCRE and control likelihoods. For the other settings, metrics includedaccuracy, AUROC, and AUPRC.",
  "E.2Assessing sensitivity to known regulatory sequence motifs": "Models were then evaluated for their ability to recognize individual transcription factor binding motifs.We used a list of 1,443 consensus transcription factor (TF) motif sequences from the HOCOMOCOv12 database. 100 neutral background sequences were randomly chosen from the cCRE classificationtask background set. Specifically, for each combination of neutral sequence and motif, the followingsequences were considered: 1. Neutral: the original neutral sequence2. Positive: the neutral sequence with the motif inserted at the center (for a length-n motif, thecentral n nucleotides of the sequence were replaced with the motif) 3. Negative: the control sequence with a shuffled version of the motif inserted at the center4. Reverse complement of the neutral (1)5. Reverse complement of the positive (2)6. Reverse complement of the negative (3)",
  "Taken together, this procedure resulted in a dataset of 577,400 unique sequences": "We employed likelihood and embedding-based approaches for this task. For the likelihood approach,we determined whether the predicted likelihood was higher for each positive sequence than foreach corresponding negative sequence. 200 such pairs exist in the dataset for each motif, and wedefined a models accuracy for that motif as the proportion of pairs where the positive sequence had ahigher predicted likelihood. We also utilized the results to compute a one-sided Wilcoxon Rank Sumsignificance test for each motif. Note that neutral sequences were not used for this analysis.",
  "E.3Learning cell-type-specific regulatory sequence features": "We next evaluated whether models can discriminate accessible regulatory regions in different celltypes that possess distinct sets of active sequence features. We utilized ATAC-seq peaks from five celllines: GM12878, H1ESC, HEPG2, IMR90, and K562, with multiple biological replicates for eachcell type. Details are in Appendix C.3. These cell lines are extensively studied and are also known todiffer in the set of key transcription factors that regulate accessibility in each cell-line. We identifieddifferentially-active peak sequences using DESeq2, a negative-binomial-model-derived statisticaltest for read-count-based experimental assays. Specifically, we formed a consensus peak set bymerging and deduplicating peaks from each cell type. Then, we counted the number of ATAC readsintersecting each consensus peak region in each cell type. Then, we used DESeq2 in a one-vs-othersfashion for each cell type, where the positive class corresponds to Ci, the cell type for which weare finding the differential peaks, and the negative set = {Cj} with j = i corresponding to all theother cell types. Our final differential peak sets were chosen with a positive log fold change > 1and an adjusted p-value < 0.001. We only kept peaks with differential activity in exactly one celltype. We summarized the number of differentially accessible peaks in each cell type in Table S2. Wevalidated our differential peak set using Homer . HOMER is a de novo motif discovery algorithmthat scores motifs by looking for motifs with differential enrichment between two sets of sequences.For our purposes, we used the differentially accessible peak set in one cell type as the target set andthe differentially accessible peak sets in all other cell types as the background set, and we repeatedthis for all cell types. HOMER takes the motifs identified from the de novo motif discovery stepand compares them against a library of known motifs in JASPAR . In Table S3, we present thenegative log of the Benjamini-Hochberg-adjusted q values from the HOMER motif discovery, withlog(q) capped at 10. In the zero-shot setting, we further restricted the peak sets to the top 5000 differential peaks per cellline, based on the adjusted DESeq2 p-value. On these peak sets, we produced model embeddingsfor each peak sequence. For the baseline, we computed motif scores using FIMO , whichscans a collection of DNA sequences for occurrences of one or motifs from the HOCOMOCOdatabase described in Appendix C.2. We intersected the motif hits with the peaks using BedTools and constructed bag-of-motifs embeddings for each peak where each entry is the sum of the log10(FIMO q-value) for a particular motif in that peak sequence. We then selected for the mostvariable motifs using a permutation method comparing the sum of the motif across all the peaksin each subsampled peak set. We performed the subsampling procedure 1000 times with eachsubsampled peak set consisting of 100 peaks. (Note that ground-truth labels are not used at any stagewhen constructing baseline embeddings.) We then performed k-means clusterings on each set ofembeddings, with k set to 50. The ability of the clustering to differentiate peaks from different celllines was quantified through the adjusted Mutual Information Score between the cluster labels and thetrue cell line labels for each peak. The Adjusted Mutual Information (AMI) score, a common methodto evaluate clustering results, measures concordance between two sets of labels. Its maximum valueis 1.0, with values close to 0 indicating random labeling and values close to 1 indicating a perfectmatch between clusters and labels. We obtained AMI scores from 100 different k-means clusteringruns and define a conservative 95% confidence interval around the mean as the difference betweenthe mean and the 2.5% quantile or the 97.5% quantile, whichever is greater.",
  "bility) and count data were obtained from the ENCODE consortium for the same set of 5 cell linesused in earlier tasks: GM12878, H1ESC, HEPG2, IMR90, and K562": "ChromBPNet models were trained on the same data and used as our baseline models. We utilized thesame training setup for our probing and fine-tuning models so that inputs and labels were identical tothose for ChromBPNet. Specifically, the ChromBPNet preprocessing pipeline involved filtering peaksto remove read count outliers and then expanding the remaining peaks to size 2,114. In addition toaccessibility peaks, ChromBPNet is also trained on matched negative genomic background sequences.Specifically, for each peak, a negative region was selected from elsewhere in the genome with thesame GC content but does not fall within the peak set. The ratio of peaks to negatives in each trainingbatch is 10:1. Within batches, half the sequences were reverse-complemented, and each sequencewas shifted a maximum of 500bp in either direction, to ensure the area of highest accessibility is notalways at the center of the input. The ground-truth activity for a given input sequence was defined asthe number of read endpoints intersecting the central 1,000 bp. Quantitative predictions were evaluated using the Pearson and Spearman (rank-normalized) correla-tion between the predicted accessibility and measured accessibility. Metrics were computed acrosspeaks only and also across peaks and background sequences. Models were also evaluated basedon their ability to classify peaks from background sequences, quantified by AUROC and AUPRC.For classification metrics, the set of positives was restricted to high-confidence, reproducible peaks,identified using the Irreproducing Discovery Rate (IDR) method that determines whether peaksidentified in replicate experiments are rank consistent and reproducible.",
  "E.5Predicting counterfactual effects of regulatory genetic variants": "A critical challenge in human genetics is predicting how genetic variants affect gene regulationthrough changes in chromatin accessibility. Models trained to predict regulatory activity fromsequence (S2A models) (such as those in .4) are typically used in a counterfactual setting topredict the effects of genetic variants on regulatory activity. This is a particularly challenging tasksince the S2A models are never directly trained on genetic variation data. We evaluated the ability ofDNALMs to prioritize and predict the quantitative effects of regulatory genetic variants that impactchromatin accessibility. Each variant is a single nucleotide polymorphism (SNP) consisting of a pair of alleles, a referenceallele xref {A,C,G,T} and an alternate allele xalt {A,C,G,T}, together with a label y {1,0},indicating whether the variant is a statistically significant chromatin accessibility QTL (dsQTL orcaQTL) or a background variant. All genomic variant coordinates for the caQTL dataset are based onthe human reference genome version GRCh38, whereas variant coordinates for the dsQTL datasetare based on the human reference genome version GRCh37. Each allele of a variant was scored by taking a sequence of length 2114, where the variant allele wasplaced in the center of a 2114-length sequence, with the remaining sequence provided as context.Both sequences, with reference and alternate alleles respectively, were passed through the model toobtain scores for each. In the zero-shot embedding setting, given reference and alternate alleles, two embeddings werecomputed, and the cosine distance between the embeddings was used as the allelic effect score of thevariant. In the zero-shot likelihood setting, the variant position was masked out and the likelihoodsat the mask token with respect to the reference and alternate alleles are compared. In supervisedsettings, we evaluated the predicted counts log fold change between the two alleles.",
  "ModelVariantParametersRuntime (ms)Memory (GB)Runtime (ms)Memory (GB)": "Caduceusps_131k_d-256_n-167,725,568239.67 1.111.07 0.00834.78 3.6740.82 0.00DNABERT-2117M117,069,313104.17 2.061.59 0.03325.93 6.748.81 0.17GENA-LMbert-large-t2t336,658,433194.04 5.473.17 0.02502.53 13.5418.35 0.73HyenaDNAlarge-1m6,550,78459.51 0.570.94 0.00174.08 3.777.57 0.00Mistral-DNAv1-1.6B-hg381,607,677,440129.63 7.419.35 0.03351.36 13.5414.69 0.24Nucleotide Transformerv2-500m-multi-species494,134,738289.58 0.764.44 0.00733.30 2.1222.21 0.00 DNALM resource requirements per batch of 64 sequences of length 2114 bp. Statistics are displayed as mean standard deviation. Valuesinclude each models classification head. Gradients were computed for all model parameters when measuring training resource requirements.This evaluation was conducted on an Nvidia L40S GPU."
}