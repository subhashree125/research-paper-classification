{
  "Abstract": "Capitalizing on the complementary advantages of generative and discriminativemodels has always been a compelling vision in machine learning, backed by agrowing body of research. This work discloses the hidden semantic structure withinscore-based generative models, unveiling their potential as effective discriminativepriors. Inspired by our theoretical findings, we propose DUSA to exploit thestructured semantic priors underlying diffusion score to facilitate the test-timeadaptation of image classifiers or dense predictors. Notably, DUSA extracts knowl-edge from a single timestep of denoising diffusion, lifting the curse of MonteCarlo-based likelihood estimation over timesteps. We demonstrate the efficacy ofour DUSA in adapting a wide variety of competitive pre-trained discriminativemodels on diverse test-time scenarios. Additionally, a thorough ablation study isconducted to dissect the pivotal elements in DUSA. Code is publicly available at",
  "Introduction": "The combination of generative and discriminative modeling has always been appealing due to theirdistinct nature in data comprehension . Discriminative models are adept at making accuratepredictions on training data , but can be fragile when confronted with unseendata . This vulnerability can be attributed to their tendency to learn spurious correlation as ashortcut, hindering their transferability . Generative models, however, are proficient in capturingthe underlying structure of the data, giving them an edge in grasping the whole picture andenhancing robustness . Prior works have verified the effectiveness of generative objectives indiscriminative learning , yet the utilization of pre-trained generative models is under-explored. The recent surge of diffusion models has ignited interest in adopting them for applicationsbeyond image generation . In the context of test-time adaptation, a pre-trained taskmodel is updated on the fly to make accurate predictions on incoming target samples without access totheir labels. This presents challenges, as the target data distribution may differ from that encounteredduring pre-training. The literature reveals that we can not only extract discriminative features fromcapacious diffusion models , but also convert these models into generativeclassifiers that demonstrate human-level generalization on out-of-distribution samples .Such properties render them viable choices for facilitating the test-time adaptation of discriminativemodels, which may underperform on unseen data . Diffusion-TTA ranks among the first",
  "arXiv:2501.00873v1 [cs.CV] 1 Jan 2025": "to employ diffusion models for test-time adaptation, where task outputs are used to modulate theconditioning of a diffusion model with the objective of likelihood maximization. While Diffusion-TTA is competitive, theres still room to unleash the full potential of diffusion models. To achieve this,two key aspects warrant further exploration. First, the conditioning space is typically low-dimensionalin diffusion models , which restricts its ability to capture the intricacies of complex data andthus impedes its expressiveness as a discriminative prior. Further, the common image-level conditionlacks a fine-grained connection with data, limiting its potential in guiding dense prediction tasks.Conversely, the high-dimensional latent space of diffusion models exhibits a surprisingly interpretablesemantic structure , making it a good fit for assisting discriminative tasks andeasily extensible to dense prediction. Second, Diffusion-TTA is heavily reliant on the Monte Carlomethod over as many as 180 timesteps to estimate a biased approximation of likelihood ,resulting in high computational complexity proportional to sampled timesteps. With this work, we aim to boost test-time adaptation performance by digging into the semanticstructure of diffusion models in the latent space, while lifting reliance on the Monte Carlo samplingof timesteps. Although a few works elucidate the semantic properties of the latent space ,they all take a generative viewpoint and are not tailored for discriminative tasks. We instead departfrom the perspective of score functions on the latent space, which is closely related to thedenoising diffusion formulation . Our method features exploring the structured semanticpriors underlying DiffUsion models as Score estimators for test-time Adaptation (DUSA). Concretely, we start by providing a theoretical illustration of the semantic structure underneath thescore functions x log p(x | y), where the conditional probability p(y | x) is implicitly embedded.The theoretical findings not only unveil discriminative priors hidden within score-based diffusionmodels, but applies to every single timestep and avoids likelihood estimation. A test-time objective isthen derived by substituting the pre-trained task model and diffusion model for the implicit priors andscore functions, respectively. Intuitively, the precise score estimation by diffusion models forms awell-structured semantic space, where the task model can learn implicit discriminative priors. Giventheir generative nature, the priors are further blessed with improved robustness, ultimately benefitingtask prediction. Another key advantage of our approach lies in shifting computational complexityfrom timesteps to the number of classes, which aligns closely with our focus on discriminative tasks.Thereby, a more efficient adaptation scheme can be enabled through our practical designs. Besides, the capacity of our DUSA is testified across a variety of task model families, test-time adapta-tion protocols, and task categories. Our DUSA consistently outperforms the competitive counterpartsin adapting pre-trained classifiers with different backbones to out-of-distribution scenarios, whetherin the mild protocol of data from a single domain or the more challenging one with a continuallychanging datastream . We also showcase the versatility of our DUSA by applying it almost as-isto test-time semantic segmentation. All diffusion models employed are trained on the correspondingsource domain of the task model. Extensive analyses of the components in our method back thevalidity of DUSA and underline the benefits of borrowing knowledge from generative modeling.",
  "Preliminaries": "Test-time adaptation.A model well-trained on source data can face severe performance degra-dation on out-of-distribution (OOD) target samples. To tackle this, test-time adaptation (TTA) is proposed to boost model performance at inference time. Formally, an off-the-shelf model f(x)pre-trained on labeled source data DS = {(xi, yi)}Ni=1 is adopted as the task model, where the sourcedata follows a probability distribution xi PS(x) and is inaccessible during adaptation. TTA aims",
  "Backprop": ": Overview of DUSA. Our method adapts a discriminative task model f with a generativediffusion model . Given image x0 at test-time, the task model outputs logits. To improve efficiency,we devise a CSM to select classes to adapt and return their probabilities (probs). The embeddings ofthe classes are then queried as diffusion model conditions, yielding conditional noise predictions fromnoisy image xt. The aggregated noise , is then constructed from ensembling conditional noiseswith probs, which is aligned with the added noise following Eq. (10). Both models are updated. at pushing the limits of model performance on unlabeled target data DT = {xj}Mj=1 on the fly, wherethe target data follows xj PT (x) and PS(x) = PT (x). With batched target data arriving online,we obtain predictions from the task model f(x) and update it on live target samples without labels. Diffusion models.Diffusion models excel at modeling data distribution p(x) by learning to restorethe gradually destroyed data structure . For diffusion models, a forward and a reverseprocess is defined. In the forward process, small Gaussian noise is iteratively applied to real data x0:",
  "Structured Semantic Priors in Diffusion Score for Test-Time Adaptation": "In this section, we first review a relevant method (Sec. 3.1), then provide the theoretical insight behindour DUSA (Sec. 3.2). At last, we advocate a few practical designs with efficiency in mind (Sec. 3.3).The framework of our DUSA is illustrated in . Given a pre-trained task model, a set of classesto optimize is selected by the Candidate Selection Module (CSM) based on task model prediction toimprove adaptation efficiency. We focus on the selected classes and aggregate the conditional noiseestimations with CSM-modulated probabilities on these classes, upon which our DUSA objective isconstructed. The structured semantic priors of the diffusion model are then propagated to the taskmodel through our objective. For more details please refer to Alg. 1 in Appendix E.",
  "Diffusion-TTA takes the first step in exploring conditional diffusion models for test-time adapta-tion. In Diffusion-TTA, the task model prediction p(y | x0) is integrated with class embeddings": "{cy}Ny=1 to get a soft condition c = y p(y | x0)cy, where N is the number of classes. The sample-wise adaptation is performed with the diffusion loss: L(, ) = Et, (xt, t, c)22. Inspiredby , the loss is averaged over hundreds of (t, ) pairs to remedy the performance degradationcaused by incorrect class prediction using a single timestep , at the cost of reduced efficiency.",
  "Unlocking the Discriminative Power of Conditional Diffusion Models": "Unlike previous attempts that rely heavily on a massive number of timesteps to provide an appropriateestimation of likelihood p(x | c) , we shed light on the semantic structure underneath thedenoising capability of conditional diffusion models from the perspective of score functions , which will be shown to hold for every single timestep. Proofs can be found in Appendix C. We first present our main theoretical contribution to reveal the semantic structure of score functions:Proposition 1. Let p(x) and {p(x | y) : y Y} be continuously differentiable probability densities,their score functions x log p(x) and {x log p(x | y) : y Y}, the following equation holds:",
  "y p(y | x)x log p(x | y).(4)": "Remark. The equation holds under mild assumptions about the densities but applies to any data xwith an entire set of conditions {y : y Y}. All score functions can be estimated by score matchingor denoising diffusion. Note that the posteriors {p(y | x) : y Y} are not directly modeled, andthus can be seen as the implicit priors hidden in the construction of (conditional) score functions. To link our Proposition 1 with a trained diffusion model, we revisit Tweedies Formula , whichserves as a key connection between score functions and the formulation of diffusion models :Lemma 1 (Tweedies Formula). Let z | z N(z; z, z), then the posterior expectation of zgiven z can be estimated by:E[z | z] = z + zz log p(z).(5) As Eq. (2) indicates q(xt | x0) = N(xt; tx0, (1 t)I), we have the following corollary:Corollary 1. Let N(0, I) be a sampled noise in a forward process parameterized by {t}Tt=1 toget noisy data xt, the connection between score function xt log p(xt) and noise can be given by:",
  "y p(y | xt)(xt, t, cy),(9)": "where all score functions are now replaced by noise predictors. Note that p(y | xt) is the implicit priorof a conditional diffusion model at a single timestep t, and thus can be learned by directly pluggingthe task model prediction on x0, dubbed as p(y | x0), into Eq. (9). The objective to minimize is:",
  "y p(y | x0)(xt, t, cy)22.(10)": "Intuitively, the optimization of this objective encourages the task model to extract knowledge fromthe semantic structure of a capacious diffusion model, promising better robustness for adaptation.Corollary 2. The objective in Eq. (10) is extensive to x0-prediction or v-prediction in diffusion. With a total of K classes and T timesteps and computational burden primarily borne by diffusionmodels, our DUSA shows a task-relevant time complexity of O(K), while that of Diffusion-TTA isthe diffusion-relevant O(T). Enhanced by practical designs in Sec. 3.3, we empirically find that ourDUSA establishes leading performance even with a small budget, leaving Diffusion-TTA behind. Free lunch in modern diffusion models.The proposed objective in Eq. (10) requires the jointtraining of task model f(x) and diffusion model (xt, t, cy) over all conditions {cy : y Y}simutaneously. The training inefficiency largely stems from the excessive adaptation of the diffusionmodel, which may not always require knowledge from the task model. Indeed, Eq. (10) can be interpreted from two distinct perspectives. From one viewpoint, the taskmodel extracts knowledge from the implicit priors of the diffusion model. From another, a weightedoptimization is applied to conditional noise estimations, allowing the diffusion model to adapt to theincoming test-time data based on task model predictions. Alternatively, the adaptation of diffusionmodels can be achieved by introducing unconditional noise estimations with null condition :",
  "y p(y | xt)(xt, t, cy),(12)": "where (xt, t, ) and {(xt, t, cy) : y Y} represent noise estimations from a specific diffusionmodel capable of handling both unconditional and conditional generation. Note that the implicit priors{p(y | xt) : y Y} in Eq. (12) serve as a critical link between the unconditional and conditionalnoise estimations. Therefore, an unconditional adaptation of the diffusion model implicitly facilitatesits conditional adaptation to the test-time scenario, without reliance on the task model. Modern conditional diffusion models maintain their unconditional generation capabilityby employing an additional null condition that replaces the original class conditions with a certainprobability (typically 10%). Leveraging this feature, we can adjust the objective to enhance efficiency:",
  "y p(y | x0)(xt, t, cy)22,Luncond() = E (xt, t, )22,": "LDUSA-U(, ) = Lcond() + Luncond(),(13)where the diffusion model is now unconditionally adapted. An immediate concern is whether suchmodifications would impact adaptation performance. We empirically find it can significantly boosttraining efficiency with minor to no performance degradation, please refer to Sec. 4.1 for more details. Readily applicable to dense prediction tasks.It is worth noting that our method is not confined toclassification tasks, but can be easily applied to a handful of dense prediction tasks as well. Takingsemantic segmentation as an example, the task model p(y | x0) is now a dense labeler assigningper-pixel class labels to the input, where y is the predicted segmentation map of shape H W K,HW is the size of input image x0, and K is the number of interested classes. Again, our propositionis nowhere strict on the form of data, and therefore should be readily applicable to every singlepixel in x0. The new objective to minimize is then easily obtained by utilizing Eq. (4) in a per-pixelfashion:",
  "k=1 p(y | x0)h,w,k (xt, t, ck)h,w22,(14)": "where (h, w) denotes the pixel location in an image sample of size H W, and ck represents the classembedding of a class k in the segmentation task. We highlight that per-pixel noise can be efficientlyacquired by extracting elements from the image-level noise estimation (xt, t, ck), which takes theentire data sample xt and class-wise condition ck as inputs. As a vast majority of diffusion models aretrained with image-level annotations, this design is advantageous as it allows the use of off-the-shelfdiffusion models without modifying their training schemes. In contrast, Diffusion-TTA requiresthe integration of per-pixel conditions into diffusion models to accommodate dense prediction tasks.",
  "Improving Adaptation Efficiency with Practical Designs": "Identifying appropriate timestep.Since our DUSA intends to extract structured semantic priorsfrom a single timestep, a critical question emerges: which timestep should we utilize to maximizeadaptation performance? Iterating over all T timesteps for a certain task model on a specific task isjust not practical, and thus a universal preference must be advocated. While the semantic structureuncovered in Eq. (4) is valid for all timesteps in theory, the estimation of score functions by denoisingdiffusion models can be unreliable. As pointed out by , for diffusion models we have a scheduled t decreasing with t and t 1 when t 0, which directly amplifies error in scoreestimation by Eq. (9) at smaller timesteps. A large timestep is also not recommended, as denoising athigher noise levels is more challenging , posing a greater challenge to score estimation. Based onthe preceding conclusions, we select timestep t = 100 and find it suits well for all our experiments. Utilizing task model for candidate selection.Similar to Diffusion Classifiers , our DUSAhas a computational complexity that scales proportional to class number. To circumvent the slowdownby a large number of classes, we utilize task model prediction to significantly improve adaptationefficiency. With the observation that classifiers typically maintain a top-k accuracy and top-1accuracy is our main concern in the test-time adaptation of discriminative models, we opt to applyour DUSA to the most promising classes. Specifically, we deem the posterior p(y | x) of less likelyclass candidates to be zero and only optimize the semantic structure among the selected classes. A mere decrease in class number can lead to optimization issues, as the task model can be biasedtowards certain classes, especially with a small batch size. This can be blamed on the underutilizationof the semantic structure, further exacerbated by the erratic task model prediction on the prunedclasses due to a lack of constraints. To tackle this, we devise a Candidate Selection Module (CSM). Inthe module, we first adopt LogitNorm to force constraints on the pruned classes to stabilizetraining, where the logits output of the task model are 2 normalized before selection. Intuitively,we discourage the optimization in the magnitude of logits to mitigate overconfidence, especially onpruned classes. Then we handle the class bias problem by introducing randomness in selection. Indetail, with a selection budget b = k + m, we split it into two parts: k for top-k classes select, andm for a multinomial selection without replacement from the remaining classes, where the samplingprobabilities are calculated from the logits before normalization. We only focus on the selected bnormalized logits, and apply softmax to get their probabilities for our DUSA objective. After a seriesof practical designs, we succeed in reducing the time complexity of DUSA from O(K) to O(b),where a small b should be valid for a large number of classes, as will be shown in Sec. 4.4.",
  "Experiments": "Datasets and models.Our experiments are conducted on three benchmarks: ImageNet-C forfully and continual test-time classification, ADE20K with corruptions defined in (dubbedas ADE20K-C) for test-time semantic segmentation. All image corruptions are at the highestseverity level 5. We use ResNet-50 , ViT-B/16 , ConvNeXt-L pre-trained on ImageNet forImageNet-C experiments, and SegFormer-B5 pre-trained on ADE20K for ADE20K-C ones. Wefollow and use the GN variant of ResNet-50 for stability. More details are in Appendix F.1. Compared methods.We compare our DUSA with Tent , CoTTA , EATA , SAR ,RoTTA , and Diffusion-TTA for image classification. For semantic segmentation, wecompare with BN Adapt , Tent and CoTTA . More details are in Appendix F.2. Evaluation metrics.Top-1 accuracy (Acc) is reported on each corruption type for image classifi-cation. For semantic segmentation, the mean Intersection-over-Union (mIoU) is reported. The mainresults of our DUSA all come with mean and standard deviation statistics over 3 independent runs. Implementation details.The batch size is 64 for test-time classification tasks unless otherwisestated. Following , we use Adam optimizer with a learning rate of 0.00001 for our DUSAand Diffusion-TTA. For other baselines, SGD with momentum 0.9 or Adam optimizer is used in linewith the literature . As for test-time semantic segmentation, the batch size is 1 and Adamwith a learning rate of 0.00006/8 is used, following . We use ImageNet trained DiT and ADE20K trained ControlNet as diffusion models. More details are in Appendix F.3.",
  "Fully Test-Time Adaptation of ImageNet Pre-trained Classifiers": "shows our DUSA in comparison with relevant methods under the online setting of test-time adaptation to every single corruption domain in ImageNet-C, also known as fully TTA .Generally, our DUSA and Diffusion-TTA both achieve a substantial performance gain, thanks tothe knowledge from a capacious generative diffusion model. Sepecifically, our DUSA yields asignificant improvement of +21.9%, +23.3%, +15.7% on ResNet-50, ViT-B/16, and ConvNeXt-Lover pre-trained classifiers. Besides, DUSA consistently outperforms the multi-timestep enhanced",
  "Diffusion-TTA by +2.0%, +4.5%, +5.1% on these classifiers, justifying the exploration of semanticpriors underneath the diffusion score estimations and demonstrating a clear superiority of our DUSA": "Furthermore, a thrilling finding is that our DUSA is not reliant on the integration of task modelprediction in objective Eq. (10) to maintain the powerful semantic priors implicitly embedded. In, we provide the adaptation results from Eq. (13), namely DUSA-U. Despite the diffusionmodel being trained unconditionally in DUSA-U and thus having no chance to borrow knowledgefrom task models, the performance is still on par with DUSA. This reinforces our conviction thatdiffusion models inherently possess such semantic priors, even without explicit inclusion of taskmodels. Although DUSA-U is more lightweight (diffusion model only trained on null condition), westick to DUSA when benchmarking against Diffusion-TTA to ensure fairness in the training budget b.",
  "Continual Test-Time Adaptation of ImageNet Pre-trained Classifiers": "We also experiment under the online continual test-time adaptation protocol, where the task modelshould adapt to continually changing scenarios . The outcomes are reported in . Our DUSAwithstands a long period of adaptation and outperforms Diffusion-TTA by a large margin of +7.3%on ConvNeXt-L. During adaptation, Diffusion-TTA witnesses a performance drop when the OODdatastream type shifts from Weather (Brit.) to Digital (Contr.), while our DUSA shows remarkableadaptation stability. This suggests that DUSA effectively learns from robust and transferable semanticpriors from score-based generative modeling, allowing it to shine over prolonged adaptation.",
  ": Visualization of segmentation results on ADE20K-C. From left to right: clean and corruptedimages, results of the source model, BN Adapt, Tent, CoTTA, our DUSA, and ground-truth labels": "the results in . Notably, previous methods fail on most tasks, except for CoTTA which achievesmodest improvements on a few tasks through a combination of stochastic weight restoration and dataaugmentation. For all tasks involved, our DUSA takes the lead by exploiting the semantic priorsfrom the high-dimensional latent space of a pre-trained text-to-image diffusion model, justifyingthe extensiveness of our proposition to a wider range of discriminative tasks beyond classification.Segmentation results for all the methods involved are visualized in . Our DUSA, as shown inthe illustration, showcases its ability to address errors by incorporating semantic priors from diffusionmodels, overcoming a limitation faced by other methods that depend solely on the task modelsprecision. We provide more visualizations over a wide range of scenarios in Appendix I.",
  "Ablation Study": "Selection of timestep t.As discussed in Sec. 3.2, our DUSA significantly reduces the number oftimesteps to a single timestep of diffusion models. illustrates the influence of timestep selectionon DUSA through adapting the ConvNeXt-L classifier to corruptions from the four main categories.Consistent with our analysis in Sec. 3.3, the guidance from diffusion models is far from perfect whenthe chosen timestep is either too small (t 0) or too large (t T). We empirically find that t = 100shows a good performance here, and generalizes well to other backbones and tasks as well. The othertimesteps, e.g., t = 50, however also emerge as strong contenders and outperform Diffusion-TTA bya considerable margin. For simplicity, we adopt t = 100 in all our experiments.",
  ": Accuracy of ViT-B/16 on JPEG and ResNet-50on Contrast, across different budgets for adaptation": "Effect of components in DUSA.To grasp a deeper understanding of DUSA, we provide a detailedablation of critical designs in , where the number in parentheses means the budget b = k + mallowed for diffusion model forward (D.F.) in Eq. (10), i.e., number of classes to adapt for eachsample. The results are obtained on ResNet-50 and ConvNeXt-L over the corruptions within theNoise category. We also include Pixelate corruption results on ConvNeXt-L to offer a well-roundedunderstanding, upon which the transferability of diffusion models to OOD data is demonstrated.",
  "+ LogitNorm (6)606646.565.170.7+ uniform select (6)426646.265.170.7+ multinomial select (6) (DUSA)426646.365.170.8+ null conditioning (6) (DUSA-U) 427146.164.770.5": "Before adaptation, the source-onlymodels serve as the baseline. In-troducing the objective in Eq. (10)when freezing the diffusion modelbrings about a performance gain of+3.6% on ResNet-50 for Noise, butcauses a degradation of 13% onConvNeXt-L. This is largely dueto the instability from discardingclasses, as pointed out in Sec. 3.3.Applying LogitNorm instantly mit-igates the issue and brings abouta consistent gain of +21.6% and+3.8% against baselines. The im-provement is made without training diffusion models and therefore can be viewed as exploiting thegenerative semantic priors formed in diffusion pre-training. However, the outcomes are still below thebaseline for Pixelate. We conjecture that such corruption might be OOD even for a diffusion modelwith strong robustness. The further adaptation of diffusion models removes this concern, pushingall results to a competitive level. We attribute this finding to the fast convergence of generativemodeling on unseen data, which is favorable to the online nature of test-time adaptation. Again,the inclusion of LogitNorm yields a significantly boosted accuracy at 46.4%, 65.0% and 70.4%. To provide a basis for the further ablation of budget schemes, the budget is raised from 4 to 6 with aslight increase in performance. A mild drop in accuracy is witnessed when handing the class biasproblem in Sec. 3.3 with a budget m = 2 used with uniform sampling, which is then improved by ourmultinomial selection in the penultimate line. We underline that such a design is indispensable for asmall batch size, which is also practical . For better consistency, k = 4, m = 2 are universallyadopted for DUSA in classification, the ratio between them to be delved into below. Interestingly, withaccess to a diffusion model capable of unconditional generation, DUSA-U could achieve performancecomparable to DUSA using Eq. (13), while significantly reducing the computational cost associatedwith diffusion model backward (D.B.). We believe this observation can back our claim of the existenceof structured semantic priors inherently embedded in diffusion models. Specifying a budget scheme.As a justification for our design of the selection strategies in CSM,we take a thorough investigation into the effects of different budget schemes over varied classifiers(ResNet-50 & ViT-B/16) and batch size (4 & 64) in . At a smaller batch size (bs) of 4 (dashedlines), the budget scheme k : m plays a vital role in performance. Concretely, a large k is favorableto weaker task models (ResNets) for eager adaptation, while a proper m is a must to prevent morepowerful ones (ViTs) from overfitting to a subset of classes. When the batch size is increased tothe standard 64 (solid lines), our DUSA becomes insensitive to budget schemes, and a consistentgain is observed for both classifiers. DUSA with b = 4 even exceeds Diffusion-TTA with b = 6,underscoring the advanced efficiency made possible by our proposition and practical designs. For abudget scheme, we find m = 2 competitive across varied b, and stick to k = 4, m = 2 for DUSA.",
  "Related Work": "Test-time adaptation.Test-time adaptation focuses on improving source data pre-trainedmodel performance on out-of-distribution target data without label access during inference time.Early works lay more emphasis on adapting the activation statistics of batch normalization (BN) . Test-time training methods manage to adapt through devising a test-timeself-supervised objective which is also injected into the pre-training stage, resulting in complicatedpipelines and increased computational cost. To lessen dependence on source data and extra loss injection, fully test-time adaptation is advocated to achieve adaptation with only unlabeled targetdata. Concretely, previous works are majorly based on entropy minimization objectives: Tent directly minimizes entropy on batched data predictions, MEMO proposes marginal entropyminimization via data augmentation, EATA pursues a sample efficient entropy minimizationand anti-forgetting regularization, while SAR advocates sharpness-aware and reliable entropyminimization. Other works delve into extensive distributional shifts in TTA , e.g., continualadaptation without forgetting , correlative data streams and label shifts . OurDUSA is much different as it is not reliant on error-prone entropy-based objectives and rather extractsknowledge from semantic priors of generative models for better adaptation of the task model. Generative models for discriminative tasks.The long-standing discussion on the connectionsbetween generative and discriminative models has inspired a handful of attempts tointegrate the two seemingly disparate paradigms . Specifically, a collectionof works showcase the impressive power of generative pre-training followed by supervised fine-tuning . Besides, a few works utilize generative models as zero-shotrecognizers . Integrating generative modeling into the task of test-time adaptation isgaining traction. Prior works manage to boost task model performance with a variety of generativetechniques, including GANs , MAEs , energy-based and flow-based . The recentprevalence of diffusion models with extraordinary generation capability stimulates a range of workson adapting them for discriminative tasks. As for TTA, two distinct research directions arise.Appreciating the generative power of diffusion models, a series of works propose to adaptsamples in the input space . Another largely under-explored direction is to repurposethe generative objective of diffusion models as a proxy of discriminative ability enhancement, withDiffusion-TTA pioneering in incorporating task predictions into the class condition of denoisingobjective in an inversion style. Our DUSA belongs to the latter direction but isfundamentally different from , in that we delve deeper into the semantic priors of diffusionmodels from the perspective of score functions and achieve better adaptability and versatility. Timestep selection in diffusion models.The importance of timestep selection in diffusion modelshas been widely recognized in the literature. In image editing tasks, diffusion models are observed toexhibit a natural coarse-to-fine pattern during the reverse process . Conse-quently, the trade-off between realism and fidelity in editing largely stems from the chosen intervalsof timesteps. In discriminative tasks, timestep selection is also crucial to the quality of extractedfeatures. An early study elucidated the features within diffusion models, revealing that the mostinformative ones are derived from smaller timesteps. Subsequent works have reinforced this findingby utilizing a single small timestep across various tasks, including semantic segmentation, referringimage segmentation, depth estimation , object detection , semantic correspondence ,and one-shot image segmentation . While our DUSA aligns with the existing literature on usinga single timestep, it differs by extracting semantic priors rather than focusing on feature extraction.",
  "Conclusion": "In this paper, we introduce DUSA, a competitive test-time adaptation method built on the structuredsemantic priors underlying diffusion models, which serve as score estimators. A proposition is offeredto unveil the semantic structure in these score-based models, upon which a test-time objective isderived to fully exploit the implicit semantic priors. Our approach is also shown to generalize wellto modern diffusion models and dense prediction tasks. Additionally, we enhance the adaptationefficiency through a few practical designs. The effectiveness of our DUSA is demonstrated acrossthree challenging benchmarks, where it consistently outperforms competing methods. We hope ourmethod will pave the way for better utilization of generative modeling for discriminative tasks.",
  "Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell, and Saining Xie. Aconvnet for the 2020s. In CVPR, pages 1197611986, 2022": "Rinon Gal, Yuval Alaluf, Yuval Atzmon, Or Patashnik, Amit Haim Bermano, Gal Chechik, and DanielCohen-or. An image is worth one word: Personalizing text-to-image generation using textual inversion.In ICLR, 2023. Le Yang, Haojun Jiang, Ruojin Cai, Yulin Wang, Shiji Song, Gao Huang, and Qi Tian. Condensenet v2:Sparse feature reactivation for deep networks. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 35693578, 2021. Le Yang, Yizeng Han, Xi Chen, Shiji Song, Jifeng Dai, and Gao Huang. Resolution adaptive networksfor efficient inference. In Proceedings of the IEEE/CVF conference on computer vision and patternrecognition, pages 23692378, 2020. Ziwei Zheng, Le Yang, Yulin Wang, Miao Zhang, Lijun He, Gao Huang, and Fan Li. Dynamic spatialfocus for efficient compressed video action recognition. IEEE Transactions on Circuits and Systems forVideo Technology, 2024. Le Yang, Ziwei Zheng, Jian Wang, Shiji Song, Gao Huang, and Fan Li. Adadet: An adaptive objectdetection system based on early-exit neural networks. IEEE Transactions on Cognitive and DevelopmentalSystems, 16(1):332345, 2023.",
  "Sara Beery, Grant Van Horn, and Pietro Perona. Recognition in terra incognita. In ECCV, pages 456473,2018": "Robert Geirhos, Jrn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, MatthiasBethge, and Felix A Wichmann. Shortcut learning in deep neural networks. Nat. Mach. Intell., 2(11):665673, 2020. Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan:Interpretable representation learning by information maximizing generative adversarial nets. In NeurIPS,pages 21722180, 2016.",
  "Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba. Scene parsingthrough ade20k dataset. In CVPR, pages 633641, 2017": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, ThomasUnterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, andNeil Houlsby. An image is worth 16x16 words: Transformers for image recognition at scale. In ICLR,2021. Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, and Ping Luo. Segformer:Simple and efficient design for semantic segmentation with transformers. In NeurIPS, pages 1207712090,2021.",
  "ABroader Impacts and Limitations": "Broader Impacts.In this work, an approach to incorporate generative diffusion models into thediscriminative task of test-time adaptation is introduced. The leverage of knowledge from generativemodeling teaches a whole picture of the scenario to the task model, enabling better robustness andadaptability and is thus favorable to some relevant scenarios like medical analysis and quality controlof manufacturing in varying environments. However, the adoption of generative models might comewith a risk of learning from a biased source of knowledge, leading to improper decisions from theadapted task model. A possible remedy for this is to foster the research into more unbiased orbalanced training of generative models. Limitations.Our work presents an effective way of borrowing semantic priors from score-baseddiffusion models to benefit the discriminative task model that demands adaptation at test time withoutlabels. We acknowledge that, as with any research endeavor, limitations exist in our work. Firstly,our competitive method involves a diffusion model pre-trained at least on the same set of sourcedata as the task model, which may not be easily accessible for certain scenarios. However, webelieve such a dilemma can be mitigated with advances in generative diffusion models, whichhave demonstrated remarkable progress in both generality and robustness. Our approach achievessignificant adaptation efficiency gains against prior diffusion-based TTA methods, but there is still agap in the time compared to methods that only update the task model. Therefore, it may not meetextreme efficiency demands in scenarios like autonomous driving. Our method, however, yieldssuperior performance and is thus appealing to another set of tasks where trading a slight loss inefficiency for boosted accuracy is tolerable, e.g., non-emergent medical diagnosis. With this said,we highlight that our theoretical findings are not confined to diffusion models but extensive to allscore-based models, therefore substituting a more lightweight technique in score estimation for thecomputationally expensive diffusion models can be a promising avenue. We leave it for future work.",
  "D.2DUSA": "In contrast, our DUSA approach does not rely on the ELBO for likelihood maximization. Instead, weleverage the structured semantic priors introduced in Eq. (4) to guide the task model in extractingknowledge from the diffusion model using a single timestep. Notably, the only estimations in ourmethod are the noise predictions (xt, t, cy) in Eq. (8), which are provably unbiased.",
  "F.1More Details on Datasets": "ImageNet-C .ImageNet-C consists of corrupted images computed from applying algorithmiccorruptions to the ImageNet validation set, which has 50,000 images. To construct ImageNet-C,15 corruptions that fall into 4 categories are applied separately to the whole validation set, includingGaussian noise (Gauss.), shot noise (Shot), impulse noise (Impl.), defocus blur (Defoc.), glass blur(Glass), motion blur (Motion), zoom blur (Zoom), snow (Snow), frost (Frost), fog (Fog), brightness(Brit.), contrast (Contr.), elastic transformation (Elastic), pixelation (Pixel) and JPEG compression(JPEG). Each corruption type has 5 severity levels and a higher severity level means a more severedistribution shift. We use the highest severity level 5 in all our experiments. ADE20K .ADE20K is a semantic segmentation dataset containing more than 20k imagesannotated with pixel-level labels on instances and object parts, among which 2k images are forvalidation. A total of 150 semantic classes are benchmarked for evaluation. We apply the corruptionsdefined in with tools provided by to construct ADE20K-C, which shares the corruptiontypes with ImageNet-C, at the highest severity level 5. We use this corrupted benchmark for test-timesemantic segmentation tasks.",
  "BN Adapt .BN Adapt has the straightforward idea that the statistics in Batch Normal-ization layers are data-dependent, and therefore can be adapted at test time for better generalization": "Tent .Tent is a pioneer in addressing the fully test-time adaptation problem. In the work,test-time batch normalization is employed to recalibrate the statistics within Batch Normalization,where features are normalized based on the current batchs statistics. Additionally, Tent utilizesentropy minimization to adjust the affine parameters of Batch Normalization layers. CoTTA .CoTTA focuses on performing test-time adaptation for continually changing distribu-tions. Firstly, it generates more robust and reliable pseudo labels through multiple data augmentationsand employs a mean-teacher architecture to reduce error accumulation. Secondly, to prevent catas-trophic forgetting, a stochastic restoration strategy is proposed, which randomly rolls back a portionof the student models parameters. Meanwhile, in the mean-teacher architecture, all the parameters ofthe student model remain trainable. EATA .EATA is devoted to improving efficiency and preventing knowledge forgetting. Con-cretely, the unreliable and redundant test samples are filtered out by the value of prediction entropyand similarity to the mean prediction. Besides, an anti-forgetting regularization based on fisherimportance is proposed. Additionally, only affine parameters in batch normalization layers areadapted. SAR .SAR points out the unreliability of entropy minimization and the instability of BatchNormalization layers during test-time adaptation. Motivated by this, it proposes a sharpness-awareand reliable entropy minimization for Group/Layer Normalization-based models. For time efficiency,only affine parameters in Group/Layer Normalization layers are optimized. RoTTA .RoTTA is dedicated to conducting test-time adaptation on complex test streamscharacterized by continually changing data distributions and temporally correlated label distributions.To begin with, it develops a prediction-balanced sampling strategy grounded in uncertainty andtimeliness, ensuring the maintenance of a robust snapshot of the test distribution for adaptation.Furthermore, a robust batch normalization layer is devised to recalibrate normalization statisticsby applying exponential moving averages to selected samples. Lastly, it introduces a timelinessreweighting strategy to attain stable and robust adaptation. Only affine parameters in robust batchnormalization layers undergo training. Diffusion-TTA .Diffusion-TTA is proposed to adapt pre-trained task models using feedbackfrom pre-trained diffusion models. The integration of the task model into the diffusion modelis achieved by modulating the conditioning of the diffusion model using the output of the taskmodel. With the generative objective of diffusion models, the knowledge is backpropagated throughconditioning to the task model. Hundreds of timesteps are sampled in a diffusion model for a singlesample as an approximation of the likelihood estimation to improve adaptation performance.",
  "F.3More Details on Implementation": "All pre-trained models involved in our paper are publicly available, including ResNet-50 (GN)2, ViT-B/16 (LN)3, ConvNext-L (LN)4, DiT-XL/25 and ControlNet6 based on Stable Diffusion v1.57 fromtimm or their official repository. The classifiers and DiT-XL/2 are pre-trained on ImageNet,while ADE20K is used to pre-train SegFormer-B5 and ControlNet. As for code, we (re)implement all test-time adaptation methods for classification under a frameworkmodified from MMPreTrain , except for Diffusion-TTA we adopt its official implementation.For test-time semantic segmentation tasks, we (re)implement all methods under a framework modifiedfrom MMSegmentation . All experiments performed are with a batch size of 64, except for part of the analysis in .Our DUSA is trained with a batch size of 8 and a gradient accumulation of 8 steps, to yield aneffective batch size of 64. Limited by its implementations, Diffusion-TTA is run with a batch sizeof 1, and a gradient accumulation of 64 steps is applied, also crafting an effective batch size of 64.We follow and use Adam optimizer with a learning rate of 0.00001 (1.0 105) and aweight decay of 0.0 for both our DUSA and Diffusion-TTA, which applies to all classifiers. As forother compared methods, we use Stochastic Gradient Descent (SGD) with momentum 0.9 and alearning rate of 0.00025 (2.5 104) for ResNet-50, while a learning rate of 0.001 (1.0 103) isused for ViT-B/16, in accordance with the literature to obtain decent baseline results.For ConvNext-L, we use Adam with a learning rate of 0.00001 (1.0 105) with a weight decay of0.0 for all methods involved. The diffusion model for classification tasks is a Diffusion Transformer DiT-XL/2 trained on ImageNet from scratch. For all classification tasks on ImageNet-C, weadopt the standard pipeline and center crop images to 224224 for task models. Our DUSA andDiffusion-TTA both use DiT-XL/2 with an input size of 256 256 as the diffusion model, thereforewe resize the cropped 224 224 image to 256 256 before passing it to DiT-XL/2 as input. Duringadaptation, we freeze the VAE encoder and condition embedder of DiT, while training the denoisingtransformer which functions in a latent space of 32 32 4. All parameters of the task models areadapted in DUSA, as is done in Diffusion-TTA and CoTTA. For hyperparameters in DUSA, we set t = 100, k = 4 and m = 2 for all classification tasks. For thesake of fair comparison and practical considerations in compute resources, we give Diffusion-TTAthe same budget b = 6, i.e., 6 timesteps in diffusion models are randomly sampled for the training ofeach image sample, which applies to all results reported on Diffusion-TTA, including those in and . For both our DUSA and Diffusion-TTA that involve diffusion models, the noise addedto input data is randomly sampled. As for other compared methods, we follow all hyperparameters intheir original setup and please refer to their paper for more detailed hyperparameter settings. For test-time semantic segmentation, we follow and use a batch size of 1, Adam optimizer with alearning rate of 0.00006/8 (6.0 105/8) and a weight decay of 0.0 for all methods. The diffusionmodel for this task is a ControlNet finetuned from Stable Diffusion v1.5 on ADE20K.Note that ControlNets come with extra conditioning capability, but we dismiss extra conditionsbeyond text so that it can be recognized as a typical text-to-image diffusion model. In detail, theconditioning of our used ConvNeXt accepts a colored segmentation map as input, and there is a colorrgb(0,0,0) for a background/undefined category, which is not among the 150 ADE20K classes, sowe find it suitable to use all-zero colormaps as the conditioning and regard the ControlNet as onlyreceiving meaningful conditions from texts. While adapting, we again freeze the VAE encodersand text embedder, while training the denoising UNet, along with the ControlNet branch pluggedin. For the task model SegFormer-B5, the input size is 512 512, so we resize the shorter side ofinput images to 512 while keeping the aspect ratio for all methods involved. As for our DUSA, theControlNet requires an input size of 512 512. To get the most of semantic priors from diffusionmodels, we apply a sliding strategy to both ControlNet input (which is a non-square input with a 512short side) and SegFormer output, which aligns the task model forward with compared methods, andthus the sliding on one image is finished in two steps. Note that SegFormer-B5 has a 4 downsamplewhile ControlNet has a 8 downsample, therefore the logits of SegFormer-B5 can be larger than thelatent space of ControlNet, so we further perform a 2 downsample on the logits to prepare for theaggregation of noise predictions in Eq. (14). As we resort to the conventional text-to-image formulation of diffusion models, a whole noiseestimation map is predicted each time a condition is given. This is much different from classificationas the segmentation results are at the pixel level, making an image-level candidate class selectionnon-trivial. Note that LogitNorm is still present before selection, which is applied to the logitsin the channel dimension. We make a little modification to the selection strategy here, instead ofattempting to change the structure of diffusion models as done in , to prove the versatility ofDUSA. Specifically, we allow a budget of 20 classes for each input image, which is also split into atask model-based top-1 selection budget and a random budget, inheriting the spirits of DUSA forclassification. We first gather the unique set of top-1 predicted classes from all pixels. If the number ofgathered classes already exceeds the budget, we randomly suppress the redundant classes. Otherwise,if there is a surplus in the budget, we further perform a random selection from the remaining classesuntil the threshold is reached. The subsequent steps are the same as in classification.",
  "F.4More Details on Compute Resources": "We use Nvidia A6000 GPU with 48GB memory for all our experiments. For faster training, we useAutomatic Mixed Precision with autocasts to fp16 for both classification and semantic segmentation.Additionally for semantic segmentation, gradient checkpointing is enabled for the task model. Fortest-time adaptation on classifiers with a batch size of 8, our DUSA takes around 43GB of memoryand 1.5h training time for a single task (roughly 0.11s per image), while our DUSA-U takes around28GB of memory and 1h training time for a single task (roughly 0.07s per image). For test-timesemantic segmentation with a batch size of 1, we experiment on two Nvidia A6000 GPUs, with atotal of 24GB+44GB=68GB and 2.5h training time for a single task (roughly 4.5s per image). Aswe perform three independent runs for each task, a total of 14 GPU days are required for results in , 3 GPU days for , and 5 GPU days for , accumulating into around 22 A6000GPU days for our main results. Preliminary experiments make the full research project require morecompute than reported, but its non-trivial for us to benchmark them all.",
  "HEnsembling Timesteps in DUSA": "In DUSA, we formulate our approach to extract knowledge from a single timestep, thereby enhancingthe efficiency of adaptation. However, it is intriguing to investigate whether an ensemble of multipletimesteps would further improve performance. We experiment on ConvNeXt-L and present ourfindings in . The results indicate that, while ensembling timesteps does provide benefits, theperformance gains may not be substantial enough to justify the increased computational overhead.",
  "IVisualization of Test-time Semantic Segmentation Results": "We visualize the test-time semantic segmentation results of our DUSA and compared methods in. A model checkpoint is saved after test-time adaptation over a whole corrupted ADE20Kvalidation set. The checkpoint is then used to yield segmentation maps. We show results from fourmain categories of corruption, and segmentation maps are colorized with the ADE20K palette forbetter visual effects. Our DUSA, which exploits the structured semantic priors underneath the score-based diffusion model, shows superior capability in correcting erroneous predictions and providingfine-grained segmentation results.",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  ". Open access to data and code": "Question: Does the paper provide open access to the data and code, with sufficient instruc-tions to faithfully reproduce the main experimental results, as described in supplementalmaterial?Answer: [Yes]Justification: The datasets and pre-trained models used in our work are all from previousworks and publicly available. We have provided dataset details in Appendix F.1, modelweights URLs in Appendix F.3, and reproducible instructions with code attached in thesupplemental material.Guidelines:",
  ". Experimental Setting/Details": "Question: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand theresults?Answer: [Yes]Justification: A brief yet informative specification is provided in Sec. 4. For more details,we specify dataset usage details in Appendix F.1, models, optimizers and hyperparametersdetails in Appendix F.3.Guidelines: The answer NA means that the paper does not include experiments. The experimental setting should be presented in the core of the paper to a level of detailthat is necessary to appreciate the results and make sense of them.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [Yes]Justification: We report all our main results with mean & standard deviation, the results areobtained by independent running over three random seeds for each task.Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
  ". Experiments Compute Resources": "Question: For each experiment, does the paper provide sufficient information on the com-puter resources (type of compute workers, memory, time of execution) needed to reproducethe experiments?Answer: [Yes]Justification: The compute resource are provided in Appendix F.4.Guidelines: The answer NA means that the paper does not include experiments. The paper should indicate the type of compute workers CPU or GPU, internal cluster,or cloud provider, including relevant memory and storage.",
  ". Broader Impacts": "Question: Does the paper discuss both potential positive societal impacts and negativesocietal impacts of the work performed?Answer: [Yes]Justification: We have discussed the potential societal impacts in Appendix A.Guidelines: The answer NA means that there is no societal impact of the work performed. If the authors answer NA or No, they should explain why their work has no societalimpact or why the paper does not address societal impact. Examples of negative societal impacts include potential malicious or unintended uses(e.g., disinformation, generating fake profiles, surveillance), fairness considerations(e.g., deployment of technologies that could make decisions that unfairly impact specificgroups), privacy considerations, and security considerations. The conference expects that many papers will be foundational research and not tiedto particular applications, let alone deployments. However, if there is a direct path toany negative applications, the authors should point it out. For example, it is legitimateto point out that an improvement in the quality of generative models could be used togenerate deepfakes for disinformation. On the other hand, it is not needed to point outthat a generic algorithm for optimizing neural networks could enable people to trainmodels that generate Deepfakes faster. The authors should consider possible harms that could arise when the technology isbeing used as intended and functioning correctly, harms that could arise when thetechnology is being used as intended but gives incorrect results, and harms followingfrom (intentional or unintentional) misuse of the technology. If there are negative societal impacts, the authors could also discuss possible mitigationstrategies (e.g., gated release of models, providing defenses in addition to attacks,mechanisms for monitoring misuse, mechanisms to monitor how a system learns fromfeedback over time, improving the efficiency and accessibility of ML).",
  "Guidelines:": "The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}