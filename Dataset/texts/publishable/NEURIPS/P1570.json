{
  "Abstract": "Most incremental learners excessively prioritize coarse classes of objects whileneglecting various kinds of states (e.g. color and material) attached to the objects.As a result, they are limited in the ability to reason fine-grained compositionalityof state-object pairs. To remedy this limitation, we propose a novel task calledCompositional Incremental Learning (composition-IL), enabling the model torecognize state-object compositions as a whole in an incremental learning fash-ion. Since the lack of suitable benchmarks, we re-organize two existing datasetsand make them tailored for composition-IL. Then, we propose a prompt-basedComposition Incremental Learner (CompILer), to overcome the ambiguous com-position boundary problem which challenges composition-IL largely. Specifically,we exploit multi-pool prompt learning, which is regularized by inter-pool promptdiscrepancy and intra-pool prompt diversity. Besides, we devise object-injectedstate prompting by using object prompts to guide the selection of state prompts.Furthermore, we fuse the selected prompts by a generalized-mean strategy, toeliminate irrelevant information learned in the prompts. Extensive experiments ontwo datasets exhibit state-of-the-art performance achieved by CompILer. Code anddatasets are available at:",
  "Introduction": "Class Incremental Learning (class-IL) gathers increasing attention due to its abilityto make the models learn new tasks rapidly, without forgetting previously acquired knowledge. Yet,traditional class-IL sets a strict limit on the old classes such that they should not recur in newlyincoming tasks. To break such a strict limitation, recent studies develop a new setting mostly calledBlurry Incremental Learning (blur-IL) , where the incremental sessions allow the recurrenceof previous classes, resulting in a more realistic and flexible scenario. Despite such empiricalprogresses on incremental learning, they aim to improve object classification only, while overlookingfine-grained states attached to the objects. For instance, analyzing how the clothing styles (akin tostates) have changed over time is important for forecasting the future trends that will emerge. To simultaneously model objects and their states, some efforts are dedicated to CompositionalLearning whose aim is how to equip the models with compositionality . The core ofcompositional learning lies in the structure of class labels, which conceptualizes a state-object pair(e.g. Brown Pants and Yellow Dress) as a whole, rather than a lonely object label. In this way, themodel can dissect and reassemble learned knowledge, achieving a more fine-grained understandingabout the objects. However, existing works are mainly focused on zero-shot generalization from seen",
  "Shoes": ": Differences between Class Incremental Learning (class-IL), Blurry Incremental Learning(blur-IL), and Compositional Incremental Learning (composition-IL). The object classes are notallowed to recur in the class-IL scenario, whereas they may recur randomly in the blur-IL scenario.Different from them, the classes in composition-IL involve state-object compositions apart from theobject classes. Besides, the compositions do not reoccur, but the primitives (states or objects) mayrandomly reappear across incremental sessions. compositions to unseen ones , whereas none of them consider the challenging fact thatthe model must deal with a significantly larger number of composition classes than object classes. Asa result, it is hardly feasible to learn all compositions by training the model once. To remedy the limitations inherent in incremental learning and compositional learning, we conceive anovel task named Compositional Incremental Learning (composition-IL), enabling the model tocontinually learn new state-object compositions in an incremental fashion. As compared in ,we can see that composition-IL integrates the characteristics of class-IL and blur-IL. Although thecomposition classes are disjoint across incremental tasks, the primitive classes (i.e. objects andstates) encountered in old tasks are allowed to reappear in new tasks. Unfortunately, existing incre-mental learning approaches are challenged by such a compositional scenario, because their modelsexcessively prioritize the object primitives while neglecting the state primitives. Consequently, thecompositions with the same object but with different states become ambiguous and indistinguishable. To tackle the problem, we propose a rehearsal-free and prompt-based Compositional IncrementalLearner (CompILer). Specifically, our model comprises of three primary components: multi-poolprompt learning, object-injected state prompting, and generalized-mean prompt fusion. Firstly, weconstruct three prompt pools for learning the states, objects and compositions individually. Uponthat, we add extra restrictions to regularize the inter-pool prompt discrepancy and intra-pool promptdiversity. This multi-pool prompt learning paradigm strengthens the fine-grained understandingand reasoning towards primitive concepts and their compositions. In addition, as the state classesare more difficult to distinguish than the object ones, we propose object-injected state promptingwhich incorporates object prompts to guide the selection of state prompts. Furthermore, we fuse theselected prompts by a generalized-mean fusion manner, which helps to adaptively eliminate irrelevantinformation learned in the prompts. Last but not least, we also leverage symmetric cross-entropy lossto alleviate the impact of noisy data during training. In summary, the main contributions in this work are encapsulated as follows: (1) We devise a newtask coined compositional incremental learning (composition-IL). It enables learning fine-grainedstate-object compositions continually while the isolated primitive concepts can randomly recur inincremental tasks. (2) To address the lack of datasets, we re-organize two existing datasets suchthat they are tailored specifically for composition-IL. For the two new datasets (Split-Clothing andSplit-UT-Zappos), we split them into 5 and 10 incremental tasks for evaluating the methods. (3)We propose a novel learning-to-prompt model for composition-IL, namely CompILer. Our state-of-the-art results on Split-Clothing and Split-UT-Zappos validate the effectiveness of CompILer forincrementally learning new compositions without forgetting old ones.",
  "Incremental Learning. The approaches to addressing catastrophic forgetting for incremental learningcan be broadly grouped into four categories: regularization based methods aim to protect": ": Data Statistics of Split-Clothing and Split-UT-Zappos for tasking composition-IL. Split-Clothing is divided into a 5-task scenario, while Split-UT-Zappos includes both 5-task and 10-taskscenarios. In all settings, the number of images per task has been balanced properly. influential weights of old experiences from updating; knowledge distillation based methods distill knowledge from the model trained on the previous tasks and adapt it to new tasks; rehearsalbased methods require a memory buffer to store some old data, so as to make thenetwork remember previous tasks; parameter isolation methods allocates different model parametersto each task, to prevent any possible interference. Different from the methods, L2P proposes aninnovative learning-to-prompt paradigm, which incorporates plasticity and stability through adaptinga set of learnable prompt tokens on top of a frozen pre-trained backbone. Inspired by L2P , morerecent works take full advantage of various prompt tuning strategies, achieving newstate-of-the-art performance for incremental learning. However, such methods take into accountobject classes solely, while neglecting various kinds of state classes associated with the objects. Tothis end, our work proposes compositional incremental learning with the purpose to continuallyidentifying the composition classes of state-object pairs. Note that, Liao, et al conduct aninitial study toward the compositionality in incremental learning, whereas their attention is on thecomposition of multiple object classes (e.g. Car and Person) in one image, rather than thestate-object compositions in this work Compositional Learning. A major line of compositional learning research focuses on CompositionalZero-Shot Learning (CZSL) , which aims to infer unseen state-object compositions by acquiringknowledge from seen ones. Subsequent approaches building upon the CZSL setting further incor-porate graph neural networks to model the dependency between primitives and compositions ,and employ cosine classifiers to avoid being overly biased toward seen compositions . Otherapproaches propose training two classifiers to identify states and objects separately. Thelatest works model both composition and primitives simultaneously, achievingstate-of-the-art results. Albeit the numerous attempts made in compositional learning, they fail toconsider an incremental learning paradigm given the increasing number of composition classes inopen-world scenarios. Besides, directly applying CZSL methods to composition-IL might lead toa stale and decaying performance on forgetting. By contrast, our proposed CompILer markedlybypasses catastrophic forgetting with the help of multi-pool prompt learning.",
  "Problem Definition": "For composition-IL, a model sequentially learns N tasks T = {T1, T2, TN} corresponding toa set of composition classes C = {C1, C2, CN}. We note that the composition classes betweenincremental tasks are always disjoint, which means Ci Cj = for any i = j. Different from thecomposition classes, the primitive classes are allowed to recur in different tasks. That means it allowsthe tasks to share some primitive concepts of objects and states. Therefore, we can define the setof all state and object classes with S = {s1, s2, , sn} and O = {o1, o2, , om}, respectively.Given each image x, it has a composition label c which is constructed with a state label s and anobject label o, i.e. c =< s, o >, where c C, s S and o O. We take the example of red shirt,where red is denoted with s, shirt corresponds to o, and red shirt is expressed with c. : t-SNE feature distributions of seven compositions from the Split-Clothing benchmark.For the compositions with the same object but with different states, our CompILer achieves moredistinguishable boundaries than the L2P baseline.",
  "Dataset Construction": "As there are no existing datasets suitable for composition-IL, we re-organize the data in Cloth-ing16K and UT-Zappos50K , and construct two new datasets tailored for composition-IL,namely Split-Clothing and Split-UT-Zappos. To be more specific, we firstly sort the compositionclasses based on the number of their images, and then select the foremost 35 compositions from Cloth-ing16K and the top 80 from UT-Zappos50K, so as to construct Split-Clothing and Split-UT-Zappos,respectively. In this way, Split-Clothing encompasses 9 states and 8 objects while Split-UT-Zapposconsists of 15 states and 12 objects in total. For Split-Clothing, we randomly partition the composi-tions into 5 tasks. Regarding Split-UT-Zappos, the compositions are sorted by count and are evenlydivided into 5 and 10 tasks. The image distribution for each task is shown in . Note that, weelaborate more details on both datasets in the following technical appendix.",
  "Revealing the Ambiguous Composition Boundary": "The main stumbling block in composition-IL is the ambiguous composition boundary. Although thecomposition label consists of two primitives (i.e. object and state), we note that the model excessivelyprioritizes the object primitive while neglecting the state primitive. Consequently, the compositionswith the same object but with different states become ambiguous and indistinguishable. To provethat, we apply L2P to composition-IL, whereas it is challenged by significant ambiguitiesin composition classification. As illustrated in (a), the t-SNE visualization showcases theentanglement among the compositions like white dress, black dress and blue dress. Weconjecture that this ambiguous problem tends to become more severe when more tasks are arrivingincrementally. To address it, we propose a new model namely CompILer, which disentanglescompositions and primitives via a multi-pool prompt learning. Advantageously, our method promotesthe learning on the states and establishes clearer composition boundaries, as shown in (b).",
  "Methodology": "Overview. We leverage the learning-to-prompt paradigm and develop a novel compositionalincremental learner (CompILer) tailored specifically for composition-IL. As depicted in ,CompILer comprises three primary components: multi-pool prompt learning, object-guided stateprompting, and generalized-mean prompt fusion. Firstly, we initialize three prompt pools dedicatedto learning and storing visual information related to states, objects and their compositions. In order todifferentiate the knowledge learned across and within prompt pools, we define inter-pool discrepantloss and intra-pool diversified loss jointly. We then employ object prompts to guide the selection ofstate prompts, thereby improving the state representation learning. Moreover, we utilize a generalized-mean fusion to integrate the selected prompts in a learnable manner. Ultimately, we optimize theclassification objective with symmetric cross-entropy loss, to alleviate the effect of noisy data.",
  "Yellow Dress": ": Overall architecture of our composition incremental learner (CompILer), which comprisesmulti-pool prompt learning, object-injected state prompting, and generalized-mean prompt fusion.The multi-pool prompt learning mechanism captures information related to states, objects, and theircompositions, each through a dedicated pool. The object-injected state prompting utilizes the objectprompt to promote the state representation learning. Moreover, the generalized-mean prompt fusionis used to prioritize the useful prompts and diminish the irrelevant ones. better through adapting a set of learnable tokens in a prompt pool to a frozen pre-trained backbone.Nevertheless, existing prompt-based approaches are initially designed for class-IL, thereby buildinga single prompt pool for object classification solely. when dealing with state-object compositionclassification, they tend to excessively prioritize the object primitive while neglecting the stateprimitive. To this end, we propose to construct three discrepant and diversified prompt pools Ps,Po and Pc, which serve to learn visual information related to states, objects and their compositions,respectively. Besides, each pool is associated with a set of learnable keys K for query-key promptselection. The three prompt pools and their keys are defined as:",
  "where P i RLD is a single prompt with token length L and embedding dimension D. Ki RD,the key of P i, is a learnable token with the same size. M is the number of prompts in each pool": "One important concern in such multi-pool prompt learning is how to enrich the prompts with theavoidance of identical pools. To achieve it, we consider integrating inter-pool prompt discrepancyand intra-pool prompt diversity jointly. On the one hand, the inter-pool prompts should be discrepantas the visual information about states, objects, and compositions should be different. One the otherhand, within each pool, the intra-pool prompts should be diversified so to capture more comprehensivefeatures from all the classes. In practice, we formulate a unified objective to regularize both inter-pool discrepancy and intra-pooldiversity, by leveraging a simple and effective directional decoupled loss used in . The directionaldecoupled (dd) loss between any two pools (e.g. Pi and Pj) is formulated as:",
  ",(3)": "where nm measures the angle between any two prompts, n and m; is a scalar to avoid division byzero. Note that, L(i,j)ddencourages the angles between each prompt to be at least thre degrees. Since(i, j) is unordered Cartesian product of , i.e. (i, j) {(i, j) | i j }, the inter-pool promptdiscrepancy loss for the three pools can be expressed with Linter = L(s,o)dd+ L(s,c)dd+ L(o,c)dd, and theintra-pool prompt diversity loss becomes Lintra = L(s,s)dd+ L(o,o)dd+ L(c,c)dd . As opposed to Linter,Lintra computes the angle between any two prompts within the same pool. Thus, it contains the casewhen n = m, for which we set thre nm = 0.",
  ": Architecture of object-injected stateprompting. Query feature serves as Q, while fusedobject prompt serves as both K and V": "Akin to the query-key matching mechanism inother work , we utilize a fixed fea-ture extractor f() to obtain a query featureq(x) = f(x)[0, :], determining which promptsin the pool to be selected. However, pre-trainedbackbones are typically trained for object clas-sification, thus under-performing for state rep-resentation learning. In addition, it is more dif-ficult to predict the state classes due to theirmore abstract and fine-grained characteristics.To tackle this problem, we strategically injectobject prompts to guide the selection of stateprompts.Intuitively, once we have learnedknowledge about the object class, it may be eas-ier to predict the correct state class and avoidmistaken results. For instance, given an objectis heels, we can expect that the correspondingstate is unlikely to be canvas or plastic. To summarize, we select object and composition promptsin each pool based on the original query feature, which means qo(x) = qc(x) = q(x); but for theselection of state prompts, we propose object-injected state prompting to ameliorate the query featureas shown in . Specifically, we employ the fused object prompt P o (see Sec. 4.3) to perform cross attention on thequery feature q(x), resulting in object-injected query feature qs(x) for the state prompt selection:",
  "qCOS(f(x), Ksi ), {s, o, c} ,(5)": "where COS(, ) denotes cosine similarity, K represents the subset of top-k keys selected from K,and {si}ki=1 is a subset of top-k indices from [1, M] (prompt number). Despite the simplicity of theobject-injected state prompting, it facilitates more judicious prompt selection within the state promptpool, alleviating the hurdles posed by state learning.",
  "Generalized-mean Prompt Fusion": "After obtaining the selected top-k prompts {P si }ki=1, the next step is fusing these prompts intoa single prompt. It is general to utilize a simple mean pooling whereas it overlooks the relativeimportance of each prompt. Besides, when the prompts contain information that is unrelated orcontradictory to current task, it is critical to strengthen useful prompts and eliminate irrelevant ones.To this end, we draw inspiration from generalized-mean pooling and exploit generalized-mean(GeM) prompt fusion which is given by:",
  "Sim-CompILer88.380.088.010.4245.700.6820.060.6233.300.1030.310.03CompILer89.210.247.260.6046.480.2619.270.7534.430.0728.690.82": "Then, we feed xp to a transformer encoder layer fr() and achieve P rs, P ro and P rc for classifyingstate, object and composition classes, respectively. We estimate the probability via a classifier ():p( | x) = (P r). For each image x, we denote its ground-truth distribution over labels withq( | x). When is consistent with the ground truth, then q( | x) = 1; otherwise, q( | x) = 0.As a result, the cross entropy (CE) loss used for classification objective is:",
  "=1q( | x) log p( | x), [|S| , |O| , |C|] ,(7)": "where represents the number of classes. However, the model optimized with a standard CE lossis easily affected by noisy samples during training. Instead, we advocate using a symmetric crossentropy loss (SCE) , which incorporates an additional term called reverse cross entropy (RCE),to mitigate the impact of noisy data. Contrary to CE, the formula for RCE loss is defined as:",
  "Datasets and Metrics": "We conduct experiments on two newly split datasets: Split-Clothing and Split-UT-Zappos as eluci-dated in .2. We assess the overall performance on compositions using Average Accuracy(Avg Acc) and Forgetting (FTT). A higher Avg Acc signifies stronger recognition abilities, while alower FTT indicates improved resilience against forgetting. Additionally, we provide individual Aver-age Accuracy scores on states and objects, denoted as State and Object for simplicity. These metricsimply the ability to recognize fine-grained primitives. Furthermore, we calculate the Harmonic Mean(HM) between State and Object, i.e. HM = 2 (StateObject) (State+Object). We provide more emphasis to AvgAcc and HM due to their more comprehensive assessment. Avg Acc encompasses the plasticity andstability and HM provides a holistic evaluation on both state and object.",
  "Sim-CompILer91.150.1096.320.0293.660.02CompILer91.810.2396.670.0194.180.06": "For a fair comparison with previousworks , we also employViT B/16 pretrained on the Ima-geNet 1K dataset as the feature ex-tractor and backbone. For multi-poolprompt learning, the size of each poolis set to 20, and each prompt has 5tokens. We select top-5 prompts fromeach pool and generate a fused prompt.During training, we utilize the Adamoptimizer with a batch size of16. The whole CompILer undergoestraining for 25 epochs on the Split-Clothing, for 10 epochs on the 5-taskSplit-UT-Zappos, and for 3 epochs onthe 10-task Split-UT-Zappos. For the Split-Clothing and the 10-task Split-UT-Zappos, we set thelearning rate to 0.03, while we use a learning rate of 0.02 for the 5-task Split-UT-Zappos. Notethat, for all the methods, their results are averaged over three runs with the corresponding standarddeviations reported to mitigate the influence of random factors.",
  "As there are a few hyper-parameters in the model, we conduct a rigorous tuning on them. For instance,we set thre to": "2 for all settings. For Split-Clothing, the loss weights 1 and 3 are set to 0.1; 2 isset to 107; and for SCE loss are 0.006 and 0.3, and the parameter during inference is 0.5.For 5-task Split-UT-Zappos, 1, 2, 3, , and are set to 1.0, 3 106, 0.7, 0.01, 0.7 and 0.02,respectively. For 10-task Split-UT-Zappos, 1, 2, 3, , and are set to 0.5, 107, 0.1, 0.05, 0.4and 0.03. We elaborate more details on hyper-parameter analysis in the appendix.",
  "Compared Baselines": "To demonstrate the effectiveness of the proposed method, we compare CompILer with state-of-the-artincremental learning methods, including prompt-free approaches and prompt-basedmethods . All the methods are rehearsal-free except iCaRL . Note that, due toLGCL relying on CLIP to achieve language guidance at the task level, it is limited by thelength of class names per task. Thereby, LGCL fails to operate on the 5-task Split-UT-Zappos sincethe total length of class names exceeds the limitation. To streamline our CompILer, we further implement a simplified version named Sim-CompILer andreport its results. Sim-CompILer is optimized using cross entropy loss and is comprised solely ofmulti-pool prompt learning and generalized-mean prompt fusion. In other words, we exclude theobject-injected prompting, directional decoupled loss, and reverse cross entropy loss, resulting in alarge reduction of hyperparameters to only , 3, and .",
  "Comparison with the State-of-the-arts": "The compared results on Avg Acc and FTT are reported in . Overall, CompILer consistentlyoutperforms all competitors on Avg Acc by a significant margin. For FTT scores, CompILer excelsprevious methods with 0.32% on the 5-task Split-Clothing and with 0.14% on the 5-task Split-UT-Zappos, while falling behind Dual-Prompt and LGCL for the 10-task Split-UT-Zappos. Wenotice that, the main reason is these methods sacrifice more plasticity for lower forgetting rates.Besides, the number of model parameters in these methods dynamically increases along with moreincremental tasks arriving, whereas our CompILer does not rely on imposing task-specific parametersto reduce the forgetting. We also report the primitives accuracy and their HM in and . Likewise, our methodsurpasses other methods considerably in terms of State and HM. Interestingly, the prompt-freemethods achieve higher accuracy in state prediction than object prediction for Split-Clothing, which is contrary to other results. This is because the states in Split-Clothing are color-related descriptions, which are easier to capture with the help of parameter fine-tuning. The prompt-based methods do not exhibit this phenomenon because their pre-trained backbones are initially",
  "T5": ": Results and analysis. (a) to (c) show accuracy of CompILer on composition, state, andobject for each task in Split-Clothing. The x-axis represents the test stream, and the y-axis denotes thestatus after training the Tk task. Darker background color indicates higher accuracy. (d) displays someimages and their predictions: top row is GT, middle row is CompILer prediction, and bottom row isL2P prediction. Green indicates correct predictions, while red indicates incorrect predictions.",
  "Additional Results and Analysis": "In order to study the repeatability characteristic in composition-IL, we exhibit more results onSplit-Clothing in : in (a), it shows a decreasing trend in composition accuracy along with theintroduction of new tasks; however, the green rectangles in (b) and (c) showcase that the accuracyoccasionally increases as more tasks are learned. We conjecture the reason is mostly attributed tothe re-occurrence of primitive concepts. This forward transfer is critical for incremental learners.We compare the composition predictions between CompILer and L2P in (d). CompILerpredicts all the images correctly, while L2P makes some mistakes, particularly for state labels. Thislimitation arises from an excessive focus on the dominant object primitive, while weakening theattention toward state primitive. Fortunately, CompILer relieves the bias toward object classes, andenhances the perception on state classes.",
  "Conclusion": "In this paper, we have proposed a novel task coined compositional incremental learning (compostion-IL), which is stumbled by ambiguous composition boundary. To tackle it, we develop a learning-to-prompt model, namely CompILer. Our model exploits multi-pool prompt learning to modelcomposition and primitive concepts, object-injected state prompting to improve the selection ofstate prompts, and generalized-mean prompt fusion to eliminate irrelevant information. Extensiveexperiments on two tailored datasets show that CompILer achieves state-of-the-art performance. Inthe future, it is challenging yet potential to consider reasoning multiple state classes per object.",
  "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprintarXiv:1412.6980, 2014": "James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, Guillaume Desjardins,Andrei A Rusu, Kieran Milan, John Quan, Tiago Ramalho, Agnieszka Grabska-Barwinska, et al.Overcoming catastrophic forgetting in neural networks. Proceedings of the national academy ofsciences, 114(13):35213526, 2017. Hyunseo Koh, Dahyun Kim, Jung-Woo Ha, and Jonghyun Choi. Online continual learning onclass incremental blurry task configuration with anytime inference. In International Conferenceon Learning Representations, 2022.",
  "Zilong Li, Yiming Lei, Chenglong Ma, Junping Zhang, and Hongming Shan. Prompt-in-promptlearning for universal image restoration. arXiv preprint arXiv:2312.05038, 2023": "Weiduo Liao, Ying Wei, Mingchen Jiang, Qingfu Zhang, and Hisao Ishibuchi. Does continuallearning meet compositionality? new benchmarks and an evaluation framework. Adv. NeuralInform. Process. Syst., 2023. Yu Liu, Jianghao Li, Yanyi Zhang, Qi Jia, Weimin Wang, Nan Pu, and Nicu Sebe. Pmgnet:Disentanglement and entanglement benefit mutually for compositional zero-shot learning.Computer Vision and Image Understanding, 2024.",
  "Pasko Rakic, Jean-Pierre Bourgeois, and Patricia S Goldman-Rakic. The self-organizing brain:from growth cones to functional networks. Elsevier, 1994": "Sylvestre-Alvise Rebuffi, Alexander Kolesnikov, Georg Sperl, and Christoph H Lampert. icarl:Incremental classifier and representation learning. In IEEE Conf. Comput. Vis. Pattern Recog.,pages 20012010, 2017. James Seale Smith, Leonid Karlinsky, Vyshnavi Gutta, Paola Cascante-Bonilla, DonghyunKim, Assaf Arbelle, Rameswar Panda, Rogrio Feris, and Zsolt Kira. Coda-prompt: Continualdecomposed attention-based prompting for rehearsal-free continual learning. In IEEE Conf.Comput. Vis. Pattern Recog., pages 1190911919, 2023. Filip Szatkowski, Mateusz Pyla, Marcin Przewiezlikowski, Sebastian Cygert, Bartomiej Twar-dowski, and Tomasz Trzcinski. Adapt your teacher: Improving knowledge distillation forexemplar-free continual learning. In Proceedings of the IEEE/CVF Winter Conference onApplications of Computer Vision, pages 19771987, 2024.",
  "Liyuan Wang, Xingxing Zhang, Hang Su, and Jun Zhu. A comprehensive survey of continuallearning: Theory, method and application. IEEE Trans. Pattern Anal. Mach. Intell., 2024": "Qingsheng Wang, Lingqiao Liu, Chenchen Jing, Hao Chen, Guoqiang Liang, Peng Wang, andChunhua Shen. Learning conditional attributes for compositional zero-shot learning. In IEEEConf. Comput. Vis. Pattern Recog., pages 1119711206, 2023. Wenjin Wang, Yunqing Hu, Qianglong Chen, and Yin Zhang. Task difficulty aware parameterallocation & regularization for lifelong learning. In IEEE Conf. Comput. Vis. Pattern Recog.,pages 77767785, 2023.",
  "Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James Bailey. Symmetriccross entropy for robust learning with noisy labels. In Int. Conf. Comput. Vis., pages 322330,2019": "Zifeng Wang, Zizhao Zhang, Sayna Ebrahimi, Ruoxi Sun, Han Zhang, Chen-Yu Lee, Xiaoqi Ren,Guolong Su, Vincent Perot, Jennifer G. Dy, and Tomas Pfister. Dualprompt: Complementaryprompting for rehearsal-free continual learning. In Eur. Conf. Comput. Vis., pages 631648,2022. Zifeng Wang, Zizhao Zhang, Chen-Yu Lee, Han Zhang, Ruoxi Sun, Xiaoqi Ren, Guolong Su,Vincent Perot, Jennifer G. Dy, and Tomas Pfister. Learning to prompt for continual learning. InIEEE Conf. Comput. Vis. Pattern Recog., pages 139149, 2022.",
  "Tian Zhang, Kongming Liang, Ruoyi Du, Xian Sun, Zhanyu Ma, and Jun Guo. Learninginvariant visual representations for compositional zero-shot learning. In Eur. Conf. Comput.Vis., pages 339355, 2022": "Yanyi Zhang, Qi Jia, Xin Fan, Yu Liu, and Ran He. Cscnet: Class-specified cascaded networkfor compositional zero-shot learning. In IEEE International Conference on Acoustics, Speechand Signal Processing, pages 37053709, 2024. Yaqian Zhang, Bernhard Pfahringer, Eibe Frank, Albert Bifet, Nick Jin Sean Lim, and YunzheJia. A simple but strong baseline for online continual learning: Repeated augmented rehearsal.Adv. Neural Inform. Process. Syst., 35:1477114783, 2022."
}