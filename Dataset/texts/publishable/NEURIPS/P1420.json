{
  "Abstract": "We study the problem of learning latent community structure from multiple correlated net-works, focusing on edge-correlated stochastic block models with two balanced communities.Recent work of Gaudio, Racz, and Sridhar (COLT 2022) determined the precise information-theoretic threshold for exact community recovery using two correlated graphs; in particular,this showcased the subtle interplay between community recovery and graph matching. Here westudy the natural setting of more than two graphs. The main challenge lies in understandinghow to aggregate information across several graphs when none of the pairwise latent vertex cor-respondences can be exactly recovered. Our main result derives the precise information-theoreticthreshold for exact community recovery using any constant number of correlated graphs, an-swering a question of Gaudio, Racz, and Sridhar (COLT 2022). In particular, for every K 3we uncover and characterize a region of the parameter space where exact community recovery ispossible using K correlated graphs, even though (1) this is information-theoretically impossibleusing any K 1 of them and (2) none of the latent matchings can be exactly recovered.",
  "Introduction": "Finding communities in networksthat is, groups of nodes that are similaris one of the fundamen-tal problems in machine learning. This task is crucially important for understanding the underlyingstructure and function of networks across diverse applications, including sociology and biology .The increasing availability of network data sets offers the intriguing possibility of improving com-munity recovery algorithms by synthesizing information across correlated networks. However, inmany settings the graphs are not alignedwhich may happen for a variety of reasons, includ-ing anonymization, missing or erroneous data, or simply the alignment being unknownwhichpresents a challenge. Thus graph matchingthe task of recovering the latent vertex alignmentbetween graphsplays a central role in efforts to integrate data across networks. Our work followsan exciting recent line of work at the intersection of community recovery and graph matching.Recently, Racz and Sridhar initiated the study of community recovery in correlated stochas-tic block models (SBMs), focusing on the simplest setting of two correlated graphs with two balancedcommunities. They determined the information-theoretic limits for exact graph matching, whichhas applications for community recovery. In particular, they uncovered a region of the parame-ter space where exact community recovery is possible using two correlated graphs even though itis information-theoretically impossible to do so using just a single graph. Subsequently, Gaudio,",
  "arXiv:2412.02796v1 [math.ST] 3 Dec 2024": "Racz, and Sridhar determined the information-theoretic limits for exact community recoveryfrom two correlated SBMs. This required going beyond exact graph matching and understandingthe subtle interplay between community recovery and graph matching.Gaudio, Racz, and Sridhar posed the question of understanding what happens in the case ofmore than two graphs, which arises naturally in all the motivating examples. For instance, peopleparticipate in numerous overlapping yet complementary social networks, and only by combiningthese can we fully understand and make inferences about society. Similarly, synthesizing informa-tion across protein-protein interaction networks from several related species can aid in inferringprotein functions . The main challenge lies in understanding how to optimally pass informationacross three or more graphs.Our main contribution fully answers this open question by Gaudio, Racz, and Sridhar .Specifically, we precisely characterize the information-theoretic threshold for exact community re-covery given K correlated SBMs, for any constant K. This result highlights an intricate phasediagram and quantifies the value of each additional correlated graph for the task of communityrecovery. In particular, for every K 3 we uncover and characterize a region of the parameterspace where exact community recovery is possible using K correlated graphs, even though (1) thisis impossible using any K1 of them and (2) none of the latent matchings can be exactly recovered.See .2 and Theorems 1 and 2 for details.Along the way, we also precisely characterize the information-theoretic threshold for exact graphmatching given K correlated SBMs, for any constant K. In particular, we uncover and characterizea region of the parameter space where the latent matching between two correlated SBMs cannot beexactly recovered given just the two graphs, but it can be exactly recovered given K > 3 correlatedSBMs. See .2 and Theorems 3 and 4 for details.To prove our results, we study the so-called k-core matching between all pairs of graphs. Recentworks have shown the k-core matching to be a flexible and successful tool in a variety of settingsfor two correlated graphs . Our main technical contribution is to extend this analysis tomore than two graphs. The main difficulty lies in understanding the size of intersections of badsets for k-core matchings for different pairs of graphs. We refer to .3 for details.",
  "Models, questions, and prior work": "The stochastic block model (SBM). The SBM is the most common probabilistic generativemodel for networks with latent community structure. First introduced by Holland, Laskey, andLeinhardt , it has garnered considerable attention and research. In particular, it can be employedas a natural testbed for evaluating and assessing clustering algorithms on average-case networks .The SBM notably displays sharp information-theoretic phase transitions for various inference tasks,offering a detailed understanding of when community information can be extracted from networkdata.The phase transition thresholds were conjectured by Decelle et al. and were provedrigorously in several papers . We refer to the survey for a detailed overviewof the SBM.In this paper, we focus on the simplest setting, a SBM with two symmetric communities. Letn be a positive integer and let p, q be parameters representing probabilities. We constructa graph G SBM(n, p, q) as follows. The graph G has n vertices, labeled by [n] := {1, 2, 3, . . . , n}.Each vertex i is assigned a community label (i) from the set {+1, 1}; these are drawn i.i.d.uniformly at random across i [n]. Let := {(i)}ni=1 denote the community label vector.The vertices are thus categorized into two communities: V + := {i [n] : (i) = +1} andV := {i [n] : (i) = 1}.Given the community labels , the edges of G are drawnindependently between pairs of distinct vertices. If (i) = (j), then the edge (i, j) is in G with probability p; otherwise, it is in G with probability q.Community recovery.In the community recovery task, an algorithm takes as input thegraph G (without knowing ) and outputs an estimated community labeling . Define the overlapbetween the estimated labeling and the ground truth as follows:",
  "b)2/2 denote the so-called Chernoff-Hellinger divergence. Then the information-theoreticthreshold is given byD+(a, b) = 1.(1.1)": "In other words, if D+(a, b) > 1, then exact recovery is possible (and, in fact, efficiently). Thatis, there is a (polynomial-time) algorithm which outputs an estimator with the guarantee thatlimn P(ov(, ) = 1) = 1. On the other hand, if D+(a, b) < 1 then exact recovery is impossible:for any estimator , we have that limn P(ov(, ) = 1) = 0.Correlated SBMs. The objective of our work is to understand how the sharp threshold forexact community recovery varies when the input data involves multiple correlated graphs. To do so,we first define a natural model of multiple correlated SBMs (and see further discussionin .5 about alternative models).We construct (G1, . . . , GK) CSBM(n, p, q, s) as follows, where the additional parameter s reflects the degree of correlation between the graphs (and the number of graphs K is droppedfrom the notation for ease of readability).First, generate a parent graph G0 SBM(n, p, q)with community labels .Subsequently, given G0, construct G1, G2, . . . , GK by independentsubsampling. Specifically, each edge of G0 is included in Gi with probability s, independently ofeverything else, and non-edges of G0 remain non-edges in Gi. The graphs Gi inherit both thevertex labels and the community labels from the parent graph G0. Finally, let 12, . . . , 1K be i.i.d.uniformly random permutations of [n] and let := (12, . . . , 1K). Define G1 := G1 and, for alli {2, . . . , K}, define Gi := 1i(Gi). In other words, for every i > 1 and j [n], vertex j in Gi isrelabeled to 1i(j) in Gi. This last relabeling step mirrors the real-world observation that vertexlabels are often unaligned across graphs. This construction is shown in .An important property of the model is that marginally each graph Gi is an SBM. Since thesubsampling probability is s, we have that Gi SBM(n, ps, qs). Thus, it follows from (1.1) that,in the logarithmic average degree regime where p = a log n",
  "nand q = b log n": "n , the communities can beexactly recovered from G1 alone precisely when sD+(a, b) = D+(sa, sb) > 1.The key question in our work is how to improve the threshold by incorporating more informa-tion as K, the number of correlated SBMs, increases. This question was initiated by Racz andSridhar and then solved by Gaudio, Racz, and Sridhar when K = 2.",
  ": Schematic showing the construction of multiple correlated SBMs (see text for details)": "An essential observation is that, to go beyond the threshold, one needs to combine informationfrom the K graphs G1, . . . , GK through graph matching. Then one can exactly recover the com-munity labels using the combined information, even in regimes where it is information-theoreticallyimpossible to exactly recover given up to K 1 graphs.To be more specific, if were known, then one can reconstruct Gj from Gj and then combinethe graphs G1, . . . , GK to obtain the union graph H, defined as follows: the edge (i, j) is includedin H if and only if (i, j) is included in at least one of G1, . . . , GK. Note that H is also an SBM;specifically, H SBMn,1 (1 s)Kp,1 (1 s)Kq, so (1.1) directly implies that thecommunities can be exactly recovered from the union graph H if1 (1 s)KD+(a, b) > 1.Graph matching. In real applications, the permutations = (12, . . . , 1K) are often notknown. The arguments above highlight the importance of an intermediate task, known as graphmatching: how can one recover the latent permutations given the graphs (G1, G2, . . . , GK)?While here we regard graph matching as an important intermediate step, it is of great significancein its own right, with applications in social network privacy , machine learning , and more.For two correlated SBMs, this problem was resolved by Racz and Sridhar , who proved that theinformation-theoretic threshold for (pairwise) exact graph matching is s2(a + b)/2 = 1. Note thatthis is also the connectivity threshold for the intersection graph of G1 and G2 (see ). Denote",
  "s1 (1 s)K1Tc(a, b) > 1,(1.4)": "which (for K > 2) is weaker than the condition s2Tc(a, b) > 1 implied by .(Moreover,in Theorem 4 we show that the condition in (1.4) is tight for exact recovery of .)Thus,by the discussion above, this gives a sufficient condition for exact community recovery given(G1, G2, . . . , GK) CSBM(n, a log n",
  "s1 (1 s)K1Tc(a, b) > 1and1 (1 s)KD+(a, b) > 1.(1.5)": "The interplay between community recovery and graph matching. The condition (1.5) is,however, not tight. To attain the sharp threshold for exact community recovery given K graphs, weneed to answer the following question: does there exist a parameter regime where exact communityrecovery is possible for K graphs, even though (1) exact graph matching is impossible, and (2)exact community recovery is impossible using only K 1 graphs?For K = 2 graphs, Gaudio, Racz, and Sridhar proved that the sharp threshold for exactcommunity recovery given K correlated SBMs is given by",
  "s2Tc(a, b) + s(1 s)D+(a, b) > 1and1 (1 s)2D+(a, b) > 1.(1.6)": "The condition1 (1 s)2D+(a, b) > 1 is necessary due to the work . The first conditionin (1.6) demonstrates the interplay between community recovery and graph matching. To be morespecific, the first term s2Tc(a, b) is the threshold for exact graph matching given (G1, G2), whilethe second term s(1 s)D+(a, b) comes from community recovery.Our main contribution generalizes this result, determining the exact community recovery thresh-old for K 3 graphs. If1 (1 s)KD+(a, b) > 1, then the sharp threshold is given by",
  "s1 (1 s)K1Tc(a, b) + s(1 s)K1D+(a, b) > 1.(1.7)": "The condition (1.7) also clearly exhibits the interplay between community recovery and graphmatching. The first term comes from graph matching, while the second term comes from communityrecovery, as in the case of K = 2. We refer to .2 and Theorems 1 and 2 for details.Despite the apparent similarity in results, when K 3 the situation differs significantly fromthat of two graphs. The primary challenge lies in the existence of multiple methods for matchingK 3 graphs. When K = 2, there is only a single matching that needs to be recovered fromG1 and G2. In contrast, with three or more graphs, the graphs can be matched pairwise, or tosome anchor graph, or potentially in many other ways. Integrating information across differentmatchings requires substantial additional effort. We present the formal results in the next section.",
  "Then exact community recovery is possible. That is, there is an estimator = (G1, G2, . . . , GK)such that limn P (ov (, ) = 1) = 1": "Combined with Theorem 2 below (which shows that Theorem 1 is tight), this result preciselyanswers an open problem of Gaudio, Racz, and Sridhar . The condition (1.8) is required forexact community recovery for K graphs by . We now focus on the condition (1.9). In theprior work , it is proved that the threshold for exact community recovery for two graphs isgiven by (1.6).The primary contribution of Theorem 1 is to go beyond this threshold as thenumber of graphs K increases.In particular, this showcases that there exists a regime where(1) it is impossible to exactly recover from (G1, G2, . . . , GK1) alone and (2) any exact graphmatching is impossible, yet one can perform exact recovery of given (G1, G2, . . . , GK). Thisrequires developing novel algorithms that integrate information from (G1, G2, . . . , GK) delicatelyand incorporate multiple graph matchings carefully.Here we first provide a detailed discussion of the algorithms for three graphs (G1, G2, G3) CSBM(n, a log n",
  "n , blog n": "n , s), andK2partial k-core match-ings := {ij : i = j [K]}. For any vertex v, define the following graph matching metagraphfor the vertex v, denoted it as MGv. E(MGv) denotes the edge set in the graph MGv. There areK nodes in MGv, where node i represents the graph Gi, and an edge exists between (i, j), thatis, (i, j) E(MGv) if and only if vertex v can be matched in the partial matching ij between Giand Gj. Note that MGv is an undirected graph. This is because of an inherent symmetry in the definitionof a k-core matching, which looks at the k-core of the intersection graph of the two matched graphs.Thus for k-core matchings, a vertex is matched by ij if and only if it is matched by ji. Thisproperty does not necessarily hold for other graph matching algorithms.",
  ". Obtain three pairwise partial almost exact graph matchings 12, 13, and 23 between graphpairs (G1, G2), (G1, G3), and (G2, G3), respectively": "3. For vertices in G1 that are part of at least two matchings, refine the almost exact communitylabeling in Step 1 via majority vote in the (union) graph consisting of edges that appear atleast once in (G1, G2, G3). 4. For vertices in G1 that are part of only 12 (resp. 13), label them via majority vote of theirneighbors labels in the graph consisting of edges that appear only in G1 and not in G2 (resp.only in G1 and not in G3).",
  ". For vertices in G1 that are not part of any of the three matchings or only part of 23, labelthem via majority vote of their neighbors labels in G1": "Each step in the algorithm involves abundant technical details.See .3 for a detailedoverview of the algorithms and proofs. Note that the threshold (1.9) captures the interplay betweencommunity recovery and graph matching, which we now discuss in more detail.The first term in (1.9), which is s1 (1 s)2Tc(a, b) for K = 3, comes from graph matching.In it is shown that for one matching, say 12, the best possible almost exact graph matchingmakes n1s2Tc(a,b)+o(1) errors. Here, we show that it is possible to obtain almost exact matchings 12 and 13 (namely, these will be k-core matchings; see .3 for details) such that the sizeof the intersection of the two error sets is n1s(1(1s)2)Tc(a,b)+o(1), which is a smaller power of n.This quantifies how synthesizing information across graph matchings can reduce errors and thisexponent is precisely what shows up in the first term in (1.9). This observation is important andrelevant for Steps 4 and 5 in the algorithm.On the other hand, the second term in (1.9), which is s(1 s)2D+(a, b) for K = 3, comes fromcommunity recovery. In fact, this term arises from the majority votes in Step 5, where we useonly edges in G1. Note that the nodes that are unmatched by 12 and 13 are, roughly speaking,the isolated nodes in the intersection graphs of G1 and G2, and G1 and G3, respectively. Thus,while we use all edges in G1 in this step, the relevant edges are not present in G2 nor in G3,giving the effective factor of s(1 s)2. By (1.1), the exact community recovery threshold forSBM(n, s(1 s)2a log n",
  "Then exact community recovery is impossible. That is, for any estimator = (G1, G2, . . . , GK),we have that limn P (ov (, ) = 1) = 0": "Impossibility of exact community recovery given K graphs under the condition (1.10) is provedin . Hence, Theorem 2 focuses on proving impossibility for exact community recovery given Kgraphs under the condition (1.11). In particular, condition (1.11) reveals a parameter regime whereexact community recovery from (G1, G2, . . . , GK) is impossible, yet, if were known, then exactcommunity recovery would be possible based on the (correctly matched) union graph.Theorems 1 and 2 combined give the tight threshold for exact community recovery for general Kcorrelated SBMs, see (1.7). exhibits phase diagrams illustrating the results for three graphs.",
  "Threshold for exact graph matching": "The techniques that we develop in order to prove Theorems 1 and 2 also allow us to solve the ques-tion of exact graph matching, that is, exactly recovering = (12, . . . , 1K) from (G1, G2, . . . , GK).In the context of correlated SBMs and community recovery, exact graph matching can be thoughtof as an intermediate step towards exact community recovery. However, more generally, graphmatching is a fundamental inference problem in its own right; see .4 for discussion ofrelated work. We start with the positive direction in the following theorem.",
  "Then exact graph matching is possible. That is, there exists an estimator = (G1, G2, . . . , GK) =(12, . . . , 1K) such that limn P ((G1, G2, . . . , GK) = ) = 1": "Since the condition in (1.12) is weaker than s2Tc(a, b) > 1 (which is the threshold for exactgraph matching for K = 2, as shown in ), Theorem 3 implies that there exists a parameterregime where 12 cannot be exactly recovered from (G1, G2), but can be exactly recovered from(G1, G2, . . . , GK). In other words, it is necessary to combine information across all graphs in orderto recover (and even just to recover 12).The estimator in Theorem 3 is based on pairwise k-core matchings (see .3 for furtherdetails). Roughly speaking, for each pairwise k-core matching the number of unmatched verticesis n1s2Tc(a,b)+o(1); however, we shall show that the number of vertices which cannot be matchedthrough some combination of pairwise k-core matchings is n1s(1(1s)K1)Tc(a,b)+o(1), which is ofsmaller order. Hence, when s1 (1 s)K1Tc(a, b) > 1, then exact graph matching is possible.The following impossibility result shows the tightness of Theorem 3.",
  "Then exact graph matching is impossible. That is, for any estimator = (G1, G2, . . . , GK) =(12, . . . 1K) we have that limn P ((G1, G2, . . . , GK) = ) = 0": "Theorems 3 and 4 combined give the tight threshold for exact graph matching for general Kcorrelated SBMs, see (1.4). We note that, in independent and concurrent work , Ameen andHajek derived the threshold for exact graph matching from K correlated ErdosRenyi randomgraphs; in other words, they proved Theorems 3 and 4 in the special case of a = b.Comparing Theorems 3 and 4 with Theorems 1 and 2, note that there exists a parameter regimewhere exact community recovery is possible even though exact graph matching is impossible.",
  "Overview of algorithms and proofs": "In this section we elaborate on the technical details of the community recovery algorithm, for whichhigh-level ideas were presented in .2. We focus our discussion on the setting of K = 3graphs, which already captures the main technical challenges; we highlight these and explain howwe overcome them. We subsequently explain the generalization from 3 graphs to K graphs. Theoverview of the impossibility proof is discussed as well.k-core matching. We now define a k-core matching , which is used for almost exactgraph matching in Step 2. Given a pair of graphs (G, H) with vertex set [n], for any permutation, we have the corresponding intersection graph G H, where (i, j) is an edge in the intersectiongraph if and only if (i, j) is an edge in G and ((i), (j)) is an edge in H. The k-core estimatorexplores all possible permutations of [n] to seek a permutation that maximizes the size of thek-core of the intersection graph G H; recall that the k-core of a graph is the maximal inducedsubgraph for which all vertices have degree at least k. The output of the k-core estimator is thena partial matching , which is the restriction of to the vertex set of the k-core in G H.One significant advantage of using k-core matchings is a certain optimality property in termsof performance.Specifically, if (G1, G2) CSBM(n, a log n",
  "(b) Fixed s = 0.25": ": Phase diagram for exact community recovery for three graphs with fixed s, and a ,b on the axes. Green region: exact community recovery is possible from G1 alone; Cyanregion: exact community recovery is impossible from G1 alone, but exact graph matching of G1and G2 is possible, and subsequently exact community recovery is possible from (G1, G2); DarkBlue region: exact community recovery is impossible from G1 alone, exact graph matching isalso impossible from (G1, G2), yet exact community recovery is possible from (G1, G2); Pink re-gion: exact community recovery is impossible from (G1, G2) (even though it would be possible if12 were known), yet exact community recovery is possible from (G1, G2, G3); Violet region: ex-act community recovery is impossible from (G1, G2, G3) (even though it would be possible from(G1, G2) if 12 were known); Light Green region: exact community recovery is impossible from(G1, G2), but exact graph matching of graph pairs is possible, and subsequently exact communityrecovery is possible from (G1, G2, G3); Grey region: exact community recovery is impossible from(G1, G2), exact graph matching is also impossible from (G1, G2), but exact graph matching is pos-sible from (G1, G2, G3), and subsequently exact community recovery is possible from (G1, G2, G3);Yellow region: exact community recovery is impossible from (G1, G2), exact graph matching isimpossible from (G1, G2, G3), yet exact community recovery is possible from (G1, G2, G3); Orangeregion: exact community recovery is impossible from (G1, G2, G3) (even though it would be possiblefrom (G1, G2, G3) if were known); Red region: exact community recovery is impossible from(G1, G2, G3) (even if is known). The principal finding of this paper is the characterization ofthe Pink, Violet, Orange, Yellow, Grey, and Light Green regions. be able to match all vertices under the parameter regime that we are interested in; however, everyvertex that it does match is matched correctly with high probability.Community recovery subroutines. The high-level summary of the algorithm is as follows.Since exact community recovery might be impossible in G1 alone, we first obtain an initial estimatewhich gives almost exact community recovery in G1, as described in Step 1. In Step 2, we usepairwise partial k-core matchings with k = 13 to obtain := {12, 13, 23} (see b), whichwe will use to combine information across (G1, G2, G3) to recover communities. Note that eachpartial matching ij only matches a subset of the vertices, denoted as Mij; we denote the setof vertices not matched by ij by Fij := [n] \\ Mij. Subsequently, we split the vertices into twocategories: good vertices and bad vertices, where good vertices are part of at least two",
  ": Schematic landscape of partial matchings over three graphs": "matchings and bad vertices are part of at most one matching (see a). We conduct severalmajority votes among good and bad vertices to do the clean-up after the graph matching phase,where each subroutine is meticulously executed to disentangle the intricate dependencies among(G1, G2, G3) and .Exact community recovery for the good vertices. The major distinction between beinggood and being bad is that good vertices can combine information from all three graphs viatheir union graph (which is denser), whereas bad vertices cannot. Suppose that vertex i is partof 12 and 13 (i.e., i M12 M13). We can then identify the union graph G1 12 G2 13 G3,which consists of edges (i, j) such that (i, j) is an edge in G1 or (12(i), 12(j)) is an edge in G2 or(13(i), 13(j)) is an edge in G3, and i is part of this union graph. Similarly, if i M12 M23, theni is part of the union graph G1 12 G2 2312 G3 that also integrates information from all threegraphs. On the union graph, we can refine the almost exact community labeling by reclassifyinggood vertices based on a majority vote among the labels of their neighbors that are also good,and this reclassification will be correct as long as the condition (1.8) holds.There are many underlying technical challenges and roadblocks in the theoretical analysis. Thekey difficulty arises from the structure of the union graph. It is statistically guaranteed that inG112 G213 G3, all vertices have a community label which is the same as the majority communityamong their neighbors .However, whether this is also the case for G1 12 G2 13 G3 isunclear, since the latter graph is only defined on the good vertices M12 M13. One would like todemonstrate that the removal of bad vertices does not significantly affect the majority communityamong neighbors of good vertices. Prior work addressed a similar problem for two graphs byemploying a technique known as Luczak expansion to F12 to ensure that the vertices inside theexpanded set F12 are only weakly connected to the vertices outside of the expanded set [n] \\ F12.Unfortunately, this method is no longer applicable for correlated SBMs with three or more graphs.Even though the size of the expanded set F12 is orderwise equal to the size of F12, the size of theintersection of the expanded sets F12F13 might not be orderwise equal to the size of F12F13, whichdirectly leads to the failure of the algorithm working down to the information-theoretic threshold.To overcome this challenge, we consider the graph G{[n]\\v} to decouple the dependence of v beingconnected to a vertex w and w being part of the k-core. Applying the Luczak expansion on such agraph for any given v, and through a union bound, we prove that unmatched vertices are containedin the set of vertices whose degree is smaller than a constant, with high probability. This allowsus to quantify the size of F12 F13 and meanwhile directly ensure that good vertices within the",
  ": Schematic showing the meta graph MGv when K = 5": "k-core are only weakly connected with bad vertices.Another hurdle needed to overcome, as stated in , concerns the almost exact communityrecovery in Step 1 which is subsequently used for majority votes. Therefore, it is of great importanceto guarantee that the incorrectly-classified vertices are not well-connected and do not have a greatimpact on majority votes. Consequently, we utilize an algorithm originally developed by Mossel,Neeman, and Sly which allows us to manage the geometry of the misclassified vertices anddemonstrate that the vertices classified incorrectly are indeed only weakly connected.Exact community recovery for the bad vertices. The remaining step is to label thebad vertices. The bad vertices can be further classified into three categories (see a):vertices in F12 F13, which are only matched by 23 or are not matched by any of the threematchings; vertices in F13 F23 \\F12, which are only matched by 12; and vertices in F12 F23 \\F13,which are only matched by 13.Consider the vertices in F12 F13 (the other cases are similar).First of all, as discussedabove, we show that |F12 F13| = n1s(1(1s)2)Tc(a,b)+o(1) with high probability. Consider thegraph G1 \\12 G2 \\13 G3, which consists of the edges (i, j) in G1 such that (12(i), 12(j)) and(13(i), 13(j)) are not edges in G2 and G3, respectively. Due to the approximate independence ofF12 F13 and G1 \\12 G2 \\13 G3, for a vertex i F12 F13 we can calculate the probability of thefailure of the majority vote in the graph G1 \\12 G2 \\13 G3 in a relatively straightforward manner,giving ns(1s)2D+(a,b)+o(1). The factor s(1 s)2 arises from the fact that the edges in this graphare subsampled in G1 and are not subsampled in G2 and G3. Now since a vertex in F12 F13 canhave at most 12 edges outside of F12 in G1 12 G2, and also at most 12 edges outside of F13 inG1 13 G3, the majority vote for i F12 F13 essentially does not change whether it is performedin G1 or in G1 \\12 G2 \\13 G3. Putting all this together, we can bound the probability that themajority vote fails as:",
  "= |F12 F13| P(majority vote fails for a vertex) = n1s(1(1s)2)Tc(a,b)s(1s)2D+(a,b)+o(1)": "Thus, if (1.9) with K = 3 holds, then majority vote will correctly classify all vertices in F12 F13.Generalization to K graphs.For K graphs, we haveK2pairwise matchings to con-sider (see b).We again categorize the vertices as good and bad.The good ver-tices can integrate information across all K graphs through the pairwise partial k-core matchings{ij : i, j [K], i = j}, while bad vertices cannot. To illustrate this concept more vividly, forany vertex v, consider a new metagraph MGv on K nodes, defined as follows: there is an edge between i and j in MGv if and only if v can be matched through ij (see ). If the metagraphMGv is connected, then there exists a path that can connect all of its K nodes. Equivalently, thereexists a set of matchings that allows us to combine information across all K graphs. Subsequently,we quantify the number of bad vertices to be n1s(1(1s)K1)Tc(a,b)+o(1). The remaining analysisfor K graphs can be derived by generalizing the analysis for three graphs.Impossibility proof. As discussed in .2, we focus on the proof of (1.11) for impossi-bility. We compute the maximum a posterior (MAP) estimator for the communities in G1. We showthat, even with significant additional information provided, including all the correct community la-bels in G2, the true matchings ij for i, j {2, 3, . . . , K}, and most of the true matching 12 exceptfor singletons in the graph G1 12 (G2 . . . GK), the MAP estimator fails to exactly recoverycommunities with probability bounded away from 0 if (1.11) holds. The proof is adapted from theMAP analysis in . The difference is that here we are considering K graphs G1, G2, . . . , GK withdifferent additional information provided for the MAP estimator. Given that the MAP estimatoris ineffective under this regime, all other estimators also fail.Exact graph matching threshold.The proof of the exact graph matching threshold isimplicitly present in the proof of the exact community recovery threshold. Essentially, since we showthat the number of bad vertices is n1s(1(1s)K1)Tc(a,b)+o(1), the condition (1.12) implies thatthere are no bad vertices with high probability. Since all vertices are good, and good verticescan integrate information across all K graphs, the latent matchings can be recovered exactly. For theimpossibility result we analyze the MAP estimator and show that, even with significant additionalinformation, including the true matchings {ij : i, j {2, 3, . . . , K}}, it fails if (1.13) holds.",
  "Related work": "Our work generalizesand solves an open question raised bythe work of Gaudio, Racz, andSridhar . Just as , our work lies at the interface of the literatures on community recoveryand graph matching1two fundamental learning problemswhich we briefly summarize here.Community recovery in SBMs. A huge research literature exists on learning latent com-munity structures in networks, and this topic is especially well understood for the SBM . Specifically, we highlight the work of , which identify the precisethreshold for exact community recovery for SBMs with two balanced communities. Our algorithmbuilds upon their analysis, taking particular care about dealing with the dependencies arising fromthe multiple inexact partial matchings between K correlated graphs.Graph matching: correlated Erdos-Renyi random graphs. The past decade has seen aplethora of research on average-case graph matching, focusing on correlated Erdos-Renyi randomgraphs . The information-theoretic thresholds for recovering the latent vertex correspondence have been established for exact recovery , almost exact recovery , and weakrecovery . In parallel, a line of work has focused on algorithmic advances , culminating in recent breakthroughs that developed efficient graph matchingalgorithms in the constant noise setting . We particularly highlight the work of Cullina,Kiyavash, Mittal, and Poor , who introduced k-core matchings and showed their utility forpartial matching of correlated ErdosRenyi random graphs. Subsequent work has shown the powerof k-core matchings as a flexible and successful tool for graph matching . Our work bothsignificantly builds upon these works, as well as further develops this machinery, which may be of 1We note that graph matching has both positive and negative societal impacts. In particular, it is well knownthat graph matching algorithms can be used to de-anonymize social networks, showing that anonymity is different, ingeneral, from privacy . At the same time, studying fundamental limits can aid in determining precise conditionswhen anonymity can indeed guarantee privacy, and when additional safeguards are necessary. independent interest. We also note the independent and concurrent work of Ameen and Hajek whichdetermined the exact graph matching threshold for K correlated ErdosRenyi random graphs .Graph matching: beyond correlated Erdos-Renyi random graphs. Motivated by real-world networks, a growing line of recent work studies graph matching beyond Erdos-Renyi graphs , including for correlated SBMs . The works that are most relevant to ours are , which have been discussedextensively above.",
  "Discussion and Future Work": "Our main contribution determines the precise threshold for exact community recovery from Kcorrelated SBMs, for any constant K. This highlights the power of integrative data analysis forcommunity recovery, yet many open questions still remain.Efficient algorithms. Theorem 1 characterizes when exact community recovery is information-theoretically possible from K correlated SBMs. Is this possible efficiently (i.e., in time polynomialin n)? The bottleneck in the algorithm that we use to prove Theorem 1, which makes it inefficient,is the k-core matching step; the other steps are efficient.In recent work (parallel to ours), Chai and Racz gave the first efficient algorithm forexact graph matching for correlated SBMs with two balanced communities, building on recentbreakthrough results on efficient graph matching algorithms for correlated ErdosRenyi randomgraphs . By a union bound, this result also applies to K correlated SBMs for any constant K.This shows that exact graph matching is possible efficiently whenever s2Tc(a, b) > 1 (i.e., when-ever pairwise exact graph matching is information-theoretically possible) and also s2 > 0.338,where is Otters tree-counting constant.Consequently, using this algorithm for exact graphmatching as a black box, exact community recovery from K correlated SBMs is also possible effi-ciently whenever the following three conditions hold:1 (1 s)KD+(a, b) > 1, s2Tc(a, b) > 1,and s2 > 0.338.However, the main focus of our work is uncovering and characterizing regimes where exactcommunity recovery is possible even though (pairwise) exact graph matching is not (see Theorem 1).Is this possible efficiently? We conjecture that it is. We refer to for further discussion.General block models. We focused here on the simplest case of SBMs with two balancedcommunities. It would be interesting to extend these results to general block models with multiplecommunities.This is understood well in the single graph setting and recent work has alsocharacterized the threshold for exact graph matching for two correlated SBMs with k symmetriccommunities .Alternative constructions of correlated graphs. An exciting research direction is to studydifferent constructions of correlated graph models. For general K, there are many ways that Kgraphs (or K Bernoulli random variables) can be correlated.In particular, the following is anatural alternative construction of multiple correlated SBMs. First, generate G0 SBM(n, p, q).Then, independently generate Hi SBM(n, p, q) for i [K]. Construct Gi := G0 Hi, andfinally generate Gi through an independent random permutation of the vertex indices in Gi. Thisconstruction is equivalent to the one we studied in this paper for K = 2 and it is different when K 3. Investigating the graph matching and community recovery thresholds under this construction isinteresting and valuable.",
  "Organization": "The rest of the paper is structured as follows. First, we elaborate on the recovery algorithm forthree graphs in . includes some useful preliminary propositions, including somenice properties of almost exact community recovery on G1. discusses the k-core estimator.After these preparations, we are ready to prove the main theorems in the paper. proves Theorem 1 for three graphs, where we first validate the accuracy of the com-munity labels for good vertices and then classify the remaining bad vertices. presentsthe proof of the impossibility result (Theorem 2) for three graphs. discusses the recoveryalgorithm for K graphs and provides a general proof for K graphs, with additional arguments onhow to identify good and bad vertices. discusses the proof of the impossibility result(Theorem 2) for K graphs. contains the proof of the threshold for exact graph matchinggiven K graphs, that is, the proofs of Theorems 3 and 4.",
  "ij is injective": "Given a matching (Mij, ij), here are some related notations.Define Gi ij Gj to be theunion graph, whose vertex set is M, whose vertex index is the same as the vertex index of Gi andwhose edge set is {{, m} : , m Mij, Am + Bij(),ij(m) 1}. In other words, the edges arethose that appear in either Gi or Gj. Conversely, Gi ij Gj represents intersection graph, whosevertex set is Mij, whose vertex index is the same as the vertex index of Gi and whose edge set is{{, m} : , m Mij, Am = Bij(),ij(m) = 1}. In other words, the edges are those that appear inboth Gi and Gj. Define Gi \\ij Gj to be the graph Gi minus Gj, whose vertex set is Mij, whosevertex index is the same as the vertex index of Gi and the edges are those only appear on Gi andnot appear in Gj. Definition 2.2. Let Gi and Gj, Gk be three graphs on vertex set [n] with adjacency matrix A, B, C,respectively. The pair (Mij, ij) is a matching between Gi and Gj, while the pair (Mjk, jk) is amatching between Gj and Gk. Denote jk ij as the composition matching between Gi and Gk,defined on the vertex set Mij Mjk.",
  "For three graphs, we can define the additional notations in the same manner as in Definition 2.1": "and the core concepts remain consistent.Gi ij Gj jkij Gk represents the union graph ofGi, Gj, Gk, whose vertex set is M = Mij Mjk, whose vertex index is the same as the vertex indexof Gi and whose edge set is {{, m} : , m M, Am + Bij(),ij(m) + Cjkij(),jkij(m) 1}.In other words, the edge set are the edges that appears in at least one graph out of Gi, Gj, Gk.Similarly, Gi ij Gj jk Gk represents the intersection graph, the edge set is {{, m} : , m M; Am = Bij(),ij(m) = Cjkij(),jkij(m) = 1}. Define Gi ij Gj \\jk Gk be the graph whoseedge set is those edges that appear in either Gi or Gj and not appear in Gk. Similarly, we candefine Gi ij Gi \\jk Gk, Gi \\ij (Gi jk Gk), and Gi \\ij (Gi jk Gk) as well. Note that all thedefinitions above are defined on vertex set M and use vertex index in Gi.Introduce dmin(G) := mini[n] d(i), where d(i) is the degree of vertex i. Definition 2.3. A matching (Mij, ij) is a k-core matching of (Gi, Gj) if dmin(Gi ij Gj) k.A matching (Mij, ij) is called a maximal k-core matching if it involves the greatest number ofvertices, among all k-core matchings.",
  ": Enumerating all possible matchings, find the maximal k-core matching (Mij, ij) of Gi and Gj": "Let (Mij, ij) be the matching found by Algorithm 1 with k = 13. Mij coincides with themaximal k-core of Gi ij Gj, denote it as Mij while ij coincides with the true permutation ij,with high probability (Lemma 4.5).The k-core matching is symmetric, i.e. ij(Mij) = Mji. Note that by Definition 2.1, Mij usesthe vertex index of Gi while Mji uses the vertex index of Gj, they are equivalent and exchangeablethrough the 1-1 mapping. Now define Fij := [n] \\ Mij be the set of vertices which are excludedfrom the matching. Note that Fij use the vertice index same as Gi. We define F ij := [n] \\ Mij bethe set of vertices which are outside the maximal k-core of Gi ij Gj. As briefly discussed in .3, we start with leveraging the good vertices in order to findthe correct communities. The good vertices are those which are part of at least two matchingsout of three partial matchings 12, 13, 23. The details are shown in Algorithm 2.",
  "A useful construction of three correlated stochastic block models": "In this section, we elaborate on an alternative method for constructing three correlated SBMs,which emphasizes the independent regions of G1, G2 and G3. we detail the construction for threegraphs to maintain reasonable and manageable notation throughout our discussion. The extensionof these ideas to the general case of K graphs follows a similar structure where the key steps andarguments can be directly applied. This construction is analogous to the construction from [24,.2], generalizing the case from two graphs to three graphs.Firstly, we construct a random partition {Eijk, i, j, k, {0, 1}} of[n]2. Independently, for eachpair {i, j} [n]2, we let {i, j} {Eijk} with a probability of (1s)3ijksi+j+k. Subsequently, foreach pair {i, j} [n]2, an edge is constructed between i and j with probability p if the two verticesare in the same community, and with probability q if they are in different communities. Graph G1is constructed using the edges from j,k{0,1},i=1Eijk, while the graph G2 is constructed using edgesfrom i,k{0,1},j=1Eijk. Graph G2 is then generated from G2 and 12 by relabeling the vertices ofG2 according to 12. Similarly, the graph G3 is constructed using edges from i,j{0,1},k=1Eijk andG3 is obtained from G3 and 13 by relabeling the vertices of G3 according to 13. This constructionoffers an alternative method for generating multiple correlated SBMs and emphasizes regions ofindependence between multiple graphs. The following lemma 3.2 describes the idea formally. Lemma 3.2. The random partition construction of correlated SBMs in .2 is equivalentto the original construction shown in . Moreover, conditioned on := (12, 13, 23), ,and E := {Eijk, i, j, k {0, 1}}, the graphs that are comprised of edges in disjoint Eijk are mutuallyindependent.",
  "= sa+b+c(1 s)3abcpif a + b + c > 0,1 p + (1 s)3pif a + b + c = 0": "If (i) = (j), the joint distribution is the same only with p replaced by q. We can see that thejoint distribution under two constructions is the same. To prove the second part of the lemma,note that conditioned on , , and the random partition {Eijk, i, j, k {0, 1}}, the edges in Eijkform independently. Hence the graphs that are comprised of edges in disjoint Eijk are mutuallyindependent.",
  "Lemma 3.4. Define sm := mina,b,c{0,1} sabc. We have P(Fc) 100n exp( s2mn2)": "Proof. Denote G holds if and only if n/2 n3/4 |V +|, |V | n/2 + n3/4. The event G is provedin Lemma 3.8 in . P(Gc) 4en.Then, look at the remaining condition of event F. Fix i [n], condition on 1, 12, 13. Notethatk+abc(i) := |{j : j Eabc E+(1(i))}| Bin(|V (i)| 1, sabc).",
  "Analysis of the k-core estimator": "Here we quantify the size of thebad vertices. Suppose that for vertex v, g = {G1, G2, . . . , GL}and b = {GL+1, GL+2, . . . , GK}, here 1 < L < K 1, v cannot be matched for all the match-ings between one graph from a and another graph from b. Apparently, v cannot be matchedfor L(K L) matchings. Heuristically, as the number of mathings that cannot be matched forvertices increases, the size of such vertices decreases, since every matching would match (1o(1))nvertices and only a very small fraction of vertices that cannot be matched. The following lemmademonstrated the claim.",
  "Proof. For a given m >2": "a+b, we would like to prove that any vertex v with degree greater thank + m will not be part of the k-core with probability o(n1). The lemma then follows by a unionbound.Isolating vertex v for independence.For a fixed v [n], consider the graph G := G{[n]\\v}. Now we look at the k-core of G, denote itby Ck( G). Since the degG(v) > k +2/(a+b), we can suppose that degG(v) = m+k, m > 2/(a+b).If the vertex v is not part of the k-core of G, it must has more than m neighbors who are / Ck( G).Note that the event w / Ck( G) is independent of the event w NG(v), while the latter eventis stochastically dominated by a binomial distribution with probability log n/n, = max(a, b).Hence, by the tower rule,",
  "E[1Bin(|{w:w/Ck( G)}|, log n/n)>m] E[1Bin(|U|, log n/n)>m] E[mint>0 exp((et 1) tm)].(4.3)": "To construct U, the idea is motivated by Luczak expansion in . We consider a modifiedversion of expanding the set in our setting.Quantify the set U.Define U to be the set of vertices with degree at most T in the graph G. The choice of Twould be specified later. Denote H := {n/2 n3/4 |V +|, |V | n/2 + n3/4}. By Lemma 3.4,P(Hc) = o(1/n).",
  "+o(1)": "Bound the probability of v being in the k-core.Note that G{[n] \\ U} has minimum degree at least T N. If a vertex i [n] \\ U, then i / U,it follows that i has degree at least T in G. However i can have at most N neighbor in U byconstruction of expansion process, so i must have at least T N neighbors in [n] \\ U. We can setT = k + N, then If i [n] \\ U, i is part of k-core in G.Since the deg(v) m + k, it must has at least m neighbors who are not part of k-core in G.Follow the equation (4.2), (4.3), denote = |U| log n/n, then we have",
  ". Define U0 := U": "2. Given Ut, define U 1t+1 to be the set of those vertices outside Ut which have at least N neighborsin Ut. If U 1t+1 is non-empty, set Ut+1 = Ut{u}, where u is the first vertex in U 1t+1. Otherwise,stop the expansion with the set Ut. Suppose the expansion ends at the step h, hence we have an increasing sequence {Us}hs=0.Denote U := Uh to be the set after expansion.Now claim that on the event Dc D0, we can choose N1, N > 0, such that |U| N1|U|.Suppose that |U| > N1|U|, then there exists > 0 s.t.|U| = N1|U|.On event D0, thereexists > 0, |U| n1, hence |U| = N1|U| n1+o(1).Denote el as the number of edgesin G{U}. Each step in the expanding process, at least N edges are added into the graph, hencee N N(|U||U|) = (N N",
  "Proof. Proved by [24, Lemma 4.13]": "Lemma 4.7. Suppose G1, G2, G3 are independently subsampled with probability s from a parentgraph G SBM(n, a log n/n, b log n/n) for a, b > 0. Let F ij be the set of vertices outside the k-core of Gi ij Gj(taking vertice index in i) with k = 13. Prove that with probability 1 o(1),|F ij F jk| n1(2s2s3)Tc(a,b)+, for any > 0. Proof. |F 12 F 23| = |F 21 F 23| = |F 12 F 13|, by symmetricity of G1, G2, G3.Define Uij to be the set of vertices with degree at most m+k in the intersection graph Giij Gjwhich marginally follows SBM(n, as2 log n",
  "(log n)3t(1 s)2(log n)3P(Xa > (log n)3) n2(log n)2 log(1s)+o(1) = o(n(1(1s)2)sa/2+o(1))": "The first inequality is true because t(1 s)2 decreases when > (log n)3 for sufficiently large n.The last equality is true because (log n)2 log(1 s) < (1 (1 s)2)sa/2 for sufficiently large n.Hence, by summing up the two parts, E[Xta(1 s)2Xa] ns(1(1s)2)a/2+o(1), similarly we canproof E[XLtb(1 s)2Xb] ns(1(1s)2)b/2+o(1). By (4.8) and (4.9),",
  "|NG2G3(12(i) F 23)| < log n/8": "What is left is to bound |NG\\(G2G3)(i) (F 23)|, |NG\\(G1G2)(i) (F 12)|.Note that conditioned on 12, 13, 23, , E := {Eijk, i, j, k {0, 1}}, the graph G \\(G1 G2) isindependent of F 12 by Lemma 3.2, since F 12 depends only on G1 G2. Thus we can stochasticallydominate |NG\\(G1G2)(i) F 12| by a Poisson random variable X with mean",
  "E[(inf>0 em+n(e1))1Z] E[emn 1Z] nm(s2Tc(a,b)o(1))": "Above, the equality on the second line is due to the tower rule and since Z is measurable withrespect to |F j|, the inequality on the third line is due to a Chernoff bound; the inequality on thefourth line follows from setting = log(1/n) (which is valid since n = o(1) if Z holds). The finalinequality uses the upper bound for n on Z. Taking a union bound, we have",
  "D+(a, b)1 + 2(sD+(a, b))1 log n/2": "The first inequality uses Lemma 3.5 that the set of errors are contained in I(G1).The lastinequality is due to Lemma 3.8, 5.4.Notice that majH(i) log n for i [n] \\ (F 12 F 23).Hence, (i) jNH(i) 1(j) majH(i) |(i) jNH(i)(1(j) (j))| log n/2 > 0, whichimplies that the sign of neighborhood majorities are equal to the truth community label for anyi [n] \\ (F 12 F 23), with probability 1 o(1). Then we can convert H to G{[n] \\ (F12 F23)}, thevertices in [n] \\ (F12 F23) are correctly labeled with probability 1 o(1).Using an identical proof, we can argue that the algorithm correctly label all vertices in M13M32and M12 M13.",
  "With high probability, the algorithm correctly labels all vertices that are in Fb": "Proof. For i Fb, define Hi := (G1 \\13 G3 \\12 G2){(M12 M13) {i}}. Let Ei be the event that ihas a majority of at most log n in the graph Hi. Let be the labeling after the step. For bervity,define a nice event based on the previous results. Define the event H, which holds if and only if:",
  "n1(2s2s3)Tc(a,b)s(1s)2D+(a,b)+ log(a/b)/2++o(1)": "Under the condition (2s2 s3)Tc(a, b) + s(1 s)2D+(a, b) > 1, we can choose , small enough sothat the right hand side is o(1). majHi(i) > log n for i F b , by Lemma 4.5, majHi(i) > log nfor i Fb.Suppose that i F13 F12, i has at most 12 neighbors in the graph (G1 12 G2){(M12 M13){i}}, and in the graph (G1 13 G3){(M12 M13) {i}}. Therefore, i has an at least ( log n 24)majority in G1{(M12 M13) {i}}, with high probability. Then, Algorithm 3 correctly label allvertices in F13 F12.Suppose that i F12 F23 \\ F13, i has at most 12 neighbors in the graph (G1 12 G2){(M12 M13) {i}} Therefore, i has an at least ( log n 12) majority in G1 \\13 G3{(M12 M13) {i}},with high probability. Hence, Algorithm 3 correctly label all vertices in F12 F23 \\ F13.Suppose that i F13 F23 \\ F12, i has at most 12 neighbors in the graph (G1 13 G3){(M12 M13) {i}}. Therefore, i has an at least ( log n 12) majority in G1 \\12 G2{(M12 M13) {i}},with high probability. Algorithm 3 correctly label all vertices in F13 F23 \\ F12.",
  "(2s2 s3)Tc(a, b) + s(1 s)2D+(a, b) < 1.(6.1)": "To prove it, we study the MAP (maximum a posterior) estimator for the communities in G1. Evenwith the additional information provided, including all the correct community labels in G2, thetrue matching 23 and most of the true matching 12, the MAP estimator fails to exactly recoverycommunities with probability bounded away form 0 if the condition (6.1) holds.The proof isadapted from the MAP analysis in . The difference is that we are considering three correlatedSBM G1, G2, G3.Since we know the true matching 23, we can consider H := G2 23 G3 SBM(n, (1 (1 s)2)a log n/n, (1 (1 s)2)b log n/n). Denote Rij the singleton in Gi Gj. ThenR = R12 R13 is the singleton set in G1 H.",
  ". If j N1(i), (j) / NH((R))": "Where A, B, C is the adjacency matrix of G1, G2, G3 respectively and D is the adjacency matrixin H = G2 23 G3. Note that D is the adjacency matrix of H, so NH((R)) = {i [n] : k (R), Di,k = 1}.Define R := R 1(NH((R))). The condition 2 and 3 in Definition 6.2 can be replacedby Ai,j = 0 for all j R. Write R = R(12, A, B, C), S = S(12, A, B, C), and R = R12 forbrevity. We study the MAP estimate provided the additional knowledge 2, 23, and 12{[n] \\S}. Theorem 5. Let A, B, C, 2, 23, 12{[n]\\S}, S be given. For i [n]\\S, MAP (i) = 2(12(i)).For vertices in S, the MAP estimator depends on whether a, b is larger:1. If a > b, then the MAP estimator assigns the label +1 to the vertices corresponding to the largest|S V +1 | values in the collection {maj(i)}iS and assigns the label -1 to the remaining verticesin S.2. If a < b, then the MAP estimator assigns the label +1 to the vertices corresponding to thesmallest |S V +1 | values in the collection {maj(i)}iS and assigns the label -1 to the remainingvertices in S.",
  "For brevity, sometimes write A": "Lemma 6.9. For any A, Ai,jB(i),(j)C23((i)),23((j)) = Ai,jB12(i)12(j)C13(i),13(j). More-over, if i S or j S,Ai,jB(i),(j)C23((i)),23((j)) = Ai,jB12(i)12(j)C13(i),13(j) = 0,Ai,jC23((i)),23((j)) =Ai,jC13(i),13(j) = 0,Ai,jB(i),(j) = Ai,jB12(i)12(j) = 0. Proof. If i, j [n] \\ S, then (i) = 12(i), (j) = 12(j), hence Ai,jB(i),(j)C23((i)),23((j)) =Ai,jB12(i)12(j)C13(i),13(j).If i S or j S, by Definition 6.2, i R or j R, henceAi,jB(i),(j)C23((i)),23((j)) = Ai,jB12(i)12(j)C13(i),13(j) = 0, Ai,jC23((i)),23((j)) = Ai,jC13(i),13(j) =0, Ai,jB(i),(j) = Ai,jB12(i)12(j) = 0.",
  "ijk{0,1}p+()ijkijkq()ijkijk": "In particular, the sums ((i),(j))E+(2) B(i),(j)C23(i),23(j), ((i),(j))E+(2) B(i),(j), and((i),(j))E+(2) C23(i),23(j), |E+(2)| are measurable with respect to B, C, 2, 23. Hence wedo not care the relevant value and use to represent. Now, for simple notations we write ABC torepresent ((i),(j))E+(2) Ai,jB(i),(j)C23((i)),23((j)), AB to represent ((i),(j))E+(2) Ai,jB(i),(j),and AC to represent ((i),(j))E+(2) Ai,jC23((i)),23((j)). Then, we can write",
  "Lemma 6.15. If |B(X)| is not empty, then |B(X)| = |S X|!|S X+|!": "Proof. The proof is almost identical to [24, Lemma 8.15].Suppose that 0, 1 B(X), byCorollary 6.12, there exists such that 1 = P0,. Claim: if i S X+, (i) S X+, ifi S X, (i) S X. If i S X+, (i) S X, then 2(0(i)) = 1, 2(1(i)) =2(0((i))) = 1. This violates the definition of B(X). The claim is proved. Hence we candecomposition into two disjoint permutations +, .+ is a permutation of S X+ while is a permutation of S X. Hence |B(X)| = (# of choices of +) (# of choices of ) =|S X+|!|S X|! = |S V +1 |!|S V |!.",
  "b": "Thus, by Lemma 6.17, if a > b, the MAP estimator maximizes iS X(i)maj(i) while the MAPestimator minimizes iS X(i)maj(i) if a < b. Suppose a > b, while satisfying the condition|S X+| = |S V +|, |S X| = |S V |, the maximum of iS X(i)maj(i) is obtainedby setting X(i) = +1 to the vertices i S corresponding to the largest |S V +1 | values in thecollection {maj(i)}iS and assigns the label -1 to the remaining vertices in S. The proof is thesame, suppose a < b. Then Theorem 5 follows.",
  "Proof of Lemma 6.5": "Denote Ei as the event that i is a singleton in G1 12 H, in other words, i R. We assumethat the communities are approximately balanced. More precisely, we assume that the event G ={n/2 n3/4 |V +|, |V | n/2 + n3/4} holds. By Lemma 3.4, we have P(G) = 1 o(1).Conditioning on 1, if i V +1 , then we have",
  "The random variables 1(i S) and j[n]\\ R Ai,j1(j) are conditionally independent given I": "Proof. Note that the sets R, R only depend on 12, H, G1 12 H . G1 \\12 H is comprised ofedges in E100, the graph H is comprised of edges in j+k>0Eijk, the graph G1 12 H is comprisedof edges in j+k>0E1jk. Thus by lemma 3.2, G1 \\12 H is conditionally independent of R, R given, 1 and the partition E. In particular, {Ai,j : {i, j} E100} is conditionally independent of I.Note that 1(i S) = 1(i R)1(Ai,j = 0, j R). Hence 1(i S) is measurable withrespect to the sigma algebra generated by I and the collection C1 := {Ai,j : j R, {i, j} E100}.On the other hand, since R is I measurable, j[n]\\ R Ai,j1(j) is measurable with respect tothe sigma algebra generated by I and the collection C2 := {Ai,j : j [n] \\ R, {i, j} E100}.C1 C2 = , the independence of Ai,j implies that the two random variables are conditionallyindependent given I.",
  "(n++o(1) + 2n2+2(2s2s3)Tc(a,b)+2+o(1))1(F G)": "The second inequality uses the fact that 1 (1 nx)2 2nx. The third inequality exists byLemma 6.5, 6.20. Now, for further simplying the upper bound, note that if is small enough(specifically, < min((2s2 s3)Tc(a, b)/8, /4)), then + + o(1) < 2 3, and 2 + 4 (2s2 s3)Tc(a, b) + o(1) < 2 3. Hence",
  "n , s), andK2partial k-core matchings := {ij : i = j [K]}, we define a vertex v to be good if and only if MGv is connected.Conversely, a vertex v is bad if and only if MGv is disconnected": "For a bad vertex v, since MGv is disconnected, the metagraph has at least two disjointedcomponents. Hence, there must exist two sets g(v), b(v) satisfying g(v) b(v) = , g(v) g(b) = [K] and for any i g(v), j b(v), (i, j) is not an edge in MGv. In other words, vcannot be matched for any matching between the graph Gi, i g(v) and the graph Gj, j b(v).Heuristically, the definition implies that bad vertices cannot utilize the combined information forall K graphs.Otherwise,the good vertices can utilize the combined information for all K graphs, as shownin Lemma 7.3. Lemma 7.3. For a good vertex v defined in Definition 7.2, for any two node i,j (represents twographs Gi, Gj), there exists a path i := 0 1 2 . . . d := j such that v can be matched formm+1, m {0, 1, ..., k 1}. Define ij(v) := d1d d2d1 . . . 12 01(v). Proof. For a good vertex v, since MGv is connected, for any two nodes i, j [K], there existsa path ij(v) := {0 1 . . . d1 d, 0 = i, d = j, (m, m+1) E(MGv)}. We can use thepath ij(v) to define the ij(v) Remark: Note that such a path is not unique. However, the choice of path does not matterwhp. By Lemma 4.5, for k-core paritial matching, ij = ij, i, j [K], with high probability.Hence, for two different paths with endpoints being i, j [K], denoted by 1ij, 2ij, we can define1ij, 2ij based on the two paths 1ij, 2ij separately. Then, with high probability 1ij = ij = 2ij.By Lemma 7.3 and its remark, we can have the union graph of K graphs (G1G2G3. . .GK)for the good vertices, using the matchings := (12, 13, . . . , 1K) where 1K is defined inLemma 7.3. If there are multiple paths existing, pick the shortest one, and break ties in lexicographicorder.",
  "The key steps of the exact community recovery algorithm for K graphs are essentially the sameas the algorithm for three graphs. Based on a given almost exact community recovery 1 andK2": "k-core matchings pairwise, we divide the vertices into two categories:good and bad verticesaccording to Definition 7.1, 7.2. Then refine the community label according to the majority votesfor the good and bad vertices sequentially, to obtain the exact community recovery label underthe given conditions. The full algorithm for exact community recovery is given in Algorithm 5:",
  ": Apply Algorithm 1 on input (Gi, Gj, k), obtaining a matching (Mij, ij), i = j {1, 2, .., K}": "3: For good vertices v, look at the set := {ij, i, j [K] : (i, j) E(MGv)}, by Lemma 7.3,we can define the := (12, 13, . . . , 1K) to obtain the union graph of K graphs based on thematchings from , denote it as (G1 G2 . . .GK). Denote M := Mij, where (i, j) satisfyingij MGv. Set (v) {1, 1} according to the neighborhood majority (resp., minority) of1(v) with respect to the graph (G1 G2 . . . GK){M} if a > b (resp., a < b). 4: For bad vertices v, denote := {j [K] : (1, j) E(MGv)}. Denote M := i[K]M1i, set(v) {1, 1} according to the neighborhood majority (resp., minority) of (v) with respectto the graph G1 \\j / Gj(M {v}) if a > b (resp., a < b).",
  ": Return : [n] {1, 1}": "Lemma 7.4. Suppose that G1, G2, . . . , GK are independently subsampled with probability s from aparent graph G SBM(n, a log n/n, b log n/n) for a, b > 0. Let F ij be the set of vertices outside thek-core of Gi ij Gj with k = 13. For 1 L K 1 and every > 0, with probability 1 o(1) wehave that | 1iL,L+1jK F ij| n1s(1(1s)K1)Tc(a,b)+.",
  "KL": "The first equality is by the tower rule. The second inequality is due to two observations. Firstly,{Li=1 1vUij} {deg(v) L(m + k) in the graph (G1 G3 . . . GL) Gj, L + 1 j K}. To bemore detailed, if the degree of v is at most m + k in the graph Gi Gj, 1 i L, then the degreeof v is at most L(m + k) in the graph (G1 G3 . . . GL) Gj. The second observation is, givenD, for j1 = j2, the events {deg(v) L(m + k) in the graph (G1 G3 . . . GL) Gj1}, {deg(v) L(m + k) in the graph (G1 G3 . . . GL) Gj2} are independent.Similar to the proof of Lemma 4.7, let Xa Bin((1 + o(1))n/2, (1 (1 s)L)a log n/n), and",
  "= o(n(1(1s)KL)(1(1s)L)a/2+o(1))": "Hence, by summing up the two parts, E[Xta(1 s)(KL)Xa] n(1(1s)KL)(1(1s)L)a/2+o(1).This is also true for Xb. Then, E[DN(1 s)(KL)D] n(1(1s)KL)(1(1s)L)Tc(a,b)+o(1).For f(x) = (1 s)x + (1 s)Kx, x [1, K 1], the function f(x) obtains its maximum atx = 1, K 1. Hence n((1s)KL1)((1(1s)L)Tc(a,b)+o(1) ns(1(1s)K1)Tc(a,b)+o(1). Similar toLemma 4.7, by Markov inequality, the lemma follows immediately.",
  "Exact recovery for good vertices": "By Lemma 3.1, we can directly deduce that if (1 (1 s)K)D+(a, b) > 1 + | log(a/b)|, then for alli [n] we have that majG1G2...GK(i) log n w.h.p.Now for a goodvertex i, there exists a corresponding matching set that i can be matchedfor all the matchings in and there is an union graph G := (G1 G2 . . .G3) that can be derivedfrom the matchings in . Let M be the set of vertices that can be matched for all matchings in .",
  "j /|NG(i) F j|.(7.8)": "Note that majG(i) > 2 log n, i [n] with probability 1 o(1), given that (1 (1 s)K)D+(a, b) >1 + 2| log(a/b)| by Lemma 3.1. Now we would like to prove that the right hand side of (7.8) canbe bounded by log n.Note that |NG(i) F j| |NGjG(i) (F j)| + |NG\\(GjG)(i) (F j)|.First, look at |NGjG(i) (F j)|, by Lemma 4.4, w.h.p.,",
  "|NGjG(i) F j| < log n/2K2": "The remaining thing is to bound |NG\\(GjG)(i)(F j)|. Note that conditioned on , , E :={Ei1i2..iK, i1, i2, . . . , iK {0, 1}}, the graph G \\ (Gj G) is independent of F j by Lemma 3.2,since F j depends only on Gj G. Thus we can stochastically dominate |NG\\(GjG)(i) F j| bya Poisson random variable X with mean",
  "|NG\\G1(i) I(G1)| + |NG1(i) I(G1)| 2D+(a, b)1 + 2(sD+(a, b))1 log n/2": "The first inequality uses Lemma 3.5 that the set of errors are contained in I(G1). The last inequalityis due to Lemma 3.8, 7.9. Notice that majH(i) log n for i M. Hence, (i) jNH(i) 1(j) majH(i) |(i) jNH(i)(1(j) (j))| log n/2 > 0, which implies that the sign of neigh-borhood majorities are equal to the truth community label for any i M, with probability1o(1). Then we can convert H to G{M}, the vertices in M are correctly labeled with probability1 o(1).",
  "With high probability, the algorithm correctly labels all bad vertices": "Proof. For vertex i that are bad, denote := {j [K] : i cannot be matched through 1j, j =1}. Denote Fb as the vertex set of all the bad vertices that have the same with vertex i. DenoteM := i[K]M1i. define Hi := (G1 \\12 G2 \\13 G3 . . . \\1K GK){M {i}}. Let Ei be the eventthat i has a majority of at most log n in the graph Hi. Let be the labeling after the step. Forbrevity, define a nice event based on the previous results. Define the event H, which holds if andonly if:",
  "n1s(1(1s)K1)Tc(a,b)s(1s)K1D+(a,b)+ log(a/b)/2+": "Under the condition s(1 (1 s)K1)Tc(a, b) + s(1 s)K1D+(a, b) > 1, we can choose , small enough so that the right hand side is o(1). majHi(i) > log n for i F b , by Lemma 4.5,majHi(i) > log n for i Fb.Note that i cannot be matched for all 1i, i . Hence i has at most 12 neighbors in the graph(G11i Gi). Therefore for any i Fb has at least log n12|| majority in G1\\1j,j /Gj{M {i}}with high probability. Hence, we can correctly label all vertices in Fb with high probability.Use the same arguments for all types of bad vertices, we can correctly label all bad vertices.",
  "Proof of impossibility for K graphs": "We study the MAP (maximum a posterior) estimator for the communities in G1.Even withthe additional information provided, including all the correct community labels in G2, the truealignments 23, 24, . . . , 2K and most of the true alignments 12, the MAP estimator fails to exactlyrecovery communities with probability bounded away form 0 if the condition (6.1) holds. The proofcan be derived by generalizing proof of impossibility for three graphs. The only difference is that we are considering K correlated SBM G1, G2, . . . , GK. Since we know the true matching i,j, i, j {2, 3, . . . , K}, we can consider H := G2 G3 . . . GK SBM(n, (1 (1 s)K1)a log n/n, (1 (1 s)K1)b log n/n). Denote Rij the singleton in Gi Gj. Then R = R12 R13 . . . R1K is thesingleton set in G1 H. The proof follows the same arguments with more involved notation, andhence we omit the details. Here we point out the differences of the proof for K graphs.Define R := R(, A, B2, ..., BK) := {i [n] : j [n], Ai,jD(i)(j) = 0, D = max(B2, ...., BK)},here Bi is the adjacent matrix of Gk. Similar to Definition 6.2, we can define S = S(, A, B2, .., BK).Let G be the event that the following inequalities all hold:",
  "n1s(1(1s)K1)Tc(a,b) |R V +1 |, |R V 1 |, | R V +1 |, | R V +1 | n1s(1(1s)K1)Tc(a,b)+": "We can prove similar versions of Lemma 6.7 and 6.8, with (2s2 s3) replaced by s(1 (1 s)K1)and s(1 s)2 replaced by s(1 s)K1. We can have same versions of Lemma 6.9, Corollary 6.12.We can similarly define +()i1i2...iK and ()i1i2...iK for all i1, . . . , iK {0, 1}, and +() and(). When deriving the posterior distribution of 12, similar to Lemma 6.14, the informationof A, B2, . . . , BK, 2, S, 12{[n] \\ S}, := {ij, i, j {2, 3, . . . , K}} are given. Note that for A, we have that +()1i2...iK and ()1i2...iK are constant for all i2, . . . , iK {0, 1} except for+()10...0 and ()10...0. We can derive an analogue of Lemma 6.14 with p100 replaced by p100...0,p000 replaced by p000...0 and similar for q. Then we have analogous versions of Lemmas 6.15, 6.16,and 6.17, with p100 replaced by p100...0, p000 replaced by p000...0, and similar for q.Note thatp100...0q000...0p000...0q100...0 = (1 + o(1)) a",
  "Exact graph matching for K graphs": "Proof. Through the 13-core matching in Algorithm 1, we obtain := {ij, i, j [K]}, where ij isthe 13-core matching between the graph Gi and Gj.Recall Definition 7.2, we can directly infer that the good vertices are those which can bematched for K graphs through a path across 13-core estimators . We can define a new estimator for those good vertices using the combination of 13-core estimator through the path thatconnects all K graphs. The path is defined as in Lemma 7.3. For any good vertex, such pathexists and we can define the estimator for that vertex.Note that, by Lemma 4.5, with high probability ij = ij. Hence if for all the matched vertices,they will be matched correctly.If the number of bad vertices approaches zero, it indicatesthat all vertices are correctly matched.Consequently, exact graph matching can be achievedthrough the 13-core matching algorithm. By Lemma 7.4, 7.6, we can quantify the size of badvertices: for every > 0 we have that | 1iL,L+1jK F ij| n1s(1(1s)K1)Tc(a,b)+. When1 s(1 (1 s)K1)Tc(a, b) > 1, that is, when the condition (1.12) holds, the number of badvertices goes to zero when n goes to infinity, with high probability. Thus all vertices can be correctlymatched and exact graph matching for K graphs is possible with high probability.",
  "Impossibility of exact graph matching for K graphs": "Proof. Now we consider the graph matching problem with additional information provided, in-cluding the true correspondences 23, . . . , 2K and the community label . Then we obtain theunion graph H := G2 23 G3 . . . 2K GK.We now prove the impossibility by contradic-tory.Suppose that there exists an estimator which can exactly match G1, G2, ..., GK, note",
  ". If (i, j) is not an edge in H, then (i, j) is not an edge in H2, H3, . . . , HK": "2. If (i, j) is an edge in H, with probability ri1,i2,...,iK, (i, j) is an edge in the graphs {Hij} whereij = 1 in ri1,i2,...,iK and (i, j) is not an edge in the graphs {Hij} where ij = 0 in ri1,i2,...,iK. Following the subsampling described as above, we can simulate H2, . . . , HK from H.Notethat by construction, (G1, G2, G3, . . . , GK) has the same distribution as (G1, H2, . . . , HK). Thenafter independent permutations, we can obtain (H3, H4, . . . , HK) by relabeling the vertex indexin (H3, H4, . . . , HK). Note that H2 = H2. Then (G1, G2, . . . , GK) has the same distribution as(G1, H2, H3, . . . , HK). Since the estimator can exactly match (G1, G2, . . . , GK) with high proba-bility, it can also exactly match (G1, H2, H3, . . . , Hk) with high probability. Naturally, it can exactlymatch vertices in G1 and H2, since H and H2 share the same vertex index then we can have anestimator that exactly match G1 and H given G1 and H, where G1, H are correlated SBMs, indepen-dently subsampling from the parent graph G with probability s1 = s for G1 and s2 = 1(1s)K1",
  "n, b log n": "n) with probability s1 and s2, respectively, if s1s2Tc(a, b) <1, then exact graph matching between G1 and G2 is impossible. Directly applying [16, Theorem 1]we have that exact graph matching between G1 and H is impossible if s(1 (1 s)K1) < 1. Thisis a contradiction, and hence exact graph matching for G1, . . . , GK is impossible.",
  "T. Ameen and B. Hajek. Exact Random Graph Matching with Multiple Graphs. Preprintavailable at 2024": "B. Barak, C.-N. Chou, Z. Lei, T. Schramm, and Y. Sheng. (Nearly) Efficient Algorithms for theGraph Matching Problem on Correlated Random Graphs. In Advances in Neural InformationProcessing Systems (NeurIPS), volume 32, pages 91909198, 2019. C. Bordenave, M. Lelarge, and L. Massoulie. Non-backtracking Spectrum of Random Graphs:Community Detection and Non-regular Ramanujan Graphs. In Proceedings of the 2015 IEEE56th Annual Symposium on Foundations of Computer Science (FOCS), pages 13471357.IEEE, 2015. K. Bringmann, T. Friedrich, and A. Krohmer. De-anonymization of Heterogeneous RandomGraphs in Quasilinear Time.In Proceedings of the 22nd Annual European Symposium onAlgorithms (ESA), pages 197208, 2014.",
  "J. Ding, Z. Ma, Y. Wu, and J. Xu.Efficient random graph matching via degree profiles.Probability Theory and Related Fields, 179(1):29115, 2021": "Z. Fan, C. Mao, Y. Wu, and J. Xu. Spectral Graph Matching and Regularized QuadraticRelaxations: Algorithm and Theory. In Proc. of the 37th Int. Conf. on Machine Learning(ICML), volume 119 of Proc. of Machine Learning Research (PMLR), pages 29852995, 2020. L. Ganassali and L. Massoulie. From tree matching to sparse graph alignment. In Proceedingsof the 33rd Conference on Learning Theory (COLT), volume 125 of Proceedings of MachineLearning Research (PMLR), pages 16331665, 2020. L. Ganassali, L. Massoulie, and M. Lelarge. Impossibility of Partial Recovery in the GraphAlignment Problem.In Proceedings of the 34th Conference on Learning Theory (COLT),volume 134 of Proceedings of Machine Learning Research (PMLR), pages 20802102, 2021. J. Gaudio, M. Z. Racz, and A. Sridhar. Exact Community Recovery in Correlated StochasticBlock Models. In Proceedings of the 35th Conference on Learning Theory (COLT), volume178 of Proceedings of Machine Learning Research (PMLR), pages 21832241, 2022.",
  "E. Onaran, S. Garg, and E. Erkip. Optimal de-anonymization in random graphs with commu-nity structure. In 2016 50th Asilomar Conference on Signals, Systems and Computers, pages709713. IEEE, 2016": "P. Pedarsani and M. Grossglauser. On the privacy of anonymized networks. In Proceedings ofthe 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining(KDD), pages 12351243, 2011. M. Z. Racz and A. Sridhar.Correlated Stochastic Block Models: Exact Graph Matchingwith Applications to Recovering Communities. In Advances in Neural Information ProcessingSystems (NeurIPS), volume 34, pages 2225922273, 2021.",
  "M. Z. Racz and A. Sridhar. Matching Correlated Inhomogeneous Random Graphs using thek-core Estimator.In 2023 IEEE International Symposium on Information Theory (ISIT),pages 24992504, 2023": "R. Singh, J. Xu, and B. Berger. Global alignment of multiple protein interaction networkswith application to functional orthology detection. Proceedings of the National Academy ofSciences, 105(35):1276312768, 2008. H. Wang, Y. Wu, J. Xu, and I. Yolou. Random Graph Matching in Geometric Models: theCase of Complete Graphs. In Proceedings of the 35th Conference on Learning Theory (COLT),volume 178 of Proceedings of Machine Learning Research (PMLR), pages 34413488, 2022.",
  "Y. Wu, J. Xu, and S. H. Yu. Settling the Sharp Reconstruction Thresholds of Random GraphMatching. IEEE Transactions on Information Theory, 68(8):53915417, 2022": "J. Yang and H. W. Chung. Graph Matching in Correlated Stochastic Block Models for Im-proved Graph Clustering. In Proceedings of the 2023 59th Annual Allerton Conference onCommunication, Control, and Computing (Allerton), pages 18. IEEE, 2023. J. Yang, D. Shin, and H. W. Chung.Efficient Algorithms for Exact Graph Matching onCorrelated Stochastic Block Models with Constant Correlation. In Proceedings of the 40thInternational Conference on Machine Learning (ICML), volume 202 of Proceedings of MachineLearning Research (PMLR), pages 3941639452, 2023."
}