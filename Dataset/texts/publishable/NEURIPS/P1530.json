{
  "Abstract": "Compared to classical machine learning (ML) models, generative models offer anew usage paradigm where (i) a single model can be used for many different tasksout-of-the-box; (ii) users interact with this model over a series of natural languageprompts; and (iii) the model is ideally evaluated on binary user satisfaction withrespect to model outputs. Given these characteristics, we explore the problem ofhow developers of new generative AI software can release and price their technol-ogy. We first develop a comparison of two different models for a specific task withrespect to user cost-effectiveness. We then model the pricing problem of generativeAI software as a game between two different companies who sequentially releasetheir models before users choose their preferred model for each task. Here, theprice optimization problem becomes piecewise continuous where the companiesmust choose a subset of the tasks on which to be cost-effective and forgo revenuefor the remaining tasks. In particular, we reveal the value of market information byshowing that a company who deploys later after knowing their competitors pricecan always secure cost-effectiveness on at least one task, whereas the companywho is the first-to-market must price their model in a way that incentivizes higherprices from the latecomer in order to gain revenue. Most importantly, we find thatif the different tasks are sufficiently similar, the first-to-market model may becomecost-ineffective on all tasks regardless of how this technology is priced.",
  "Introduction": "The recent explosion of generative artificial intelligence (AI) has introduced new machine learning(ML) frameworks for applications from chatbots to robotics [Wu et al., 2023, Nasiriany et al., 2024].Whereas in classical ML, a user interacted with a single model designed for a specific predictive task(e.g., classification) via input data and output predictions, a single generative AI model can solvea variety of tasks for a user out-of-the-box [Brown et al., 2020]. Moreover, users interact with thegenerative model over a universal interface of natural language prompting [Arora et al., 2022]. The prompt-based paradigm has fostered two recent human-AI interaction trends. First, promptingfacilitates such a wide distribution of tasks (i.e., user inputs and model outputs) that conventionalmetrics for evaluating models have become insufficient, leaving the most effective evaluation metricto be a binary score of whether the user is satisfied with the model output [Li et al., 2024, Chiang et al.,2024]. For example, Ziegler et al. empirically analyzed the GitHub Copilot software to revealthat the frequency of generated code approved by a user is a better predictor of perceived [user]productivity than alternative measures. Second, if a user does not receive a satisfactory output, theycan try again in another prompting round by inputting to the model additional information [Castroet al., 2023]. For instance, the Anthropic HH and the Chatbot Arena datasets report on average 2.3and 1.3 prompting rounds per conversation, respectively [Bai et al., 2022, Chiang et al., 2024]. In this work, we study the impact of these interaction characteristics on the pricing of generative AItechnology. While classical ML products can be priced by analyzing the user demand for a model thatcan achieve a given performance metric on a specific task [Gurkan and de Vricourt, 2022, Mahmood",
  ": Overview of the competitive pricing problem for generative AI models": "et al., 2022], a generative AI model is priced per user prompt 1. This set price determines the usercost for multiple different tasks and variable number of prompting rounds, e.g., the cost of usingGPT-4 for math reasoning or code generation depends only on the per-token price, and the lengthand number of prompts. Thus, developers of a generative AI product must factor the demand for allpotential use-case tasks of the technology when setting a price. This pricing problem becomes furtherchallenging when considering the rapidly growing marketplace of competing generative AI models,since companies must also ensure that their products do not become unattractive to users as soon as acompetitor develops a newer and better model. We first characterize when, for a given task, a user will prefer one generative AI model versusanother. We argue that users minimize their total cost, measured by the cost-per-prompt times thenumber of prompting rounds needed for the model to produce a satisfactory output; this leads to acomparison of price-performance competitiveness between AI models. We then study a game withtwo firms developing competing models used for a set of tasks. Both firms know each others modelsperformance on the tasks. The first firm deploys their product and sets a price, followed by the secondfirm with their product and price. Finally, a user decides which models to use for each task. Bothfirms seek to maximize revenue, but the first firm acts without knowledge of their competitors price. summarizes the problem setting and insights. Our key observations include: 1. The pricing problem reduces to a piecewise optimization problem, where firms pricetheir model to be competitive on a subset of the tasks while forgoing revenue from theothers. This subset can be determined by ranking the tasks on the competitive ratio betweenthe two models for each task and selecting the most competitive tasks. 2. A firm who deploys late always obtains revenue from at least one task by leveragingthe available market information. In contrast, the first-to-market must strategically settheir prices to encourage the latecomer to set higher prices and focus on fewer tasks. 3. Under certain conditions on model performance and user demand, the first-to-marketmay acquire zero revenue regardless of their price. In these settings, the latecomernaturally maximizes their revenue by being competitive for all tasks. Thus, developers thatare first should have a minimum model performance before deploying their product.",
  "Related literature": "Evaluating ML models. ML models are typically evaluated on generalization error for a task viaout-of-sample test dataset benchmarks and competitions [Deng et al., 2009]. Generative AI andlarge language models (LLMs) are evaluated on a suite of benchmark tasks such as for coding [Chenet al., 2021], math [Cobbe et al., 2021], and problem solving [Hendrycks et al., 2021]. However,standardized benchmarks become uninformative over time as new models are trained to overfit tothese metrics [Roelofs et al., 2019, Koch et al., 2021]. Recently, Chiang et al. introducedthe Chatbot Arena for comparing LLMs head-to-head on human preference. Here, a user posesa real-world prompt which is input to two models. The user reviews both model outputs and caneven continue multiple conversation rounds, before ranking which model generated a satisfactoryanswer first. Although difficult to measure, user satisfaction rate is increasingly viewed as the mostinformative metric as seen from generated code approvals on GitHub Copilot [Ziegler et al., 2024],or perceived aesthetic quality of text-to-image generation such as MidJourney and Playground [Liet al., 2024]. Our work combines user satisfaction with a user cost to construct a price-performanceratio for comparing different models. 1In practice, generative AI models are typically priced-per-token. In Appendix B, we show that all our resultsextend to the price-per-token setting with a minor change of variables. For a list of prices for current generativeAI prices, see: Human-generative AI interaction. Prompt-based interaction has increased the diversity of taskswhere these models can be applied [Eloundou et al., 2023]. Castro et al. analyze how andwhen human users will use a generative AI model for a task versus performing it manually, as wellas the characteristics of interacting over multiple prompt rounds. The quality of prompts is crucialto generating higher-quality answers [Liu et al., 2023, Binz and Schulz, 2023]. This has motivatedstudies on prompt techniques, such as chain-of-thought [Wei et al., 2022] and self-consistency [Wanget al., 2022]. In our work, we treat prompt quality as a random variable and to simplify the structuralanalysis, assume that users will interact with a generative AI model for as many prompting rounds asneeded to get a satisfactory answer. Pricing and competition. Duopolies of competitive products use game theoretic models such as theBertrand (i.e., simultaneous pricing) and Stackelberg (i.e., sequential pricing) models of interaction[Gibbons, 1992]. Both deterministic and probabilistic demand can be used to study oligopolisticpricing of a single or multiple products Chintagunta and Rao , Gallego and Hu . Specificstructured demand frameworks allow for identifying market equilibria and failure settings whererevenue is unobtainable [Federgruen and Hu, 2015, 2019]. Our work is most closely related to theStackelberg literature by modeling a sequential game and exploring the conditions under exponentialdemand that make certain generative AI models unattractive [Hamilton and Slutsky, 1990]. Pricing AI products. AI technology can be priced at various levels, ranging from training data tomodel queries [Liu et al., 2021, Chen et al., 2019, Cong et al., 2022]. A core aspect of the pricingproblem involves valuating the ML model based on performance [Xu et al., 2024]. ML products arefurther susceptible to an AI flywheel effect where the release and price of an AI product will affect thesubsequent collection of new training data from users, leading to a dynamic pricing problem [Gurkanand de Vricourt, 2022, Chen and Xue, 2023]. More generally, novel technology products such asa new generative AI model with emergent use-cases may feature social-learning and dynamicallygrowing market sizes [Feldman et al., 2019, Zhang et al., 2022]. The closest to our work is Gurkanand de Vricourt who explore pricing and contracting the development of a classical ML modelunder the AI flywheel. In contrast, our work explores competition between ML model developerswhen faced with a diverse set of potential downstream tasks for which the model can be used.",
  "Problem setup": "Tasks. We define a task as a set of independent problem instances where for each instance, a userqueries a machine learning model with an input prompt and receives an output generated the model.For example, a programming task may have instances where a user inputs a commented functiondefinition and the model must complete the code to perform the function Chen et al. , Ziegleret al. . Task instances are evaluated by a user via a binary correctness score. For tasks wherecorrectness is unambiguous (e.g., whether the program runs), the score is equivalent to accuracy,whereas for open-ended tasks (e.g., whether the output meets the stylistic preferences of the user), wetreat correctness simply as whether the user is satisfied with the output 2 Generative AI model. Given a set of T different tasks, a generative model is an ML model that canbe used to solve instances of any of the different tasks via prompts. We define this model as a tuple(p, V1, V2, . . . , VT ) where p denotes the price for using the model, as measured in dollars-per-prompt(see Appendix B for the extension to pricing per-token), and for each t [T], Vt (0, 1) denotesthe average score of the model over instances of each task. We assume that Vt 1 implies that themodel can always generate a correct output for any task instance and Vt 0 implies that the modelwill always generate an incorrect output. Therefore, for any random instance of task t, Vt can also beinterpreted as a Bernoulli probability of the generative model producing a satisfactory output in asingle attempt. 2For example in code completion, users prefer generated code that provides a good starting point for theusers to improve on rather than code that is technically correct but confusing [Ziegler et al., 2024]. Users will not use the generative model if its price is too high with respect to the users valuation ofthe specific task. For any given task t, let Dt(p) R+ be the demand function, i.e., the number ofusers who will use a generative AI model for task t as a function of the price p. Following standardassumptions, we assume that Dt(p) is differentiable and non-increasing in the model price, as well asbeing known to the developer of the AI model [Gallego and Van Ryzin, 1994]. Multi-round use.Most ML benchmarks typically evaluate models on whether the models cangenerate the correct output under a single prompt round [Chen et al., 2021, Cobbe et al., 2021,Hendrycks et al., 2021]. However, in-the-wild users of generative models typically have interactivemulti-round conversations where if the model generates an unsatisfactory solution after the firstprompt, the user can provide feedback via their preferences or corrections in a second prompt round[Castro et al., 2023, Liao et al., 2024]. For example in code completion, if the model fails to accountfor an edge-case input to the function, the user can identify the edge-case and ask the model toaccount for it. To characterize this multi-round use, we extend the single prompt to a sequenceof Bernoulli trials that continue until the user is satisfied with the model output. For simplicity ofmodeling, we make the following assumptions on user behavior. Assumption 1. The total number of prompting rounds nt(Vt) that a user will engage with the model:(i) has a finite mean; and (ii) is independent of the model price p conditioned on the user knowing Vt. Assumption 1 implies that the price of a model only determines demand via whether the modelis used at all, rather than how many times (i.e., prompting rounds) the model is used. Under thisassumption, there are many choices for modeling the distribution of nt(Vt). We give three examples: Geometric: Because non-expert users tend to design uninformative prompts [Zamfirescu-Pereira et al., 2023], we may suppose the probability of success on any round does notdepend on user input, and each round is an i.i.d. Bernoulli trial with probability Vt. Then,the total number of rounds is nt Geom(Vt), following a Geometric distribution. Truncated Geometric: Users may quit the model after a maximum Tt rounds if it fails togenerate a satisfactory response [Castro et al., 2023]. For instance, conversations in theChatbot Arena dataset terminate after an average 1.3 rounds [Chiang et al., 2024]. Here,Pr{nt = n} := (1 Vt)n1Vt for 1 n < Tt and Pr{nt = Tt} := (1 Vt)Tt1. Prompt-dependent: Suppose the success probability is prompt-dependent Vt(xi) wherexi Pr{x} is the prompt on the i-th round. If users prompt until the model generates asatisfactory answer, we have Pr{nt = n} := Ex1, ,xn[Vt(xn) n1i=1 (1 Vt(xi))]. Ultimately, the choice of characterizing nt depends on the information available to the generativeAI model provider. With limited information, the Geometric assumption may be most practical,but given knowledge of user prompts, we may consider more sophisticated models. Our results allhold independent of the distribution as long as Assumption 1 is satisfied. For ease of notation andinterpretability, we assume nt Geom(Vt) in the remainder of this work.",
  "Modeling user preference between AI models": "Given the above task and user behavior framework, we analyze the problem of a user who mustchoose between two competing generative models to solve instances of their tasks. Since a user mayprefer different models for different tasks, we consider a single task and omit subscript t. Consider two generative models: model A (q, W) and model B (p, V ). Under Assumption 1, given asufficient number of prompt rounds, both models can eventually solve every task instance. Thus, arational user will seek to minimize the expected cost of completing a task instance, measured by theaverage price-per-prompt times the expected number of rounds required to complete the task instance.In this comparison, model B will incur a lower cost for the user if",
  "Condition (1) states that for any task, a specific generative AI model is preferred if the price-performance ratio for this task (i.e., the cost of using this model over the models performance) is": "lower than any other competing generative model. For example, if model B is twice as likely togenerate a user-satisfactory output as model A for a given input prompt, i.e., V = 2W, then theuser will prefer model B as long the cost of prompting this model is not twice as high, i.e., p 2q.Otherwise, the user will incur lower costs and still obtain their desired outputs by simply promptingthe weaker model for twice as many rounds. We note that (1) can also compare the use of a generative AI model versus manually performing thetask [Castro et al., 2023]. For instance, if we treat model B as a human and a prompt round as a timedattempt at completing a task (e.g., coding the function within one hour), then V is the probability of ahuman being able to perform the task in the single attempt and p is the time-value of this labor. Finally, this framework can also compare free-to-use generative AI models such as LLaMA [Touvronet al., 2023]. Although there may not be a given price-per-token for using these models, there isa fixed cost to set up the infrastructure and environment. Given an expected total number of taskinstances, this fixed cost can be approximated to an equivalent p.",
  "Pricing generative AI models": "We now develop a general framework under which a provider of a generative AI model can pricetheir product. We first define the pricing problem as a game between two firms developing competinggenerative AI models. We then create tractable reformulations for these problems for both firms,representing pricing with and without considering competition. Pricing problem.Consider a set of T tasks. Let (q, W1, W2, . . . , WT ) and (p, V1, V2, . . . , VT ) bethe generative models released by two competing firms, A and B, respectively. Firm A deploys theirgenerative AI model (i.e., model A) first and sets the price q for this product. Then, firm B deploystheir competing model (i.e., model B) and sets their price p. After both firms deploy their models, auser with demand functions Dt() for each t will decide which models to use as determined by (1).We evaluate the total revenue obtained by each firm, given by RA(q|p) and RB(p|q) respectively:",
  ".(2)": "Note that in practice, the user demand may depend on p and q simultaneously; for simplicity, weassume the demand for a specific model to be determined only after the user preference condition(1) is resolved. The results in this section easily generalize to more complex demand functions. Therevenue functions are composed of the demand for each task times the price set by the firm [Van Ryzinand Talluri, 2005], summed over all tasks for which the firms model is competitive according to theprice-performance ratios. Each firms objective is to maximize their revenue. However, because firmA is the first-to-market and they do not know the action that firm B will take; instead, firm A mustoptimize for the worst-case scenario as determined by firm B. On the other hand, firm B first observesthe price set by firm A. Thus, the two firms set prices as follows:",
  "q := arg maxq0{RA(q|p) | p arg max RB(p|q)}p := arg maxp0{RB(p|q)} .(3)": "We assume both firms know Vt and Wt for all t [T]. This is motivated by the availability ofresearch papers and reported benchmark scores, and the predictability of model performance viapower laws [Kaplan et al., 2020]. In practice, a firm may not know their competitors performance,but they can forecast the state-of-the-art score in the short term.",
  "Pricing in isolation": "We first consider firm Bs problem, who set their price after firm A has already released a competingmodel with price q. Firm Bs problem depends on the competitive ratio t := E[n(Wt)]/E[n(Vt)]for task t [T], i.e., the relative ratio of number of prompting rounds between the two firms, whichunder a Geometric distribution assumption, simplifies to t := Vt/Wt. To maximize their revenue,firm B can rank the tasks in order of t, select a subset of tasks in this order, and solve the optimizationproblem for each subset. This results in an overall piecewise optimization problem. : (Left) Three tasks with three different exponential demand functions D1(p) = 100e0.5p,D2(p) = 200e0.5p, D3(p) = 400e0.5p. (Right) The corresponding revenue from each task alongwith the total revenue function for a firm RB(p). The vertical lines correspond to 1q, 2q, and 3q,where 1 > 2 > 3. For p < 3q, revenue is obtained from all three tasks, for p (3q, 2q],revenue is obtained from only the first two tasks, and for p (2q, 1q], revenue is only obtainedfrom the first task. No revenue can be obtained if p > 1q.",
  ".(5)": "Theorem 1 shows that a generative AI model should be priced by prioritizing a subset of the tasksand making the model price-performance competitive for those tasks only. Consequently, the firmignores the remaining tasks for which the model has low competitive ratios t, since they would needextremely low prices in order to satisfy (1) for these tasks. This strategy is due to the observationthat for any task (t), if a model satisfies (1), then the model will also satisfy the condition for all(t) for t t. Furthermore, Theorem holds without loss of generality with respect to the strictinequalities on (4), since tasks with the same competitive ratios can be grouped together by summingthe constituent demand functions. Finally, Theorem 1 holds for arbitrary demand functions. Inpractice, the demand functions are known and typically have a parametric structure. givesan example using three tasks with demand that decays exponentially with price. Theorem 1 reveals two key implications on how a firm can price a generative mode when givencompetitor information. First, pricing reduces to solving T optimization problems, where each ofthese problems are of a single variable with a differentiable objective and boundary constraints.Thus, the inner problems can be solved via gradient descent. Second, as long as firm B sets a pricep (1), they will obtain some non-zero revenue, i.e., problem (5) always has a feasible solution.This advantage is due to the fact that firm B sets their price given a fixed q.",
  "(6)": "Theorem 2 relies on the observation that the reverse order of () in (4) cn rank the most to leastcompetitive tasks for firm A. For any t, if q < p1(t), then model A is price-performance competitivefor all tasks (t), , (T) and firm A will acquire revenue from all these tasks. Firm A may not always be able to obtain revenue. Problem (6) is infeasible if for every t [T 1],there is no q 0 that satisfies the bi-level constraint. This infeasibility implies for any q 0, firm Balways maximizes their revenue by setting a low price p (T )q. Thus, the key motivation of firmA is that the firm benefits only when their competitor is incentivized to set high prices.",
  "Structural analysis under exponential demand": "Demand is typically modeled via structured parametric functions [Van Ryzin and Talluri, 2005]. Inthis section, we specialize the pricing problem to the standard choice of exponentially decayingparametric demand to extend the previous general results. See (Left) for an example.Assumption 2. For each task t, the demand function decays exponentially in price Dt(p) :=at exp(bp), where at > 0 is the zero-price base demand and b > 0 is the price-sensitivity of users.Furthermore, all tasks have the same price-sensitivty. Under the exponential demand model, the demand for each task t is equal to at when p = 0, anddecays at a rate b. We assume that the decay rate is the same for each task; this is motivated by thepractical consideration that the different tasks should have relatively similar user value to have thesame price. If one task is uniquely price-sensitive to users, the firm may instead develop a finetunedmodel for that task or propose incentives such as task-specific discounts to better optimize revenue.",
  "b a(t)e1(7)": "Theorem 3 states that problem (5) can be solved by by solving each of the inner problems startingfrom the lowest price range up until we arrive at the zero-gradient solution of the revenue function,i.e., 1/b. Furthermore, for each of the price ranges before this point, the optimal solution is theupper price boundary. Note that if 1/b > (1)q, i.e., there does not exist any t satisfying thecondition, then we take the maximum of all T problems. (Right) visualizes the revenuefunction RB(p|q) for T = 3 tasks with exponential demand. Finally, this structure also reveals thatthe optimal price is bounded from both above and below via these optima.Corollary 1. The optimal price for firm B is bounded 1/b p (1)q. : The relationship between 2/1 and a1/(a1 + a2) for firm A. In the blue region, firm Bwill always set a price that is competitive on both tasks and firm A will acquire zero revenue. In theorange region, the maximum price that firm A can set is upper bounded (see problem (11)). In thegreen region, the maximum price that firm A can set has a higher upper bound (see problem (10)).",
  "Pricing when accounting for competition under exponential demand": "We now revisit firm As pricing problem, which is a bi-level problem with multiple inner optimizationconstraints. To obtain structural insights on the challenges of pricing under competition, we explore aspecial case with T = 2 tasks. Without loss of generality, we assume 1 > 2, i.e., (t) = t. When there are only two tasks, firm B will either set their price to be competitive for the first taskonly (i.e., the task with the higher competitive ratio) or for both tasks. In the latter case, model Awould be unattractive for both tasks and firm A would obtain zero revenue. Therefore, firm A shouldset their price in such a way that they maximize revenue on the second task, while ensuring that firmB is motivated to be competitive only for the first task. Thus, problem (6) simplifies to",
  "s. t. maxppD1(p) 1q p > 2q> maxpp (D1(p) + D2(p)) 2q p > 0(8)": "If firm A sets a price q that is infeasible for this problem, they will get zero revenue. Furthermore,this problem reduces to two single-level optimization problems with only bounding constraints.Theorem 4. Suppose that T = 2, that Assumption 2 holds, and without loss of generality, assume(t) = t. For z R, let W(z) be the Lambert W function defined only over z > e1. If",
  "Determining which problem to solve to obtain the optimal price depends on a relationship betweentwo constants 2/1 and a1/(a1 + a2). Here, 2/1 is the relative competitive ratio with respect to": "the two tasks for firm B, where 1 > 2 > 0. Thus, 2/1 1 suggests that the relative performancedifferences between model A and model B are similar for both tasks, whereas 2/1 0 suggeststhat relative to model A, model Bs performance is much worse on the second task than for the firsttask. The second parameter a1/(a1 + a2) is the fraction of the total demand that is occupied by thefirst task. If this is close to 1, then the first task has significantly higher demand than the second, butif it is close to 0, then the first task has significantly lower demand than the second. We now discuss the structural insights obtained from Theorem 4 (see for a visualization).First, note that when condition (9) is satisfied, firm A is able to set higher prices than it could ifthe condition were not satisfied. In the latter case, the optimal price that firm A can set must beupper bounded by the constraint in problem (11), which in this scenario, is less than the upper boundin problem (10). Intuitively, this condition partitions firm As pricing problem into two regimes: ahigh-price and low-price regime. Furthermore, the high-price regime is only attainable if the relativeperformance difference between the two tasks is greater than the Lambert W function of the fractionof total demand occupied by the first task. Second, if firm Bs relative performance difference between the two tasks is larger than the fractionof demand occupied by the first task, then firm As pricing problem is infeasible. That is, no matterwhat price that firm A sets, firm B is always incentivized to set a price that ensures users will prefermodel B and consequently, leave no revenue for firm A.",
  "Proposition 1. If 2/1 > a1/(a1 + a2), then for any price that firm A sets, firm B will always set aprice that allows them to be price-performance competitive for both tasks": "Intuitively, if the relative performance difference is high, then model Bs performance relative tomodel A is approximately the same for both tasks. Consequently, the range (2q, 1q] is small,meaning that a small perturbation from this price would not significantly decrease firm Bs revenuefrom the first task, while permitting the firm to obtain revenue from the second task as well. Notethat model B does not necessarily have to be better than model A, only that the performance onthe tasks must be similar. Finally, this ratio 2/1 only needs to be larger than the fraction of totaldemand that is occupied by the first task. Consequently, even if the ratio is small, firm B can stillbe incentivized to set a competitive price for both tasks if the potential revenue that can be obtainedfrom the second task is high. Theorem 4 and Proposition 1 sets a guideline for when a firm should deploy their generative AI model.Consider a company that has developed a model for a new application area with no competitors. Thiscompany knows that upon releasing their model to the public, competitors will release their ownmodels. If the first-to-market company believes that the use-cases for this model are sufficientlysimilar to each other with respect to model performance, but are differentiated with respect to userdemand, then they must ensure that the model performs exceedingly well on at least one specificuse-case that their competitors cannot match. That is, the company must differentiate their product[Schmalensee, 1982], or competitors can outprice the initial company with similar products. Although firm A must price accounting for firm Bs actions, if model A is sufficiently differentiatedfrom model B, then firm A can acquire their maximum possible revenue. Recall that the zero-gradientoptimal price for problem (8) is q = 1/b. Furthermore recall that if condition (9) is met, then firmA can set higher prices for their model. We show below that if condition (9) is satisfied and if 2 issufficiently low with respect to the demand ratio, then the optimal price is feasible.",
  "Conclusion": "We study how a company developing a generative AI model can set the price for this technology.Generative AI models are a fundamentally different technology product compared to classical AImodels due to two factors. First, a single generative AI model is performant on multiple distinctuse-cases that each invite individual respective user demands. Second, generative AI models offerinteractivity via prompting, thereby encouraging geometric user interaction where users can repeat-edly prompt the model until it generates a satisfactory answer, compared to classical non-interactiveAI models that invite one-shot Bernoulli interaction. These features combined with a singular unitprice per-prompt for model use warrant new revenue maximization frameworks for this technology. We find that for generative AI models, the pricing problem reduces to ranking the different tasksin order of the relative performance of the model versus a competing alternative. In isolation, acompany can then always obtain non-zero revenue by setting a price to be competitive for at least onedownstream task. However, when considering the competition from alternative models that may bereleased after the price is set, the company faces strict upper bounds on the prices they can set basedon the performance of the companys model relative to the latecomers. In particular, if the relativedifference in performances on the tasks is sufficiently small, then a competitor will always be ableto outprice the company on all tasks. This result reveals that an outsized performance improvementon at least one of the downstream applications of a generative AI model is essential to maximizingrevenue. Limitations.We explore a theoretical market problem where firms know user demand and theperformance of competing AI models. In practice, these would be estimated with some noise.Furthermore, we study a static marketplace where each firm sets their price once. In contrast, AItechnologies feature a flywheel where a low price and an early release of a product can allow for afirm to collect more training data and improve their model downstream [Gurkan and de Vricourt,2022]. In particular, the opportunity to acquire high-quality data can significantly improve modelperformance, thereby motivating the first mover position. Finally, we do not include the cost ofdeveloping the generative AI models themselves, but assumes that the fims have already decided tobuild these models. The market dynamics can change when considering how large of a model tobuild, how much resources (e.g., compute hours) to spend, or even whether to build a generative AImodel. We see these scenarios as important future extensions. Societal impact. Pricing of generative AI can significantly affect the democratization of generativeAI technology. This paper explores the conditions that incentivize firms to develop or deploy thistechnology, e.g., when firms can obtain revenue. Setting appropriate prices for these models canallow for this technology to be more easily accessible to a wider set of users.",
  "and Disclosure of Funding": "The author thanks the NeurIPS 2024 editorial chairs and anonymous referees for providing valuablefeedback that significantly improved this paper. The author also thanks David Acuna, Sanja Fidler,Marc Law, and James Lucas for providing insightful discussion and valuable suggestions on earlyversions of this paper. Simran Arora, Avanika Narayan, Mayee F Chen, Laurel Orr, Neel Guha, Kush Bhatia, Ines Chami, andChristopher Re. Ask me anything: A simple strategy for prompting language models. In The EleventhInternational Conference on Learning Representations, 2022. Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, StanislavFort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless assistant with reinforcementlearning from human feedback. arXiv preprint arXiv:2204.05862, 2022.",
  "Francisco Castro, Jian Gao, and Sbastien Martin. Human-ai interactions and societal pitfalls. arXiv preprintarXiv:2309.10448, 2023": "Lingjiao Chen, Paraschos Koutris, and Arun Kumar. Towards model-based pricing for machine learning in a datamarketplace. In Proceedings of the 2019 international conference on management of data, pages 15351552,2019. Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, HarriEdwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, MichaelPetrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov,Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William HebgenGuss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain,William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, EvanMorikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, BobMcGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating large languagemodels trained on code, 2021.",
  "Jonathan H Hamilton and Steven M Slutsky. Endogenous timing in duopoly games: Stackelberg or cournotequilibria. Games and Economic Behavior, 2(1):2946, 1990": "Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.Measuring massive multitask language understanding. Proceedings of the International Conference onLearning Representations (ICLR), 2021. Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray,Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprintarXiv:2001.08361, 2020.",
  "Rafid Mahmood, James Lucas, Jose M Alvarez, Sanja Fidler, and Marc Law. Optimizing data collection formachine learning. Advances in Neural Information Processing Systems, 35:2991529928, 2022": "Soroush Nasiriany, Fei Xia, Wenhao Yu, Ted Xiao, Jacky Liang, Ishita Dasgupta, Annie Xie, Danny Driess,Ayzaan Wahid, Zhuo Xu, et al. Pivot: Iterative visual prompting elicits actionable knowledge for vlms. arXivpreprint arXiv:2402.07872, 2024. Rebecca Roelofs, Vaishaal Shankar, Benjamin Recht, Sara Fridovich-Keil, Moritz Hardt, John Miller, andLudwig Schmidt. A meta-analysis of overfitting in machine learning. Advances in Neural InformationProcessing Systems, 32, 2019.",
  "Garrett J Van Ryzin and Kalyan T Talluri. An introduction to revenue management. In Emerging theory, methods,and applications, pages 142194. Informs, 2005": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, andDenny Zhou. Self-consistency improves chain of thought reasoning in language models. arXiv preprintarXiv:2203.11171, 2022. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al.Chain-of-thought prompting elicits reasoning in large language models. Advances in neural informationprocessing systems, 35:2482424837, 2022. Tianyu Wu, Shizhu He, Jingping Liu, Siqi Sun, Kang Liu, Qing-Long Han, and Yang Tang. A brief overview ofchatgpt: The history, status quo and potential future development. IEEE/CAA Journal of Automatica Sinica,10(5):11221136, 2023.",
  "q > (t+1),": "then all of the tasks (1), (2), . . . , (t) become competitive for firm Bs generative model comparedto firm As model, i.e., by satisfying (1), whereas tasks (t + 1), . . . , (T) are competitive for firmAs model instead. As a result, for prices constrained in this range, the resulting problem becomesmaxp p ts=1 D(s)(p). Therefore, to solve the overall pricing problem, we only need to solve thisresulting constrained problem for each value of t.",
  "(t)q p > (t+1)q": "for all t = t. Furthermore, given this t, firm A will only obtain revenue from tasks (t + 1), (t +2), , (T), thereby revealing the objective function. Finally, note that if t = T, then firm A willnot acquire any revenue since firm B will be price-performance competitive on all tasks. Therefore,firm As optimization problem is to simultaneously solve for q and for t [T 1]. Proof of Theorem 3. First, note that under an exponential demand function the revenue function foreach piece t of problem (5) is pa(t) exp(bp), and therefore has a zero-gradient point at p = 1/b.Thus, when solving problem (5), we can solve the inner problem by breaking into 3 cases based onwhich t to consider. For t satisfying the condition. Here, the zero-gradient price p is a feasible solution to the innerpricing problem, meaning that this must be the optimal price. Substituting this into the revenuefunction yields a(t) exp(1)/b. For t > t. Note that for any t > t, the price is constrained to be less than (t+1) < 1/b. In thisregime, the revenue function pa(t) exp(bp) is monotonically increasing, meaning that the optimalprice will be the maximum possible value, i.e., p = q(t). Substituting this into the revenue functionyields (t)qa(t) expb(t)q. For t < t. Here, the set of feasible prices is strictly greater than (t) > 1/b. In this regime, therevenue function is monotonically decreasing, meaning that the optimal price will be the minimumvalue, i.e., p q(t+1), approaching from above. However, for any such setting, decreasing p toequal the infinum would make firm B price-performance competitive for the t + 1-th task as well andthereby yield a higher return. Therefore, the optimal solution for any t < t can always be upperbounded by the optimal solution for t + 1, leading up to t. Proof of Corollary 1. The upper bound follows from the proof of Theorem 3, as we show that theoptimal revenue cannot be achieved without satisfying task (t). The lower bound follows fromobserving the optimal solution for t = T. Proof of Theorem 4. Let p1 := arg max{pD1(p) | 1q p > 2q}. Furthermore, let p2 :=arg max{p(D1(p) + D2(p)) | 2q p > 0}. Although p1 and p2 depend on q, we omit thisdependency to simplify the notation. We prove our theorem by exploring three regimes for q:(0, 1/(b1)], (1/(b1), 1/(b2)], and (1/(b2), ). We then show that whether condition (9), theproblems for each regime simplify further into problems (10) and (11). For q (1/(b2), ). For any q > 1/(b2), we have 2q 1/b > 0. From Theorem 3, p2 = 1/bis the optimal price. Furthermore, since 1q p1 > 2q, we have p1 > 1/b. From Corollary 1, p1 ispriced too high and cannot achieve a higher revenue than p2. Therefore in this regime, firm B willset a price low enough that their model is competitive for both tasks, and consequently firm A willachieve zero revenue. For q (1/(b1), 1/(b2)]. From Theorem 3, p1 = 1/b and p2 = 2q are the optimal prices thatfirm B can set for their two sub-problems. For firm A to achieve any revenue, the constraint inproblem (8) becomes",
  "a1 + a2": "The second line follows from multiplying both sides by 1/b. This condition means that problem(12) does not have a feasible region, meaning that the optimal price can only be obtained by solvingproblem (11). Proof of Proposition 1. The proof of the follows from observing that when this condition is satisfied,the intermediate problems from the proof of Theorem 4, i.e., problems (12) and (13) both becomeinfeasible. If those problems become infeasible, the nominal problems (10) and (11) also must beinfeasible. First,",
  "BExtensions from per-prompt to per-token pricing": "In this paper, we assume that the generative AI models can be used at a fixed price per-prompt. Inpractice, generative AI models are priced either per-token or priced via a subscription mechanismwhere users pay a fixed cost for (potentially unlimited) use. Furthermore, different tasks may featurestatistically different numbers of tokens either via longer (or shorter) prompts, or longer (or shorter)model outputs. Consequently under per-token pricing, different tasks will have different costs on",
  "average. The price-per-prompt framework of this paper naturally extends to pricing per-token with asmall change of variables that preserves all fundamental results": "Suppose there are two firms, A and B, developing generative AI models with fixed price per-tokensq0 and p0, respectively. We assume that the price is the same for both input and output tokens. Foreach task t and model, there is now a distribution of the number of tokens t and t, that the usersends and receives through the respective model in a given prompt. Note that the correspondingprice-per-prompt pt and qt are now random variables pt = p0t and qt = q0t, that depend on thespecific task. For any given task t, a user will prefer model B if",
  "t=1Dt(p0)1 {p0E[tn(Vt)] q0E[tn(Wt)]}": "To solve this problem, note that the inherent structure is equivalent to equation (3). Let t :=E[tn(Wt)]/E[tn(Vt)] be the corresponding competitive ratio of the two models and note that theset of tasks can be ranked according to this re-defined competitive ratio. Then, Theorem 1 followsusing the same steps and the re-defined t. Moreover, all subsequent results carry over from thisresult.",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-perimental results of the paper to the extent that it affects the main claims and/or conclusionsof the paper (regardless of whether the code and data are provided or not)?Answer: [NA]Justification: This is primarily a theory-driven paper. The only numerical analysis is acomputational example which we detail in the main paper.Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible is important, regardless ofwhether the code and data are provided or not.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  ". Experimental Setting/Details": "Question: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand theresults?Answer: [NA]Justification: We do not train any neural networks.Guidelines: The answer NA means that the paper does not include experiments. The experimental setting should be presented in the core of the paper to a level of detailthat is necessary to appreciate the results and make sense of them.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [NA]Justification: We do not have any experiments with statistical noise.Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
  ". Experiments Compute Resources": "Question: For each experiment, does the paper provide sufficient information on the com-puter resources (type of compute workers, memory, time of execution) needed to reproducethe experiments?Answer: [NA]Justification: There is no compute required.Guidelines: The answer NA means that the paper does not include experiments. The paper should indicate the type of compute workers CPU or GPU, internal cluster,or cloud provider, including relevant memory and storage.",
  ". Broader Impacts": "Question: Does the paper discuss both potential positive societal impacts and negativesocietal impacts of the work performed?Answer: [Yes]Justification: Broader societal impacts are discussed in the conclusion.Guidelines: The answer NA means that there is no societal impact of the work performed. If the authors answer NA or No, they should explain why their work has no societalimpact or why the paper does not address societal impact. Examples of negative societal impacts include potential malicious or unintended uses(e.g., disinformation, generating fake profiles, surveillance), fairness considerations(e.g., deployment of technologies that could make decisions that unfairly impact specificgroups), privacy considerations, and security considerations. The conference expects that many papers will be foundational research and not tiedto particular applications, let alone deployments. However, if there is a direct path toany negative applications, the authors should point it out. For example, it is legitimateto point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point outthat a generic algorithm for optimizing neural networks could enable people to trainmodels that generate Deepfakes faster. The authors should consider possible harms that could arise when the technology isbeing used as intended and functioning correctly, harms that could arise when thetechnology is being used as intended but gives incorrect results, and harms followingfrom (intentional or unintentional) misuse of the technology. If there are negative societal impacts, the authors could also discuss possible mitigationstrategies (e.g., gated release of models, providing defenses in addition to attacks,mechanisms for monitoring misuse, mechanisms to monitor how a system learns fromfeedback over time, improving the efficiency and accessibility of ML).",
  ". Safeguards": "Question: Does the paper describe safeguards that have been put in place for responsiblerelease of data or models that have a high risk for misuse (e.g., pretrained language models,image generators, or scraped datasets)?Answer: [NA]Justification: No data or models are released in this paper.Guidelines: The answer NA means that the paper poses no such risks. Released models that have a high risk for misuse or dual-use should be released withnecessary safeguards to allow for controlled use of the model, for example by requiringthat users adhere to usage guidelines or restrictions to access the model or implementingsafety filters.",
  ". Licenses for existing assets": "Question: Are the creators or original owners of assets (e.g., code, data, models), used inthe paper, properly credited and are the license and terms of use explicitly mentioned andproperly respected?Answer: [NA]Justification: No assets are introduced in this paper.Guidelines: The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  "According to the NeurIPS Code of Ethics, workers involved in data collection, curation,or other labor should be paid at least the minimum wage in the country of the datacollector": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA]Justification: No human studies were performed.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}