{
  "Abstract": "Ongoing efforts that span over decades show a rise of AI methods for accelerating scientific discovery[Fajtlowicz, 1988, Petkovsek et al., 1996, Wolfram et al., 2002, Buchberger et al., 2006, Baileyet al., 2007, Raayoni et al., 2021, Davies et al., 2021, Fawzi et al., 2022], yet accelerating discoveryin mathematics remains a persistent challenge for AI. Specifically, AI methods were not effectivein creation of formulas for mathematical constants because each such formula must be correct forinfinite digits of precision, with near-true formulas providing no insight toward the correct ones.Consequently, formula discovery lacks a clear distance metric needed to guide automated discoveryin this realm. In this work, we propose a systematic methodology for categorization, characterization,and pattern identification of such formulas. The key to our methodology is introducing metrics basedon the convergence dynamics of the formulas, rather than on the numerical value of the formula.These metrics enable the first automated clustering of mathematical formulas. We demonstrate thismethodology on Polynomial Continued Fraction formulas, which are ubiquitous in their intrinsicconnections to mathematical constants [Lagarias, 2013, Bowman and McLaughlin, 2002, Laughlinand Wyshinski, 2004], and generalize many mathematical functions and structures. We test ourmethodology on a set of 1,768,900 such formulas, identifying many known formulas for mathemat-ical constants, and discover previously unknown formulas for , ln(2), Gauss, and Lemniscatesconstants. The uncovered patterns enable a direct generalization of individual formulas to infinitefamilies, unveiling rich mathematical structures. This success paves the way towards a generativemodel that creates formulas fulfilling specified mathematical properties, accelerating the rate ofdiscovery of useful formulas.",
  "= tan(x)(1)": "enable calculating infinitely many digits for these constants. Discovering such formulas oftenleads to profound revelations regarding the properties and underlying structure of fundamentalconstants. For example, the continued fraction formula for tan(x), shown in Eq. 1, was used byJohann Heinrich Lambert in the first proof of the irrationality of Pi [Lambert, 1768][Berggren et al.,2004]. Unfortunately, such formulas are notoriously hard to find on-demand, often relying on amathematicians profound intuition. Part of the challenge is the lack of a well-defined distance, or a",
  "arXiv:2412.16818v1 [cs.AI] 22 Dec 2024": "metric, between a formula and a given constant. i.e., there is no known way to tell whether a formulais nearly accurate. The formula either works, or it does not. In other fields of science, a predictionaccurate to 1000 digits is precise enough for any practical need. However, in mathematics, if the1001st digit is wrong, the formula is incorrect and gives no insight regarding a correct formula. Thislack of a metric is a substantial hurdle both for human efforts and for automated analysis, as manymethods for optimization such as gradient descent become unsuitable. Recent efforts developed computer algorithms to discover a multitude of formula hypotheses formathematical constants [Raayoni et al., 2021], even implementing the first large-scale distributedcomputation for such discoveries [Elimelech et al., 2023], but they relied mostly on exhaustivesearch methods. These approaches complements earlier applications of algorithms for automatedtheorem proving (ATP) (such as computer proofs of hypergeometric identities [Petkovsek et al.,1996], Malarea [Urban, 2007], and Flyspeck [Kaliszyk and Urban, 2012]), and automated conjecturegeneration (ACG) (such as mechanical mathematics [Wang, 1960], the Automated Mathematician[Lenat, 1982], EURISKO [Lenat and Brown, 1984, Davis and Lenat, 1982], and Graffiti [Fajtlowicz,1988]). Here we propose a fundamentally new methodology for automated investigation and discovery offormulas for mathematical constants. We constructed a large dataset of continued fractions, and en-riched it with metrics based on their convergence dynamics, which are found to embody fundamentalinformation about each continued fraction. These dynamical metrics enable the identification andgeneralization of patterns within the dataset. Using the metrics, we develop a process of categorizationand clustering () of continued fractions that share similar values of their dynamical metrics.Analyzing each automatically identified cluster of formulas, we find that all its members often relateto the same mathematical constant, showing the value of the dynamical metrics for the discovery ofnew formulas and the internal structure of families of such formulas. This novel method of formuladiscovery allowed us to identify both previously known and completely new formulas for constantssuch as , ln(2), cot(1), the Golden Ratio, square roots of multiple integers, the Gauss constant, andthe Lemniscate constant.",
  "Further": "investigation No connection found : Systematic clustering and labeling of formulas by dynamical metrics. Our methodologyanalyzes Polynomial Continued Fractions (PCFs) in two main stages. Clustering: (a) Filter degener-ate PCFs. (b) Evaluate PCFs and extract their dynamics-based metrics (section 3). (c) Choose thebest few metrics and use them to cluster the data. Labeling: In every cluster, look for PCFs known inthe literature and use them as anchors. (d) If anchors are found in the cluster, validate that they do notcontradict, i.e., relate to different constants. (d.1) If all anchors are in agreement, choose a randomsubset of other points in the cluster and use PSLQ to validate that they also relate to the same constant.If the validation is successful, the cluster is labeled. If not, the cluster should be split. (d.2) If theanchors relate to different constants, the cluster should be split return to step c for finer clusteringof the data. When focusing on a specific cluster, the best metrics could be different than those forthe full dataset. (e) If no anchor is found in a certain cluster, attempt to label by (e.1) choosing asmall subset of PCFs in the cluster and running a PSLQ search for each of them against a large set ofpotential constants. If a connection is found, the cluster now has an anchor return to step d. (e.2) Ifan anchor is still not found, attempt to connect a sample of data points within the cluster using PSLQ.If successful, conclude that the cluster is correct, but has no identified constant. Define a new labelfor that cluster. If PSLQ failed to connect points within the cluster, return to step c for finer clustering.If no further refinement is appropriate, flag the cluster for further analytical investigation. As part of our analysis of metrics of continued fractions, we developed and applied the mostcomplete classification of polynomial continued fractions known to date, detailed in Appendix B.This classification includes the prediction of whether the continued fraction converges directly basedon its defining polynomials. Traditional clustering methods attempt to relate data points by calculating distance metrics basedon the parameters of these data points, e.g., the coefficients of the defining polynomials. The mostcommon approaches (like SVM) rely on linear classification, while more advanced methods rely onnon-linear kernel transformations - but usually use various functions calculated directly on the dataparameters. In our dataset, each point is a continued fraction formula defined by the polynomialsused to construct it. However, we find that it is not sufficient to use the parameters of the polynomials,and not even the numerical limit of the continued fraction. Instead, we find that it is the dynamicsof the continued fraction generated by these polynomials, rather than any direct function on theircoefficients, which provides the most useful metrics for analysis. In other words, we find thatthe useful underlying metrics to extract from each data point are embedded within the intricateprogression of the sequence created by the formula, rather than the explicit numerical value (limit)of that formula, or the coefficients defining it. Thus, in order to assess the distance between twopolynomial continued fractions, and identify relations between such formulas, it is imperative tocharacterize the nuanced behavior of their sequences, analyzing trends in the convergence process ofthese sequences, spanning over numerous terms. Some of the metrics we extract, such as the irrationality measure, are well-known in the mathematicalcommunity, yet were never considered for a large-scale classification effort. The evaluation of theirrationality measure is technically challenging for formulas whose limit is not known in advance(which is the vast majority). This challenge made it impossible to extract the irrationality of formulasfor a large dataset. Consequently, we develop a new algorithm the Blind- algorithm (.4) to enable the extraction of the irrationality measure of a continued fraction without prior knowledgeof its limit. This algorithm allowed us to extract the irrationality measure for the entire dataset. These advances provide the building blocks for our novel methodology for formula discovery. Wecluster formulas by their closeness to other formulas according to these new metrics, thus identifyingpromising formulas regardless of their numerical value (left). Once a candidate formula isfound, we numerically validate it by calculating its value to a large precision and then identifyingits relation to a mathematical constant. The generate validate approach is inspired by works inAI-driven code generation [Ridnik et al., 2024] and problem solving in geometry [Trinh et al., 2024].",
  "Polynomial Continued Fractions": "In this work we chose to focus on polynomial continued fraction (PCF) formulas as our test casedue to the combination of their simplicity and expressive power. PCFs relate to a wide range ofmathematical fields, represent a variety of constants, are equivalent to infinite sums [Euler, 1748],and cover mathematical functions such as Bessel functions, trigonometric functions, integral families,widely used Taylor series, and generalized hypergeometric functions [Cuyt et al., 2008]. Thus,studying PCFs can provide insight into a plethora of mathematical objects and applications.",
  "It is known that for irrational numbers this measure is 1 (Dirichlet theorem for Diophantineapproximations), and for rationals it is 0": "Note that the irrationality measure of L is greater or equal to the irrationality measure of any specificsequence converging to the same L. While the irrationality measure of a sequence can be any number -1, the irrationality measure of its limit L is always either 0 or 1 [Church, 2019].",
  "-Predictor Formula": "The classification of a large number of continued fraction formulas requires an efficient and accuratecalculation of the irrationality measure for each formula. This calculation is challenging becauseit depends on the asymptotic behavior of the converging sequence, and because appears as anexponent of a large basis number. The -Predictor formula that we present here provides a wayaround this challenge - requiring no specific knowledge about the convergence rate and trajectory, oreven about the sequence limit itself:",
  ", |1(n)| > |2(n)|": "This formula extends a hypothesis made in a previous work [David et al., 2021], which was limited toPCFs with deg(B) = 2deg(A) and with a qn that grows exponentially. As we found in this work, Eq.5works for any converging PCF. It was validated numerically and proven for the deg(B) = 2deg(A)case in Appendix F. This formula helps estimate the irrationality measure, a critical dynamical metricfor our work. Specifically, the asymptotic behavior of qn and 1/2 are still required for findingpredicted, but they are usually easier to derive.",
  "Discovery of Formulas by Unsupervised Learning": "Each PCF formula is defined by the polynomials that generate it. This work focuses on polynomialsup to 2nd degree: an = A2n2 + A1n + A0, bn = B2n2 + B1n + B0, with integer coefficients inthe domain 5 Ai 5, 5 Bi 5. We removed the a = 0 and b = 0 cases, as they breakthe PCF structure, leaving us with 1,768,900 formulas. Some of these PCFs do not converge to asingle limit, rendering their measured metrics meaningless (see Appendix B for the classificationmethod we developed to predict PCF convergence). We filtered out all formulas that do not converge,providing the final filtered dataset of 1,543,926 formulas.",
  "The growth rate of qn, comprised of three parameters: For each PCF, we fit the denominatorto qn n! en n for large n. We store the fitted parameters , ,": "Based on this set of metrics, we applied unsupervised clustering for unlabeled data (using thehierarchical density-based HDBSCAN algorithm [McInnes et al., 2017]). The clustering is the keycomponent in the algorithm we developed (), leading to the discovery of a variety of formulasand data patterns that exposed formula families (see sections 4.1, 4.2, 4.3, and 4.4 for selected results).",
  "If 0 < s <1 (m)": "(n) < S is bounded away from zero and infinity for all n large enough, then theapproximation of the Blind- algorithm has the same convergence rate as Eq.3, bypassing the need toevaluate L. Intuitively, this condition holds whenever |(n)| 0 fast enough, which is true for thevast majority of PCFs (see Appendix F for details).",
  "Choice of Metrics for Clustering": "As part of the automated formula discovery flow we choose the best metric (for each step), in termsof representation power, which is measured by applying the Davies-Bouldin Index [Davies andBouldin, 1979] on clustering using each metric individually. shows results for a randomlychosen sample of 25K converging PCFs. Note the extremely poor performance of the PCF limitL, in agreement with b,d. This dimensionality reduction is important for efficiency during theclustering step and for better explainability. The former is because the dataset size grows exponentiallywith the PCF degree and with the magnitude of the polynomial coefficients.",
  "Factorial coefficient 0.77": "Other metrics were tested. Some have been shown to have little to no representation power (e.g. pnand qn, as defined in Eq.2, modulo various primes, their sign, their GCD etc.) while others showpotential and are left for future study (e.g. the leading Fourier coefficients of the \"noise\" around the fitof qn). A relatively small number of metrics were measured and used, which helped keep the resultsmathematically explainable. Nevertheless, the clustering using the metrics in showcases thestrength of our dynamical metrics approach.",
  "deg < deg 2 deg = deg 2 deg > deg": ": Discovery of mathematical structures via analysis of dynamical metrics of formulas.(a) Projecting the data on the vs. (qn factorial coefficient) plane, it is easy to see the emergingsubsets. We focus on PCFs with 0, as a previous work [Elimelech et al., 2023] indicated thisas an important property. (b) Clustering in the vs. (qn exponential coefficient) plane showsexamples of common properties within a cluster, like rationality or convergence to a specific constant(up to a linear fractional transformation). Focusing further on the deg(B) > 2deg(A) cluster (asit is a clear anomaly in the 0 subset), we used a PSLQ algorithm to identify links betweenthese formulas and mathematical constants. This identification was feasible since a preliminary stepidentified a promising subset 5, 000 times smaller than the initial dataset. (c) The result of thisclustering and identification procedure is a structured arrangement of formulas that reveal a range ofnovel formulas related to constants such as , ln(2), 2, Gauss constant, and Lemniscates constant.(d) Keeping only PCFs with B2 = 1 we are left with a highly symmetrical checkerboard patternof formulas for and ln(2), which was generalized into infinite formula families hypotheses (seesection 4.3). Error bars not shown for visual clarity, see Appendix A for a discussion regardingmeasurement errors.",
  "LLemniscate 4(9)": "As well as for second order roots, and ln(2) (see section 4.3). Note that unlike the formulas in Eq.6and Eq.7, which are analytically proven, the formulas in Eq.8 and Eq.9 are (to the best of the authorsknowledge) novel. Their limits were numerically validated to a large precision, yet formal proofs forthese formula hypotheses remain an open challenge. It should be noted that usually in number theory, a bigger is considered good, whereas a smaller(often negative) is considered bad. We use as a metric, without judgment. These novelformulas (Eq.8, Eq.9 and the infinite family of formulas shown in section 4.3), which have the bad 1, are a demonstration that our non-judgmental approach is successful.",
  "Clustering in Dynamics-Based Metric Latent Space": "This section shows that clusters in the latent space of dynamics-based metrics are successful ingrouping together different formulas in a way that exposes their shared properties, such as themathematical constant to which they relate. Looking at the top left cluster in b (defined by qn exponential coefficient < 0.6 and > 0.9), werecognize the canonical form of the Golden Ratio PCF (shown in Eq.1). This cluster also contains 21additional PCFs, with different generating polynomials, some of higher degree. As it turns out, all ofthem are linear fractional transformations of 5 (see Appendix C), which were labeled automaticallyby the formula discovery algorithm (). Another example of property conservation within clustersis the rational cluster marked in green on b. The limits of the PCFs in this subset are varied,and its spread is real (i.e., not only due to numerical imperfections). Yet, all the PCFs in this clusterconverge to rationals - which is not directly measured by any of the latent space dimensions.",
  "showcases a collection of clusters with shared properties. Using a set of 126 (mathematicallyunique) known anchor formulas, 441 novel mathematical formula hypotheses were automatically": "discovered. The constants which are related to the most new conjectures are: e2 (28 anchor formulasgave 178 new conjectures), (39 anchor formulas gave 116 new conjectures), e (44 anchor formulasgave 80 new conjectures), and 17 (1 anchor formula gave 55 new conjectures). Some of the novelformulas are equivalent to known PCFs (see Appendix C for a discussion about equivalence) whileother formulas were analytically proven (see Appendix A.3 and Appendix G). Note the multi-anchor clusters of e and e2, as well as the algebraic roots: these clusters failed to singleout a specific constant, yet relate to constants of similar nature - suggesting meaningful clusteringnevertheless. For the sake of visualization the algorithm stopped after the second iteration. In astandard run these multi-anchor clusters would have been separated via additional metrics.",
  "Detecting Patterns and Underlying Structure": "As mentioned in section 4.1, the deg(B) > 2deg(A), 0 cluster, contains many formulas ofinterest (see c and d). They were discovered via a PSLQ algorithm, identifying linear fractionalrelations between the limit values of PCFs in the subset and notable mathematical constants (such as or e). This is a computationally heavy operation, and it would be challenging to run it on all 1.5Mformulas in the data set. Yet by first identifying the promising clusters, we reduce the search space 5, 000 times, allowing for a deeper inspection of each PCF.",
  "Once the checkerboard pattern in d was discovered, the hypothesis was expanded into 2infinite families of PCFs with sub-exponential convergence relating to and ln(2):": "an = i + 2j + 1, bn = n2 + (i + k)n, with integers i, j 0, and k {0, 1}. This isexpected to be related to if k = 1, and to ln(2) if k = 0 (in fact, this pattern can begeneralized even further, into a novel 3-dimensional Conservative Matrix Field, provided inAppendix C. See [Elimelech et al., 2023] for the definition of Conservative Matrix Fields).",
  "Novel square root formulas": ": Higher-degree PCF formulas for mathematical constants, overlaid on b. Formulas thatare equivalent to an existing element in the original dataset are marked with o, while x marks trulynovel formulas. The higher-degree PCFs fit, using the same dynamical metrics, into clusters trainedon lower-degree PCFs, showing the ability to identify novel formulas despite being of mathematicalforms not seen during training. The final validation for the dynamical metrics approach is to show its potential even on test sets of adifferent mathematical structure than the training set. For that purpose, the clusters created based onthe original dataset were treated as a classifier, and a test set of higher-degree PCFs (up to 3rd degreeAn and 4th degree Bn, coefficient range ) was created, measured and classified. Naturally, not all high-degree PCFs fit neatly into the existing clusters (as they represent constants thatwere not present in the original dataset), but some were correctly identified and labeled, discoveringnovel formulas in the process (see for a sample of the results).",
  "Discussion and Outlook": "This work marks an important step toward the vision of automated on-demand formula creation inmathematics. Going beyond all previous algorithms in this field, we connect the challenge of formulacreation to robust ML methods. This methodology provides a wide variety of automatically generatedformulas, including both previously known and previously unknown ones, exposing their underlyingmathematical structure and enabling new proofs. The next research step directly building on our methodology could help to finally reveal the completeintricate mathematical structure of PCFs. For example, starting with the band-structure found inc, or with clusters of formulas with various structures representing the same mathematical con-stant. Further exploration of our conjectures from section 4 could have more impact on mathematics,perhaps achieving further generalizations and prescriptive formula generation. The technique presented here can be applied to a larger scope of continued fractions and for completelydifferent types of formulas. For more general continued fractions, dynamical metrics such as thenumerical trajectories and the corresponding sequences of (in addition to its asymptotic value)hold valuable information even in continued fractions that do not converge at all. We expect thesedynamical metrics to provide a fingerprint for wider families of formulas and perhaps even forthe mathematical constants themselves. This approach was directly applied in this work to higherpolynomial degrees, larger polynomial coefficients, and can be expanded to continued fractionsnot based on polynomials. Looking beyond continued fractions, metrics that are derived from thedynamics of a numerical calculation of certain formulas are an especially good fit for automatedcomputer-assisted investigations. Such metrics can be measured for a variety of mathematicalstructures, including ones whose evaluation is iterative or recursive, that are defined via an infinitesum, or any other process which produces rational approximants. Any such mathematical structurecan be measured, clustered, and identified using the proposed method - treating the generatingfunctions as a black box. We believe that such dynamical metrics can unveil patterns and underlyingstructures in broad fields of mathematics and in other areas of science. To exemplify this universal concept, we looked into higher depth recursion relations, which are apromising research direction because little is known about their global structure, yet they are involvedin several important conjectures. For example, the best rational approximation formula known forEulers gamma constant is constructed via such a recursion relation [Aptekarev, 2009]. This familyof formulas is broader than continued fractions, yet they can be described by the same metricsas PCFs. Another type of mathematical structure successfully analyzed using the same methodis hypergeometric functions, showing the applicability of our measurement-clustering-generationapproach to a bigger family of mathematical functions. This generalization can be useful in a widevariety of contexts, such as investigations of integral formulas (e.g., Beukers-type integrals [Beukers,1979, Dougherty-Bliss et al., 2022, Brown and Zudilin, 2022]). Our work was based on a limited-size dataset and on a small set of metrics. It would be intriguingto test the extracted conjectures on larger datasets, which can help reveal additional, more intricate,phenomena. Considering the success we had using a relatively small set of metrics, we would like touse an order-of-magnitude larger set of metrics and find what new predictions can be recovered. Infact, the creation and evaluation of the metrics themselves can be automated. Taking a broader perspective, the methodology presented in this work can be seen as a generalprescription for tackling scientific discovery challenges in mathematics and theoretical physics thatrely on numerical evaluations and generalizations. Such an advance is especially exciting for suchchallenges that were considered in the past to require intuitive leaps of creativity.",
  "R. Davis and D.B. Lenat. Knowledge-based Systems in Artificial Intelligence. A McGraw-Hilladvertising classic. McGraw-Hill International Book Company, 1982. ISBN 9780070155572. URL": "Robert Dougherty-Bliss, Christoph Koutschan, and Doron Zeilberger. Tweaking the beukers integralsin search of more miraculous irrationality proofs a la apry. The Ramanujan Journal, 58(3):973994, 2022. Rotem Elimelech, Ofir David, Carlos De la Cruz Mengual, Rotem Kalisch, Wolfgang Berndt, MichaelShalyt, Mark Silberstein, Yaron Hadad, and Ido Kaminer. Algorithm-assisted discovery of anintrinsic order among mathematical constants. arXiv preprint arXiv:2308.11829, 2023.",
  "Leonhard Euler. Introductio in analysin infinitorum, volume 1,2. Apud Marcum-Michaelem Bousquet& Socios, 1748": "Siemion Fajtlowicz. On conjectures of graffiti. In J. Akiyama, Y. Egawa, and H. Enomoto, editors,Graph Theory and Applications, volume 38 of Annals of Discrete Mathematics, pages 113118. Elsevier, 1988. doi: URL Alhussein Fawzi, Matej Balog, Aja Huang, Thomas Hubert, Bernardino Romera-Paredes, Moham-madamin Barekatain, Alexander Novikov, Francisco J R Ruiz, Julian Schrittwieser, GrzegorzSwirszcz, et al. Discovering faster matrix multiplication algorithms with reinforcement learning.Nature, 610:4753, 2022.",
  "Godfrey Harold Hardy, Edward Maitland Wright, et al. An introduction to the theory of numbers.Oxford university press, 1979": "Charles R. Harris, K. Jarrod Millman, Stfan J. van der Walt, Ralf Gommers, Pauli Virtanen, DavidCournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J. Smith, Robert Kern, MattiPicus, Stephan Hoyer, Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime Fernndezdel Ro, Mark Wiebe, Pearu Peterson, Pierre Grard-Marchant, Kevin Sheppard, Tyler Reddy,Warren Weckesser, Hameer Abbasi, Christoph Gohlke, and Travis E. Oliphant. Array programmingwith NumPy. Nature, 585(7825):357362, September 2020. doi: 10.1038/s41586-020-2649-2.URL",
  "Josef Urban. Malarea: a metasystem for automated reasoning in large theories. ESARLT, 257, 2007": "Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau,Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stfan J. van der Walt,Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, EricJones, Robert Kern, Eric Larson, C J Carey, Ilhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas,Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R. Harris,Anne M. Archibald, Antnio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0Contributors. SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python. NatureMethods, 17:261272, 2020. doi: 10.1038/s41592-019-0686-2.",
  "To measure the growth coefficients of qn and (n), the values of log ((n)) (see section 3.4) and oflog (qn) were evaluated up to depth 1000": "The most resource-intensive values that are generated are pn, qn and gcd(pn, qn) - all other valuesare calculated from them (and require less precision). For the worst case PCF this requires 36MB ofmemory (without optimizations) and 1.9 seconds of run time on a single core of a basic workstation,which translates to an upper cap of 900 hours for the whole data set. In practice we used a highpower cluster with 64 cores, which ran each iteration of the measurements in 8.5 hours.",
  "One may justifiably wonder if 5 data points are sufficient to fit accurately enough the desired metrics": "A test comparing between a 5 data point fit and a 1000 data point fit was done. As the test set, 50PCFs were randomly chosen out of each of 9 categories (450 total test cases). The categories wereall combinations of deg(a) = 0, 1, 2 and deg(b) = 0, 1, 2. Focusing on the dominant coefficients( and ), for each case, a full (1000 point) fit was performed (producing f, f), and compared tothe down sampled fit of 5 points (producing p, p). We tested 2 methods of choosing the 5 points,even (i = 6, 206, 406, 606, 806) and logarithmic (i = 6, 125, 250, 500, 1000). The relative error wasthen calculated ( |pf |",
  "|f |and |pf |": "|f |) for (n) and qn. The relative errors were then averaged overthe test set (results summarised in table 2) - showing the 5-point fit to be almost as good as the full1000-point fit. In our measurements we use the logarithmic point distribution as it gives better resultsfor most metrics.",
  "s 3s 0s 2s 1": "We can further elaborate on the converging cases by discussing the conjectured rate of convergence.Usually, a PCF is expected to converge at a sub-exponential rate, but in the case of s = 0, C0 > 0 itis expected to converge faster: If C0 = 1 then the PCF will converge at an exponential rate, and the exact rate of convergenceincreases monotonically as C0 1, with a vertical asymptote at C0 = 1. The convergencerate is identical for C0 and1C0 .",
  "CDiscovering equivalence of continued fractions": "Polynomial continued fractions use two polynomials an = a(n) and bn = b(n) to generate asequence of rationals pn/qn. However, the same sequences with identical behaviour can be generatedusing more then one set of polynomials. By identifying transformations under which the dynamicsof pn/qn remains invariant, we can formally prove equivalence between data points, validating theclustering power of the chosen metrics.",
  "qn is identical tothe original one, it exhibits the same dynamics. We call this process Inflation by cn": "The metrics we are interested in are mostly not affected by a finite number of elements in the sequence.For example, both the convergence rate and discuss an overall trend as n grows. Consequently, wecan initiate the sequence at different values of n = 0 without changing the latent parameters. Whenexpressing these transformations as modification to the continued fraction definition, we see that thelimit of the continued fraction might change due to this shift in sequence initiation, but only by arational fractional transform.",
  "pnqn a0": "For example, we consider the cluster of formulas related to the golden ratio shown in figure 3b. Alarge portion of these PCFs stem from transforming the known formula for the golden ratio shown inEq.1 via the methods aforementioned. The exact transformations are depicted in . : Continued fractions converging to linear fractional transformations of the Golden Ratio ,found using the top left cluster of b. Numerous data points in this cluster exhibit identicalsequence dynamics and are equivalent under the inflation and index indentation transformations. Theequivalent data points create families of continued fractions in the cluster. Discrepancies betweenthe calculated irrationality measure within the same family is ascribed to numerical inaccuracies,typically on the order 0.001. However, when comparing families, discrepancies in the irrationalitymeasure rise to a magnitude of 0.04, suggesting potential deeper distinctions among these PCFs.",
  "DScalability to Larger Datasets": "The methodology can be scaled to larger data sets in multiple ways. For example, by extending therange of PCF coefficients from to , the size of the data set increases by approximately50 times. Additionally, by considering polynomials of higher degrees - such as advancing to third-degree an and fourth degree bn with coefficients in - the dataset size can be amplified byapproximately 1,333 times.",
  "To manage the substantial computational demands associated with these expansions, a three-foldsolution is proposed": "First, a dynamically chosen measurement depth is implemented during evaluation, aiming for afixed precision across all PCFs rather than maintaining a constant depth for all computations. Thisapproach optimizes computational efficiency by adjusting the measurement depth based on thespecific convergence rate of each PCF. Second, using known equivalences of PCFs such as inflation (see Appendix C), it is possible tosubstantially decrease the effective size of the dataset that needs to be measured. In particular, whencn = 1, we observe that the sign of an does not affect the dynamics of the sequence - only flips the sign of the limit to L. For every PCF its inflation by -1 is also contained in the current data set, andclearly will have the same dynamics-based metrics. This equivalence single handedly de-facto cutsthe size of the current data set by half (to 771,963 converging formulas). Third, the inherently parallelizable nature of computing metrics for each formula is leveraged.The algorithm has been adapted and deployed within the Berkeley Open Infrastructure for NetworkComputing [Anderson, 2004], enabling parallel computation across thousands of volunteer computers.Assuming a typical contribution of approximately 1,000 BOINC volunteer cores, processing theexpanded data set requires about one month of computational time.",
  "EClustering Visualizations": ": Automated clustering and labeling of PCFs via a 2D tSNE with perplexity = 10. Clusterswere verified via PSLQ relations between members of the cluster and known formulas. For visualclarity not all points are shown and error bars are not shown, see Appendix A for a discussionregarding measurement errors. and show alternate clustering and 2D visualization approaches (in addition to ). Thesame set of anchors was used for all 3 versions. The tSNE algorithm () provides a visualizationthat separates well between clusters, but loses out on explainability. In the opposite approachwas taken - using only 2 dynamical metrics for clustering allows each cluster to be defined veryclearly, but information from other dynamical metrics (which can be used for better cluster separation)is lost along the way.",
  "FAnalysis of the convergence rate": "The growth rate for simple continued fraction or equivalently for constant linear recurrences is wellunderstood, and usually boils down to the matrix defining the recurrence, and its eigenvalues. In ourcase, the coefficient in the recurrence also depend on n, so their study is more involved, however theideas are similar, which we now describe : Automated clustering and labeling of PCFs via HDBSCAN. Only 2 dynamical metricswere used, and (as in a), and yet the clustering is already informative. For visual clarityerror bars are not shown, see Appendix A for a discussion regarding measurement errors.",
  "Let d = maxda, 1": "2dband denote by A, B the coefficients of xd, x2d of a (x) , b (x) respectively.Note that both A, B are either the corresponding leading coefficients or zero, depending on whetherda = d, respectively db = 2d. If 2da < db and db is odd, then da < d = db",
  "with 1 > |2|, we expect that for almost every": "initial condition(1, 1) Dk k1. This is true as long as the initial vector is not in R e2, and wehave similar behaviour for other type of matrices. When the Dn are not constant, we need to take alittle bit more care. The image you should have in mind is the following: Instead of the two eigenvectors being on the X and Y axes, they only converge to it, so we onlyknow that they are somewhere inside the red and blue regions. Thus, to understand this system wefirst need a separation condition saying that these regions are disjoint. Assuming the X-axis is the pulling axis (larger eigenvalue), we will need at least one point outside the error region around the Yaxis, which we call the initial condition. Once both these conditions hold, a standard investigationof diagonalizable product will show that the points orbit converge towards the eigenvector in theX-region. As this region shrinks to X in the limit, we see that the limit of the orbit is there as well."
}