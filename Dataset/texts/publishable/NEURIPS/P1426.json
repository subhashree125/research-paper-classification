{
  "Abstract": "Recent advances in techniques for monitoring and perturbing neural populationshave greatly enhanced our ability to study circuits in the brain. In particular,two-photon holographic optogenetics now enables precise photostimulation ofexperimenter-specified groups of individual neurons, while simultaneous two-photon calcium imaging enables the measurement of ongoing and induced activityacross the neural population. Despite the enormous space of potential photostimula-tion patterns and the time-consuming nature of photostimulation experiments, verylittle algorithmic work has been done to determine the most effective photostimu-lation patterns for identifying the neural population dynamics. Here, we developmethods to efficiently select which neurons to stimulate such that the resultingneural responses will best inform a dynamical model of the neural population activ-ity. Using neural population responses to photostimulation in mouse motor cortex,we demonstrate the efficacy of a low-rank linear dynamical systems model, anddevelop an active learning procedure which takes advantage of low-rank structureto determine informative photostimulation patterns. We demonstrate our approachon both real and synthetic data, obtaining in some cases as much as a two-foldreduction in the amount of data required to reach a given predictive power. Ouractive stimulation design method is based on a novel active learning procedure forlow-rank regression, which may be of independent interest.",
  "Introduction": "Neural population dynamics describe how the activities across a population of neurons evolve overtime due to local recurrent connectivity and inputs to the population from other neurons or brain areas.Identifying these population dynamics can provide critical insight into the computations performedby a neural population . Dynamical systems models have enabled neuroscientists to generate andtest a multitude of hypotheses about how specific neural populations support the neural computationsthat underlie, for example, motor control , motor timing , decision making , workingmemory , social behavior , and learning . The traditional approach to data-driven modeling of a neural population typically involves two sep-arate stages. First, neural population activity is recorded while an animal performs a task of interest.",
  "arXiv:2412.02529v2 [q-bio.NC] 3 Jan 2025": "Then, a dynamical systems model is fit to the recorded neural responses . This approachsuffers from two key limitations. First, any inferred structure is purely correlational, and cannot beinterpreted with any notion of causality. Second, the experimenter has limited control over how theneural population dynamics are sampled, which can lead to inefficient data collectionoversamplingin some parts of neural activity space while altogether missing others. Given constraints on timeand resources in neurophysiological experiments, there is a strong need for techniques that minimizethe amount of experimental data required to identify the neural population dynamics. We seek to overcome these limitations by actively designing the causal circuit perturbations thatwill be most informative to learning a dynamical model of the neural population response. Forcircuit perturbations, we employ two-photon holographic photostimulation (), which providestemporally precise, cellular-resolution optogenetic control over the activity of ensembles of neurons. When paired with two-photon calcium imaging, photostimulation protocols can provideinsight into network connectivity by enabling the measurement of the causal influence that eachperturbed neuron exerts on all other recorded neurons . This platform enables targetedexcitation of the neural population dynamics, thus providing the experimenter with unprecedentedcontrol over the data collected for informing a model of the neural population dynamics. Here, we develop active learning techniques for designing photostimulation patterns that allow forefficient estimation of low-rank neural population dynamics and the underlying network connectiv-ity. First, we introduce a low-rank autoregressive model that captures low-dimensional structurein neural population dynamics and allows inference of the causal interactions between recordedneurons. We then propose an active learning procedure which chooses photostimulations to targetthis low-dimensional structure, and demonstrate it in two settings: estimating the underlying causalinteractions when using the learned autoregressive model as a simulator of the true dynamics, andadaptively selecting which samples to observe from our dataset of neural population activity recordedvia two-photon calcium imaging of mouse motor cortex in response to two-photon holographicphotostimulation. In both cases, we show that our active approach obtains substantially more accurateestimates with fewer measurements compared to passive baselines. Our methodology is based on anovel analysis of nuclear-norm regression with non-isotropic inputs. To the best of our knowledge,this is the first approach to demonstrate significant gains applying active learning to low-rank matrixestimation problems, and thus we believe this may be of independent interest.",
  "Related Work": "Modeling Neural Responses to Stimulation. Many studies have applied direct electrical or opticalstimulation to neural populations to probe the dynamical properties of neural circuits and theirrelation to circuit function . However, these stimulation techniques lack the spatialspecificity needed to precisely probe the causal influence of individuals neurons on the populationdynamics, and these experimental designs were passive in that the stimulation protocols were specifiedprior to data collection (with as notable exceptions). Other work has explored a related butseparate problem of minimizing off-target effects when photostimulating individual neurons . Low-Rank Matrix Recovery. Low-rank matrix recovery has been intensively researched over thelast decade and a half . However, existing analyses rely critically on the assumption that theset of measurements taken are highly symmetric and satisfy some notion of the restricted isometryproperty (RIP) or incoherence. The matrix recovery problem of our setting departs from the classicalliterature in several ways. First, the set of feasible measurements we can take is constrained by thephysical limits of the photostimulation system. Second, as we aim to adapt and actively learn thesematrix coefficients, we should expect that our resulting set of measurements should be highly skewedby design. Motivated by this, we develop, to the best of our knowledge, the first bounds on low-rankestimation using the nuclear norm heuristic that gives a quantification of the estimation error in termsof the precise individual measurements taken (i.e., in contrast to a more global property like RIP). Active Learning and Low-Rank Estimation. The active learning literature is vast, and a full surveyis beyond the scope of this work. We focus in particular on active learning for dynamical systems, andproblems with low-rank structure. The estimation of dynamical systemsthe system identificationproblemis central to many areas of engineering and science . The problem of actively designinginputs to effectively estimate the parameters of a dynamical system has been studied extensively fordecades . More recently, a variety of provably efficient approaches have been developed for",
  "two-photon holographic stimulation(a)": ": (a) Two-photon imaging and holographic photostimulation platform (left) and a representative imageframe (right). Purple circles indicate neurons photostimulated immediately before frame acquisition. Redand blue indicate increases and decreases of firing activity, respectively, relative to before photostimulation.(b) Example time series photostimulation inputs (top) and neural responses (bottom) from 100 randomlyselected neurons (out of d = 663 recorded neurons identified in the FoV). (c) Neural responses yt occupya low-dimensional subspace. Singular values from a representative datasets demeaned neural activity datamatrix (blue) indicate substantially more data variance residing in a few dozen dimensions (out of the fulld = 663 dimensional neural activity space) than is expected by chance (orange, singular values when removinglow-dimensional structure by shuffling time indices independently for each neuron; note clipped horizontal axis). both linear and nonlinear systems. Other related work has considered active learningfor latent variable models , which are often effective models of neural dynamics. As comparedto these works, a key feature of our setting is the low-rank structure present in the data, which toour knowledge has not been previously studied within the active system identification literature. Beyond dynamical systems, some attention has been devoted to active learning with low-rank struc-ture, in particular works on low-rank bandits . While the setting considered in these works issomewhat differentthey aim to solve a bandit problem, while we are interested in regressiontheysimilarly seek to develop active learning approaches which make efficient use of low-rank structure.Also related is the work of , which shows that in the related sparse estimation setting, theredoes not exist more than a logarithmic gain to being adaptive. The results of this work are minimax,howeveronly applying to certain hard problemsand do not address the matrix recovery problem.",
  "Preliminaries": "Dataset Details.Neural population activity was recorded in mouse motor cortex using two-photoncalcium imaging at 20Hz of a 1mm1mm field of view (FoV) containing 500-700 neurons. Eachrecording spanned approximately 25 minutes and 2000 photostimulation trials. In each trial, a 150msphotostimulus was delivered and was followed by a 600ms response period before the next trial began.Each photostimulus targeted a group of 10-20 randomly selected neurons, and a total of 100 uniquephotostimulation groups were defined for each experiment ( 20 trials per group). We evaluate ourtechniques on four such datasets.",
  "Fitting Low-Rank Dynamical Models": "We first seek to develop effective dynamical models of the neural activity in our photostimulationdatasets. Obtaining such models will provide insight into which photostimuli are most informative,and gives us a means to evaluate the effectiveness of our active learning methods. We consider threeclasses of models: autoregressive (AR) models, low-rank AR models, and nonlinear RNN models.Results from fitting these models are shown in . We describe the model details next. At discrete time t N, we denote the true neural activity across the d imaged neurons as xt Rd,the noisy, measured activity as yt Rd, and the photostimulus intensity applied across thosesame d neurons as ut Rd. Applying stimulus ut influences the measured neural activity at thenext timestep yt+1. However, just the snapshot yt may not capture the full true state of the neuralpopulation, which may include not just the current neural activity, but potentially also multiple ordersof temporal derivatives. To capture these effects, we consider an AR-k model defined as:",
  "stimulationinputs": ": Example data and cross-validated model predictions. (a) Roll-out predictions of the activityof an example neuron i using low-rank AR-k models (k = 4) and GRU networks for 22 exampledata segments (3.3s per segment; segments separated by brief horizontal spaces). Each modelspredictions are seeded with the first k = 4 timesteps (200ms) of activity from d = 663 neurons andare then unrolled to predict the activity across all d neurons over the next 66 timesteps, given the full70-timestep sequence of photostimulation to all d neurons. Most responses of neuron i are tied todirect photostimulation of neuron i (pink, first row of panels). Several indirect responses are tiedto stimulation of other neurons j = i that influence neuron i through the population dynamics. Toavoid showing all indirect stimuli (to d 1 neurons), only select indirect stimuli are shown (green,second row of panels). (b) Receiver operator characteristic (ROC) curve of true-positive rate andfalse-positive rate for response detection are calculated on indirect responses only (left) and all directand indirect responses (right). (c) Area under ROC curve (AUROC) and (d) mean square error (MSE)for all predictions. input-observation pairs {(ut, yt)}t, the coefficients {(As, Bs)k1s=0, v} of (3.1) can be fit using leastsquares. Despite its simplicity, this linear model reproduces the recorded neural activity remarkablywell (see full rank model of ). Neural population dynamics are frequently reported as residing in a subspace of lower dimensionthan the total number of recorded neurons . The population dynamics in our datasetsare consistent with such low-dimensional structure, as indicated by the singular value spectrum in Fig-ure 1(c). Inspired by this observation, we introduce a set of low-rank dynamical models, where eachmatrix of {(As, Bs)k1s=0} is re-defined as diagonal plus low-rank. Explicitly, we parameterize As =DAs + UAsV As and Bs = DBs + UBsV Bs, where D Rdd with Dij = 0 for all i = j, U Rdr,and V Rdr for predefined rank r. The diagonal matrices account for substantial autocorrelationin each neurons activity (DAs) and for the reliable response of each neuron to direct photostimu-lation (DBs), whereas the low-rank matrices (UV ) confer coupling between neurons. To fit theseparameters, we optimize the following objective function with gradient descent over all parameters:",
  "minimizeAs,BsRdd,s=0,...,k1,vRdTt=1yt+1 k1s=0 Asyts k1s=0 Bsuts v)2.(3.2)": "shows that these low-rank models perform comparably to the full rank versions in terms ofpredictive performance; indeed the rank r = 35 model appears almost indistinguishable from the fullrank model. From a statistical perspective, low-rank models have far fewer degrees of freedom, andhence require less data to fit. To assess whether more expressive nonlinear models could be advantageous, we also fit a gatedrecurrent unit (GRU) network model, adapted from , as shown in . Interestingly, theGRU model did not perform as well as the AR-k models, potentially due to the complexities ofhyperparameter tuning. Therefore, we focus on linear models in the analysis that follows. Additionaldetails on model fitting are provided in Appendix B.2.",
  "The Causal Connectivity Matrix": "While we require dynamical models to predict the temporal evolution of the neural population activity,we are also interested in inferring how the activity of one recorded neuron causally influences theactivity of the other recorded neurons. To address this need, we define a causal connectivity matrix,H Rdd, to be the mapping such that Hu Rd quantifies the total response (across time) ofeach neuron to a single-timestep photostimulus u. That is, t=1 xt = Hu, where x1, x2, x3, . . . arethe neural activities generated by the population dynamics if u0 = u, ut1 = 0, and xt0 = x isthe steady state or resting state of the system subject to no photostimulation. If the dynamics arelinear, or more specifically follow (3.1), such a matrix H is guaranteed to exist, and can be formed bysimply rolling out (3.1) with the appropriate initializations. While H is not explicitly constrained tobe low-rank, if it is obtained from a low-rank AR-k model, it too will exhibit low-rank structure. In our experimental paradigm, photostimulation acts as a causal perturbation to the populationdynamics, and as such, our statistical framework is able to capture causal interactions, as opposedto merely correlative interactions. This is in contrast to the majority of work on neural populationdynamics, which involves fitting dynamical models to passively obtained data. Due to the lack ofcausal manipulations in these studies, one cannot distinguish whether statistical relationships arisebetween neurons due to correlation (e.g., due to a shared upstream influence) versus causation (e.g.,neuron i directly influences neuron j). Such correlative relationships are typically referred to asfunctional connectivity; we instead use the term causal connectivity to convey the additionalcausal interpretability afforded in our setting. To fit H, we could first fit { As, Bs}k1s=0 and then use these as plug-in estimates for their true values tocompute H. Alternatively, we take a more direct approach inspired by the definition of H itself. Byinspecting the raw data of (a) and observing the rate at which each stimulated neuron returnsto baseline activity, it is clear that the system mixes (i.e., forgets the past) quickly. This suggests thatthe total response due to input u asymptotes after some finite number of timesteps . Thus, we canapply some photostimulus u Rd at time t = 0 and then measure the total response z = t=1 yt,where yt Rd is the noisy measurement of the true neural response xt. If we repeat this for manypairs {(un, zn)}n then we can approximate H asH := arg minH n zn Hun22.In this work we adopt this latter approach. Since we believe H to be low rank, this amounts to alow-rank matrix recovery problem with matrix-vector observations. In the next section, we willdescribe how to adaptively choose {un}n to estimate H using as few (stimulus, response) pairs aspossible. Subsequently in , we will demonstrate that actively designing inputs to acceleratethe learning of H effectively accelerates the learning of the full dynamics as well.",
  "Active Learning of Low-Rank Matrices": "In the previous section, we saw that estimating the causal connectivity matrix H induced by the neuralpopulation dynamics amounts to low-rank matrix recovery, where we apply some photostimulusu Rd and observe the neural population response z Hu plus noise. In this section we seek tounderstand how we should choose the photostimuli to estimate the causal connectivity as quickly aspossible. To this end, in .1 we present novel results characterizing the estimation error of thenuclear norm regression estimator, and in .2 present an algorithm motivated by these resultswhich seeks to actively estimate low-rank matrices. These results will directly motivate a procedurefor designing photostimulation inputs. To demonstrate the generality of our results, in .1 we consider a general matrix regressionsetting. In particular, let Rd1d2 be a rank r (potentially non-square) matrix, n Rd1d2some input matrix, and assume scalar observations:zn = , n + n,n N(0, 1),(4.1) where , n = tr( n) for tr() the trace of a matrix. Note that the setting considered in.2 is a special case of this observation model with H and, for each input stimulationu, measuring the response of (4.1) to d inputs j of the form j eju for j = 1, . . . , d. Matrix Notation.We let F, op, denote the Frobenius, operator, and nuclear norm ofa matrix, respectively. denotes the pseudo-inverse of a matrix. vec() denotes the vectorization of amatrix, and mat() the inverse of the vectorization. We also let U denote the simplexthe set ofdistributionsover a set U.",
  "= arg minK() z22 := Nn=1(n, zn)2forK := { : }, (4.2)": "where here we let () RN denote the vector where the nth element is n, , and z =() + the vector of observations, for the vector with elements n. Define = UV asthe skinny SVD such that U Rd1r, V Rd2r, and consider the linear projection operatorsP, P : Rd1d2 Rd1d2 defined as:",
  "P(M) := (I UU )M(I V V )andP(M) := M P(M),": "for any M Rd1d2. We call P the projection onto the tangent space of . Note that thedimension of the range of P is equal to just r(d1 + d2) r2 d1d2. We are now ready to state ourmain result on the estimation error of , for as defined in (4.2).Theorem 1. Define := ()1/2((PP))1/2op. Then with probability at least 1 2:",
  "n nn, M and tr() describes the sum of the eigenvalues of the linearoperator (PP) : Rd1d2 Rd1d2": "Theorem 1 provides a precise bound on the estimation error of the nuclear norm estimator underarbitrary inputs {n}n. To the best of our knowledge, this is the first such characterization of thisestimator. This characterization is particularly essential in active learning problems, such as the prob-lem considered here, where it is critical that we understand precisely how the estimation error scaleswith different inputs, in order to determine which inputs will most effectively reduce the estimationerror. As the observation model of .2 is a special case of the setting considered in (4.1) with H, Theorem 1 provides a quantification of how quickly we can estimate the causal connectivitymatrix given some set of inputs; we expand on the implications of this connection in .2. Theorem 1 states that the estimation error of the estimator (4.2) scales (predominantly) with thestrength of our inputs n in the tangent space of . Indeed, if [w1, . . . , wd1] and [v1, . . . , vd2] arethe left and right singular vectors of the full SVD of , and L Rd1d2r(d1+d2)r2 is a matrix withorthonormal columns vec(wivj ) for (i, j) : {i r} {j r}, then",
  "tr(PP)= trLNn=1vec(n)vec(n)L,": "so we see that the estimation error depends only on the scaling of Nn=1vec(n)vec(n) inthe space spanned by vec(uivj ) for i r or j rthe tangent space to . As an exampleof how this scales, assume that for n = 1, . . . , N the entries of each n are IID N(0, 1) andN r(d1 + d2) r2. Then 0, tr(PP) r(d1+d2)r2",
  "N": "Critically, we see that this does not scale with the total number of parameters, d1d2, but instead withr(d1 + d2), which could be much smaller. The following result, due to , provides a lower boundon the estimation error of any unbiased estimator, and shows that the rate obtained by Theorem 1 isessentially unimprovable.",
  "Active Learning for Low-Rank Matrix Estimation": "Given the above characterization, we turn now to the active learning problem: how can we bestchoose our inputs n to speed up estimation error of ? For simplicity, rather than the generalmatrix regression setting of (4.1), we consider here the vector regression case, as this is the setting ofinterest in learning the causal connectivity. In particular, assume that we play some un Rd2 andobserve zn = un + n, for n N(0, Id1). A single vector observation corresponds to observingd1 observations from (4.1), the responses to the matrix inputs j ejun for j = 1, . . . , d1. Assumethat is rank r and let V0 := [v1, . . . , vr] denote the first r right singular vectors of the full SVD of. Then we have that:",
  "tr(PP)= (d1 r) tr(V 0 NV0)+ r tr(N),N := Nn=1unun .(4.3)": "This calculation, combined with Theorem 1, shows that the estimation error of scales with a weight-ing of two terms: one quantifying the amount of input energy we put into directions spanned by the top-r right singular vectors, and one that quantifies the amount of input energy played isotropically (that is,in all directions). Note, however, that the input energy played in directions V0 is weighted by a factorof d1 r d1, much larger weight than the weight of r given to the term quantifying the isotropic in-put energy. This suggests that, to minimize the estimation error of , we should focus a large portionof our sampling budget to target the directions spanned by the top-r right singular vectors of . This strategy admits a transparent intuition. If is rank-r and some vector u is orthogonal to the top-r right singular vectors of , then u = 0. Thus, if we know what subspace the top-r right singularvectors of span, playing u orthogonal to this subspace gives us no additional information about; in this case we should instead play u aligned with this subspace. This is precisely what the firstterm in (4.3) quantifies, while the second term reflects the fact that we must also estimate the subspacespanned by the top-r right singular vectors of , for which playing inputs isotropically is optimal. In general, as we do not know , we do not know V0, and so cannot directly compute inputs minimiz-ing (4.3). To circumvent this, we consider the following iterative procedure, which alternates betweenobtaining an estimate of , , and then playing the inputs that would minimize the estimationerrorminimize (4.3)if were the true parameter. We present this procedure in Algorithm 1.",
  ": return +1": "At every iteration , Algorithm 1 computes two distributions over inputs: V , which targets thetop-r right singular vectors of our current estimate of , and unif, which plays inputs isotropically,covering all directions. Rather than playing these distributions according to the precise weightinggiven in (4.3), we instead found it most effective to mix them at an equal rate. As we do not initiallyknow which directions are spanned by the top-r right singular vectors of , V is not guaranteedto target the correct directions, especially in early iterations. unifplays inputs in every direction,however, and thus, even if V is not aligned to the top-r right singular vectors of , will ensure",
  "sufficient energy is still being played in the correct directions to allow for learning. Given this, weincrease the weight of playing unifrelative to that prescribed by (4.3)": "Note that the computation of the optimal inputs is a form of A-optimal experiment design , whichin general can be efficiently solved by, for example, the Frank-Wolfe algorithm . Furthermore,efficient procedures for solving nuclear-norm regression problems exist, allowing us to estimate +1on line 6 efficiently . We remark that Algorithm 1 takes as input r, the rank of , and K, whichrequires knowledge of . In general, when these quantities are unknown, they can be chosen viastandard cross-validation procedures. We emphasize again that the setting considered here corresponds precisely to the setting consideredin .2 with H, un the input stimulation patterns, and zn the observed neural responseto input un. As such, if the causal connectivity H is low rank, Algorithm 1 and the preceding resultsprovide a methodology to select input stimuli to most efficiently estimate H. In the following section,we will apply this to our photostimulation datasets.",
  "Active Learning for Estimating Neural Population Dynamics": "We return now to the problem of photostimulus design for learning neural population dynamics,and seek to apply the insights of to this setting. We present two sets of experiments. In.1 we use real data to fit a model of the population dynamics, treat this fitted model asa simulator for the true dynamics, and then demonstrate that we can learn the causal connectivitymatrix H of this simulator faster using active inputs versus passive inputs. Then, in .2 wesplit our real data into 750ms long trials of (stimulus, response) pairs (see ) and demonstratethat our active learning algorithm is able to improve the performance of learning dynamical modelson real data by adaptively selecting which trials to observe, training a model on the observed trials,and evaluating on a hold-out set of unseen trials. Here we find that our approach is able to learn anaccurate model of the dynamics more quickly than non-adaptive approaches.",
  "Active Learning on Data-Driven Neural Population Dynamics Simulator": "In .1, we demonstrated that photostimulation data can be effectively reconstructed using anAR-k dynamics model. Given the effectiveness of these models at fitting our data, in this section wetreat them as a simulated representation of our true dynamics, allowing us to query them arbitrarilyas a stand-in for the ground truth dynamics, and seek to determine whether carefully choosing thephotostimulation pattern allows for efficient estimation of the causal connectivity matrix H. Experiment Details. To obtain models of the population dynamics to use for simulation, we fit anAR-k model to each dataset as described in .1. In all cases we use an AR-k model withorder k = 4. We do one run of the experiments using low-rank model parameters UV with rankr = 15, and then repeat the experiments using r = 35. In each case, we simulate N = 10000 trials,where each trial corresponds to applying a photostimulus and observing the response for = 15timesteps, simulating our true data generation process. To simulate measurement noise and othertrial-to-trial variability in neural responses, we corrupt the observations with Gaussian random noise.Motivated by the empirically observed fast decay of population dynamics in our datasets, we resetthe initial state of the simulator at each new trial. In practice, both the magnitude of the stimuli and number of neurons stimulated at each timestep areconstrained by the photostimulation platform. To reflect this limitation in our simulator, we constrainour inputs to lie in , and also impose a sparsity penalty. Precisely, we choose the input set U inAlgorithm 1 to be U := {u d : u1 }, for some value > 0 (which we set to = 30).While this does not explicitly constrain inputs to be sparse, it can be efficiently optimized over, andwe found in practice that the optimal inputs within this constraint set are in general at least 2-sparse.As baseline methods, we consider the following:",
  "(d) Mouse 3 (FoV B)": ": Performance of active learning estimating photostimulation response on held-out trials.Each mouse dataset is split into trials corresponding to a stimulus-response pair, and we considerhow these trials might be ordered to obtain more effective estimates with fewer training data trials,simulating the active learning process. Our approach (Active) is motivated by the low-rank excitationcriteria of Algorithm 1 (see Appendix B.4 for more details) and we compare with randomly choosingwhich trial to observe next (Random). We plot the accuracy of the learned model in predicting neuralresponses on held-out test trials. We consider 20 different train-test splits (with 20 trials per split),and include plots of average performance across these splits, as well as splits where Active has thelargest and smallest improvement over Random. We plot error bars denoting 1 standard error (noteagain that the error bars are barely visible as the standard deviation is very small). We fit a dynamics model to the current set of observed trials, as described in .1, and usethis model to predict the response of the true system on the held-out test inputs, computing themean-squared error of these predictions as our metric. We apply a variant of Algorithm 1, describedin more detail in Appendix B.4, and adapted to the query model above. In particular, to applyAlgorithm 1 to learning a full dynamical system, we choose our inputs to target the right singularvectors of Bs in (3.1). As a baseline method, we consider the procedure which randomly chooses anunobserved segment from Dtrain at each iteration. We run the above experiment for 20 different randomly generated train-test splits on each dataset, andpresent our results in , providing the results for the average performance over the train-testsplits, as well as the best- and worst-case splits for active learning performance. As these resultsillustrate, though active learning does not give a substantial gain in all cases, in many cases it is ableto give a gain of up to a factor of 2 in the number of samples required over the random baseline, andin the worst case, matches the baseline performance. This further confirms that taking into accountlow-rank structure when choosing which measurements to take can improve estimation rates, and, webelieve, is a strong indicator that our active learning procedure would speed up estimation of neuralpopulation dynamics in online settings.",
  "MHF, for H our estimate of H, M a matrix with all entries 1 except its diagonal,which is 0, and element-wise multiplication": "Experiment Results. We present our results in . As can be seen, across all learnedsimulators and rank levels, our active learning approach yields a non-trivial gain over both baselineapproaches. In particular, on Mouse 1 and both datasets for Mouse 3, we observe a gain of between1.5-2 over baselinesthat is, to achieve a given estimation error, our approach requires between1.5-2 fewer samples than baseline methods. This demonstrates the effectiveness of our activelearning procedure for estimating low-rank matricesour method is able to exploit the low-rankstructure present in the underlying dynamics to speed up estimation, as compared to methods whichdo not take into account this structure. Furthermore, it shows that on a realistic simulation of neuralpopulation dynamics, we can effectively design stimuli to speed up the estimation of the dynamics.",
  "Active Ranking of Real Data Observations": "As described in , each of our datasets consist of roughly 2000 (stimulus, response) trials.In an online photostimulation experiment, we would choose the photostimulus actively for eachtrial. Here we seek to simulate this process using real experimental data, but offline, by choosingthe ordering of the trials available in our pre-collected datasets. This serves as a testbed for activelearning procedures: if we can more efficiently learn models in this offline setting, that is a strongindication that we should also see gains in online experiments. Indeed, those gains may be evengreater online because in our offline setting we are severely restricted to choosing from only 100candidate stimulation patterns. Thus, we interpret the results in this section as a lower bound on theperformance we might expect online. To validate this approach, we randomly choose 20 (out of the 100 total) unique photostimulationpatterns and set aside a test set containing all 20 repeated trials of those photostimuli. This creates an80%/20% train-test split of non-overlapping stimulus patterns. For Dtrain and Dtest our train andtest datasets, respectively, we consider the following query model:",
  "Discussion": "In this work, we have developed a principled approach to active learning of photostimulation inputs forthe identification of neural population dynamics and connectivity. We discuss three limitations of ourapproach, which each suggest potential future directions. First, we have considered active learning ofthe causal connectivity matrix and minimization of prediction error, both uniformly across all recordedneurons. Future work may focus on more specific scenarios, such as targeting particular dimensions ofthe neural activity space or changes in connectivity due to learning. Second, while we found that lineardynamics fit our data remarkably well, this may not always be the case. Does our methodology effec-tively scale to nonlinear dynamics? Finally, our real-data experiments were performed offline. Futurework may explore running our algorithm online during closed-loop photostimulation experiments. This work was supported by NSF DMR award 2308979 to the University of Washington MaterialsScience Research Center (AW & KJ), the Shanahan Foundation Fellowship (LM & MSB), the PaulG. Allen Foundation (MR, KS, KD & MDG), NIH award R00-MH121533 (MDG), NSF CCF award2007036 (KJ), and NSF CAREER award 2141511 (KJ).",
  "Saurabh Vyas, Matthew D Golub, David Sussillo, and Krishna V Shenoy. Computation throughneural population dynamics. Annual Review of Neuroscience, 43:249275, 2020": "Mark M Churchland, John P Cunningham, Matthew T Kaufman, Justin D Foster, Paul Nuyu-jukian, Stephen I Ryu, and Krishna V Shenoy. Neural population dynamics during reaching.Nature, 487(7405):5156, 2012. David Sussillo, Mark M Churchland, Matthew T Kaufman, and Krishna V Shenoy. A neural net-work that finds a naturalistic solution for the production of muscle activity. Nature Neuroscience,18(7):10251033, 2015.",
  "Krithika Mohan, Ou Zhu, and David J Freedman. Interaction between neuronal encoding andpopulation dynamics during categorization task switching in parietal cortex. Neuron, 109(4):700712, 2021": "Arseny Finkelstein, Lorenzo Fontolan, Michael N Economo, Nuo Li, Sandro Romani, and KarelSvoboda. Attractor dynamics gate cortical information flow during decision-making. NatureNeuroscience, 24(6):843850, 2021. Warasinee Chaisangmongkon, Sruthi K Swaminathan, David J Freedman, and Xiao-Jing Wang.Computing by robust transience: how the fronto-parietal network performs sequential, category-based decisions. Neuron, 93(6):15041517, 2017. Aditya Nair, Tomomi Karigo, Bin Yang, Surya Ganguli, Mark J Schnitzer, Scott W Linderman,David J Anderson, and Ann Kennedy. An approximate line attractor in the hypothalamusencodes an aggressive state. Cell, 186(1):178193, 2023.",
  "Saurabh Vyas, Nir Even-Chen, Sergey D Stavisky, Stephen I Ryu, Paul Nuyujukian, andKrishna V Shenoy. Neural population dynamics underlying motor learning transfer. Neuron, 97(5):11771186, 2018": "Britton A Sauerbrei, Jian-Zhong Guo, Jeremy D Cohen, Matteo Mischiati, Wendy Guo, MayankKabra, Nakul Verma, Brett Mensh, Kristin Branson, and Adam W Hantman. Cortical patterngeneration during dexterous movement is input-driven. Nature, 577(7790):386391, 2020. Xulu Sun, Daniel J OShea, Matthew D Golub, Eric M Trautmann, Saurabh Vyas, Stephen IRyu, and Krishna V Shenoy. Cortical preparatory activity indexes learned motor memories.Nature, 602(7896):274279, 2022. Emily R Oby, Alan D Degenhart, Erinn M Grigsby, Asma Motiwala, Nicole T McClain, Patrick JMarino, Byron Yu, and Aaron P Batista. Dynamical constraints on neural population activity.bioRxiv, pages 202401, 2024. Byron M Yu, John P Cunningham, Gopal Santhanam, Stephen I Ryu, Krishna V Shenoy, andManeesh Sahani. Gaussian-process factor analysis for low-dimensional single-trial analysis ofneural population activity. Journal of Neurophysiology, 102(1):614635, 2009. Jakob H Macke, Lars Buesing, John P Cunningham, Byron M Yu, Krishna V Shenoy, andManeesh Sahani. Empirical models of spiking in neural populations. Advances in NeuralInformation Processing Systems, 24, 2011. Evan W Archer, Urs Koster, Jonathan W Pillow, and Jakob H Macke. Low-dimensional modelsof neural population activity in sensory cortical circuits. Advances in Neural InformationProcessing Systems, 27, 2014.",
  "Yuanjun Gao, Evan W Archer, Liam Paninski, and John P Cunningham. Linear dynamicalneural population models through nonlinear embeddings. Advances in Neural InformationProcessing Systems, 29, 2016": "Chethan Pandarinath, Daniel J OShea, Jasmine Collins, Rafal Jozefowicz, Sergey D Stavisky,Jonathan C Kao, Eric M Trautmann, Matthew T Kaufman, Stephen I Ryu, Leigh R Hochberg,Jaimie M Henderson, Krishna V Shenoy, Larry F Abbott, and David Sussillo. Inferring single-trial neural population dynamics using sequential auto-encoders. Nature Methods, 15(10):805815, 2018. Joshua Glaser, Matthew Whiteway, John P Cunningham, Liam Paninski, and Scott Linderman.Recurrent switching dynamical systems models for multiple interacting neural populations.Advances in Neural Information Processing Systems, 33:1486714878, 2020. Timothy D Kim, Thomas Z Luo, Jonathan W Pillow, and Carlos D Brody. Inferring latentdynamics underlying neural population activity via neural differential equations. In InternationalConference on Machine Learning, pages 55515561. PMLR, 2021. Orren Karniol-Tambour, David M Zoltowski, E Mika Diamanti, Lucas Pinto, David W Tank,Carlos D Brody, and Jonathan W Pillow. Modeling communication and switching nonlineardynamics in multi-region neural activity. bioRxiv, pages 202209, 2022. Daniel J OShea, Lea Duncker, Werapong Goo, Xulu Sun, Saurabh Vyas, Eric M Trautmann,Ilka Diester, Charu Ramakrishnan, Karl Deisseroth, Maneesh Sahani, et al. Direct neuralperturbations reveal a dynamical mechanism for robust computation. bioRxiv, pages 202212,2022. Mohammad Reza Keshtkaran, Andrew R Sedler, Raeed H Chowdhury, Raghav Tandon, DiyaBasrai, Sarah L Nguyen, Hansem Sohn, Mehrdad Jazayeri, Lee E Miller, and Chethan Pandari-nath. A large-scale neural network training framework for generalized estimation of single-trialpopulation dynamics. Nature Methods, 19(12):15721577, 2022. Adrian Valente, Jonathan W. Pillow, and Srdjan Ostojic. Extracting computational mechanismsfrom neural data using low-rank RNNs. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave,and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.",
  "Mark M Churchland and Krishna V Shenoy. Delay of movement caused by disruption ofcortical preparatory activity. Journal of neurophysiology, 97(1):348359, 2007": "Nishal Shah, Sasidhar Madugula, Pawel Hottowy, Alexander Sher, Alan Litke, Liam Paninski,and EJ Chichilnisky. Efficient characterization of electrically evoked responses for neuralinterfaces. Advances in Neural Information Processing Systems, 32, 2019. Yuxiao Yang, Shaoyu Qiao, Omid G Sani, J Isaac Sedillo, Breonna Ferrentino, Bijan Pesaran,and Maryam M Shanechi. Modelling and prediction of the dynamic responses of large-scalebrain networks during direct electrical stimulation. Nature biomedical engineering, 5(4):324345, 2021.",
  "Patrick T Sadtler, Kristin M Quick, Matthew D Golub, Steven M Chase, Stephen I Ryu,Elizabeth C Tyler-Kabara, Byron M Yu, and Aaron P Batista. Neural constraints on learning.Nature, 512:423426, 2014": "Saul Kato, Harris S Kaplan, Tina Schrdel, Susanne Skora, Theodore H Lindsay, EviatarYemini, Shawn Lockery, and Manuel Zimmer.Global brain dynamics embed the motorcommand sequence of caenorhabditis elegans. Cell, 163(3):656669, 2015. Matthew D Golub, Patrick T Sadtler, Emily R Oby, Kristin M Quick, Stephen I Ryu, Eliza-beth C Tyler-Kabara, Aaron P Batista, Steven M Chase, and Byron M Yu. Learning by neuralreassociation. Nature Neuroscience, 21(4):607616, 2018. Juan A Gallego, Matthew G Perich, Stephanie N Naufel, Christian Ethier, Sara A Solla, andLee E Miller. Cortical population activity within a preserved neural manifold underlies multiplemotor behaviors. Nature Communications, 9(1):4233, 2018. Rishidev Chaudhuri, Berk Gerek, Biraj Pandey, Adrien Peyrache, and Ila Fiete. The intrinsicattractor manifold and population dynamics of a canonical cognitive circuit across waking andsleep. Nature Neuroscience, 22(9):15121520, 2019.",
  "Proof. Recognizing that () RN we have": "()22 = (P() + P())22= (P()) + (P())22= (P())22 + (P())22 + 2(P()), (P()).To aid in readability, we make a number of notational modifications. First, we drop parentheses so that(P()) is just notated as P. Second, we define M /2 := (M )1/2 where M is the pseudoin-verse. If is invertible restricted to the range of P, then P = (PP)/2()1/2Pfor all . Thus,|(P()),(P())| = |P, P|",
  "(P()), (1 )(P())22 0": "Proof. The linear operator P : Rd1d2 RN can be decomposed as P = Nn=1 nwnnwhere {wn}n are orthonormal on RT , {n}n are orthonormal linear operators on Rd1d2, andn 0 are decreasing. For k = 0, 1, . . . , min{log2(N), d1d2} 1 let Wk = [w2k, . . . , w2k+11]so that",
  "B.1Further Details on Dataset": "The photostimulation data were collected from transgenic reporter mice Ai229, which express Cre-recombinase-dependent cytosolic GCaMP6m and soma-targeted ChRmine, crossed with the Vglut1-cre mouse line. Imaging and photostimulation experiments were performed on a Bergamo (Thorlabs)microscope equipped with a 16x (0.8 NA) Nikon objective. Post-hoc motion correction and neuronsegmentation were performed with the Suite2p package (",
  "B.2Further Details on Experiment of .1": "We split each of our photostimulation datasets into non-overlapping training and test datasets. Allmodels were trained exclusively using the training dataset and were then evaluated (as shown in) using the test dataset. To build our test datasets, we randomly chose 5 (out of the 100 total)unique photostimulation patterns and then included all 70-timestep windows about each of the 20instances of those 5 unique photostimuli. The resulting test set amounted to 20% of each dataset. In, all models were evaluated using these 70-timestep test sequences of the form {yt, ut}70t=1,where yt Rd is the recorded neural activity and ut Rd is the photostimulation delivered at time t.During evaluation on a given test window, all models were provided {yt}4t=1 and {ut}70t=1 to predict{yt}70t=5.",
  "A0A1...Ak1B0B1...Bk1v": "and the closed-form solution is W = (XT X)1XT Y . For the low-rank AR-k models, we fit allparameters via gradient descent using Adam over 100 training epochs with a learning rate of0.01. Gradient descent was implemented in PyTorch and ran on a single NVIDIA Tesla T4 GPU. During evaluation of the AR-k models, for each test window we first computed yk+1 given {yt, ut}kt=1using (B.1). Then for all subsequent predictions, on the right-hand side of (B.1) we replaced allinstances of yt with yt for t > k. In this manner, each entire roll-out prediction of {yt}70t=k+1 used allphotostimulation inputs {ut}70t=1, but only the first k timesteps of neural activity {yt}kt=1. All AR-kmodels in this paper used k = 4. Gated recurrent unit (GRU) networks: GRU networks were loosely based on the sequentialvariational autoencoders of . Each model consisted of an encoder GRU network that encodesk = 4 initial timesteps of recorded neural activity into a bottlenecked initial state for a decoder GRUnetwork. The decoder then unrolls an entire predicted timeseries of recorded neural activity given(as input) all photostimulation that was delivered over that time period. Model fitting proceeded byoptimizing the evidence lower bound (ELBO) with respect to all model parameters. Both encoderand decoder GRUs had 512 hidden units. We used Adam optimization with a learning rate of 0.001over 4000 training epochs of batch size 100. Models were implemented with PyTorch, and optimizedon a single NVIDIA Tesla T4 GPU. Evaluation metrics: We evaluated all models using roll-out predictions on held-out test windows. Wequantified performance with mean squared error between recorded and predicted neural activity foreach neuron. We also performed thresholded response detection, whereby detections were defined astimesteps at which a given neurons measured calcium fluorescence exceeded a predefined threshold.To calculate a receiver operator characteristic (ROC) curve, we enumerated a range of thresholds,normalized by the standard deviation of each neurons empirical activity distribution, and performedthreshold detection separately on the real and model-predicted neural activity traces. We then computethe overall false-positive rate and true-positive rate at each threshold level to trace out an ROC curve.We calculate area under the ROC curve (AUROC) to quantify the accuracy of each model. Longer roll-out evaluations: To assess AR-k models ability to predict over longer time horizons,we implemented another train-test strategy, where the first 80% of timesteps in a recording are usedfor training, and the last 20% of timesteps (6736 steps) are used for testing. During the test phase, weuse the same procedure described above, providing only the k = 4 initial timesteps of neural activityand then unrolling predictions over the remainder of this long test window. We report these results in.",
  "for u our input, and z = t=1 xt the observed response, where here xt are the observations generatedfrom playing input u, and = 15": "As K is defined with respect to the nuclear norm of the true parameter, which we do not assume isknown, we run each method with a range of possible values for the nuclear-norm constraint, and plotthe performance of each method for the constraint value that has minimum error. We state the valueof the nuclear-norm constraint used for each plot below:",
  ": Nuclear-Norm Constraint Settings for Results of .1": "To choose the input rank of Algorithm 1, we ran our experiment with several different ranks andprovide results for the best-performing rank. We found, however, that results are typically robust tothe setting of the rank parameter of Algorithm 1, and our choice of r did not significantly impactperformance. Furthermore, we believe this could effectively be chosen adaptively. We state ourchosen values of r below.",
  "B.4Further Details on Experiment of .2": "For this experiment, on the data D we observed thus far, we fit the AR-k model described in.1 with k = 1. We found that for this experiment, simply using the least squares estimatorwith no low-rank penalty produced the best results. We use the same estimation method for both ourmethod and the baseline method. Given a input response trajectory in the test set, (x1, . . . , x15), with input u, to compute the test MSE,we provide our learned dynamics model with the initial state x1 and input u, and then roll this out for15 timesteps to generate predictions x2, . . . , x15. Precisely, if A and B are our estimated parameters,we let",
  "for learning rate i": "In this experiment, we simply choose un as above, with U the set of remaining active inputs in Dtrain,and (n) replaced with n1s=1 usus . This therefore approximates the solution to the experimentdesign of Algorithm 1, and has the advantage of being very computationally efficient. Furthermore,we set V to be the right singular vectors of B. We believe this is reasonable in dynamical systemsettings with fast decay. The primary hyperparameter for this experiment is the choice of r, the rank of V . As in the previoussection, we did not find the results particularly sensitive to setting of r. For each dataset, we ran withr , and include results for the best-performing setting."
}