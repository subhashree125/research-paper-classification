{
  "Abstract": "Estimating the location of contact is a primary function of artificial tactile sens-ing apparatuses that perceive the environment through touch. Existing contactlocalization methods use flat geometry and uniform sensor distributions as a sim-plifying assumption, limiting their ability to be used on 3D surfaces with variabledensity sensing arrays. This paper studies contact localization on an artificial skinembedded with mutual capacitance tactile sensors, arranged non-uniformly in anunknown distribution along a semi-conical 3D geometry. A fully connected neuralnetwork is trained to localize the touching points on the embedded tactile sensors.The studied online model achieves a localization error of 5.7 3.0 mm. Thisresearch contributes a versatile tool and robust solution for contact localization thatis ambiguous in shape and internal sensor distribution.",
  ": Contact localization model takes in a sensorimage from any configuration of artificial tactile skin anddetermines the location of touch through a feedforwardneural network": "Artificial skin sensors are a direct way to mea-sure external contact and have a wide range ofapplications in healthcare , prosthetics,and robotics . As robots are increasinglydeployed in close proximity to humans, the abil-ity to localize where touch occurs allows actu-ating bodies to react appropriately to detectedcontact, interactable objects, and obstacles. Artificial skin that is capable of localizing con-tact to a greater number of points on its sensorarray than the number of sensors present is cur-rently limited to flat surfaces .The localization methods used are typically con-strained by assuming either a flat plate array or auniform density of sensors. This paper presentsa method of localizing contact on 3D artificialskin with non-uniform sensor distribution. We present a curved, variable-density artificial skin equipped with mutual capacitance sensors thatdetect touch on the surface of the artificial skin. A neural network infers a relationship between thesensor readings and the geometry of the tactile skin. We evaluate this model by comparing known",
  "Related Work": "Artificial skin sensors have a range of sensing methods such as acoustics , computer vision, capacitive sensing , electrical resistance tomography (ERT), and fiber Bragg grating (FBG) optical sensing . Artificial skins composed of sensorarrays have increased scalability and conformity to non-flat geometries compared to computer visiontactile sensors. Our artificial skin uses a low-cost mutual capacitance sensing array method that ishighly flexible to shape and size during fabrication. Explicit contact localization methods can achieve high accuracies with capacitive sensor arrays andare standard in touchscreens and artificial skins with known sensor distributions . Theseexplicit methods utilize the known positions of sensors to interpret locations of contact. Machinelearning has been used in previous artificial skins to enhance contact localization accuracy with knownsensor locations due to its ability to learn complex patterns . Our method treats capacitivesensor readings as images and uses a neural network to bypass the embedded spatial distribution ofsensors by directly learning touch localization patterns.",
  "(a)(b)(c)": ": (a) CAD model for the curved geometry. (b)General wiring scheme. Sensors are located at each in-tersection of transmitter (TX) and receiver (RX) wires.(c) Fabricated skin sensor array where the sensing cir-cuits are embedded within a layer of silicone. A challenge in implementing an artificial sens-ing skin array on a 3D object is conforming thesensing array to a curved surface. This is ad-dressed by fabricating a two-dimensional sheetembedded with sensors, and then overlaying theartificial skin onto a semi-conical surface. As shown in , the curved surface is outfit-ted with a total of 16 wires, divided evenly into8 transmit and 8 receive elements, forming anetwork of 64 intersections. These intersectionsserve as the loci for capacitance measurements,effectively creating 64 sensors distributed across the surface. A mutual capacitance board (Muca)attached to the wires measures the capacitance values at each intersection . A layer of 6mmthick silicone rubber is then molded on top of the wiring to provide a dielectric layer between wireintersections to ensure effective capacitive sensing. A thin copper sheet affixed to the underside of the3D-printed structure functions as the grounding plate, mitigating electromagnetic noise from beneaththe artificial skin. The result is a flush, 14.2 16.4 8.1 cm semi-conical surface capable of contactlocalization through mutual capacitive sensing.",
  "Calibration": "The calibration process includes collecting a small dataset in a given operational environment toestablish a correlation between raw capacitance readings and specific touch locations in 3D space.Each pair of raw sensor readings corresponding to a touch location are referred to as a \"pointlog\". Data is gathered by touching the artificial skin with an index finger at known locations. Twomethodologies are employed for collecting point logs: random sampling and even spacing. Forrandom sampling, the location is chosen as a point on a randomly selected edge from the CAD modelof the skin. For even spacing, the surface of the CAD model is discretized into evenly spaced pointsdepending on the selected number of point logs. When the skin sensor array is touched, 50 samplesof the capacitance readings for each sensor are stored and correlated to the prompted touch position.This process is repeated until the desired number of point logs has been processed.",
  "Sensing": "Mutual capacitance coupling occurs at the intersection of transmitter and receiver nodes. The intensityof the coupled capacitance can be measured by sending a known signal to the transmitter wire andmeasuring the signal of the receiver wire. The coupled capacitance is affected by grounded conductiveobjects entering the electromagnetic field near the intersection, such as a human finger. Groundedconductive objects reduce the measured capacitance at the receiver electrodes which correlates tohigher contact outputs for a particular sensor. The accuracy of the sensor measurements is determined by their noise levels through a signal-to-noiseratio. Fifty sensor measurements are taken for every point log and calibration measurement. Usingthese measurement samples, the average sensor values for each point log ( S), the average initialsensor values without contact (S0), and the standard deviation from the average sensor value withoutcontact (0) are used to calculate the signal-to-noise ratio (SNR) of each sensor, i, within the sensorarray using Eq. 1.",
  "(a)": ": (a) Fully-connected neural network takes in sensorinput of size 64 and outputs a 3D coordinate. (b) Artificialtactile skin sends mutual capacitance measurements to anArduino microcontroller that formats the readings and passesinto the neural network. We use a supervised fully-connected neu-ral network to localize the touching pointbased on raw sensor readings. This typeof model is a low computation method oftranslation from raw sensor inputs to spatialpredictions due to the nature of the artifi-cial skin sensor data, as explained in Sec-tion 3.3. In the ideal scenario with zero sen-sor noise, a sensor image exists for everypossible touch position along the surface ofthe skin. A sensor image is the full set ofsensor values for a single touch and shownin Fig 1. Although this sensor image isalso dependent on the probing finger andbackground electromagnetic field capacitance, we will assume these variables remain constant forthis experiment by testing with the same finger and without changing locations for the duration ofcollecting data. A newly recorded sensor image can therefore be linked to a unique location along thesurface of the skin once the relationship between the sensor image and position is established throughour trained model. The advantage of this method as opposed to algorithmic statistical estimation approaches is that itdoes not require the locations of the sensors within the skin to be known. The neural network uses amean square error loss to compare the predicted touch locations from the sensor images collectedduring the calibration process against the associated given probe locations. A single hidden layerwith 32 hidden nodes is trained to minimize the loss using gradient descent. To constrain the outputto the surface of the skin, the predicted output from the model is compared to a set of discrete pointson the surface of the skin. The point on the surface with the shortest distance to the predicted locationof the model is used as the final prediction. This process effectively constrains the model to strictlyoutput points on the surface of the skin.",
  "Results": "Multiple sets of training data are collected with a varied number of point logs to analyze the accuracyof the contact localization model. (b) shows the prediction error for a validation set of 20random point logs tested for accuracy using contact localization models trained with 20, 50, 80, and100 point logs, respectively. Data collection took approximately 1-2 minutes for every 20 point logs.The results show a trend of increasing the number of point logs used to train the model decreases theoverall error in touch detection. However, on our skin array, this decrease in error levels off at about80 point logs. Our best model has an accuracy of 5.7 3.0mm.",
  ": (a) The linear relationship between SNR and point logs dataset size suggests correlation. (b) Predictionerror for contact localization models trained with varying sets of point logs": "The average SNR of all 64 sensors in the skin array is < 30 dB. (a) shows the resulting SNRvalues for each trained model that we have tested. There exists a linear relationship between thequantity of point logs used in training the model and SNR values. The proportional increase in SNRwith calibration dataset size may be due to a wider range of activation throughout the embeddedsensors during calibration.",
  ": Our mutual capacitance sensor achieves spatialacuity consistent with sensing arrays of known distribu-tions and human skin": "This paper studies a machine learning approachto contact localization on an artificial skin em-bedded with mutual capacitance tactile sensors,arranged non-uniformly in a semi-conical geom-etry. This model only requires a CAD modeland touch data to distinguish the relationshipsbetween a sensor image and touch location. Wedemonstrate this using a complex and unmea-sured internal sensor distribution. This paperdemonstrates that it is unnecessary to locate theplacement of internal sensors in artificial skinto acquire accurate touch predictions. Changesin sensor location due to skin deformation thatis incurred through conformation to various surface geometries may be navigated through neuralnetwork adaptability rather than altering the fabrication and calibration design. Our method achieveda better average localization accuracy than human skin and comparable results to artificial sensorswith non-uniform sensor distribution methods. One of the biggest limitations of our current implementation is the lack of precise visual cues duringthe data collection process, resulting in probing inaccuracies apart from the model inaccuracies. Toimprove this, we propose the application of a grid pattern to the surface of the skin with discretetouch locations. This grid can be loaded into the contact localization model and integrated intothe data collection process reducing the error between the intended and actual touch locations. Inaddition, this research has only been conducted using single-touch interactions. Future work aims atidentifying multi-touch accuracy and gesture identification, such as swiping up or down, which willdrive its application toward robot-human communication through touch. Iris Andrussow, Huanbo Sun, Katherine J Kuchenbecker, and Georg Martius. Minsight: Afingertip-sized vision-based tactile sensor for robotic manipulation. Advanced IntelligentSystems, page 2300042, 2023. Rachael Bevill Burns, Hasti Seifi, Hyosang Lee, and Katherine J Kuchenbecker. Getting intouch with children with autism: Specialist guidelines for a touch-perceiving robot. Paladyn,Journal of Behavioral Robotics, 12(1):115135, 2020. Wei Chen, Heba Khamis, Ingvars Birznieks, Nathan F Lepora, and Stephen J Redmond.Tactile sensors for friction estimation and incipient slip detectiontoward dexterous roboticmanipulation: A review. IEEE Sensors Journal, 18(22):90499064, 2018. Gordon Cheng, Emmanuel Dean-Leon, Florian Bergner, Julio Rogelio Guadarrama Olvera,Quentin Leboutet, and Philipp Mittendorfer. A comprehensive realization of robot skin: Sensors,sensing, control, and applications. Proceedings of the IEEE, 107(10):20342051, 2019.",
  "Won Kyung Do and Monroe Kennedy. Densetact: Optical tactile sensor for dense shapereconstruction. In 2022 International Conference on Robotics and Automation (ICRA), pages61886194. IEEE, 2022": "Won Kyung Do, Bianca Jurewicz, and Monroe Kennedy. Densetact 2.0: Optical tactile sensorfor shape and force reconstruction. In 2023 IEEE International Conference on Robotics andAutomation (ICRA), pages 1254912555. IEEE, 2023. Siyuan Dong, Wenzhen Yuan, and Edward H Adelson. Improved gelsight tactile sensor formeasuring geometry and slip. In 2017 IEEE/RSJ International Conference on Intelligent Robotsand Systems (IROS), pages 137144. IEEE, 2017. Zackory Erickson, Henry M Clever, Vamsee Gangaram, Greg Turk, C Karen Liu, and Charles CKemp. Multidimensional capacitive sensing for robot-assisted dressing and bathing. In 2019IEEE 16th International Conference on Rehabilitation Robotics (ICORR), pages 224231. IEEE,2019.",
  "Perla Maiolino, Marco Maggiali, Giorgio Cannata, Giorgio Metta, and Lorenzo Natale. Aflexible and robust large scale capacitive tactile system for robots. IEEE Sensors Journal, 13(10):39103917, 2013": "Luca Massari, Giulia Fransvea, Jessica DAbbraccio, Mariangela Filosa, Giuseppe Terruso,Andrea Aliperta, Giacomo DAlesio, Martina Zaltieri, Emiliano Schena, Eduardo Palermo, et al.Functional mimicry of ruffini receptors with fibre bragg gratings and deep neural networksenables a bio-inspired large-area tactile-sensitive skin. Nature Machine Intelligence, 4(5):425435, 2022. Stefan Escaida Navarro, Maximiliano Marufo, Yitao Ding, Stephan Puls, Dirk Gger, BjrnHein, and Heinz Wrn. Methods for safe human-robot-interaction using capacitive tactileproximity sensors. In 2013 IEEE/RSJ International Conference on Intelligent Robots andSystems, pages 11491154. IEEE, 2013.",
  "Kyungseo Park and Jung Kim. Neural-gas network-based optimal design method for ert-basedwhole-body robotic skin. IEEE Transactions on Robotics, 38(6):34633478, 2022": "Kyungseo Park, Hyunkyu Park, Hyosang Lee, Sungbin Park, and Jung Kim. An ert-basedrobotic skin with sparsely distributed electrodes: Structure, fabrication, and dnn-based signalprocessing. In 2020 IEEE International Conference on Robotics and Automation (ICRA), pages16171624. IEEE, 2020. Siddharth Rupavatharam, Caleb Escobedo, Daewon Lee, Colin Prepscius, Larry Jackel, RichardHoward, and Volkan Isler. Sonicfinger: Pre-touch and contact detection tactile sensor forreactive pregrasping. In 2023 IEEE International Conference on Robotics and Automation(ICRA), pages 1255612562. IEEE, 2023. Marc Teyssier, Brice Parilusyan, Anne Roudaut, and Jrgen Steimle. Human-like artificialskin sensor for physical human-robot interaction. In 2021 IEEE International Conference onRobotics and Automation (ICRA), pages 36263633. IEEE, 2021.",
  "Yung-Chen Wang, Tsun-Yi Chen, Rongshun Chen, and Cheng-Yao Lo. Mutual capacitiveflexible tactile sensor for 3-d image control. Journal of microelectromechanical systems, 22(3):804814, 2013": "Jun Chang Yang, Jaewan Mun, Se Young Kwon, Seongjun Park, Zhenan Bao, and Steve Park.Electronic skin: recent progress and future prospects for skin-attachable devices for healthmonitoring, robotics, and prosthetics. Advanced Materials, 31(48):1904765, 2019. Zhenxuan Zhao, Jianshi Tang, Jian Yuan, Yijun Li, Yuan Dai, Jian Yao, Qingtian Zhang,Sanchuan Ding, Tingyu Li, Ruirui Zhang, et al. Large-scale integrated flexible tactile sensorarray for sensitive smart robotic touch. ACS nano, 16(10):1678416795, 2022."
}