{
  "Eric Volkmann1,2,, Alena Brndle1,3,4,, Daniel Durstewitz1,3,4,, Georgia Koppe3,5,6,": "1Department of Theoretical Neuroscience, Central Institute of Mental Health (CIMH),Medical Faculty Mannheim, Heidelberg University, Mannheim, Germany2Institute for Machine Learning, Johannes Kepler University, Linz, Austria3Interdisciplinary Center for Scientific Computing, Heidelberg University, Heidelberg, Germany4Faculty of Physics and Astronomy, Heidelberg University, Heidelberg, Germany5Hector Institute for AI in Psychiatry & Dept. for Psychiatry and Psychotherapy, CIMH6Faculty of Mathematics and Computer Science, Heidelberg University, Heidelberg, Germany, These authors contributed equally",
  "Abstract": "Data-driven inference of the generative dynamics underlying a set of observedtime series is of growing interest in machine learning and the natural sciences. Inneuroscience, such methods promise to alleviate the need to handcraft models basedon biophysical principles and allow to automatize the inference of inter-individualdifferences in brain dynamics. Recent breakthroughs in training techniques forstate space models (SSMs) specifically geared toward dynamical systems (DS)reconstruction (DSR) enable to recover the underlying system including its geo-metrical (attractor) and long-term statistical invariants from even short time series.These techniques are based on control-theoretic ideas, like modern variants ofteacher forcing (TF), to ensure stable loss gradient propagation while training.However, as it currently stands, these techniques are not directly applicable to datamodalities where current observations depend on an entire history of previous statesdue to a signals filtering properties, as common in neuroscience (and physiologymore generally). Prominent examples are the blood oxygenation level dependent(BOLD) signal in functional magnetic resonance imaging (fMRI) or Ca2+ imagingdata. Such types of signals render the SSMs decoder model non-invertible, arequirement for previous TF-based methods. Here, exploiting the recent success ofcontrol techniques for training SSMs, we propose a novel algorithm that solves thisproblem and scales exceptionally well with model dimensionality and filter length.We demonstrate its efficiency in reconstructing dynamical systems, including theirstate space geometry and long-term temporal properties, from just short BOLDtime series.",
  "Introduction": "Models and theories based on dynamical systems (DS) concepts have a long tradition in computationalneuroscience in accounting for physiological phenomena and computational processes of the brain . Constructing such models from first principles (biophysics) is time-consuming and hard,and utilizing them to account for inter-individual differences in brain dynamics, when model settingsneed to be personalized, is even more challenging. Yet, constructing valid models of the brainsfunctional dynamics is immensely important, not only for understanding the neurocomputationalbasis of inter-individual differences in cognitive and emotional style , but also when aiming at",
  "Dynamical models in neuroscience": "In computational neuroscience, multiple approaches to infer large-scale brain dynamics have beenadvanced over the past decades (e.g., ). Pioneering work introduced latent linear DS,including Gaussian process latent variable models , and extensions like Switching Linear DS(SLDS) . Whereas linear DS models are very limited in their dynamical repertoire, SLDS offer amore flexible approach to modeling a larger range of dynamical phenomena by combining severallinear (or affine) DS, with a switching mechanism that selects the active system at each moment. These approaches have become common tools for inferring and visualizing neuraltrajectories within low-dimensional state spaces. Arguably the most popular class of generative models in whole brain simulations relies on meanfield neural population models, including neural mass and neural field models . Thesemodel the moments of the activity of cortical areas by averaging over properties (like firing rates) ofneural (sub)populations, and are often biophysically motivated . Many popular large-scale meanfield modeling approaches are implemented in The Virtual Brain (TVB) environment . TVBincorporates biologically realistic brain connectivity into neural field models to generate simulationsof large-scale brain activity. Alternatively, Dynamic Causal Modeling (DCM) describes a set ofmore statistically motivated and mostly linear techniques, primarily for the purpose of inferringthe effective connectivity between brain regions based on invasive or non-invasive brain recordings(e.g., ). While many of these models may account for aspects of the dynamics, likepatterns of functional connectivity and their task modulation, they are not, strictly, dynamical systemsreconstruction (DSR) tools, entailing that they may miss important dynamical phenomena by beingconstrained through the biological assumptions and simplifications imposed. In the analysis of functional magnetic resonance imaging (fMRI), only recently a shift in focushas introduced data-driven, deep-learning based methods for inferring generative models of systemdynamics . Models that implement dynamics either directly on the observed , orwithin an underlying latent space have been proposed, partly using available structuralinformation and hierarchical inference approaches .",
  "Dynamical systems reconstruction (DSR)": "A variety of Deep Learning (DL)-based models for approximating the generative dynamical processesunderlying observed time series has been put forward in recent years (; see also for an overview). These include approaches which approximate a systemsvector field, e.g., through a library of basis functions and penalized regression as in SINDy ,or through deep neural networks and neural Ordinary Differential Equations (ODE) .Alternatively, methods that approximate the associated flow (solution) operator directly have beensuggested, often employing state space model (SSM)-type architectures which distinguish betweenan observation process and a latent process commonly instantiated through recurrent neural networks(RNNs; e.g., ). Recurrent SLDS (rSLDS) , an extension of SLDS, and LatentFactor Analysis via Dynamical Systems (LFADS) also fall into this category. In DSR we ask for models that are generative in the sense that after training they provide anexecutable surrogate model of the observed system, from which we can simulate samples that agreewith their empirical counterparts in topological, geometrical and temporal characteristics (in contrastto . This required agreement in long-term temporal and geometric properties is not automaticallyguaranteed for standard training of common RNNs or neural ODEs, which may yield good short-termpredictions but may fail to recover the full system dynamics . Recent breakthroughs indata-driven DSR build on insights from the field of chaos control and synchronization ,by guiding the training process through optimally chosen control signals modern variations ofclassical teacher forcing (TF) that prevent exploding gradients . Chaotic dynamics in particular, as typical for neural systems (e.g., ), poses a severeproblem here as trajectories and hence loss gradients inevitably diverge due to the presence ofa positive Lyapunov exponent . Recent amendments of TF protocols, including sparse TF",
  "Specific contributions": "Nonlinear SSMs distinguish between an underlying latent process that governs the dynamics of asystems state, and an observation process (referred to as observation or decoder model), that linksthe system states to the actual measurements . Invertible (or pseudo-invertible) decoder modelsplay a crucial role in control-theoretic approaches, like STF or GTF, for training SSMs, in orderto project observations into the models latent space. This inversion is fairly straightforward whenones assumes that the current measurement depends solely on the present latent state, i.e, whenxt = f(zt), but not if it depends on a history of states {zt, zt1, . . . , zt}. In practice, unfortunately,this assumption is often violated due to a signals filtering properties. For instance, blood oxygenationlevel dependent (BOLD) signals, as assessed via fMRI, are only an indirect measurement of neuralactivity, with the hemodynamic response function (hrf) broadly smearing out the signal across time.Each measurement is therefore a function of a history of past neural (latent) states whose dynamicswe wish to infer . Similar challenges arise in calcium imaging when spike times are to beinferred , or, in fact, any other observation process where the actual measurement is a filteringof the process of interest. Here we rectify this issue by developing a particularly efficient SSM approach which works formeasurements that depend on longer histories of latent states, yet allows to take advantage of recentpowerful training strategies for DSR . In particular, our contributions are threefold: First,we create and validate a novel SSM-based DSR algorithm for observation models which involveconvolutions with latent state series, and demonstrate its scalability with SSM size, as well asconvolution filter length. Second, we introduce an evaluation scheme for selecting DSR models onshort empirical time series, by demonstrating that the used DSR measures assessed on short timeseries accurately predict a systems long-term temporal and geometric properties. This is of highpractical relevance, as in many empirically relevant scenarios, like fMRI, we only have access tocomparatively short time series. Finally, we show that the proposed models can reliably extract keyDS features that, moreover, differentiate between subjects.",
  "Latent DSR model": "We start by defining our generative model used for DSR, a variant of a piecewise linear RNN(PLRNN). Its specific architecture has first been suggested in and later expanded to increase thePLRNNs expressivity . While the present approach is generic and independent of the specificDSR architecture, here we use the so-called shallow PLRNN (shPLRNN; Appx. A.3) and the clippedshallow PLRNN (cshPLRNN; ). In the cshPLRNN, the temporal evolution of the (latent) systemstate zt RM is expressed as",
  "zt = Azt1 + W1 [ (W2zt1 + h2) (W2zt1)] + h1(1)": "where () = max(0, ) is an elementwise ReLU activation function, W1 RML, W2 RLMare connection weights, A RMM is a diagonal matrix of autoregressive weights, and h1 RMand h2 RL are bias vectors. Its trajectories {zt} RMT will be bounded if the absoluteeigenvalues of A are smaller than 1 . The Markov property of the latent model is crucial toensure it formally constitutes a DS with complete state space . Finally, Equation 1 can easilybe extended to incorporate the effect of external inputs, such as experimental stimuli, by addingCst (with st RK representing an input vector and C RMK its effect on the latent dynamics).However, here we consider input-free data from resting state experiments.",
  "t Lt =": "t xt xt22 between thegenerated (predicted) {xt} and the observed {xt} sequence is commonly used to optimize parametersby stochastic gradient descent (SGD) with GTF . Regularization terms to enforce a structure inlatent space that helps to map slowly evolving processes may further be added to this loss . A fundamental issue in training such systems by SGD is the well-known exploding-and-vanishinggradients problem (EVGP), preventing systems from capturing relevant time scales in the data. Infact, proved that for chaotic systems gradient-based training techniques for RNNs will inevitablylead to diverging loss gradients (see also ). Successful DSR algorithms need to address thisproblem. Based on this connection between chaos and diverging gradients, Engelken suggestedregularizing the systems Lyapunov spectrum, thereby also biasing the dynamics toward certain(non-hyperbolic) solutions. A theoretically well founded approach that does not limit a systemsdynamical expressivity, which we will adopt here, is GTF, proposed in . GTF is designed to keepmodel generated trajectories on track and, theoretically, can completely abolish the EVGP withoutconstraining model expressivity. The main idea is that during training the latent state zt is computedas a linear interpolation between the PLRNN generated state zt = PLRNN(zt1) and a data-inferredstate dt that serves as a control signal , i.e.,zt := (1 ) zt + dt, [0, 1).(3)There is a theoretically optimal choice for that can be approximated concurrently whilst trainingthrough a specifically designed annealing protocol , but more simply may just be determinedby grid search (as done here). Control signals dt are obtained by inverting the decoder model(Equation 2). Since in general M = N, the matrix inverse of B RNM does not exist and isapproximated by the Moore-Penrose (pseudo-) inverse B+:dt = B+xt(4)To keep the gradients on track, the interpolation is performed at each time step before applying thecshPLRNN mapping (Equation 1). These control signals are turned off during actual data generationby the model (i.e., in a test phase), where it runs completely autonomously.",
  "Teacher forcing for decoder models with signal convolution": "Decoder model for convolved signalsGTF (and similar techniques like STF; ) are powerfulstate-of-the-art (SOTA) tools for controlling gradients, especially in the context of DSR. However, theyrequire a (pseudo-)invertible observation model for producing adequate control signals. Empirically,there are many situations where this requirement is not met. For instance, in BOLD time series theobserved signal is a highly filtered and strongly smoothed version of the underlying neuronal processthat we would like to recover . This fairly complex hemodynamic process is often modeledby the hrf . A decoder model that relates the neuronal processes given as latent time series {zt} to measuredBOLD time series {xt} may be formulated as in ,xt = B ((hrf z)t) + Jrt + t, t N(0, )(5)with regression coefficient matrices B RNM and J RNP , nuisance variables rt RP (suchas movement or respiratory artifacts) and a Gaussian observation noise term t (with usually diagonalcovariance RNN). Here, denotes the convolution operation and z is a history of states zt:t,the length of which depends on the observed sampling rate, commonly referred to as time of repetition(TR). The discrete hrf sequence is computed by evaluating the canonical hrf at the observed TR. We will denote the hrf response for a given TR by hrfT R. By incorporating the hrf into the observation model, we disentangle the neural state and its dynamics the processes of interest from the neurovascular mechanics (or any filtering at the level ofobserved signals). We thereby eliminate the history dependence present in the observations, andthus help unfolding trajectories in latent space and satisfying the uniqueness assumptions requiredin reconstructing dynamical systems (see also Appx. ). However, Equation 5 posesa major complication for applying TF techniques, as observations (and model outputs xt) do notsimply depend on the current state zt, but due to the convolution on a set of states across severalprevious time steps. We can thus not compute the control signal dt through straightforward decoderinversion anymore, but require a new type of inversion algorithm. Wiener deconvolutionFollowing , we use a Wiener filter to invert Equation 5. We brieflyintroduce this approach here in the context of our specific problem, and refer to Appx. A.4 for furtherdetails. Given an observed noisy signal {xt}, composed of the signal of interest {zt} convolved witha known impulse response hrf plus some noise term t (distribution unknown, Wiener is optimal forGaussian distribution),xt = (hrf z)t + t,(6)the Wiener deconvolution provides the estimate zt of the unknown signal zt through least-MSEestimation. Defining Conv1(, hrf) as the Wiener deconvolution operator, we can write",
  "{dt} = Conv1B+(xt Jrt), hrf,(8)": "whereB+(xt Jrt)is the time series that needs to be deconvolved. Note that this approach isquite general and we can simply exchange the hrf with alternative functions if we want to accountfor filtering in the original signal. As stated, since B and J are matrices of learnable parametersupdated during training, we would need to perform this deconvolution step at every training epoch,which is computationally very costly. We therefore make use of the linearity of convolutions andseparate the deconvolution step from the learnable parameters, rewriting Equation 8 as",
  "dt = B+xdeconvt J rdeconvt.(10)": "This now is computationally much more efficient, as we need to perform the deconvolution onlyonce prior to training. During training then, only the decoder model parameters need to be inferredto obtain the control signal. We will refer to the convolutional model for DSR (Equation 1 andEquation 5) trained with GTF and SGD as convSSM. The full inversion algorithm is provided inAlgorithm 1 with additional information given in Appx. A.6. Key components of SGD+GTF trainingare illustrated in .",
  "Performance measures": "In DS theory in general, and DSR more specifically, we are mostly concerned with invariant propertiesof a system, such as attractor geometry and long-term temporal statistics . In chaotic systems inparticular, in which trajectories diverge exponentially fast with time, the mean squared predictionerror (PE) is a useful statistic only on relatively short time scales (see Appx. ).To evaluate our models performance, in addition to short-term n-step ahead PEs, PEn, we assess thefollowing two established performance measures to capture the temporal and geometrical structure: 1. The deviation in power spectra between the (smoothed) empirical and model-generatedpower spectra, assessed in terms of the Hellinger distance and referred to as power spectrumerror (PSE), DP SE, in the following , and",
  ". the Kullback Leibler divergence between the empirical and model-generated trajectoriesacross state space, Dstsp, measuring the overlap in attractor geometries": "To obtain a reference value for Dstsp, we further included two references in which we assessed Dstspwhen all mass is centered on the expectation value (similar to a fixed point solution), and when thestate space is populated by points drawn from a Gaussian with mean and variance equal to the data(similar to a fixed point solution plus measurement noise). For comparability with experimental data, we evaluated performance on comparatively short timeseries obtained from the adaptive linear-nonlinear (ALN) cascade model and the LEMON data set. Inthese cases, performance metrics were assessed on 100 generated trajectories per model and thenaveraged. For more details, see Appx. A.7.",
  "zt1zt": ": Schematic of training protocol and gradient flow. A: Before training, observations {xt}and nuisance artifacts {rt} are deconvolved. B: The deconvolved time series are used to generatea forcing signal dt1 which is used for guiding cshPLRNN training. C: Latent states zt:t andnuisance artifacts rt are used to predict xt through the decoder model. Gradients are computed onthe squared error loss Lt, propagated from the decoder model back to the latent states (blue), andfrom the latent DS model backwards in time (orange).",
  ".2convSSM validation & scalability on Lorenz63": "As a well-established and popular benchmark for a chaotic system, we first performed numericalexperiments with the famous Lorenz63 system. The Lorenz63 is a 3-dimensional system introducedin to describe atmospheric convection, and exhibits chaotic behaviour in the chosen regime(see Appx. B.1). To mimic BOLD observations, we generated 100 standardized chaotic Lorenz63trajectories, convolved them with hrfT R functions at different sampling rates TR {0.2s, 0.5s, 1.2s}(B), and added Gaussian noise with standard deviation {0.01, 0.1}. This resulted in 6benchmark settings with different levels of signal degradation by convolution and noise. Each dataset was divided into a training and a test set of T = 5 104 time steps each. We trained 100 models on each of these 6 data sets. The following models were compared: theconvSSM trained via SGD+GTF, the convSSM trained via SGD and no GTF, the standard SSMtrained via SGD+GTF, and MINDy, a recently published method for DSR in fMRI . convSSMand standard SSMs were trained with the shPLRNN, with M = 3, L = 50, and = .1 (see Appx. for all additional hyperparameters). The hidden dimension was selected such that the standardSSM (no-hrf model) performed well . We emphasize that the standard SSM has already beenextensively benchmarked on a variety of simulated and real-world data sets and is considered to be aSOTA model in the field . The performance measures Dstsp, DP SE, and PE20 were assessedon the test sets after training for 1, 000 epochs. We used the same hyperparameters for all networks(aside from TR) to show that performance increases can be solely attributed to the improved decodermodel. Hyperparameters were chosen such that the shPLRNN achieved near perfect performance onunconvolved, noiseless trajectories from the Lorenz63 system. The convSSM significantly outperformed all other methods, including the standard SSM in almost allcases, with the performance gap increasing with decreasing TR (see Appx. for performance,and A for example reconstructions, providing an intuition on how to interpret Dstsp). Themore heavily the signal was degraded by the convolution filter, the larger was the performance gap infavor of the convSSM. An important consideration especially for large-scale applications of such models to empir-ical data is how well they scale with model size and convolution filter length.To as-sess this, we collected trajectories of length T=105 from the chaotic Lorenz63 sys-tem, and studied training epoch times as a function of convSSM latent dimension M={3, 10, 50, 100, 500}, hidden dimension L = {10, 50, 100, 500, 1000}, TR = {0.2, 0.5, 1.2, 3},time series length T= {500, 1000, 5000, 10000, 50000, 100000} and observation dimension",
  "DEF": ":Validations on Lorenz63 and ALN. A: Illustration of reconstruction performance asassessed by the geometrical agreement measure Dstsp. Average Dstsp values for the convSSM wereDstsp < 0.30 at noise level = .01 and Dstsp < 0.71 at noise level = .1, indicating successfulreconstructions in the majority of cases. B: Example trajectory from the Lorenz63 system in latentspace (top) and observation space (convolved with hrf0.2) (bottom). C: Probability density overmaximal max values (orange) assessed on 1000 convSSMs trained on Lorenz63 time series of length1000 (example shown in right panel). Black line denotes the known max 0.9056 of the Lorenzsystem. D: Comparison of standard SSM (standard), convSSM (conv), and convSSM trainedwithout generalized teacher forcing (conv (NoGTF)) on the ALN data set. Histograms over Dstspassessed on the observed space (left panel) and latent space (right panel). E: Dstsp for convSSMevaluated on the full pseudo-empirical time series of typical empirically available length (T = 500;x-axis) vs. the long GT test set (T = 5, 000; y-axis). F: Dstsp for convSSM evaluated on the observedtime series (x-axis) vs. on the latent time series (y-axis). N = {10, 30, 50, 100, 500, 1000}. Shorter/longer TRs directly implicate longer/shorter convolutionfilters since the filters assume a constant time interval. Results are displayed in Appx. A. Theruntime per epoch did not significantly depend on TR, which means that time series convolved withlong impulse response functions can be trained in times comparable to short ones. The per-epoch-runtime increases approximately linearly with dimensions L, M, and N (Appx. B,C,E),implying that models can be scaled up efficiently. Finally, empirical data is often short, yet we want to reliably infer DS features that characterize theunderlying dynamics. To demonstrate that our model can robustly reconstruct dynamics based onshort time series, we inferred 1000 convSSMs on n = 100 convolved Lorenz63 time series (TR= 0.5) of length T = 1000 only (see C). We then assessed the degree of chaoticity in therecovered trajectories by examining the trained models maximum Lyapunov exponents, max. maxmeasures how quickly trajectories starting from nearby points in a systems state space converge ordiverge with time. If max > 0, trajectories will exponentially diverge and the system, if bounded,will exhibit chaos. We show that we can successfully recover max (known for the Lorenz63 system;C) even from models trained on these just short series.",
  "Validating performance measures on short time series": "In empirical situations, we do not have access to the latent dynamics of the true system, of course,but we still rely on our reconstruction measures evaluated on the observed signals to yield resultsvalid for the (unobserved) latent space. It is therefore a practically very relevant question whether a)the convSSM trained on such short time series would be able to accurately recover the underlyingneural latent dynamics, and b) our measures (Dstsp, DP SE) evaluated on such short time series, anddirectly on the observations, would yield results similar to what would be expected if much longertime series and access to the ground truth latent space were available. To tackle these questions, we used a more realistic simulation model, the ALN model forsimulating whole brain (neural) activity. 100 data sets of length T = 10, 000 were simulated from thismodel using neurolib , sampled at 0.1 ms, and filtered through Equation 5 (with TR = 0.1 ms) tocompute the corresponding BOLD time series. Subsequently, these time series were downsampledto a TR of 0.5 s to mimic an experimentally realistic scenario (see Appx. B.2 for details). Mosthyperparameters were adopted from previous experiments (see Appx. ). For the latentdimension, we chose M = 16 to match the dimensions of the empirical LEMON data set, seesubsection 3.4. To mimic real fMRI experiments, we then pretended that only the first 500 time points are availablefor model estimation (called pseudo-empirical here to distinguish it from the actual empiricalLEMON data set). We trained 10 convSSM models on the first 375 time steps of each of thesevirtual experiments, treating the left out 125 time points as pseudo-empirical test set and call thelast 5, 000 time points of the entire trajectory (i.e., time steps 5, 001-10, 000 of the full simulationset) the ground truth (GT) test set (which would not be accessible in a real experiment). DSRperformance was assessed on both the observed {xt} and latent {zt} time series, evaluated for a) theshort pseudo-empirical test set of length 125, b) the full pseudo-empirical time series (i.e., of length500), and c) the GT test set of length 5000 (which also assesses dynamics on the limit set and doesnot contain transients anymore). D shows histograms over Dstsp (on the full pseudo-empirical time series) for the convSSM,the standard SSM, and the benchmark conditions. The convSSM significantly outperformed thestandard SSM in latent space (rank-sum test Z = 11.50, p .001), demonstrating an improvedrecovery of the ground truth DS and indicating that the deconvolution acts as an inductive bias thatforces the model to learn a latent space structured in agreement with our biophysical understandingof fMRI. Moreover, the proposed performance measures (Dstsp, DP SE) successfully discriminatedbetween good and poor reconstructions even on these short time series more typical for empirical data:For one, evaluating DSR on the observations was consistent with evaluating DSR directly on the latentdynamics space (F and Appx. ). Second, DSR assessed on the pseudo-empiricaltime series (either full or only test set) was strongly correlated with performance assessed on the longGT test set (which, again, in empirical situations we do not have, E and Appx. ).",
  "Application to experimental fMRI data": "We finally tested convSSM on empirical data, for which we chose the LEMON study (Leipzig Studyfor Mind-Body-Emotion Interactions) as a publicly available data set. This data set was collectedat the Max-Planck-Institute Leipzig and consists of 227 healthy participants, each of whomcompleted a battery of tests, including a 15min 30s resting state fMRI (rsfMRI) session sampledat TR = 1.4s (thus comprising T = 652 time points). We used the preprocessed rsfMRI data setsas provided, and selected 16 regions from which we extracted a subset of the available time series.These were subsequently smoothed, band-pass filtered, and standardized as in . The time serieswere split 3 : 1 into training (Ttrain = 489) and test (Ttest = 163) set, respectively. Data fromparticipants with non-stable variance were discarded (i.e., non-stationary data, see Appx. B.3 fordetails), leaving N = 51 participants for analysis. We trained 20 models on data of each participant with latent dimension M = N = 16 (i.e., equalto the observation dimension), = .1, and hidden dimension L = 50 (where L and M refer to thedimensions of the connectivity matrices W1, W2 in the cshPLRNN, Equation 1). Latent dimensionand were determined via grid search, by inferring systems using a subset of the data and assessingthe performance on the held-out set . Otherwise the same hyperparameters as used in forEEG data were applied (see Appx. for all details). In addition to the model comparisons",
  "EFG": ": Results on empirical LEMON data set. A: Distribution over Dstsp for 1020 systems inferredwith convSSM. B: Example of a good and C: poor reconstruction. D: Illustration of reconstructionperformance as a function of Dstsp. E: Histogram over maximum Lyapunov exponents max. F:Distribution over max for 5 selected participants (n = 100 systems with 10 trajectories each). G:Within- as compared to between-subject variance in max distribution after filtering models by DSperformance measures (selecting the 20 best by Dstsp and 10 best by DP SE). discussed earlier, we also compared our method to the performance of rSLDS and LFADS (see Appx. C.2 for details). On top of Dststp, DP SE, and PEn, we also assessed the trained modelsmaximum Lyapunov exponents, max, analyzed how reliably these can be inferred, and whetherthey distinguish between subjects. Note that obtaining an estimate of the Lyapunov exponent is anadvantage of the generative model, as empirical time series are often too short to compute it reliably.Also, since we do have access to the cshPLRNNs Jacobians, the computations can be performedanalytically (although practically we need to evaluate these along model-generated trajectories, wherehere we used an algorithm proposed in ). The DSR results are shown in . We obtained successful reconstructions on average with amean Dstsp of 2.73, better than all other models (A and D). Interestingly, most recoveredsystems were characterized by a positive maximal Lyapunov exponent max (E), indicatingthe presence of chaotic attractors in these data (consistent with previous observations, ).Moreover, max values could be inferred reliably (F), and differentiated between individuals,as indicated by lower within- as compared to between-subject variation (G, T(50) =11.53, p < .001. : DSR measures evaluated for the convSSM, standard SSM, convSSM trained without GTF,as well as MINDy , rSLDS and LFADS , trained on the LEMON dataset. Model runswere excluded if the 1-step PE > 1 on the training data.",
  "Conclusions": "Methods for producing generative models of the underlying dynamics from time series observationsis a rapidly expanding research field . Current SOTA models for this purpose rely on controltheoretically motivated training techniques like STF and GTF , but these require some meansto generate from the actual observations a TF signal in the models latent space for guiding trajectoryand gradient flows. This becomes difficult if the current observation depends on a whole series oflatent states, as common if the actual measurements are some filtering of an underlying process ofinterest, such as in fMRI or Ca2+ imaging. Here we provide a novel technique that efficiently dealswith this problem, exploiting linearity of Wiener deconvolution. A hallmark of our technique is thatit efficiently scales with model size and convolution length. Another major contribution of this work is to numerically demonstrate that the short time seriesobtained in typical fMRI experiments are actually sufficient for proper model selection accordingto established DSR performance measures, and that these can indeed be properly evaluated inobservation space and do not require access to the unobserved dynamics/ latent space. This is ofmajor empirical relevance for many scientific scenarios, beyond fMRI, in which time series samplingis costly or restricted for technical reasons. Finally, using our DSR technique, we showed thatexperimental fMRI signals mostly exhibit properties of chaotic oscillators (consistent with ), andthat these can be reliably inferred and differ between subjects. Taken together, these contributionspave the way for deploying data-driven fMRI DSR models at large scale to understand inter-individualdifferences in brain dynamics and explore the predictive value of nonlinear DS features for cognitiveor clinical assessment. We emphasize that the proposed framework is highly flexible due to its modular structure, and maybe easily adapted to meet diverse requirements. First, the latent model can be replaced with any otherdifferentiable and recursive dynamical model, such as e.g. LSTMs . The GTF training frameworkwould remain unchanged as the control signal and the latent state update (Equation 3) are not affectedby such modifications . Likewise, the observation model can easily be adapted to account fornonlinear effects of nuisance covariates, e.g. through basis expansions in these variables, or throughlearnable but regularized MLPs. While our model was designed as a scalable method to integratebiological prior knowledge on convolution filters like the hrf, alternatively we can parameterizethe filter weights within the observation model, making them learnable through BPTT, with filterlength either as a hyperparameter, or by imposing a regularization that truncates filter length bydriving coefficients to zero. To prevent conflicts between filter adjustment and latent model, a viablestrategy may be stage-wise learning as suggested in . Once the filter is adjusted, one may reducethe learning rate on the observation model, or even fix its parameters, to prioritize learning of thedynamics. Fixing the filter parameters after an initial stage would have the advantage that subsequenttraining would enjoy the same speed benefits as in our suggested method. We furthermore highlight that our framework could be adapted to accommodate noise in the latentprocess. For example, in Brenner et al. the GTF procedure has been modified to work in thecontext of stochastic DSR models using variational inference. Instead of the multimodal encodermodel in Brenner et al. , one may use the inversion in Equation 9 to generate a TF signal whichsteers a probabilistic latent DS model, i.e. controls its distributional mean, via Equation 3, and usingthe reparameterization trick for BPTT in latent space. However, although probabilistic frame-works are appealing, deterministic BPTT has previously been shown to be (at least) comparable interms of DSR performance, even for clearly noisy observations and latent processes , such that thebenefits for DSR would need to be further examined. Limitations Data-driven approaches such as the one proposed here lack detailed biophysical mech-anisms and may thus not be as suited to address specific questions relating to pharmacological orreceptor mechanisms beyond functional-dynamical implications. Moreover, currently open questionsare how to best deal with non-stationarity in the data, how to efficiently combine data from manysubjects, and how trained models generalize to out-of-domain data.",
  "H. D. I. Abarbanel. The statistical physics of data assimilation and machine learning. CambridgeUniversity Press, 2022": "M. Augustin, J. Ladenbauer, F. Baumann, and K. Obermayer. Low-dimensional spike ratemodels derived from networks of adaptive integrate-and-fire neurons: Comparison and imple-mentation. PLoS Computational Biology, 13(6):e1005545, 2017. A. Babayan, M. Erbey, D. Kumral, J. D. Reinelt, A. M. Reiter, J. Rbbig, H. L. Schaare,M. Uhlig, A. Anwander, P.-L. Bazin, et al. A mind-brain-body dataset of MRI, EEG, cognition,emotion, and peripheral physiology in young and old adults. Scientific Data, 6(1):121, 2019.",
  "R. Henson and K. Friston. Chapter 14 - Convolution Models for fMRI. In Statistical ParametricMapping, pages 178192. Academic Press, London, 2007": "D. Hernandez, A. K. Moretti, Z. Wei, S. Saxena, J. Cunningham, and L. Paninski. Nonlinearevolution via spatially-dependent linear dynamics for electrophysiology and calcium data.Neurons, Behavior, Data analysis, and Theory, 3(3), 2020. J. R. Hershey and P. A. Olsen. Approximating the Kullback Leibler divergence between Gaussianmixture models. In International Conference on Acoustics, Speech and Signal Processing,volume 4, pages 317320. IEEE, 2007.",
  "J.-H. Ko, H. Koh, N. Park, and W. Jhe. Homotopy-based training of NeuralODEs for accuratedynamics discovery. In Advances in Neural Information Processing Systems, volume 36, pages6472564752, 2023": "G. Koppe, H. Toutounji, P. Kirsch, S. Lis, and D. Durstewitz. Identifying nonlinear dynamicalsystems via generative recurrent neural networks with applications to fMRI. PLoS Computa-tional Biology, 15(8):e1007263, 2019. D. Kramer, P. L. Bommer, C. Tombolini, G. Koppe, and D. Durstewitz. Reconstructing nonlineardynamical systems from multi-modal time series. In International Conference on MachineLearning, volume 162, page 1161311633. PMLR, 2022.",
  "F. Lejarza and M. Baldea. Data-driven discovery of the governing equations of dynamicalsystems via moving horizon optimization. Scientific Reports, 12(1):11836, 2022": "S. Linderman, M. Johnson, A. Miller, R. Adams, D. Blei, and L. Paninski. Bayesian learningand inference in recurrent switching linear dynamical systems. In Artificial Intelligence andStatistics, pages 914922. PMLR, 2017. S. W. Linderman, A. C. Miller, R. P. Adams, D. M. Blei, L. Paninski, and M. J. Johnson.Recurrent switching linear dynamical systems. In Advances in Neural Information ProcessingSystems, volume 33, pages 1486714878, 2020.",
  "J. Mikhaeil, Z. Monfared, and D. Durstewitz. On the difficulty of learning chaotic dynamics withRNNs. In Advances in Neural Information Processing Systems, volume 35, pages 1129711312,2022": "C. Pandarinath, D. J. OShea, J. Collins, R. Jozefowicz, S. D. Stavisky, J. C. Kao, E. M.Trautmann, M. T. Kaufman, S. I. Ryu, L. R. Hochberg, et al. Inferring single-trial neuralpopulation dynamics using sequential auto-encoders. Nature Methods, 15(10):805815, 2018. J. Pathak, B. Hunt, M. Girvan, Z. Lu, and E. Ott. Model-free prediction of large spatiotemporallychaotic systems from data: A reservoir computing approach. Physical Review Letters, 120(2):024102, 2018.",
  "M. I. Rabinovich, P. Varona, A. I. Selverston, and H. D. Abarbanel. Dynamical principles inneuroscience. Reviews of Modern Physics, 78(4):1213, 2006": "J. P. Ramirez-Mahaluf, A. Roxin, H. S. Mayberg, and A. Compte. A computational modelof major depression: the role of glutamate dysfunction on cingulo-frontal network dynamics.Cerebral Cortex, 27(1):660679, 2017. D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic backpropagation and approximateinference in deep generative models. In International Conference on Machine Learning,volume 32, pages 12781286. PMLR, 2014.",
  "P. Verzelli, C. Alippi, and L. Livi. Learn to synchronize, synchronize to learn. Chaos: AnInterdisciplinary Journal of Nonlinear Science, 31(8), 2021": "P. R. Vlachas, W. Byeon, Z. Y. Wan, T. P. Sapsis, and P. Koumoutsakos. Data-driven forecastingof high-dimensional chaotic systems with long short-term memory networks. Proceedings ofthe Royal Society A: Mathematical, Physical and Engineering Sciences, 474(2213):20170844,2018. P. R. Vlachas, J. Pathak, B. R. Hunt, T. P. Sapsis, M. Girvan, E. Ott, and P. Koumoutsakos.Backpropagation algorithms and reservoir computing in recurrent neural networks for theforecasting of complex spatiotemporal dynamics. Neural Networks, 126:191217, 2020.",
  "P. R. Vlachas, G. Arampatzis, C. Uhler, and P. Koumoutsakos. Multiscale simulations ofcomplex systems by learning their effective dynamics. Nature Machine Intelligence, 4(4):359366, 2022": "J. T. Vogelstein, A. M. Packer, T. A. Machado, T. Sippy, B. Babadi, R. Yuste, and L. Paninski.Fast nonnegative deconvolution for spike train inference from population calcium imaging.Journal of Neurophysiology, 104(6):36913704, 2010. R. Vogt, M. Puelma Touzel, E. Shlizerman, and G. Lajoie. On Lyapunov exponents for RNNs:Understanding information propagation using dynamical systems tools. Frontiers in AppliedMathematics and Statistics, 8:818799, 2022.",
  "E. Yaksi and R. W. Friedrich. Reconstruction of firing rate changes across neuronal populationsby temporally deconvolved Ca2+ imaging. Nature Methods, 3(5):377383, 2006": "L. Yang, X. Sun, B. Hamzi, H. Owhadi, and N. Xie. Learning dynamical systems from data:A simple cross-validation perspective, part V: Sparse kernel flows for 132 chaotic dynamicalsystems. arXiv preprint arXiv:2301.10321, 2023. B. M. Yu, J. P. Cunningham, G. Santhanam, S. Ryu, K. V. Shenoy, and M. Sahani. Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity.In Advances in Neural Information Processing Systems, volume 21, pages 18811888, 2008.",
  "DE": ": Training duration per epoch (y-axis) in seconds for different TRs (A), hidden dimensions L(B), latent dimensions M (C), time series length (D), and observation dimensions (E). Mean, standarderror (SEM) and linear curve fits (gray dashed lines) are displayed. The per-epoch-runtime increasesapproximately linearly with dimensions L, M, and N; explained variance R2L = 0.989, R2M = 0.993,and R2N = 0.996 for linear regressions with predictors L, M, and N, respectively. Experimentswere performed on a standard notebook with Intel i5-8250U 1,60 GHz CPU and 8GB RAM.",
  "zt = Azt1 + W (zt1) + h.(11)": "where zt RM is a latent state vector at time t, () = max(0, ) is the ReLU activation function,W RMM is an off-diagonal matrix of connection weights and A RMM a diagonal matrixcontaining the autoregressive weights . Neurobiologically motivated, the entries of the latent state zi,t may be interpreted as membranepotentials, the diagonal elements in A as the neurons individual membrane time constants, and theoff-diagonal elements in W as synaptic connections between neurons. The ReLU activation emulatesthat neurons only start spiking above a certain firing threshold.",
  "Nk = E[|Hk|2] is the mean power spectral density of the noise t, the superscript denotes complex conjugation, and F 1 is the inverse Fourier transform": "The noise spectrum Nk is typically unknown in practice, but can be reliably estimated based onthe median estimator on the finest scale wavelet coefficients of xt. As approximation to the powerspectrum of the original signal, we use the denoised signal xt which we obtain by applying theVISUSHRINK algorithm , Algorithm 2, to the observed signal xt. This approximation workswell in practice in absence of knowledge about the true underlying signal.",
  "s=0hrfs zts(22)": "due to the finite non-zero value of , i.e., the maximum time difference at which a previous statezt still influences the current state zt according to the hrf. Furthermore, due to causality, onlypast states are allowed to influence the current state. Since the convolution operation as well as matrix multiplication are linear, the order of convolutionand matrix multiplication in Equation 5 can be inverted to yield Equation 9. This can be seen moreeasily if we consider a decoder model without noise",
  "A.6Additional information on Algorithm 1": "In order to deal with numerical instabilities, additional hyperparameters were introduced. A too lownoise level determined by the VISUSHRINK Algorithm 2 can lead to high frequency artifacts,which can be dealt with by defining a lower noise level boundary min. Although this is unlikely tooccur in empirical (noisy) data, the lower noise level boundary helps to study artificial noise free data.Since the convolution treats the finite signal as periodic, artifacts at the boundaries of the computeddeconvolved signal xdeconvtmay occur. With the hyperparameters cut_l, cut_r (corresponding to startand end of signal, respectively) one can therefore define absolute cutoff times, either by integer or byfloating point values (if, e.g., a cutoff time is to be defined relative to the length of the hrf).",
  "A.7Performance measures": "If the maximum Lyapunov exponent max of a dynamical system is larger than 0, a necessarycondition for chaos, nearby trajectories will diverge exponentially. This limits the applicability ofn-step ahead prediction errors (PEs), as conventionally used in machine learning, to evaluate modelperformance, as even small numerical errors will lead to exponentially growing PEs. In processesin which we can expect chaotic behavior (like neural recordings), we therefore need performancemeasures which are insensitive to a systems initial conditions and yet capture the most relevantdynamical properties. Here, we use two established measures to evaluate the DSR, the statespace divergence, capturing geometric overlap of (ergodic) distributions in state space, and the powerspectrum error, capturing agreement in long-term temporal properties.",
  "A.7.2State space divergence Dstsp": "Given an observed N-dimensional time series {xt} of length T and a time series {xt} with the samedimension/length generated by a model, Dstsp measures the geometrical overlap of orbits in statespace . For low dimensional systems, N 6, the state space is segregated into kN bins where k is thenumber of bins per dimension. Each bin is given an index i and we count the number of times ni thetime series visited bin i. The relative frequency of visits is then obtained by dividing by time serieslength Tpi = ni",
  "(36)": "where pi are the relative frequencies of the observed and qi of the predicted (generated) time series.Note that Dstsp is not a metric in the mathematical sense, but a divergence that assesses the (dis-)agreement of probability distributions. The complexity of this binning approach scales exponentially with the observation dimension Nand thus becomes intractable for larger N. To compute Dstsp in higher-dimensional systems, use Gaussian mixture models (GMMs) with centers (means) xt and diagonal covariance =diag(2, , 2), where is a hyperparameter. The GMMs along the trajectory points are given by",
  "dx3dt = x1x2 x3(45)": "where x1 is proportional to the rate of convection, x2 to the horizontal temperature variation, and x3to the vertical temperature variation. The constants , and are system parameters proportional tothe Prandtl number, Rayleigh number, and certain physical dimensions of the fluid-layer. For chaoticbehavior, = 10, = 28 and = 8 3 are typical settings. These settings produce the so-called\"butterfly attractor\" characteristic of the Lorenz system. For each data set, we drew random initialconditions x0 N(0, 133) and simulated the system using the DynamicalSystems.jl Julia package,(). 105 time steps were saved and used as data set (1 : 1 training vs. test split) after discardingthe first 1, 000 time points to remove transients from the data. To create the benchmark data sets,these trajectories were then convolved with the hrfT R function. Gaussian white noise drawn fromN(0, 133) was added to all data points.",
  "B.2ALN model": "The adaptive linear-nonlinear (ALN) cascade model is a population model of spiking neural networks.The dynamical variables of the ALN model describe the average firing rate and other macroscopicvariables of a randomly connected, delay-coupled network of excitatory and inhibitory adaptiveexponential integrate-and-fire neurons (AdEx) with non-linear synaptic currents . We used neurolib to create neural activity generated by an ALN model . In neurolib, the firingrate of the excitatory subpopulation of every brain area is used to simulate the BOLD signal viathe BalloonWindkessel model (for formula see ). As an alternative, we implemented theBOLD decoder model (Equation 5) as model linking the latent states zt (i.e., the latent neuralactivity corresponding to the excitatory firing rates) to the observed BOLD signal. In order to createinteresting dynamics, certain values were altered from the authors default settings, sigma_ou = 0and b = 5.0. Furthermore, only the first 16 dimensions of the structural connectivity matrix Cmatand the delay matrix Dmat (see explanatory notebook provided by ) were used for comparabilitywith the empirical LEMON data set. neurolib produces simulated (latent) neural activity with a sampling rate of 0.1ms. To stay in acomparable regime with the fMRI and Lorenz time series, we chose a sampling rate of 0.5s for thesimulated (observed) data. To achieve this without loss of critical information, the neuronal activityas well as the BOLD time series were decimated using a 30 point finite impulse response (FIR) filterwith Hamming window. Furthermore, the neural activity time series was smoothed with a Gaussiankernel with standard deviation = 1 and length 5, and then standardized. Outliers in DSR measures () were removed using the interquartile range (IQR) method. TheIQR method considers values as outliers if they are 1.5 IQRs above the third (Q3) or below the first(Q1) quantile (where IQR = Q3 Q1). In and corresponding D, we present the quantitative comparison between the standardSSM, the convSSM, the convSSM without GTF, and two benchmark conditions. depictscorrelations between measures computed on different subsets of the ALN dataset. : DSR measures evaluated on the ALN data set for the convSSM, the standard SSM, and theconvSSM trained without generalized teacher forcing by setting = 0. Measures were evaluated onthe ground truth latent space and the noisy observation space on the different created test sets.",
  "C": ": A: Agreement in DSR measures assessed on the observed (x-axis) vs. latent (y-axis)space of the short pseudo-empirical test set (top) and the full pseudo-empirical time series (bottom).Correlations between Dstsp (left), DP SE (middle), and PE10 (right) are displayed, respectively. B:Top: Agreement in DSR measures assessed on the pseudo-empirical test set (short) vs. GT test set(long). Bottom: Same for full pseudo-empirical time series (short) vs. GT test set (long). Correlationsbetween Dstsp (left), DP SE (middle), and PE10 (right) are displayed, respectively. C: Correlationsbetween DSR measures between pseudo-empirical test set and full pseudo-empirical time series,same order as in B.",
  "B.3LEMON data set": "For the LEMON data set, we observed non-stationarity in the data that partly resulted in performancedegradation. We therefore only included participants with nearly constant variance over time. Toremove non-stationary data sets, we assessed the moving average of the variance over time (windowsize w = 40 time steps). We then discarded data sets in which the variance changed with time(assessed by computing the correlation with time, with threshold set to |r| > .16).",
  "AB": ": A. Ground truth Lorenz trajectory sampled with noise (black), a good reconstruction withlow Dstsp (orange) that accurately recovers the attractor, and a poor reconstruction with high Dstsp(green) that represents the attractor inaccurately, yielding an oscillatory (limit cycle) instead of achaotic solution. B. Trajectories of systems in A. unfolded in time. The inaccurate reconstruction (top)achieves a lower prediction error (PE) than the accurate reconstruction (bottom), due to trajectorydivergence in chaotic systems. This example illustrates that PEs are inadequate to capture thereconstruction of chaotic DS.",
  "C.2Comparison methods": "MINDy: For MINDy we used the implementation at trained models for each subject with the settings provided by the authors for fMRI data. To obtaintrajectories for calculating PE10, DP SE, and Dstsp, we used the provided deconvolution functionto obtain an initial condition in latent space. We iterated the model forward in time for the latenttrajectory and then applied the authors observation function to output a BOLD time series which iscompared with the test data.LFADS: For LFADS , we used the lfads-torch implementation at which provides an LFADS re-implementation in the deep learninglibrary Pytorch . The default hyperparameters provided are optimized for neural spiking data.We changed the observation model (in the framework this is referred to as reconstruction target) to aGaussian, and changed the start and stop learning rates from lrstart = 4 103, lrend = 1 105,to lrstart = 4 104, lrend = 1 106, which improved the fit to our data. To obtain trajectories,we iterated the trained models forward in time with initial conditions from the test dataset using theprovided model.predict_step function.rSLDS: For rSLDS , we used the implementation at We trained the rSLDS with the Laplace-EM method with the Structured Mean-Field Posterior,as recommended by the authors, with diagonal_Gaussian dynamics and Gaussian_id emissions.For a fair comparison, we used the same number of latent dimensions as for the observations (sameas for the cshPLRNN). We determined the rSLDS training parameters = 0.9 and K = 2 viagrid search over [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] and K [] by inferringsystems using a subset of the data and assessing the performance on the held-out set . To generatetrajectories for the model comparison, we first approximated the posterior of the test data and thensampled with model.sample using the approximated posteriors x and z and the test data as prefixinput for the model.",
  "B": ": A: Full (solid) and residual (dashed) average (across dimensions) auto-correlation functionsfor the latent (left) and observed (right) time series. For the residual auto-correlation, the immediatelypreceding time step was regressed out. For the dotted curve, cshPLRNN(zt1) instead of zt1 wasregressed out. B: Same as A for the mutual information as a function of time lag.",
  "zt = cshPLRNN(zt1) + t, t N(0, diag(, , ))": "The cshPLRNN employed here was trained to become a surrogate model for the Lorenz63 system,and t is Gaussian white noise with standard deviation = 0.1 on each dimension. Note that thereare no correlations between noise terms at different time points. A time series of length T = 105 wassimulated. The corresponding observation time series {xt} was created by convolving {zt} with thehemodynamic response function hrf0.5 for TR = 0.5 s. We then computed auto-correlation functions for the actual and a residual time series, where for thelatter the linear effect of zt1 on zt (and, likewise, xt1 on xt) was removed (similar to a partialauto-correlation). As A shows, the autocorrelation of the residual time series drops muchfaster, instantaneously at first, for the latent states (left) as compared to the observed/convolvedvariables on the right, illustrating the convolution effect is removed in the models latent space. It isnot completely gone if only linear dependencies are removed if the model forwarded-iterated statescshPLRNN(zt1) are regressed out instead, the auto-correlation immediately drops to zero for thelatent states (dotted lines in , left), as it should by model definition. Likewise, the (nonlinear)mutual information (B) shows there are no temporal dependencies left in the residual latentseries, while still present in the residual observed series, empirically confirming our approach doeswhat it is supposed to do.",
  "C.4Acronyms": "SSM: State space modelsDS: Dynamical systemsDSR: Dynamical systems reconstructionTF: Teacher forcingBOLD: Blood oxygenation level dependentfMRI: Functional magnetic resonance imagingSLDS): Switching LinearTVB: The Virtual BrainDCM: Dynamic Causal ModelingDL: Deep LearningODE: Ordinary Differential Equation RNN: Recurrent neural networkrSLDS: Recurrent SLDSLFADS: Latent Factor Analysis via DynamicalSystemsSTF: Sparse TFGTF: Generalized TFHRF: Hemodynamic response functionPLRNN: Piecewise linear RNNshPLRNN: Shallow PLRNNcshPLRNN: Clipped shallow PLRNNMSE: Mean squared error SGD: Stochastic gradient descentEVGP: Exploding-and-vanishing gradientsproblemSOTA: State of the artTR: Time of repetitionPE: Prediction errorDPSE: Hellinger distance/Power spectrum er-rorDstsp: Kullback Leibler/ State space divergenceALN: Adaptive linear-nonlinear cascade model max:Maximum Lyapunov exponent GT:Ground truthLEMON: \"Leipzig Study for Mind-Body-Emotion Interactions\"rsfMRI: Resting state fMRI EEG: Electroen-cephalographyLSTM: Long Short-Term MemoryMLP: Multi layer perceptronBPTT: Backpropagation through time",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  "Guidelines:": "The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  "Answer: [Yes]": "Justification: The dataset we use containing human subjects was fully anonimized and allsubjects gave consent for the the data to be used. The data acquisition experiments werecarried out in accordance with the Declaration of Helsinki and the experimental protocolwas approved by the ethics committee at the medical faculty of the University of Leipzig(reference number 154/13-ff), see for details.",
  "Answer: [No]": "Justification: Full experimental details on acquisition of the human publicly availableLEMON data set are given in , and the dataset is properly referenced in the paper. Here,we only include the information relevant to our analyses and replication. The data setconsists of far more details, beyond the scope of the paper.",
  ". Safeguards": "Question: Does the paper describe safeguards that have been put in place for responsiblerelease of data or models that have a high risk for misuse (e.g., pretrained language models,image generators, or scraped datasets)?Answer: [No]Justification: We do not release data and we believe our models do not have a high risk formisuse.Guidelines: The answer NA means that the paper poses no such risks. Released models that have a high risk for misuse or dual-use should be released withnecessary safeguards to allow for controlled use of the model, for example by requiringthat users adhere to usage guidelines or restrictions to access the model or implementingsafety filters.",
  ". Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjects": "Question: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [No] Justification: In this work, we performed data analysis on an anonymized publicly availabledataset of human subjects. The data acquisition was carried out in accordance with theDeclaration of Helsinki and the data acquisition protocol was approved by the ethicscommittee at the medical faculty of the University of Leipzig (reference number 154/13-ff) . An ethics approval in Germany requires study participants to be made aware offoreseeable risks. The data is specifically made available for research purposes. To thebest of our knowledge, no additional risks were incurred by the analyses presented in thismanuscript.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}