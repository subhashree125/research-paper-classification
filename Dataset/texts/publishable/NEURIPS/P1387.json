{
  "Abstract": "Airborne Laser Scanning (ALS) technology has transformed modern archaeologyby unveiling hidden landscapes beneath dense vegetation. However, the lackof expert-annotated, open-access resources has hindered the analysis of ALSdata using advanced deep learning techniques. We address this limitation withArchaeoscape (available at a novellarge-scale archaeological ALS dataset spanning 888 km2 in Cambodia with 31,141annotated archaeological features from the Angkorian period. Archaeoscape isover four times larger than comparable datasets, and the first ALS archaeologyresource with open-access data, annotations, and models.We benchmark several recent segmentation models to demonstrate the benefits ofmodern vision techniques for this problem and highlight the unique challengesof discovering subtle human-made structures under dense jungle canopies. Bymaking Archaeoscape available in open access, we hope to bridge the gap betweentraditional archaeology and modern computer vision methods.",
  "Introduction": "Airborne Laser Scanning (ALS) has been celebrated as a geospatial revolution in modern archaeol-ogy due to its ability to penetrate vegetation and unveil traces of human activities that may otherwisebe concealed or invisible . Extensive acquisition campaigns conducted in Southeast Asia ,Central America , and Europe have led to a reevaluation of the historical impact of humanson natural landscapes, especially in tropical regions . However, finding archaeological featuresin vast volumes of ALS data presents a significant challenge. Manual analysis is time-consuming andrequires advanced expert knowledge of the studied civilization as well as on-site validation . The emergence of deep learning offers a promising tool to assist researchers in identifying archaeo-logical patterns, simplifying the exploration of these extensive acquisitions. Yet, the development ofspecialized models is hampered by the lack of expert-annotated datasets. In response, we introduceArchaeoscape, the largest open-access ALS dataset for archaeological research published to date.Spanning 888 km2, it comprises 31,411 annotated instances of anthropogenic features of archaeologi-cal interest. The dataset includes orthophotos and LiDAR-derived normalized Digital Terrain Models",
  "(nDTM), encompassing over 3.5 billion pixels with RGB values, nDTM elevation, and semanticannotations": "Traditionally, U-Net models have dominated archaeological studies. In this paper, we evaluateseveral recent architectures for semantic segmentation. Our findings indicate that identifying ancientfeatures beneath vegetation canopies using ALS still poses significant challenges. These difficultiescan be attributed to the subtle nature of the objects sought, which are largely represented by faintelevation patterns. Moreover, certain features can span several kilometers and require extensive spatialcontext to disambiguate. With Archaeoscape, we aim to challenge the machine learning and computervision communities to address the rich, impactful, and unsolved problem of ALS-based archaeology.At the same time, we also encourage the archaeological community to adopt open-access policiesand explore modern deep learning approaches.",
  "ALS archaeology datasets": "Deep learning for ALS archaeology is a dynamic field . In , we list the main deep learningworks on ALS-archaeology. Archaeoscape is not only one of the few open-access datasets availablebut also the largest and most comprehensively annotated by a significant margin. 1 Open-access policies.ALS archaeology datasets typically withhold data, annotations, and codedue to legitimate concerns about misuse , and the absence of established open-access normsin archaeology. However, recognizing the critical role of reproducibility and open access in science,we make Archaeoscape accessible to academic researchers. We implement strict safeguards to protectsensitive archaeological information, as described in .1. Scope and extent.Archaeoscape is the largest ALS archaeology dataset in terms of area covered(888 km2) and number of annotated instances (31,411). Archaeoscape covers a 2 larger surfacearea and contains 3 more instances than the next-largest closed archaeology LiDAR dataset (see). It is also the first such dataset related to the Khmer civilization of Southeast Asia.",
  "Semantic segmentation with deep learning": "ALS archaeology approaches rely predominantly on U-Net-based models . However, the fieldof semantic segmentation has evolved considerably since its introduction in 2015. We propose toassess the performance of an array of contemporary, state-of-the-art models on the Archaeoscapebenchmark. Models and pretraining strategies evaluated in are denoted in bold throughoutthe text for clarity and ease of reference. Convolution-based models.Convolutional Neural Networks (CNNs) , and the U-Net architecture in particular, remain the predominant choice for dense prediction tasks across variousapplication fields due to their simplicity and effectiveness. DeepLabv3 improves on this modelby using dilated convolution and Spatial Pyramid Pooling to learn multiscale features. Vision transformers.Vision transformers harness the versatility and expressivity of transformers to extract rich image features. The Vision Transformer ViT model splits the images intosmall patches, which are embedded with a linear layer, while the final patch encodings are convertedinto pixel prediction with another linear layer. DOFA embed each input channel conditionallyto its wavelength, allowing generalization to new sensors. Alternatively hybrid HybViT replacesthese linear layers with a combination of convolutional and deconvolutional layers for encoding anddecoding patches, respectively. This adaptation is particularly effective on smaller datasets, as theconvolutions help capture local feature dependencies more effectively. Hierarchical ViTs.Several variants of the ViT model use a hierarchical approach to effectivelycapture spatial features with a large context. The Pyramid Vision Transformer (PVT) applies itsattention mechanism according to a nested hierarchical structure, while SWIN uses overlappingwindows of increasing sizes. Building on these concepts, PCPVT introduces a conditionalrelative position encoding mechanism, and PVTv2 also allows for overlapping patches. Pre-training strategies.Recent advances in self- and weakly-supervised learning have profoundlyimpacted the efficacy of neural networks. These strategies often use large datasets with text annota-tions such as CLIP-OPENAI or its open-source counterpart CLIP-LAION2B . Alterna-tively, DINOv2 learns from large, unannotated image datasets. The recent Masked Auto-Encoder tunes large models by using the pretext task of masked patch reconstruction. This approach hasbeen adapted to address the specific needs of aerial imagery, leading to variants such as ScaleMAE which are trained on satellite images.",
  "(c) Test": ": Archaeoscape overview. We show the vectorial annotations overlaid onto the relative elevation mapsfor each parcel, and their assignment to the training, validation or test splits. The position and orientation of theparcels is arbitrary. The geometry of the annotations has been simplified to reduce the file size of the paper. Bestviewed on a computer screen.",
  "In this section, we describe the content of Archaeoscape (.1), as well as its acquisitionprocess (.2)": "Context.Angkor, the heart of the medieval Khmer Empire, is often referred to as a hydrauliccity due to its extensive water management infrastructure. This system allowed the Khmer to thrivein a challenging environment, oscillating between monsoon and dry seasons, from the 9th to the15th century. Today, much of the built environment of Angkor and the other cities of this periodhas disappeared, as virtually all non-religious architecture was built using perishable materials suchas wood. What remains is often hidden by dense vegetation or damaged by erosion and modernagricultural practices, rendering these sites nearly invisible at ground level, so that even expertsmight walk over such sites without realizing it. However, the advent of LiDAR (Light Detectionand Ranging) technology has been transformative, uncovering distinct, often geometric patterns inthe topography indicative of ancient occupation and landscape alteration. By combining carefulanalysis of ALS imagery with targeted ground surveys, this decade-long project has documentedtens of thousands of ancient Khmer features, many previously undiscovered, providing a new andexpanded perspective on the history of the region.",
  "Dataset characteristics": "Splits.As shown in , the dataset consists of 23 non-overlapping parcels of varying size,ranging from 2 to 183 km2, and include archaeologically relevant areas such as ancient temples, cities,and roadways. We present the splits for Archaeoscapes training (623 km2, 16 parcels), validation(97 km2, 3 parcels), and test (168 km2, 4 parcels) sets. The splits were chosen to respect the globaldistribution of features and landscapes: densely or scarcely occupied regions, hills or floodplains,large-scale hydraulic engineering sites, monumental temples, and subtle earthen features. Under these constraints, splitting the dataset into spatially distinct regionsas is commonly donein geospatial machine learningproved impractical. To prevent data contamination all parcels areseparated by a least a 100 meter buffer. The test set consists of 2 remote parcels, set apart fromthe others by more than 5 km, and 2 parcels adjacent to training and validation sets, covering two",
  "use cases: predicting features in a new area under a domain shift, and a realistic scenario in whicharchaeologists annotate part of an area of interest and train a model to pre-segment the rest": "Misuse prevention.There is a valid concern that large-scale annotated ALS data could be misusedby malicious actors, leading to the targeted looting or destruction of historical sites . Thepotential for misuse has been a significant factor in the lack of public availability of archaeologicaldatasets. To mitigate this risk and alleviate the concerns of local stakeholders, we propose severalmeasures to balance the benefits of open access with the legal and practical protection of culturalheritage sites: Data partitioning: The data is divided into parcels and stripped of georeferencing and absoluteelevation information to prevent spatial identification of remote, less well-known sites. Whilefamous temples such as Angkor Wat may be recognizable, they are already under close protectionby the local authorities.",
  "Dataset format.We distribute the data as GeoTIFF files with a 0.5 m resolution and polygonannotations in the GeoPackage format. We associate each pixel with the following values:": "Radiometry: RGB values obtained from contemporary orthophotography. Ground elevation: Digital Terrain Model (DTM) obtained with ALS, see .2. Semantic label: One-hot encoding of the five classes described below. Annotation.One of the most significant undertakings of Archaeoscape is the meticulous annotationby experts, who have individually traced and field-verified a wealth of archaeological features. Theannotators employed a granular classification system with 12 feature types. However, to mitigatesevere class imbalance and reduce ambiguity, we have streamlined this system into a more manageable",
  "-class nomenclature, represented in . We explain these classes below and provide, whereapplicable, the number of instances and pixel frequency:": "Temple (827, 0.2%). Quintessential to the Cambodian landscape, these edifices stand as themost iconic remnants of the Angkorian civilization. The scale of these temples ranges from themonumental Angkor Wat, spanning over one hundred hectares, to much smaller sites marked bylittle more than a scattering of bricks or stone blocks. Mound (14,400, 8.6%). Manifesting as slight elevations, these artificial earthen features areindicative of a range of human activities. They include habitation and crafting sites, as wellas the embankments of canals and reservoirs. Although very numerous, mounds are oftenconcealed by dense vegetation or too subtle to be easily detectable on the ground. Hydrology (16,184, 10.4%). This class groups together various features of Khmer hydro-engineering such as rivers, canals, reservoirs that can reach several kilometers in width, andsmaller artificial ponds. These features highlight the Angkorian civilizations significant invest-ment in water management and have long been of particular interest to archaeologists. Void (3,145, 2.5%). This annotation is reserved for areas that are considered ambiguous byexpert annotators and for structures excluded from the analysis presented in this paper. Voidpixels are removed from supervision and evaluation. Background (78.3%). This category encompasses everything else: regions that lack particulararchaeological features or are obscured by modern development. Background includes a widearray of non-archaeological elements such as modern agricultural plots and infrastructure.",
  "Acquisition and processing": "Acquisition.ALS and orthophotography imagery was obtained during the KALC (2012) andCALI (2015) acquisition campaigns in Cambodia, from which a subset of 888 km2 was selected,as described in .1, corresponding to over 13,000 aerial photos and 10 billion 3D points, witha density of 10-95 points per m2, depending on the terrain. The data was acquired with Leica LiDAR (ALS60 for KALC, ALS70-HP for CALI) and cameras(RCD105 and RCD30). The instruments were mounted on a pod attached to the skid of a EurocopterAS350 B2 helicopter flying at 800 m above ground level as measured by an integrated HoneywellCUS6 IMU, and positional information was acquired by a Novatel L1/L2 GPS antenna. GPS groundsupport was provided by two Trimble R8 GNSS receivers. Preprocessing.Non-terrain points (i.e. corresponding to tree canopies, modern buildings) areremoved from ALS points with the Terrasolid software . We form a DTM by fitting a triangularirregular network to the remaining points and linearly interpolating the ground point elevationvalues within each triangular plane on a 0.5 meter grid. The photos are orthorectified and resampledto the same 0.5 meter resolution. Annotation.The endeavor to map Khmer archaeological features has a long history, tracing backto the 19th century, with significant advancements following the availability of aerial imagery in the1990s . Our annotation process builds upon this historical groundwork, but mostly leveragesthe LiDAR data collected in 2012 and 2015. Our approach relies on an iterative process of manualannotation using a Geographic Information System, QGIS, and targeted ground survey to verifyfeatures in the field. These mapping and verification efforts were performed by a shifting team ofarchaeologists, both local and foreign, who collectively contributed to the analysis and validation ofthe data. The first pre-LiDAR surveys date back to 1993, and work continued until 2024.",
  "We formulate the problem of finding archaeological features as a semantic segmentation task, andbenchmark several backbone networks on our dataset": "Metrics.We evaluate the prediction of the models with the overall accuracy (OA), class-wiseIntersection over Union (IoU), and the unweighted mean of the IoUs (macro-average). For theevaluation, we exclude pixels annotated with the void label. Implementation details.We train the evaluated models using the configurations of the officialopen-source repository and provide more details in the supplementary materials. The predictions onthe test set are performed along a grid corresponding to the input size and with 25% overlap on eachside. Only the central portion of each prediction is kept while the border predictions are discarded. We use a combination of internal clusters and the HPC GENCI to run our experiments. Reproducingthe entire benchmark requires 260 GPU-h with A100 GPUs. We estimate the total cost of ourhyperparameters search and initial experiments at 1100 GPU-h.",
  "Adapting baselines.To evaluate the performance of modern vision models for ALS archaeology,we adapt several semantic segmentation models to our setting. The changes are minimal:": "Inputs. Beyond radiometry (RGB), we also incorporate ground elevation derived from the ALSdata described in .2. As we consider networks trained on natural images, we modifythe first layer to accommodate an extra band and initialize the additional weights randomlyaccording to N(0, 0.01). Segmentation head. For all transformer-based methods, we map the final patch embeddings topixel-level prediction with linear layers, except for HybViT which uses transposed convolutions.For CNNs, we use their dedicated segmentation heads, which we initialize randomly. Pre-training and fine-tuning. We consider models pre-trained on ImageNet1K andImageNet21K , but also foundation vision models trained on large external datasets: DINOv2, CLIP-OPENAI and LAION-2B , and Earth observation datasets .",
  "We report the quantitative performance of various state-of-the-art semantic segmentation models in, and provide qualitative examples in": ": Semantic segmentation benchmark. We evaluate an array of pre-trained models fine-tuned onArchaeoscape. We first consider models with the same input size of 224 224, then present report performancefor 512 512. We group models as CNNs, Vision Transformers (ViT), and hierarchical vision transformers(HViT). We bold the best performance for an input size of 224, and underline the performances within 0.5 pointof this score. We frame the best overall performance across all resolutions.",
  "d huggingface.co/laion e github.com/bair-climate-initiative/scale-mae f g": "Influence of the backbone.Surprisingly, CNN-based methods such as U-Net outperform mostViTs on our dataset. We attribute this result to ViTs reliance on extensive pre-training on RGBimages. In our data, the most informative channel is the elevation rather than RGB, as the radiometricinformation is typically blocked by the dense canopy cover. Indeed, and as shown in .3,models trained on RGB all perform below 30% mIoU. This distinction may explain why foundationmodels renowned for their effectiveness on natural images, such as DINOv2 or CLIP, fail to adapt tothis new setting. Even ScaleMAE and DOFA, which are pre-trained on large amounts of satelliteimagery, lead to poor performances. The hybrid ViT model HybViT, which uses convolutions for patch encoding and decoding, performsbetter. This suggests that integrating local feature processing (typical of CNNs) with a globalperspective (a strength of ViTs) is beneficial for interpreting archaeological ALS data. This analysis isfurther supported by the relatively high performance of hierarchical ViT models, which even surpassCNNs in some cases. We hypothesize that the hierarchical structure of these models aligns well withthe dual requirement of our task: to recognize local patterns and to integrate them within a broaderspatial context. This capability is particularly advantageous for detecting archaeological features,which often consist of both small objects and expansive, interconnected structures. Influence of the input size.In our experiments, we use the default size of ViTs in all experiments:224 pixels, equivalent to 112 meters. However, the Archaeoscape dataset includes structures suchas basins spanning several kilometres, and which can only be detected with a larger context. Whenscaling our input size to 512, we noted a significant improvement in performance, especially with theU-Net model. Attempts to further increase the input size did not yield additional performance gains,as the models quickly overfit to the training set. Qualitative analysis.As depicted in the top row of , models trained on our data can detectcomplex structures, such as the central grid inside the temple moat and the maze-like features outside.However, they miss the broader semantic context, e.g. finding the prominent temple walls whilefailing to segment the platform. In the middle row, the models detect isolated features and temples",
  "(e) RGB+E": ": Channel ablation. We represent the orthophotography (a), normalized terrain model (b), andannotations (c). We also provide the prediction of a PVTv2 model operating on RGB photos (d), and a modelprocessing both RGB and elevation data (e). The model using only radiometric information performs worseoverall, and in particular, fails to identify any structures under the heavily forested area at the top left corner. with the standard horseshoe configuration, while the large ponds are mostly missed, likely dueto the limited context window size. In the bottom row, the hilly areas with faint feature elevationpose a significant challenge. This highlights the limitations of current models in handling the varyinglandscape, scale, and semantic context of archaeological features. Overall performance.The performance across models remains relatively low, especially if com-pared to results achieved on complex computer vision segmentation benchmarks featuring numerousclasses. This suggests that contemporary model architectures may not adequately meet the specificchallenges of ALS archaeology, which involves interpreting subtle local elevation patterns withina broader spatial context. Furthermore, foundation models for natural images often fail to adapt tothe specificity of the data and the new elevation channel, possibly due to their extensive pre-training.This situation highlights the need for bespoke models specifically tailored for ALS data analysis.",
  "We evaluate the impact of some of the choices made in the design of Archaeoscape through anablation study": "Channel importance.Airborne LiDAR scans are pivotal for uncovering the subtle elevation pat-terns of archaeological features like mounds and canals, which are typically not visible in orthophotos,as shown in . Moreover, dense canopies can obscure or completely hide radiometric informa-tion about the ground. Conversely, in less densely forested areas, orthophotos can capture detailedinformation about archaeological features, complementing LiDAR data. The ablation study results,documented in , highlight the limitations of relying solely on RGB data. Models using onlyRGB information registered a mean Intersection over Union (mIoU) of about 30%, significantlylower than models also utilizing elevation data. This disparity underscores the inadequacy of RGBdata under dense canopy coverage. Furthermore, while removing RGB information only moderatelyaffects performance, it particularly affects the detection of templessome of which are still standingto this day, and are typically not covered by the canopy. The performance gap between modelspretrained with DINOv2 and those pretrained on ImageNet widens without RGB, suggesting thatDINOv2 models are highly optimized for RGB processing, whereas ImageNet models adapt better toelevation data. Initialization strategy.Adapting models trained on RGB data to handle elevation channels poseschallenges. Our approach, detailed in , initialize with small values the weights of the firstlayer corresponding to the new channel while retaining the pre-trained weights for RGB. In ,we evaluate this method against three alternatives: fully random initialization, random initializationof the first layer with other weights retained, and LoRA fine-tuning. Randomly initializing the firstlayer results in performance akin to training the network from scratch, demonstrating the efficacy ofour strategy to leverage pre-existing RGB training.",
  "Conclusion": "We have introduced Archaeoscape, the largest published dataset for ALS archaeology featuringopen-access imagery and annotations. Focused on the ancient Khmer settlement complexes andtemples of Cambodia, our dataset covers 888 km2 and comprises 31,144 individual anthropogenicinstances. We provide an extensive benchmark evaluating several state-of-the-art computer visionmodels for detecting archaeological features within elevation maps and images. Despite formulatingthe problem as a classic semantic segmentation task, we observe that even usually high-performingmodels struggle to achieve high scores. We attribute this poor performance to the unique challenges ofALS archaeology, such as the subtlety of the patterns sought, and the importance of large-scale context.We hope that our dataset will encourage the computer vision and machine learning community topropose novel solutions for these unresolved challenges.",
  "This project is funded by the European Research Council (ERC) under the European Unions Horizon2020 research and inovation programme (grant agreement No 866454)": "Arlen F Chase, Diane Z Chase, Christopher T Fisher, Stephen J Leisz, and John F Weishampel.Geospatial revolution and remote sensing LiDAR in Mesoamerican archaeology. Proceedingsof the National Academy of Sciences, 2012. Arlen F Chase, Kathryn Reese-Taylor, Juan C Fernandez-Diaz, and Diane Z Chase. Progres-sion and issues in the Mesoamerican geospatial revolution: An introduction. Advances inArchaeological Practice, 2016. Damian Evans, Roland J Fletcher, Christophe Pottier, Jean-Baptiste Chevance, DominiqueSoutif, Boun Suy Tan, Sokrithy Im, Darith Ea, Tina Tin, Samnang Kim, et al. Uncoveringarchaeological landscapes at Angkor using LiDAR. Proceedings of the National Academy ofSciences, 2013. Marcello A Canuto, Francisco Estrada-Belli, Thomas G Garrison, Stephen D Houston,Mary Jane Acua, Milan Kovc, Damien Marken, Philippe Nonddo, Luke Auld-Thomas,Cyril Castanet, et al. Ancient lowland Maya complexity as revealed by airborne laser scanningof northern Guatemala. Science, 2018. Alexandre Guyot, Marc Lennon, Thierry Lorho, and Laurence Hubert-Moy. Combined detectionand segmentation of archeological structures from LiDAR data using a deep learning approach.Journal of Computer Applications in Archaeology, 2021. Pawe Zbigniew Banasiak, Piotr Leszek Berezowski, Rafa Zapata, Miosz Mielcarek, KonradDuraj, and Krzysztof Sterenczak. Semantic segmentation (U-Net) of archaeological features inairborne laser scanningexample of the Biaowieza forest. Remote Sensing, 2022.",
  "Jincheng Zhang, William Ringle, and Andrew R. Willis. Unveiling ancient Maya settlementsusing aerial LiDAR image segmentation. arXiv preprint arXiv:2403.05773, 2024": "Wouter Verschoof-van der Vaart, Karsten Lambers, Wojtek Kowalczyk, and Quentin P.J.Bourgeois. Combining deep learning and location-based ranking for large-scale archaeo-logical prospection of LiDAR data from the netherlands. ISPRS International Journal ofGeo-Information, 2020. Marco Fiorucci, Wouter Verschoof-van der Vaart, Paolo Soleni, Bertrand Le Saux, and AriannaTraviglia.Deep learning for archaeological object detection on LiDAR: New evaluationmeasures and insights. Remote Sensing, 2022. Wouter Verschoof-van der Vaart, Alexander Bonhage, Anna Schneider, William Ouimet, andThomas Raab. Automated large-scale mapping and analysis of relict charcoal hearths inConnecticut (USA) using a deep learning YOLOv4 framework. Archaeological Prospection,2023.",
  "Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,ukasz Kaiser, and Illia Polosukhin. Attention is all you need. NeurIPS, 2017": "Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai,Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al.An image is worth 16x16 words: Transformers for image recognition at scale. ICLR, 2021. Zhitong Xiong, Yi Wang, Fahong Zhang, Adam J Stewart, Jolle Hanna, Damian Borth,Ioannis Papoutsis, Bertrand Le Saux, Gustau Camps-Valls, and Xiao Xiang Zhu. Neuralplasticity-inspired foundation model for observing the Earth crossing modalities. arXiv preprintarXiv:2403.15356, 2024. Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu, PingLuo, and Ling Shao. Pyramid vision transformer: A versatile backbone for dense predictionwithout convolutions. In ICCV, 2021.",
  "Wenhai Wang, Enze Xie, Xiang Li, Deng-Ping Fan, Kaitao Song, Ding Liang, Tong Lu,Ping Luo, and Ling Shao. PVTv2: Improved baselines with pyramid vision transformer.Computational Visual Media, 2022": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal,Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visualmodels from natural language supervision. In ICML, 2021. Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman,Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, PatrickSchramowski, Srivatsa Kundurthy, Katherine Crowson, Ludwig Schmidt, Robert Kaczmarczyk,and Jenia Jitsev. LAION-5B: An open large-scale dataset for training next generation image-textmodels. In NeurIPS Datasets and Benchmarks Track, 2022. Maxime Oquab, Timothe Darcet, Tho Moutakanni, Huy V Vo, Marc Szafraniec, VasilKhalidov, Pierre Fernandez, Daniel HAZIZA, Francisco Massa, Alaaeldin El-Nouby, et al.DINOv2: Learning robust visual features without supervision. TMLR, 2023.",
  "Favyen Bastani, Piper Wolters, Ritwik Gupta, Joe Ferdinando, and Aniruddha Kembhavi.SatlasPretrain: A large-scale dataset for remote sensing image understanding. In ICCV, 2023": "Karsten Lambers, Wouter Verschoof-van der Vaart, and Quentin P. J. Bourgeois. Integratingremote sensing, machine learning, and citizen science in Dutch archaeological prospection.Remote Sensing, 2019. Dragi Kocev, Nikola Simidjievski, Ana Kostovska, Ivica Dimitrovski, and iga Kokalj. Discoverthe mysteries of the Maya: Selected contributions from the machine learning challenge & thediscovery challenge workshop at ECML PKDD 2021, 2022.",
  "Oula Seitsonen and Janne Ikheimo. Detecting archaeological features with airborne laserscanning in the alpine tundra of Spmi, northern Finland. Remote Sensing, 2021": "H. Richards-Rissetto, D. Newton, and A. Al Zadjali. A 3D point cloud deep learning approachusing LiDAR to identify ancient Maya archaeological sites. ISPRS Annals of the Photogramme-try, Remote Sensing and Spatial Information Sciences, 2021. Alexander Bonhage, Mahmoud Eltaher, Thomas Raab, Michael Breu, Alexandra Raab, andAnna Schneider. A modified mask region-based convolutional neural network approach forthe automated detection of archaeological sites on high-resolution light detection and ranging-derived digital elevation models in the north German lowland. Archaeological Prospection,2021.",
  "(b) Did you specify all the training details (e.g., data splits, hyperparameters, how theywere chosen)? [Yes] See .1 and supplementary materials": "(c) Did you report error bars (e.g., with respect to the random seed after running experi-ments multiple times)? [No] Due to the extensive computational resources requiredto calculate error bars in time for the submission deadline, we were unable to includethem in the current version of the paper. We plan to conduct the necessary experimentsover the coming weeks and intend to incorporate error bars in the final camera-readyversion of the paper, should it be accepted.",
  "(a) If your work uses existing assets, did you cite the creators? [Yes](b) Did you mention the license of the assets? [N/A] The code licenses are given on thelinked websites": "(c) Did you include any new assets either in the supplemental material or as a URL? [Yes](d) Did you discuss whether and how consent was obtained from people whose data youreusing/curating? [Yes] The data was acquired by the EFEO during the KALC and CALIprojects, as explained in .2. (e) Did you discuss whether the data you are using/curating contains personally identi-fiable information or offensive content? [Yes] The misuse prevention is discussed in.1. See supplementary material for more details.",
  "A.3Additional ALS archaeology-related datasets": "ALS data are well-used by archaeologists for its precision and ability to recover the archaeologicalfeatures . Several recent works have leveraged deep learning techniques to automatically detectfeatures of interest. In Table A.1, we provide a list of such works. Note that this is a very dynamicfield, and this list may not be exhaustive.",
  "Figure A.1: DINOv2 fine-tuning vs LoRA. We fine-tuned DINOv2 small with LoRA at different ranks andcompared their mIoU. Lower ranks perform better but are still 5% behind full fine-tuning": "Foundation models can be difficult to fine-tune to new datasets or tasks, as they tend to easily overfit.Low rank adaptation (LoRA) can remedy this issue by only learning a low-rank update to theweights of the pre-trained model. Figure Figure A.1 provides the performance of PVTv2 and DINOmodels fine-tuned using LoRA compared to a fully fine-tuned. When fine-tuned with LoRA, the performance of DINO rapidly plateaus and even decreases, showingthat the learned features can not be easily adapted from RGB images to terrain models. Conversely,the performance of PVTv2 increases with the rank used for LoRA, but does not reach the performanceof a fully fine-tuned network. This suggests that, when fine-tuned to new input and target domains,and particularly when using LoRA, large models can become over-adapted to their source domainand struggle to generalize. We provide additional visualizations of the mapping outputs generated by our models in Figure A.2.Those once again illustrate the difficulty that arises from large-scale dependency, particularly inwater prediction. Columns 2 and 3 are respectively an illustrations of a failure and success casein predicting large bodies of water. While our model is able to accurately identify most templesand mounds, the reconstruction of the exact shape of religious or settlement complexes remainsapproximate. Moreover, we observe that the model struggles to detect fainter mounds, although theseare still visible to human experts.",
  "using the mean and variance of each sampled image. We use a batch size of 64 throughout allexperiments": "To sample random images during training, we first randomly select pixels from one of the predefinedstudy areas with a probability proportional to their area. We then take a crop of size 224 224centered on this pixel. The image is rejected if over 80% of its extent falls out of the area. otherwise,the out-of-area pixels are padded with the images mean for each channel. Finally, we apply thefollowing augmentations, each activated with an independent probability of 0.5:",
  "The Archaeoscape dataset is under a custom license, which prevents redistribution and attempts atlocalizing the data. We provide the full text of the license below": "The cole franaise dExtrme-Orient (EFEO) makes the Archaeoscape dataset (the DATASET)available for research and educational purposes to individuals or entities (\"USER\") that agree to theterms and conditions stated in this License. 1 The USER may access, view, and use the DATASET without charge for lawful non-commercial research purposes only. Any commercial use, sale, or other monetizationis prohibited. The USER may not use the DATASET for any unlawful activities, includingbut not limited to looting, vandalism, and disturbance of archaeological sites. 2 The USER may not attempt to identify the location of any part of the DATASET and mustexercise all reasonable and prudent care to avoid the disclosure of the locations referencedin the DATASET in any publication or other communication. 3 The USER may not share access to the DATASET with anyone else. This includes distributingthe download link or any portion of the DATASET. Other users must register separately andcomply with all the terms of this Licence. 4 The USER must use the DATASET in a manner that respects the cultural heritage ofCambodia and its people, and in compliance with the relevant Cambodian authorities. Anyuse of the DATASET that could harm or exploit these cultural sites or their environment isstrictly prohibited.",
  "The USER must properly attribute the EFEO as the source of the data in any publications,presentations, or other forms of dissemination that make use of the DATASET": "6 This agreement may be terminated by either party at any time, but the USERs obligationswith respect to the DATASET shall continue after termination. If the USER fails to complywith any of the above terms and conditions, their rights under this License shall terminateautomatically and without notice. THE DATASET IS PROVIDED \"AS IS,\" AND THE EFEO DOES NOT MAKE ANY WARRANTY OFANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO WARRANTIES OFMERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, AND NON-INFRINGEMENT.IN NO EVENT SHALL THE EFEO OR ITS COLLABORATORS BE LIABLE FOR ANY CLAIM,DAMAGES, OR OTHER LIABILITY ARISING FROM THE USE OF THE DATASET.",
  "Q7 Does the dataset contain all possible instances or is it a sample (not necessarily random)of instances from a larger set?": "Archaeoscape covers only a fraction of the full extent of the Khmer Empire at itsapogee and of the likely distribution of Khmer archaeological features in the landscape.Those parts of the dataset contained in the training, validation, and test sets have been extensively annotated by archaeological experts. We can affirm with a reasonablydegree of confidence that the vast majority of the archaeological features in these splitshave been identified and annotated.",
  "Q8 What data does each instance consist of?": "Each parcel is a raster file under the GeoTIFF format with a ground sampling distanceof 0.5 m. Each pixel is associated with: (i) a terrain elevation relative to the lowestpoint of the file, (ii) an RGB value derived from an orthorectified aerial photograph,(iii) where available, a label corresponding to one of the sought classes, (iv) a binaryvalue indicating whether or not the pixel is in the parcel.",
  "Q13 Are there any errors, sources of noise, or redundancies in the dataset?": "As the annotations are made through visual interpretation with quality control, someerrors are unavoidable, especially for classes that are visually hard to distinguish. Someunavoidable noise occurs due to the ambiguous boundaries of subtle archaeologicalfeatures. Internal quality control has been performed to limit such errors. There are noredundancies in the dataset, each parcel covers a distinct area.",
  "This dataset is self-contained and will be stored and distributed by the EFEO": "Q15 Does the dataset contain data that might be considered confidential (e.g., data that isprotected by legal privilege or by doctorpatient confidentiality, data that includes thecontent of individuals non-public communications)? [No] The data does not contain confidential information. However, to limit potentialmisuse such as looting or destruction of historical sites, the georeferencing and absoluteelevation of the parcels have been removed.",
  "Q21 How was the data associated with each instance acquired?": "The ALS data and photography were acquired from aerial surveys in Cambodia andmapped onto a cartographic coordinate reference system. From this data a subset of888 km2 was selected, corresponding to over 13,000 aerial photos and 10 billion points,with a density of 10-95 points per m2, depending on the terrain. The ALS points were filtered to remove noise and classified. The normalized DigitalTerrain Models (nDTM) (relative ground elevation) was obtained from the classifiedALS point clouds using open-source software. A triangular irregular network was fittedto the ground points (excluding extraneous elements such as tree canopies and modernbuildings), with a DTM formed by linear interpolation of the elevation values withineach triangular plane based on a 0.5 meter grid. The same procedure was applied toobtain intensity and return number metadata maps. The photos were orthorectified andresampled to the same 0.5 meter resolution.",
  "Q22 What mechanisms or procedures were used to collect the data (e.g., hardware apparatusor sensor, manual human curation, software program, software API)?": "The data was acquired with Leica LiDAR (ALS60 for KALC, ALS70-HP for CALI)and cameras (RCD105 and RCD30). The instruments were mounted on a pod attachedto the skid of a Eurocopter AS350 B2 helicopter flying at 800 m above ground level asmeasured by an integrated Honeywell CUS6 IMU, and positional information acquiredby a Novatel L1/L2 GPS antenna. GPS ground support was provided by two TrimbleR8 GNSS receivers.",
  "Q23 If the dataset is a sample from a larger set, what was the sampling strategy (e.g.,deterministic, probabilistic with specific sampling probabilities)?": "The target areas for the LiDAR acquisition campaigns were selected on the grounds ofarchaeological value and interest by domain experts. A subset of 888 km2 presented inthis dataset was selected by choosing 23 non-overlapping parcels in the areas wherearchaeological annotations were deemed complete and finalized, preserving the globaldistribution of features and landscapes across the training, validation and test sets.",
  "Q24 Who was involved in the data collection process (e.g., students, crowdworkers, contrac-tors) and how were they compensated (e.g., how much were crowdworkers paid)?": "These mapping and verification efforts were performed by a shifting team of archaeolo-gists, both local and foreign, who collectively contributed to the analysis and validationof the data, with the first pre-LiDAR surveys dating back to 1993, and continuing until2024. All persons involved were employees and researchers from foreign governmentalinstitutions, such as the EFEO or Sydney University, or employed by the Cambo-dian governmental authorities, following strictly existing ethical codes and nationalregulations.",
  "A.7.4Preprocessing, cleaning, and/or labeling": "Q34 Was any preprocessing/cleaning/labeling of the data done (e.g., discretization or bucket-ing, tokenization, part-of-speech tagging, SIFT feature extraction, removal of instances,processing of missing values)? [Yes] The ALS acquisitions are delivered in the form of 3D point clouds. The ALSpoints were filtered to remove noise and classified. We have extracted terrain modelsfrom the ground clouds only, i.e. those not belonging to the tree canopies and modernbuildings.",
  "The dataset will be distributed upon acceptance of this paper, and will be made publicat the camera-ready deadline at the latest": "Q47 Will the dataset be distributed under a copyright or other intellectual property (IP)license, and/or under applicable terms of use (ToU)? If so, please describe this licenseand/or ToU, and provide a link or other access point to, or otherwise reproduce, any relevantlicensing terms or ToU, as well as any fees associated with these restrictions."
}