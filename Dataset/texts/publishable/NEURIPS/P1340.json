{
  "Abstract": "The Global Change Analysis Model (GCAM) simulates complex interactionsbetween the coupled Earth and human systems, providing valuable insights intothe co-evolution of land, water, and energy sectors under different future scenarios.Understanding the sensitivities and drivers of this multisectoral system can lead tomore robust understanding of the different pathways to particular outcomes. Theinteractions and complexity of the coupled human-Earth systems make GCAMsimulations costly to run at scale - a requirement for large ensemble experimentswhich explore uncertainty in model parameters and outputs. A differentiableemulator with similar predictive power, but greater efficiency, could provide novelscenario discovery and analysis of GCAM and its outputs, requiring fewer runs ofGCAM. As a first use case, we train a neural network on an existing large ensemblethat explores a range of GCAM inputs related to different relative contributions ofenergy production sources, with a focus on wind and solar. We complement thisexisting ensemble with interpolated input values and a wider selection of outputs,predicting 22, 528 GCAM outputs across time, sectors, and regions. We report amedian R2 score of 0.998 for the emulators predictions and an R2 score of 0.812for its input-output sensitivity.",
  "Introduction and Background": "The global change problem involves both Earth and human system dynamics, interacting and creatingfeedbacks among the multiple components and sectors that make up the whole system. The GlobalChange Analysis Model (GCAM) and other models of the same class are essential to representthe future evolution of the human system, including socioeconomic, land, energy, and water sectors,giving rise to future plausible and coherent scenarios of emissions. These scenarios are in turn usedas drivers of Earth system model projections. In the opposite direction, climate output from Earthsystem models is used to model impacts in GCAM and other integrated multi-sector models. Thiswork focuses on emulating GCAM specifically; it is an open-source multisector dynamic model thatsimulates the integrated, simultaneous evolution of energy, agriculture, land use, water, and climatesystem components. GCAM simulates global markets segmented into 32 distinct socioeconomicregions, 235 hydrological basins, forming 384 land units from the intersection of basins and regions. Historically, GCAM and comparable models have run a discrete set of storylines or representa-tive future scenarios. In contrast, thanks to advances in computational power and analysis tools,exploratory modeling, sampling a much larger set of drivers (and therefore outcomes) has becomepopular in recent years . In this approach, large ensembles of scenarios are designed and run",
  "arXiv:2412.08850v1 [econ.GN] 12 Dec 2024": "to fill the gaps between the representative storyline scenarios. This approach has been fruitful forexploring the complex sensitivities these models have to assumptions about the systems under test,and the external drivers that determine their outcomes. This understanding of sensitivity and driverscan facilitate identification of pros and cons of different pathways to outcomes of interest (e.g., tominimize water scarcity ). The ensembles are often designed to incorporate a range of data sources,expert opinion, and discrete parameterizations in a factorial combination . However, even withaccess to modern computing clusters, computational cost hinders a comprehensive exploration ofthese inputs. We aim to enable this comprehensive exploration via deep learning-based emulation ofGCAM. Existing large ensembles provide data to train and evaluate such emulators. Once trained, a high-fidelity emulator can be used to aid our understanding both of the coupledEarth-human systems and their models (e.g., GCAM). For example, an emulator could be used toexplore the input (assumption) space, to steer the generation of large GCAM ensembles, or to bettercharacterize model sensitivities. There are two defining aspects to our approach that set it apart fromGCAM toward these goals. First, once trained, predicting outcomes for novel scenarios is faster thanGCAM by at least three orders of magnitude. Second, the differentiability of the emulation enablesefficient search algorithms over the input space. Relatively little work has been done with emulationof integrated, multisector models, but results have been promising . Here we introduce ahigh-fidelity emulator of GCAM, both in the predictions and in the input-output sensitivities.",
  "Data": "Each scenario of GCAM is shaped by exogenous factors like socioeconomic trends (population andGDP growth), technology costs and performance, historical information, and assumptions aboutfuture values of key drivers. These are what we call inputs in this paper, and a subset of these willbe sampled in our ensembles. GCAM provides a detailed, time-evolving analysis of sectors withinthe economy and simulates how different external factors might affect specific sectors over time,taking into account the effects from all other sectors; these serve as the outputs of our emulator. Inputs:This paper follows the experiment set up by Woodard et al. , W2023 henceforth, tostudy the effect of varying inputs on wind and solar energy adoption by 2050. We use the same 12GCAM inputs as W2023, representing costs, constraints, backups, and demand in the energy sector.These factors were chosen by climate experts to describe a wide variety of scenarios to exploreGCAM and its outputs. describes each of the 12 inputs. In W2023 experiments, these factorswere held to high and low values which were encoded as 1 and 0, respectively, in our experiments. To enrich the input space, we consider here input values between the high and low. For nine of the 12inputs (see Appendix A), an intermediate value between high and low is well-defined, so we relax thedomain from {0, 1} to the interval 0 x 1. The extreme high and low values still represent theoriginal binary meaning, while all intermediate values are linearly interpolated between the high andlow scenarios. For three of the twelve inputs, a notion of intermediate is not well-defined; namely,for bioenergy, electrification, and emissions, the binary values represent the presence of absence ofspecific input files to GCAM. Sampling Strategies:With the introduction of interpolated values, the input space can no longerbe enumerated, so we consider two strategies for sampling the space: Latin hypercube andfinite-diff . In either strategy, the nine interpolated inputs are sampled by the strategywhile the remaining three inputs are randomly sampled randomly uniformly in {0, 1}. We selectedLatin hypercube to efficiently explore the interpolated input space, while the finite-diff was selectedto support our sensitivity analysis. We sample 4096 input configurations for Latin hypercubedata (denoted here interpolated) data, which we split into training, validation and test sets at an80%/10%/10% ratio. The finite-diff data (denoted here as the DGSM or sensitivity dataset)contains 4000 samples and is entirely test set, as it was used neither for model training nor tuning. Outputs:Each GCAM run produces a large output database related to the energy, water, climate,and land sectors. Among these, we identify 44 GCAM output quantities to predict (see Appendix Bfor full details). These quantities were chosen to cover physical quantities and prices over the major",
  ": Diagram of the input-output relationship using GCAM. The emulator approximates thedashed box, mapping directly from inputs to outputs": "resources in the water, land, and energy sectors relevant to renewable energy adoption, in light of thefocus in W2023. For each of the 44 output quantities, GCAM and our emulator predict values over32 regions and over 16 model years, {2025, 2030, 2035, . . . , 2095, 2100}. This yields a total outputdimension of 22, 528 values to predict.",
  "Emulator": "illustrates the emulation problem. Our emulator abstracts a series of steps between inputsand outputs, including interpolating the configuration XMLs, running GCAM, and running queries toextract the output values of interest. Model Architecture:Motivated by the success of neural networks learning non-linear relation-ships , we employ a nueral network to emulate input-output relationship (dashed box of ).Specifically, we use a four-layer, feed-forward, fully connected neural network, each layer with 256hidden units followed by a linear rectified unit (ReLU) hidden activation function . The fullyconnected output layer contains 22, 528 units. Training:The model is trained to minimize mean squared error loss between the emulator pre-dictions and GCAM outputs on the training set using hyperparameters selected with a BayesianHyperparameter search via Weights and Biases on the validation set. All output values are z-score normalized using their training set statistics each quantity-region-year pair xqry is normalizedusing (xqry qry)/qry; where mean (qry) and standard deviation (qry) are computed for thatspecific quantity-region-year value across all training dataset scenarios. We train with the AdamW stochastic optimization algorithm for 500 epochs with a learning rate of 0.001.",
  "Results and Analysis": "As summarized in , we analyze the performance of our emulator by comparing the outputvalues to those of GCAM, as well as comparing the sensitivities of the emulator to those of GCAM.For the Predictions row of the table, we evaluate the Overall emulator performance on theinterpolated test set by calculating the R2 score for each of the 22,528 output values and report themedian over these output values. This shows very high agreement with GCAM, with a median R2of 0.998. The results for Region, Year, and Quantity involve first aggregating targets over the othertwo dimensions (e.g., Region averages over Year and Quantity); R2 is then computed for each theremaining outputs (44 if Quantity, 32 if Region, 16 if Year), and the median R2 over these aggregatedoutputs is reported. This level of aggregation does not improve the already near-perfect overall R2. : Evaluation of emulator on test sets. Results are reported as R2 values between GCAM andthe emulator on its predictions (on the interpolated test set) and on input-output DGMS sensitivity(on the DGSM set), aggregated to region, year or quantity-level, and overall (no aggregation).",
  "Conclusion and Future Work": "We present in this paper a high-fidelity and computationally efficient emulator of GCAM using deeplearning. In the process of doing so, we enriched the sampling strategy of inputs underpinning anexisting exploration (in W2023) of the drivers of renewable energy deployment by 2050, relaxing9 of 12 input variables from binary to continuous. This represents a particularly valuable additionto the past study that, by limiting exploration to binary choices for the input parameters, riskedoverlooking outcomes of interest associated with intermediate values. We confirm that our emulatoris highly accurate and that its sensitivities are consistent with GCAMs. In future work, we planto explore the use of this high-fidelity emulator for searching over input space (e.g., to identifycircumstances that minimize water scarcity) to steer the generation of large ensembles of GCAM,and to better understand GCAM itself. Ultimately, we view this work as a bridge to a new era wherelarge ensembles are still relevant, but their creation can be aided by machine learning to reduce thecost and complexity; future work to answer scientific questions around climate, energy, land andwater systems can generate tailored ensembles in an iterative, emulator-in-the-loop manner.",
  "Acknowledgements": "This research was supported by the U.S. Department of Energy, Office of Science, as part ofresearch in MultiSector Dynamics, Earth and Environmental System Modeling Program. The PacificNorthwest National Laboratory is operated for DOE by Battelle Memorial Institute under contractDE-AC05-76RL01830. The views and opinions expressed in this paper are those of the authors alone.",
  "Lukas Biewald. Experiment tracking with weights and biases, 2020. Software available fromwandb.com": "Ben Bond-Lamberty, Kalyn Dorheim, Ryna Cui, Russell Horowitz, Abigail Snyder, KatherineCalvin, Leyang Feng, Rachel Hoesly, Jill Horing, G. Page Kyle, Robert Link, Pralit Patel,Christopher Roney, Aaron Staniszewski, Sean Turner, Min Chen, Felip Feijoo, Corinne Hartin,Mohamad Hejazi, Gokul Iyer, Sonny Kim, Yaling Liu, Cary Lynch, Haewon McJeon, StevenSmith, Stephanie Waldhoff, Marshall Wise, and Leon Clarke. Gcamdata: An R Package forPreparation, Synthesis, and Tracking of Input Data for the GCAM Integrated Human-EarthSystems Model. 7(1):6, March 2019. Katherine Calvin, Pralit Patel, Leon Clarke, Ghassem Asrar, Ben Bond-Lamberty, Ryna YiyunCui, Alan Di Vittorio, Kalyn Dorheim, Jae Edmonds, Corinne Hartin, Mohamad Hejazi, RussellHorowitz, Gokul Iyer, Page Kyle, Sonny Kim, Robert Link, Haewon McJeon, Steven J. Smith,Abigail Snyder, Stephanie Waldhoff, and Marshall Wise. GCAM v5.1: Representing thelinkages between energy, water, land, climate, and economic systems. Geoscientific ModelDevelopment, 12(2):677698, February 2019. Flannery Dolan, Jonathan Lamontagne, Katherine Calvin, Abigail Snyder, Kanishka B. Narayan,Alan V. Di Vittorio, and Chris R. Vernon. Modeling the Economic and Environmental Impactsof Land Scarcity Under Deep Uncertainty. Earths Future, 10(2):e2021EF002466, February2022. Flannery Dolan, Jonathan Lamontagne, Robert Link, Mohamad Hejazi, Patrick Reed, and JaeEdmonds. Evaluating the economic impact of water scarcity in a changing world. NatureCommunications, 12(1):1915, March 2021.",
  "Jon Herman and Will Usher. SALib: An open-source python library for sensitivity analysis.The Journal of Open Source Software, 2(9), jan 2017": "Takuya Iwanaga, William Usher, and Jonathan Herman. Toward SALib 2.0: Advancing theaccessibility and interpretability of global sensitivity analyses. Socio-Environmental SystemsModelling, 4:18155, May 2022. Franklyn Kanyako, Jonathan Lamontagne, Abigail Snyder, Jennifer Morris, Gokul Iyer, FlanneryDolan, Yang Ou, and Kenneth Cox. Compounding uncertainties in economic and populationgrowth increase tail risks for relevant outcomes across sectors. Earths Future, 2023.",
  "I.M. Sobol and S. Kucherenko. Derivative based global sensitivity measures and their link withglobal sensitivity indices. Mathematics and Computers in Simulation, 79(10):30093017, June2009": "Junya Takakura, Shinichiro Fujimori, Kiyoshi Takahashi, Naota Hanasaki, Tomoko Hasegawa,Yukiko Hirabayashi, Yasushi Honda, Toshichika Iizumi, Chan Park, Makoto Tamura, andYasuaki Hijioka. Reproducing complex simulations of economic impacts of climate changewith lower-cost emulators. Geoscientific Model Development, 14(5):31213140, June 2021. Dawn L. Woodard, Abigail Snyder, Jonathan R. Lamontagne, Claudia Tebaldi, Jennifer Morris,Katherine V. Calvin, Matthew Binsted, and Pralit Patel. Scenario Discovery Analysis of Driversof Solar and Wind Energy Transitions Through 2050. Earths Future, 11(8):e2022EF003442,August 2023. Weiwei Xiong, Katsumasa Tanaka, Philippe Ciais, Daniel J. A. Johansson, and Mariliis Lehtveer.emIAM v1.0: An emulator for Integrated Assessment Models using marginal abatement costcurves. Preprint, Integrated assessment modeling, March 2023.",
  "InputKeyDescription": "Wind and Solar BackupsbackSystems needed to backup wind and solarBioenergybioTax on bioenergyCarbon CaptureccsCarbon storage resource costElectrificationelecShare of electricity in building, industry, and transportationEmissionsemissCO2 emission constraintsEnergy DemandenergyEnergy Demand - GDP and population assumptionsFossil Fuel CostsffCost of crude oil, unconventional oil, natural gas, and coalNuclear CostsnucCapital overnight costsSolar Storage CostssolarSSolar storage capital overnight costsSolar Tech CostssolarTCSP and PV costsWind Storage CostswindSWind storage capital overnight costsWind Tech CostswindTWind and wind offshore capital overnight costs"
}