{
  "Abstract": "Estimates of seismic wave speeds in the Earth (seismic velocity models) are keyinput parameters to earthquake simulations for ground motion prediction. Owingto the non-uniqueness of the seismic inverse problem, typically many velocitymodels exist for any given region. The arbitrary choice of which velocity modelto use in earthquake simulations impacts ground motion predictions. However,current hazard analysis methods do not account for this source of uncertainty. Wepresent a proof-of-concept ground motion prediction workflow for incorporatinguncertainties arising from inconsistencies between existing seismic velocity models.Our analysis is based on the probabilistic fusion of overlapping seismic velocitymodels using scalable Gaussian process (GP) regression. Specifically, we fit a GPto two synthetic 1-D velocity profiles simultaneously, and show that the predictiveuncertainty accounts for the differences between the models. We subsequentlydraw velocity model samples from the predictive distribution and estimate peakground displacement using acoustic wave propagation through the velocity models.The resulting distribution of possible ground motion amplitudes is much widerthan would be predicted by simulating shaking using only the two input velocitymodels. This proof-of-concept illustrates the importance of probabilistic methodsfor physics-based seismic hazard analysis.",
  "Introduction": "Seismic velocity models estimates of the Earths seismic wave speeds underpin earthquakeground motion prediction in seismic hazard analysis, as they are key inputs to wave equation solvers.They continue to be produced at different resolutions and scales, stemming from different methods(e.g., tomography , reflection surveys ). The seismic inverse problem is ill-posed as there arenot enough data to constrain a unique true Earth model . As such, many overlapping velocitymodels exist for a given region. Consequently, the choice of which velocity model to use in groundmotion prediction is often arbitrary. Nevertheless, it has a significant impact on the results as differentmodels have different structures, length scales, and amplitudes.",
  "arXiv:2412.03299v1 [physics.geo-ph] 4 Dec 2024": "models (GMMs) are used to predict the median and uncertainty of a ground motion parameter(e.g., peak ground displacement PGD) for earthquake scenarios . They make rapid predictions,but drastically simplify the underlying physical processes. Importantly, they approximate the effectof seismic velocities on ground motion, typically only using the average shear wave velocity in theuppermost 30 m . GMMs are thus limited in accuracy and reliability. An alternative is to simulateearthquake scenarios in 3-D by solving the wave equation and extracting PGD estimates, requiring3-D seismic velocity information as input. However, there are two issues: (i) simulating manyearthquakes is computationally costly, and (ii) choices of input parameters are subjective, includingthe input velocity model. To address the first issue, recent advances in machine learning have begunaccelerating wave propagation methods . However, current physics-based hazard analysisworkflows do not consider inconsistencies between velocity models. This omits a key source ofuncertainty, given that predicted ground motion can be drastically impacted by velocity structure. Onepossible solution is to fuse different velocity models, and use the output in earthquake simulations.Unfortunately, existing methods for velocity model fusion [e.g., 1214] typically do not produceprobabilistic outputs, limiting their ability to account for differences between velocity models. In this study, we propose a workflow to account for inconsistencies between seismic velocity modelsin ground motion prediction. Our method is based on the probabilistic fusion of velocity modelsusing Gaussian processes (GPs), and estimates uncertainties owing to differences between them. Wethen produce probabilistic ground motion predictions with respect to these uncertainties by drawingvelocity model samples from the GP predictive distribution, simulating acoustic wave propagationusing each sample, and extracting the PGD predictions. We illustrate that such a probabilistic methodis necessary to capture the spread of possible ground motion scenarios. Our key contributions are as follows: (i) We present a workflow for probabilistic earthquake groundmotion prediction that accounts for inconsistencies between seismic velocity models. (ii) Wedemonstrate the capability of scalable GPs for the probabilistic fusion of different estimates of thesame physical parameter, through a synthetic example using 1-D seismic velocity models. The codefor this work is written in Python and is available at Scivier et al. .",
  "Gaussian processes and data fusion": "GPs are a class of non-parametric models for defining a distribution over function spaces. Theyare widely used for regression, providing robust uncertainty quantification and predictive performance.Unfortunately, exact GP regression is limited in scalability owing to a computational cost of O(n3),where n is the number of data points. Despite the small datasets used in this study, seismic datasetsof realistic size can have n 106107. To overcome this, approximate GP methods have beendeveloped . One popular method for scalable GP inference is the sparse variational Gaussian Wave speed [arb. units] 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Depth [arb. units] (a) Input data m1m2 Wave speed [arb. units] 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 (b) SVGP fit",
  "Samples": "> 5 Distance from in Wave speed [arb. units] 0.0 0.5 1.0 1.5 2.0 2.5 3.0 3.5 4.0 Depth [arb. units] (d) PPGPR samples : Comparison of SVGPR and PPGPR for the probabilistic fusion of seismic velocitymodels. (a) shows the input synthetic 1-D seismic velocity profiles with depth. (b) and (c) showthe fusion results of SVGPR and PPGPR, and (d) shows the 200 function samples drawn fromthe PPGPR predictive distribution used in . The shading in (b) and (c) show the SVGPposterior predictive distribution, qSVGP (y), and the PPGPR latent predictive distribution, qPPGPR (f),respectively, in terms of distance from the predictive means in standard deviations. process (SVGP) , which applies variational inference to fit GPs. SVGPs introduce a set ofinducing variables to approximate the full dataset using a smaller set of points m n. Thus, thecomputational cost is reduced to O(nm2 + m3), making SVGPs practical to apply to large 2-D and3-D datasets. In this study, we use scalable GP regression for fusing seismic velocity models by fitting a GP tomultiple datasets simultaneously. A key advantage of GPs is their modelling of covariance structure,which enables samples matching the spatial patterns of the input data to be drawn from the predictivedistribution. We aim to model inconsistencies between velocity estimates as uncertainty in the GP predictivedistribution. Thus, we need to understand the form of the predictive variance in the SVGP model.Below we provide a brief summary of the key SVGP results to highlight the relevant context for ourwork. The interested reader is referred to Titsias , Matthews et al. , Jankowiak et al. , andMurphy for full derivations and explanations. The inputs are the training set (coordinates of theinput velocity models), X, the inducing point locations, Z, and the points at which we wish to predict,X. Then fX, fZ, f are the (unknown) velocity values that we predict at these locations; and y arethe observed data (input velocity values). SVGP-based methods approximate the joint posterior asq (f, fX, fZ) = p (f, fX | fZ) q (fZ), where p (f, fX | fZ) is calculated exactly . The variationaldistribution is q (fZ) = N (fZ | m, S), where m and S are (learned) variational parameters. Thepredictive distribution over the underlying function (at the target points) f is given by",
  "f (x)2 = K, K,ZKZ,Z1 (KZ,Z S) KZ,Z1KZ,,": "with e.g., K,Z = k (X, Z), and k (, ) is the (chosen) covariance function. Assuming a Gaussianlikelihood, measurements (at the target points) y are related to the underlying function (at thetarget points) f as py | f, 2y= Ny | f, 2yI, where 2y is the (learned) observational noisevariance. Thus, the predictive distribution over y is,",
  "= Ny | , f (x)2 + 2yI.(2)": "The predictive variance at a target point x,i is thus the sum of input-dependent variance overthe underlying function, f (x,i)2, and observational noise, 2y: Var (x,i) = f (x,i)2 + 2y.Despite this symmetry in the predictive variance, Jankowiak et al. highlight that the typicalSVGP objective function (variational ELBO) targets only large 2y often resulting in 2y f (x,i)2, which we see from the data-fit term: LSVGP 1 22y |yi X,i|2. This means wewould model disagreements between different velocity models as observational noise. Given thedegree of disagreement varies spatially, y would need to be input-dependent [e.g., 22, 23]. However,this would result in noisy samples in the predictive distribution (see b) making them uselessfor downstream tasks. We instead wish to model inconsistencies between velocity models as input-dependent uncertaintyin the underlying physical process (i.e., f (x)). To enable this, we use the parametric predictiveGP regression (PPGPR) model . PPGPR is a variation of SVGP with an objective function thatdirectly targets the predictive distribution (Eq. (2)). Notably, the PPGPR objective encourages largef (x)2, as seen from the data-fit term: LPPGPR 1",
  "Fusing synthetic seismic velocity models": "We present a proof-of-concept demonstrating the applicability of PPGPR for the probabilistic fusion oftwo synthetic 1-D seismic velocity models. We note that we do not consider uncertainties attached toinput velocity models in this study (i.e., the input models themselves are not probability distributions).Two datasets, s1 and s2, are sampled (n = 25 data points, each) from a GP prior, using radial basisfunction (RBF) kernels with different length scales. The samples have different coordinates in anoverlapping region. The first model is set as the first sample, m1 = s1. The second model is aweighted superposition of the two samples, m2 = 2",
  "3s2, to create larger-scale similarities andsmaller-scale differences typical of different seismic velocity models. a shows the inputvelocity models, which are 1-D profiles with respect to depth": "At training time, the input models are concatenated and used to condition the GP as a single dataset.For regression, we employ both PPGPR and SVGPR for comparison, using scaled RBF kernels,m = 20 inducing points (with learned locations), and Gaussian likelihoods. The models are trainedusing the Adam optimiser and identical hyperparameters (i.e., learning rate and number ofiterations). Hyperparameters are chosen through trial-and-error, and full hyperparameter details areprovided in the code . Training the models takes one minute for each method, on a laptop usingan NVIDIA T500 2GB GDDR6 GPU. b and c show the results of SVGPR and PPGPR, respectively, on the two velocity models.As discussed in , optimising the SVGP objective results in 2obs f(x)2, making itunsuitable for this task owing to a lack of input-dependence on the predictive variance and noisyfunction samples. On the other hand, PPGPR performs well, with predictive samples appearing toreflect the spatial patterns of the input models. In an ideal case of maximum likelihood estimation forfitting a univariate Gaussian distribution to two observations, y1 and y2, the resulting distribution isN = 1",
  "(y1 + y2), 2 = y1y2": "22. In our example, we therefore expect the 1 contoursto approximately follow each of the input velocity models. We interpolated m1 and m2 at the testpoints using cubic splines and calculated the root mean square error (RMSE) of the SVGP andPPGPR predictive means and variances with respect to the above ideal result. The RMSEs on SVGPand 2SVGP were 0.243 and 0.098 (in wave speed units), respectively, while for PPGPR and 2PPGPRthe RMSEs were 0.045 and 0.012 (in wave speed units). The PPGPR predictive distribution thusappropriately quantifies the uncertainty on the knowledge of seismic velocities in the region. Mostimportantly for our application, the covariance structure of the data is modelled. This enables thedrawing of samples from the predictive distribution that match the spatial patterns of the input data.Despite only fusing two velocity models here, our approach is generally applicable for fusing anynumber of input datasets.",
  "Probabilistic ground motion prediction": "We propose a proof-of-concept workflow for propagating the predicted uncertainty on seismicvelocities through simulations of the acoustic wave equation, to produce probabilistic ground motionpredictions. First, we draw 200 function samples from the PPGPR latent predictive distribution(d). Then for each sample, we simulate the 1-D acoustic wave equation for displacement, u, witha Ricker wavelet as the earthquake source, using a finite difference scheme (6 s for 200 simulations ona laptop vectorised over velocity models). At the surface, we implement a free-surface boundarycondition (i.e., the acoustic pressure p = 0). At depth, we implement an absorbing boundarylayer according to Chern . af shows snapshots of the displacement field at various timesteps in one of the simulations. For each simulation, we record the peak ground displacement atthe surface (i.e., PGD; depth = 0), producing one PGD estimate per simulation (i.e., per samplevelocity model). g shows a histogram of the recorded PGD measurements from the simulations.Additionally, we ran simulations using interpolated versions of m1 and m2 and marked the resultingPGD measurements in g, to investigate how much information is gained by running simulationsfor many velocity model samples. Clearly, the PGD measurements for m1 and m2 do not accountfor the spread of possible ground motions, given the degree of knowledge of seismic velocities in thisexample. Despite being 1-D, our work already shows that it is not possible to approximate the fulldistribution of possible ground motions using only two velocity models. 2.55.07.5 Depth [arb. units] t = 0.16 s a 2.55.07.5 t = 0.33 s b 2.55.07.5 Wave speed [arb. units] t = 0.49 s c 2.55.07.5 t = 0.66 s d 2.55.07.5 t = 0.82 s e 2.55.07.5 t = 0.99 s f 0.70.80.91.0 Peak displacement [arb. units]",
  "Density": "gMedianMiddle 70%m1m2 Displacement [arb. units] : Wavefield snapshots and probabilistic ground motion prediction. (a)(f) shows wavefielddisplacement snapshots at increasing time steps for one simulation. Each panel includes the sourcelocation (yellow star), the maximum PGD up to that time step (yellow dot), and the underlyingvelocity model of the simulation. The shaded region indicates where an absorbing boundary layer isapplied . (g) shows a histogram of the PGD measurements from the simulations, and highlightsthe median and middle 70% of predictions. Also shown are the PGD measurements resulting fromsimulations using just m1 or m2 as input.",
  "Limitations": "This work is a proof-of-concept and can be extended in several ways. For example, we do not accountfor data with varying length scales or structure, or address kernel design or choice, which would berequired for dealing with real seismic datasets. For real-world applicability, it will also be importantto extend our workflow from 1-D to 2-D and 3-D, and to solve the elastic wave equation instead of theacoustic wave equation. Working with 3-D velocity models would add complexity, but in principleit would consist of changing the GP coordinate space from 1-D to 3-D. There are many optimised3-D seismic wave propagation codes that could then be used for the simulation component of theworkflow [e.g., 11, 2729]. If the input velocity models had different spatial densities of data points,the objective function would be weighted towards one of them, and the result would be skewed. Thiscan be readily solved by weighting their contributions to the objective. Additionally in this work, thesynthetic input velocity models do not have uncertainties, which we plan to incorporate in the future(i.e., the input velocity models would themselves be probability distributions). In this study, we were unable to compare our method with existing methods for velocity modelfusion. Current methods are generally designed for enhancing larger-scale velocity models usingsmaller-scale models and are thus not applicable when the models occupy the same domain and/orhave similar spatial data density, as in our case. Additionally, existing methods typically do notproduce probabilistic outputs, meaning it is not possible to compare them in the ground motionprediction component of the study ().",
  "Conclusion": "Seismic velocity models underpin predictions of earthquake ground motion. Current methodsfor physics-based seismic hazard analysis do not account for inconsistencies between existingvelocity models. In this study, we present a proof-of-concept workflow for probabilistic groundmotion prediction that takes this source of uncertainty into account. Firstly, we demonstrate theapplicability of scalable GP regression to the probabilistic fusion of input velocity models, showingthat inconsistencies between velocity models can be modelled as predictive uncertainty. This providesaccess to any number of plausible velocity models for the region by drawing samples from thepredictive distribution. Secondly, we build up a distribution of possible ground motion scenariosfor the family of possible velocity models according to the GP predictive distribution. Our resultsshow a much wider spread of possible peak ground motions than would be predicted by simulatingearthquake scenarios using just the input velocity models themselves. We thus highlight the value ofusing probabilistic methods, such as the one presented here, in physics-based seismic hazard analysisto account for differences between velocity models.",
  "ReproducibilityThe code used to produce the results and figures in this study is available at Scivieret al.": "SoftwareThe code for this work was written in Python, and used the open-source software libariesJUPYTER NOTEBOOKS , BINDER , NUMPY v2.1.3 , SCIPY v1.14.1 , MATPLOTLIBv3.9.2 , PYTORCH v2.5.1 , and GPYTORCH v1.13 . FundingSAS is funded by a UKRI NERC DTP Award (NE/S007474/1) and gratefully acknowl-edges their support. PK acknowledges financial support from a Royal Society University ResearchFellowship (URF\\R1\\180377). AGB was supported by grants from NVIDIA and the Munich Institutefor Astro-, Particle and BioPhysics (MIAPbP), funded by the Deutsche Forschungsgemeinschaftunder Germanys Excellence Strategy EXC-2094 390783311.",
  "N. Rawlinson, S. Pozgay, and S. Fishwick.Seismic tomography:A window into deep Earth.Physics of the Earth and Planetary Interiors, 178(3):101135, 2010. ISSN 0031-9201. doi: URL": "Carlo Meletti, Warner Marzocchi, Vera DAmico, Giovanni Lanzano, Lucia Luzi, Francesco Martinelli,B. Pace, Andrea Rovida, Francesco Visini, MPS Group, Giovanni Barreca, Carmelo Monaco, and IunioIervolino. The new Italian Seismic Hazard Model (MPS19). Annals of Geophysics, 64(1), 05 2021. doi:10.4401/ag-8579. Barbara Motnikar, Polona Zupancic, Mladen ivcic, J. Atanackov, Petra Jamek Rupnik, Martina Carman,Laurentiu Danciu, and Andrej Gosar. The 2021 seismic hazard model for Slovenia (SHMS21): overviewand results. Bulletin of Earthquake Engineering, 20:130, 08 2022. doi: 10.1007/s10518-022-01399-8. Norman A. Abrahamson, Nicolas M. Kuehn, Melanie Walling, and Niels Landwehr. Probabilistic SeismicHazard Analysis in California Using Nonergodic Ground-Motion Models. Bulletin of the SeismologicalSociety of America, 109(4):12351249, 07 2019. ISSN 0037-1106. doi: 10.1785/0120190030. URL Robert Graves, Thomas Jordan, Scott Callaghan, Ewa Deelman, Edward Field, Gideon Juve, Carl Kessel-man, Philip Maechling, Gaurang Mehta, Kevin Milner, David Okaya, Patrick Small, and Karan Vahi.CyberShake: A Physics-Based Seismic Hazard Model for Southern California. Pure and Applied Geo-physics, 168:367381, 03 2010. doi: 10.1007/s00024-010-0161-6.",
  "Yan Yang, Angela F. Gao, Jorge C. Castellanos, Zachary E. Ross, Kamyar Azizzadenesheli, and Robert W.Clayton. Seismic wave propagation and inversion with Neural Operators, 2021": "Ben Moseley, Andrew Markham, and Tarje Nissen-Meyer. Finite basis physics-informed neural networks(FBPINNs): a scalable domain decomposition approach for solving differential equations. Advances inComputational Mathematics, 49, 07 2023. doi: 10.1007/s10444-023-10065-9. Fatme Ramadan, Bill Fry, and Tarje Nissen-Meyer. Rapid Computation of Physics-Based Ground Motionsin the Spectral Domain using Neural Networks. In EGU General Assembly Conference Abstracts, EGUGeneral Assembly Conference Abstracts, page 18444, April 2024. doi: 10.5194/egusphere-egu24-18444. Fanny Lehmann, Filippo Gatti, Michal Bertin, and Didier Clouteau. 3D elastic wave propagationwith a Factorized Fourier Neural Operator (F-FNO). Computer Methods in Applied Mechanics andEngineering, 420:116718, 2024. ISSN 0045-7825. doi: URL Andreas Fichtner, Dirk-Philip van Herwaarden, Michael Afanasiev, Saule Simute, Lion Krischer, Yesimubuk Sabuncu, Tuncay Taymaz, Lorenzo Colli, Erdinc Saygin, Antonio Villaseor, Jeannot Trampert,Paul Cupillard, Hans-Peter Bunge, and Heiner Igel. The Collaborative Seismic Earth Model: Generation1. Geophysical Research Letters, 45(9):40074016, 2018. doi: 10.1029/2018GL077338. URL R. Ajala and P. Persaud. Effect of Merging Multiscale Models on Seismic Wavefield Predictions Nearthe Southern San Andreas Fault. Journal of Geophysical Research: Solid Earth, 126(10), 2021. doi:10.1029/2021JB021915. URL Hao Zhang and Yehuda Ben-Zion. Enhancing Regional Seismic Velocity Models With Higher-ResolutionLocal Results Using Sparse Dictionary Learning.Journal of Geophysical Research: Solid Earth,129(1):e2023JB027016, 2024. doi: URL e2023JB027016 2023JB027016.",
  "Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for Machine Learning.The MIT Press, 11 2005. ISBN 9780262256834. doi: 10.7551/mitpress/3206.001.0001. URL": "Haitao Liu, Yew-Soon Ong, Xiaobo Shen, and Jianfei Cai. When Gaussian Process Meets Big Data: AReview of Scalable GPs. IEEE Transactions on Neural Networks and Learning Systems, 31(11):44054423,2020. doi: 10.1109/TNNLS.2019.2957109. Michalis Titsias. Variational Learning of Inducing Variables in Sparse Gaussian Processes. In Davidvan Dyk and Max Welling, editors, Proceedings of the Twelfth International Conference on ArtificialIntelligence and Statistics, volume 5 of Proceedings of Machine Learning Research, pages 567574,Hilton Clearwater Beach Resort, Clearwater Beach, Florida USA, 1618 Apr 2009. PMLR. URL Alexander G. de G. Matthews, James Hensman, Richard Turner, and Zoubin Ghahramani. On SparseVariational Methods and the Kullback-Leibler Divergence between Stochastic Processes. In Arthur Grettonand Christian C. Robert, editors, Proceedings of the 19th International Conference on Artificial Intelligenceand Statistics, volume 51 of Proceedings of Machine Learning Research, pages 231239, Cadiz, Spain,0911 May 2016. PMLR. URL Martin Jankowiak, Geoff Pleiss, and Jacob Gardner. Parametric Gaussian process regressors. In Hal DaumIII and Aarti Singh, editors, Proceedings of the 37th International Conference on Machine Learning, volume119 of Proceedings of Machine Learning Research, pages 47024712. PMLR, 1318 Jul 2020. URL",
  "Albert Chern. A reflectionless discrete perfectly matched layer. Journal of Computational Physics, 381:91109, March 2019. ISSN 0021-9991. doi: 10.1016/j.jcp.2018.12.026. URL": "Daniel Peter, Dimitri Komatitsch, Yang Luo, Roland Martin, Nicolas Le Goff, Emanuele Casarotti, PieyreLe Loher, Federica Magnoni, Qinya Liu, Celine Blitz, Tarje Nissen-Meyer, Piero Basini, and Jeroen Tromp.Forward and adjoint simulations of seismic wave propagation on fully unstructured hexahedral meshes.Geophys. J. Int., 186(2):721739, 2011. doi: 10.1111/j.1365-246X.2011.05044.x. Takuto Maeda, Shunsuke Takemura, and Takashi Furumura. OpenSWPC: an open-source integratedparallel simulation code for modeling seismic wave propagation in 3D heterogeneous viscoelastic media.Technical report, Springer, 2017. Kuangdai Leng, Tarje Nissen-Meyer, Martin van Driel, Kasra Hosseini, and David Al-Attar. AxiSEM3D:broad-band seismic wavefields in 3-D global earth models with undulating discontinuities. GeophysicalJournal International, 217(3):21252146, 02 2019. ISSN 0956-540X. doi: 10.1093/gji/ggz092. URL Thomas Kluyver, Benjamin Ragan-Kelley, Fernando Prez, Brian Granger, Matthias Bussonnier, JonathanFrederic, Kyle Kelley, Jessica Hamrick, Jason Grout, Sylvain Corlay, Paul Ivanov, Damin Avila, SafiaAbdalla, Carol Willing, and Jupyter development team. Jupyter Notebooks - a publishing format forreproducible computational workflows. In Fernando Loizides and Birgit Scmidt, editors, Positioningand Power in Academic Publishing: Players, Agents and Agendas, pages 8790. IOS Press, 2016. URL Project Jupyter, Matthias Bussonnier, Jessica Forde, Jeremy Freeman, Brian Granger, Tim Head, ChrisHoldgraf, Kyle Kelley, Gladys Nalvarte, Andrew Osheroff, M Pacer, Yuvi Panda, Fernando Perez,Benjamin Ragan Kelley, and Carol Willing. Binder 2.0 - Reproducible, interactive, sharable environmentsfor science at scale. In Fatih Akici, David Lippa, Dillon Niederhut, and M Pacer, editors, Proceedings ofthe 17th Python in Science Conference, pages 113 120, 2018. doi: 10.25080/Majora-4af1f417-011. Charles R. Harris, K. Jarrod Millman, Stfan J. van der Walt, Ralf Gommers, Pauli Virtanen, DavidCournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J. Smith, Robert Kern, Matti Picus,Stephan Hoyer, Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime Fernndez del Ro, MarkWiebe, Pearu Peterson, Pierre Grard-Marchant, Kevin Sheppard, Tyler Reddy, Warren Weckesser, HameerAbbasi, Christoph Gohlke, and Travis E. Oliphant. Array programming with NumPy. Nature, 585(7825):357362, September 2020. doi: 10.1038/s41586-020-2649-2. URL Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, David Cournapeau,Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stfan J. van der Walt, MatthewBrett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, Andrew R. J. Nelson, Eric Jones, RobertKern, Eric Larson, C J Carey, Ilhan Polat, Yu Feng, Eric W. Moore, Jake VanderPlas, Denis Laxalde,Josef Perktold, Robert Cimrman, Ian Henriksen, E. A. Quintero, Charles R. Harris, Anne M. Archibald,Antnio H. Ribeiro, Fabian Pedregosa, Paul van Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0:Fundamental Algorithms for Scientific Computing in Python. Nature Methods, 17:261272, 2020. doi:10.1038/s41592-019-0686-2.",
  "J. D. Hunter. Matplotlib: A 2D graphics environment. Computing in Science & Engineering, 9(3):9095,2007. doi: 10.1109/MCSE.2007.55": "Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, TrevorKilleen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kpf, Edward Yang,Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai,and Soumith Chintala. PyTorch: An Imperative Style, High-Performance Deep Learning Library, 2019.URL Jacob R Gardner, Geoff Pleiss, David Bindel, Kilian Q Weinberger, and Andrew Gordon Wilson. GPyTorch:Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration. In Advances in NeuralInformation Processing Systems, 2018."
}