{
  "Abstract": "Diffusion models have demonstrated remarkable success in various domains, in-cluding molecular generation. However, conditional molecular generation remainsa fundamental challenge due to an intrinsic trade-off between targeting specificchemical properties and generating meaningful samples from the data distribu-tion. In this work, we present Time-Aware Conditional Synthesis (TACS), a novelapproach to conditional generation on diffusion models. It integrates adaptivelycontrolled plug-and-play \"online\" guidance into a diffusion model, driving sam-ples toward the desired properties while maintaining validity and stability. A keycomponent of our algorithm is our new type of diffusion sampler, Time CorrectionSampler (TCS), which is used to control guidance and ensure that the generatedmolecules remain on the correct manifold at each reverse step of the diffusion pro-cess at the same time. Our proposed method demonstrates significant performancein conditional 3D molecular generation and offers a promising approach towardsinverse molecular design, potentially facilitating advancements in drug discovery,materials science, and other related fields.",
  "Introduction": "Discovering molecules with specific target properties is a fundamental challenge in modern chemistry,with significant implications for various domains such as drug discovery and materials science . While diffusion models have shown great success in the generation of real-world molecules , their primary goal is often simply to generate realistic molecules without considering specificproperties, which can lead to producing molecules with undesirable chemical properties. Existing works address this issue by leveraging controllable diffusion frameworks to generatemolecules with desired properties . One approach is to use classifier guidance , whichutilizes auxiliary trained classifiers to guide the diffusion process . An alternative is to useclassifier-free guidance (CFG) , which directly trains the diffusion models on condition-labeleddata. While both approaches can generate stable molecules, they struggle to generate truly desirablemolecules due to the complex structures and the discrete nature of atomic features . On the other hand, recent works have introduced training-free guidance for controllablegeneration in a plug-and-play manner, which we hereafter refer to as online guidance (OG). Thisapproach can directly estimate the conditional score with unconditional diffusion model. However, ouranalysis shows that applying online guidance into the molecular generation can result in generatingsamples with significantly low molecular stability and validity due to the stepwise enforcement ofspecific conditions without considering the original distribution at each timestep.",
  "arXiv:2411.00551v1 [cs.LG] 1 Nov 2024": "Time prediction: Correct effective timestep Tweedies formula at corrected timestep tp: predict clean molecule Online Guidance: Fulfill desired condition Forward step: Original data manifold Noisy data manifold at t Deviation timestep ab : (a) Overview of Time-Aware Conditional Synthesis (TACS). TACS helps generate high-quality samples that match target condition while following basic properties of the molecules. At eachtimestep t, online guidance is applied to push xt towards the desired condition. Time Predictor findsthe desired timestep tp for xt after applying the guidance. Using predicted timestep tp, Tweediesformula is used to predict the clean molecule xt0. Finally, forward process q(xt1|x0) is applied toproceed to the next denoising step of t 1. (b) Motivation for TACS. Applying online guidance (g,purple) can shift the generated samples away from the correct data manifold corresponding to thecurrent timestep. This undesirable deviation (red) can be avoided by using time correction to firstmeasure the deviated timestep t, then adjusting the guidance to get corrected guidance vector ( g,green), which keeps the generated samples stay on the correct data manifold. To address this gap, we propose Time-Aware Conditional Synthesis (TACS), a novel frameworkfor generating 3D molecules. TACS utilizes the online guidance in tandem with a novel diffusionsampling technique that we call Time Correction Sampler (TCS). TCS explicitly considers thepossibility that online guidance can steer the generated sample away from the desired data manifoldat each step of the diffusion models denoising process, resulting in an effective timestep that doesnot match the correct timestep during the generation. TCS then corrects this mismatch between thetimesteps, thereby effectively preventing samples from deviating from the target distribution whileensuring they satisfy the desired conditions. By combining online guidance with TCS and integratingthem into a diffusion model, TACS allows generated samples to strike a balance between approachingthe target property and remaining faithful to the target distribution throughout the denoising process.",
  "We propose Time-Aware Conditional Synthesis (TACS), a new framework for diffusion modelthat utilizes adaptively corrected online guidance during the generation": "We introduce Time Correction Sampler (TCS), a novel diffusion sampling technique that ensuresthe generated samples remain faithful to the data distribution. It includes a time predictor, anequivariant graph neural network that accurately estimates the correct data manifold duringinference by predicting the time information of the generation process. Through extensive experiments on a 3D molecule dataset, we demonstrate that TACS outper-forms previous state-of-the-art methods by producing samples that closely match the desiredquantum chemical properties while maintaining data consistency.",
  "Related Works": "Diffusion modelsDiffusion models have achieved great success in a variety of domains, includinggeneration of images , audio generation , videos , and point clouds . Aparticular highlight in the success of diffusion models is their potential to generate molecules that can form the basis of new, previously unseen, medical compounds. Multiple approaches have beenexplored to achieve this. For instance, graph diffusion such as GeoDiff , GDSS , and Di-Gress can generate graph structures that correspond to molecular candidates. Additionally, someapproaches incorporate chemical knowledge tailored to specific applications, such as RFdiffusion forprotein design , a method based on the RoseTTAFold structure prediction network . Otherprevious literature considers different domain-specific applications, such as diffusion for moleculardocking , or molecular conformer generation . Most relevant to our work, diffusion modelshave also shown promising results in synthesizing 3D molecules , generating stable andvalid 3D structures. Conditional molecular generationDeep generative models have made considerableprogress in synthesizing 3D molecules with specific properties. Specifically, conditional diffusionmodels have achieved noticeable improvements in synthesizing realistic molecules.EDM trains separate conditional diffusion models for each type of chemical condition, whileEEGSDE trains an additional energy-based model to provide conditional guidance during theinference. GeoLDM utilizes a latent diffusion model to run the diffusion process in the latentspace. MuDM applies online guidance to simultaneously target multiple properties. However,existing methods either produce unstable and invalid molecular structures or are unable to accuratelymeet the target conditions. To overcome these limitations, we propose TACS, a novel frameworkwhich ensures the generative process remains faithful to the learned marginal distributions in eachtimestep while effectively guiding the samples to meet the desired quantum chemical properties.",
  "Preliminaries": "Diffusion models Diffusion models are a type of generative model that learn to reversea multi-step forward noising process applied to the given data. In the forward process, noise isgradually injected into the ground truth data, x0 p0, until it becomes perturbed into random noise,xT N(0, I), where T is the total number of diffusion steps. We follow the Variance Preservingstochastic differential equation (VP-SDE) where the forward process is modeled by thefollowing SDE:",
  "(t)dwt,(2)": "where pt is the probability density of xt and wt is a standard Wiener process with backward timeflows. The reverse process in Eq. (2) can be used as a generative model when the score functionx log pt(x) is known. To estimate the score function from given data, a neural network s is trainedto minimize the following objective :",
  "Time-Aware Conditional Synthesis": "In this section, we propose our framework, Time-Aware Conditional Synthesis (TACS). .1presents the key component of TACS: the Time Correction Sampler, a novel sampling technique thatleverages corrected time information during the generation process. .2 introduces the overallframework of TACS, which accurately integrates online guidance into the diffusion process using oursampling technique to generate stable and valid molecules that meet the target conditions.",
  "Time Correction Sampler": "Diffusion models are known to have an inherent bias, referred to as exposure bias, where the marginaldistributions of the forward process do not match the learned marginal distributions of the backwardprocess . To mitigate exposure bias in the diffusion models, we propose the Time CorrectionSampler (TCS), which consists of two parts: time prediction and time correction. Time PredictorDuring conditional generation process of diffusion model, a sample follows thereverse SDE as in Eq. (4). However, due to error accumulation during the generation process ,a sample at timestep t of the reverse process of diffusion may not accurately reflect the true marginaldistribution at timestep t. This discrepancy between forward and reverse process can especiallyincreased when applying online guidance for every denoising steps and consequently lead to thegeneration of molecules with low stability and validity. We aim to mitigate this issue by correctingthe time information based on the samples current position. To achieve this, we train a neural network, a time predictor, to estimate the proper timestep of agiven noised data. Specifically, given a random data point x with unknown timestep, time predictormodels how likely x pt for each timestep in [0, T]. For training, we parameterize a time predictor Algorithm 1 Time-Aware Conditional Synthesis (TACS)Input: Total number of diffusion timesteps T, online guidance strength z, target condition c, diffusionmodel , time predictor , time-clip window size .",
  ": end for": "by equivariant graph neural network (EGNN) . Then, cross-entropy loss between the one hotembedding of timestep vector and the logit vector for the model output is used as follows:Ltp() = Et,x0 [log (p(xt)t)] ,(10)where timestep t is sampled from the uniform distribution U[0, T], x0 is chosen from the datadistribution, xt is constructed from Eq. (1), and p(xt)t is the t-th component of the model outputp for a given input xt. We empirically evaluate the performance of the time predictor on the QM9train and test datasets. Forward noise, corresponding to each true timestep, is added to the data, andthe time predictor estimates the true timestep, with accuracy measured accordingly. As shown in 3b,the predictor struggles in the white noise region, but achieves near-perfect accuracy after timestep400. Time correctionTCS works by first modifying Tweedies formula (Eq. 7) using the estimatedtimestep from time predictor to utilize the information of the proper timestep estimated by timepredictor during the denoising diffusion process. Specifically, for a sample xt at time t during the reverse diffusion process, we use the correctedtimestep tpred predicted by time predictor, instead of the current timestep t, to estimate the finalsample x0 as follows:",
  "From the better prediction of the final sample x0, we perturb it back to the next timestep t1 usingthe forward process using Eq. (1)": "Intuitively, TCS encourages the generated samples to adhere more closely to the proper data manifoldsat each denoising step. The iterative correction of the time through the generative process ensures thefinal sample lie on the correct data distribution. Consequently, for 3D molecular generation, TCShelps synthesizing molecules with higher molecular stability and validity, both of which are crucialfor generating realistic and useful molecules.",
  "Unified guidance with time correction": "Finally, we present TACS in Algorithm 1, which is a novel diffusion sampler for conditional gener-ation that integrates TCS with online guidance. For each timestep of the reverse diffusion process(Eq. 4), we apply online guidance (Eq. 8) to guide the process toward satisfying the target condition.Subsequently, TCS is applied to correct the deviation from the proper marginal distribution inducedby online guidance. This ensures the samples follow the correct marginal distribution during thegenerative process, as shown in . In , we experimentally validate that TACS is capableof generating valid and stable molecules satisfying the target condition. z (online guidance strength) 0.1 0.2 0.3 0.4 0.5 MAE CFG (Baseline)CFG + OGTACS (Ours)",
  ": Synthetic experiment on H+3 dataset. TACS is robust in generating samples that (a) matchthe desired condition and (b) stick to the original data distribution": "Time clippingDuring the generation, we empirically observe that the predicted timestep tpred oftendeviates significantly from the current time step t. Naively applying this information to TCS canbe problematic as the dramatic changes in timestep may skip crucial steps, resulting in unstable orinvalid molecules. To prevent large deviation of tpred, we set a time window so that tpred remains inthe time interval [t , t + ], where is a hyperparameter for the window size.",
  "Experiments": "In this section, we present comprehensive experiments to evaluate the performance of TACS anddemonstrate its effectiveness in generating 3D molecular structures with specific properties whilemaintaining stability and validity. In .1, we present synthetic experiment with H+3 molecules,where the ground state energies are computed using the variational quantum eigensolver (VQE). In.2, we assess our method using QM9, a standard dataset in quantum chemistry that includesmolecular properties and atom coordinates. We compare our approach against several state-of-the-artbaselines and provide a detailed analysis of the results.",
  "Synthetic experiment with H+3": "Quantum online guidanceWe present quantum online guidance as a modified version of onlineguidance where quantum machine learning algorithm for the property estimation of generatingmolecules. Specifically, we use VQE when calculating the ground state energy of generatedmolecules. Contrary to prior works , which train auxiliary classifiers to estimate each condition,this quantum computational chemistry-based approach can leverage exact calculation of the conditionfor a given estimate. This, in turn, is expected to generate molecules with accurate target ground stateenergies. A detailed explanation of this approach is provided in Appendix A.2. SetupWe first construct synthetic H+3 as follows. For each molecule, a hydrogen atom is placeduniformly at random within the 3-D unit sphere. We then augment our sample by rotating eachmolecule randomly to satisfy the equivariance property . Then the ground state energy of eachmolecule is measured with VQE in order to provide conditional labels. Finally, we train unconditionaldiffusion model and CFG-based conditional diffusion model with the constructed data. For evaluation,we measure the ground state energy and calculate MAE (Mean Absolute Error) with the target energy.Also, we measure the average L2 distance between position of each atom and its projection to theunit sphere. ResultsThe results in indicate that while online guidance correctly guides the samples tothe target condition, it can lead to the samples deviated from the original data distribution. In contrast,molecules sampled from TACS can satisfy both low MAE and low L2 distance. Further details andadditional discussions are provided in Appendix B.1. : Conditional generation with target quantum properties on QM9. TACS generate sampleswith lowest MAE while maintaining similar level of stability and validity as other baselines. TCS cangenerate molecules with high stability and validity. notation is marked for the values for the bestMAE within methods with molecule stability above 80%.",
  "Conditional generation for target quantum chemical properties": "DatasetWe evaluate our method on QM9 dataset , which contains about 134k molecules withup to 9 heavy atoms of (C, N, O, F), each labeled with 12 quantum chemical properties. Followingprevious works , we test on 6 types of quantum chemical properties and split the dataset into100k/18k/13k molecules for training, validation, and test. The training set is further divided into twodisjoint subsets of 50k molecules each: Da for property predictor training and Db for generativemodel training. Further details are provided in Appendix B.2. EvaluationTo evaluate how generate samples meet the desired target condition, a property pre-diction model p is trained on Da. Then, MAE for K number of samples is calculated as1KKi=1 |p(x(i)) c(i)|, where x(i) represents i-th generated molecule and c(i) is correspondingtarget quantum chemical properties. Molecular stability (MS) and validity (Valid) are used tomeasure how generated samples satisfy basic chemical properties. Details of the evaluation metricsare provided in Appendix B.2. BaselinesWe use Equivariant Diffusion Models (EDM) and Equivariant Energy Guided SDE(EEGSDE) for the baselines. Following , we put additional baselines including \"NaiveUpper-Bound\" (randomly shuffled property labels), \"#Atoms\" (properties predicted by atom count),and \"L-Bound\" (lower bound on MAE using a separate prediction model). Results shows the result of conditional generation of TACS and TCS with baselines. Wegenerate K=104 samples for the evaluation in each experiment and the average values and standarddeviations are reported across 5 runs. For all of the quantum chemical properties, TACS achieveslower MAE while maintaining comparable or higher molecular stability (MS) and validity comparedto other baselines. Notably, when comparing with the baseline methods that maintains the MSabove 80%, the MAE of TACS is significantly lower than the baselines. The result demonstrates theeffectiveness of TACS in balancing the objectives of generating molecules with desired propertiesand ensuring their structural validity. TCS achieves high validity and atom stability and molecular stability, surpassing the unconditionalgeneration performance of the baselines, but with a higher MAE compared to TACS. This highlightsthe importance of online guidance for precise property targeting. However, applying only onlineguidance yields samples with low MAE but suffers from reduced validity and stability, occasionallyfailing to generate valid molecules due to numerical instability. This shows the ability of TACS whichplaces the samples on the correct data manifold at each denoising step, even if they deviate from thetrue time-manifold due to the online guidance. Finally, we put the results of different methods with9 different runs for each method and plot the MAE and MS in a. The result clearly shows 0.100.150.200.250.300.350.40 MAE 0.2 0.4 0.6 0.8",
  "Target structure generation": "We conduct experiments on target structure generation with QM9 as in . For evaluation, wereport Tanimoto similarity score which captures similarity of molecular structures by molecularfingerprint and molecular stability to check whether basic properties of molecules are satisfied duringthe conditional generation process. We put additional details of the experiment in Appendix B.3.2. Results shows that TACS significantly outperforms baseline methods both in Tanimotosimilarity and molecular stability. Interestingly, performance of TACS is robust in the online guidancestrength z. This demonstrates TACSs ability to generalize on different tasks.",
  "Unconditional generation on Geom-Drug dataset": "To verify the scalability of time correction sampler, we use Geom-Drug as our dataset. Geom-Drugconsists of much larger and complicate molecules compared to the QM9. For fair comparisons, wefollow to split the dataset for training, validation and test set include 554k, 70k, and 70ksamples respectively. We test the performance of TCS on unconditional generation of 3D moleculeswhen using Geom-Drug. For evaluation, we use atom stability (AS) and validity of generated samples.The result in shows that samples generated by TCS satisfy the highest atom stability and thevalidity with high margin compared to the baselines. Details of the experiments are in Appendix B.3.1.",
  "Ablation Studies": "Time prediction functionWe investigate how the the design of time prediction function affects theperformance of TACS. Specifically, for line 6 in Alg. 1, rather than using argmax function to obtaincorrected timestep tpred, we choose to use expectation value by tpred = E[(x)]. shows thecomparison between two methods in six different types of quantum chemical properties. Expectationbased time prediction results in molecules with higher MAE and higher molecular stability.",
  "TCS (z = 0)49391.796.2OG17021.142.3z = 1.531180.390.7z = 1.023674.986.3z = 0.528882.791.3": "Online guidance strength zTo analyze the effectof online guidance strength z in Eq. (9), we measureMAE, molecular stability, and validity of samplesgenerated by TACS for different z values. shows the result with target condition on LUMO val-ues. One can observe while trade-off occurs for dif-ferent z values, performance of TACS is robust invarying z. Interestingly, our experiment shows thatthere exists an optimal value of z which generatessamples with the lowest MAE that is even compara-ble to applying online guidance without time correction (OG). As expected, using z = 0 (TCS)generates molecules with the highest MS and validity but with the highest MAE.",
  "Discussion": "Exploiting quantum chemistryIn .1, we demonstrate that quantum computing-basedguidance can serve as an accurate property predictor for the online guidance. Currently, in the absenceof a non-noisy quantum computer, scaling up this exact guidance to the QM9 dataset is close toimpossible due to compounding noise . However, future fault-tolerant quantum technology isexpected to provide quantum advantage in calculating chemical properties. This can be incorporatedinto our algorithm when using online guidance and therefore, further improvements of our TACS areon the horizon. Connection to other fieldsRecent works point out the exposure bias exists for diffusion mod-els , where there is a mismatch between forward and reverse process. Our experiments in 5.2indicate that Time Correction Sampler can provide a solution to the exposure bias problem duringthe sampling process in diffusion models. Moreover, since time predictor can gauge this mismatchduring inference, one might leverage this information for future works. Another direction is applying our algorithm to matching frameworks. Contrary todiffusion models, these matching models can start with arbitrary distributions and directly learnvector fields. We expect time predictor to be also effective with these types of algorithms. Investigatingthe connection between our algorithm and matching models will be an interesting future direction.",
  "Conclusion": "In this work, we introduce Time-Aware Conditional Synthesis (TACS), a novel approach for condi-tional 3D molecular generation using diffusion models. Our algorithm leverages a Time CorrectionSampler (TCS) in combination with online guidance to ensure that generated samples remain onthe correct data manifold during the reverse diffusion process. Our experimental results clearlydemonstrate the advantage of our algorithm, as it can generate molecules that are close to the targetconditions while also being stable and valid. This can be seen as a significant step towards preciseand reliable molecular generation. Despite multiple advantages, several open questions remain. For example, how can we more efficientlyuse the Time Correction Sampler, or more generally, whether this method improves performance inother domains such as in image generation. We expect that our work will open various opportunitiesacross different domains, such as quantum chemistry and diffusion models. LimitationAlthough we demonstrate the effectiveness of our algorithm on multiple datasets andtasks, we use a trained neural network to estimate chemical properties of each molecule for mainexperiments. Using exact computational chemistry-based methods might improve our algorithm. Societal impactsWe believe that our framework can assist in drug discovery, which requiressynthesizing stable and valid molecules that satisfy target conditions. However, our work couldunfortunately be misused to generate toxic or harmful substances. This work was supported by Institute for Information & communications Technology Planning &Evaluation (IITP) grant funded by the Korea government (MSIT) (No. RS-2019-II190075, ArtificialIntelligence Graduate School Program (KAIST); No. RS-2024-00457882, AI Research Hub Project),the National Research Foundation of Korea NRF grant funded by the Korean government (MSIT)(No. RS-2019-NR040050 Stochastic Analysis and Application Research Center (SAARC)), and LGElectronics.",
  "Hyungjin Chung, Jeongsol Kim, Michael T Mccann, Marc L Klasky, and Jong Chul Ye. Diffu-sion posterior sampling for general noisy inverse problems. arXiv preprint arXiv:2209.14687,2022": "Jacob M. Clary, Eric B. Jones, Derek Vigil-Fowler, Christopher Chang, and Peter Graf. Explor-ing the scaling limitations of the variational quantum eigensolver with the bond dissociation ofhydride diatomic molecules. International Journal of Quantum Chemistry, 123(11):e27097,2023. doi: Gabriele Corso, Hannes Strk, Bowen Jing, Regina Barzilay, and Tommi S. Jaakkola. Diff-dock: Diffusion steps, twists, and turns for molecular docking. In The Eleventh InternationalConference on Learning Representations, 2023.",
  "Frank Jensen. Introduction to computational chemistry. John wiley & sons, 2017": "Bowen Jing, Gabriele Corso, Jeffrey Chang, Regina Barzilay, and Tommi Jaakkola. Torsionaldiffusion for molecular conformer generation. Advances in Neural Information ProcessingSystems, 35:2424024253, 2022. Jaehyeong Jo, Seul Lee, and Sung Ju Hwang. Score-based generative modeling of graphsvia the system of stochastic differential equations. In International Conference on MachineLearning, pages 1036210383. PMLR, 2022.",
  "Mingxiao Li, Tingyu Qu, Ruicong Yao, Wei Sun, and Marie-Francine Moens. Alleviatingexposure bias in diffusion models through sampling with shifted time steps. arXiv preprintarXiv:2305.15583, 2023": "Sijia Liu, Pin-Yu Chen, Bhavya Kailkhura, Gaoyuan Zhang, Alfred O Hero III, and Pramod KVarshney. A primer on zeroth-order optimization in signal processing and machine learning:Principals, recent advances, and applications. IEEE Signal Processing Magazine, 37(5):4354,2020. Yixin Liu, Kai Zhang, Yuan Li, Zhiling Yan, Chujie Gao, Ruoxi Chen, Zhengqing Yuan, YueHuang, Hanchi Sun, Jianfeng Gao, et al. Sora: A review on background, technology, limitations,and opportunities of large vision models. arXiv preprint arXiv:2402.17177, 2024.",
  "Mang Ning, Mingxiao Li, Jianlin Su, Albert Ali Salah, and Itir Onal Ertugrul. Elucidating theexposure bias in diffusion models. arXiv preprint arXiv:2308.15321, 2023": "Alberto Peruzzo, Jarrod McClean, Peter Shadbolt, Man-Hong Yung, Xiao-Qi Zhou, Peter JLove, Aln Aspuru-Guzik, and Jeremy L Obrien. A variational eigenvalue solver on a photonicquantum processor. Nature communications, 5(1):4213, 2014. Adam Polyak, Amit Zohar, Andrew Brown, Andros Tjandra, Animesh Sinha, Ann Lee, ApoorvVyas, Bowen Shi, Chih-Yao Ma, Ching-Yao Chuang, et al. Movie gen: A cast of mediafoundation models. arXiv preprint arXiv:2410.13720, 2024.",
  "Gregory Sliwoski, Sandeepkumar Kothiwale, Jens Meiler, and Edward W Lowe. Computationalmethods in drug discovery. Pharmacological reviews, 66(1):334395, 2014": "Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsuper-vised learning using nonequilibrium thermodynamics. In International conference on machinelearning, pages 22562265. PMLR, 2015. Jiaming Song, Qinsheng Zhang, Hongxu Yin, Morteza Mardani, Ming-Yu Liu, Jan Kautz,Yongxin Chen, and Arash Vahdat. Loss-guided diffusion models for plug-and-play controllablegeneration. In International Conference on Machine Learning, pages 3248332498. PMLR,2023. Yang Song, Jascha Sohl-Dickstein, Diederik P Kingma, Abhishek Kumar, Stefano Ermon, andBen Poole. Score-based generative modeling through stochastic differential equations. arXivpreprint arXiv:2011.13456, 2020. Jules Tilly, Hongxiang Chen, Shuxiang Cao, Dario Picozzi, Kanav Setia, Ying Li, Edward Grant,Leonard Wossnig, Ivan Rungger, George H Booth, et al. The variational quantum eigensolver:a review of methods and best practices. Physics Reports, 986:1128, 2022. Clement Vignac, Igor Krawczuk, Antoine Siraudin, Bohan Wang, Volkan Cevher, and Pas-cal Frossard. Digress: Discrete denoising diffusion for graph generation. In The EleventhInternational Conference on Learning Representations, 2023. Joseph L Watson, David Juergens, Nathaniel R Bennett, Brian L Trippe, Jason Yim, Helen EEisenach, Woody Ahern, Andrew J Borst, Robert J Ragotte, Lukas F Milles, et al. De novodesign of protein structure and function with rfdiffusion. Nature, 620(7976):10891100, 2023. Lemeng Wu, Chengyue Gong, Xingchao Liu, Mao Ye, and Qiang Liu. Diffusion-based moleculegeneration with informative prior bridges. Advances in Neural Information Processing Systems,35:3653336545, 2022.",
  "For conditional diffusion model, we train separate time predictor for each of the target property byconcatenating conditional information c to the input xt": "The rationale behind using cross-entropy loss rather than simple regression loss is because p(t|x)can not be estimated from the point estimate if there exists intersection between support of marginaldistributions pt and ps which is from different timesteps s and t, respectively. In other words, thisimplies there exists x Rd such that pt(x)>0 and ps(x)>0 simultaneously holds.",
  "A.2Quantum online guidance": "Quantum Machine LearningQuantum computing is expected to become a powerful computa-tional tool in the future . While at its early stage, various of quantum machine learning algorithmsare proved to have advantage over classical methods . In computational chemistry, these advantagesare indeed expected to have huge potential since classically intractable computations like findingground state for big molecules are expected to become feasible with exponential speed-ups ofquantum machines. Variational Quantum EigensolverVariational Quantum Eigensolver (VQE) is a near termquantum machine learning algorithm which leverages variational principle to obtain the lowest energyof a molecule with given Hamiltonian. For the given Hamiltonian H, trial wave function |()which is parameterized by a quantum circuit () is prepared to obtain ground state energy E0 withfollowing inequality:",
  "()|() .(14)": "When quantum circuit is expressive enough, one can see that |(), where is a minimizerof Eq. (14), gives the ground state of the given system. For more comprehensive review with itspotential advantages, one may refer to . Quantum online guidanceQuantum online guidance is a type of online guidance algorithm wherewe use VQE-based algorithm to calculate exact values of quantum chemical properties instead ofusing classifier which is usually a neural network. In each denoising step of diffusion model, we first apply Tweedies formula (Eq. 7) to estimateclean molecule x0. Then we use VQE to calculate ground state energy of the estimated molecule byiteratively updating for E(x0, ) = ()|H(x0)|(). After obtaining (x0) which minimizesE(x0, ), we obtain target property value E0(x0). To obtain gradient in Eq. (8), we use zeroth-ordermethod with respect to the position of atoms to obtain gradient as follows:",
  "A.3Properties of the Zero-Center-of-Mass Subspace": "Let X = {x RM3 :1MMi=1 xi = 0} be the subspace of RM3 where the center of mass iszero. Here we discuss some properties of X that are used in the TACS framework. First, note that Xis a linear subspace of RM3 with dimension (M 1) 3. There exists an isometric isomorphism : R(M1)3 X, i.e., a linear bijective map that preserves distances: (x) = x for allx R(M1)3. Intuitively, allows us to map between the lower-dimensional space R(M1)3 andthe constrained subspace X without distortion. If x X is a random variable with probability densityq(x), then the corresponding density of x = 1(x) in R(M1)3 is given by q(x) = q((x)).Similarly, a conditional density q(x|y) on X can be written as q(x|y) = q((x)|(y)). In practice,computations involving probability densities on X can be performed in R(M1)3 and mapped backto X using as needed. This allows TACS to efficiently learn and sample from distributions onmolecular geometries while preserving translation invariance. For further mathematical details onsubspaces defined by center-of-mass constraints, we refer the reader to and .",
  "A.4Classfier-free guidance": "For conditional generation, we need conditional score x log pt(xt|c) where c is our target condition.Classifier-free guidance (CFG) replaces conditional score with combination of unconditionalscore and conditional score. Here, diffusion model is trained with combination of unlabeled sample(x0, ) and labeled samples (x0, c). The reverse diffusion process (Eq. 2) in CFG changes as follows:",
  "B.2Experiments on QM9": "Dataset detailsThe QM9 dataset is a widely-used benchmark in computational chemistry andmachine learning. It contains 134k stable small organic molecules with up to 9 heavy atoms (C, O, N,F) and up to 29 atoms including hydrogen. This size constraint allows the molecules to be exhaustivelyenumerated and have their quantum properties calculated accurately using density functional theory(DFT). Each molecule in QM9 is specified by its Cartesian coordinates (in Angstroms) of all atomsat equilibrium geometry, along with 12 associated properties calculated from quantum mechanicalsimulations.",
  "Molecule Stability (MS)Percentage of generated molecules where all constituent atomsare stable": "BaselinesWe compare our method against Equivariant Diffusion Models (EDM) which learna rotationally equivariant denoising process for property-conditioned generation and EquivariantEnergy Guided SDE (EEGSDE) , which guides generation with a learned time-dependent energyfunction. Additional baselinesTwo baselines are employed following the approach outlined by . Tomeasure \"Naive (U-Bound)\", we disrupt any inherent correlation between molecules and propertiesby shuffling the property labels in Db and evaluating c on the modified dataset. \"L-Bound\" is a lowerbound estimation of the predictive capability. This value is obtained by assessing the loss of c on Db,providing a reference point for the minimum achievable performance. If a proposed model, denoted as, surpasses the performance of Naive (U-Bound), it indicates successful incorporation of conditionalproperty information into generated molecules. Similarly, outperforming the L-Bound demonstratesthe models capacity to incorporate structural features beyond atom count and capture the intricaciesof molecular properties. These baselines establish upper and lower bounds for evaluating meanabsolute error (MAE) metrics in conditional generation tasks. Diffusion model trainingFor a fair comparison with EDM and EEGSDE , we adopt theirtraining settings, using model checkpoints provided in the EEGSDE code: The diffusion model is trained for 2000 epochs with a batch size of 64,learning rate of 0.0001, Adam optimizer, and an exponential moving average (EMA) with a decayrate of 0.9999. During evaluation, we generate molecules by first sampling the number of atomsM p(M) and the property value c p(c|M). Here p(M) is the distribution of molecule sizes inthe training data, and p(c|M) is the conditional distribution of the property given the molecule size.Then we generate a molecule conditioned on M and c using the learned reverse process. Hyperparameters for TACSWe analyze different hyperparameter settings for all six quan-tum chemical properties (, , HOMO, LUMO, , Cv) for the result in the .Wevary the TCS starting timestep tTCS {200, 400, 600, 800}, online guidance starting timesteptOG {200, 400, 600, 800}, online guidance ending timestep tOG {10, 20, 30}, gradient clippingthreshold {, 1, 0.1} for Eq. (8), and guidance strength z {1.5, 1.0, 0.5} in Eq. (9). Exceptfor LUMO (optimal with z = 0.5, tOG = 0), we find tTCS = 600, tOG = 600, tOG = 20, z = 1, and = 1 consistently achieve low MAE with molecular stability above 80%.",
  "B.3.2Experiments on Target Structure Generation": "Training DetailsFor molecular fingerprint-based structure generation, we follow the evaluationprotocol in . The diffusion model architecture remains consistent with our QM9 experiments,using EGNN with 256 hidden features and 4 layers, trained for 10 epochs. Performance MetricsFor evaluation, we use Tanimoto similarity score which measures thestructural similarity between generated molecules and target structures through molecular fingerprintcomparison. Specifically, let Sg and St be the sets of bits that are set to 1 in the fingerprints ofgenerated and target molecules respectively. The Tanimoto similarity is defined as |Sg St|/|Sg St|,where | | denotes the number of elements in a set. We evaluate the similarity on 10,000 generatedsamples. BaselinesFor both experiments, we directly compare with baseline results reported in . ForGeom-Drug unconditional generation, these include ENF , G-Schnet , GDM variants ,EDM , and EDM-Bridge . For target structure generation, we compare against G-SchNet ,GDM, GDM-AUG , Conditional EDM , and EEGSDE with various guidance scales.",
  "C.1When to apply TCS and OG": "We ablate when to start the time-corrected sampling (TCS) and online guidance (OG) during thereverse diffusion process. The notation tTCS and tOG indicates we apply TCS after timestep tTCS andOG after the timestep tOG in the reverse diffusion process. We report results for property LUMO in. The result shows that applying TACS from early steps (t = 600, 800) generates samplesbest satisfying the target condition but with less molecular stability and validity. In contrast, when westart applying TACS after later step t = 400, generated samples have higher MAE, MS, and Validity.Interstingly, if we apply TACS only in the later part (after t = 200), MAE, MS, and validity decreasesagain. We leave further investigation on this phenomenon and explanation for future works.",
  "C.2Number of MC samples": "Additional experiments are conducted on the effect of number of MC samples m in Eq. (8). LGD estimates x0 assuming q(x0|xt) is a normal distribution with mean x0 (Eq. 7) and variance 2 whichis a hyperparameter. First, we investigate the effect of varying the variance in MC sampling. shows that theresult is robust in the small values of but when is larger than some point, quality of generatedsamples decreases (higher MAE and lower MS). Next, we test how the performance of TACS is affected by number of MC samples m. shows that performance of TACS is robust in number of MC samples but we did not observe anyperformance increase with the number of MC samples as in .",
  "C.3Results on Novelty, Uniqueness": "We report additional metrics on the novelty, uniqueness of generated molecules in followingprevious literature . Novelty measures the percentage of generated molecules not seenin the training set. Uniqueness measures the proportion of non-isomorphic graphs within validmolecules. Higher values indicate better quality for both metrics. The result shows that TACSgenerates molecules with decreased novelty. This shows that TACS is effective in making generatedmolecules that stick to the original data distribution while satisfying to meet the target condition.",
  "h(RX + v1) = g(f(RX + v1))= g(R f(X))(E(3) equivariance of f)= g(f(X))(Permutation invariance of g)= h(X).(20)": "Theorem 1 (Time Predictor Equivariance). Let G = (V, E) be a graph representing a molecule,where V = {1, . . . , N} is the set of nodes (atoms) and E V V is the set of edges (bonds). LetXt RN3 denote the atomic coordinates and c Rd be a condition vector at diffusion timestep t.Consider a time predictor p(t|Xt, c) = softmax(f(Xt, c)) parameterized by a composition of anE(3)-equivariant graph neural network EGNN : RN3 RNdh Rd RNd, a permutation-invariant readout function : RNd Rd, and a multilayer perceptron : Rd RT , i.e.,",
  "While with different motivations and methods, here, we list some of the relevant works and comparetheir algorithms with ours": "Comparison with DMCMCDMCMC trains a classifier to predict noise levels of the givendata during the reverse diffusion process which is similar to our time predictor. However, they use theclassifier to estimate the current noise state when conducting MCMC on the product space of the dataand the noise. In contrast, our time predictor directly predicts timesteps for correction in diffusionsampling itself. Moreover, while the purpose of noise prediction in DMCMC is for fast sampling, ourwork use time predictor to accurately produce samples from the desired data distribution. Comparison with TS-DPMTime-Shift Sampler targets to reduce exposure bias targets similarapproach of fixing timesteps during the inference as our time correction method. However, while ourmethod directly selects timesteps based on the time predictor, which has demonstrated robustnessin our experiments selects timesteps by calculating variance of image pixels at each step andmatching the noise level from the predefined noise schedule which is often inaccurate and expensive.Moreover corrected timestep in is used directly for the start of the next step, while our approachmaintains the predefined timestep after accurately estimate clean sample by corrected time step (line9 in Algorithm 1). By taking every single diffusion step while carefully using predicted time, TACS /TCS can generate samples closer to the target distribution. To further validate our approach, we provide additional experimental results comparing TS-DDPM and TACS on the QM9 dataset with step size 10. The result in shows consistentimprovements across various quantum properties which shows the robustness of our approach."
}