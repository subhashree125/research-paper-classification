{
  "Abstract": "This work presents an analysis of the hidden representations of Variational Autoen-coders (VAEs) using the Intrinsic Dimension (ID) and the Information Imbalance(II). We show that VAEs undergo a transition in behaviour once the bottleneck sizeis larger than the ID of the data, manifesting in a double hunchback ID profileand a qualitative shift in information processing as captured by the II. Our resultsalso highlight two distinct training phases for architectures with sufficiently largebottleneck sizes, consisting of a rapid fit and a slower generalisation, as assessedby a differentiated behaviour of ID, II, and KL loss. These insights demonstratethat II and ID could be valuable tools for aiding architecture search, for diagnosingunderfitting in VAEs, and, more broadly, they contribute to advancing a unifiedunderstanding of deep generative models through geometric analysis.",
  "Introduction": "Variational Autoencoders (VAEs) are a central paradigm in the field of representation learning due to the breadth of practical applications and depth of technological developments they have inspired. Their ability to shape useful representations for a wide range of taskswithout supervision has made it crucial to interpret their structure and geometry. A first line of workfocused on interpreting the latent space and improving the performance of the VAEs by disentanglingthe latent space features, making each relevant factor of variation of the data dependent on a singlelatent unit . Since nearest neighbour relations can be used to define meaningful similarities ,a second line of work described the right notion of distance between datapoints in the latentspace and used it to regularise training , to improve the clustering and interpolation ofthe data, and to devise ways to probe and modify their semantics . In this study, we take a different perspective: we describe how two geometrical properties of thehidden representations of the VAE, their Intrinsic Dimension (ID), and their Information Imbalance(II) change through all the hidden representations. The analysis of these quantities has provenuseful in understanding high-level stages of information processing in convolutional networks and transformers . For instance, in transformers for image generation layers rich in abstractinformation about data lie between two intrinsic dimension peaks and, in language models,the II can be used to identify blocks that encode semantic information . This work shows thatthese findings also hold in VAEs despite the very different architecture and training objective. Moreprecisely, we find that (1) in VAEs, the ID profiles have two peaks in the middle of the encoder anddecoder and a local minimum in correspondence to the bottleneck, and that (2) the II identifies a firstphase of information compression in the encoder and a second one of information expansion in thedecoder, irrespective of phases of expansion and compression of the ID. We also show that (3) thesegeometric features arise only if the bottleneck is larger and the ID of the data and develop the finalpart of training.",
  "Methods": "Architectures and training details. We build encoder networks consisting of four convolutionallayers with 64, 128, 256, and 256 channels and analyse the geometry of their hidden representationsas the size K of the bottleneck increases from 2 to 128. As we train the networks on 32x32 pixelcoloured images, the encoders have extrinsic dimensions of 3072 (in the input), 16384, 8192, 4096,1056, and K (in the bottleneck). The decoder reconstructs the original input by mirroring the encoderarchitecture and adding a final sigmoid activation to generate the output image. We train eacharchitecture for 200 epochs on the ELBO loss using an Adam optimiser with a weight decay of 104.We train the VAEs on the CIFAR-10 and MNIST datasets. In Sec. 3, we report the ID andII curves on 5,000 images selected from the CIFAR test set and show the results on MNIST in Sec. Cof the Appendix. Intrinsic Dimension. The ID of a dataset can be formally defined as the minimum number ofvariables needed to describe the data with no loss of information . In this work we use the 2NNestimator , which computes ID as N/ N log i, where i is the ratio of the Euclidean distancesbetween a point i and its second and first nearest neighbours, and N is the number of points in thedataset. Information Imbalance. The II is a recent statistical measure grounded in information theoreticconcepts that quantifies the asymmetric predictive power that one feature space carries on another .Specifically, the II from space A to space B is written as (A B) and is a number between zeroand one. If (A B) = 1, then the II is at its maximum, meaning that A carries no information onB. On the contrary, if (A B) = 0, then the II is at its minimum, and A carries full informationon B. Importantly, the II is not a measure of mutual information between spaces. In fact, the II isnot symmetric as one space can generally be more predictive of another (for instance, if the data aredistributed according to the non-invertible function y = sin(x), x carries more information abouty than vice-versa). (A B) is related to exponential of the conditional entropy H(cB | cA) ofthe copula variables cA and cB and, it can be robustly estimated by checking how nearestneighbour relationships in space A are preserved in space B. In practice, if rAij (rBij) denotes thedistance rank of point j with respect to i in space A (B) the information imbalance can be computedas",
  "Results and discussion": "We begin our discussion in .1 by presenting ID and II profiles of trained VAEs and continuein .2 by studying how they appear during training. We find that ID and II effectively identifya sharp transition in the VAEs information processing when the bottleneck size exceeds the inputsID and two distinct phases in the learning process.",
  "Trained Architectures": "The ID identifies a transition through the emergence of a double hunchback profile.The leftpanel of shows how the ID changes from input to output for different bottleneck sizes. Wefirst note that, independently of the architecture, the ID in the encoding part of the network increasesfrom around 20 at the input (layer 0) to approximately 80 before decreasing to roughly match thesize of the bottleneck layer (layer 5), creating a distinctive hunchback shape. A similar patternof expansion and compression is observed in the decoding network, leading to the appearance of adouble hunchback curve in the ID. However, the second hunchback curve appears exclusively forVAE architectures with sufficiently large bottleneck sizes, roughly from 32 onwards. Interestingly,the transition occurs when the bottleneck size matches the ID of the input data, which can be readfrom the figure (at layer 0) to be approximately 30. The II identifies a transition through distinct information processing modes.A similar transitionafter a specific bottleneck size can be observed through the analysis of II profiles. The central panel : ID and II of trained architectures. Left) IDs for different bottleneck sizes K. Centre)IIs (l l0) from layer (l) to the input (l0) for different bottleneck sizes K. Right) Relative IIdifference between consecutive layers (l and l + 1) as a function of layer index l. In all panels, thequantities are graphed as a function of the layer index (l). shows the II from every layer l of the networks to the input layer l0. To start with, we verifythat (l0 l0) is always zero since the input layer is trivially fully informative on itself. At theother extreme, we see that (l10 l0) starts very high for bottleneck size K = 2 and graduallydecreases, indicating that the reconstructed images carry limited information about the original imagesbut improve progressively. For reference, the II from the output layer to the input is much higherand around one for any untrained architecture, as shown in Fig.A2 of the Appendix, indicating theabsence of any useful information in the output before training. Notably, the II (l10 l0) reachesa minimum for K = 16 and then increases for larger sizes (see also the left axis of Fig. A1 of theAppendix), marking a discontinuous change in the nature of the generated images. The transition isalso reflected in behaviour of (l5 l0), the II from the bottleneck (l5) to the input (l0). Prior to thetransition (K = 2 to K = 16), the bottleneck carries increasingly more information on the input withincreasing bottleneck sizes, as indicated by II values decreasing roughly from 0.4 to 0.05. In contrast,after the transition, the bottleneck progressively loses information on the input, as indicated by the II,gradually increasing to over 0.4. These results indicate a qualitative shift in information processingbefore and after the transition. Before the transition, VAEs predominantly preserve low-level featuresof increasing detail all the way to the bottleneck, which are, in turn, passed to the output with minimalinformation processing. After a transition, for sufficiently large bottleneck sizes, the features passedto the bottleneck are no longer directly informative on the input, becoming more abstract and usefulfor the generation process in the decoder. The right panel of provides further support for this hypothesis. It depicts the relative II differencebetween adjacent layers, defined as 2(l,l+1 l+1,l)/(l,l+1 + l+1,l) where l,l = (l l).The quantity is plotted as a function of the layer index and measures the relative information contentof consecutive layers. A value above zero indicates that the l + 1 layer is more informative thanthe l layer, signifying an expansion of information content. Conversely, a negative value indicates acompression. The graph clearly illustrates that while both K = 4 and K = 64 undergo a compressionin the encoder, only the K = 64 architecture also undergoes an expansion in the decoder as the smallbottleneck size of the K = 4 architecture inhibits such expansion. Lastly, a transition is also visibleby comparing the relative information content of neighbouring architectures (e.g., K = 2 vs K = 4or K = 64 vs K = 128) for fixed layers, as done in Fig. A1 of the Appendix.",
  "Training dynamics": "The KL loss identifies two phases of training.The sharp transition described in the previoussection is also reflected in qualitatively different training dynamics before and after a specificbottleneck size. The left and centre panels of Fig 2 display the the FID loss and the KL loss,respectively. While the FID loss decreases monotonically as training progresses for all architectures,the KL loss exhibits a differentiated behaviour. Specifically, only for architectures with sufficientlylarge bottleneck dimension the KL loss goes through two distinct phases. In the first phase, roughlyuntil epoch 10, the KL loss increases, while it decreases in the second phase until the end of training. The II identifies two phases of training.A similar dynamic can be observed in the right panelof , which shows (l10 l0), i.e., the II from the output layer to the input, as a functionof the training epoch. The figure illustrates that, after a minimally large bottleneck size, the II : Losses and II during training. Left) FID loss on test set. Centre) KL Loss on test set.Right) II from last layer (l10) to the input (l0). In all panels, the quantities are graphed as a functionof training epoch and for architectures of increasing bottleneck sizes (denoted by different colours). dynamic exhibits two phases that closely parallel the two phases of the KL loss during training, withthe II decreasing sharply up to epoch 10 and then increasing gradually for the rest of the training.",
  ": ID during training. IDas a function of layer index for dif-ferent epoch numbers for K = 64": "We can interpret the first phase as a rapid fitting phase to thedata and the second phase as a more gradual generalisationphase where the bottleneck becomes more Gaussian (leading toa decrease in KL loss), and the output discards the details of theinput data that are not useful for the generative task (leading toan increase of (l10 l0)). The double hunchback ID profile emerges in the secondphase of training.Finally, shows the evolution of theID across layers during training for the K = 64 architecture.The graph illustrates that the evolution of the ID curve alsomirrors the two phases of training, as the characteristic doublehunchback shape emerges only after epoch ten and during thesecond training phase.",
  "Conclusions": "In this study, we explored the use of geometric tools the ID and the II to analyse the internalrepresentations and training dynamics of Variational Autoencoders. We identify a sharp transition inthe behaviour of VAEs as the size of the bottleneck layer increases above the ID of the data, leading tothe emergence a double hunchback curve in the ID profile and to a qualitatively different informationprocessing mechanism as measured by the II. Furthermore, we find that architectures with sufficientlylarge bottleneck undergo two distinct phases in the training dynamic. We envisage two practical implications of our findings. First, they can inform architecturesearch since a well-performing VAE network can be expected (and measured) to exhibit a doublehunchback ID curve and an II information processing involving a compression and a later expansion.Second, monitoring ID and II during training can provide valuable insights into the learning process,potentially enabling diagnostic tools for avoiding underfitting and improving training. More generally, the geometric analysis we propose can be useful for robustly and nonparametricallycompare architectures, when dealing with high-dimensional spaces. For example, the double hunch-back shape we observe in VAEs closely mirrors the findings of in their analysis of Transformerstrained on ImageNet, suggesting this shape may be a common feature of a large class of deep genera-tive networks. Furthermore, the two training phases we identify resemble the two phases proposed inthe Information Bottleneck (IB) theory of deep learning . However, while previous studies onthe IB theory and its application to neural networks have faced challenges due to the difficultyof accurately estimating mutual information , our approach circumvents these issues byemploying distance-based geometric tools that allow reliable studies of the information processingdynamics even in high-dimensional hidden representations.",
  "Thomas N. Kipf and Max Welling. Variational graph auto-encoders, 2016": "Herke van Hoof, Nutan Chen, Maximilian Karl, Patrick van der Smagt, and Jan Peters. Stablereinforcement learning with autoencoders for tactile and visual data.In 2016 IEEE/RSJInternational Conference on Intelligent Robots and Systems (IROS), pages 39283934, 2016. Rafael Gmez-Bombarelli, Jennifer N. Wei, David Duvenaud, Jos Miguel Hernndez-Lobato,Benjamn Snchez-Lengeling, Dennis Sheberla, Jorge Aguilera-Iparraguirre, Timothy D. Hirzel,Ryan P. Adams, and Aln Aspuru-Guzik. Automatic chemical design using a data-drivencontinuous representation of molecules. ACS Central Science, 4(2):268276, 2018. PMID:29532027. Aaron van den Oord, Oriol Vinyals, and koray kavukcuoglu. Neural discrete representationlearning. In I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, andR. Garnett, editors, Advances in Neural Information Processing Systems, volume 30. CurranAssociates, Inc., 2017. Arash Vahdat and Jan Kautz.Nvae: A deep hierarchical variational autoencoder.InH. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin, editors, Advances in NeuralInformation Processing Systems, volume 33, pages 1966719679. Curran Associates, Inc.,2020.",
  "Georgios Arvanitidis, Lars Kai Hansen, and Sren Hauberg. Latent space oddity: on thecurvature of deep generative models. In International Conference on Learning Representations,2018": "Nutan Chen, Alexej Klushyn, Richard Kurle, Xueyan Jiang, Justin Bayer, and Patrick Smagt.Metrics for deep generative models. In Amos Storkey and Fernando Perez-Cruz, editors,Proceedings of the Twenty-First International Conference on Artificial Intelligence and Statistics,volume 84 of Proceedings of Machine Learning Research, pages 15401550. PMLR, 0911Apr 2018. Nutan Chen, Alexej Klushyn, Francesco Ferroni, Justin Bayer, and Patrick Van Der Smagt.Learning flat latent manifolds with VAEs. In Hal Daum III and Aarti Singh, editors, Proceed-ings of the 37th International Conference on Machine Learning, volume 119 of Proceedings ofMachine Learning Research, pages 15871596. PMLR, 1318 Jul 2020.",
  "Alessio Ansuini, Alessandro Laio, Jakob H Macke, and Davide Zoccolan. Intrinsic dimensionof data representations in deep neural networks. Advances in Neural Information ProcessingSystems, 32, 2019": "Tolga Birdal, Aaron Lou, Leonidas J Guibas, and Umut Simsekli. Intrinsic dimension, persistenthomology and generalization in neural networks. Advances in Neural Information ProcessingSystems, 34:67766789, 2021. Eduard Tulchinskii, Kristian Kuznetsov, Laida Kushnareva, Daniil Cherniavskii, SergeyNikolenko, Evgeny Burnaev, Serguei Barannikov, and Irina Piontkovskaya. Intrinsic dimensionestimation for robust detection of ai-generated texts. In A. Oh, T. Naumann, A. Globerson,K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neural Information ProcessingSystems, volume 36, pages 3925739276. Curran Associates, Inc., 2023. Lucrezia Valeriani, Diego Doimo, Francesca Cuturello, Alessandro Laio, Alessio Ansuini,and Alberto Cazzaniga. The geometry of hidden representations of large transformer models.Advances in Neural Information Processing Systems, 36, 2024. Emily Cheng, Diego Doimo, Corentin Kervadec, Iuri Macocco, Jade Yu, Alessandro Laio, andMarco Baroni. Emergence of a high-dimensional abstraction phase in language transformers.arXiv preprint arXiv:2405.15471, 2024.",
  "Fabrizio Durante, Carlo Sempi, et al. Principles of copula theory, volume 474. CRC press BocaRaton, FL, 2016": "Aldo Glielmo, Iuri Macocco, Diego Doimo, Matteo Carli, Claudio Zeni, Romina Wild, MariadErrico, Alex Rodriguez, and Alessandro Laio. Dadapy: Distance-based analysis of data-manifolds in python. Patterns, 3(10), 2022. Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.Gans trained by a two time-scale update rule converge to a local nash equilibrium. Advances inneural information processing systems, 30, 2017.",
  "ANetwork architecture and training details": "We build encoder networks consisting of four convolutional layers, each with 44 kernels, a stride of2, a padding of 1, and number of channels of 64, 128, 256 and 256 respectively. Each convolutionallayer is followed by batch normalisation and Leaky ReLU activation. After the final convolutionallayer, the output is flattened into a vector, which is passed through fully a connected layer to computethe mean and log-variance of the latent space of various dimension K depending on the architecturefrom 2 to 128. As we train the networks on 32-pixel colour images, the encoders have extrinsicdimensions of 3072 (in the input), 16384, 8192, 4096, 1056 and K (in the bottleneck). The decoderreconstructs the original input by mirroring the encoder architecture, and adding a final sigmoidactivation to generate the output image. We build our models using PyTorch and train eacharchitecture for 200 epochs on the ELBO loss using an Adam optimiser with a weight decay of 104.We used the CIFAR-10 dataset for the experiments presented here, consisting of 60,000, across10 classes representing various objects (e.g., airplanes, cars, and animals). The dataset is divided intoa training set of 50,000 and a test set 10,000. For training, we used 0.8 of the training set, with theremaining 0.2 reserved for validation. We performed training on a single T4 GPU with 16MB ofRAM using batch size of 256 and one run with 200 training epochs took around 40 minutes. For thecomputation of ID and II curves we selected 5,000 images from the test set. In the Appendix, wereport the results obtained by training the same architectures on the alternative MNIST dataset .",
  "BCIFAR10 extra results": "Figure A1: II and FID, and IIs between different architectures. Left) II from the output to theinput (left axis) and FID test loss (right axis) for increasing bottleneck sizes (latent dimensions). Thepanel clearly shows a transition in the nature of the output layer of VAEs as the bottleneck surpassesa critical value. This transition is not paralleled by an increase in the test error as measured by theFID loss. Centre and Right) The II curves for layer indices set to l5 (bottleneck) and l10 (output)and measuring the imbalances across different architecturs (K 2K) and (2K K) whereK is the size of the bottleneck. The two panels show that a transition is present in the nature of thebottleneck layer (layer 5) and output layer (layer 10) when the bottleneck size of VAEs surpasses avalue of K = 16. Figure A2: II curves during training. II from every layer (l) to the input (l0) as a function of thelayer index for increasing epochs during training and for architectures with different bottleneck sizes(2, 8 and 128, here referred to as Dim.). The figures show that before training (dashed black curve)the II is zero up to the bottleneck and one afterwards, indicating full information in the encoder andno information in the decoder. The figures also illustrate the difference in II before and after thetransition at K = 16 .",
  "CMNIST Results": "We observe similar tendencies on MNIST, although with some key differences due to the simplernature of the dataset. The characteristic (double) hunchback shape remains, but the overall ID and IIrange is smaller comparatively, reflecting the reduced feature complexity in MNIST compared toCIFAR-10. In particular, the ID in the encoder starts from around 10 at the input layer and peaksat around 25, before compressing to match the size of the bottleneck layer. And during expansionin the decoder the ID goes up to 60 for the highest bottleneck size, largely exceeding the ID peakobserved in the encoder. Another important difference lies in the fact that the critical bottleneck sizefor the transition is K = 8 and not K = 16. As the ID of the input image is smaller for MNIST andaround 10-12, this finding supports the hypothesis that the transition emerges after the bottleneck hasmatched the ID of the input data. Figure A3: ID and II of trained architectures. Left) IDs for different bottleneck sizes (differentcolours). Centre) IIs (l l0) from layer (l) to the input (l0) for different bottleneck sizes (differentcolours). Right) Relative II difference between consecutive layers (l and l + 1) as a function of layerindex l for bottleneck sizes of 4 and 32. In all panels, the quantities are graphed as a function of thelayer index (l). Figure A4: II and ID during training. Left) II from the last layer (l10) to the input (l0) as a functionof the epoch number and for different bottleneck sizes (different colours). Right) ID as a function oflayer index for different epoch numbers (different colours) and for latent dimensions 4, 32 and 64respectively."
}