{
  "Abstract": "Out-of-distribution (OOD) detection is crucial for deploying reliable machinelearning models in open-world applications. Recent advances in CLIP-based OODdetection have shown promising results via regularizing prompt tuning with OODfeatures extracted from ID data. However, the irrelevant context mined from IDdata can be spurious due to the inaccurate foreground-background decomposition,thus limiting the OOD detection performance. In this work, we propose a novelframework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem foreffective OOD detection with only the given few-shot ID data. Specifically, SCTintroduces modulating factors respectively on the two components of the originallearning objective. It adaptively directs the optimization process between the twotasks during training on data with different prediction uncertainty to calibrate theinfluence of OOD regularization, which is compatible with many prompt tuningbased OOD detection methods. Extensive experiments and analyses have beenconducted to characterize and demonstrate the effectiveness of the proposed SCT.The code is publicly available at:",
  "Introduction": "The deep neural networks (DNNs) are demonstrated to be overconfident on the OOD data out ofthe pre-defined label space [Hendrycks and Gimpel, 2017], which can induce severe problems inthose safety-critical applications like autonomous driving or medical intelligence. Various explo-rations [Liang et al., 2018, Djurisic et al., 2022, Du et al., 2022, Zhu et al., 2023b] thus have beenconducted in designing scoring functions or fine-tuning methods with auxiliary outliers to improvethe OOD distinguishability. Specially, with the emergence of the powerful pretrained vision-languagemodels (VLMs) [Radford et al., 2021], a series of prompt tuning based methods [Miyai et al., 2024b,Tao et al., 2023, Bai et al., 2023, Ming et al., 2022c] show impressive performance in current OODdetection benchmarks, with the regularization given only few-shot in-distribution (ID) data. Generally, these regularizations [Wang et al., 2023, Miyai et al., 2024b] are built upon the ID-irrelevantlocal context as the surrogate OOD source, which is extracted by VLMs (refer to ) based onits alignment with ID-class text features. Although this saves the costly collection of auxiliary outliersfrom the open world, the quality of the ID-irrelevant local context also becomes the bottleneck, whichcan be greatly affected by the foreground-background decomposition with VLMs. Specifically, asrevealed in previous studies [Oh et al., 2023, Tu et al., 2024, Wang et al., 2024], the prevalent VLMsstruggle with poor calibration, which means that the decomposition performance on downstream datamight not be well guaranteed. Thus, it naturally motivates the following question:",
  "Keeshond": ": Imperfect foreground background decomposition. The top row shows the original imagesfrom ImageNet-1k and the bottom row shows the ID-irrelevant context extracted from the originalimages (shown as the colored patches of images on the second row), using CLIP fine-tuned withCoOp on 16-shot data. Due to the imperfect decomposition of fine-tuned vision-language models,large portions of the extracted local features from ID data belong to ID-related regions, thus harmingthe performance of OOD detection. More illustrations are presented in the Appendix A.3.3.",
  "Can we flexibly leverage the imperfect OOD features extracted by the VLM itself,to facilitate the few-shot prompt tuning for effective OOD detection?": "As illustrated in , a significant portion of extracted local context from ID data are not validOOD features due to the inevitable imperfect decomposition. Consequently, OOD regularizationbased on such unreliable OOD features may potentially constrain the improvement of OOD detection.To investigate this problem, we conduct a proof-of-concept experiment on CLIP with ImageNet as theID dataset and prompt-tune the model with different groups of data divided by their overall predictionuncertainty. Specifically, we find that the performance of prompt tuning based methods significantlydeteriorates as the uncertainty of the given ID data rises, as presented in , which motivatesus to leverage such clues to overcome the current issue. Intuitively, as the model prediction on IDsamples is less certain, the OOD features extracted from these data are less reliable. PerformingOOD regularization on such unreliable surrogate OOD features can degrade the OOD detectionperformance of CLIP. Therefore, a potential idea is to adaptively adjust the importance of OODfeatures extracted from ID data according to their prediction uncertainty during model training. Based on the previous observation, we propose a new learning framework, i.e., Self-CalibratedTuning (SCT), to alleviate the problem induced by spurious OOD features. At the high level, we aimto dynamically adjust the weight of OOD regularization from different training samples based ontheir prediction uncertainty to calibrate their influence on model training. In detail, we introducemodulating factors based on the sample uncertainty estimation respectively on the two parts ofthe original learning objective of prompt tuning for OOD detection (refer to Eq (4)). Under thisnew learning framework, the models attention is directed towards the classification task to bettergeneralize to the downstream ID dataset when training with low-confidence data. OOD featuresextracted from high-confidence ID data are attached more importance to achieve more effective OODregularization. The redirection effect of these two modulating factors facilitates VLMs learningfrom imperfect OOD features to ultimately improve the OOD detection of prompt tuning. Our maincontributions can be summarized as follows, Conceptually, we investigate the problem of imperfect OOD features extracted in prompttuning based OOD detection methods and observe that ID data with different predictionuncertainty exhibits a distinctive influence on the OOD regularization. (in .2) Technically, we propose a novel learning framework, namely Self-Calibrated Tuning (SCT),for facilitating prompt tuning for effective OOD detection given only few-shot ID samples,which conducts adaptive redirection of model optimization process between the two tasks tocalibrate the influence of OOD features mined from different ID data. (in Sections 3.3) Empirically, extensive experiments from different perspectives are conducted to verifythe effectiveness of SCT in improving OOD detection performance. To be specific, SCTimproves the false positive rate (FPR95) by 3% compared to the previous best method on the",
  "Related works": "Prompt tuning for VLMs. The concept of prompt tuning was originally applied in the fieldof natural language processing [Radford et al., 2018]. To eliminate the need for manual promptcrafting, prompt tuning exploits supervision signals from downstream tasks to automate the processof prompt generation. Autoprompt [Shin et al., 2020] searches for tokens that cause the greatestchanges in gradients based on the label likelihood. Prefix-Tuning [Li and Liang, 2021] introducesa sequence of continuous vectors that can be end-to-end optimized in the token embedding space.Incorporating prompt tuning into computer vision. CoOp [Zhou et al., 2022a] adapts pretrainedvision-language models by optimizing a set of learnable continuous prompt vectors. Various prompttuning methods [Zhou et al., 2022b, Khattak et al., 2023, Sun et al., 2022] have been subsequentlyproposed to address different vision tasks. However, since these methods are not developed for OODdetection, they face challenges in identifying unknown OOD samples encountered at inference stages. Out-of-distribution detection with VLMs. Large pretrained vision-language models have enrichedthe landscape of OOD detection through their remarkable generalization capability in both visualand textual domains. MCM [Ming et al., 2022a] employs the concept of maximum softmax proba-bility [Hendrycks and Gimpel, 2017] into the inference process of CLIP for OOD detection, whileCLIPN [Wang et al., 2023] trains an additional text encoder using and set of prompts with a largeexternal dataset to improve its negative semantic understanding. Compared with zero-shot methods,prompt tuning based approaches achieve better OOD detection with access to few-shot ID trainingdata. LoCoOp [Miyai et al., 2024b] adopts prompt tuning and extracts ID-irrelevant backgroundfrom CLIPs local features as surrogate OOD data to regularize the learned prompts. [Bai et al.,2023] discovers ID-like outliers from ID samples via random cropping to learn a set of negativeprompts. However, these two representative prompt learning-based methods suffer from spuriousOOD features extracted from ID data due to the imperfect foreground-background decomposition ofVLMs. In addition, LSN [Nie et al., 2023] introduce negative prompts to empower VLMs to learnnegative semantics from ID samples while NegPrompt [Li et al., 2024] leverages negative prompts toinvestigate the novel setting of open-vocabulary OOD detection.",
  "Method": "In this section, we introduce our new framework, i.e., Self-Calibrated Tuning (SCT), which conductsadaptive redirection of model learning far away from OOD data region during prompt tuning with onlythe few-shot ID data. Firstly, we provide preliminaries and notations about prompt tuning based OODdetection (.1). Secondly, we present and discuss the critical motivation that inspires ourmethod (.2). Thirdly, we introduce its newly derived learning objective with the explanationand analysis of the underlying intuition and present its algorithmic realization (.3).",
  "Preliminaries": "VLM-based OOD detection aims to identify test samples that do not belong to any ID class designatedby the downstream tasks [Miyai et al., 2024a]. Therefore, the ID distribution is defined by the IDclasses from the downstream tasks, which are different from those of the upstream pretraining.Formally, we consider multi-class classification as the original training task [Nguyen et al., 2015],where X Rd denotes the input space and Y = {1, . . . , M} denotes the label space. A reliableclassifier should be able to detect the OOD input, which can be considered a binary classificationproblem. We consider Din as the distribution of ID data over pairs of examples x Rd andcorresponding labels y Y. At test time, the environment can present a distribution Dout over X ofOOD data. In general, the OOD distribution Dout is defined as an irrelevant distribution of which thelabel set has no intersection with Y [Zhu et al., 2023a] and thus should not be predicted by the modelparameterized by . A decision model () can be made with the threshold :",
  "Shot": "FPR95 high-uncertaintylow-uncertainty : Empirical demonstration about invalid OOD features extracted from ID data in LoCoOpand the influence of sample uncertainty on OOD detection performance. In the left and middlepanels, we illustrate the extracted OOD features at different levels of uncertainty and find that theybecome unreliable as the uncertainty increases. The numbers at the bottom denote the predictionprobability for the ground-truth labels from fine-tuned CLIP. In the right panel, we collect ID samplesof different uncertainty levels based on prompt-tuned CLIP and divide them into 2 groups. Theresult demonstrates that the OOD detection performance of LoCoOp significantly degrades as theuncertainty level of ID data rises. We leave the experimental details in Appendix A.3.1 for reference. Vanilla prompt tuning. Given an ID image x and its corresponding label y, a global visual featuref = f(x) is obtained by the visual encoder f of CLIP. Then, the textual prompt vectors can beformulated as tm = {1, 2, ..., N, cm}, where cm denotes the word embedding of the ID classname and = {n|Nn=1} are N learnable context vectors, each of which has the same dimension asthe word embedding. The text encoder g takes prompt tm as the input and outputs the textual featureas gm = g(tm). The final prediction probability of the CLIP model is computed as follows:",
  "p(y = m | x; ) =exp (sim (f, gm) /)Mm=1 exp (sim (f, gm) /),(2)": "where sim (, ) denotes cosine similarity, and represents the temperature of Softmax. We usep(x; ) to represent the probability vector [p(y = 1|x; ), p(y = 2|x; ), . . . , p(y = M|x; )],denoting the prediction probability of ID image x for every ID class. Prompt tuning for OOD detection. Compared with vanilla prompt tuning methods like CoOp [Zhouet al., 2022a], advanced prompt tuning based OOD detection methods extract surrogate OOD featuresfrom ID data via various methods to perform OOD regularization. LoCoOp [Miyai et al., 2024b] canfurther improve the detection performance by regularizing the learnable prompts on OOD featuresX extracted from ID local features using a ranking-based method, and its corresponding learningobjective is defined as follows,",
  "LLoCoOp = E(x,y)DinCE(p(y|x; ), y) + OOD(p( X; )),(3)": "where is the balancing parameter, CE() is the Cross-Entropy (CE) loss, p( X) is the predic-tion probability vector for X and OOD() is the negative entropy of the given probability vector.IDLike [Bai et al., 2023] conducts multiple random cropping on ID data and chooses cropped regionsas OOD features based on their feature similarity with textual features of ID classes.",
  "Motivation": "Given the only ID data, previous studies propose to extract the ID-irrelevant local context as thesurrogate OOD source, which depends on the foreground-background decomposition using CLIP.However, since the model itself has uncertainty on the prediction results, the correctness of thedecomposition cannot always be guaranteed. Thus, as illustrated in , the extracted localregions based on the prediction of CLIP may result in spurious OOD features, which then limits theOOD detection performance. Thus, it naturally motivates the following critical research question:",
  "How could we better utilize the surrogate OOD features extracted by imperfectforeground-background decomposition of CLIP for effective OOD regularization?": "In this work, we conduct a proof-of-concept experiment to investigate the relationship between sampleuncertainty and OOD detection performance of prompt tuning based methods. We use ViT-B/16CLIP as the model and large-scale ImageNet-1k OOD benchmarks. First, we observe that the qualityof OOD features extracted by CLIP is highly correlated with the uncertainty estimation of ID data.The extracted OOD features become more spurious as the uncertainty escalates, as illustrated in theleft and middle panel of . Furthermore, as empirically shown in the right panel of ,the performance of prompt tuning based methods is heavily affected by the overall uncertainty levelof the given ID data. Intuitively, as the predictions of the model on ID samples are less confident,the OOD features extracted from these data are less reliable. Regularizing on such invalid OODfeatures can undermine the calibration ability and OOD detection performance of CLIP, which canbe reflected by the higher FPR95 score (indicating a higher error on OOD detection). Therefore, anew mechanism is required to take the sample uncertainty into consideration to assist the model inlearning from these imperfect OOD features for more effective OOD detection.",
  "Self-calibrated tuning": "As aforementioned, the LoCoOp-based OOD detection paradigm relies on the extracted ID-background local features for OOD regularization. Given the imperfect foreground-backgrounddecomposition, the model is expected to effectively learn from the inaccurate OOD features for betterOOD detection. Inspired by the previous observation as shown in .2, one conceptual idea tomitigate this problem is to adaptively adjust the importance of OOD regularization generated fromdifferent ID samples based on uncertainty estimation to alleviate the wrong guidance of invalid OODfeatures. Under this learning paradigm, the model can be regularized by more valid OOD featuresand simultaneously prevent itself from overconfidence to improve OOD detection. To this intuition,we consider reformulating the learning objective under the framework of prompt tuning as follows,",
  "LSCT = E(x,y)DinCE(p(y|x; ), y) (p(y|x; )) + OOD(p( X); ) (p(y|x; )),(4)": "where : RM R and : RM R indicate the newly-introduced modulating functions thatcalculate adaptive factors for the two components of the original loss function (i.e., Eq (3)) of LoCoOpbased on the uncertainty estimation. In this loss function, the left part is for the ID classification task,and the right part is for the OOD regularization. Specifically, should be monotonically decreasingand should be monotonically increasing with respect to p(y|x; ) so that the modulating factorsshift the focus of prompt learning between the two tasks during the training process. In detail, when the model outputs low-confidence prediction for the ground-truth label, the importanceof the ID classification task is highlighted in order to better generalize to the downstream task andsimultaneously reduce the effect of regularization from invalid OOD features extracted from ID data.When the model can accurately and confidently classify the ID samples, its attention is redirectedtowards OOD regularization to strengthen the positive effect of useful ID-irrelevant features for betterOOD detection. In the meantime, the loss contribution of the classification task is reduced to avoidthe model overfitting to the downstream dataset, which benefits the calibration of the model [Mukhotiet al., 2020] and further enhances the validity of extracted OOD features. Under this learning framework, the goal of confidence calibration and OOD detection can benefitfrom each other. This method calibrates the influence of OOD features mined from different ID databased on model prediction confidence during the training process to facilitate capturing more reliableOOD features from ID data. Among a wide range of functions that satisfy the simple requirements asdiscussed above, we choose the linear function due to its simple design. Concretely, we formulate theloss function of SCT as follows,",
  ": end for": "To be specific, we select the region indices of ID-irrelevant regions from a set of all region indicesI = {0, 1, 2, ..., H W 1}, where H and W denote the height and width of the feature map. Wecalculate the classification prediction probabilities for each region i during training by computing thesimilarity between the image features f (i) of each region i and the text features of the ID classes.Then we choose regions that do not include their ground truth class in the top-K predicted classes asID-irrelevant regions J. The corresponding formulation is presented as follows:",
  "J = {i I : rank(p(i)(y|x; )) > K},(6)": "where p(i)(y|x; ) denotes the prediction probability of region i for the ground-truth label andrank(p(i)(y|x; )) denotes the rank of the ground-truth label among all ID classes. We summarizethe whole procedure of the proposed SCT in Algorithm 1. Test-time OOD detection.At the testing stage, we use the GL-MCM score proposed by [Miyaiet al., 2023] since it has been empirically proved to outperform the conventional MCM score. Itcombines the maximum softmax probability scores for both global and local image features. Thedetailed formulation is presented as follows:",
  "where f (i) denotes the local image feature of ID samples x for region i and we set = 1": "Comparison and compatibility.Compared with the previous prompt tuning based OOD detectionalgorithm [Miyai et al., 2024b], the critical idea behind SCT is trying to adaptively adjust thecontribution of OOD features extracted from ID data with different uncertainty during training. Itprovides a general framework (under the guidance of the learning objective in Eq. (4)) to assist VLMsin learning from spurious OOD features for effective OOD detection. The discriminative featureregularized by our SCT can be utilized by those advanced post-hoc scoring functions [Sun et al., 2021,Huang et al., 2021, Sun and Li, 2022]. For prompt tuning based methods, the adaptive modulationintroduced in SCT is orthogonal to current tuning objectives [Liu et al., 2020] and also compatiblewith different augmentation [Lu et al., 2023] or mining strategies [Bai et al., 2023, Zhu et al., 2023b].",
  "Experiment": "In this section, we present the comprehensive verification of the proposed SCT in the CLIP-basedOOD detection scenario. First, we provide the experimental setups in detail (in .1). Secondly,we provide the performance comparison of our approach with a series of CLIP-based post-hocmethods and prompt tuning based methods (in .2). Thirdly, we conduct various ablationstudies and further discussions to understand our method (in .3).",
  "Datasets. Following the common benchmarks used in previous works, we adopt the ImageNet-1Kdataset [Deng et al., 2009] as the ID data. For OOD datasets, we adopt the same ones as in [Huang": "and Li, 2021], including subsets of iNaturalist [Van Horn et al., 2018], SUN [Xiao et al., 2010],Places [Zhou et al., 2017], and TEXTURE [Cimpoi et al., 2014]. For the few-shot training, we use 1,2, 4, and 16 shots ID data for training, respectively, and evaluate models in the full test set. We alsopresent the comparison results on conventional CIFAR benchmarks [Hendrycks et al., 2019, Liu et al.,2020], which adopt CIFAR-10 and CIFAR-100 as ID datasets [Krizhevsky, 2009], in Appendix A.3.2. Evaluation metrics. We employ the following two common metrics to evaluate the performanceof OOD detection: (i) Area Under the Receiver Operating Characteristic curve (AUROC) [Davisand Goadrich, 2006] can be interpreted as the probability for a positive sample to have a higherdiscriminating score than a negative sample [Fawcett, 2006]; (ii) False Positive Rate (FPR) at 95%True Positive Rate (TPR) [Liang et al., 2018] indicates the probability for a negative sample to bemisclassified as positive when the true positive rate is at 95%. We also adopt in-distribution testingaccuracy (ID-ACC) to measure the preservation level of the performance for the original classificationtask on ID data and use Expected Calibration Error (ECE) [Naeini et al., 2015] to measure theperformance of SCT on confidence calibration, which are both presented in Appendix A.3.2. Implementation details. Following previous works [Tao et al., 2023, Ming et al., 2022a, Miyai et al.,2023], we use ViT-B/16 [Dosovitskiy et al., 2021] as the backbone model for the main experiment.For the hyperparameter K in the surrogate OOD features extraction, we use 200 in all experimentsas recommended by [Miyai et al., 2024b]. For SCT, we adopt = 0.4 under the 1-shot setting and = 0.2 under the 16-shot setting. We train the CLIP for 25 epochs with a learning rate of 0.002 andother hyperparameters (e.g. batch size=32, SGD optimizer and token lengths N=16) are the same asthose of CoOp [Zhou et al., 2022a]. We use two Nvidia 3090 GPUs for all experiments. OOD detection baselines. We compare SCT with several competitive CLIP-based OOD detectionmethods in the two directions, including post-hoc methods and prompt tuning based methods. Forpost-hoc methods, we compare with MCM [Ming et al., 2022a] and GL-MCM [Miyai et al., 2024b]as zero-shot baselines. We also adopt Maximum Softmax Probability (MSP) [Hendrycks and Gimpel,2017], ODIN [Liang et al., 2018], ReAct [Sun et al., 2021], MaxLogit [Hendrycks et al., 2022], andEnergy score [Liu et al., 2020] as conventional scoring function baselines. In addition, we providemore discussions about post-hoc methods and our methods in Appendix A.3.2. For prompt tuningbased methods, we adopt CoOp [Zhou et al., 2022a], LoCoOp [Miyai et al., 2024b], IDLike [Baiet al., 2023], NegPrompt [Li et al., 2024] and LSN [Nie et al., 2023] as baselines. For all prompttuning based methods, we constrain all major experiments to few-shot learning scenarios, which ismore practical in real cases. Note that LSN is a general learning framework that can be combinedwith various prompt tuning methods and we report the result of LSN incorporated with LoCoOp in. We leave more definitions and implementation details in the Appendix A.1.",
  "Main results": "In this part, we present the major performance comparison with some representative baseline methodsfor OOD detection to demonstrate the effectiveness of the proposed SCT. Specifically, we considerseveral zero-shot methods as the performance reference based on the pretrained CLIP and someprompt tuning based methods for specific comparison on fine-tuning with few-shot ID data. Note thatwe leave the experiment results on 2-shot and 4-shot settings in Appendix A.3.2. Comparisons on conventional OOD detection In , we present the overall results of thecomparison between different baseline methods and SCT for OOD detection. Since the prompttuning based methods engage the ID data during training, the model will generally gain betterempirical performance on OOD detection, reflected by evaluation metrics like FPR95 and AUROC.IDLike, NegPrompt, and LSN all introduce a set of negative prompts for each ID class to learnnegative semantics of ID objects using different strategies, which obtain different levels of detectionperformance gains. Without sacrificing much classification performance (i.e., ID classificationaccuracy) on ID data, as shown in , our SCT can consistently achieve better OOD detectionperformance on the large-scale ImageNet-1k benchmark, which verifies the effectiveness of ourmethods with the newly proposed modulation factors. Compatibility with other baselines. In , we report the results of compatibility experiments,in which we compare those prompt tuning based methods with their variants, incorporating ourSCT to dynamically adjust the importance of OOD regularization from ID samples with differentuncertainty levels. We can find that our SCT can consistently help them gain better or comparable : Comparison results on ImageNet-1k OOD benchmarks. All methods are trained on thesame backbone CLIP-ViT-B/16. Bold numbers are superior results. indicates larger values arebetter, and indicates smaller values are better. Results marked with are taken from [Wang et al.,2023] and [Miyai et al., 2024b]. The prompt tuning based methods are run under multiple trials withreporting the mean and standard deviation of the performance.",
  "-shot26.4793.3771.77": "Importance of the modulation factors in SCT.As an important aspect of the learning objectiveof SCT in Eq. (4), the newly introduced modulating factors in the learning objective of SCT conductadaptive redirection of prompt tuning towards suitable tasks. Although each of modulating factorscan seemingly achieve the redirection effect alone, we empirically find that both modulating factorsplay a significant role in enhancing OOD detection performance of VLMs, as shown in . Influence of regularization weight in OOD regularization.The regularization weight controlsthe contribution of OOD regularization to the prompt learning process like the role of the twomodulation factors. In (a), we show the performance by varying the ratio = 1. It is worthnoting that setting high regularization weights such as = 1 may even degrade the performance,indicating that the ID classification task should be attached more importance for better OOD detection. Generality of using different OOD regularization functions.Since SCT introduces a generallearning framework of prompt tuning for OOD detection, the specific realization for the OODregularization function can have multiple choices (e.g., MSP [Hendrycks and Gimpel, 2017] or Energyscore function [Liu et al., 2020]). Here we report the performance using different OOD regularizationfunctions in (b), where they have different performance improvements compared with theoriginal LoCoOp baseline. Specifically, the energy regularization needs tuning the two energythreshold hyperparameters min and mout, limiting its advantages over other regularization functions. Implementation with different CLIP architectures.We evaluate SCT with different VLMarchitectures and the results are shown in (c). The result illustrates that the larger backboneboosts the performance of OOD detection and also shows SCT can outperform LoCoOp acrossvarious VLM architectures. It is important to note that we take the same hyperparameters across allarchitectures, demonstrating the robustness of SCT hyperparameters on different VLM architectures. Comparison between different methods for extracting OOD features.In (d), weperform the comparison of our method adopting different methods for extracting OOD features,including the probability-based and entropy-based methods. The results verify the superiority of SCTon OOD detection across all the OOD feature extraction methods. Specifically, the probability-basedmethod and entropy-based method both have a threshold hyperparameter to discriminate betweenID and OOD features. The sensitivity to hyperparameters of different methods might be the reasonbehind the different OOD detection performance. For the entropy-based method, the performance issignificantly poor since it is challenging to determine the appropriate threshold [Miyai et al., 2024b].",
  "Discussions and limitations": "Comparisonswithadvancedpost-hocmethods.Recently,advancedpost-hocap-proaches [Djurisic et al., 2022, Xu et al., 2024] exhibit comparable OOD detection performance totuning based methods, despite the lack of training data. However, prompt tuning based methods canleverage the generalization ability of VLMs to better fit the domains of the downstream tasks givenonly few-shot ID training data. Whats more, post-hoc methods and prompt tuning based methodsare compatible with each other, further boosting the OOD detection performance. We provide moredetailed discussions, including empirical experiments, on the compatibility of SCT with advancedpost-hoc methods in Appendix A.3.2. Furthermore, future research efforts into post-hoc calibrationmethods for prompt tuning based OOD detection could also contribute to the community. 0.10.20.250.40.51.0",
  "Performance improvement on the AUROC metric.The experiment results in and 2": "indicate that the improvements of SCT over LoCoOp on AUROC are less notable than the FPR95metric. However, as shown in the comparison of different baselines in , the improvementspace for FPR95 is significantly larger than AUROC. Therefore, the progress on these two metricsshould not be treated equally. Nevertheless, further investigation is necessary to enhance the OODdetection performance specifically targeting improvement on the AUROC metric. The sensitivity to training data under the few-shot setting.VLMs are exposed to limited IDdata samples under the few-shot scenarios, which means that the OOD detection performance ofprompt tuning based methods, including SCT, can be susceptible to the quality of limited ID trainingdata in practice. Exploration of selection strategies of suitable training data or overcoming the datasensitivity inherent in the few-shot setting could further facilitate the practical application of prompttuning based OOD detection methods in real-world scenarios. Theoretical analysis of the proposed method.Although we propose a novel framework to mitigatethe problem of invalid extracted OOD features, we have not yet provided sufficient theoretical analysisto prove the effectiveness of our method. We choose the linear function as the modulation function forthe sake of simplicity, instead of based on theoretical justification. Conducting theoretical analyseson the relationship between sample uncertainty and OOD detection performance of prompt tuningbased methods under few-shot settings is also a potential direction for future work. .",
  "Conclusion": "In this paper, we propose a novel learning framework, i.e., Self-Calibrated Tuning (SCT), thatimproves the OOD detection capability of VLMs with only the given ID training data. To mitigatethe problem caused by invalid OOD features mined from ID data, SCT introduces two modulatingfactors to the original learning objective to conduct adaptive redirection of prompt tuning processbetween the tasks of ID classification and OOD regularization. Through the redirection effect, ourmethod calibrates the impact of OOD features extracted from different ID samples based on thesample uncertainty estimation during the training process, which facilitates the model learning fromimperfect surrogate OOD features for OOD regularization. We have conducted extensive experimentsto demonstrate the effectiveness of SCT and its compatibility with a range of prompt tuning basedmethods, along with various ablation studies and further explorations to characterize the framework.",
  "and Disclosure of Funding": "GY and JCY were supported by the National Key R&D Program of China (No. 2022ZD0160703),111 plan (No. BP0719010) and National Natural Science Foundation of China (No. 62306178). JNZand BH were supported by NSFC General Program No. 62376235, Guangdong Basic and AppliedBasic Research Foundation Nos. 2022A1515011652 and 2024A1515012399, RIKEN CollaborativeResearch Fund, HKBU Faculty Niche Research Areas No. RC-FNRA-IG/22-23/SCI/04, and HKBUCSD Departmental Incentive Scheme.",
  "AAppendix / Supplemental Material": "The whole Appendix is organized as follows. In Appendix A.1, we present the detailed definitionsand implementation of zero-shot, post-hoc methods and several prompt tuning based methods thatare considered in our experiments. In Appendix A.3, we provide our extra experimental detailsand more comprehensive results with further discussion on the underlying implications. Finally, inAppendix A.4, we discuss the potential broader impact and limitations of our work.",
  "SMSP(x; f) = maxm P(y = m|x; f) = max softmax(f(x))(8)": "where f represents a given well-trained model and m is one of the classes Y = {1, . . . , M}. A higherMSP score signifies a greater probability that a sample belongs to the in-distribution distribution,indicating the models confidence on the sample. ODIN.Liang et al. designs the ODIN score function, utilizing the temperature scaling andminor perturbations to test samples to widen the gap between the distributions of ID and OOD data.The ODIN score is defined as follows,",
  "where T denotes the temperature parameter. As theoretically proved in Liu et al. , a lowerEnergy score represents a higher probability for a sample to belong to ID": "ReAct.Sun et al. designs a simple and effective approaches, named Rectified Activations(ReAct), to alleviate model overconfidence on out-of-distribution data. This work observes thatOOD samples can induce unusually high unit activation in the deep layer of neural networks. ReActimproves OOD detection by simply rectifying the activations at an upper limit c > 0, which can beperformed on a pretrained model without any modification to training. MaxLogit.Hendrycks et al. demonstrates that the conventional MSP OOD detector does notscale well to challenging large-scale multiclass and multi-label OOD detection setting and proposes asurprisingly simple detector based on the maximum logit, called MaxLogit, that greatly outperformsprevious post-hoc methods. The definition of MaxLogit is as follows,",
  "SMaxLogit(x; f) = maxm f(x)m(11)": "MCM.Ming et al. [2022a] explores the potential of large-scale vision-language models likeCLIP for OOD detection and proposes a simple yet effective zero-shot OOD detection methodcalled Maximum Concept Matching (MCM), which is based on aligning visual features with textualconcepts. This method characterizes OOD uncertainty by appropriately scaling of the distance fromthe visual feature to the nearest ID prototype, of which the formulation is as follows,",
  "where denotes the temperature parameter, f and gm represents image and text features respectively,and sim() represents the cosine similarity between the image and text features": "GL-MCM.Miyai et al. designs a zero-shot OOD detection method called Global-LocalMaximum Concept Matching(GL-MCM) that leverages the maximum softmax score of both globaland local image features and designs. Utilizing the matching score with local features can compensatefor the low global matching score and produce more accurate ID confidence. The detailed formulationof GL-MCM is shown in Eq (7).",
  "CoOp.Drawing inspiration from the success in prompt learning within natural language processing,": "Zhou et al. [2022a] proposes Context Optimization (CoOp), a simple framework specifically to adaptvision-language models like CLIP for downstream image recognition. Concretely, CoOp representsthe context words of a prompt as learnable vectors while keeping the entire pretrained encoders fixed.The specific framework of CoOp is presented in .1. LoCoOp.Miyai et al. [2024b] introduces an approach named Local regularized Context Opti-mization (LoCoOp) to enhance the OOD detection performance of prompt tuning. It first extractsID-irreverent contexts from CLIPs local features and utilizes it as OOD features to perform OODregularization with entropy maximization. The details of this method are provided in .1 IDLike.Bai et al. designs a new framework of prompt tuning for OOD detection to focuson challenging OOD detection scenarios. It first constructs surrogate outliers from ID samples byconducting multiple random cropping on ID data and filtering them based on their cosine similaritywith textual features of ID classes. Then it introduces a set of OOD prompts along with conventionalID prompts and optimizes them with a new loss function that consists of in-distribution loss, out-of-distribution loss and diversification regularization. NegPrompt.Li et al. proposes a prompt tuning based OOD detection method, namedNegPrompt, which learns a set of negative prompts for each ID class, with only ID data, to capturethe negative semantics associated with these classes. The training process is divided into two stages.In the first stage, the model learns the positive prompts. In the second stage, the positive prompts arekept frozen and the negative prompts are optimized via three loss functions that enforce the separationbetween negative prompts and ID images, a proper degree of similarity between negative and positiveprompts, and the diversity of the negative prompts. LSN.Nie et al. reveals that CLIP cannot fully understand the negative semantics of textualinformation and proposes to learn a set of negative prompts for each class to alleviate this problem.The learned positive prompt (for all classes) and negative prompts (for each class) are utilizedsimultaneously to calculate similarity and dissimilarity in the feature space, thereby enhancing theaccuracy of OOD sample detection.",
  "A.2In-depth comparison between SCT and hard example mining": "The part of ID classification in the learning framework of SCT bears a strong resemblance to hardexample mining methods, such as focal loss [Lin, 2017]. In this section, we clarify the novelty andinsights of our SCT by analyzing the difference between SCT and hard example mining as follows. Conceptually, the motivation of SCT is to mitigate the problem of unreliable OOD features in prompttuning based OOD detection methods. Generally, these methods rely on the ID-irrelevant localcontext extracted by VLMs as the surrogate OOD features to perform regularization, the quality ofwhich is greatly affected by the inaccurate foreground-background decomposition of VLMs. Asshown in and , although VLMs can mask out some ID-related regions (shown as thegrey patches of images), large portions of the extracted OOD features (shown as the colored patchesof images) obviously belongs to ID features. Empirically, we find that the quality of extracted OOD features significantly correlated with theuncertainty level of ID data. As illustrated in the left panel of , the extracted OOD featuresbecome more inaccurate as the uncertainty increases. In the right panel of , we train LoCoOpon multiple data groups with different uncertainty levels. The results demonstrate that the OODdetection performance of LoCoOp can be significantly impacted by the uncertainty level of ID data.Therefore, to mitigate the issue of unreliable OOD features, we propose SCT to calibrate the influenceof OOD regularization from different ID samples based on their uncertainty level. Technically, despite the simple design, SCT is significantly different from hard sample mining. Thelatter conducts reweighting directly on the samples based on the classification difficulty duringtraining. The former adaptively adjusts the importance between the two components of the originallearning objectives for every single sample. Data with high uncertainty are directly down-weightedin hard sample mining while they are utilized more for OOD regularization in SCT. As shown in, under 16-shot ID data, the OOD detection performance of simply assigning 1p(y|x) to Lce(denoted as and ) are significantly inferior to SCT (denoted as and ), demonstratingthe difference of SCT and hard sample mining.",
  "A.3Additional experimental results and further discussion": "In this section, we provide more experiment results from various perspectives to characterize ourproposed SCT. First, we introduce the additional experimental setups for the empirical verification inprevious figures and our learning framework. Second, we offer more detailed results and analysesof our method in comparison to other advanced baselines. Finally, more demonstrations of themotivation of our method are provided.",
  "A.3.1Additional experimental setups": ".In the right panel of , we conduct experiments to investigate the relationshipbetween sample uncertainty and OOD detection performance of prompt tuning based methods. Wefirst calculate the prediction probability for ground-truth labels of all the training samples in a 64-shottraining set using a prompt-tuned CLIP model. This model is prompt-tuned with LoCoOp on a4-shot training set which contains no overlapping samples with the 64-shot set. We use the predictionprobability for ground-truth labels to represent uncertainty. High-uncertainty samples are assignedlow prediction probability for their ground-truth labels and vice versa. We choose the data with thelowest and highest uncertainty for every ID class to generate two data groups of specific shots withdifferent uncertainty levels respectively, and train the model with LoCoOp on these two data groups. .In (b), we explore different regularization functions to perform OOD regular-ization, including entropy maximization [Miyai et al., 2024b], cross-entropy loss to the uniformdistribution [Hendrycks et al., 2019, Ming et al., 2022b] and the energy-based function [Liu et al.,2020], under the 16-shot setting. In (a), (c) and (d), we train the modelsof all the architectures with 16-shot training datasets. In (d), we evaluate the performanceof SCT with various methods for ID-irrelevant region extraction. To be specific, we consider threedifferent methods, including the ranking-based method, probability-based method, and entropy-basedmethod. Following the setups in [Miyai et al., 2024b], for the entropy-based method, we extract localregions where the entropy of pi(x) is lower than log M",
  "A.3.2Additional experimental results and illustrations": "Experiments on multiple few-shot settings.In order to further understand the effectiveness ofour SCT on different few-shot settings, we report the evaluation results of our SCT with 2-shot and4-shot training datasets, which are summarized in . The results demonstrate that SCT can gainsignificant improvement on OOD detection under all the few-shot settings. ID classification performance of baselines and SCT in and .To evaluate theperformance of all the considered baselines and SCT on the original classification task, we reportthe classification accuracy on the ID test set in . Since NegPrompt and LSN learn positiveprompts and negative prompts separately, they have the same ID classification performance as vanillaCoOp. The results show that SCT maintains comparable ID classification performance comparedwith vanilla prompt tuning CoOp and other advanced prompt tuning based OOD detection methodswhile achieving more effective OOD detection.",
  "p(y|x; ))": "test, we present the fine-grained OOD detection results in . We observe from the results thatalthough each of the modulation factors can individually contribute to redirect model training, theircombination maximizes the improvement on OOD detection, which achieves the best results on mostOOD test sets and shot numbers. Experiments on other instantiations of modulation functions.To explore the generality of ourproposed learning framework, we consider other instantiations of modulation functions. Specifically,we consider the power, logarithmic, and trigonometric functions, which are formulated in .For the experiment on the power function, we set = 0.25, = 0.5 for 1-shot and = 0.25, = 4for 16-shot. The experiment results, as shown in , indicate that all the considered choicesof modulation function can achieve significantly better OOD detection performance than LoCoOp,which further empirically proves the effectiveness of the learning framework of SCT. Experiments on conventional CIFAR benchmarks.We conduct the experiments on conventionalCIFAR benchmarks, following previous works [Liu et al., 2020]. We adopt CIFAR-10, CIFAR-100[Krizhevsky, 2009] as the ID datasets and use Textures [Cimpoi et al., 2014], Places365 [Zhouet al., 2016], iSUN [Xu et al., 2015], LSUN_Crop [Yu et al., 2015], and LSUN_Resize [Yu et al.,2015] as the OOD test datasets. We summarize the comparison results averaged across all OOD testdatasets in , which confirm that SCT achieves superior performance to LoCoOp. Experiments on Computational CostSCT doesnt incur any extra computational cost to theLoCoOp due to its simple design. Technically, SCT introduces modulating factors respectively on thetwo components of the original learning objective. The modulating factors (instantiated as 1 p(y|x)for and p(y|x) for in Equation (4) in the submission) only involves the computation of theprediction probability of ground truth classes p(y|x), which can be repeatedly used after the originalforward pass of CLIP models. Whats more, the operation of local features involved in LoCoOp andSCT are also relatively low-cost in terms of computation. The local are generated from the forwardpass of the vision encoders of CLIP, which doesnt bring additional computational cost compared toregular training. Regarding the extraction of OOD features, we compute the similarity between everylocal feature and text feature of all the ID classes and we identify regions that do not include their",
  ": The comparison of calibration measured by ECE between SCT and LoCoOp trained with 1,2, 4, 16 shots data. The evaluation is performed on the original validation set of ImageNet-1k": ": OOD detection performance of different instantiations of modulation functions. All methodsare trained on the same backbone CLIP-ViT-B/16. Bold numbers are superior results. indicateslarger values are better, and indicates smaller values are better. SCT-L denotes SCT with the linearfunction, SCT-Pow denotes SCT with the power function, SCT-Log denotes SCT with the logarithmicfunction and SCT-Tri denotes SCT with the trigonometric function as the modulation function.",
  "siamang": ": Examples of the invalid OOD features extracted by CLIP. The odd-numbered rows showthe original images from ImageNet-1k and the even-numbered rows show the extracted ID-irrelevantcontext from the corresponding images. The ground-truth labels are annotated below every even-numbered row. Although CLIP can mask out some ID-related regions (shown as the gray patchesof images), large portions of the extracted OOD features (shown as the colored patches of images)obviously belong to ID features. Discussions about current advanced post-hoc methods and our method.prompt tuning basedmethod can leverage the generalization ability of VLMs to better fit the domains of the downstreamtasks with relatively low computational cost. Post-hoc methods need to be built on a well-trainedmodel, the capacity of which greatly affects the OOD detection performance. Whats more, post-hocmethods and prompt tuning based methods are compatible with each other, further boosting theOOD detection performance. We conduct experiments on the compatibility of an advanced post-docmethod, NegLabel [Jiang et al., 2024], with SCT in the , and the results show that SCT canbe combined with post-hoc methods for better OOD detection. In addition, recent advanced post-hoc methods, such ASH [Djurisic et al., 2022] and ISH [Xu et al.,2024], improve OOD detection from the perspective of activation scale. However, VLMs like CLIPcompute prediction probability based on the cosine similarity between image and text features. Thecomputation of cosine similarity involves the normalization of features, which naturally eliminatesthe effect of the activation scale. Therefore, ASH and ISH cant apply to VLM models.",
  "Improvement on confidence calibration.We use Expected Calibration Error (ECE) [Naeini et al.,": "2015] to measure the improvement of SCT on confidence calibration over LoCoOp, with lowervalues indicating better calibration. ECE is calculated by dividing predictions on samples into Mequally-spaced bins by confidence scores, then computing the mean average of the difference betweeneach bins accuracy and confidence. It can be formulated as ECE = Mm=1|Binm|",
  "A.4Broader impact": "OOD detection is crucial for deploying reliable deep learning systems in real-world scenarios[Nguyen et al., 2015, Hendrycks et al., 2022]. This significance is particularly evident in safety-critical domains such as finance or medical intelligence, where a trustworthy model must accuratelydistinguish between samples belonging to distinct label spaces (e.g., animals) rather than simplyproviding predictions based on known classes (e.g., financial products or medical conditions). Ourresearch focuses on a general and practical challenge concerning prompt tuning methods for improvingOOD detection efficacy. We specifically focus on the issue of spurious OOD features extracted fromID samples. It is important for effective OOD detection to gain better empirical performance throughregularizing prompt tuning.",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-perimental results of the paper to the extent that it affects the main claims and/or conclusionsof the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justification: The experimental setups are provided in .1 to ensure the resultreproducibility.Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible is important, regardless ofwhether the code and data are provided or not.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  ". Experimental Setting/Details": "Question: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand theresults?Answer: [Yes]Justification: We provide the detailed experimental setups in .1 and more discussionin Appendix A.1.Guidelines: The answer NA means that the paper does not include experiments. The experimental setting should be presented in the core of the paper to a level of detailthat is necessary to appreciate the results and make sense of them.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [Yes]Justification: We demonstrate the experimental statistical significance by reporting the meanand std value based on multiple trials of the experiments in Tables 1, 2, and other results.Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
  ". Experiments Compute Resources": "Question: For each experiment, does the paper provide sufficient information on the com-puter resources (type of compute workers, memory, time of execution) needed to reproducethe experiments?Answer: [Yes]Justification: We provide the details of the used experiment compute resources in thereproducibility statement in Appendix.Guidelines: The answer NA means that the paper does not include experiments. The paper should indicate the type of compute workers CPU or GPU, internal cluster,or cloud provider, including relevant memory and storage.",
  ". Code Of Ethics": "Question: Does the research conducted in the paper conform, in every respect, with theNeurIPS Code of Ethics [Yes]Justification: The research conducted in the paper conforms, in every respect, with theNeurIPS Code of Ethics.Guidelines: The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. If the authors answer No, they should explain the special circumstances that require adeviation from the Code of Ethics.",
  ". Broader Impacts": "Question: Does the paper discuss both potential positive societal impacts and negativesocietal impacts of the work performed?Answer: [Yes]Justification: We discuss the potential positive and negative societal impacts of the work inAppendix A.4.Guidelines: The answer NA means that there is no societal impact of the work performed. If the authors answer NA or No, they should explain why their work has no societalimpact or why the paper does not address societal impact. Examples of negative societal impacts include potential malicious or unintended uses(e.g., disinformation, generating fake profiles, surveillance), fairness considerations(e.g., deployment of technologies that could make decisions that unfairly impact specificgroups), privacy considerations, and security considerations. The conference expects that many papers will be foundational research and not tiedto particular applications, let alone deployments. However, if there is a direct path toany negative applications, the authors should point it out. For example, it is legitimateto point out that an improvement in the quality of generative models could be used togenerate deepfakes for disinformation. On the other hand, it is not needed to point outthat a generic algorithm for optimizing neural networks could enable people to trainmodels that generate Deepfakes faster. The authors should consider possible harms that could arise when the technology isbeing used as intended and functioning correctly, harms that could arise when thetechnology is being used as intended but gives incorrect results, and harms followingfrom (intentional or unintentional) misuse of the technology. If there are negative societal impacts, the authors could also discuss possible mitigationstrategies (e.g., gated release of models, providing defenses in addition to attacks,mechanisms for monitoring misuse, mechanisms to monitor how a system learns fromfeedback over time, improving the efficiency and accessibility of ML).",
  "Guidelines:": "The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  "According to the NeurIPS Code of Ethics, workers involved in data collection, curation,or other labor should be paid at least the minimum wage in the country of the datacollector": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA]Justification: This paper does not involve crowdsourcing nor research with human subjects.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}