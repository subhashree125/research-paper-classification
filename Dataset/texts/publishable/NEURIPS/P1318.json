{
  "Abstract": "As a key component of power system production simulation, load forecastingis critical for the stable operation of power systems. Machine learning methodsprevail in this field. However, the limited training data can be a challenge. Thispaper proposes a generative model-assisted approach for load forecasting undersmall sample scenarios, consisting of two steps: expanding the dataset usinga diffusion-based generative model and then training various machine learningregressors on the augmented dataset to identify the best performer. The expandeddataset significantly reduces forecasting errors compared to the original dataset,and the diffusion model outperforms the generative adversarial model by achievingabout 200 times smaller errors and better alignment in latent data distributions.",
  "Introduction": "The modern power grid faces new challenges for stable and secure operation, such as the difficulty inforecasting load demand due to the uncertain charging profiles of electric vehicles (EV)s. Accurateload forecasting informs power consumption for a given time horizon, enabling power utilities toschedule sufficient power generation while minimizing waste. Consequently, production simulation,viz., an optimization program to economically allocate each power plants output, is widely used byutility companies. Various machine learning methods for load forecasting have been reported. Fan et al. employeda Long Short-Term Memory (LSTM) network for short-term load forecasting. Similarly, Kong etal. developed a hybrid model combining Convolutional Neural Networks (CNN) and LSTMto enhance forecasting accuracy by capturing spatial and temporal dependencies. A random forest(RF) model was utilized in to address overfitting through ensemble learning for short-term loadforecasting. Wang et al. applied a Gradient Boosting Decision Tree (GBDT) model to effectivelycapture nonlinear relationships in the data. The CatBoost model was used in to predict powerload demands, demonstrating strong performance with mixed data types. The methods mentioned above assume abundant, high-quality load demand data, which is oftenunavailable in the power industry. Communication failures, device malfunctions, and newly builtcommunities with limited data can impede accurate load forecasting.",
  "arXiv:2412.12146v1 [eess.SY] 10 Dec 2024": "many variants have been developed, among which TimeGAN (Time-series Generative AdversarialNetworks) performs well in synthesizing time series data. In addition, the diffusion model has been applied for time-series data generation in recent years. For example, Yuan. et al. proposedan interpretable diffusion model for generic time series generation . In this paper, we explore the effectiveness of load data augmentation for power system productionsimulation using TimeGAN and TS-Diffusion, respectively. The first step is augmenting the originaldataset, the second step is training a forecasting model based on the augmented dataset, and the laststep is feeding the predicted load demand in an optimization model to conduct the power systemproduction simulation. The source code and data are freely accessible at",
  "Dataset Description": "The dataset used in this paper is collected from a household in northwest China, comprising 168hourly load records from April 16 to April 22, 2024. It includes additional meteorological data:temperature, barometric pressure, wind speed, wind direction, surface horizontal radiation, directnormal radiation, and diffuse radiation. These variables will be included during dataset augmentation.In our load forecasting model, the meteorological data serve as features, while the load values areused as labels.",
  ": TS-Diffusion training framework": "The encoder module processes the input time series using a multi-head attention mechanism and afeed-forward neural network. The decoder module also uses multi-head attention and feed-forwardlayers, plus a deep decomposition design to capture the trend and seasonality components of thetime series. The diffusion-embedding module incorporates time-step information, and the positionalencoding module adds positional information to help the model capture the inherent temporal patternsof the data.",
  "Experiment Results": "This section mainly 1) compares the quality of the augmented datasets obtained by the two generativemachine learning approaches and 2) gives a simple showcase for power system production simulation.An in-depth analysis of the experiment results can be found in Appendix A.4. All the experimentsare implemented on a desktop PC with Intel 5.4GHz CPU and 32GB RAM.",
  "Quality of TS-Diffusion Augmented Dataset": "The original data is divided into the training and test sets at the beginning with an 8:2 split ratio.Then, the TS diffusion model is used to augment the original training set (about 134 data samples) to3456 samples. Prediction models are then trained respectively on the original training set and theaugmented training set. Besides, another comparison dataset is established by expanding the originaltraining set to the same size as the TS diffusion-augmented dataset using simple replication, followedby model training. RMSE (Root Mean Square Error) and MAE (Mean Absolute Error) are used asthe performance metrics. Four types of regression models are considered: ExtraTree, Random Forest,CatBoost, and XGBoost. Each model is independently trained once on the original, replicated, andaugmented datasets and tested on the (previously split) 20% testing set. Results are shown in .",
  "ModeldatasetRMSEMAE": "XGBoostoriginal0.057740.04276replicated0.064850.04427augmented0.063980.03445CatBoostoriginal0.043890.03323replicated0.045360.03243augmented0.056370.02761RandomForestoriginal0.041830.02952replicated0.058460.03968augmented0.061300.02949ExtraTreeoriginal0.044670.03209replicated0.044950.03229augmented0.053560.02395 The results in reveal that the model trained on the TimeGAN-augmented dataset outperformsthe one trained on the original and replicated data regarding the MAE but underperformed in RMSE.MAE measures the average absolute error between predicted and actual values, giving equal weightto each error. In contrast, the RMSE is more sensitive to larger errors due to the squaring operation.The augmented data leads to lower MAE but higher RMSE, indicating smaller errors overall witha few extreme outliers. This suggests that TimeGAN may have introduced slight anomalies duringaugmentation, thus enlarging the RMSE. Besides, the augmented data possibly deviates from theoriginal data distribution in the tail, leading to poorer model performance in extreme cases. While theaugmentation improves prediction accuracy to some extent, it somewhat compromises robustness. On the other hand, the load forecasting models trained on the TS-Diffusion augmented dataset arebetter than those trained on the original data, both in terms of MAE and RMSE. Also, compared withthe TimeGAN augmented dataset, the quality of the TS-Diffusion augmented dataset is obviouslybetter. Taking ExtraTree as an example, the MAEs of the model trained on the original dataset, theTimeGAN augmented dataset, and the TS-Diffusion augmented dataset are respectively 0.03209,0.02395, and 0.00004. The performance of the TS-Diffusion augmented dataset is remarkable.",
  "The previously predicted load data can be utilized in a standard power system production simulationprocedure, which means solving the following optimization model:": "Suppose a regions load is supplied by grid-purchased power Pgrid(t) and photovoltaic (PV) powerPpv(t) . The cost of PV power is 0.4 $/kWh, while the cost of the grid-purchased power is 1$/kWh. To optimize this regions power operation, the objective is to minimize the power productioncost while meeting load requirements Pload(t). The objective function is defined in Eq.(1), withconstraints from Eq.(2) to Eq.(4).",
  "subject toPload(t) = Pgrid(t) + Ppv(t),t = 1, ..., T(2)Pgrid(t) 0,t = 1, ..., T(3)0 Ppv(t) Ppv,max(t),t = 1, ..., T(4)": "In Eq.(4), Ppv,max(t) is the maximum possible PV power at time t. Since the load demand of thefuture horizon (e.g., the next day) is unknown, we employ the ExtraTree-based load forecastingmodel (trained on the dataset augmented by TS-Diffusion) as the future days load, Pload(t). Then,this forecast load will be substituted in Eq.(2). After solving the optimization problem, the simulationresults of the PV generation and grid power purchase are depicted in . During the no-PV-power period (before sunrise or after sunset), the regions power supply fully relieson external grid support. As the PV power increases, the grid power exchange gradually decreases.From 10:00 to 16:00, when the PV power is the most sufficient, it fully meets the regions load needs.",
  "Conclusion and Future Work": "In this paper, we propose a method to improve the accuracy of load forecasting models usinggenerative machine learning under small samples. The quality of the generated load data ( especiallyby the diffusion model) significantly improves the load-forecasting accuracy, demonstrating thefeasibility and capability of generative machine learning for power system production simulation. Future work includes fine-tuning the generative models for better data quality and conductingadditional comparisons. A limitation of this study is that the trained generative model for one regionalpower system may not directly apply to neighboring regions. Thus, applying transfer learning toenhance the models generalizability will be the next step.",
  "Zhang, Y. H., Qiu, C. M., He, X., Ling, Z. N., & Shi, X. (2017). A short-term load forecasting based onLSTM neural network. Electric power information and communication technology, 15(9), 19-25": "Kong, W., Dong, Z. Y., Jia, Y., Hill, D. J., Xu, Y., & Zhang, Y. (2017). Short-term residential loadforecasting based on LSTM recurrent neural network. IEEE transactions on smart grid, 10(1), 841-851. Dudek, G. (2015). Short-term load forecasting using random forests. In Intelligent Systems 2014: Pro-ceedings of the 7th IEEE International Conference Intelligent Systems IS2014, September 24-26, 2014,Warsaw, Poland, Volume 2: Tools, Architectures, Systems, Applications (pp. 821-828). Springer Interna-tional Publishing. Liu, S., Cui, Y., Ma, Y.,& Liu, P. (2018, October). Short-term load forecasting based on GBDTcombinatorial optimization. In 2018 2nd IEEE conference on energy internet and energy system integration(EI2) (pp. 1-5). IEEE.",
  "W. Li et al.(2023), DLS-GAN: Generative Adversarial Nets for Defect Location Sensitive Data Augmenta-tion, in IEEE Transactions on Automation Science and Engineering": "J. -H. Kim and Y. Hwang(2022), \"GAN-Based Synthetic Data Augmentation for Infrared Small TargetDetection,\" in IEEE Transactions on Geoscience and Remote Sensing, vol. 60, pp. 1-12, 2022, Art no.5002512 Tan, M., Liao, C., Chen, J., Cao, Y., Wang, R., & Su, Y. (2023). A multi-task learning method formulti-energy load forecasting based on synthesis correlation analysis and load participation factor. AppliedEnergy, 343, 121177.",
  "A.1GAN-based Load Demand Augmentation Model": "TimeGAN (Time-series Generative Adversarial Networks) is a GAN model customized for timeseries data generation. It integrates GAN with self-supervised learning to capture complex temporalpatterns. Like traditional GAN, it includes a generator that produces synthetic data and a discriminatorthat distinguishes between real and generated data. Through iterative training, the generator improvesin producing simulated time series. A key feature of TimeGAN is its use of self-supervised learning via an auto-encoder, comprisingan encoder that maps time series data to latent representations and a decoder that reconstructs theoriginal data. This structure enhances the models ability to capture the intrinsic time-series features. illustrates the TimeGAN training process.",
  "txt xt2(5)": "When TimeGAN generates data, the generator receives two types of inputs during training. First,in the open-loop mode, the generator receives synthetic embedding hS, h1:t1 to generate the nextsynthetic vector ht. The gradient is calculated based on the unsupervised loss in Eq.(6), in order toprovide the correct classification results yS, y1:T for the generated data and the training data as muchas possible.",
  "tht gX (hS, ht1, zt)2(7)": "Compared with traditional GANs, TimeGAN can capture temporal dependencies and generatesequences with a similar temporal dependency structure as real data. In addition, by combining ad-versarial training and self-supervised learning, TimeGAN can simultaneously optimize the processesof data generation and feature transformation. Hence, high-quality data can be generated. Moreover,the trained TimeGAN can generate multi-dimensional time series of arbitrary lengths.",
  "A.2TS-Diffusion-based Load Demand Augmentation Model": "As shown in , the TS-Diffusion model contains forward and reserve processes. In this setting,a sample from the data distribution x0 q(x) is gradually noised by a Gaussian noise N during theforward process, where the transition is parameterized by q(xt|xt1) = N(xt; 1 txt1, tI)with t (0, 1) as the amount of noise added at diffusion step t.Then a neural networklearns the reverse process of gradual denoising the sample via reverse transition p(xt1|xt) =N(xt1; (xt, t),",
  "A.3ExtraTree-based Load Forecasting Model": "ExtraTree is a decision tree-based machine learning model that improves its generalization abilityand computational efficiency by introducing extreme stochasticity to randomly select features andfeature splitting points. Unlike the usual approach that uses only a subset of the data, it uses the entire training dataset to buildeach tree. During the training process, the ExtraTree model introduces a lot of randomness. At eachsplit node, it randomly selects features and feature values to split rather than choosing the optimalfeature split point. More specifically, it randomly selects a subset of all features, then randomlyselects a feature from this subset to split, and randomly selects one of the possible split points as theactual split point. illustrates the basic idea of the ExtraTree model for load forecasting.",
  ": ExtraTree Model": "When making predictions, the ExtraTree model first makes individual predictions for each tree.Specifically, the input data is passed to each decision tree, and each tree makes a prediction based onthe feature splitting rule for the path from the root node to the leaf nodes. Finally, the predictions ofall decision trees are averaged to obtain the final prediction.",
  "A.4An In-depth Analysis of the Experiment Results": "In this subsection, the \"generation quality\" of the TS-Diffusion and TimeGAN augmented datasetsare respectively analyzed. The load forecasting models are trained on the augmented datasets, ofwhich the MAE and RMSE are compared with the forecasting models trained on the original data.The complete results of section 3.2 are shown in .",
  "Figures5 and 6 show the PCA (Principal components analysis) plot versus t-SNE (t-DistributedStochastic Neighbor Embedding) plot of the TS-Diffusion and TimeGAN generated data versus theoriginal data": "From the PCA and t-SNE plots, it can be found that with an equal number of generated samples, thedata generated by TS-Diffusion overlaps with the original data better. In contrast, the data generatedby TimeGAN is relatively widely dispersed. Thus, we can infer that TS-Diffusion might learn thedistribution of the input data better when generating the time series data, which is a key requirementin time series data generation. On the other hand, we also want to check if such a high overlap of the TS-Diffusion generated datawith the original data on the above 2D plots means that the TS-Diffusion does not have the potential todissimilate the original data (Because nobody wants to always generate the same data as the originaldataset!). So, we further inspect the distribution (i.e., probability density) of each generated featurecolumn by the KDE (kernel density estimation) plots shown in .",
  "MeanStandard deviationMeanStandard deviationMeanStandard deviation": "Load0.08460.07960.07850.10470.08400.0819Temperature12.11513.551911.90753.884311.89593.7428Pressure805.42522.1036805.03962.2329805.24512.1093Wind Speed3.08232.05803.21602.21033.17382.1988Wind Direction200.2355112.9504209.9846108.3983211.6479116.6709Surface Horizontal Radiation223.0501299.1725240.8833311.9197233.1411311.5514Normal Direct Radiation174.3329280.0541199.4151290.4430194.1014296.6413Scattered Radiation95.8374114.814591.6883107.399890.9040109.0043 Finally, it can be observed that the distribution of the data generated by TS-Diffusion does notcompletely overlap with the distribution profile of the original data (but still captures the basicposition and shape of the original data). This further explains the previously observed superiority( vs. ) of the TS-Diffusion augmented dataset over the TimeGAN augmented dataset.Briefly speaking, the TS-Diffusion model is not simply copying the target dataset when it tries togenerate its own data. In addition, we calculate the mean and standard deviation of the seven input features and the loaddemand for the original dataset and the augmented datasets, respectively, to inspect the quality of theaugmented datasets from a statistical perspective. The results are shown in . It can be seen more clearly from that although the augmented dataset is much larger, it stillholds similar statistics as the original data, demonstrating again that the augmented models can indeedcapture the original datas inherent patterns."
}