{
  "Abstract": "Real-world machine learning systems often encounter model performance degrada-tion due to distributional shifts in the underlying data generating process (DGP).Existing approaches to addressing shifts, such as concept drift adaptation, arelimited by their reason-agnostic nature. By choosing from a pre-defined set ofactions, such methods implicitly assume that the causes of model degradation areirrelevant to what actions should be taken, limiting their ability to select appropriateadaptations. In this paper, we propose an alternative paradigm to overcome theselimitations, called self-healing machine learning (SHML). Contrary to previousapproaches, SHML autonomously diagnoses the reason for degradation and pro-poses diagnosis-based corrective actions. We formalize SHML as an optimizationproblem over a space of adaptation actions to minimize the expected risk under theshifted DGP. We introduce a theoretical framework for self-healing systems andbuild an agentic self-healing solution H-LLM which uses large language models toperform self-diagnosis by reasoning about the structure underlying the DGP, andself-adaptation by proposing and evaluating corrective actions. Empirically, weanalyze different components of H-LLM to understand why and when it works,demonstrating the potential of self-healing ML.",
  ": Different adaptation strategiesa1,...,a4 might result in different per-formance after an environment change": "Consider the following scenario: You are tasked with mon-itoring the performance of a black-box model f deployedin production. After some time, you notice that the predic-tive performance of f has started to degrade. What wouldbe the appropriate action a you should take to ensure thatthe models performance returns to its prior performancelevels: a1: re-train the model on a subset of the data; a2:change the type of the model used; a3: remove discoveredcorrupted values; a4: add new covariates? Clearly, the answer to this question is it depends. Differ-ent actions might result in different behavior of the modelover time, as illustrated in . If we could pinpoint why the performance of the model hasdegraded, it could help us understand what actions are most promising, since we could select anaction which would directly address the root cause of the problem.",
  "arXiv:2411.00186v1 [cs.LG] 31 Oct 2024": "While we take this intuition for granted, state-of-the-art techniques for handling model degradationdo not reflect this line of reasoning and rely on pre-determined actions, such as model retraining, re-using old models , or other specialized methods . Such approaches sharea common, implicit assumption the reason for the degradation in model performance is irrelevant.We refer to this as reason-agnostic methods.",
  "Self-Healing Components": ": Our work introduces self-healing machine learning. Ahealing mechanism H interacts with a deployed model f. Hcontains four components: monitoring, diagnosis, adaptation, andtesting. The overall goal of SHML is to find optimal adaptationactions to maximize the predictive performance of a model f. The practical implications ofmethods being reason-agnosticare quite concerning. By not con-sidering the causes for drop inperformance, the corrective ac-tions are, essentially, shots inthe dark. In high-stakes applica-tions like healthcare, finance, orpolicing, misguided adaptationscan lead to real-world harms,such as inaccurate diagnoses, fi-nancial losses, or system fail-ures. In some industriessuchas healthcare this has resultedin avoiding automated model retraining altogether . We propose self-healing machine learning (SHML) to overcome the limitations of reason-agnosticapproaches. SHML equips ML models with the ability to diagnose the reasons for performancedegradation and take targeted corrective actions. We define a self-healing system as a tuple H,f,where f is a black-box model and H is a healing mechanism that can modulate the behavior of f.An example of H modulating f is by deciding what data to use to re-train f, as illustrated in ourintroductory example. H contains four components: monitoring, diagnosis, adaptation, and testing(). The goal of H is to decide what actions to take in response to model degradation whichare chosen based on an adaptation policy that provides a mapping from diagnoses to actions. Wetherefore formalize the goal of H as finding optimal actions under the shifted data generating process(DGP) which are sampled from an adaptation policy conditioned on a diagnosis (Sec. 3.3). In ourintroductory example, the optimal action is taking action a1 (). Building upon these insights,we propose the first self-healing ML algorithm, H-LLM (Sec. 5) which generates diagnoses behindmodel degradation and suggests diagnosis-based adaptation strategies. Significance beyond technical contributions. By enabling systems to autonomously diagnose andadapt to model degradation, we lay the groundwork for a new class of self-healing algorithms. Weenvision self-healing systems as crucial for high-stakes applications where optimal model performanceis essential. We also believe this work has immediate practical relevance in high-stakes areas wheremodel degradation is common, such as medicine , fraud detection or finance . Contributions. 1 We identify fundamental limitations in existing reason-agnostic adap-tation approaches that do not consider the reason for model degradation (Sec. 3.2). 2We introduce the paradigm of self-healing machine learning and establish a theoreticalfoundation for finding adaptation actions with diagnosis-guided action sampling (Sec. 3.3- 4).3 We propose the first self-healing ML algorithm H-LLM which reasons aboutthe causes of degradation and modulates the behavior of ML models (Sec. 5).4 Wedemonstrate the viability of SHML by studying why and when it works (Sec. 6).",
  "SHML is most closely related to concept drift adaptation or specialized drift handling methods. Weprovide an extended discussion on related work within each component in Appendix A": "Concept drift adaptation. The field of concept drift adaptation focuses on developing algorithms tomaintain the performance of machine learning models in changing environments. Such algorithmsare predominantly proposed within the setting of tabular data. Most common adaptation techniquesare re-training models on new data , re-using stored models or obtaining newdata altogether . These approaches can be implicit, like continuous retraining, or explicit,based on drift detection in data or model error . Because these approaches do not explicitly incorporate the reason for model degradation, we refer to them as reason agnostic. SHML divergesfrom common approaches by introducing the core idea of diagnosing the root cause to search foroptimal adaptation actions. Specialized drift handling. Techniques have also been developed to adapt in the presence of variousdrift scenarios, such as sliding windows or adaptive classifiers which repairconcept drift . However, these methods lack an explicit diagnosis mechanism and operate underfixed decision rules, which do not incorporate the root causes of degradation into the adaptationstrategy. Similarly, works that aim to understand distribution shifts or attribute shifts tospecific variables through causal mechanisms provide valuable insights but do not offer acomprehensive framework for adaptation. We note that some work could be in principle a part ofsome SHML system components (discussed in Appendix A).",
  "Model degradation over time": "Preliminaries. Let X and Y denote the input and output spaces, respectively, and let Pt denotethe data distribution over X Y at time step t [T]. At each t, we observe a batch of dataDt = {(x(i)t ,y(i)t )}nti=1 Pntt , where nt = 1 in the streaming setting and nt > 1 in the batch setting.We will drop the superscripts where clear from context.",
  "where F is a function class and Y Y R0 is a loss function": "In the time-invariant setting where Pt = P t [T], the goal reduces to learning a single function f F that minimizes the risk R(f) = EP[(f(x),y)]. When P is unknown, f is often approximatedby minimizing the empirical risk on a training set {(x(i),y(i))}ni=1 Pn. However, when Ptevolves over time, the optimal predictor f t arg minfF EPt[(f(x),y)] changes across timesteps1. Failing to adapt ft in this time-varying setting leads to model degradation, as the learnedfunction becomes increasingly suboptimal w.r.t. the current data distribution.",
  "Limitations of existing approaches in adapting to changing environments": "Maintaining stable model performance in the presence of a changing environment poses uniquechallenges. As the optimal predictor f t evolves over time, the estimated predictor should also adapt.Ideally, we could obtain a large batch of data Dt+1 = {(x(i)t+1,y(i)t+1)}nt+1i=1 and minimize the empiricalrisk over this dataset. However, this is often impractical due to constraints such as (i) ground-truthlabels not being immediately available ; (ii) the streaming setting, where each new batch containsonly one data point ; (iii) gradual shifts, where past data remains relevant ; or (iv) the presenceof corrupted data in new batches .",
  "Three primary mechanisms through which Pt varies are covariate shift: Pt(x) Pt+1(x) Pt(yx) =Pt+1(yx), label shift: Pt(y) Pt+1(y) Pt(xy) = Pt+1(xy), and concept drift: Pt(yx) Pt+1(yx)": "To address this, the research community has developed specialized methods determining the appro-priate corrective actions in such drifts. As discussed in Sec. 2, these methods primarily executepre-defined actions upon detecting a change, such as model retraining , re-using old models, or other more specialized methods . However, such methods are reason-agnostic,disregarding valuable information that inform better adaptation actions. Consider an illustrativeexample: suppose a batch of new data arrives, but due to a sensor malfunction , 80% of the labelsbecome corrupted and are independent of the input for that batch only. Naively retraining the modelon this noisy batch would degrade its performance. This is because this strategy implicitly assumes:",
  "for some k > 0. Similarly, this might result in suboptimal performance due to the nature of the shift.Each adaptation method discussed in Sec. 2 has such implicit assumptions about the model or DGP": "By not taking into account the reason for the model degradation (such as corrupted data), theadaptation strategy is defaulting to suboptimal corrective actions. While any adaptation strategyinherently involves some assumptions about the relationship between the predictor and the data, wewould like to prioritize making informed assumptions. As we discuss in Sec. 3.3, a key source ofsuch information is diagnosing why the models performance has dropped. To address the reason-agnostic nature of such adaptation methods, we propose a paradigm shift calledself-healing machine learning (SHML), where deployed models autonomously diagnose the reasonfor degradation and take diagnosis-guided corrective actions.",
  "The four stages of self-healing machine learning": "Self-healing machine learning is a framework for autonomously detecting, diagnosing, and correctingperformance degradation in deployed ML models. It aims to maintain model performance in changingenvironments without constant human intervention. The motto of self-healing ML is understandingyour problem is half the solution (and the most important half). A SHML system is defined by atuple H,f, where f X Y is the deployed machine learning model we aim to heal (i.e., thefunction that makes predictions on input data), and H is a healing mechanism that interacts with theenvironment and acts upon the model f by proposing and implementing actions, such as selectingwhen to retrain a model, what data to use or how to change the input data before making predictions.Thus, H can modulate the behavior of the deployed model f.",
  "Self-Healing Machine Learning in a nutshell": "Self-healing ML contains four components: monitoring, diagnosis, adaptation, and testing. Afterthese steps, the best action is implemented on the ML model, illustrated in .I. Monitoring. The first step is the detection of degradation, potentially due to a shift in thedata distribution. We formalize this as a monitoring component HM that takes as input thesequence of data batches {Di}ti=1, up to time t, and outputs st , indicating the likelihoodof model degradation. Formally,HM (X Y) ,(4)where higher values of st indicate a greater likelihood of a shift.II. Diagnosis. The diagnosis component HD detects the reason of degradation. It takes databatches {Di}ti=1, up to time t, along with any available contextual information c C (e.g. back-ground knowledge), and outputs a distribution (Z) over a space of possible reasons Z:HD (X Y C) (Z).(5)Z represents the finite space of possible reasons of the shift and is a stochastic vector.III. Adaptation. The adaptation component is a policy that outputs a distribution over actions.Given a diagnosis vector , actions a A are selected from a finite space A by: a (), where (Z) (A).(6)Each action a modifies f. We denote the model used at time t, selected by action a, as f ta.IV. Testing. The testing component HT evaluates each action a A on a relevant distributionand outputs a performance measure:",
  "Suppose the following motivating example to guide the notation above": "Illustrative example. Consider a deployed ML model ft for predict-ing diabetes. The monitoring component HM detects a significantdrop in performance, with st = 0.95 (Eq. 4). The diagnosis com-ponent HD outputs three most likely reasons z1, z2, z3 Z, with(z1) = 0.95 for data quality issues, (z2) = 0.03 for concept drift,and (z3) = 0.02 for model overfitting (Eq. 5). Based on, , theadaptation policy samples two actions a1, a2 () (Eq. 6): a1:remove detected biologically implausible values (e.g. Age > 200)and retrain ft; a2: include interaction terms between features tocapture non-linearities. The testing component HT evaluates theadapted models f a1tand f a2ton new incoming data (Eq. 7) andselects a1 due to lower estimated loss. The primary insight of SHML is that the action a () should bebased on the diagnosis , which is a distribution over possible reasonsz Z for model degradation. In contrast, standard approaches (Sec.3.2) assume that . SHML formalizes this as an optimizationproblem over a space of adaptation actionswe aim to find the optimalactions to take each time the model f degrades, with these actionschosen by the policy of the self-healing system H (). Differentpolicies 1 and 2 might propose different actions in response to thesame performance drop. While the diagnosis informs the policy, wedo not assume it is necessarily useful. Since (Z) is a probability distribution, it can encode noknowledge by being uniform over the diagnosis space: (z) =1Z,z Z. These components andtheir interactions between two time points t and t + 1 are shown in .",
  "An analysis of the properties of self-healing diagnosis": "Self-healing systems have the unique property of having a diagnosis stage. But what constitutes agood diagnosis? In this section, we analyze the properties of self-healing diagnosis and establish itsconnection to the performance of adaptation actions. To effectively use diagnosis information to guide the search for adaptation actions, we require away to quantify the usefulness of a diagnosis. We propose three desirable properties for such ameasure: (i) concentration: it should favor diagnoses that provide more information, i.e. assignhigher probabilities to fewer possible reasons; (ii) sensitivity: it should be sensitive to changes inthe diagnosis distribution, such that small changes in probabilities would result in small changes inthe measure; (iii) maximum uncertainty: it should reach its maximum value when the diagnosis distribution is uniform, indicating no knowledge about the reason for degradation. Therefore, wepropose using the entropy of the diagnosis vector as a useful proxy for quality which satisfies all threeproperties. Because entropy measures uncertainty, we refer to this as the certainty of the diagnosis.Definition 1 (Certainty of the Diagnosis). Let Z be the finite space of possible reasons for degradationand (Z) be the diagnosis space. The certainty of a diagnosis (Z) in a self-healing machinelearning system is measured by its entropy H(), defined as:",
  "where (Z) is the diagnosis space, () is the conditional distribution over actions induced bydiagnosis vector , and R(a) denotes the risk of f at associated with action a A": "This formalizes the intuition that the best diagnosis is the one that leads to the best adaptation actions,on average. To characterize the properties of this optimal diagnosis, we introduce an assumptionabout the structure of the adaptation policy:Assumption 1 (Independent actions). We assume that () has a hierarchical structure. First, areason z Z is sampled according to the diagnosis : z . Then, an action is sampled conditionedon this reason, a (z), where z (Z) such that z(z) = 1. () can then be described asthe following mixture.(a) = zZ(az)(z)(11)",
  "Under this hierarchical structure, we can prove a useful property of the optimal diagnosis:Proposition 1. Under Assumption 1, the optimal diagnosis has a zero entropy, i.e., H() = 0": "Proof in Appendix E. To ensure that the optimal diagnosis is well-defined, we also prove its existenceunder mild assumptions:Proposition 2 (Existence of Optimal Diagnosis). Suppose that the action space A is a compactsubspace of Rn and R is continuous. Then there exists at least one optimal diagnosis . Proof. The expected risk Ea()[R(a)] is a continuous function of by the continuity of R andthe compactness of A. Since the diagnosis space (Z) is also compact (being a probability simplex),the extreme value theorem guarantees the existence of a minimizer . Takeaway. The existence of an optimal diagnosis establishes a foundation for designingalgorithms that can accurately approximate it in practice. By identifying the underly-ing reasons for performance degradation, a high-quality diagnosis enables a self-healingsystem to take the most effective adaptation actions.",
  "There are data entry errorsThe minimum value for Insulin in the new dataset is negative, which is not possible in a real-world context10": ": Example diagnoses suggested by H-LLM. The system proposes diagnoses and suggestsevidence for the diagnosis. A post-hoc relative confidence score, constructed using the evidencecolumn, helps to guide which diagnoses to pay most attention to while designing adaptation policies. specify exhaustively in real-world scenarios; and (ii) assigning well-calibrated probabilities to reasonsfor model degradation is difficult due to both the epistemic and aleatoric uncertainty that exists inreal-world environments. This makes it difficult to approximate the optimal diagnosis (Def. 2). Challenges in adaptation. The adaptation policy (Eq. 6) requires selecting optimal adaptationactions a based on the diagnosis . This is challenging because (i) it requires reasoning about howactions interact with diagnoses; and (ii) the space of adaptation actions may be extremely large inpractice, making it difficult to find the optimal action (Eq. 8).",
  "Language models to empower self-healing": "We posit that LLMs have the potential to satisfy many of the required properties of self-healingcomponents because of the following capabilities: (i) Hypothesis proposers. LLMs are known tobe phenomenal hypotheses proposers which are required to hypothesizing diagnoses of MLmodel performance degradation; (ii) Contextual understanding. LLMs have been pretrained with avast corpus of information and hence have extensive prior knowledge around different contexts andsettings ; (iii) Language model agents. Language models can work as agents within a largersystem which is required to actively interact with a deployed model, trigger and implementchanges. We therefore see LLMs as capable proxies for different self-healing components.",
  "H-LLM in a nutshell": "H-LLM is the first SHML algorithm that modulates the behavior of f following .I. Monitoring. We use statistical drift detection algorithms to monitor model degradation fromk previous time points . Diagnosis is triggered if a shift is detected. II. Diagnosis.Upon detection, we use a pre-defined prompt template to obtain informationabout the dataset before and after the diagnosis.The prompt template gives us numericalinsights into how the dataset has changed and includes covariate information before and afterthe shift, together with other numerical details. We denote this prompt as an extractor functionE D Dc to obtain an information vector v. Using v and a chain-of-thought (CoT) modulewith self-reflection, H-LLM generates k candidate reasons for degradation {zi}ki=1 l(v) viaMonte Carlo (MC) sampling with associated confidence scores. As before, this is obtained byfollowing pre-defined prompt templates conditioned on the obtained information (e.g. Suggest{self.n} possible reasons why the model might have failed on the basis of the issues presented).These candidates form an empirical diagnosis vector , approximating the optimal diagnosis . illustrates diagnoses generated by H-LLM. III. Adaptation. Conditioned on the empirical diagnosis distribution , H-LLM generates mcandidate adaptation actions {aj}mj=1 l() via CoT-based MC sampling. This approximatessampling from () (Def. 6). The actions sampled from l are textual representations, so weuse an interpreter function to execute each a on f. IV. Testing.The sampled actions are evaluated on an empirical dataset (Def.7), and theempirically optimal action a = arg minj[m] R(a) is implemented. Limited access to the shiftedDGP complicates evaluating R(a), but it can be approximated with empirical data Dtest byusing a backtesting window, continuously incoming data, or historical data (Appendix B.4).",
  "Experimental viability studies": "The previous sections constituted the primary contribution of our paperestablishing SHML as aframework. The goal of this section is to provide a viability study by analyzing different componentsof SHML. We conduct six viability studies.2 Experimental setup. We desire to meet two properties: (i) have full control of the DGP to varyexperimental parameters; and (ii) we need to benchmark against existing adaptation methods (Sec.2) which are predominantly tabular-based. Therefore, we simulate a diabetes prediction task based on the setup in Sec. 3.1. We predict diabetes Yt {0,1} at each time point t for aset of n observations, generated according to a (changing) pre-specified DGP log ( P (Yt=1Xt) P (Yt=0Xt)) =t + kK t,kXt,k + t, where K includes relevant parameters such as Age or BMI, t,k are time-varying covariates and t N(0,2) is a noise component. For evaluating H-LLM actions, we use abacktesting windowa representative sample of the shifted distribution obtained after detecting thechange but before deploying the adapted model (Sec. B.4). Details provided in Appendix C.",
  "Viability study I: Adaptation in the presence of model degradation": "Setup. We aim to empirically demonstrate the limitations of existing approaches in adapting tochanging environments (Sec. 3.2). We benchmark H-LLM against four common drift adaptationmethods: (i) new model retraining on post-drift data, (ii) partially updating models with new data;(iii) Ensemble methods by re-using old models, and (iv) No retraining of the models . At timet, we introduce a sudden, single intervention by changing the DGP parameters and corrupting apercentage of k columns. shows the performance of different methods across and k.",
  ": Accuracy of a deployed model f upon an intervention which changes the DGP and corrupts percentage of k columns. Error represents standard deviation. is better": "Discussion. The performance of f degrades if the corrupted columns are not handled appropriately,such as removing or inputting the corrupted data. Defaulting to standard techniques of adapting toa changed environment results in poor performance. H-LLM diagnoses issues by observing thatsome values have drifted too much from their original values and the DGP has changed. One ofthe proposed adaptation strategies is to remove samples which were estimated to be corrupted, andre-training the model on the remainder of the data. This results in superior performance.",
  ". We simulate real-world unexpected degradations by assuming lagged labels and corruptingfeatures at test time and evaluating models for different datasets ()": "Discussion. Ground-truth labels are often not immediately available , a core feature of manystreaming settings. We evaluate how H-LLM compares to existing approaches in such scenarios.Across five datasets with different characteristics, H-LLM consistently outperforms traditionaladaptation methods by adapting f at at each time point t. Therefore, SHMLs ability to identify anddecorrupt features provides a robust adaptation strategy across varied data distributions and schemas.",
  "H-LLM0.56 0.000.70 0.030.66 0.020.72 0.010.73 0.000.56 0.000.70 0.030.66 0.020.72 0.010.73 0.00": ": Accuracy of various methods on different datasets with corrupted columns and varyingcorruption values. Error represents standard deviations of five runs. is better. We simulate conceptdrift by corrupting the test set as follows: we randomly selected k features and multiplied theirvalues by a corruption factor . H-LLM identifies that the test data has been corrupted and perform arelevant transformation to decorrupt the value to its original feature space at test time.",
  ":Lower driftdetection thresholds canbenefit SHML": "Setup. We use the same setup as experiment I and vary the drift detectionthreshold which influences the sensitivity of a detection system to changesin the DGP. Low values mean high sensitivity, and high values meanlow sensitivity . We measure average recovery time for H-LLM toreturn recover from degradation and post-intervention accuracy, H-LLMsaverage performance after intervention. shows this relationship. Discussion. Intuitively, one might expect earlier drift detection (lowerthreshold) to consistently yield faster recovery and higher accuracy. Inreality, concept drift algorithms often struggle with false positives whichcan result in worse model performance because of unnecessary re-training. Self-healing ML exhibits greater robustness to these false pos-itives, as any action will be implemented only if it outperforms doingnothing. This contrasts with traditional systems which would automat-ically trigger the selected action. In , this represents the higherpost-intervention accuracy with smaller thresholds.",
  ": KL-Divergence between esti-mated probabilities of which variablesare corrupted, and true probabilities,based on outlier factors and corruptioncoefficients. is better": "Setup. We evaluate how well self-healing systems identifythe root causes of problems. We corrupt a proportionof observations (corruption coefficient) by multiplyingtheir values by a factor (outlier factor) and see if the H-LLM detects issues related to these factors. We output aprobability distribution over diagnoses of which variableis corrupted. Knowing the true corrupted variable, wemeasure the difference between the distributions using KL-Divergence, with lower values indicating closer matches totrue corruption. A uniform diagnosis baseline representsrandom guessing. shows these differences. Discussion. As the outlier factor and corruption coefficient increase, making data issues moreapparent, H-LLM assigns higher probabilities to the corrupted variables. Thus, the diagnosisaccuracy improves as the problem becomes more evident.",
  "Viability study V: Adaptation": "2%5% 10% 20% 50% 75% Range of values corrupted 50% 60% 70% 80% 90% Accuracy per action Highest dot is the best discovered action Highest dot is the best discovered action Highest dot is the best discovered action Accuracy by corruption Size of backtesting window Accuracy by test set size",
  ": Model f accuracy for actions with vary-ing corruption range and backtesting window size": "Setup. We study the sensitivity of SHML adap-tation actions by examining how well actionsperform based on (i) the number of corruptedvalues and (ii) the size of the backtesting dataset. shows this relationship. Discussion. As more values are corrupted, adap-tation actions become more concentrated andless effective. With a larger backtesting dataset,actions are more spread out. This suggests (i) action evaluation is more reliable with non-corrupteddata and (ii) larger backtesting windows help in selecting better adaptations.",
  "Other studies": "We provide further experiments in Appendix D. Our framework shows strong performance withlower warm-start parameters and increasing benefit as data degradation becomes more severe (Sec.D.4). A component-wise ablation analysis (Sec. D.6) reveals each stage of SHML is essential.Extended benchmarks (Sec. D.5) and model agnostic evaluations (Sec. D.7) demonstrate consistentimprovements across different adaptation approaches and ML architectures.",
  "Discussion": "Algorithms hold significant decision-making power in high-stakes applications, yet little has beendone to ensure their optimal performance. This work presents a major leap towards that goal. Byenabling systems to autonomously diagnose and adapt to new environments, we aim to create a waveof self-healing systems beneficial to both the ML community and society. Our theoretical framework(Sec. 3.3, 4) builds the foundation for the development of self-healing theory, such as optimaladaptation or diagnosis methods, and our viability study shows the potential benefits of SHML. Ourlargest contribution is formalizing this fieldwe hope to spur new theoretical developments andencourage the adoption of such systems in critical domains like medicine and finance . Limitations. SHMLs success relies on accurate root cause identification and finding effectiveadaptation policies which could pose challenges in some complex, real-world settings (Sec. 5.1).Furthermore, the prioritization of adaptation strategies is also not trivial. Currently, H-LLM primarilylooks for subgroup-level issues. We see future work tackling all areas of self-healing ML: findingbetter diagnosis strategies, improving adaptation selection, and enabling better testing of actions inthe presence of changing environments.",
  "Daniel Vela, Andrew Sharp, Richard Zhang, Trang Nguyen, An Hoang, and Oleg S Pianykh.Temporal quality degradation in ai models. Scientific reports, 12(1):11654, 2022": "Zachary Young and Robert Steele. Empirical evaluation of performance degradation of machinelearning-based predictive modelsa case study in healthcare information systems. InternationalJournal of Information Management Data Insights, 2(1):100070, 2022. George Alexandru Adam, Chun-Hao Kingsley Chang, Benjamin Haibe-Kains, and AnnaGoldenberg. Hidden risks of machine learning applied to healthcare: unintended feedbackloops between models and future data causing model degradation. In Machine Learning forHealthcare Conference, pages 710731. PMLR, 2020. Berkman Sahiner, Weijie Chen, Ravi K Samala, and Nicholas Petrick. Data drift in medicalmachine learning: implications and potential remedies. The British Journal of Radiology, 96(1150):20220878, 2023.",
  "Ayne A Beyene, Tewelle Welemariam, Marie Persson, and Niklas Lavesson. Improved conceptdrift handling in surgery prediction and other applications. Knowledge and Information Systems,44:177196, 2015": "Hamish Huggard, Yun Sing Koh, Gillian Dobbie, and Edmond Zhang. Detecting concept driftin medical triage. In Proceedings of the 43rd International ACM SIGIR Conference on Researchand Development in Information Retrieval, pages 17331736, 2020. Tung-Duong Mai, Kien Hoang, Aitolkyn Baigutanova, Gaukhartas Alina, and Sundong Kim.Customs fraud detection in the presence of concept drift. In 2021 International Conference onData Mining Workshops (ICDMW), pages 370379. IEEE, 2021.",
  "Ralf Klinkenberg and Ingrid Renz. Adaptive information filtering: Learning in the presence ofconcept drifts. Learning for text categorization, pages 3340, 1998": "Joao Gama, Pedro Medas, Gladys Castillo, and Pedro Rodrigues. Learning with drift detection.In Advances in Artificial IntelligenceSBIA 2004: 17th Brazilian Symposium on ArtificialIntelligence, Sao Luis, Maranhao, Brazil, September 29-Ocotber 1, 2004. Proceedings 17,pages 286295. Springer, 2004. Manuel Baena-Garca, Jos del Campo-vila, Raul Fidalgo, Albert Bifet, Ricard Gavalda, andRafael Morales-Bueno. Early drift detection method. In Fourth international workshop onknowledge discovery from data streams, volume 6, pages 7786. Citeseer, 2006. Bartosz Krawczyk, Bernhard Pfahringer, and Micha Wozniak. Combining active learning withconcept drift detection for data stream mining. In 2018 IEEE international conference on bigdata (big data), pages 22392244. IEEE, 2018. Nicols Astorga, Tennison Liu, Nabeel Seedat, and Mihaela van der Schaar. Partially observablecost-aware active-learning with large language models. In The Thirty-Eighth Annual Conferenceon Neural Information Processing Systems, 2024. Ben Halstead, Yun Sing Koh, Patricia Riddle, Russel Pears, Mykola Pechenizkiy, Albert Bifet,Gustavo Olivares, and Guy Coulson. Analyzing and repairing concept drift adaptation in datastream classification. Machine Learning, 111(10):34893523, 2022. Dewan Md Farid, Li Zhang, Alamgir Hossain, Chowdhury Mofizur Rahman, Rebecca Strachan,Graham Sexton, and Keshav Dahal. An adaptive ensemble classifier for mining concept driftingdata streams. Expert Systems with Applications, 40(15):58955906, 2013.",
  "Anton Dries and Ulrich Rckert. Adaptive concept drift detection. Statistical Analysis andData Mining: The ASA Data Science Journal, 2(5-6):311327, 2009": "Tinofirei Museba, Fulufhelo Nelwamondo, Khmaies Ouahada, and Ayokunle Akinola. Recurrentadaptive classifier ensemble for handling recurring concept drifts. Applied ComputationalIntelligence and Soft Computing, 2021:113, 2021. En Yu, Jie Lu, Bin Zhang, and Guangquan Zhang. Online boosting adaptive learning underconcept drift for multistream classification. In Proceedings of the AAAI Conference on ArtificialIntelligence, volume 38, pages 1652216530, 2024.",
  "En Yu, Yiliao Song, Guangquan Zhang, and Jie Lu. Learn-to-adapt: Concept drift adaptationfor hybrid multiple streams. Neurocomputing, 496:121130, 2022": "Jiashuo Liu, Tianyu Wang, Peng Cui, and Hongseok Namkoong. On the need for a languagedescribing distribution shifts: Illustrations on tabular datasets. Advances in Neural InformationProcessing Systems, 36, 2024. Andrs R Masegosa, Ana M Martnez, Daro Ramos-Lpez, Helge Langseth, Thomas D Nielsen,and Antonio Salmern. Analyzing concept drift: A case study in the financial sector. IntelligentData Analysis, 24(3):665688, 2020.",
  "Mauricio A Hernndez and Salvatore J Stolfo. Real-world data is dirty: Data cleansing and themerge/purge problem. Data mining and knowledge discovery, 2:937, 1998": "Tuomo W Pirinen, Jari Yli-Hietanen, P Pertila, and Ari Visa. Detection and compensationof sensor malfunction in time delay based direction of arrival estimation. In 2004 IEEEInternational Symposium on Circuits and Systems (IEEE Cat. No. 04CH37512), volume 4,pages IV872. IEEE, 2004. Linlu Qiu, Liwei Jiang, Ximing Lu, Melanie Sclar, Valentina Pyatkin, Chandra Bhagavatula,Bailin Wang, Yoon Kim, Yejin Choi, Nouha Dziri, et al. Phenomenal yet puzzling: Testinginductive reasoning capabilities of language models with hypothesis refinement. arXiv preprintarXiv:2310.08559, 2023. Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung,Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. Large language modelsencode clinical knowledge. Nature, pages 19, 2023. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, AdamRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022. Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang, Hao Yang, Jingsen Zhang, Zhiyuan Chen,Jiakai Tang, Xu Chen, Yankai Lin, et al. A survey on large language model based autonomousagents. Frontiers of Computer Science, 18(6):126, 2024. Zhiheng Xi, Wenxiang Chen, Xin Guo, Wei He, Yiwen Ding, Boyang Hong, Ming Zhang,Junzhe Wang, Senjie Jin, Enyu Zhou, et al. The rise and potential of large language modelbased agents: A survey. arXiv preprint arXiv:2309.07864, 2023.",
  "Aishwarya Mujumdar and Vb Vaidehi. Diabetes prediction using machine learning algorithms.Procedia Computer Science, 165:292299, 2019": "Muhammad Azeem Sarwar, Nasir Kamal, Wajeeha Hamid, and Munam Ali Shah. Prediction ofdiabetes using machine learning algorithms in healthcare. In 2018 24th international conferenceon automation and computing (ICAC), pages 16. IEEE, 2018. Albert Bifet, Geoff Holmes, Bernhard Pfahringer, Philipp Kranen, Hardy Kremer, Timm Jansen,and Thomas Seidl. Moa: Massive online analysis, a framework for stream classification andclustering. In Proceedings of the first workshop on applications of pattern analysis, pages4450. PMLR, 2010.",
  "Sebastian Raschka. Model evaluation, model selection, and algorithm selection in machinelearning. arXiv preprint arXiv:1811.12808, 2018": "Tania Cerquitelli, Stefano Proto, Francesco Ventura, Daniele Apiletti, and Elena Baralis. Au-tomating concept-drift detection by self-evaluating predictive model degradation. arXiv preprintarXiv:1907.08120, 2019. Markus Hittmeir, Andreas Ekelhart, and Rudolf Mayer. On the utility of synthetic data: Anempirical evaluation on machine learning tasks. In Proceedings of the 14th InternationalConference on Availability, Reliability and Security, pages 16, 2019.",
  "A.1Comparison to other fields": "Concept drift adaptation. Concept drift adaptation algorithms, a key component of self- healing MLsystems, primarily handle drifts by re-training models on new data or older, pre-trained storedmodels . These approaches can be implicit, like continuous retraining, or explicit, basedon drift detection in data or model error . Drift detection methods compare distributions,analyze data sequentially, or use statistical process control . For instance, the DDM algorithm has in-control, warning, and out-of-control states. Specialized drift handling. Techniques have been developed for various drift scenarios. Forrecurring drifts, methods store and reuse historical models . Streaming data is handled byblind approaches, like sliding windows or adaptive decision trees , and informed approacheswith explicit drift detection . Resampling can repair adaptation errors , while dynamicclassifier selection finds the best model for each input . Methods have been proposed forrobustness to noise , specific drift types , and other issues . Recent work exploresunderstanding distribution shifts through latent variable models and other techniques . Someadaptive methods of re-training the model also include adding more hidden layer to a learner upondetection of a drift . Another area of research closely linked within the field is dynamicselection which attempts to find the most suitable classifier conditional on the covariates . On repairing concept drift. There have been other methods propose that implicitly try to adaptby detecting changes . However, these adaptations are still based on the observed empiricaldistributions as opposed to observing the reason for degradation. By periodically sampling theaccuracy of inactive classifers, the authors identify cases where change was missed or misclassifed.However, this falls under the broader umbrella of trying out many pre-determined actions withoutdirectly reasoning about the reason for model degradation. Continual learning. One might get the impression that self-healing machine learning might bearclose resemblance to continual learning. Continual learning focuses on developing models that learncontinuously from a stream of data, acquiring, retaining, and transferring knowledge across tasksover time . This contrasts strongly with self-healing machine learning. Below, we outline sevencriteria by which self-healing machine learning and continual learning differ.",
  "Differences between continual learning and self-healing machine learning": "1. Objective.The objectives of the two fields are different.Continual learning aimsto learn sequentially from a stream of tasks while mitigating catastrophic forgetting.SHML focuses on autonomously diagnosing and recovering from performance degrada-tion within a single task due to distribution shifts. 2. Knowledge retention. A core goal of continual learning is to preserve previously acquiredknowledge while learning new tasks.SHML does not explicitly aim to retain priorknowledge or acquire new knowledge, but rather to maintain stable performance onthe current task by adapting to the reason for degradation. 3. Stability-Plasticity Dilemma. Continual learning grapples with the trade-off betweenbeing plastic enough to learn new tasks and stable enough to remember old ones. Incontrast, there is no such dilemma within SHML. 4. Task expansion.Continual learning seeks to expand the models capabilities by in-creasing the number of tasks it can perform. In contrast, SHML operates on a singlewell-defined taskensuring the optimal performance of a model, typically by minimiz-ing empirical risk and does not aim to increase the number of tasks. Instead, thefocus is on ensuring optimal performance under a single task. 5. Adaptation mechanism. The underlying logic or mechanism of adaptation is different.Continual learning typically adapts by modifying model architecture, updating param-eters via constrained optimization, using memory replay. In contrast, SHML explicitlyadapts by diagnosing the root cause of performance drops and conditioning an adapta-tion action on the basis of that diagnosis. This explicit mechanism which is conditionedon is not a part of a continual learning system. 6. Shift assumptions.Continual learning primarily handles shifts across distinct tasks,where the input or output distribution changes between tasks.In contrast, SHMLconsiders shifts within the same task, where the joint distribution might change. 7. Theoretical formalism.Continual learning is often formalized as a sequence of con-strained optimization problems to mitigate interference between tasks.In contrast,SHML is formalized as finding an optimal policy that can propose actions on the basisof diagnoses.",
  ": Summary table of self-healing ML. Use this as a guiding source to navigate the paper.Related work defines the most similar available work within each component": "Monitoring. Related work within monitoring largely relates to different statistical techniques fordiscovering the presence of shifts/drifts or model degradation. We see them as an integral partof SHML. However, they are also actively used by other adaptation methods to trigger adaptationsystems. Diagnosis. The diagnosis component is a core component of SHML. Two primary works are closelyrelated. The first work, why did the distribution change? , attempts to factorize the change ofthe joint distribution into conditional distributions of each variable and attribute some changes to oneof the marginals. This is achieved by modeling the change and relationship between variables as acausal mechanism. The second work, why did the model fail? attributes model performancedegradation via a causal mechanism. They assume that distribution shifts are induced due to anintervention in the causal mechanism which results in model performance changes, and uses Shapleyvalues to attribute changes to specific distributions. These two methods are fundamentally differentfrom SHML in multiple respects. First and most important, these works do not propose any actions onthe basis of these failures or shifts. The primary goal of both works is to understand why a distributionhas changed or a model has failed, attributing it to a causal mechanism, instead of adapting themodel to perform optimally. Second, the theoretical formalism introduced is substantially differentand comes with different properties. Both works operate within the directed acyclic graph (DAG)framework, whereas we operate under a diagnosis component which is defined as a vector over a spaceof possible reasons. Other key differences relate to the adaptation mechanism, shift assumptions,adaptation assumptions, level of granularity of the diagnosis, level of granularity of the adaptation, ortesting. Recent work has already started coming out on understanding distribution shifts . It is knownthat understanding why a distribution shift happens is important for mitigating that shift . Someother people have looked at modeling shifts via latent variable models without relying on accessto labels at test time . However, as before, these methods do not share the objective of findingoptimal actions for adaptation. Self-healing systems outside ML. Self-healing systems have been proposed outside of machinelearning . We view these as inspirations for our work but consider them disparate and separatebecause none of them touch upon the core problem of machine learning model degradation, and havenot been applied in practice.",
  "A.3Unique properties of self-healing machine learning": "The core of self-healing machine learning revolves around two primary components: the deployedML model f and the healing system H. Here, we provide additional clarity on these components andtheir interactions: Definition of the Deployed Model fThe model f represents the deployed machine learning modelthat we aim to heal. It is the function that makes predictions on input data and whose performancewere trying to maintain and improve. In our viability studies, we demonstrate this framework usinglogistic regression models as f, though the approach generalizes to any predictive model. Relationship Between f and While f is the model making predictions, is the adaptationpolicya function that determines what actions to take to modify f based on the diagnosed reasonsfor its performance degradation. The healing system H follows policy to output actions a (such asa1: retrain a model or a2: remove corrupted features) which are then implemented onto f. Therefore,H follows policy which helps to determine optimal actions a that change/modulate the deployedML model f. Practical ImplementationIn our viability studies with H-LLM, the policy is instantiated withan LLM (GPT-4) which uses the diagnosed reasons for model failures (also achieved with an LLM)to propose concrete actions. For instance, if f is a diabetes prediction model and diagnoses thatfs performance has degraded due to concept drift, might suggest an action to retrain f with morerecent data or to adjust feature weights.",
  "Extended discussion": "I. Monitoring. We use statistical drift detec-tion algorithms to monitor model degradationfrom k previous time points . Di-agnosis is triggered if a shift is detected. Forour practical implementation, we use the DriftDetection Method, a popular method for binarydrift detection classification. II. Diagnosis. Upon detection, H-LLM uses anextractor function E D Dc to transform thedataset information into an information vectorv. This extractor function is a mapping from thedataset to information about the dataset. It takesinformation before the shift happened and calcu-lates summary statistics, such as the mean, aver-age, standard deviation, percentiles, etc., withineach column, as well as the performance of adeployed model f under various data slices. Forinstance, this would also involve looping over allvariables, binning them into 10 discrete valuesand calculating the average model performanceacross each bin. This is done to ensure that theinformation contained within the informationvector are both summary statistics, i.e. how thedata has changed, as well as specific performance metrics within data slices. The information is usedto generate specific diagnoses as to what has happened. We observe, for instance, that summarystatistics are extremely helpful if there are any larger deviations from average, as the diagnosis modulewithin H-LLM picks up on these clues. This information is provided as textual information to thenext step which is the diagnosis phase. The information vector is used as a textual representation within the next LLM call to generateconcrete hypotheses / diagnoses about the reason for the f failure. This is where additional context ccould be added, if available, such as the presence of any particular exogeneous events that could haveaffected model performance and could guide the diagnosis search. In the future, we envision that theadditional context could be acquired by the system itself. This is used in a chain-of-thought modulewith self-reflection, where k candidates for degradation are generated along with associated scores.We employ different diagnosis modules within H-LLM. For instance, there is a specific diagnosismodule that only attempts to find which covariates are responsible for degradation. The systemlevel instruction could be as follows: Find covariates that are responsible for the model degrading.However, we also supplement this with more broader reasons for degradation, such as Find andhypothesize reasons that could have resulted in model degradation , given the information provided.We provide three prompt templates used to hypothesize issues in Section B.2.1. We sample suchprompts m times using MC sampling. The chain-of-thought and self-reflection is implementedby calling H-LLM multiple times to re-consider the evidence and hypotheses. illustratesdiagnoses generated by H-LLM. III. Adaptation. Conditioned on the empirical diagnosis distribution , H-LLM generates mcandidate adaptation actions {aj}mj=1 l() via CoT-based MC sampling. Specifically, we focus onthree kinds of adaptation actions.",
  "This is reflected in three different prompt templates in Appendix B.2.2": "Generic adaptation actions. The first attempt is to find generic adaptation actions that the diagnosismodule suggests on the basis of the identified evidence. These are often quite generic, for instance,add new covariates that could control for the seasonality. In many such cases, within the confinesof our experiments, we do not have the ability to resolve the issues on the basis of the proposedsolutions. Therefore, we add two more directly actionable adaptation actions that are also attemptedby H-LLM after the generic adaptation actions have been attempted. Adaptation actions by removing corrupted data. Another concrete adaptation action is that weinstruct H-LLM to hypothesize specific data slices that might have been corrupted. This could be,for instance, biologically implausible values (negative insulin, age > 200, implausible hba1c levels),mismatches (e.g. height, weight do not match BMI), sudden shifts in the data (ages change fromaverages of 30 to 60), and other. The adaptation module then proposes which data slices to remove toachieve superior performance. These suggested data slices are then removed and re-trained in thenext batch. Adaptation actions by training multiple models. The final concrete adaptation action is to proposespecific data slices where the model might have drifted within that slice. This is done because insteadof global drifts, models sometimes drift locally and require complete re-training of the new dataset. Example outputs of such strategies are presented in Appendix B.3. We note, however, that, in reality,there might be many possible adaptation actions, such as re-training the model on combinations ofold and historical data, re-using old models, re-using parts of old models, creating custom ensembles,changing models altogether, changing hyperparameters or adding regularization terms, buildingdifferent models for different samples based on their difficulty, switching between symbolic andpredictive ML models in the face of high uncertainty, and many more. Our approach is to introduceonly the primary few ways with the hope of extending this in the future.",
  "As before, because the actions sampled from l are textual representations, we use an interpreterfunction to execute each a on f": "IV. Testing. The sampled actions are evaluated on an empirical dataset (Def. 7), and the empiricallyoptimal action a = arg minj[m] R(a) is implemented. Limited access to the shifted DGP compli-cates evaluating R(a), but it can be approximated with empirical data Dtest by using a backtestingwindow, continuously incoming data, or historical data. In all of our experiments, we use a backtest-ing window. However, other strategies could be attempted. The different strategies are explained ingreater detail in Appendix B.4. Goal. This procedure aims to approximate the optimal action (Def. 8). We remark that there mightbe better adaptation policies that could be suggested on the basis of evidence. Likewise, there mightbe better diagnosis modules available. We see H-LLM as a first attempt to integrate self-healing intoML.",
  "B.4Evaluation strategies of self-healing algorithms": "Self-healing relies on a testing phase, i.e. the ability to test whether the proposed actions perform wellon a test dataset. However, given that the distribution has shifted and the historical data no longerrepresents the new distribution, one might ask: how can we test models on this new distribution? Theprimary alternative used in our experiments is a backtesting window which we define formally below.Definition 3 (Backtesting Window). Let {Pt}tT be a sequence of probability measures on X Y,and suppose a distributional shift occurs at time t T, i.e., Pt Pt1. Let t > t be the time atwhich the self-healing system detects the shift. The backtesting window is the time interval [t,t]satisfying the following properties:",
  "t [t,t] (xt,yt) / Pt1": "We notice that the backtesting window is a unique property that arises uppon sudden shifts in thedata generating process. Specifically, because we assume only two data generating processes anda transition between them at time point t, then all points k where k > t will be from the new DGPand all points k < t will be from the old DGP. Since a drift detection algorithm requries some timeto detect the drift, by the time a drift has been detected, we have some collected data from the newdistribution which we call the backtesting window. We can therefore optimize our actions on thisspecific window of the dataset. Clearly, this does not hold when the assumptions about the nature of the shift change. In such acase, we could always use continuously incoming streaming data. Upon the arrival of each newbatch, we can test each proposed action and validate it, consistently upgrading and using the actionsthat perform well on the most recent batch of data. This strategy assumes that the labels are almostimmediately available at prediction time. If not, another strategy employed could be to test suchactions on the mot recent available data with labels. Other approaches could include generating synthetic data to imitate the new shift with labels or usinghistorical data by de-biasing it. However, these are experimental approaches which need furthervalidation.",
  "B.5Computational notes": "Computational overhead. SHML methods have larger overhead than reason-agnostic approachesdue to the self-healing system (LLM pipeline) identifying model failure reasons. Practically, it takes20-40 seconds to implement a full pipeline and correct a model upon drift detection. This overhead isnegligible for real-world systems given the benefits. Overhead may vary across systems.",
  "C.1Details on the experimental setup": "Experimental setup. To evaluate the performance of self-healing systems, we require to manipulatethe data generating process (DGP) and ask what-if questions. Real-world datasets, while valuable,do not offer control over the DGP and come with pre-embedded biases that can implicitly affectdetection systems . In contrast, by using synthetic data to control the DGP, we can run controlledin silico experiments and perform viability studies . Furthermore, the overwhelming majority ofmodel adaptation methods are designed for tabular data (refer to Sec. 2 and Sec. A) which includesour benchmarks (see Sec. 6.1). Therefore, we simulate a diabetes prediction task . Weperfectly mimic the introduced setup in Sec. 3.1. Our goal is to predict the presence of diabetesYt {0,1} at each time point t for a set of n observations, generated according to a (changing)pre-specified DGP log ( P (Yt=1Xt)",
  "In all cases, the optimal strategy was removing a corrupted batch of data, where the amount ofcorrupted values or their extent varied": "Comments on the experimental setup of viability study I. The goal of this setup is to showcasethat blindly retraining the model or using pre-determined actions is not necessarily optimal. In thiscase, the strategy required is to understand that the model requires full re-training and some valueshave been corrupted which require careful dealing, such as adjustments or removal.",
  "Code Listing 13: An example of true corrupted probabilities": "Therefore, the KL divergence is computed between these two probability distributions. The KL is thehighest when the outputted probability distribution is uniform (first example) and the lowest whenit perfectly matches the reference/true probability distribution. It has been shown that with certaintechniques, LLMs can generally output calibrated confidence scores or probabilities . The reason why the KL-divergence decreases is because the predicted probabilties put greater relativevalue on the true corrupted value (i.e. the Age column in this example) as (i) the outlier factorincreases and as (ii) the percent of values corrupted increase. Viability Study V. We study the sensitivity of SHML adaptation policies by examining how wellactions perform based on (i) the number of corrupted values and (ii) the size of the backtesting dataset. shows this relationship. The corruption coefficient is described in the overall experimentalsetup. The size of the backtesting window is the size of the dataset used to evaluat the proposedactions. Recall that H-LLM has three adaptation actions in place: (i) generic; (ii) filtering corrupteddata slices; and (iii) training slice-specific models (Appendix B). For this experiment, we focus onactions proposed by the second adaptation strategy: filtering corrupted data slices. Each adaptationaction is an identified data slice by H-LLM that might be corrupted, the removal of which mightimprove performance. The following is an example of proposed adaptation actions by the removal ofthe following queries (each query is a separate candidate adaptation action):",
  "Such actions are proposed for each range of values corrupted and evaluated accordingly": "Viability study VI. We study the importance of the testing component (Eq. 7) by evaluating H-LLMsuggested actions with and without the testing phase (backtesting window) and comparing theiraccuracies. shows this relationship. The action with the backtesting window is the actionwhich has received the highest empirical performance on the backtesting window. In contrast, theaction proposed by no backtesting window is the action that is selected as the most likely one byH-LLM without any empirical validation. Most likely implies that after a few iteration loops, thiswas the action that was listed as the first action to perform. This showcases the usefulness of having away to filter out actions with some specific actions. We mimic the setup from study IV where eachaction is a specific subgroup to filter out to achieve better performance due to the corrupted nature ofthe data.",
  ": Adaptation strate-gies of different methods inresponse to three shifts": "Setup. We vary the warm-star criterion within drift detection methodsto evaluate the recovery time and post-intervention accuracy of H-LLM.The warm start parameter is the minimum number of samples requiredto conclude that a drift has been detected and trigger re-training or self-healing. Discussion. showcases the relationship between the warm-startparameter and the average recovery tiem and post-intervention accuracy.You see the massive increase in average covery time that jumps whenthe warm-start is set at a relatively high threshold. This results froma drift detection algoritihm detecting a false positive drift just beforethe actual drift. However, given the wwarm-star parameter, there was asignificant delay in re-triggering the self-healing system. This suggestsself-healing systems benefit from lower warm-start parameters in case thedrift detection algorithms are sensitive to false positives. This correspondswith a relative drop in the post-intervention accuracy because of the longertime it took to trigger self-healing.",
  ": The qualtiy of diagnosis based on n columns.Lower is better": "Setup. In this experiment, instead ofcorrupting a single variable which isresponsible for model degradation, wecorrupt n variables to evaluate howwell H-LLM can diagnose multiplecorrupted values at once. With eachcorrupted columns, the true corruptedprobability changes. For instance, ifthere are four columns and there is asingle corrupted column, the true cor-ruption vector is . If thereare four corrupted columns, then it is[0.25, 0.25, 0.25, 0.25]. We use theseprobabilities and compare them to thecorruption probabilities outputted byH-LLM. This is shown in . Discussion. This showcases that the more columns are corrupted, the better the predictive diagnosisbecomes. For instance, once all columns are corrupted, H-LLM outputs a uniform diagnosis becauseit has no information given the evidence observed. This exactly corresponds to the true corruptionprobability, outputting a KL of 0. We notice that the KL generally decreases with the number ofcorrupted columns for this reason.",
  "This section expands on the adaptation experiments by providing more variables and values bycorruption coefficient and the number of columns corrupted": ": Accuracy based on the number of corrupted columns, where 5% of values given a selectedcolumn are corrupted on a shifted dataset with a number of corrupted values. Higher is better. (with acorruption coefficient of 0.05) No retraining0.43 0.020.44 0.020.44 0.020.44 0.020.45 0.020.45 0.020.45 0.020.45 0.02Partially Updating0.72 0.020.71 0.020.70 0.020.69 0.020.68 0.020.67 0.020.65 0.020.54 0.06New model training0.71 0.020.70 0.020.69 0.020.69 0.020.68 0.020.67 0.020.64 0.020.50 0.02Ensemble Method0.71 0.020.70 0.020.69 0.020.69 0.020.68 0.020.67 0.020.64 0.020.50 0.02",
  "D.4Effects of Self-Healing across corruption levels": "We systematically analyze how self-healing effectiveness varies with corruption levels across ourfive datasets (Airlines, Poker, Weather, Electricity, and Forest Type). For each dataset, we varyboth the corruption value and the number of corrupted columns k, measuring accuracy with andwithout the self-healing mechanism. shows that self-healings impact grows with corruptionseverity. Specifically, as either or k increases, the gap between baseline and self-healed performancewidens. This pattern holds consistently across all datasets, though with varying magnitudes. Theseresults demonstrate that self-healing becomes more crucial as data degradation becomes more severe,providing a safety mechanism for maintaining model performance under challenging conditions. # Corrupted Cols 0.5 0.6 0.7",
  "Weather": "Self-healingNo self-healing : Effects of self-healing for five datasets as we vary the number of corrupted columnsand the corruption value. Self-healing consistently identifies corrupted columns at test time. Thistypically becomes more important as the corruption level increases (either by corruption value ornumber of corrupted columns). Baseline is not implementing a self-healing mechanism upon driftdetection.",
  "AblationAccuracy (%)Takeaway": "Baseline (no self-healing)52Accuracy is worse without self-healingFull (full self-healing)76Self-healing improves accuracy over baseline.No monitoring52Monitoring is required to trigger the SHML system. H-LLM was not triggered and no actions were proposed.No diagnosis52Diagnosis is required for proposing sensible actions. Defaults to non-sensical actions.No actions52Actions could not be implemented because they were not proposed, defaults to no behavior.No testing62Actions chosen but not tested against empirical data. A suboptimal action was chosen.",
  ": Ablation study results for H-LLM. We systematically remove one component of the systemand inspect its outputs. The takeaway represents our qualitative evaluation": "The ablation reveals that each component is crucial for effective self-healing. Removing monitoring(52% accuracy) prevents the system from triggering adaptation. Without diagnosis, the systemproposes non-sensical actions, leading to baseline performance. Removing action generation ortesting similarly degrades performance to baseline levels, though testing removal shows slightly betterperformance (62%) as some reasonable actions are still attempted, albeit without proper validation.",
  "D.7Model agnosticism": "We evaluate SHMLs effectiveness across ten different ML models to demonstrate its model-agnosticnature. shows results for models ranging from simple (e.g., Decision Trees) to complex(e.g., XGBoost), comparing various adaptation strategies. SHML consistently outperforms baselineapproaches across all model types, with improvements ranging from 11 percentage points (NaiveBayes) to 31 percentage points (LDA). This consistent improvement demonstrates that SHMLsbenefits are not tied to any particular model architecture but rather stem from its ability to reasonabout and address degradation causes.",
  "Answer: [Yes]": "Justification: Yes. We discuss this in Sec. 7. To reiterate, we believe our work can havesignificant positive effects on multiple areas within AI and have substantial practical impli-cations, as discussed in the Discussion section. This includes having immediate practicalbenefits in industries where model degradation is common, such as medicine, finance, pre-dictive policing, IoT data streams, and more. We further hope our work spurs substantialdevelopments in self-healing theory. We also discuss that the unique improvements insystems that can employ self-healing could also be misused by agents for other purposes,such as using self-healing for surveillance systems or other ethically ambiguous technolo-gies. The broader impact also subsumes future work in this area. We hope that a potentialdirection for future work is building theory around optimal diagnoses, optimal adaptationstrategies, as well as scaling larger algorithms.",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  "Guidelines:": "The answer NA means that there is no societal impact of the work performed. If the authors answer NA or No, they should explain why their work has no societalimpact or why the paper does not address societal impact. Examples of negative societal impacts include potential malicious or unintended uses(e.g., disinformation, generating fake profiles, surveillance), fairness considerations(e.g., deployment of technologies that could make decisions that unfairly impact specificgroups), privacy considerations, and security considerations. The conference expects that many papers will be foundational research and not tiedto particular applications, let alone deployments. However, if there is a direct path toany negative applications, the authors should point it out. For example, it is legitimateto point out that an improvement in the quality of generative models could be used togenerate deepfakes for disinformation. On the other hand, it is not needed to point outthat a generic algorithm for optimizing neural networks could enable people to trainmodels that generate Deepfakes faster. The authors should consider possible harms that could arise when the technology isbeing used as intended and functioning correctly, harms that could arise when thetechnology is being used as intended but gives incorrect results, and harms followingfrom (intentional or unintentional) misuse of the technology. If there are negative societal impacts, the authors could also discuss possible mitigationstrategies (e.g., gated release of models, providing defenses in addition to attacks,mechanisms for monitoring misuse, mechanisms to monitor how a system learns fromfeedback over time, improving the efficiency and accessibility of ML).",
  ". Licenses for existing assets": "Question: Are the creators or original owners of assets (e.g., code, data, models), used inthe paper, properly credited and are the license and terms of use explicitly mentioned andproperly respected?Answer: [Yes]Justification: We cite and refer to all appropriate codebases that are employed as benchmarks.Guidelines: The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  ". New Assets": "Question: Are new assets introduced in the paper well documented and is the documentationprovided alongside the assets?Answer: [Yes]Justification: The core assets, including the framework and the algorithm, are clearlydescribed.Guidelines: The answer NA means that the paper does not release new assets. Researchers should communicate the details of the dataset/code/model as part of theirsubmissions via structured templates. This includes details about training, license,limitations, etc.",
  "According to the NeurIPS Code of Ethics, workers involved in data collection, curation,or other labor should be paid at least the minimum wage in the country of the datacollector": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA]Justification: The paper does not involve crowdsourcing nor research with human subjects.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}