{
  "Abstract": "Evaluating the performance of deep models in new scenarios has drawn increasingattention in recent years due to the wide application of deep learning techniques invarious fields. However, while it is possible to collect data from new scenarios, theannotations are not always available. Existing Domain Adaptive Object Detection(DAOD) works usually report their performance by selecting the best model on thevalidation set or even the test set of the target domain, which is highly impracticalin real-world applications. In this paper, we propose a novel unsupervised modelselection approach for domain adaptive object detection, which is able to selectalmost the optimal model for the target domain without using any target labels. Ourapproach is based on the flat minima principle, i.e., models located in the flat min-ima region in the parameter space usually exhibit excellent generalization ability.However, traditional methods require labeled data to evaluate how well a model islocated in the flat minima region, which is unrealistic for the DAOD task. There-fore, we design a Detection Adaptation Score (DAS) approach to approximatelymeasure the flat minima without using target labels. We show via a generalizationbound that the flatness can be deemed as model variance, while the minima dependon the domain distribution distance for the DAOD task. Accordingly, we propose aFlatness Index Score (FIS) to assess the flatness by measuring the classificationand localization fluctuation before and after perturbations of model parametersand a Prototypical Distance Ratio (PDR) score to seek the minima by measuringthe transferability and discriminability of the models. In this way, the proposedDAS approach can effectively represent the degree of flat minima and evaluate themodel generalization ability on the target domain. We have conducted extensiveexperiments on various DAOD benchmarks and approaches, and the experimentalresults show that the proposed DAS correlates well with the performance of DAODmodels and can be used as an effective tool for model selection after training. Thecode will be released at",
  "Introduction": "With the explosion of deep neural networks , object detection hasachieved promising results and shown great potential in many downstream tasks such as autonomousdriving , video understanding , robot navigation , etc. However, the well-trainedobject detection models frequently face previously unseen domains in real-world scenarios and oftensuffer from dramatic performance degradation when being deployed in a novel domain . This isbecause the training set (i.e., source domain) and the test set (i.e., target domain) have distinct domaindistributions. To address this problem, Domain Adaptive Object Detection (DAOD)",
  "DAS": ": (a) The performance of classic DAOD method AT on Real-to-Art (P2C) adaptationtask during training. It suffers from performance degradation as the training goes on. The proposedDAS outperforms previous unsupervised model evaluation methods and selects desirable checkpointswithout accessing any labels in the target domain. (b) The motivation of the work. We propose aDetection Adaptation Score including a Prototypical Distance Ratio (PDR) score and Flatness IndexScore (FIS) to evaluate the model performance in an unsupervised way. It can be a good substitutemetric for using annotations for DAOD model evaluation.",
  "has been proposed to transfer the knowledge from the labeled source domain to an unlabeled targetdomain by leveraging adversarial training or pseudo-labeled approaches": "Although effective, these DAOD methods evaluate the detector performanceand conduct model selection relying on the labeled target data, which is usually unavailable andimpractical for real-world domain adaptation scenarios. Due to the natural complexity of objectdetection, DAOD methods that leverage adversarial training and self-training techniques are oftenunstable and prone to overfitting to the target domains. As shown in (a), DAOD methodsusually suffer from a performance drop during training (marked as purple in (a)). These issueslimit the application of the DAOD model in real-world scenarios. Therefore, it is urgent and desirableto develop an unsupervised model selection method for DAOD, as shown in (b). Regarding the unsupervised model selection, several seminal works attempt to evaluatethe models from different aspects. For example, TS examines the spatial uniformity of theunsupervised domain adaptive classifier, as well as the transferability and discriminability of deeprepresentation. ATC learns a threshold on the confidence of the model and predicts accuracyas the fraction of unlabeled examples for which model confidence exceeds that threshold. In objectdetection, however, the evaluation involves not only classification but also precise localization ofobjects within an image. This crucial distinction renders these methods ineffective in fully assessingan object detection model. A recent work proposes a BoS metric to evaluate the generalizationof the detection model by measuring the stability of the box under feature dropout. However, it doesnot consider the domain discrepancy between the source and the target domain, making the metricunreliable for DAOD model selection (see (a) and our experiments in Sec. 4.2). In this paper, we propose a novel Detection Adaptation Score (DAS) to evaluate the DAOD modelswithout accessing any target labels, enabling select almost the optimal model for the target domainin an unsupervised way. The proposed DAS is based on the flat minima principles, i.e., models thatare located in the flat minima region in the parameter space exhibit better generalization ability thanthat in sharp minima region . However, the traditional flat minima search method requireslabeled data to evaluate how well a model is located in the flat minima region, which is unrealisticfor DAOD tasks. Therefore, we investigate how to measure the flat minima approximately withoutusing target labels. We derive a generalization error bound that shows the flatness can be deemedas model variance, while the minima depend on the domain distribution distance for the DAODtasks. Therefore, we first propose a Flatness Index Score (FIS) to assess the flatness by observing theclassification and localization fluctuation before and after perturbations of model parameters. Then,we propose a Prototypical Distance Ratio (PDR) score to seek the minima models by measuring thetransferability and discriminability of the models in the target domain. To this end, the proposedDAS can effectively represent the degree of flat minima for DAOD models and evaluate the modelperformance on the target domain. To evaluate the effectiveness of the proposed DAS, we conductextensive experiments on public DAOD benchmarks, including weather adaptation, real-to-art, andsynthetic-to-real adaptation. The experimental results show that the proposed metric can effectivelyevaluate the performance of DAOD models without annotating the target domain.",
  "With the pressing need for the application of DAOD in real-world scenarios, to our bestknowledge, we are the first to evaluate the DAOD models without using target labels": "We propose a novel Detection Adaptation Score (DAS) by seeking the flat minima withoutusing any target labels to evaluate the performance of DAOD models on the target domain.A Flatness Index Score (FIS) and a Prototypical Distance Ratio (PDR) score are proposed tomeet the requirements of flatness and minima, respectively. We have conducted extensive experiments on several DAOD benchmarks and approaches.Our DAS benefits from selecting the optimal checkpoints of model parameters to avoidnegative transfer or pseudo-label error accumulation. The experimental results validate theeffectiveness of the proposed DAS.",
  "Related Work": "Object Detection. Object detection is a fundamental task in computer vision thatinvolves identifying and locating multiple objects within an image or video. The object detectionapproaches can be roughly divided into two categories: one-stage and two-stage. The one-stagemethods directly estimate the categories and the location of the objects, such asFCOS , CenterNet , and YOLO series . The two-stage methods first generateregion proposals for objects and then classify the category and regress the bounding box coordinatesbased on the proposal features, e.g., Faster RCNN and Cascade RCNN . Recently, an end-to-end object detection model based on Transformer (i.e., DEtection TRansformer, DETR) hasbeen proposed to eliminate the complex anchor generation and post-processing operations such asnon-maximum suppression (NMS). Many successive works further improve the trainingefficiency and accuracy of DETR. With the strong representation of deep neural networks, the objectdetection model has achieved promising results in many object detection benchmarks. However,these models usually suffer from performance degradation because of the domain discrepancybetween the training and testing domains. Domain Adaptive Object Detection. Domain Adaptive Object Detection (DAOD) aims to transfer knowledge from the labeled source domain to an unlabeled targetdomain. Previous works can be roughly categorized into two aspects: domain alignment and self-training. The domain alignment directly minimizes the domain discrepancy betweenthe source and target domains. They minimize the feature distribution mismatch via adversarialtraining , prototype alignment , graph matching , etc. The self-trainingapproaches follow a Mean Teacher (MT) framework and generate pseudo-labelsfrom the teacher network to supervise the training of the student network. UMT leveragesthe style transfer algorithm to eliminate the MT model bias towards the source domain. AdaptiveTeacher (AT) combines adversarial training and self-training to improve the accuracy on thetarget domain. CMT introduces contrastive learning to improve the instance feature representation.HT reveals that the consistency between classification and localization is crucial for pseudo-labelgeneration and proposes a reweight strategy based on the harmony measure between the classificationand localization. While effective, these approaches evaluate the modelperformance relying on labeled target data, which is not always available in real-world scenarios.Therefore, we propose a Detection Adaptation Score (DAS) to evaluate the model performance in anunsupervised manner, enabling the application of DAOD models in real-world scenarios. Unsupervised Model Selection (UMS) for UDA. Unsupervised Model Selection for UDA evaluatesmodel performance in the target domain without involving annotations. Some previous works seek to predict model performance in OOD scenarios. PS , ATC leveragethe prediction confidence, and estimate from the perspective of entropy. DEV estimatesand decreases the target risk by embedding adapted feature representation while validation. TS examines the spatial uniformity of the classifier, as well as the transferability and discriminabilityof deep representation. However, they mainly focus on classification tasks. For object detection,the BoS estimates the detection performance via the stability of bounding boxes with featuredropout but does not consider the domain discrepancy, which is vital for DAOD methods. To this end,we introduce the Detection Adaptation Score (DAS), which consists of a Flatness Index Score (FIS)and a Prototypical Distance Ratio (PDR) score by seeking a flat minima model in the target domain.",
  "Method": "In the DAOD task, we are given a labeled source domain, which includes images annotated withbounding boxes and class labels, and an unlabeled target domain containing only unlabeled images.Let us denote Ds = {(xsi, ysi)}Nsi=1 drawn from a data distribution Ps as the labeled source domainand Dt = {xtj}Ntj=1 drawn from a data distribution Pt as the unlabeled target domain. DistributionsPs and Pt are related but different domains, i.e., (Ps = Pt). In other words, they have distinctdomain shifts. And ysi = {(bsij, csij)|mij=1}, where bsij R4 and csij {1, . . . , K} are the boundingbox and corresponding category for each object, and mi is the total number of objects in an imagexsi. The goal of the DAOD approach is to learn an object detection model that performs well on thetarget domain from both the labeled source and unlabeled target domains. In this work, we considerthe model selection for DAOD approaches. In particular, there are M models F = {f l|Ml=1} fromdifferent epochs or iterations. Our goal is to propose a proper metric for model evaluation in anunsupervised manner that can reflect the detection performance (i.e., mAP) of the DAOD models. In the following, we first introduce the domain adaptation generalization bound with flat minima inSec. 3.1. Then, we will introduce our Detection Adaptation Score (DAS) in detail, which consists ofa Flatness Index Score (FIS) in Sec. 3.2 and a Prototypical Distance Ratio (PDR) score in Sec. 3.3.",
  "Domain Adaptation Generalization Bound with Flat Minima": "In this paper, we propose a novel unsupervised model selection approach for the DAOD task, whichcan almost select the optimal checkpoint for the target domain. Our approach is based on theassumption that flat minima exhibit better model generalization than sharp minima, which has beenevidenced by many literatures . The model parameters at flat minima will have smaller changesof loss values within its neighborhoods than sharp minima. To find flat minima, traditional methodsrequire labeled data, which is unrealistic for DAOD. As the target labels are unavailable for modelevaluation in DAOD scenarios, we cannot directly find the flat minima. To this end, we derive ageneralization error bound as follows:Theorem 1. Given any 0, exist hypothesis h H where H is the hypothesis set, h denotes theparameters of h. Given any hypothesis h {h|h H, h h2 }, which is located in theneighborhood of h with radius > 0, the following generalization error bound holds with at least aprobability of 1 , ET (h) |ET (h) ET (h)| + ES(h) + dis(S, T ) + ,(1)where dis(S, T ) is the distribution mismatch between the source domain S and target domain T .ES(h) is the risk of h on the source domain. is a constant term. Proof is provided in the appendix. The generalization bound shows that in addition to the constant term , the risk for the targethypothesis h around by h with -ball radius can be bounded by three terms: the flatness, i.e., thedifference between the original h and neighborhood h of h, the error on the source domain Ds, andthe distribution distance between the source and target domains. Usually, the error on source ES(h)can be minimized with the labeled source samples. To this end, one can minimize the first and thirdterms to find the flat minima. From the analysis in Theorem 1, the flatness can be deemed as model variance, while the minimadepends on the domain distribution distance for DAOD task. Accordingly, we propose a FlatnessIndex Score (FIS) to assess the flatness by measuring the classification and localization fluctuationbefore and after perturbations of model parameters, and a Prototypical Distance Ratio (PDR) score toseek the minima by measuring the transferability and discriminability of the models. In this way, theproposed DAS approach can effectively represent the degree of flat minima and evaluate the modelgeneralization ability on the target domain.",
  "Flatness Index Score": "In this subsection, we introduce the Flatness Index Score (FIS), which assesses the flatness of themodel parameters by measuring the variance in outputs before and after parameter perturbations. Forobject detection, we calculate the variance of both classification and localization predictions. For theproperty of minima on the target domain, we introduce it later in Sec. 3.3. Specifically, let denote the radius of the parameter space. We can then obtain the neighbor modelf(; ) by adding a perturbation to the original parameter , i.e., + . We control ofthe perturbation as a constant (i.e., = ), thus the neighbor model f(; ) lies on a fixed radiussphere of the original model f(; ).",
  "We measure the prediction correspondence between the original and neighbor models. Given aninput target domain image xi, the original model predicts {(bj, pj)|nij=1} as the neighbor model": "predicts {(bj, pj)|nij=1}, where bj is the bounding box and pj is the probability vector of the j-thinstance. We use djj(f(xi; )) to represent the matching cost of the j-th and j-th object intwo models predictions on image xi. As the model predictions has results from both regressionand classification branches, the matching cost djj contains the divergence of bounding boxes andclassification probability vectors as follows:",
  "Prototypical Distance Ratio": "To facilitate the search for flat minima, we explore methods to identify minima regions in thetarget domain. In DAOD, the model with better transferability and discriminability would performwell on the target domain. There are many methods to evaluate the domain distance between thesource and target domains, for example, Maximum Mean Discrepancy (MMD) and ProxyA-distance (PAD) . However, simply measuring the image feature distribution is not feasibleto reflect the transferability of the detection model. Meanwhile, the traditional discriminabilitymetrics such as entropy , and mutual information also fail to effectively correlate the modelperformance. In this paper, we consider the class prototype distance of instances in images acrossdomains to evaluate the transferability and discriminability of the DAOD models. The class prototypeof instances is the center of a specific class and aggregates the instance information from the samples.In unsupervised domain adaptation, prototype-based domain alignment is comprehensively studiedin the literature and attempts to narrow the distance between prototypes of the samecategories of two domains, showcasing the effectiveness of prototype alignment. Now, we show how to leverage prototype distance to effectively evaluate the transferability anddiscriminability of the DAOD models. Our prototype is calculated based on the instance feature, e.g.,the proposal feature in Faster RCNN. In particular, we denote the instance feature as Fij Rd forthe j-th instance in the i-th image and the final classification probability vector as pij. The prototypeof the k-th class Pk Rd for the target domain can be calculated softly as follows:",
  "where (P, P ) =1": "K2KKk=k Mkk(P, P ) is a function to calculate distance among differentcategories. Combine the intra-category distance and inter-category distance into our PrototypicalDistance Ratio (PDR) score as follows:PDR = dinter/dintra.(7)The proposed PDR score can be an effective metric to evaluate the transferability and discriminabilityof the DAOD models. The higher PDR score indicates that the instance features of detection modelshave better properties with large inter-category distances and small intra-category distances.",
  "Benchmarks. We follow previous works and evaluate the effectiveness of the proposedDAS on the following adaptation scenarios:": "Real-to-Art Adaptation (P2C): In this scenario, we test our proposed method with domainshift between the real image domain and the artistic image domain. Following , wechoose the PASCAL VOC 2007/2012 and Clipart1k as the source and target domains,respectively. PASCAL VOC is a widely used benchmark in the object detectioncommunity. We use the 2007 and 2012 versions of PASCAL VOC that contain about 15kimages with instance annotations for 20 object classes. Clipart1k contains 500 trainimages and 500 testing images in clipart style, annotated with bounding boxes for the same20 object categories as in the PASCAL VOC. Weather Adaptation (C2F): In real-world scenarios, such as autonomous driving systems,object detectors may encounter various weather conditions. We study the adaptation fromnormal to foggy weather. In particular, we use the Cityscapes and Foggy Cityscapes as thesource and target domains, respectively. Cityscapes contains a diverse set of urbanstreet scenes captured from 50 cities and 2, 975 training images and 500 validation images,annotated for 8 object classes. Foggy Cityscapes is a variant of the Cityscapes datasetwhere synthetic fog is added to the images to simulate adverse weather conditions. Theannotations remain consistent with the original Cityscapes dataset. Note that we choose theworst foggy level (i.e., 0.02) of Foggy Cityscapes in the experiment following . Synthetic-to-Real Adaptation (S2C): Synthetic images offer an alternative solution foraddressing the data collection and annotation issues. However, there is a distinct distributionmismatch between synthetic images to real images. To adapt the synthetic to the realscenes, we utilize Sim10k as the source domain and Cityscapes as the target domain.Sim10k consists of 10,000 synthetic images generated from a simulation environment,with annotations for car bounding boxes. Because only the car is annotated in both domains,we report the AP of car in the validation set of Cityscapes.",
  "Oracle17.49 35.75 47.83 40.82 29.17 47.51 49.26 49.36 45.09 55.41 47.44 55.5343.39": "DAOD Frameworks. In this work, we test our method on four classical DAOD models in the twomain DAOD streams (i.e., adversarial training and self-training): DA Faster RCNN (DAF) , Mean-Teacher (MT) , Adaptive Teacher (AT) , Contrastive Mean-Teacher (CMT) . DAF is a typical DAOD framework extending the Faster RCNN architecture by incorporating domainadaptation techniques. It employs adversarial training to align the feature distribution across domainsat both image and instance levels. MT leverages a teacher-student paradigm to generate pseudolabels to provide extra supervision for the student model on the target domain. The teacher modelis an exponential moving average (EMA) of the student model and thus can provide more accuratepseudo-labels for the student model. This approach helps in leveraging unlabeled data by enforcingconsistency between the predictions of the teacher and student models. AT improves uponthe Mean-Teacher framework by employing an adversarial learning module to align the featuredistributions across two domains, reducing domain bias and improving pseudo-label quality. CMT enhances the Mean-Teacher framework with contrastive learning techniques by encouraging similarinstances to be closer in the feature space while pushing the features of dissimilar instances apart. Unsupervised Model Selection Baselines. Existing unsupervised model selection methods for UDAtasks are mainly based on classification tasks, such as Prediction Score (PS) , Entropy Score(ES) , Average Threshold Confidence (ATC) , Transfer Score (TS) . We reproduce theseapproaches on the classification branch of object detection models. Besides, we also use the FrchetDistance (FD) to measure the domain distance on backbone features as a compared method.Bounding Box Stability (BoS) is introduced to tackle unsupervised model evaluation problemsspecifically for object detection networks. It evaluates the model generalization of the detectionmodel by probing the bounding box stability under feature dropout. Implement Details. Following previous works , we choose one of the representative detectionframeworks Faster RCNN as our base detector. We followed the instructions from the releasedcode of the DAOD methods and reproduced their results. The hyperparameters, learning rates, andoptimizers are set according to the default configurations provided in the original papers. We set ourhyperparameters = 1 and = 1 in all experiments, which perform well on all the benchmarks.Our implementation is built upon the Detectron2 detection framework. We have added a detailedimplementation in the appendix.",
  "Main Results": "Checkpoint Selection after Training. Checkpoint selection after training is pivotal for the applicationof DAOD approaches in real-world scenarios since the DAOD models usually suffer from negativetransfer and overfitting the target domain during training. For example, on the real-to-art adaptation(P2C), AT drops 5.85% from the highest mAP (47.83%) to the last checkpoint (41.98%). Thedetailed results on checkpoint selection, with the highest DAS, after training are listed in .Compared with the last checkpoint, the proposed method works well on almost all the DAOD methods.For example, the proposed method for AT achieves 5.85%, 1.1%, and 19.09% improvementsin terms of mAP on real-to-art, weather, and synthetic-to-real adaptations, respectively. Theseexperimental results demonstrate that the proposed method can choose a reliable checkpoint and thusavoid the negative transfer and overfitting on the target domain during training. Moreover, we compare our method with the recent unsupervised model evaluation methods in ,showing that our method consistently outperforms all the compared baselines. For instance, ourmethods outperform recent works TS and BoS by 2.42% and 3.60% mAP on average,respectively. These results demonstrate the effectiveness of the proposed method in choosing theoptimal checkpoints. We also present the correlation between unsupervised model evaluation metricsand the ground truth mAP (i.e., using the annotations in the target domain to evaluate the model) in. It is clearly shown that the previous methods give higher scores as the training goes on andfail to correlate with the performance of DAOD checkpoints. In contrast, the proposed DAS scorecorrelates well with the performance of DAOD checkpoints (i.e., 0.86 PCC).",
  "Further Analysis": "Ablation Study. We conduct the ablation study of the proposed method by isolating DAS into separatemetrics. In particular, we conduct experiments on three benchmarks and use four DAOD methodsincluding DAF , MT , AT , and CMT . We summarize the results in . Theexperimental results indicate that the proposed PDR score and FIS evaluate the model performancewithout labels effectively. In particular, the PDR score and FIS select checkpoints with mAP 42.14%and 41.74%, PCC 0.64 and 0.48, respectively. DAS combines them and further improves theirperformance to 42.52% mAP and 0.67 PCC, demonstrating the synergy effect among them. Hyperparameter Sensitivity. We investigate the sensitivity of the hyperparameter controllingthe weight of PDR for DAS on real-to-art adaptation (P2C). The results are summarized in . = 1.0 achieves the best average results. From a wide range of , DAS has relatively stable results.",
  "Conclusion": "In this work, we propose a novel metric named Detection Adaptation Score (DAS) by seekingflat minima to evaluate the domain adaptive object detection models without involving any targetlabels. The proposed DAS consists of a Flatness Index Score (FIS) and a Prototypical DistanceRatio (PDR) score and can find flat minima of DAOD models in an unsupervised way. Extensiveexperiments have been conducted on public DAOD benchmarks for several classical DAOD methods.Experimental results indicate that the proposed DAS correlates well with the performance of thedetection model and thus can be used for checkpoint selection after training. The proposed methodfosters the application of DAOD methods in the real-world scenario. We hope that our work willinspire researchers and contribute to advancing research in DAOD.",
  "Chaoqi Chen, Zebiao Zheng, Xinghao Ding, Yue Huang, and Qi Dou. Harmonizing transferability anddiscriminability for adapting object detectors. In CVPR, pages 88698878, 2020": "Jiefeng Chen, Frederick Liu, Besim Avci, Xi Wu, Yingyu Liang, and Somesh Jha. Detecting errors andestimating accuracy on unlabeled data with self-training ensembles. Advances in Neural InformationProcessing Systems, 34:1498014992, 2021. Meilin Chen, Weijie Chen, Shicai Yang, Jie Song, Xinchao Wang, Lei Zhang, Yunfeng Yan, Donglian Qi,Yueting Zhuang, Di Xie, et al. Learning domain adaptive object detection with probabilistic teacher. ICML,2022.",
  "A.1Proofs of Theorem 1": "Theorem 1. Given any 0, exist hypothesis h H where H is the hypothesis set, h denotesthe parameters of h. Given any hypothesis h {h|h H, h h2 } located in theneighborhood of h with radius > 0, the following generalization error bound holds with at least aprobability of 1 ,",
  "A.2More Implementation Details": "Training and Evaluating Details. In our experiment, all the DAOD models are trained according tothe default setting specified in their original papers and the open-source codebases. For DA FasterRCNN, we train it on the three benchmarks with a VGG-16 backbone pre-trained on ImageNet,using a batch size of 4. For Mean Teacher, Adaptive Teacher, and Contrastive Mean Teacher, we trainthe models with a pre-trained ResNet-101 backbone on ImageNet for the real-to-art adaptationsetting, and with a pre-trained VGG-16 backbone for the weather adaptation and synthetic-to-realadaptation settings. The batch size of AT, MT, and CMT are set to 8. Training is conducted on fourRTX 3090 GPUs or two A100 GPUs according to the computational requirements of different DAODmethods. For all the results, we report the mean Average Precision (mAP) at the IoU threshold of 0.5. Detection Adaptation Score. For the Flatness Index Score (FIS), we perturb the detector modelby adding a normalized random direction for all the model parameters including the backbone anddetection head. For the Prototypical Distance Ratio (PDR) score, we use the features of the regionproposals and the corresponding predicted probability (including background) from the classificationbranch of the detection head to aggregate the information. In our implementation, L2 distance is usedas the prototype distance.",
  "A.3More Experimental Results": "Top3 Checkpoint Selection Results after Training We summarize the top3 checkpoint selectionresults in . We can observe that with more loose selection condition, our method stilloutperforms other unsupervised model selection methods by a large margin. These results furtherdemonstrate the effectiveness of the proposed DAS in select optimal checkpoints for DAOD methods.",
  ": The performance gap among the last checkpoint, our DAS, and Oracle checkpoint. (a)real-to-art adaptation, (b) the weather adaptation, and (c) the synthetic-to-real adaptation": "Performance Gap between Last Checkpoint and Oracle Model. In , we compare the DASselection results between the last checkpoint and the Oracle checkpoint (i.e., using the ground-truthlabels in the target domain to evaluate the model performance) of various frameworks and benchmarks.It shows that there is a significant performance gap between them, making it urgent to design aneffective method for unsupervised model selection in DAOD scenarios. In this paper, we proposeDAS by seeking the flat minima of the DAOD models. From , we can observe that the proposedDAS shows promising unsupervised model selection results. While our method has made progresscompared to others, there is still room for further improvement. More Visual Correlation Results. We show the correlation comparison results in under thereal-to-art adaptation using MT . Overall, our DAS correlates well with the detection performanceand outperforms the previous method. It is worth noting that the compared method cannot figure outthe overfitting issue while our method successfully reflects it. More Unsupervised Model Selection Results. The DAS can select models on other DA methods andtasks. 1) We also conducted our method on SIGMA++ on weather adaptation, which minimizesthe domain gap by graph matching. DAS chooses a checkpoint at 41.7% mAP (which is the oracle),while the last checkpoint reaches 39.5% mAP. 2) For prototype-based DAOD methods. The DASincludes FIS and PDR derived from the generalization bound. It can evaluate DAOD models fromdifferent aspects. Some existing works like GPA use the prototype-based alignment method tominimize the domain gap between domains. However, the prototype estimation in existing worksonly utilizes samples in a mini-batch during the model training. In contrast, our DAS uses the entiredataset to estimate the prototypes, which is more robust and has better generalization ability. To verifythis, we experimented on Synthetic-to-Real adaptation for GPA . The DAS chooses a checkpointat 45.8% mAP (the oracle is 47.0%) while the last checkpoint reaches 43.1%. Our proposed methodstill works when DAOD frameworks also optimize the prototype-based distance. 3) For other DAtasks. Our method can also work on other DA tasks, such as semantic segmentation. We conductedour DAS on the well-known DAFormer method on GTA5 to Cityscapes Adaptation. It is shownthat our DAS can choose a better checkpoint of the model with an average mIoU of 64.2% while thelast checkpoint of the model only achieves 60.9% and the oracle checkpoint is at 65.9%.",
  "A.4Limitation": "Although our method outperforms many unsupervised model evaluation methods in many DAODbenchmarks and methods, it still has considerable room for improvement. There are certain scenarioswhere our proposed method faces limitations, such as the inability to consistently select the bestcheckpoint and a lack of sufficient correlation between the proposed DAS and the ground truthdetection performance of DAOD models on the target domain. To address these limitations, we couldconsider incorporating a more fine-grained distribution alignment metric to evaluate the distanceacross domains. On the other hand, we can explore methods that extend beyond the constraintsof labeled data by leveraging few-shot labeled data in the target domain to help model evaluation.Another limitation is that our method requires the entire dataset of the source and target domains tocalculate the evaluation score. It would be beneficial to develop a more data-efficient approach thatcan effectively evaluate the performance of DAOD models while minimizing the data requirements.",
  "MethodsDAFMTATCMT DAFMTATCMT DAFMTATCMT": "Last Ckpt.15.72 34.25 41.98 40.11 28.27 45.74 48.16 48.46 43.05 54.85 28.35 42.3539.27PS17.32 34.25 43.93 40.11 29.17 47.51 48.69 48.46 43.05 55.29 32.56 50.4340.90ES17.49 34.25 43.95 40.11 29.01 46.95 48.69 49.15 44.33 55.29 32.56 44.6640.54ATC (th=.3)17.32 34.25 43.93 40.11 29.17 47.51 48.69 48.46 43.05 55.29 32.56 50.4340.90ATC (th=.4)17.49 34.25 43.93 40.11 29.17 47.51 48.69 48.46 43.05 55.29 32.56 50.4340.91ATC (th=.95) 17.32 34.25 43.93 40.11 29.01 46.95 48.69 48.49 43.05 55.29 32.56 50.4340.84FD14.70 33.93 45.18 40.11 29.17 47.51 48.69 48.46 45.09 55.41 47.44 44.6641.70TS17.16 34.92 45.94 40.05 29.17 47.51 48.69 49.36 44.73 55.14 31.17 50.4341.19BoS16.38 34.25 43.93 40.11 22.01 44.74 49.26 48.31 45.07 55.29 32.56 55.2140.59",
  "A.5Societal Impact": "Our Detection Adaptation Score (DAS) method has the potential to positively impact various down-stream systems, such as autonomous driving and embodied AI. These systems frequently encounterpreviously unseen domains in real-world scenarios, and our method effectively addresses the unsuper-vised evaluation problem of domain adaptive object detection methods. However, it is important toacknowledge that the application of our method may also introduce potential negative impacts. Forexample, when applied to surveillance videos and medical images, privacy concerns may arise. It isessential to understand that these issues are not inherent to the technology itself but rather depend onthe responsible and ethical use by human beings."
}