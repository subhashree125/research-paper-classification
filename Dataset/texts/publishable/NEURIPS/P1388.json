{
  "Abstract": "One-shot Federated learning (FL) is a powerful technology facilitating collaborativetraining of machine learning models in a single round of communication. While itssuperiority lies in communication efficiency and privacy preservation compared toiterative FL, one-shot FL often compromises model performance. Prior researchhas primarily focused on employing data-free knowledge distillation to optimizedata generators and ensemble models for better aggregating local knowledgeinto the server model. Prior research has primarily focused on employing data-free knowledge distillation to optimize data generators and ensemble modelsfor better aggregating local knowledge into the server model. However, thesemethods typically struggle with data heterogeneity, where inconsistent local datadistributions can cause teachers to provide misleading knowledge. Additionally,they may encounter scalability issues with complex datasets due to inherent two-step information loss: first, during local training (from data to model), and second,when transferring knowledge to the server model (from model to inversed data).In this paper, we propose FedSD2C, a novel and practical one-shot FL frameworkdesigned to address these challenges. FedSD2C introduces a distiller to synthesizeinformative distillates directly from local data to reduce information loss andproposes sharing synthetic distillates instead of inconsistent local models to tackledata heterogeneity. Our empirical results demonstrate that FedSD2C consistentlyoutperforms other one-shot FL methods with more complex and real datasets,achieving up to 2.6 the performance of the best baseline. Code:",
  "Introduction": "Federated learning (FL) has emerged as a cutting-edge technology that enables training a globalmodel across multiple clients without sharing their raw data . Original FL requires multiplecommunication rounds for exchanging information between clients and servers. While this paradigmyields a better global model by frequent communication, such high communication costs along withthe risk of connection drop errors make it impractical and intolerable in real-world FL applications . Moreover, frequent communication poses security risks such as man-in-the-middle attacks and privacy concerns . To address these issues, one-shot FL has been proposed, requiring only a single communicationround, significantly reducing communication costs and concurrently diminishing vulnerability tomalicious interception. Due to one communication round property, One-shot FL can also be easilyscaled up to large-scale client scenarios, especially for cross-device settings . Despite its sufficientbenefits, the limitation of a single communication round makes one-shot FL fall short in accuracycompared to conventional multiple-round FL.",
  "Bad samples": ": Illustration of issues in one-shot FL based on DFKD: (1) Information loss occurs duringthe transfer from local data to the model and from the model back to the inversed data. (2) t-SNEplots of feature distributions of data generated by DENSE(left ), Co-Boosting(middle ), and ourFedSD2C(right ). We randomly select five different classes (indicated by different colors) of realand synthetic data from Tiny-ImageNet. Bad samples are data generated by the DFKD-based methodthat deviates from the distribution of local real data. To facilitate effective knowledge transfer from client models to the server model within a singleround, most previous one-shot FL methods have focused on knowledge distillation.Early approaches use knowledge distillation to transfer knowledge from an ensemble ofclient models to the server model. While effective, these methods often require additionalpublic datasets, which can be cumbersome or unfeasible in real-world scenarios . Alternatively,data-free knowledge distillation (DFKD) is introduced to avoid the need for public datasets. Forexample, DENSE employs Generative Adversarial Networks (GANs) as data generators andan ensemble of client models as a discriminator to synthesize diverse data for knowledge transferto server model in a data-free manner. Co-Boosting extends DENSE by proposing a mutuallyreinforcing approach to enhance synthetic data and the ensemble model for server training. Nevertheless, such a method of generating data implies two-tier information loss. First, due to modelcapacity limitations, client models may struggle to encapsulate all information about local data,affecting the quality of the generated data. Second, the generated data do not fully represent theinformation within the model, as they are produced from random noise without explicit guidance.Therefore, some classes of synthetic data cannot have similar feature distributions to the original realdata, as depicted in . Moreover, data heterogeneity in FL can result in inconsistent andmisleading predictions from local models , which has been shown to hinder knowledge distilla-tion . Consequently, the server model trained on such noisy and information-lossy generateddata typically suffers significant performance degradation, particularly on complex datasets . In this paper, we propose FedSD2C (One-shot Federated Learning via Synthetic Distiller-DistillateCommunication), a novel and practical one-shot FL framework that introduces a pre-defined distillerfor informative, privacy-enhanced, and communication-efficient distillate communication. In specific,FedSD2C first adopts a V-information based Core-Set selection method to distill the localdataset into an informative Core-Set. By capturing the diversity and realism through V-information,the distilled Core-Set fully encapsulates the information of the local data domain for training arobust server model. However, directly transmitting the Core-Set, which may include the originalsamples, poses potential privacy risks and incurs significant communication costs, especially for high-resolution images. In this regard, FedSD2C employs two techniques to further distill the Core-Setinto distillates, thereby enhancing privacy and reducing communication costs: 1) Utilizing Fouriertransform perturbation to alter the amplitude components of the Core-Set samples for distillateinitialization, enhancing privacy while retaining semantic content; 2) Employing a pre-trainedAutoencoder provided by the server as a distiller to distill the perturbed Core-Set into distillatesand optimizing its V-information to be as close as possible to original Core-Set, thus minimizinginformation loss. Finally, clients transmit synthetic distillates to the server instead of inconsistent models for knowledge transfer. Compared to generating noisy knowledge from inconsistent clientmodels with two-tier information loss, end-to-end distillate synthesis minimizes information lossand their aggregation mitigates the impact of data heterogeneity. Through extensive experimentsover various real-world datasets , we show that our proposed method significantly surpasses thegenerated-based one-shot FL methods. The contributions of this paper are:",
  "One-shot Federated Learning": "One-shot federated learning was first proposed by , which introduces a method to aggregatea server model by distilling knowledge from an ensemble of client models using public datasets.FedKT propose a hierarchical knowledge transfer framework, enabling various types of classi-fication models. While their approaches demonstrate promising results, the requirement of publicdatasets which is inaccessible for privacy or transmission reasons limits their practical applications.To address the limitations associated with public datasets, DENSE introduces a DFKD processutilizing an additional data generator trained on the ensemble model. Considering the challenge ofhigh statistical heterogeneity, FedCVAE proposes replacing the local training task with trainingconditional Variation Autoencoders. Furthermore, Co-Boosting aims to enhance the perfor-mance of both the data generator and the ensemble model through a two-tier process. Despite theseadvancements, generating data through DFKD involves a two-tier information loss. Simultaneously,the inconsistency among client models due to data heterogeneity , further degradesthe quality of generated data, introducing label noise and thus limiting the performance of the servermodel. In this work, we tackle these problems from the perspective of sharing synthetic distillates.By utilizing Core-Set selection and pre-trained Autoencoders as distillers, our proposed methodsdistill diverse and informative data for server training.",
  "Dataset Distillation in Federated learning": "Dataset Distillation (DD) was first introduced by , aiming to distill the knowledge of datasets intosynthetic data while preserving the performance of the model trained on it. Early dataset distillationmethods are formulated as a bi-level optimization problems , where the outer loop optimize thesynthetic data via gradient matching , distribution matching and performancematching , while the inner loop progressively trains a model on the synthetic data. Consideringcomputational resources constraints, single-level optimization methods based on kernelridge regression are proposed to decouple the bi-level optimization, thereby reducing training cost.These methods demonstrate comparable performance in non-complex datasets like CIFAR10 and areimplemented in FL to tackle communication bottlenecks , data heterogeneity andone-shot FL . However, these methods require significant computational resources, makingthem impractical for edge devices with limited capability in FL. Additionally, they may struggle toeffectively distill high-resolution datasets.",
  ": Framework of proposed FedSD2C": "The details of FedSD2C are described in and Algorithm 1. In the preparation phase ofone-shot FL, the server distributed a pre-trained Autoencoder as the distiller to each client. Sub-sequently, clients synthesize informative, privacy-enhanced, and communication-efficient distillatesfor server-side training. Specifically, to ensure the distillates fully encompass local information,clients first utilize a V-information-based Core-Set selection method to extract diverse and infor-mative Core-Set from their local data domains. Aiming to further reduce the communication costsand enhance the privacy of distillates, clients then perturb the Core-Set with Fourier transform fordistillate initialization and employ the received pre-trained Autoencoder to optimize distillates in acompact latent space via V-information alignment with the Core-Set. Finally, clients transmit thedistillates, and the server decodes them using the pre-trained Autoencoder for training. We will nowdelve into the details of each component.",
  "V-information based Core-Set Selection": "V-information was first proposed to measure the mutual information between X and Y con-strained on predictive family V which is denoted as:IV(X Y ) = HV(Y |) HV(Y |X)(1)where HV(Y |) and HV(Y |X) denote the predictive V-entropy conditioned on or X. Core-Set selection is a type of dataset distillation method that focuses on preserving a subset of theoriginal training dataset containing only valuable or representative samples. The objective is to enablemodels trained on this subset to achieve performance similar to those trained on the entire dataset.Typically, this is achieved by minimizing certain criteria, such as data distribution . In our case,the emphasis lies on maximizing the diversity and information content of the subset. Therefore, inthe context of V-information, Core-Set selection can be reformulated as:(Xs, Ys) = arg maxX,YIV(Xt Yt)(2) where Xt and Yt denotes the images and labels in the original datasets and (Xs, Ys) denotes theselected Core-Set. The intuition behind this equation is that Core-Set should include sufficientinformation and provide a concise representation corresponding to original datasets, constrained byobservers V. Inspired by , we maximize the V-information of the Core-Set from two levels. First, we identifythe most informative image segments within each image by evaluating patches extracted at variousscales from each image. Second, we select the top-ipc with the highest V-information for eachclass to construct the final Core-Set. The algorithm description can be found at Appendix A. Sincea model pre-trained on original datasets can serve as an optimal observer for approximating theV-information , we proposed using local pre-trained models as the observer models (predictivefamily V) to conduct V-information-based Core-Set selection on local datasets. Given that pre-trainedlocal models are commonly present in one-shot FL , their utilization does not violate thepracticality of our approach.",
  "Distilling Core-Set into Distillates with Pre-trained Autoencoders": "In this section, we will describe how to synthesize informative, privacy-enhanced, and communication-efficient distillates using pre-trained Autoencoders. Although Core-Set significantly reduces dataset size, communication costs remain a challenge for high-resolution data in real-world applications.Moreover, while sharing Core-Set provides consistent resistance to membership inference attacks ,transmitting patches may still risk exposing sensitive information of original images. Therefore,further enhancing the privacy of shared data is essential. To alleviate these concerns, we proposetwo novel techniques: 1) distillate initialization with Fourier transform perturbation, which alters theamplitude components of the Core-Set samples to enhance privacy while retaining semantic content;and 2) distillate synthesis with pre-trained Autoencoders which act as the distillers. The pre-trainedAutoencoder converts the perturbed samples into distillates by optimizing their V-information to beas close as possible to the original Core-Set samples, minimizing information loss. We will nowdiscuss each component in detail below. The process is described in Algorithm 1. Distillate initialization with Fourier transform perturbation. A typical privacy-enhanced tech-nique for sharing synthetic data is adding noise . Although this approach can blur the visualinformation of the synthetic data, it can also destroy important semantic information and seriouslydegrade model performance. Our approach leverages a well-known property of the Fourier transform:the phase component of the Fourier spectrum encodes high-level semantic information, whereasthe amplitude component captures low-level details . Inspired by this, we propose a novelprivacy-enhanced method that perturbs the amplitude components in Core-Set samples through theFourier transform to reduce visual information while preserving semantic information. Given animage x, its Fourier transform can be formulated as: F(x) = A(x) ejP(x)(3)where A(x), P(x) depict the amplitude and phase components respectively. We then perturb theamplitude information via linearly interpolating:A(x) = (1 )A(x) + A(x)(4)where the is a scaling coefficient and x can be other images or random noise. Then, we combinethe perturbed amplitude spectrums with the original phase component to generate the perturbedCore-Set sample:x = F1( A(x) ejP(x))(5)where F1(x) defines the inverse Fourier transform which can be calculated with the FFT algo-rithm effectively. Distillate synthesis with pre-trained Autoencoders. The Fourier transform perturbation servesto protect visual privacy but also compromises the realism of images, resulting in inconsistent V-information between the perturbed Core-Set and the original Core-Set. To address this issue, wepropose optimizing the alignment of the V-information between the perturbed Core-Set and theoriginal Core-Set to reconstruct key information. One straightforward and efficient approach is tooptimize the perturbed Core-Set in pixel space . However, this method can be prone tooverfitting into high-frequency patterns that only match the observer model . Such overfitting isdetrimental to training a global model due to inconsistent local models caused by data heterogeneity.Leveraging the powerful priors obtained from large-scale datasets, a pre-trained Autoencoder candecode latent representations into generalizable images. As a result, optimizing in the latent space actsas a regularization method that encourages synthetic data to be more generalizable, thereby makingpre-trained Autoencoder an ideal distiller for local Core-Sets distillation. Furthermore, compactlatent representations can reduce communication costs and mitigate privacy leakage if the latentis intercepted by attackers. Consequently, we employ a pre-trained Autoencoder on the client todistill the Core-Set into informative, privacy-enhanced, and communication-efficient distillates, andtransmit them to the server for model training. On the server side, they are decoded by the decoderand are expected to maintain similar V-information to the original Core-Set from the perspective ofthe observer model while remaining visually unidentifiable. In specific, in the preparation phase of one-shot FL, the server first distributes a pre-trained Au-toencoder to n clients, denoted as E and D for encoder and decoder, respectively. Each client ithen conducts V-information-based selection to construct a Core-Set (Xis, Y is ), i = 1, 2 , n withdiverse information regarding the original local datasets. Subsequently, client i learns a latent setZi = {zj}|Zi|j=1 initialized by {E(xij)}|Xis|j=1 , xij Xis which is perturbed with Fourier transform, such",
  "paired. By minimizing Lsyn, we synthesize a set of latent variables Zi = {zj}|Zi|j=1 that containsdiverse information of local data domains": "Finally, clients transmit the latent set Zi along with the corresponding soft label Y is predicted by localmodels to the server. The server combines the synthetic local distillates from each client S = (Z, Ys).It then uses decoder D to reconstruct the images from data (z, y) (Z, Ys) and distills the knowledgeby minimizing the following objective function:",
  "where f(h()) denotes the server model. By minimizing the KL loss, we can transfer the localknowledge in the distillate to the server model": "Discussion on privacy. We first consider whether an attacker can train a performant model with theintercepted distilled data and labels during transmission . Because the attacker cannot knowthat the distilled data is encoded by VAE, nor can the attacker access the pre-trained VAE encoder,which can be easily achieved by being predefined offline or via encryption, it is hard for the attackerto reproduce an effective model. For model inversion and membership inference attacks, accordingto , there has been no prior research has performed these attacks solely using distilled data and : Accuracy of different one-shot FL methods over three datasets with ConvNet and ResNet-18.We vary the = {0.1, 0.3, 0.5} to simulate different levels of data heterogeneity for Tiny-ImageNetand Imagenette and use pre-defined splits for OpenImage. \"Central\" means that clients send all theirlocal data to the server for centralized training, representing the upper bound of model performance.",
  "Co-Boosting27.060.6128.530.8630.531.1210.290.4314.350.9316.390.599.521.52FedSD2C47.520.5153.690.1755.900.5326.830.1029.920.3731.660.8522.690.14": "labels and previous works have also revealed the advantage of dataset distillation inthis regard. Therefore, we employ the synthetic data as the reconstructed samples for the evaluationof model inversion attacks. Furthermore, we compare our proposed Fourier transform perturbationwith other privacy-enhanced techniques, including adding random noise to synthetic samples anddata augment . Experimental results can be found in .3.1.",
  "Experimental Setup": "Datasets and partitions. We conduct experiments on three real-world image datasets with differentranges of resolution including Tiny-ImageNet , ImageNette , and OpenImage . Tiny-ImageNet contains 10000 images of 6464 resolution across 200 classes. ImageNette is a widely usedsubset of 10 classes from ImageNet-1K with 9469 color images, resized to 128128. OpenImageis a large-scale real-world vision dataset with over 9 million images of 256256 resolution. Tosimulate data heterogeneity in real-world applications of one-shot FL, we use Dirichlet distribution togenerate non-IID data to generate non-IID local data, as in for Tiny-ImageNet and ImageNette.Specifically, for client i, we sample pik Dir() to allocate a pik proportion of class k to client i.The parameter controls the degree of data heterogeneity, with smaller indicating severe dataheterogeneity. The is set to 0.1 by default unless otherwise stated. For OpenImage, we randomlychoose n real-world clients from FedScale and use their corresponding test sets to form globalsets. We set the default number of clients n to 10, unless otherwise specified. Baseline methods and Configurations. We compare our proposed FedSD2C with existing methods:FedAVG , DENSE and Co-Boosting . Following , we also introduce DAFL withone-shot FL settings, denoted as F-DAFL. We use two different model architectures: ConvNet and ResNet-18 for all methods. In FedSD2C, the image per class ipc is set to 50 for Tiny-ImageNet and ImageNette, and 10 for OpenImage. We set the Fourier transform coefficient = 0.8and use a public pre-trained Autoencoder from Stable Diffussion by default for all tasks. Fordistillate synthesis, we set Tsyn = 50, syn = 0.1 by default. trn is set to 0.2 for Tiny-ImageNetand 0.02 for ImageNette and OpenImage. More experimental details can be found in the Appendix.",
  "Evaluation Results": "To evaluate the effectiveness of our method, we conduct experiments under various non-IID set-tings with = {0.1, 0.3, 0.5} for Tiny-ImageNet and Imagenette and pre-defined splits forOpenImage. As illustrated in , our proposed FedSD2C surpasses all other methods in mostsettings. In particular, under extreme data heterogeneity( = 0.1), FedSD2C achieves up to 1.3,2.6, and 1.8 the accuracy of the best baseline on ImageNette, Tiny-ImageNet and OpenImage,respectively. This superior performance is attributed to FedSD2Cs approach of sharing synthetic : Accuracy, PSNR and SSIM of FedSD2C combining different privacy-enhanced techniques.Laplace and Gaussian indicate adding corresponding noise into synthetic distillates without Fouriertransform initialization. FedMix denotes averaging two real samples from Core-Set to synthesizedata. \"-\" indicates no privacy-enhanced technique is combined.",
  "FedMix41.8637.7616.8858.9313.8616.2616.4356.91": "distillates rather than inconsistent local models, thereby mitigating the impact of data heterogeneity.Moreover, FedSD2C demonstrates the independence from model structures. In contrast, other meth-ods struggle to adapt to different model structures and complex datasets. For instance, at = 0.5,Co-Boosting with ResNet-18 achieves only half the accuracy of ConvNet on ImageNette, whereasFedSD2C maintains consistent performance. This discrepancy arises because differences in modelcapacity affect their ability to condense local knowledge and the two-tier information loss duringdata generation increases the difficulty of transferring local knowledge to the server model, resultingin poor robustness to complex datasets and varied networks. In contrast, the shared distillates inFedSD2C are synthesized through end-to-end local distillation, mitigating information loss duringknowledge transfer.",
  "Privacy Evaluation": "For privacy evaluation, we consider an honest-but-curious server attempting to reconstruct clientdata from distillates. We compare our proposed FedSD2C with other privacy-enhanced techniquesfor sharing synthetic data, including adding random noise and FedMix . In the randomnoise approach, we incorporate it into FedSD2C by removing the Fourier transform perturbation andinstead directly using Core-Set samples for initialization. We then add random noise to the syntheticdistillates before transmitting them to the server, following the methods in . Specifically,Given latent z, a perturbation coefficient p, randomly generated noise e and its scale parameter s,the data to be shared is formulated as z = (1 p)z + e s. FedMix proposes using linearinterpolation of real samples to preserve privacy. In this approach, we synthesize data by averagingeach two real samples from the Core-Set. For our proposed Fourier transform perturbation, wevary the = {0.1, 0.5, 0.8} and observe the variations in performance and privacy protection. Toquantitatively evaluate the privacy protection of the synthetic data, we employ the Peak Signal-to-Noise Ratio (PSNR) and Structure Similarity Index Measure (SSIM). A higher PSNR or SSIM valueindicates greater similarity between the synthetic samples and the original samples, which impliesmore severe privacy leakage. We calculate the average PSNR and SSIM values of all the syntheticsamples. As depicted in , although FedMix provides better privacy protection, as evidenced by lowerPSNR and SSIM values, it comes at the expense of significant performance degradation. Theapplication of random noise requires a delicate balance between performance and privacy protection.For example, with a perturbation coefficient p = 0.2, it offers similar privacy protection to thatof FedMix, but the performance drops approximately 10% compared to p = 0.1. However, thep = 0.1 setting increases the risk of privacy leakage. In comparison, the synthetic distillatesgenerated by our proposed FedSD2C achieve comparable PSNR values with them. This suggeststhat our proposed Fourier transform perturbation offers effective privacy protection for the real datasample. Furthermore, FedSD2C consistently outperforms other methods in terms of accuracy whilemaintaining a minimal performance degradation compared to no privacy protection techniques. Thisindicates that FedSD2C strikes a balance between privacy preservation and performance. We also : Comparison of communication costs and accuracy at = 0.1 with ResNet-18. Resultshighlighted in bold represent outcomes with default ipc settings. Acc. and Comm. denote accuracyand communication costs, respectively.",
  "Scalability of Communication Efficiency": "By employing Core-Set selection and communication-efficient distillate communication, ourFedSD2C condenses local data to mere MBs, while the model trained on these condensed dataexhibits comparable performance, as shown in . Specifically, the communication costs ofFedSD2C for sharing synthetic distillate is at most 4% of that of sharing model. Notably, we excludethe communication costs of sending and receiving pre-trained Autoencoder, as this can be pre-definedoffline, allowing for the reuse of multiple one-shot FL tasks. Given the considerable capacity forcommunication costs, we further investigate the scalability of communication efficiency and perfor-mance. Our experimental results demonstrate that increased data transmission enhances the diversityof compressed data, leading to further improvements in performance. By increasing ipc from 20to 80, the accuracy boosts by 13.03% and 4.48% on ImageNette and Tiny-ImageNet respectively.Additionally, we compare FedSD2C without Autoencoder at equivalent communication costs, wherethe absence of synthesized images limits performance to at best half of the default setting. Thecommunication-efficiency of FedSD2C highlights its practicality in real-world applications.",
  "(b) ImageNette": ": (a) Experiments on the medical image data domain.Adopting pre-trained Autoencoders on other data domains canreduce performance. However, this can be mitigated by increasingTsyn. (b) Experiments of FedSD2C with randomly initializeddownsampling and upsampling modules (blue line) compared topre-trained Autoencoders (orange line) on ImageNette. Withoutpre-trained knowledge, FedSD2C requires a higher Tsyn for distil-late synthesis but can still achieve comparable results. ResNet-18is used for both experiments. Pre-trained Autoencoders aretypically trained on natural datadomains , while practical ap-plications of federated learningoften involve a broader range ofdomains, such as medical im-ages. This raises the questionof whether pre-trained Autoen-coders remain effective when ap-plied to a different domain andwhether our proposed FedSD2Ccan adapt to these differences. Toinvestigate this, we evaluate per-formance using a medical datasetCOVID-FL . As shown in a, usingthe default synthesis iteration ofTsyn = 50 yields suboptimalresults. By increasing Tsyn to1000, the performance improves and then stabilizes. This observation suggests that the pre-trainedknowledge of Autoencoders may influence the speed of distillate synthesis convergence. To fur-ther validate this, we replace the encoder and decoder of pre-trained Autoencoders with randomlyinitialized downsampling and upsampling modules. We vary Tsyn from 50 to 1000 and compare",
  "= 0.56.3011.498.3221.76": "its performance with employing pre-trained Autoencoders on ImageNette, setting ipc = 80 forbetter illustration. b demonstrates that as Tsyn increases, the performance of FedSD2Cwith randomly initialized modules improves progressively, eventually matching the performance ofFedSD2C with pre-trained Autoencoders. In summary, while pre-trained knowledge can enhanceconvergence rate, FedSD2C can achieve comparable performance by adjusting Tsyn, demonstratingits adaptability across domains.",
  "Impact of Client Scales": "As practical FL deployments often involve participating clients , we evaluate our FedSD2C withvarious numbers of clients n = {20, 50, 100} and maintain consistent communication budget bysetting ipc = {40, 20, 10}, respectively. We compare these methods under on Tiny-ImageNet withdata heterogeneity = {0.1, 0.3, 0.5} for partitions and employ ConvNet. As depicted in ,FedSD2C consistently achieves the highest accuracy as the number of clients increases. Moreover,FedSD2C demonstrates greater robustness to the number of participants. Specifically, as the numberof participants changes, the accuracy of FedSD2C fluctuates within only 1%. In contrast, the accuracyof F-DAFL, DENSE, and Co-Boosting dropped by up to 4.71%, 3.49%, and 3.10%, respectively underdifferent settings. This further validates the utility of sharing synthesized distillates in real-worldone-shot FL applications.",
  "Limitations": "The local distillation process introduces additional computational overhead. While Core-Set selectionrequires no training and the distillate synthesis process only requires 50 iterations with a speedof 0.4s/per image on RTX3090, it still imposes higher resource requirements on the local devicecompared to the method of sharing model. One direction worth exploring is to integrate with themodel market to enable clients to synthesize distillates once for permanent use.",
  "Conclusion": "In this paper, we propose a new one-shot FL framework driven by distiller-distillate communica-tion, denoted as FedSD2C, to alleviate the information loss of knowledge transfer and impactsof data heterogeneity. FedSD2C compresses the local data into Core-Set with V-information andemploys a pre-trained Autoencoder as the distiller to distill informative, communication-efficient, andprivacy-enhanced distillates from Core-Set. Moreover, We discuss FedSD2Cs resistance to attackersintercepting distillate communications and attacks from honest-but-curious servers and introduceFourier transform perturbation to further minimize the risk of privacy leakage. Empirical resultsvalidate the effectiveness of FedSD2C in transferring local knowledge to the server in one-shot FLwhile balancing communication efficiency and privacy protection.",
  "Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. Federated learning: Challenges, methods,and future directions. IEEE Signal Processing Magazine, 37(3):5060, 2020": "Peter Kairouz, H Brendan Mcmahan, Brendan Avent, AurLien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji,Kallista Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, and Others. Advances andopen problems in federated learning. Foundations and Trends in Machine Learning, 14(12):1210,2021. Junyuan Zhang, Shuang Zeng, Miao Zhang, Runxi Wang, Feifei Wang, Yuyin Zhou, Paul Pu Liang, andLiangqiong Qu. Flhetbench: Benchmarking device and state heterogeneity in federated learning. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages1209812108, June 2024. Derui Wang, Chaoran Li, Sheng Wen, Surya Nepal, and Yang Xiang. Man-in-the-middle attacks againstmachine learning classifiers via malicious generative models. IEEE Transactions on Dependable andSecure Computing, 18(5):20742087, 2020. Hongxu Yin, Arun Mallya, Arash Vahdat, Jose M Alvarez, Jan Kautz, and Pavlo Molchanov. See throughgradients: Image batch recovery via gradinversion. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR), pages 1633716346, 2021.",
  "Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen. Dataset condensation with gradient matching. ICLR,2021": "George Cazenavette, Tongzhou Wang, Antonio Torralba, Alexei A Efros, and Jun-Yan Zhu. Datasetdistillation by matching training trajectories. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR), pages 47504759, 2022. Ruonan Yu, Songhua Liu, Jingwen Ye, and Xinchao Wang. Teddy: Efficient large-scale dataset distillationvia taylor-approximated matching. In European Conference on Computer Vision, pages 117. Springer,2025.",
  "Timothy Nguyen, Roman Novak, Lechao Xiao, and Jaehoon Lee. Dataset distillation with infinitely wideconvolutional networks. Advances in Neural Information Processing Systems, 34:51865198, 2021": "Yuanhao Xiong, Ruochen Wang, Minhao Cheng, Felix Yu, and Cho-Jui Hsieh. Feddm: Iterative distributionmatching for communication-efficient federated learning. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition (CVPR), pages 1632316332, 2023. Rui Song, Dai Liu, Dave Zhenyu Chen, Andreas Festag, Carsten Trinitis, Martin Schulz, and Alois Knoll.Federated learning via decentralized dataset distillation in resource-constrained edge environments. InIJCNN, pages 110. IEEE, 2023. Renjie Pi, Weizhong Zhang, Yueqi Xie, Jiahui Gao, Xiaoyu Wang, Sunghun Kim, and Qifeng Chen.Dynafed: Tackling client data heterogeneity with global dynamics. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition (CVPR), pages 1217712186, 2023.",
  "Hanlin Lu, Changchang Liu, Ting He, Shiqiang Wang, and Kevin S Chan. Sharing models or coresets: Astudy based on membership inference attack. arxiv preprint arxiv:2007.02977, 2020": "Yue Tan, Guodong Long, Jie Ma, Lu Liu, Tianyi Zhou, and Jing Jiang. Federated learning from pre-trained models: A contrastive learning approach. Advances in Neural Information Processing Systems,35:1933219344, 2022. Qinwei Xu, Ruipeng Zhang, Ya Zhang, Yanfeng Wang, and Qi Tian. A fourier-based framework fordomain generalization. In Proceedings of the IEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR), pages 1438314392, 2021.",
  "Zeyuan Yin, Eric Xing, and Zhiqiang Shen. Squeeze, recover and relabel: Dataset condensation at imagenetscale from a new perspective. Advances in Neural Information Processing Systems, 36, 2024": "Jonas Geiping, Hartmut Bauermeister, Hannah DrGe, and Michael Moeller. Inverting gradients-howeasy is it to break privacy in federated learning? Advances in Neural Information Processing Systems,33:1693716947, 2020. Jiawei Shao, Zijian Li, Wenqiang Sun, Tailin Zhou, Yuchang Sun, Lumin Liu, Zehong Lin, and JunZhang. A survey of what to share in federated learning: Perspectives on model utility, privacy leakage, andcommunication efficiency. arxiv preprint arxiv:2307.10655, 2023.",
  "Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. Measuring the effects of non-identical data distribu-tion for federated visual classification. arxiv preprint arxiv:1909.06335, 2019": "Fan Lai, Yinwei Dai, Sanjay Singapuram, Jiachen Liu, Xiangfeng Zhu, Harsha Madhyastha, and MosharafChowdhury. Fedscale: Benchmarking model and system performance of federated learning at scale. InInternational Conference on Machine Learning, pages 1181411827. PMLR, 2022. Hanting Chen, Yunhe Wang, Chang Xu, Zhaohui Yang, Chuanjian Liu, Boxin Shi, Chunjing Xu, ChaoXu, and Qi Tian. Data-free learning of student networks. In Proceedings of the IEEE/CVF InternationalConference on Computer Vision (ICCV), pages 35143522, 2019. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition.In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages770778, 2016. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and BjRn Ommer. High-resolutionimage synthesis with latent diffusion models. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR), pages 1068410695, 2022. Jianqing Zhang, Yang Liu, Yang Hua, and Jian Cao. An upload-efficient scheme for transferring knowledgefrom a server-side pre-trained generator to clients in heterogeneous federated learning. arxiv preprintarxiv:2403.15760, 2024. Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross Wightman, Mehdi Cherti,Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell Wortsman, and Others. Laion-5b: An open large-scale dataset for training next generation image-text models. Advances in Neural Information ProcessingSystems, 35:2527825294, 2022. Rui Yan, Liangqiong Qu, Qingyue Wei, Shih-Cheng Huang, Liyue Shen, Daniel Rubin, Lei Xing, andYuyin Zhou. Label-efficient self-supervised federated learning for tackling data heterogeneity in medicalimaging. IEEE Transactions on Medical Imaging, 2023. Manasi Vartak, Harihar Subramanyam, Wei-En Lee, Srinidhi Viswanathan, Saadiyah Husnoo, SamuelMadden, and Matei Zaharia. Modeldb: A system for machine learning model management. In Proceedingsof the Workshop on Human-in-the-Loop Data Analytics, pages 13, 2016.",
  "BMore Experimental Details": "We use the SGD optimizer with momentum=0.9, learning rate=0.01 and weight decay=0.0001 forclients local training. The batch size is set to 128 and local epoch is 200. For all generationbased methods, we set the resolution of the generated images to 64 64, 128 128 and 256 256for Tiny-ImageNet, ImageNette and OpenImage, the number of generated images in each batchis 128, and the learning rate of the generator is 0.001, the latent dimension is 256, iteration fortraining generator is 30, using Adam for optimization. The server model is optimized with SGD withmomentum 0.9, the learning rate is 0.01, and the training epochs are 200. The synthesized batchsize and server model training batch size is both 128. In DENSE, we set 1 = 1 for BN loss and2 = 0.5 for diversity loss. In Co-Boosting, the perturbation strength is set to = 8/255 and thestep size = 0.1/n. In Core-Set selection stage of FedSD2C, for each image xi, we employ thetorchvision.transform.RandomResizeCrop K times to generate a collection of patches. Forpatch size, we set the scale=(0.08, 1.0), which is to collect diverse image patches. Following , weemploy ConvNet-4 for Tiny-ImageNet, ConvNet-5 for ImageNette and ConvNet-6 for OpenImage.All methods are implemented with Pytorch and conducted on GeForce RTX 3090. Details of t-SNE plots in We randomly select a client and five classes from its localdataset (Tiny-ImageNet) and employs its local model (ResNet-18) to extract features. The feature isextracted from the final layer (before the classifier). We then use t-SNE plots to illustrate the featuredistribution.",
  "C.1Additional datasets": "CIFAR-10. We set the resolution of generated images to 3232 for CIFAR-10 and keep allthe other settings the same. As shown in Table S1, there is an initial performance discrepancy atthe standard setting of ipc = 50. This occurs because our method prioritizes efficiency with largedatasets rather than low-resolution ones. However, upon increasing the amount of synthetic data(ipc = 500), our method can still achieve comparable results.",
  "C.2Membership Inference Attack": "To further validate the effectiveness of our method, we employ an improved version of LiRA toconduct Membership Inference Attacks on our methods. When attacking each client, for FedSD2C,we use the distillates uploaded by the client to train a new model and conduct membership inferenceattacks on that model. For the sharing model-based methods, we perform membership inferenceattacks on the models uploaded by the clients. The client model is ResNet-18 with = 0.1, ipc = 50.We set the raw images of Core-Set as the canary (target data x), as this is the most serious case of ourmethods. The results confirm that our approach does not introduce more privacy risk than the sharingmodel-based approach, even for the most vulnerable targets.",
  "C.3Wavelet transform perturbation": "We explore the use of wavelet transforms to replace the Fourier transforms during Fourier transformperturbations. We use ResNet-18 on Tiny-ImageNet with = 0.1, ipc = 50. The results indicate thatWavelet Transform offers greater scalability in privacy protection. By increasing , the PSNR/SSIMcan be reduced to as low as 12.90/15.30. When the accuracy is comparable to that of Fourier transform(Wavelet = 0.5 vs. Fourier = 0.8), the PSNR and SSIM of Wavelet transform is lower.",
  "In this section, we perform ablation experiments to explore the significance of V-information Core-Setselection. We use ResNet-18 with = 0.1, ipc = 50. Compared with V-information Core-Set": "selection, the accuracy of random selection decreased by 3.5 and 5.46 on Tiny-ImageNet andImageNette, respectively. We also report the performance of uploading Core-Set directly, whichachieve the best performance. However, without distillate synthesis, it will increase the cost ofcommunication and the risk of privacy leakage. Table S5: Performance of different selection strategy. Core-Set denotes that clients directly uploadtheir local Core-Set, which leads to privacy issue. FedSD2C w/ random selection denotes replacingV-information-based Core-Set selection with random selection.",
  "C.6More discussion": "FGL also explore the employment of pre-trained Autoencoder in federated learning. However,its approach demands significantly more computational resources and data with ipc = 20, 000.In contrast, FedSD2C is more cost-effective in terms of data synthesis. It relies solely on anAutoencoder, eliminating the need for Stable Diffusion , which is a computationally intensiveprocess. Moreover, FGL necessitates prior knowledge of the category name and assumes that theimages adhere to the prior distribution of Stable Diffusion. This assumption can be restrictive, as itmay not be applicable to diverse datasets or specialized domains such as medical imaging, whereStable Diffusion may not be able to synthesize X-rays or similar images based solely on labels.",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-perimental results of the paper to the extent that it affects the main claims and/or conclusionsof the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justification: We provide a detailed description of FedSD2C and the parameters for imple-menting the baseline in and the Appendix.Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible is important, regardless ofwhether the code and data are provided or not.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  ". Experimental Setting/Details": "Question: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand theresults?Answer: [Yes]Justification: We provide a detailed description of FedSD2C and the parameters for imple-menting the baseline in and the Appendix.Guidelines: The answer NA means that the paper does not include experiments. The experimental setting should be presented in the core of the paper to a level of detailthat is necessary to appreciate the results and make sense of them.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [Yes]Justification: We report the standard deviation in .Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
  "Guidelines:": "The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  "According to the NeurIPS Code of Ethics, workers involved in data collection, curation,or other labor should be paid at least the minimum wage in the country of the datacollector": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA]Justification: We do not involve crowdsourcing nor research with human subjects.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}