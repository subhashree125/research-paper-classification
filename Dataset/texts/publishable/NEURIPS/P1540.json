{
  "Abstract": "Large language models (LLMs) have demonstrated remarkable capabilities, buttheir outputs can sometimes be unreliable or factually incorrect. To address this, weintroduce Self Logits Evolution Decoding (SLED), a novel decoding frameworkthat enhances the truthfulness of LLMs without relying on external knowledgebases or requiring further fine-tuning. From an optimization perspective, ourSLED framework leverages the latent knowledge embedded within the LLM bycontrasting the output logits from the final layer with those from early layers.It then utilizes an approximate gradient approach to enable latent knowledge toguide the self-refinement of outputs, thereby effectively improving factual accuracy.Extensive experiments have been conducted on established benchmarks acrossa diverse range of model families (LLaMA 2, LLaMA 3, Gemma) and scales(from 2B to 70B), including more advanced architectural configurations such as themixture of experts (MoE). Our evaluation spans a wide variety of tasks, includingmulti-choice, open-generation, and adaptations to chain-of-thought reasoning tasks.The results demonstrate that SLED consistently improves factual accuracy by up to20% compared to existing decoding methods while maintaining natural languagefluency and negligible latency overhead. Furthermore, it can be flexibly combinedwith other decoding methods to further enhance their performance.",
  "Introduction": "Large Language Models (LLMs) have achieved remarkable breakthroughs in recent years, demon-strating exceptional performance across various domains .How-ever, a significant challenge associated with LLMs is their tendency to hallucinate or distortthe truth, resulting in outputs that are not factual .This issue of hallucinationundermines the reliability and trustworthiness of LLMs in practical applications.A popu-lar strategy for improving the LLM factuality involves refining the decoding process .",
  ": Factuality decoding overview": "Decoding focuses on how the model selects the next to-ken during the generation process, which can significantlyinfluence the factual accuracy of the output. The decod-ing methods can be cost-effective since (a) they do notrely on external knowledge and (b) no additional train-ing is required. Furthermore, decoding methods can besynergistically combined with other techniques aimed atimproving the LLM factuality, such as retrieving infor-mation from external knowledge bases , variousfine-tuning strategies for better alignment , or en-semble learning methods .",
  ": Illustration of our Self Logits-Evolution Decoding (SLED) workflow": "Recent studies suggest that LLMs sometimes have learned the factual content basedon extensive pretraining or fine-tuning, although they fail to produce the correct answer when auser queries the model. This has inspired the development of several factuality decoding methods to reveal what the model implicitly \"knows.\" summarizes the underlyingmechanism of these factuality decoding methods. The LLMs output distribution is derived byapplying the softmax function to the output logits from the final layer. During the training phase, thisdistribution is optimized based on the real-world factuality distribution represented by the trainingdataset. However, during the inference phase, \"what the LLM tells\" might still contain factual errors,which implies a discrepancy between the output distribution and the real-world factuality distribution.While the real-world distribution remains inaccessible during the inference phase, the models latentknowledge (\"what the model knows\") may have implicitly learned some factual content correctlyduring the training phase . Therefore, a key challenge for factuality decoding strategies lies ineffectively harnessing the latent knowledge embedded within LLMs to refine the output distribution(logits) during inference. To address this challenge, we propose Self Logits Evolution Decoding (SLED), a novel factualitydecoding approach that leverages the latent knowledge within LLMs by contrasting the final layerslogits with early layers logits. During the decoding process, as LLMs progress from early to finallayers, they progressively incorporate factual information stored in each layer into the output. SLEDtracks this evolution process to unearth the latent knowledge within LLMs, and enables the self-evolution of the output distribution further to align it more closely with real-world facts. Furthermore,our approach recognizes that the latent knowledge within LLMs, while valuable, may not always beperfect. Therefore, instead of simply replacing the original outputs with this latent knowledge, SLEDintegrates it into the original logits through an operation similar to single-step gradient descentover the output logits during the inference time. This operation minimizes the Kullback-Leibler(KL) divergence between the latent knowledge distribution and the output distribution, effectivelybalancing the two and mitigating potential drawbacks such as overfitting or biased outputs. illustrates the SLED workflow, highlighting how SLED optimizes the output logits, leading to amore factual output distribution. We evaluate SLED on various LLMs (e.g., LLaMA 2 , LLaMA3 , Gemma ) and benchmarks to demonstrate its state-of-the-art performance in layer-wisecontrastive decoding methods. In summary, our main contributions are:",
  "Loss": "70B : We analyze the next-token predictions of three LLaMA-2-base models using the logits fromeach layer individually. This analysis is performed on 200 true claims from the FACTOR dataset.The results verify that the logits distribution at the final layer is closer to the real-world distributionthan all the early layers in terms of KL divergence.",
  "Self Logits Evolution Decoding": "A large language model, equipped with N layers and a vocabulary V = [v1, v2, . . . , vd], typicallygenerates text in the next-token prediction fashion. For each given prefix, the model computes thelogits at the final (N -th) layer, logitsN ((1,N), (2,N), . . . , (d,N)), which are obtained by applyinga linear transformation to the hidden states of the final layer, projecting the high-dimensional hiddenstate vectors onto the space of the vocabulary size. Subsequently, the output distribution PlogitsN atthe final (N -th) layer for the next token is derived by applying softmax function on the logits,",
  "j=1 exp((j,N)/)": "Similarly, we can also derive the logits from early layers by applying the same linear transformationmentioned above to their hidden states. For any early layer n (n < N), we denote its logits aslogitsn ((1,n), . . . , (d,n)) and the corresponding distribution as Plogitsn (p(1,n), . . . , p(d,n)).",
  "Logits Evolution": "To improve factual accuracy, it is crucial that the correct token vi receives a higher value of logitsNto ensure a higher probability value p(i,N) in the output distribution PlogitsN . From a mathematicalperspective, this means aligning the models output distribution PlogitsN closely with the real-worldfactuality distribution Preal. Specifically, we can formulate this goal as optimizing the following lossfunction L regarding the logits:",
  "L(logits) KL(Preal, Plogits), where logits = (1, ..., d), Plogits = softmax(logits/)(1)": "We describe the above optimization as Logits Evolution. Interestingly, the training of LLMs alsoaims at minimizing the divergence (typically the KL divergence, as the training loss function is oftenthe cross-entropy loss) between the ground truth Preal and the output distribution PlogitsN . During thetraining phase, the logits evolution is driven externally by the real-world distribution Preal presentedin the training dataset, and the corresponding solution is logits = logitsN . However, Preal is notaccessible during the inference phase. To address this challenge, SLED utilizes the models latentknowledge to estimate Preal and enables \"self-evolution\" of the logits. We denote the estimation asPlatent and the self logits evolution can be achieved by the following gradient-descent operation:",
  "Estimate Preal by Tracking the Logits Evolution Direction throughout Layers": "The core principle of our method involves leveraging the difference between each early layers logitsand the final layers logit, logitsn logitsN to approximate the gradient of KL(Preal, Plogits) atlogits = logitsn. Then we estimate Preal based on this approximation. This is inspired by a new perspective of interpreting the training phase of LLMs as the evolutionof logits described in Problem 1. As mentioned above, the solution derived by the training phaseis the final layers logits logits = logitsN , since the final layers logitsN directly engage with thereal-world distribution Preal through the loss function in training. This implies that we can generallyconsider the final logits logitsN to be a better solution than the logits from an early layer logitsn, withKL(Preal, PlogitsN ) < KL(Preal, Plogitsn). We present some examples in to demonstratethis. Based on this discussion, if we contrast the final layers logits with the early layers logits,we can consider the direction (orientation) of logitsn logitsN can approximately align with thedirection of the gradient logitsKL(Preal, Plogits)|logits=logitsn. To further verify this motivation,we calculate the cosine similarity between logitsn logitsN and logitsnKL(Preal, Plogitsn) forthousands of tokens across different models in . We find that the majority of these values arepositive, which means that the directions of these two vectors are close.",
  "Achieving the Self Logits Evolution in Three Phases": "Based on the above analysis, we can introduce the procedures of SLED: First, we estimate P(n)latentfor each early layer n using the gradient approximation in .2. Subsequently, we apply aweighted average on {P(n)latent} across all early layers n < N to derive Platent, which serves as thefinal estimation of the real-world distribution. Finally, we apply Platent in Equation 2 to facilitate theself-evolution of logitsN , thereby derive the updated logits, logitsN .",
  "Phase 1:An exhaustive search for an exact solution to the complex optimization problem (Equation": "3) is computationally impractical. We can reduce the solution space by the following. Supposethe real-world factuality distribution dictates that the next word to be generated is the i-th token vifrom the vocabulary V. Thus Preal = Pei, where Pei represents a standard basis vector (one-hotvector) with the i-th component set to 1 and all other components set to 0. Then, we can simplify theaforementioned optimization problem by limiting the solution space to {Pei}di=0 and decide whichtoken i should be selected. The corresponding gradient when P = Pei has the following formulation.Proposition 1. The gradient of KL(Pei, Plogits) at logits = logitsn is:logitsnKL(Pei, Plogitsn) = (Plogitsn Pei)/ =p(1,n), . . . , p(i,n) 1, . . . , p(d,n)/(4)We calculate the cosine similarity between the gradient logitsnKL(Pei, Plogitsn) and the differencelogitsn logitsN for each token in the vocabulary V. Then we select the Pei of which the gradientis closest to logitsn logitsN as the estimation P(n)latent. Mathematically, this involves selecting iaccording to the following criterion",
  "i=1 m(n)i": "We square { m(n)i} to moderately amplify their differences. Prior studies prove that soft targets usuallyoffer stronger generalization capabilities, more information, and more robustness to noise than hardtargets . Hence, we adopt the soft estimation in lieu of the hard estimation. Eliza's rate per hour for the first 40 hours she works each week is $10. She also receives an overtime pay of 1.2 times her regular hourly rate. If Eliza worked for 45 hours this week, how much are her earnings for this week?",
  "values across layers": ": An example from GSM8K demonstrating SLEDs mechanism. SLED derives the estima-tions P(n)latent by contrasting final layers logits logitsN with early layers logits {logitsn}. We list thetoken with the highest probability value from the P(n)latent for different early layers. As shown, SLEDdownplays incorrect tokens by assigning lower weights s(n) to the corresponding P(n)latent. Conversely,if the estimation is correct, the weights are relatively larger. The parameter evaluation scale is set to 2.",
  "n=0 m(n))": "This estimation suggests that the weight s(n) of certain layer n will be larger if the corre-sponding gradient approximation logitsn logitsN is more closely aligned with the gradients{logitsnKL(Pei, Plogitsn)} for the tokens in the vocabulary. This in turn amplifies the influenceof layer n on the final estimation, which is a desirable effect in our method. demonstratesthat SLED can downplay incorrect tokens based on the gradient alignment. One can further validatethat for each component mi in the final estimation Platent (m1, m2, . . . , md), the followingrelationship holds: mi = Nn=0 m(n)i/(Nn=0dj=1 m(n)j). This property simplifies the descriptionin Algorithm 1. Phase 3:Applying Platent in Equation 2 enables us to derive the gradient necessary for steeringthe self-evolution on the final layers logits logitsN .Proposition 2. The gradient of KL(Platent, Plogits) at logits = logitsN is:",
  "Computational Complexity and Design Decisions": "For each layer, computing CosSim(logitsn logitsN , Plogitsn Pei) for every token vi in thevocabulary V needs O(d2) operations. To reduce the computational complexity, we select only asubset VIk, where the token vi VIk has the top-k highest logits in the final layer. In this scenario,we only initiate the self-evolution in Equation 2 of the logits corresponding to these top-k tokens.For the remaining tokens, which have lower probabilities, their logits are adjusted to a very lowernumerical value, e.g., 1000. This strategy significantly reduces the computational complexity, whilemaintaining focus on the most relevant tokens. We name the parameter k, as Evolution Scale, sinceit determines the number of top-probability tokens active for self-evolution.",
  ": end for12: Output: The self-evolved logits are logitsN = ((1,N), . . . , (i,N), . . . , (d,N))": "layer with the highest JSD as the premature layer, and the chosen layer will be contrasted with thefinal layer to update probabilities. Obviously, if this strategy is reasonable, a larger candidate setshould lead to a better choice of the premature layer and, consequently, enhanced overall performance.However, a paradoxical finding from their experimental results, which our tests also confirm in thediscussion in .5, is that a larger candidate set for DoLa leads to decreased performance.Specifically, when the candidate set for DoLa ranged from 0 to 32 layers for LLaMA-2-7B-Base, theperformance was inferior compared to a smaller set of 0 to 16 layers. This fundamental flaw indicatesthat selecting a good candidate set remains a challenge when applying DoLa. In contrast, our methoddoes not face this concern as it applies an ensemble approach to all early layers. It is also importantto note that our method works well even when only contrasting the final layer with part of the earlylayers, as demonstrated in .5 and A, proving the robustness of our approach.",
  "Q 2.2: Why not use Platent directly as the models output distribution?": "It is crucial to understand that Platent is merely an estimation of the real-world distribution basedon the models latent knowledge instead of the exact Preal. Consequently, relying solely on Platent,similar to DoLa, might lead to inaccuracies, as the latent knowledge can be imperfect. The originallogits logitsN are still important as they are refined directly by real-world data during training. Theevolution rate in Equation 2, serves to balance this trade-off, enabling a reciprocal enhancementbetween Platent and the original logitsN . More ablation studies are provided in .5 and A.",
  "Q 2.2: Considering that SLED adopts logitsn logitsN as the estimation of the gradient, why notdirectly apply it in Equation 2?": "It is important to note that while logitsn logitsN is unconstrained, the gradients estimated inEquation 2 (e.g., p(1,N) m1, . . . , p(d,N) md) are constrained within . Thus, direct substi-tution could lead to a mismatch in magnitudes and might also introduce unexpected noise. Propernormalization and subsequent aggregation of estimations from different layers are precisely what ourmethod addresses in .2 and 2.3. Further analysis is provided in Section A.",
  "Experiments": "As a novel layer-wise contrastive decoding approach, we first benchmark SLED against the state-of-the-art approach DoLa across a diverse range of model families (LLaMA 2, LLaMA 3,Gemma) and model scales (from 2B to 70B), including the more advanced mixture of experts (MoE)architecture, as detailed in .2 and 3.3. The results showcase notable factuality improvementsacross a variety of tasks, including multi-choice, open-generation, and adaptations to chain-of-thoughtreasoning tasks. Then, in .4, we integrate our method with other established factualitydecoding techniques, illustrating that SLED can further enhance their performance. In .5, wefurther conduct in-depth studies on mitigating the repetition issue, layer selection, various parametersettings, and latency overhead to gain more comprehensive insights into SLEDs performance. We",
  "Experimental Setup": "BenchmarksWe compare our method with baselines on several multiple-choice and open-endedgeneration tasks. For multiple-choice question tasks, we use the TruthfulQA and FACTOR (Wiki) datasets to assess the LLMs factuality in short-answer/long-paragraph scenario, respectively.For open-ended generation tasks, we adopt TruthfulQA and tasks involving chain-of-thoughtreasoning : StrategyQA and GSM8K . Models & BaselinesWe evaluate the performance of SLED on six LLaMA-2 models ({7B,13B,70B}-Base, {7B,13B,70B}-Chat), four LLaMA-3 family models ({8B,70B}-Base,{8B,70B}-IT), two Gemma models (2B,7B), two MoE models (Mixtral-87B, Mixtral-87B-IT) . We adopt the following baselines: 1) standard decoding (greedy decoding or samplingdepending on the tasks), 2) DoLa , 3) Inference Time Intervention (ITI) , 4) Activation Decod-ing (AD) , 5) Contrastive Decoding (CD) , and 6) Induce-then-Contrast Decoding (ICD) . MetricsWe adopt the factual accuracy evaluation implemented in for multiple-choice tasksand chain-of-thought reasoning tasks. For the open-ended generation task on TruthfulQA, we followthe evaluation procedure in , using finetuned-GPT3-judges to measure the truthfulness,informativeness, and rejection rate of generated outputs respectively.",
  "Evaluation on a Broad Range of LLM Benchmarks": "Multiple-Choices TasksThe objective of these tasks is to employ decoding methods that enableLLMs to assign higher probabilities to correct completions/answers over incorrect alternatives. Wedemonstrate the effectiveness of SLED for both Short-Answer Factuality on the TruthfulQA andLong-Paragraph Factuality on the FACTOR dataset. For both DoLa and our SLED, we contrast theresults from the final layer against all preceding layers. We randomly sample approximately 5% ofthe data for validation regarding parameter selection. The results, as shown in , indicate thatSLED achieves superior outcomes in almost all metrics across six LLaMA-2 models. Notably, SLED",
  "LLaMA-3-70B-IT73.9544.8070.2941.02Gemma-7B60.4231.5847.6322.75+DoLa71.5138.4368.7035.21+DoLa36.0725.2143.1426.13+SLED (ours)76.8548.3574.0343.16+SLED (ours)65.5632.3149.8825.22": "achieves better performance under the MC1/MC3 metrics on TruthfulQA, which are more sensitiveto fluctuations and pose a greater challenge. For long sentences in FACTOR, our method showsimprovements over baselines by 5-13%. These results not only underscore the benefits of our methodfor factuality but also demonstrate its robustness across different lengths of text. Open-Ended Generation TasksIn open-ended settings, we prompt the model to generate answersfor the same questions from TruthfulQA, following the settings outlined in . In , wecompare the performance of six LLaMA-2 models using standard greedy decoding, (greedy) DoLa,and (greedy) SLED. All the generated answers are then evaluated by a fine-tuned GPT-3 model forboth truthfulness and informativeness scores. Considering that a 100% truthful score can be easilyachieved by simply responding with I have no comment, which would result in a 0% informativescore and thus is not very useful, we have introduced additional metrics%Truth Info and therejection ratio %Reject to demonstrate that SLED is a mutual-gains approach to achieve better bothtruthful and informative scores. We have improved the overall %Truth x Info scores by 3-20% acrossdifferent models and reduced the rejection ratio by up to 95%. These enhancements demonstrate thatour method effectively avoids the rejection pitfall, making it more helpful. Adaptation to Chain-of-thought Reasoning TasksAlthough the StrategyQA and GSM8K tasksare also open-ended and require factual accuracy, the primary focus here is to evaluate how differentdecoding methods adapt to the Chain-of-Thought (COT) approach for handling complex reasoningtasks. We maintain a repetition penalty of 1, as we will discuss the repetition flaws associatedwith DoLa in .5. StrategyQA demands multi-hop reasoning, and as shown in , ourmethod boosts accuracy across six models, whereas DoLa generally worsens it without a repetitionpenalty. GSM8K, a benchmark for math word problems that require arithmetic reasoning, also showsconsistent accuracy improvement with SLED in 7B, 13B and 70B models.",
  "Evaluation Across Diverse LLM Configurations": "As discussed above and shown in , our method, SLED, demonstrates strong generalizationcapabilities across the LLaMA-2 model family, proving robust from 7B to 70B model sizes. In, we further showcase SLEDs impressive performance on the more recent LLaMA-3 familymodels, both at 8B and 70B sizes, in terms of long paragraph factuality and short answer factuality.Interestingly, SLED is also applicable to different pre-trained models, such as Gemma at both 2B and7B sizes, and can even be adapted to the increasingly popular Mixture of Experts (MoE) architectures.These results confirm the exceptional adaptability of our method across various LLM configurations.",
  "Ablation Studies and Analysis": "Mitigating Repetition Issues demonstrates that our method, SLED, effectively addressesa significant issue in DoLa: repetitive content in open-ended generation tasks. Our approachoutperforms DoLa without the need for excessive repetition penalty. While a slight increase in therepetition penalty further enhances the performance of our method, excessive penalties, such as1.1, tend to degrade it. This suggests that SLED does not inherently require heavy adjustments forrepetition issues. In contrast, DoLas performance improves with higher penalties (e.g., 1.1, 1.2,2), indicating a more critical need for addressing repetitive content. We also employ two intuitivemetrics, Repetition-4 and Repetition-Sen, to gauge the severity of repetition issues, following priorresearch . Regardless of the repetition penalty imposed, our method consistently exhibits lowerrepetition rates. includes some examples of generated text to illustrate this further. Layer SelectionAs discussed in .4, how to choose a good candidate set is still a para-doxically difficult task when applying DoLa. Our method does not exhibit this issue. Instead ofselecting a single premature layer from the candidate set like DoLa, SLED contrasts the final layerwith all layers in the candidate set and then ensembles all the results. shows that setting alarger candidate set, such as all the 32 layers for LLaMA-2-7B-Base, yields better performance thanfocusing solely on either the first [0, 16) or second half [16, 32). This implies that our layer-wisecontrast approach captures more useful information in a more scientific manner. Furthermore, ourtests confirm the robustness of our method even when the candidate set is minimal, such as a singlelayer, consistently demonstrating strong performance. Our settings mirror those of DoLa. Parameter AnalysisWe next investigate the impact of parameters evolution rate and evolutionscale k on the performance of SLED using a subset of the FACTOR dataset. We test evolutionrates from {0.01, 0.1, 1, 2, 5, 10} and evolution scale values from {5, 10, 20, 50}. Without extreme : Evaluating using different premature layers for SLED and DoLa on a 10% subset of theGSM8K dataset. Contrasting all layers for SLED is better than using only the first half [0, 16) orthe second half [16, 32). Hence, there are no improvements for SLED from strategic layer subsetselection.",
  "(d) LLaMA 2 13B Chat": "evolution rates (e.g., 10), our method performs well, confirming its robustness. As analyzed inour methodology and Eq. 2, the evolution rate balances the logit distribution (PN ) with the latentknowledge distribution (Platent). A lower evolution rate works better for larger models (13B) andchat models as their logits already better represent real-world distributions. LatencyOur method, SLED, does not incur significant latency overhead. The latencies presentedin demonstrate that our method, SLED, just increases the decoding time of DoLa by factorsranging from 0.1% to 10%. Notably, even with an atypical setting such as evolution scale = 100,which is seldom used, the increase remains around 10%. The latency for DoLa and SLED is muchhigher compared to the vanilla greedy decoding because we set all early layers as candidate layers setfor both DoLa and SLED for a fair comparison.",
  "Related Work": "There have been many advances in improving training and inference to develop better out-of-the-boxLLMs . Unfortunately, LLMs still suffer from hallucinations andproducing non-factual text. This has led researchers to develop many methods to improve factuality. Retrieval, Fine-tuning, and Preferences.Many techniques use additional knowledge graphs orfine-tuning data to increase factuality by updating the model parameters for this goal. One method isRetrieval-Augmented Generation (RAG) to use external knowledge to improve generation .Another option is to use post-generation retrieval and editing for improving attribution . Otherdirections that use additional training or preference data are supervised fine-tuning (SFT) ,",
  "RLHF , DPO or self-rewarding . Complementary to these approaches, we wish toimprove the LLM output distribution directly without needing any additional data": "Decoding and Factuality DecodingFor each prefix, the LLM generates a probability distributionfor the next token on a fixed vocabulary list, and a decoding method determines how the next token isderived based on the estimated distribution. Decoding methods were initially developed to enhancethe fluency and coherence of text generation, such as Beam Search (BS), which maintains the k mostprobable sequences at each time step. Common decoding methods also include Diverse Beam Search(DBS) , Contrastive Decoding , Top-p Sampling and so on. Recently, the potential of decoding has extended beyond merely improving text readability, withsome factuality decoding methods being proposed. These methods modify the generation process tofocus on truthful statements rather than unsupported claims during the inference phase, aiming toreduce hallucinations. Notable recent works include Inference-Time Intervention (ITI) , Induced-Contrastive Decoding , Decoding by Contrasting Layers (DoLa) and so on. ITI adjusts modelactivations during inference by following learned directions across a limited number of attentionheads to improve truthfulness. Some researchers have extended previous Contrastive Decoding methods to improve factual accuracy, such as Frustratingly Easy Model Decoding and Induced-Contrastive Decoding , leveraging differences between expert and amateur models. Most closelyrelated to our work is DoLa, which also employs contrasting logits from different layers. However,significant distinctions exist: Firstly, our method diverges in how to utilize those differences betweenlogits to extract latent knowledge. Secondly, whereas DoLa directly substitutes the original outputdistribution with the latent knowledge distribution, our approach recognizes potential inaccuracies inthis estimated distribution and adopts gradient descent within an optimization framework to integratethe models latent knowledge with the original output. Limitations.As we continue to refine our approach, several aspects of our method can be furtherdeveloped and enhanced. Our method, SLED, achieves better factuality at the cost of operatingslightly slower. Ideally, we could improve the output logits without incurring any computational costcompared to performing inference on the base LLM model. Another aspect is that currently, ourexperimental results support the superiority of SLED on multiple datasets. Parameter optimizationusing Bayesian methods , evolutionary algorithms or reinforcementlearning might also lead to more robust performance. It would also be ideal to back upour results with more theoretical analysis of SLED.",
  "Conclusion": "We introduced Self Logits Evolution Decoding (SLED), which is a new method to improve accuracyand factuality without requiring external knowledge (e.g., RAG) or fine-tuning (e.g., SFT). The keyidea is to optimize the output logits based on the LLMs latent knowledge to improve factualityduring inference. On several datasets, SLED achieved the SOTA results, improving over the vanilladecoding and DoLa. We also show that SLED does not increase the inference time significantlyand that it can be combined with other factuality decoding methods. For future work, it would beinteresting to combine SLED with supervised fine-tuning methods, e.g., to adapt to other domains. This work was done when Jianyi Zhang was an intern at Google Research. In addition, Jianyi Zhangand Yiran Chen disclose the support from grants NSF CNS-2112562 and ARO W911NF-23-2-0224.We thank area chair and reviewers for their valuable comments.",
  "AI@Meta. Llama 3 model card. 2024. URL": "Rohan Anil, Andrew M Dai, Orhan Firat, Melvin Johnson, Dmitry Lepikhin, Alexandre Passos,Siamak Shakeri, Emanuel Taropa, Paige Bailey, Zhifeng Chen, et al. Palm 2 technical report.arXiv preprint arXiv:2305.10403, 2023. Jiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun. Benchmarking large language mod-els in retrieval-augmented generation. In Proceedings of the AAAI Conference on ArtificialIntelligence, volume 38, pages 1775417762, 2024. Shiqi Chen, Miao Xiong, Junteng Liu, Zhengxuan Wu, Teng Xiao, Siyang Gao, and Junxian He.In-context sharpness as alerts: An inner representation perspective for hallucination mitigation.arXiv preprint arXiv:2403.01548, 2024. Xin Cheng, Di Luo, Xiuying Chen, Lemao Liu, Dongyan Zhao, and Rui Yan. Lift yourselfup: Retrieval-augmented text generation with self-memory. Advances in Neural InformationProcessing Systems, 36, 2024.",
  "Paul Francis Christiano, Jan Leike, Tom B. Brown, Miljan Martic, Shane Legg, and DarioAmodei. Deep reinforcement learning from human preferences. ArXiv, abs/1706.03741, 2017": "Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James R. Glass, and PengchengHe. Dola: Decoding by contrasting layers improves factuality in large language models.In The Twelfth International Conference on Learning Representations, 2024. URL Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers tosolve math word problems. arXiv preprint arXiv:2110.14168, 2021. Yujuan Ding, Wenqi Fan, Liangbo Ning, Shijie Wang, Hengyun Li, Dawei Yin, Tat-Seng Chua,and Qing Li. A survey on rag meets llms: Towards retrieval-augmented large language models.arXiv preprint arXiv:2405.06211, 2024.",
  "Yilun Du, Shuang Li, Antonio Torralba, Joshua B. Tenenbaum, and Igor Mordatch. Improvingfactuality and reasoning in language models through multiagent debate, 2024. URL": "Luyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, YichengFan, Vincent Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, and Kelvin Guu. RARR: Researchingand revising what language models say, using language models. In Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki, editors, Proceedings of the 61st Annual Meeting of the Associationfor Computational Linguistics (Volume 1: Long Papers), pages 1647716508, Toronto, Canada,July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.910.URL Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Didaristotle use a laptop? a question answering benchmark with implicit reasoning strategies.Transactions of the Association for Computational Linguistics, 9:346361, 2021.",
  "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. The curious case of neuraltext degeneration. arXiv preprint arXiv:1904.09751, 2019": "Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qian-glong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, et al. A survey on hallucination inlarge language models: Principles, taxonomy, challenges, and open questions. arXiv preprintarXiv:2311.05232, 2023. Max Jaderberg, Valentin Dalibard, Simon Osindero, Wojciech M Czarnecki, Jeff Donahue, AliRazavi, Oriol Vinyals, Tim Green, Iain Dunning, Karen Simonyan, et al. Population basedtraining of neural networks. arXiv preprint arXiv:1711.09846, 2017. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang,Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation.ACM Computing Surveys, 55(12):138, 2023. Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, ChrisBamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian Bressand,Gianna Lengyel, Guillaume Bour, Guillaume Lample, Llio Renard Lavaud, Lucile Saulnier,Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang, Szymon Antoniak,Teven Le Scao, Thophile Gervet, Thibaut Lavril, Thomas Wang, Timothe Lacroix, andWilliam El Sayed. Mixtral of experts, 2024. URL",
  "Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. triviaqa: A Large ScaleDistantly Supervised Challenge Dataset for Reading Comprehension. arXiv e-prints, art.arXiv:1705.03551, 2017": "Saurav Kadavath, Tom Conerly, Amanda Askell, Tom Henighan, Dawn Drain, Ethan Perez,Nicholas Schiefer, Zac Hatfield-Dodds, Nova DasSarma, Eli Tran-Johnson, et al. Languagemodels (mostly) know what they know. arXiv preprint arXiv:2207.05221, 2022. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh,Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee,Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le,and Slav Petrov. Natural questions: a benchmark for question answering research. Transactionsof the Association of Computational Linguistics, 2019. Deren Lei, Yaxi Li, Mengya Hu, Mingyu Wang, Vincent Yun, Emily Ching, Eslam Kamal,et al. Chain of natural language inference for reducing large language model ungroundedhallucinations. arXiv preprint arXiv:2310.03951, 2023. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, NamanGoyal, Heinrich Kttler, Mike Lewis, Wen-tau Yih, Tim Rocktschel, et al. Retrieval-augmentedgeneration for knowledge-intensive nlp tasks. Advances in Neural Information ProcessingSystems, 33:94599474, 2020. Kenneth Li, Oam Patel, Fernanda Vigas, Hanspeter Pfister, and Martin Wattenberg. Inference-time intervention: Eliciting truthful answers from a language model.In A. Oh, T. Nau-mann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors, Advances in Neu-ral Information Processing Systems, volume 36, pages 4145141530. Curran Associates,Inc., 2023. URL Xiang Lisa Li, Ari Holtzman, Daniel Fried, Percy Liang, Jason Eisner, Tatsunori Hashimoto,Luke Zettlemoyer, and Mike Lewis. Contrastive decoding: Open-ended text generation asoptimization. arXiv preprint arXiv:2210.15097, 2022.",
  "Qiang Liu and Dilin Wang. Stein variational gradient descent: A general purpose bayesianinference algorithm, 2019": "Gemma Team Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya Bhupatiraju, ShreyaPathak, L. Sifre, Morgane Riviere, Mihir Kale, J Christopher Love, Pouya Dehghani Tafti,Leonard Hussenot, Aakanksha Chowdhery, Adam Roberts, Aditya Barua, Alex Botev, AlexCastro-Ros, Ambrose Slone, Amelie Heliou, Andrea Tacchetti, Anna Bulanova, AntoniaPaterson, Beth Tsai, Bobak Shahriari, Charline Le Lan, Christopher A. Choquette-Choo,Clement Crepy, Daniel Cer, Daphne Ippolito, David Reid, Elena Buchatskaya, Eric Ni, EricNoland, Geng Yan, George Tucker, George-Christian Muraru, Grigory Rozhdestvenskiy, HenrykMichalewski, Ian Tenney, Ivan Grishchenko, Jacob Austin, James Keeling, Jane Labanowski,Jean-Baptiste Lespiau, Jeff Stanway, Jenny Brennan, Jeremy Chen, Johan Ferret, Justin Chiu,Justin Mao-Jones, Katherine Lee, Kathy Yu, Katie Millican, Lars Lowe Sjoesund, Lisa Lee,Lucas Dixon, Machel Reid, Maciej Mikula, Mateo Wirth, Michael Sharman, Nikolai Chinaev,Nithum Thain, Olivier Bachem, Oscar Chang, Oscar Wahltinez, Paige Bailey, Paul Michel,Petko Yotov, Pier Giuseppe Sessa, Rahma Chaabouni, Ramona Comanescu, Reena Jana, RohanAnil, Ross McIlroy, Ruibo Liu, Ryan Mullins, Samuel L Smith, Sebastian Borgeaud, Sertan Gir-gin, Sholto Douglas, Shree Pandya, Siamak Shakeri, Soham De, Ted Klimenko, Tom Hennigan,Vladimir Feinberg, Wojciech Stokowiec, Yu hui Chen, Zafarali Ahmed, Zhitao Gong, Tris BrianWarkentin, Ludovic Peran, Minh Giang, Clement Farabet, Oriol Vinyals, Jeffrey Dean, KorayKavukcuoglu, Demis Hassabis, Zoubin Ghahramani, Douglas Eck, Joelle Barral, FernandoPereira, Eli Collins, Armand Joulin, Noah Fiedel, Evan Senter, Alek Andreev, and Kathleen Ke-nealy. Gemma: Open models based on gemini research and technology. ArXiv, abs/2403.08295,2024. URL Risto Miikkulainen, Jason Liang, Elliot Meyerson, Aditya Rawal, Dan Fink, Olivier Francon,Bala Raju, Hormoz Shahrzad, Arshak Navruzyan, Nigel Duffy, et al. Evolving deep neuralnetworks. In Artificial intelligence in the age of neural networks and brain computing, pages269287. Elsevier, 2024. Dor Muhlgay, Ori Ram, Inbal Magar, Yoav Levine, Nir Ratner, Yonatan Belinkov, Omri Abend,Kevin Leyton-Brown, Amnon Shashua, and Yoav Shoham. Generating benchmarks for factualityevaluation of language models. arXiv preprint arXiv:2307.06908, 2023.",
  "Xin Qi and Bing Xu. Hyperparameter optimization of neural networks based on q-learning.Signal, Image and Video Processing, 17(4):16691676, 2023": "Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, andChelsea Finn. Direct preference optimization: Your language model is secretly a reward model.Advances in Neural Information Processing Systems, 36, 2024. Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon Suematsu, Jie Tan,Quoc V Le, and Alexey Kurakin. Large-scale evolution of image classifiers. In Internationalconference on machine learning, pages 29022911. PMLR, 2017.",
  "Chufan Shi, Haoran Yang, Deng Cai, Zhisong Zhang, Yifan Wang, Yujiu Yang, and Wai Lam. Athorough examination of decoding methods in the era of llms. arXiv preprint arXiv:2402.06925,2024": "Gemini Team, Rohan Anil, Sebastian Borgeaud, Yonghui Wu, Jean-Baptiste Alayrac, Jiahui Yu,Radu Soricut, Johan Schalkwyk, Andrew M Dai, Anja Hauth, et al. Gemini: a family of highlycapable multimodal models. arXiv preprint arXiv:2312.11805, 2023. Christian Thiel. Classification on soft labels is robust against label noise. In Ignac Lovrek,Robert J. Howlett, and Lakhmi C. Jain, editors, Knowledge-Based Intelligent Information andEngineering Systems, pages 6573, Berlin, Heidelberg, 2008. Springer Berlin Heidelberg. ISBN978-3-540-85563-7. Katherine Tian, Eric Mitchell, Huaxiu Yao, Christopher D Manning, and Chelsea Finn. Fine-tuning language models for factuality. In The Twelfth International Conference on LearningRepresentations, 2024. URL Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timo-the Lacroix, Baptiste Rozire, Naman Goyal, Eric Hambro, Faisal Azhar, et al. Llama: Openand efficient foundation language models. arXiv preprint arXiv:2302.13971, 2023. Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei,Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Openfoundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023. Ashwin Vijayakumar, Michael Cogswell, Ramprasaath Selvaraju, Qing Sun, Stefan Lee, DavidCrandall, and Dhruv Batra. Diverse beam search for improved description of complex scenes.Proceedings of the AAAI Conference on Artificial Intelligence, 32(1), Apr. 2018. doi: 10.1609/aaai.v32i1.12340. URL",
  "Qinsi Wang, Saeed Vahidian, Hancheng Ye, Jianyang Gu, Jianyi Zhang, and Yiran Chen.Coreinfer: Accelerating large language model inference with semantics-inspired adaptive sparseactivation, 2024. URL": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed H. Chi,Quoc V Le, and Denny Zhou. Chain of thought prompting elicits reasoning in large languagemodels. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors,Advances in Neural Information Processing Systems, 2022. URL Sean Welleck, Amanda Bertsch, Matthew Finlayson, Hailey Schoelkopf, Alex Xie, GrahamNeubig, Ilia Kulikov, and Zaid Harchaoui. From decoding to meta-generation: Inference-timealgorithms for large language models. arXiv preprint arXiv:2406.16838, 2024.",
  "Chang-Bin Zhang, Peng-Tao Jiang, Qibin Hou, Yunchao Wei, Qi Han, Zhen Li, and Ming-MingCheng. Delving deep into label smoothing. IEEE Transactions on Image Processing, 30:59845996, 2021": "Jianyi Zhang, Ruiyi Zhang, Lawrence Carin, and Changyou Chen.Stochastic particle-optimization sampling and the non-asymptotic convergence theory. In Silvia Chiappa andRoberto Calandra, editors, Proceedings of the Twenty Third International Conference on Arti-ficial Intelligence and Statistics, volume 108 of Proceedings of Machine Learning Research,pages 18771887. PMLR, 2628 Aug 2020. URL Jianyi Zhang, Yang Zhao, and Changyou Chen. Variance reduction in stochastic particle-optimization sampling.In Hal Daum III and Aarti Singh, editors, Proceedings of the37th International Conference on Machine Learning, volume 119 of Proceedings of Ma-chine Learning Research, pages 1130711316. PMLR, 1318 Jul 2020.URL Jianyi Zhang, Aashiq Muhamed, Aditya Anantharaman, Guoyin Wang, Changyou Chen, KaiZhong, Qingjun Cui, Yi Xu, Belinda Zeng, Trishul Chilimbi, and Yiran Chen. ReAugKD:Retrieval-augmented knowledge distillation for pre-trained language models. In Anna Rogers,Jordan Boyd-Graber, and Naoaki Okazaki, editors, Proceedings of the 61st Annual Meeting ofthe Association for Computational Linguistics (Volume 2: Short Papers), pages 11281136,Toronto, Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-short.97. URL",
  "AAdditional Analysis and Ablation Studies": "Justification on the Gradients Approximation of SLED in .2To further sup-port our methods mechanism, which utilizes logitsn logitsN to approximate the gradient ofKL(Preal, Plogits) at logits = logitsn, we manually calculate the Cosine_similarity(logitsn logitsN , logitsKL(Preal, Plogits)|logits=logitsn) among thousands of tokens and layers. We plot thedensity function for different models. We find that the majority of these values are positive, demon-strating that the directions of these two vectors are very close. Hence, our gradient approximationstrategy in .2 is reasonable. 1.000.750.500.250.000.250.500.751.00",
  "Density": "Llama-2-7B-chatLlama-2-13B-chatLlama-2-70B-chatLlama-3-8B-InstructLlama-3-70B-InstructMixtral-8x7B-Instruct : We collect 10k pairs of (logitsn logitsN , logitsnKL(Preal, Plogitsn)) on different tokensin FACTOR and different early layers. We calculate their cosine similarity values and draw thedensity function for each LLM. Most of the pairs have positive Cosine similarity values, whichverifies that the approximation strategy of SLED is reasonable. Further Ablation Studies for .4We design the following two ablation studies to supportour claims in .4. The first study, referred to as Ablation 1, directly employs Platent asthe output distribution as discussed in Q 2.2. The second study, denoted as Ablation 2, involvesdirectly scaling the differences, {logitsn logitsN }, to constrain their magnitudes within .Then, we simply average these scaled differences across different layers and apply them to Equation2 as mentioned in Q 2.3. The results presented in demonstrate that the design of our SLED isreasonable.",
  "DoLa": "Wembley Arena is in London, England. The moon is a celestial body, and the moon isin the sky. The moon is in the sky, and Wembley Arena is in London, England. London,England is on Earth, and the moon is in the sky. The moon is in the sky, and WembleyArena is on Earth. Wembley Arena is on Earth, and the moon is in the sky. The moon isin the sky, and Wembley Arena is on Earth. The moon is in the sky, and Wembley Arenais on Earth. Wembley Arena is on Earth, and the moon is in the sky. The moon is in thesky, and Wembley Arena is on Earth. Wembley Arena is on Earth, and the moon is inthe sky. The moon is in the sky, and Wembley Arena is on Earth. Wembley Arena is onEarth, and the moon is in the sky. The moon is in the sky, and Wembley Arena is onEarth. Wembley Arena is on Earth, and the moon is in the sky. The moon is in the sky,and Wembley Arena is on Earth. Wembley Arena",
  "CFurther Results from Open-ended Generation Task Benchmarks": "We have conducted additional experiments on more realistic open-ended generations datasets, Hot-PotQA , Natural Question (NQ) , TriviaQA . We adopt the Exact Match(EM) and theF1 score. Different from the setting in the , we adopt as candidatelayers for LLaMA 2 7B Chat model and as candidate layers for LLaMA 213B Chat model for both DoLa and SLED. Our method still has robust performance across differentdatasets and metrics.",
  "DImplementation Details": "We conducted all experiments utilizing NVIDIA A100 GPUs and implemented our method basedon the following repositories: DoLa1, AD2, and ICD3. For decoding responses from the LLMs onTruthfulQA, StrategyQA, and GSM8K, we employed greedy decoding. The models were operatedwith 16-bit floating-point precision and a batch size of 1. For the LLaMA 2 models sized 7B, 13B,and 70B, we utilized 1, 1, and 3 GPUs respectively. Cross-GPU inference, involving model weightsharding, was facilitated by the Hugging Face Accelerate package4. Regarding the details in .4, we evaluate the 7B-chat model for ITI, as the checkpoint ispublicly available. Combining ITI with SLED results in better performance compared to using ITIalone. AD employs an entropy-based metric to measure the sharpness of in-context hidden statesand incorporates it into the decoding process. Combining AD with SLED surpasses both the originalAD and its combination with DoLa across four model types. For CD, we have conducted experimentsin two distinct configurations: (i) the LLaMA 2 13B base model is contrasted with that of the Llama 27B base model, and (ii) the LLaMA 2 13B chat model and the LLaMA 2 7B chat model are compared.Applying SLED to the larger models (13B) boosts performance beyond vanilla CD. ICD contrasts atrustworthy 7B model with a fine-tuned, untrustworthy 7B model, and again, applying SLED on thetrustworthy 7B model improves factual accuracy further.",
  "EAdditional Results of DoLa": "presents some additional results of DoLa across various benchmarks. 5 Specifically, DoLain selects a subset of early layers as candidates for calculating the Jensen-Shannon Diver-gence (JSD) instead of using all layers. For example, for the LLaMA 2 7B Chat model, layers are designated as candidate layers. Notably, a specific trick implemented inDoLa is omitting the post-softmax step on logits for the TruthfulQA multiple-choice task to enhanceaccuracy. This trick is not applied to the vanilla greedy decoding in . In contrast, for the resultspresented in our Tables 1, 2, and 3, this technique is also been applied to vanilla greedy decoding toensure a fair comparison."
}