{
  "Abstract": "In recent years, it has been shown empirically that standard disentangled latentvariable models do not support robust compositional learning in the visual do-main. Indeed, in spite of being designed with the goal of factorising datasetsinto their constituent factors of variations, disentangled models show extremelylimited compositional generalisation capabilities. On the other hand, object-centricarchitectures have shown promising compositional skills, albeit these have 1) notbeen extensively tested and 2) experiments have been limited to scene composition where models must generalise to novel combinations of objects in a visual sceneinstead of novel combinations of object properties. In this work, we show thatthese compositional generalisation skills extend to this later setting. Furthermore,we present evidence pointing to the source of these skills and how they can beimproved through careful training. Finally, we point to one important limitationthat still exists which suggests new directions of research.",
  "Introduction": "A hallmark of human intelligence is compositional generalisation, namely, our ability to perceiveand comprehend novel combinations of familiar elements. For example, in the domain of vision, aslong as we can perceive red triangles and blue squares, then we can also perceive blue triangles andgreen squares. This gives humans the ability to make infinite use of finite means [Von Humboldtet al., 1999, Chomsky, 2014, Smolensky, 1988, McCoy et al., 2021] and it is a key priority for AI toachieve human-like abilities. However, it has proven a challenge for neural network models of vision. In the context of generative vision models, it was first hypothesized that disentangled representationsbased on the Variational Auto-Encoder (VAE) architecture could support such compositional gen-eralisation abilities [Duan et al., 2020]. While this was a reasonable hypothesis, which had somepreliminary experimental support [Higgins et al.], subsequent work showed that such results wherenot robust and they didnt extend across different levels of difficulty in generalisation [Montero et al.,2020, 2022].Furthermore these results extended to most popular architectures at the time in bothsupervised and unsupervised settings [Schott et al., 2021]. Recent work on the other hand has shown that models which perform perceptual grouping i.e.which decompose images into constituent objects exhibit increased compositional generalisationcapabilities [Singh et al., 2021, Frady et al., Wiedemer et al.]. However, these results typically focusedon scene compositions i.e. generalisation to novel configurations of known objects in a scene. This ishowever, a fundamentally different challenge to the one posed by composition of different objectproperties, both intrinsic (like shape and color) and extrinsic ones(like position and rotation), sincethe former requires manipulating the relation between objects and the later the relation between theirparts and how this is translated from proximal to distal representations [Pizlo, 2001].",
  ";": ": Generalization to novel shape and rotation combinations in the Pentomino dataset.Generalization reconstructions for both FgSeg and a WAE control model. The models where trainedon 11 of the 12 Pentomino shapes and tested at reconstructing a held out one in different configurationsof position, rotation and scale. Softmax to decide which slot is responsible for reconstructing a particular pixel, we use a Sigmoidactivation function which determines if the latent must reconstruct a particular pixel. Thus the modelis encouraged to only represent the Pentomino shape, and not the full image. This makes analysingthe model easier as having slots compete to explain the Pentomino object (a.k.a. the figure) tendsto split said object amongst the different slots. Additionally, it is easier to explore how the object isrepresented if we know it is encoded in the only available latent.",
  "Object-level Compositional Generalisation in Object-centric Models": "It was argued in Montero et al. that a possible cause for the failures at combinatorial gen-eralisation described in Montero et al. and Schott et al. was that, despite learningdisentangled representations, the generative models did not segment images into their constituentparts. Thus, when faced with novel combinations of properties that determine the same element ofan image (e.g. novel combinations of shape and color), they could not manipulate the individualelements in an image in order to change the relevant property (e.g. the location) without affecting therepresentation of other properties. : Quantitative results on standard datasets. Pixel-wise sum of squared errors for both anSA and a WAE model on the same datasets and conditions showed in . For 3DShapes modelswith a score below 20 tend to be visually indistinguishable. For dSprites, the same effect tends tohappen at 10.",
  "SlotAE1.639.761.503.06WAE18.66180.347.1014.20": ": Pentomino shapes a) The twelve Pentomino shapes and their names2. We construct thedataset by performing affine transformations of these shapes: 5 values of scale, 40 values of rotationand 20 values of translation along each of the X and Y axis. b) The low-level features that comprisethe different shapes. From top to bottom: straight lines, convex right angles and concave right angles. We test a SlotAttention (SA) model on these same conditions for which disentangled models failed inMontero et al. : novel combinations of shape and position in dSprites, and novel combinationsof shape and color in 3DShapes (see Appendix B for more details). Results can be seen in . The results on the left show a clear success for the 3DShapes dataset, where previous disentangledmodels failed catastrophically. Given the architectural properties of SA it is also easy to pinpoint towhy this can be the case. First, SA possesses in-built positional knowledge in the form of positionembeddings. This allows the model to capture the relation between different patches in the scene,and amongst them, the ones that encode parts of the same object. This should allow the model tomap how those different patches will change when asked to produce a different rotation. Second,the SlotDecoder forces reconstructions to be performed on a per-object basis, reinforcing the innatebias of the model to limit its representations to aggregations of patches that should be manipulatedtogether. The above is further illustrated with the results obtained on dSprites. On the right, the model failswhen tested on novel combinations of shape and rotations on dSprites (half of the rotations of theheart where excluded). However, while the model reconstructions are worse, they do not constitute acomplete failure as was the case in previous studies. In fact it seems like the model correctly identifiesthe required shape and rotation, but fails to properly reconstruct them. We hypothesize that in thisimage space, features are orientation specific which means that removing some of them prevents themodel from learning how to reconstruct them. In the next section we explore how far we can pushthese models when we correct for said issue in the training data.",
  "Pushing the Generalisation Capabilities of Object-centric Models": "To test whether the previous failures when known shapes are presented in novel rotations are the resultof models not having access to the correct local features during learning, we create a dataset where alllocal features are trained and test whether the model succeeds when tested on equivalent conditions(excluded shape and rotation combinations). We designed said dataset using the Pentomino shapes:sets of five blocks arranged into different shapes which we vary along different factors of variation asin dSprites ( (), see Appendix B.1 for more details). Notice that in this dataset all low-level features are straight lines or right angles (, panel b).Thus even when presented with a novel combination of shape and rotation as before, we can be moreconfident that the low-level features are not novel and the model only needs to respect the globalconfiguration of the different parts of the shape. This is in contrast to dSprites where a novel rotationof a shape such as the heart requires reconstructing a novel local-feature (e.g. the small dip of theheart in a novel rotation is effectively a novel feature in the image frame of reference). To facilitate our analysis we will test a simplified version of the SA architecture. In this version thereis only one slot which must perform figure ground segmentation (hence we name it FgSeg). As inSA the model, it uses an attention mechanism, but instead of slots competing to explain patches ofdata, the latent must only integrate information about the foreground while ignoring the background.During reconstruction we use a simplified version of the SlotDecoder where instead of using a",
  "Compositional Generalisation Results": "We train FgSeg on the Pentomino dataset, excluding half of the rotations for a 4 of the shapes (outof a total of 12). We then test the model on these excluded shapes as before. To control that themodel performance is not only due to the qualitative differences in the dataset, we compare against aWasserstein Auto-Encoder (WAE, Tolstikhin et al. ) tested on the same generalisation condition(). The figure clearly shows that, while the WAE fails to reconstruct novel rotations of a known shape,the FgSeg model succeeds, which shows that a perceptual grouping model can solve previouslychallenging generalisation conditions given an appropriate dataset one where novel combinationsof factors do not imply the presence of novel local features in image space. A quantitative measure is presented in , showing that the qualitative examination is supportedby the scores achieved by the model. In this case, training scores refers to validation on a randomlysampled held-out dataset. In all cases the FgSeg model achieves better scores than the WAE model,though the generalisation for property prediction, while better, still doesnt match the validationperformance. : Novel shape-rotation combination scores on the Pentomino dataset. Scores for bothFgSeg and the baseline WAE on the Pentomino dataset. Reconstruction scores are in P-MSE, whilerotation prediction uses plain MSE. Classification is in accuracy.",
  "Extrapolation results": "Given this success, what happens if we now test the model on an extrapolation condition where themodel must reconstruct completely novel shapes? We show that, perhaps surprisingly, the model canalso succeed when tested on reconstructing three novel shapes in the Pentomino dataset, effectivelylearning how to recombine the local features in the Pentomino dataset into potentially arbitrary shapes(). We quantify this success, showing how the FgSeg models reconstruction scores change as we excludemore and more shapes from the training data. We see that between that there is no significant dropfrom 1 to three, and only after removing half of the shapes (6) do we start to see a drop in performance. : New shape extrapolation On the left, Slot Attention reconstructions of a novel shape, inthis case the W. Left to right, different values of rotation sampled uniformly over the whole rangeof values [0, 360) can be seen. On the right, the same results for WAE. It is clear that SA succeedswhere WAE does not.: Pentomino shape-rotation generalisation. Reconstruction scores for extrapolation condi-tions of increasing number of novel shapes. Reconstruction error in P-MSE.",
  "Discussion": "We have shown that SA can solve compositional generalisation challenges that posed a significantissue for standard auto-encoder generative models. Furthermore, we have shown that failures inthose datasets are likely due to the fact that some local features are effectively removed from thedataset when we exclude certain combinations, and that if we control for this fact, we can achievegeneralsation for more complex factor combinations such as novel combinations of shape and rotation. To our surprise, when trained and tested on this qualitatively different dataset, the model was evenable to solve extrapolation tasks that require reconstruction of unseen shapes. This shows once aagain that careful data curation can have a significant effect on model capabilities when combinedwith the right architecture. Our results also show that we may not require stronger inductive biasessuch as the ones introduce in Singh et al. to solve these tasks, and that separation into discretetokens describing values of the properties is likely only needed for higher-level cognitive tasks (suchas reasoning and planning) Indeed our follow-up experiments suggest that the models learn abstract representations of theconcepts present in said dataset. When using the learned embeddings from FgSeg to fit a classificationmodel for the shape property, we find that a linear classifier is unable to correctly solve the problem,and instead we must use a non-linear one such as a Support Vector Machine. Even then, such aclassifier is unable to correctly classify the held-out combinations from using the test embeddingswithout jointly training both i.e. it does not generalise in the same way the reconstruction does(see Appendix D). Extracting or learning such higher level concepts using/from the representationsproduced by these simpler models is thus an interesting direction for future research. One way to accomplish this could be to design architecture that incorporate more principles fromthe Gestalt theory of perception, of which FgSeg and and SA only implement a subset of, namelyfigure-ground segmentation and perceptual-grouping [Wagemans et al., 2012, Yantis, 2001, Treismanand Gelade, 1980]. Principles such as common-fate (the idea that the visual system is biased towardsgrouping together features that move together in time to the same object representation), couldpotentially further constrain the model and induce more general representations of shape, and ideathat has been preeliminary explored in Tangemann et al. . and Disclosure of FundingThe authors would like to thank the members of the Mind & Machine Learning Group for usefulcomments throughout the different stages of this research. This research was supported by a ERCAdvanced Grant, Generalization in Mind and Machine #741134. Wilhelm Von Humboldt, Wilhelm Freiherr von Humboldt, et al. Humboldt:On language: On thediversity of human language construction and its influence on the mental development of the humanspecies. Cambridge University Press, 1999.",
  "R Thomas McCoy, Jennifer Culbertson, Paul Smolensky, and Graldine Legendre. Infinite use offinite means? evaluating the generalization of center embedding learned from an artificial grammar.2021": "Sunny Duan, Loic Matthey, Andre Saraiva, Nicholas Watters, Christopher P. Burgess, Alexan-der Lerchner, and Irina Higgins.Unsupervised Model Selection for Variational Disentan-gled Representation Learning.arXiv:1905.12614 [cs, stat], February 2020.URL arXiv: 1905.12614. Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick,Shakir Mohamed, and Alexander Lerchner. $\\beta$-VAE: Learning basic visual concepts with aconstrained variational framework. page 13. Milton L. Montero, Casimir J.H. Ludwig, Rui Ponte Costa, Gaurav Malhotra, and Jeffrey S. Bow-ers. The role of disentanglement in generalisation. In International Conference on LearningRepresentations, 2020. Milton L. Montero, Jeffrey S. Bowers, Rui Ponte Costa, Casimir J.H. Ludwig, and Gaurav Malhotra.Lost in latent space: Examining failures of disentangled models at combinatorial generalisation.Advances in Neural Information Processing Systems, 35:1013610149, 2022. Lukas Schott, Julius von Kgelgen, Frederik Truble, Peter Gehler, Chris Russell, Matthias Bethge,Bernhard Schlkopf, Francesco Locatello, and Wieland Brendel. Visual representation learningdoes not generalize strongly within the same domain. arXiv preprint arXiv:2107.08221, 2021.",
  "ALimitations": "We have presented our results using a single model. In our preliminary tests we trained several modelson the generalisation conditions and found that there was no significant difference in performancefor those baseline tests. As such, we conducted the rest of the experiments using only one seed pertests. Additionally, we also tested SLATE on the same conditions of dDsprites and 3DShapes andfound that it performed qualitatively the same. As such we elected to not test it further as we believeit unlikely that it would perform differently. Another limitation is that visualising the latent space provided no useful information. This isunsatisfying since raw scores tend to not provide a full picture of how the models are performing agiven task.",
  "DShapes: Contains the 6 generative factors:[floor hue, wall hue, object hue,": "scale, shape, orientation]. Colors are defined in the HSV format, and the valuescorrespond to the hue component. Here orientation defines the angle of point-of-view forthe scene. The objects themselves do not rotate. The hard condition in this case is all imagessuch that [shape=pill, object-hue=> 0.5], which were excluded from the training set.Again, these are pills colored as any of the colors in the second half of the HSV spectrum.These colors (shades of blue, purple, etc) were observed on the other shapes, and the pillwas observed with other colors such as red and orange. See Burgess and Kim .",
  "dSprites: Contains the following generative factors: [shape, scale, orientation, posi": "tion X, position Y]. Orientation here refers to the rotation of the shape along its centerof mass. The hard condition is all images such that [shape=heart, rotation< 180], whichwere excluded from the training set. Thus, no squares rotated beyond the 180 are seen duringtraining and the model must reconstruct them at test time. We also excluded redundantrotations for the training data since shapes such as the ellipsis and the square, unlike theheart, are less than 360 symmetrical. See Matthey et al. . Notice that excluding a combination of a shape with another factor means that said shape will notbe seen the same number of times during training. For example in the dSprites condition definedabove squares will be observed half as many times as the other two shapes. To ensure that shapesare observed an equal amount of times, we sample instances from the dataset with the followingprobabiliy:",
  "|{(xj, gj) Dtrain | gj[shape] == gi[shape]}|(1)": "This ensures that images in the training set that belong to the shape that is used in the generalisationcondition (e.g. the square in dSprites) are seen as frequently as other shapes. Of course there willbe less variation in the factor that is used to test said generalisation condition (e.g. position alongthe X-axis), however these have a larger number of values so they are less likely to be the cause ofover-fitting.",
  "B.1The Pentominos Dataset": "To adjudicate between these two views we unfortunately cannot rely on the dSprites dataset since theshapes used to generate it share few low-level features amongst them. Indeed the most prominentfeatures (the curve of the ellipsis, the right angles of the square and the dip of the heart) are unique toeach of them. Thus we introduce a new dataset based on the pentomino shapes to tackle this issue.",
  "Position-Y20Evenly spaced in (-1, 1)": ": Pentomino shapes a) The twelve pentomino shapes and their names4. We construct thedataset by performing affine transformations of these shapes: 5 values of scale, 40 values of rotationand 20 values of translation along each of the X and Y axis. b) The low-level features that comprisethe different shapes. From top to bottom: straight lines, convex right angles and concave rightangles. c) Example stimuli containing different configurations of the different factors, with eachshape represented once. without taking into account rotations or mirror symmetries (the so-called free pentominos). It isthen clear how these shapes solve our issue: The low-level features that compose all the shapes arestraight-lines, convex right angles and concave right angles (.b). Moreover, all shapes have atleast one instance of each of these features with the sole exception of the I which does not have aconcave right angle (notice that it is impossible to create a polygon without the other two). To generate the dataset we use similar variations in the generative factors as in dSprites with animportant caveat. Because there are 12 shapes as opposed to 3, we reduce the range of values thatthree of the generative factors (scale, position x, and position y) can take so that the dataset is notmuch larger. We preserve the 40 values of rotation since this is one of the factors we wish to test. Forthe rest, apart from the already established 12 values of shape, we use 5 values of scale and 20 values",
  "Novel shape and rotation combinations: We exclude combinations such that [shape": "{F, P, T, W}, rotation > 180]. We selected these shapes so that there are a couple ofshapes that are similar to other shapes in the training data at those rotations (T and Y, Wand V or U), and other two (F and P) that are very distinct. The fist pair tests if the modelwill confuse when the rotation value is novel and the latter if it will be able to produce areconstruction for which it is harder to interpolate. Four shapes also allows us to maintaina similar ratio of 1:3 excluded to included during training for the shape factor (4 of 12excluded here vs 1 of 3 in dSprites). As in the previous section, we remove the redundant rotations of the I, X and Z shapes and correct forthe unbalance of presentations of the shapes as defined by Equation 1. We use the same architectureand training configuration that we used for dSprites for both FgSeg and WAE. We use the latter as abaseline. We also use this baseline to control for the increase in the amount of shapes with respect todSprites. If FgSeg was to succeed in this new dataset, it could be argued that this is because havingtwelve shapes gives the model more opportunity to learn a proper representation of what constitutes ashape. A success at generalisation by FgSeg and failure from a baseline model would rule out thispossibility, which means the formers success is much more interesting than if both succeed.",
  "o": "The results can be seen in . Reconstructions are plotted along the circumference accordingto the ground truth rotation value. For simplicity we keep the other generative factors fixed at themidpoint value. In the case of FgSeg we see that the results are very impressive. The model shows nosign of confusing either to rotation or the shape of unseen combinations. Thus they clearly supportthe second view over the first one described in the introduction to this section: errors committed onnovel shape-rotation combinations are due to decoder errors. It is also clear that said improvement in generalization is not due to the increase in the number ofshapes as the results for WAE show clear and systematic failures at generalisation, especially forrotations that are far from the ones observed during training, as should be expected.",
  "C.2Additional Extrapolation Results": "We also test the model when excluding more than one shape from traning to test the degree towhich variety in the training examples influences the quality of the learned representations/genertivemechanism: Three novel shapes: We exclude all instances where [shape {P, T, W}]. We includeP and T because when we tested WAEs these were routinely confused with F and Yrespectively. Thus it may increase the likelihood of SA failing by making the same mistakes.",
  "Modified from Pentomino Naming Conventions. R.A. Nonenmacher, CC BY-SA 4.0, via WikimediaCommons": ": Generalization to novel shape and rotation combinations in the Pentomino dataset.Generalization reconstructions for both FgSeg and a WAE control model. Example rotations of theexcluded shape are plotted inside their circumference according to their rotation value. Sampleshighlighted in red are novel combinations only seen during testing. The rest (highlighted in blackare used during training. Reconstructions for FgSeg and WAE are plotted on the outside in thecorresponding angle. FgSeg is always outside and WAE inside. can see that the corners are not as well defined as before. For others like the T, the deformations aremore pronounced. In the case of the V it seems to even confuse it with the W on some examples.Nonetheless, these results are still better than what we obtained with a WAE when excluding onlyone shape. Thus we can conclude that while there is an effect of data diversity, the model is fairlygood at generalization even when a large number of examples are excluded form the training data.",
  "DTesting predictivity of learned representations": "Are the learned representations high level? In other words does the model learn concepts relatedto each shape and color or does it solve the task using simpler, lower level representations? Unlikedisentangled VAEs it is not easy to directly visualise the latent representations of these models.Instead we turn to prediction of the different concepts (such as the shape classes) as a way to assessthis. If models learn representations that are abstract, we should be able to use them to predict theclasses for both training and held out samples. We test this below. First of all, we see that models : Extrapolation to three new shapes. Figure-ground Segmentation model reconstructionswhen three shapes are excluded from training (P, T, W). Every pair of consecutive rows containsimages of one of the shapes at 10 different rotation values. These are taken at evenly spaced angelsfrom 180 to 360 and plotted increasingly from left to right. The rest of the generative factors arekept constant. We can observe that the model achieves good quality reconstructions in spite of nothaving seen these shapes at all. do learn representations that are decodable using linear probes since we need at least a two-layerMLP to achieve 100% accuracy on the training data. An even these models cannot achieve significantprediction accuracy in the test data, which shows that the models representations are not abstractafter all. : Extrapolation to six new shapes. Figure-ground Segmentation model reconstructionswhen six shapes are excluded from training (F, P, N T, V, W). Every pair of consecutive rows containsimages of one of the shapes at 10 different rotation values. These are taken at evenly spaced angelsfrom 180 to 360 and plotted increasingly from left to right. The rest of the generative factorsare kept constant. Unlike the previous example, model reconstructions start to show significantdegradation. : Testing abstract representations. On the left accuracy of three different probing modelswhen prediction the shape of training images using the representations learned by a Slot Attentionmodel: A simple Linear classifier trained with SGD, an MLP with one hidden layer and a SupportVector Machine. On the right, the same models now tested on prediction shapes for novel imagesusing the slot embeddings obtained from the model."
}