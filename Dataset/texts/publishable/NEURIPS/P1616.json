{
  "Abstract": "In this paper, we present PCoTTA, an innovative, pioneering framework for Con-tinual Test-Time Adaptation (CoTTA) in multi-task point cloud understanding,enhancing the models transferability towards the continually changing targetdomain. We introduce a multi-task setting for PCoTTA, which is practical andrealistic, handling multiple tasks within one unified model during the continualadaptation. Our PCoTTA involves three key components: automatic prototypemixture (APM), Gaussian Splatted feature shifting (GSFS), and contrastive proto-type repulsion (CPR). Firstly, APM is designed to automatically mix the sourceprototypes with the learnable prototypes with a similarity balancing factor, avoid-ing catastrophic forgetting. Then, GSFS dynamically shifts the testing sampletoward the source domain, mitigating error accumulation in an online manner.In addition, CPR is proposed to pull the nearest learnable prototype close to thetesting feature and push it away from other prototypes, making each prototypedistinguishable during the adaptation. Experimental comparisons lead to a newbenchmark, demonstrating PCoTTAs superiority in boosting the models trans-ferability towards the continually changing target domain. Our source code isavailable at:",
  "Introduction": "Recent advancements in 3D point cloud understanding have marked a significant leap in the field ofcomputer vision and 3D processing . Current methods primarilyconcentrate on training and testing on a single domain . Nevertheless, they encounternoticeable performance drops on other target data. Different datasets have domain gaps, also knownas domain shifts. For instance, models trained on meticulously structured synthetic data, such asModelNet40 , may encounter difficulties in adapting to intricate and noisy real-world data, suchas ScanObjectNN .",
  "Target Model 2": ": (a) Previous UDA approaches on point cloud suffer from catastrophic forgetting anderror accumulation toward the continually changing target domains. (b) In contrast, we present aninnovative framework PCoTTA to address these issues, enhancing the models transferability. To mitigate domain shifts, recent researchers have introduced Unsupervised Domain Adaptation(UDA) techniques into point cloud understanding. Some studies synthesizediverse training data , and others leverage adversarial learning , pseudolabeling , consistency learning , feature disentanglement or self-supervised learning to align the latent features across different domains.Nonetheless, these methods still face challenges especially when the target domain is streamingonline and the whole training set of the target domain is inaccessible. As such, Test-Time Adaptationis introduced into point cloud where the model can adapt to target distributions inan online manner at test-time without requiring any prior knowledge of the whole target domain.However, these methods may still fail when the target domain is continually changing, referred toas Continual Test-Time Adaptation (CoTTA), and such an open problem is rarely explored in pointcloud understanding contexts. On the one hand, due to the lack of specific designs for 3D data, current CoTTA methods that are designed for 2D images are inapplicable to 3D point cloud tasksor exhibit less desired performance. On the other hand, few works like MM-CCTA target theCoTTA problem in 3D point cloud tasks. Although MM-CTTA designs a Continual Cross-ModalAdaptive Clustering (CoMAC) approach for 3D semantic segmentation, it suffers from two primarylimitations: (1) it is specifically designed for one task only, and cannot handle other point cloud taskssuch as point cloud reconstruction, denoising, and registration. Redesigning and retraining a CoTTAmethod for each task is cost-expensive. (2) The adapted model would inevitably forget the previouslylearned data (catastrophic forgetting) and accumulate the model errors (error accumulation) duringthe continual adaptation, limiting the models transferability toward the target domains. Motivated by the above analysis, we present PCoTTA, an innovative, pioneering framework forContinual Test-Time Adaptation (CoTTA) in multi-task point cloud understanding, enhancing themodels transferability towards the continually changing target domain. Also, we introduce a multi-task setting for PCoTTA, which is practical and realistic, handling multiple tasks within one unifiedmodel during the adaptation. In particular, given an off-the-shelf model pre-trained on the sourcedomains, our PCoTTA aims to bridge the gap between the source and continually changing targetdomains by dynamically scheduling the shifting amplitude at test time. Our PCoTTA mainly consists of three novel modules. Firstly, to prevent catastrophic forgetting,we propose an automatic prototype mixture (APM) strategy that automatically mixes the sourceprototypes with the learnable target prototypes based on the automatic similarity balancing factor(ASBF), which avoids straying too far from its original source model. Secondly, to mitigate erroraccumulation, we present Gaussian Splatted feature shifting (GSFS) that dynamically shifts thetesting sample toward the source domain based on the distance between the testing features andthe shared prototype bank. In addition, we also introduce Gaussian weighted graph attention tofurther adaptively schedule the shifting amplitude in a learnable manner at test time. Our insight is tohighlight the similarity between the target sample and its similar prototypes and suppress the dissimilarweights. It therefore mitigates the risk of catastrophic forgetting. Finally, we devise the contrastiveprototype repulsion (CPR) to pull the nearest learnable prototype close to the testing feature andpush it away from other prototypes, making learnable prototypes more distinguishable. Furthermore, we present a new benchmark. We meticulously select a total of 30, 954 point cloud samples from4 datasets, including 2 synthetic datasets (ModelNet40 and ShapeNet ) and 2 real-worlddatasets (ScanNet and ScanObjectNN ), encompassing 7 same object categories, and generatecorresponding ground truth for 3 different tasks (reconstruction, denoising, and registration). Ourmain contributions are three-fold: We present PCoTTA, an innovative, pioneering, and unified framework for Continual Test-Time Adaptation (CoTTA) in multi-task point cloud understanding, enhancing the modelstransferability towards the continually changing target domain. We introduce a multi-tasksetting with a new benchmark for PCoTTA, which is practical and realistic in the real world. We devise three innovative modules for PCoTTA, i.e., automatic prototype mixture (APM),Gaussian Splatted feature shifting (GSFS), and contrastive prototype repulsion (CPR)strategies, where APM avoids straying too far from its original source model, mitigating therisk of catastrophic forgetting, and GSFS dynamically shifts the testing sample toward thesource model, alleviating error accumulation, and CPR pulls the nearest learnable prototypeclose to the testing feature and pushes it away from other prototypes.",
  "Related Work": "Point Cloud Understanding. Pioneering works such as PointNet and PointNet++ pro-cess point clouds directly, with PointNet utilizing pooling operations for spatial encodingsand PointNet++ employing hierarchical processing for capturing local structures at variousscales. DGCNN updates the graph in feature space to capture dynamic local semantic features,while PCT addresses global context and dependencies within point clouds using order-invariantattention mechanisms. Recent methods like Point-BERT and Point-MAE have introducedMasked Point Modeling (MPM) for reconstructing obscured point clouds. Point-BERT em-ploys a BERT-style pre-training strategy for improving performance in subsequent tasks, whilePoint-MAE uses masked autoencoders for self-supervised learning, enabling comprehensiverepresentations without labeled data. PIC explores the In-Context Learning (ICL) paradigmto enhance 3D point cloud understanding, showcasing the models potential in multi-task learning.Despite their gratifying progress, they only consider a single data domain and suffer from performancedegradation in target domains. Thus, we study continual test-time adaptation for point cloud tasks. Continual Test-Time Adaptation. This task aims to adapt the pre-trained model toward the continu-ally changing environments at test time. CoTTA employs a weighted augmentation-averagedmean teacher framework to address this issue. capitalizes on the temporal correlations withinstreamed input data through reservoir sampling and instance-aware batch normalization. in-troduce domain-specific prompts and domain-agnostic prompts to preserve both domain-specific anddomain-shared knowledge, respectively. Meanwhile, EATA focuses on adapting non-redundantsamples to facilitate efficient updates. Another work RMT uses a mean teacher setup withsymmetric cross-entropy and contrastive learning. More recently, MM-CTTA designs a ContinualCross-Modal Adaptive Clustering (CoMAC) approach for 3D semantic segmentation. Despite thesemethods showing promising potential in 3D data, they mainly suffer from two limitations: Firstly,they are specifically designed for one task only, and they cannot handle other point cloud tasks likethose in PIC . Secondly, the model would inevitably forget the previously learned knowledge(catastrophic forgetting) and accumulate prediction errors (error accumulation) during the continualadaptation, leading to undesirable results. In contrast, we present a unified model, PCoTTA, forcontinual test-time adaptation of multi-task point cloud understanding.",
  "Method": "We present a novel framework, namely PCoTTA, for Continual Test-Time Adaptation in point cloudunderstanding tasks with the practical multi-task and multi-domain setting. As depicted in ,we propose an innovative approach to effectively address the challenges of continuously changingtarget data in test time within a unified model. In particular, our PCoTTA consists of three novelcomponents: Automatic Prototype Mixture (APM) to mitigate catastrophic forgetting, Gaussian",
  "Learnable Prototype Source Prototype": ":Our PCoTTA. It addresses continually changing targets by using their nearest sourcesample as a prompt for multi-task learning within a unified model. We introduce Gaussian SplattedFeature Shifting (GSFS) to align unknown targets with sources, improving transferability. Sourceprototypes from different domains and learnable prototypes form a prototype bank. The AutomaticPrototype Mixture (APM) pairs these prototypes based on the similarity to the target, preventingcatastrophic forgetting. We project these prototypes as Gaussian distributions onto the feature plane,with larger weights assigned to more relevant ones. Our graph attention updates these weightsdynamically to mitigate error accumulation. Additionally, our Contrastive Prototype Repulsion (CPR)ensures that learnable prototypes are distinguishable for different targets, enhancing adaptability.",
  "Point Cloud Continual Test-Time Adaptation": "Problem Formulation. In this work, we study a practical setting of continual test-time adaptation formulti-task point cloud understanding. Suppose we have R source domains Ds = {D1s, D2s, . . . , DRs },our PCoTTA employs the input point clouds {Iq, Ip} (along with their targets {T kq , T kp }, where krepresents the task index) from two different sources {Dis, Djs} Ds, (i = j) to form the contextpairs, facilitating the model with a comprehensive representation that effectively generalizes acrossall source domains. In the pre-training phase, each input sample comprises two context pairs: theinput point cloud pair (query and prompt) and their corresponding target pair addressing the sametask. During the test time, our PCoTTA strives to align streamed target data It Dt (whereDt = {D1t D2t . . . } denotes the set of continuously varying target domains) towards sources thatpossess correlative features to the off-the-shelf pre-trained model. Multi-task Learning Objective. We follow PIC for three point cloud understanding tasks: (1)Reconstruction, which focuses on generating a dense point cloud from the sparse input; (2) Denoising,aiming at eliminating noise or outliers from the input point cloud; (3) Registration, dedicated torestoring the original orientation of a randomly rotated point cloud. Please note these three tasksmight be slightly different from conventional definitions. They are used as they can be handledsimilarly given current point learning can predict point positions directly. This makes them unifiedwith position output and a single loss. We employ the MPM framework to generate query resultsacross multiple downstream tasks, with a unified objective and a unified model. Let () denote themodel shared across all domains and all tasks, and predicted masked patches P can be depicted as:",
  "{Iq, Ip} P = (F(Iq) F(T kq ) F(Ip) F(T kp ), M),(1)": "where F() represents the feature encoder that produces patch-wise features, i.e., the tokens, frompoint cloud feature, and M denotes the masked token utilized to replace the masked patches in theinputs. During the pre-training stage, M is derived from the random masking among query andprompt point clouds; whereas at test time, M exclusively masks the query target to generate the",
  "Automatic Prototype Mixture": "The empirical evidence perceived by the human visual system illustrates that when people are notcertain about the identity of an object, they would seek to find a distinct object from other domainsthat share high semantic similarity with the current object in the target domain. Motivated by this, wepropose Automatic Prototype Mixture (APM) that adapts to continuously changing target data byaligning it with model-familiarized prototypes of source domains at test time. Source Prototypes Estimation. Our insight lies in that source prototypes can potentially representsource domains feature distribution. Pulling the target data toward source prototypes within thefeature space can effectively narrow the domain gap, bolstering the models transferability. Accord-ingly, the source prototypes Zis(i [1, R]) can be determined by computing the average of all tokensproduced by the MPM framework across all data within the sources:",
  "n=1F(In),Zs RRKMC,(3)": "where NDis denotes the sample number in domain Dis, K represents the tasks number, and Mindicates the tokens number in each sample. After pre-training on the multi-task and multi-domainsetting, we save all source prototypes Zs derived from the model at the last epoch, considering themas the shared common knowledge available to the target data during the test time. Prototype Bank. We propose a novel prototype bank that stores not only the source prototypesZs but also a series of learnable prototypes Zl RSKMC, where S indicates the number ofall potential target domains Dt. The learnable prototypes Zl aim to extract the current domainknowledge, thereby paving the way for handling subsequent unknown test data. We achieve thetest-time adaptation of target tokens through the mixture of the paired prototypes in the prototypebank, selectively updating only the learnable prototypes while maintaining the source ones, thusmitigating the risk of catastrophic forgetting of the source domain knowledge due to the over-relianceon the adaptively learned information. Prototype-pair Node Mixture. The source prototypes Zs along with the learnable prototypes Zl inthe prototype bank are paired to form prototype-pair nodes. As illustrated in (a), the tokensfrom each test data F(It) serve as the central node in a graph structure, adjacent to all prototype-pairnodes. We propose the Automatic Prototype Mixture (APM) module, designed to merge source and",
  "Diag(Norm(Zs) Norm(R(It)T )) RRK,(5)": "where Diag() indicates creating a diagonal matrix, Norm() denotes normalization along the lastdimension (i.e., the feature channel), and ()T represents transposition specifically applied to thelast two dimensions. Likewise, the similarity Sl RSK between the test data and the learnableprototypes can also be determined. We further propose the Automatic Similarity Balancing Factor (ASBF) to measure the impact of thesource and learnable prototypes toward the test data through the similarities Ss and Sl, automaticallyprioritizing the prototypes and assigning greater weight to more similar components. The mixedprototypes (i.e., the prototype-pair nodes) Zm can be defined as:",
  "Gaussian Splatted Feature Shifting": "Our PCoTTA considers all nodes but applies dynamically updated weights to each edge, enablingdistinguishing the feature shifting in the continual test-time adaptation. To this end, we propose theGaussian Splatted Feature Shifting (GSFS), preventing error accumulation in an online manner. Gaussian Splatted-based Graph Attention. Our key insight is that prototypes within a node (i.e.,the source-learnable prototypes pair) can mutually constrain each other and collaboratively determinethe weight of the edge connected to this node. We interpret the similarities between the test data andthese two types of prototypes as Gaussian projections onto a plane, with the source and learnableprototypes corresponding to two orthogonal axes, respectively. As illustrated in (b), theprojections of all nodes on the feature plane are treated as a blend of Gaussians, where nodes withstronger correlations to the test data (i.e., higher similarities) are assigned larger weights. In thismanner, all prototype-pair nodes are seamlessly integrated into the feature adaptation process. Wecompute the attention coefficient of each node as follows:",
  ",(7)": "where Ss, Sl represent the variances of Ss and Sl, respectively, and Ss, Sl denote their meanvalues. Note that the Gaussian function is inversely correlated with the similarity. We introducea parameter , set slightly above the maximum similarity observed, to ensure that more similarprototypes have a stronger influence. Attention-based Feature Shifting. The attention coefficient Ei,j reflects the relative importance ofthe source Zis and the learned Zjl prototypes. To ensure comparability across all connected nodes,we normalize coefficients using the Softmax function. Furthermore, we adopt a learnable sharedattention module to dynamically update edge weights as follows:",
  "i,j=0((1 Wi,j) F(It) + Wi,j Zi,jm ).(9)": "The proposed GSFS dynamically updates the contribution from each node in the graph with GaussianSplatted-based graph attention, effectively assigning distinctive weights of feature shifting accordingto each nodes relevance to the test data. This enables the test data to effectively align with task-beneficial domains, significantly diminishing the potential for error accumulation in the model.",
  "Contrastive Prototype Repulsion": "The learnable prototypes within the prototype bank strive to capture the domain-specific knowledgeof the current test data. Instead of predicting domain pseudo-labels to all test data, a common practicein prior techniques , our method pulls the most similar learnable prototype closer to the testdata while pushing it away from the others, thereby implicitly learning the distinctive features fromdifferent samples. To this end, we introduce Contrastive Prototype Repulsion (CPR) that effectivelyrefines the learnable prototypes in the prototype bank, ensuring their distinctiveness and preventingdomain-flattening from iterative learning and settling at sub-optimal points. We form a positive pairbetween the test data F(It) and their nearest learnable prototype Ztl , and the rest serve as negativepairs. Our CPR optimization objective can be expressed as:",
  "Experimental Setting": "Implementation Details. We implement our method using PyTorch and perform experiments ontwo NVIDIA A40 GPUs. Following PIC , we set the training batch size to 128 and utilize theAdamW optimizer . The learning rate is set to 0.001, with a cosine learning scheduler and aweight decay of 0.05. All models are trained for 300 epochs during the pertaining stage, and wetrain the pre-trained model for 3 epochs on the source domains to initialize our prototype bank. Attesting time, we continuously adapt test samples to the source pre-trained model and validate theanti-forgetting capability of our method across multiple rounds. Each point cloud is sampled to1, 024 points and then split into 64 patches, with each patch consisting of 32 points. Within the MPMframework, the mask ratio is set to 0.7, consistent with prior studies . New Benchmark. We meticulously curate and select data from 4 distinct datasets (2 syntheticand 2 real-world datasets), containing 7 identical object categories. Subsequently, we generatecorresponding ground truth based on 3 different tasks. The synthetic datasets include ModelNet40 and ShapeNet . ModelNet40 consists of 3, 713 samples for training and 686 for testing, whileShapeNet comprises 15, 001 training samples and 2, 145 testing samples. We also consider real-worlddata: ScanNet and ScanObjectNN . ScanNet provides annotations for individual objectsin real 3D scans, and we choose 5, 763 samples for training and 1, 677 for testing. ScanObjectNNincludes 1, 577 training samples and 392 testing samples. In all experiments, we employ ScanNet and ShapeNet as the source domains and evaluate the transferability of our method on the othertwo target domains, i.e., ModelNet40 and ScanObjectNN with 3 repeated times by default.",
  "Main Results": "shows the comparison results of our PCoTTA against other methods across tasks of recon-struction, denoising, and registration in the introduced setting. Our method consistently outperformsothers by a large margin, demonstrating superior adaptability in a multi-domain multi-task setting.Conventional methods such as PointNet , DGCNN , and PCT often struggle with unseendata, leading to significant performance drops. Augmentation-based methods like Pointmixup and PointCutMix , though adapted for multi-domain learning, exhibit limited performance in",
  "Task-specificModels": "38.2 38.1 40.4 39.3 39.5 41.5 37.7 38.4 40.7 39.0 39.8 42.0 38.2 38.1 40.9 39.2 39.5 42.2DGCNN 36.0 33.7 36.0 37.3 35.6 37.6 35.3 32.7 34.1 36.6 34.6 36.0 36.1 32.6 34.7 37.1 34.4 36.5PCT 29.7 29.6 30.6 30.2 30.3 31.5 29.6 29.8 30.6 30.2 30.5 31.8 30.8 29.5 30.8 31.5 30.1 31.8Pointmixup 37.3 36.8 38.5 38.4 37.0 40.3 37.0 36.5 37.9 38.9 36.7 40.1 37.8 36.8 38.1 38.5 36.9 40.7PointCutMix 41.5 40.1 38.2 43.3 44.7 40.5 41.1 40.4 38.5 42.9 44.1 40.7 40.8 40.0 39.2 43.1 44.5 40.2",
  "Multi-taskModels": "38.3 38.8 41.4 39.5 40.4 43.0 38.0 38.5 41.3 39.3 40.2 42.8 38.4 38.6 42.1 39.6 40.4 43.3DGCNN 37.0 33.5 36.0 38.1 35.2 37.7 36.9 33.2 36.0 38.1 35.5 37.7 36.9 33.2 36.5 38.0 35.2 37.8PCT 29.6 30.2 32.5 30.4 30.9 33.7 29.9 30.4 32.4 30.7 30.9 33.5 29.8 30.0 31.9 30.5 30.8 33.1Pointmixup 37.8 41.5 39.2 44.6 45.1 40.7 38.3 40.9 39.1 43.4 44.2 41.6 38.2 41.3 39.2 44.1 44.8 40.9PointCutMix 42.3 44.1 39.9 45.4 47.3 43.8 41.9 43.2 40.1 45.2 46.8 42.3 42.1 43.7 40.4 45.2 47.1 42.9",
  "CoTTAModels": "58.7 52.1 37.7 64.1 76.8 57.2 58.9 51.5 37.2 64.1 74.2 53.9 56.8 50.3 35.5 62.1 71.7 51.1TENT 57.9 50.6 36.8 64.8 76.4 55.0 57.8 50.0 36.7 64.7 73.5 51.1 55.2 48.4 35.0 62.1 69.2 49.7CoTTA 58.3 50.1 36.4 62.5 73.6 50.3 56.7 49.0 34.4 60.4 71.8 49.1 55.2 46.9 34.3 59.6 66.3 48.5ViDA 52.4 47.2 35.1 58.2 69.8 47.5 51.6 46.9 34.3 57.6 67.2 45.5 51.3 46.2 32.8 54.4 63.1 42.8RMT 31.2 44.0 34.3 47.4 59.6 39.9 30.6 43.5 33.9 45.6 53.0 35.8 30.4 42.7 33.8 45.9 51.1 36.4SANTA 32.3 42.1 37.8 44.9 55.2 38.6 31.7 41.9 37.4 42.0 53.4 35.6 30.1 41.6 36.4 40.6 52.9 34.7Our PCoTTA6.3 21.4 15.4 8.9 28.3 20.7 5.5 19.9 14.6 8.5 26.9 19.6 5.4 18.6 12.1 8.2 25.2 19.3 multi-task generalization. Despite incorporating task-specific heads, these methods still fall shortcompared to our unified model, which excels across all tasks due to our Automatic Prototype Mixture(APM) and Gaussian Splatted Feature Shifting (GSFS) modules. While PIC performs wellin multi-task scenarios, its transferability is limited, often failing with changing target data. OurPCoTTA addresses this by aligning the target data with source prototypes and dynamically updatinglearnable prototypes at test time, effectively narrowing the domain gap. Our method demonstratesstrong continuous online learning abilities, improving results across multiple validations and showingresilience against catastrophic forgetting and error accumulation. We compare our PCoTTA with advanced CoTTA methods like AdaBN , TENT , CoTTA ,ViDA , RMT , and SANTA . To ensure fairness, we also update the LayerNorm parametersfor AdaBN, TENT, and SANTA. While these methods handle continuously changing targets, theystruggle with multi-task aspect in our challenging setting. Even when equipped with multi-taskcapabilities, these methods still underperform compared to our PCoTTA. Our success is attributedto three main factors: (1) Usually, these methods heavily rely on the student-teacher architecture torealize consistency regularization. As a result, they would inevitably introduce pseudo-label noise,leading to error accumulation. Although they use symmetric cross-entropy or other techniques toalleviate the pseudo-label noise, such problems still exist and cannot be fundamentally addressed.In contrast, our PCoTTA framework does not use any online or offline pseudo-labeling techniques,which inherently avoids the risk of error accumulation. (2) These methods are specifically designedfor CoTTA in 2D images and perform well on 2D images. However, compared to 2D images, 3Dpoint cloud data is disordered, unstructured, and sparsely distributed, making these 2D image-basedCoTTA methods less effective or even inapplicable. Our method involves specific designs for 3D pointcloud data, e.g., Gaussian Splatted-based Graph Attention for comprehensive, patch similarity-basedadaptation, well-suited for 3D data, and achieves better performances than these methods. (3) Thesemethods often focus on single tasks and all lack specialized design in multi-task learning, which maylead to gradient conflicts in the optimization process of continual test-time adaptation. Instead, ourPCoTTA devises task-specific prototype banks where individual source-learnable prototype pairs areused for different adaptations in each task, thus favoring the multi-task learning in our setting.",
  "Ablation Studies": "Effect of Each Component. shows the effects of different components. Compared with thebaseline, Model A simply shifts target features by equally fusing with every source-learnable prototypepair (APM), demonstrating that our prototype bank effectively enriches the source informationfor targets, thereby improving the models transferability. By adding GSFS, we achieve betterperformance. This is because Model B uses the similarity between targets and prototypes as weights during aggregation, and meanwhile, our attention mechanism in GSFS also enables dynamic updatingof these weights, offering greater weights to prototypes closer to the current sample. Finally, addingCPR (Ours) enables the prototype banks learnable prototypes to be more distinct, achieving the bestperformance. These improvements confirm that these individual components are complementary andtogether they significantly promote the performance. Quantity of Learnable Prototypes. We conducted an additional ablation study on the number oflearnable prototypes, as shown in , and the results indicate marginal changes. Additionally, weshow the case with no learnable prototypes (i.e., quantity 0), where our method degrades to aligningthe target feature by solely considering source prototypes similarities. While this case achieves somedegree of test-time adaptation, its performance is less decent than our PCoTTA.",
  "Models Quantity Rec. Den. Reg.I015.5 32.4 30.7II18.2 24.9 17.4Ours25.4 18.6 12.1III36.8 19.5 14.8IV46.5 20.3 14.0": "Cross Validation. shows our models effectiveness in bridging the domain gap from thesynthetic to real scan data. Consistently, our method surpasses CoTTA in all tasks, demonstratingthe superiority of our method. Remarkably, our model also performs better than CoTTA whenpre-trained on the two real scan datasets which involve background interference and missing parts.This underscores our methods strong transferability between various domains. Efficiency Analysis. We present an analysis of model parameters and running time in . Theresults show that our method achieves fast inference on target data, and our model has the fewestparameters compared to other CTTA methods. As such, this shows potential for many real-worldapplications, e.g., autonomous driving and virtual reality, since our PCoTTA is an end-to-end test-timeadaptation method without relying on a teacher-student model or pseudo-labeling technique, it ismore efficient and suitable for real-time deployment.",
  "Visualization and Analysis": "Visualization of Different Tasks. illustrates the qualitative results in the last round ofour PCoTTA model. From the figure, we have two observations. Firstly, our proposed PCoTTAmanages to generate quality predictions in the continually changing target domain by leveragingthe proposed distinctive prototype bank, minimizing the discrepancies between source and targetdomains. Secondly, without retraining a CoTTA method for each task, our proposed PCoTTA is ableto successfully handle multiple tasks such as point cloud reconstruction, denoising, and registrationand multiple domains with a unified model, demonstrating strong practicability and transferability inthe real world. We provide more visual comparisons with state-of-the-art methods in Appendix ??. T-SNE Feature Visualization. To understand how our PCoTTA aligns the domains, we visualize thefeature distributions of the source and target domains via t-SNE. We display the latent features of thepoint cloud reconstruction task in . From the figure, we make the following observations: Thebaseline model means directly deploying the source pre-trained model in the continually changingdomains, resulting in an unsatisfactory alignment. Although CoTTA aligns the source and",
  "Conclusion": "In this paper, we present an innovative, pioneering, and unified framework, namely PCoTTA forContinual Test-Time Adaptation in multi-task point cloud understanding, boosting the modelstransferability towards the continually changing target domains. Our approach effectively mitigatescatastrophic forgetting and error accumulation issues through the three novel modules: automaticprototype mixture (APM), Gaussian Splatted feature shifting (GSFS), and contrastive prototype repul-sion (CPR). These three components make our model more adaptable and robust across continuallychanging domains by aligning the targets towards all source domains. Furthermore, we present anew benchmark in terms of the practical Continual Test-Time Adaptation for multi-task point cloudunderstanding. Comprehensive experiments show our PCoTTAs superior performance, proving itsefficacy in significantly improving the models transferability across various domains. We believeour work will inspire a new direction and interesting ideas in the community, in terms of ContinualTest-Time Adaptation for multi-task point cloud understanding.",
  "Jincen Jiang is supported by the China Scholarship Council (Grand Number 202306300023), and theResearch and Development Fund of Bournemouth University": "Idan Achituve, Haggai Maron, and Gal Chechik. Self-supervised learning for domain adaptation on pointclouds. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, pages123133, 2021. 2 Dhanajit Brahma and Piyush Rai. A probabilistic framework for lifelong test-time adaptation. In Proceed-ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 35823591, 2023.2 Haozhi Cao, Yuecong Xu, Jianfei Yang, Pengyu Yin, Shenghai Yuan, and Lihua Xie. Multi-modalcontinual test-time adaptation for 3d semantic segmentation. In Proceedings of the IEEE/CVF InternationalConference on Computer Vision, pages 1880918819, 2023. 2, 3",
  "Goirik Chakrabarty, Manogna Sreenivas, and Soma Biswas. Santa: Source anchoring network and targetalignment for continual test time adaptation. Transactions on Machine Learning Research, 2023. 8": "Angel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, SilvioSavarese, Manolis Savva, Shuran Song, Hao Su, et al. Shapenet: An information-rich 3d model repository.arXiv preprint arXiv:1512.03012, 2015. 3, 7 Yunlu Chen, Vincent Tao Hu, Efstratios Gavves, Thomas Mensink, Pascal Mettes, Pengwan Yang, andCees GM Snoek. Pointmixup: Augmentation for point clouds. In Computer VisionECCV 2020: 16thEuropean Conference, Glasgow, UK, August 2328, 2020, Proceedings, Part III 16, pages 330345.Springer, 2020. 7, 8 Angela Dai, Angel X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and Matthias Niener.Scannet: Richly-annotated 3d reconstructions of indoor scenes. In Proceedings of the IEEE/CVF Confer-ence on Computer Vision and Pattern Recognition, pages 58285839, 2017. 3, 7 Dasith de Silva Edirimuni, Xuequan Lu, Gang Li, Lei Wei, Antonio Robles-Kelly, and Hongdong Li.Straightpcf: Straight point cloud filtering. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 2072120730, 2024. 1 Dasith de Silva Edirimuni, Xuequan Lu, Zhiwen Shao, Gang Li, Antonio Robles-Kelly, and Ying He.Iterativepfn: True iterative point cloud filtering. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 1353013539, 2023. 1 Mario Dbler, Robert A Marsden, and Bin Yang. Robust mean teacher for continual and gradual test-timeadaptation. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,pages 77047714, 2023. 2, 3, 8 Zhongbin Fang, Xiangtai Li, Xia Li, Joachim M Buhmann, Chen Change Loy, and Mengyuan Liu. Explorein-context learning for 3d point cloud understanding. Advances in Neural Information Processing Systems,36, 2024. 3, 4, 7, 8",
  "Sheldon Fung, Xuequan Lu, D Edirimuni, Wei Pan, Xiao Liu, and Hongdong Li. Semreg: Semanticsconstrained point cloud registration. In Proceedings of the Europeon Conference on Computer Vision,2024. 1": "Yulu Gan, Yan Bai, Yihang Lou, Xianzheng Ma, Renrui Zhang, Nian Shi, and Lin Luo. Decoratethe newcomers: Visual domain prompt for continual test time adaptation. In Proceedings of the AAAIConference on Artificial Intelligence, volume 37, pages 75957603, 2023. 2, 3, 7 Taesik Gong, Jongheon Jeong, Taewon Kim, Yewon Kim, Jinwoo Shin, and Sung-Ju Lee. Note: Robustcontinual test-time adaptation against temporal correlation. Advances in Neural Information ProcessingSystems, 35:2725327266, 2022. 3",
  "Meng-Hao Guo, Jun-Xiong Cai, Zheng-Ning Liu, Tai-Jiang Mu, Ralph R Martin, and Shi-Min Hu. Pct:Point cloud transformer. Computational Visual Media, 7:187199, 2021. 3, 7, 8": "Ahmed Hatem, Yiming Qian, and Yang Wang. Point-tta: Test-time adaptation for point cloud registrationusing multitask meta-auxiliary learning. In Proceedings of the IEEE/CVF International Conference onComputer Vision, pages 1649416504, 2023. 2 Ahmed Hatem, Yiming Qian, and Yang Wang. Test-time adaptation for point cloud upsampling usingmeta-learning. In 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),pages 12841291. IEEE, 2023. 2 Qianjiang Hu, Daizong Liu, and Wei Hu. Density-insensitive unsupervised domain adaption on 3d objectdetection. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,pages 1755617566, 2023. 2",
  "Jincen Jiang, Xuequan Lu, Lizhi Zhao, Richard Dazaley, and Meili Wang. Masked autoencoders in 3dpoint cloud representation learning. IEEE Transactions on Multimedia, 2023. 1": "Jincen Jiang, Lizhi Zhao, Xuequan Lu, Wei Hu, Imran Razzak, and Meili Wang. Dhgcn: Dynamic hopgraph convolution network for self-supervised point cloud learning. In Proceedings of the AAAI Conferenceon Artificial Intelligence, volume 38, pages 1288312891, 2024. 1 Jincen Jiang, Qianyu Zhou, Yuhang Li, Xuequan Lu, Meili Wang, Lizhuang Ma, Jian Chang, and Jian JunZhang. Dg-pic: Domain generalized point-in-context learning for point cloud understanding. In EuropeanConference on Computer Vision, pages 455474. Springer, 2025. 2 Peng Jiang and Srikanth Saripalli. Lidarnet: A boundary-aware domain adaptation model for point cloudsemantic segmentation. In 2021 IEEE International Conference on Robotics and Automation (ICRA),pages 24572464. IEEE, 2021. 2",
  "Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou. Revisiting batch normalization forpractical domain adaptation. arXiv preprint arXiv:1603.04779, 2016. 8": "Hanxue Liang, Hehe Fan, Zhiwen Fan, Yi Wang, Tianlong Chen, Yu Cheng, and Zhangyang Wang. Pointcloud domain adaptation via masked local 3d structure prediction. In European Conference on ComputerVision, pages 156172. Springer, 2022. 2 Jiaming Liu, Senqiao Yang, Peidong Jia, Renrui Zhang, Ming Lu, Yandong Guo, Wei Xue, and ShanghangZhang. Vida: Homeostatic visual domain adapter for continual test time adaptation. arXiv preprintarXiv:2306.04344, 2023. 8, 9 Wei Liu, Zhiming Luo, Yuanzheng Cai, Ying Yu, Yang Ke, Jos Marcato Junior, Wesley Nunes Gonalves,and Jonathan Li. Adversarial unsupervised domain adaptation for 3d semantic segmentation with multi-modal learning. ISPRS Journal of Photogrammetry and Remote Sensing, 176:211221, 2021. 2 Shaocong Long, Qianyu Zhou, Xiangtai Li, Xuequan Lu, Chenhao Ying, Yuan Luo, Lizhuang Ma, andShuicheng Yan. Dgmamba: Domain generalization via generalized state space model. In Proceedings ofthe 30th ACM International Conference on Multimedia (ACM MM), 2024. 2",
  "Shitong Luo and Wei Hu. Diffusion probabilistic models for 3d point cloud generation. In Proceedings ofthe IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 28372845, 2021. 1": "Zhipeng Luo, Zhongang Cai, Changqing Zhou, Gongjie Zhang, Haiyu Zhao, Shuai Yi, Shijian Lu,Hongsheng Li, Shanghang Zhang, and Ziwei Liu. Unsupervised domain adaptive 3d detection withmulti-level consistency. In Proceedings of the IEEE/CVF International Conference on Computer Vision,pages 88668875, 2021. 2 Fahim Faisal Niloy, Sk Miraj Ahmed, Dripta S Raychaudhuri, Samet Oymak, and Amit K Roy-Chowdhury.Effective restoration of source knowledge in continual test time adaptation. In Proceedings of the IEEE/CVFWinter Conference on Applications of Computer Vision, pages 20912100, 2024. 2 Shuaicheng Niu, Jiaxiang Wu, Yifan Zhang, Yaofo Chen, Shijian Zheng, Peilin Zhao, and Mingkui Tan.Efficient test-time model adaptation without forgetting. In International Conference on Machine Learning,pages 1688816905. PMLR, 2022. 2, 3 Yatian Pang, Wenxiao Wang, Francis EH Tay, Wei Liu, Yonghong Tian, and Li Yuan. Masked autoencodersfor point cloud self-supervised learning. In European Conference on Computer Vision, pages 604621.Springer, 2022. 1, 3, 7 Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3dclassification and segmentation. In Proceedings of the IEEE/CVF Conference on Computer Vision andPattern Recognition, pages 652660, 2017. 1, 3, 7, 8 Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas. Pointnet++: Deep hierarchical featurelearning on point sets in a metric space. Advances in Neural Information Processing Systems, 30, 2017. 3 Can Qin, Haoxuan You, Lichen Wang, C-C Jay Kuo, and Yun Fu. Pointdan: A multi-scale 3d domainadaption network for point cloud representation. Advances in Neural Information Processing Systems, 32,2019. 2 Amirreza Shaban, JoonHo Lee, Sanghun Jung, Xiangyun Meng, and Byron Boots. Lidar-uda: Self-ensembling through time for unsupervised lidar domain adaptation. In Proceedings of the IEEE/CVFInternational Conference on Computer Vision, pages 1978419794, 2023. 2 Di Shao, Xuequan Lu, Weijia Wang, Xiao Liu, and Ajmal Saeed Mian. Trici: Triple cross-intra branchcontrastive learning for point cloud analysis. IEEE Transactions on Visualization and Computer Graphics,2024. 1 Yuefan Shen, Yanchao Yang, Mi Yan, He Wang, Youyi Zheng, and Leonidas J Guibas. Domain adaptationon point clouds via geometry-aware implicits. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 72237232, 2022. 2 Damian Sjka, Sebastian Cygert, Bartomiej Twardowski, and Tomasz Trzcinski. Ar-tta: A simple methodfor real-world continual test-time adaptation. In Proceedings of the IEEE/CVF International Conferenceon Computer Vision, pages 34913495, 2023. 2 Hugues Thomas, Charles R Qi, Jean-Emmanuel Deschaud, Beatriz Marcotegui, Franois Goulette, andLeonidas J Guibas. Kpconv: Flexible and deformable convolution for point clouds. In Proceedings of theIEEE/CVF International Conference on Computer Vision, pages 64116420, 2019. 1 Mikaela Angelina Uy, Quang-Hieu Pham, Binh-Son Hua, Thanh Nguyen, and Sai-Kit Yeung. Revisitingpoint cloud classification: A new benchmark dataset and classification model on real-world data. InProceedings of the IEEE/CVF International Conference on Computer Vision, pages 15881597, 2019. 1, 3,7 Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, and Trevor Darrell. Tent: Fully test-timeadaptation by entropy minimization. In International Conference on Learning Representations, 2021. 8",
  "Feiyu Wang, Wen Li, and Dong Xu. Cross-dataset point cloud recognition using deep-shallow domainadaptation network. IEEE Transactions on Image Processing, 30:73647377, 2021. 2": "Qin Wang, Olga Fink, Luc Van Gool, and Dengxin Dai. Continual test-time domain adaptation. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 72017211,2022. 2, 3, 7, 8, 9 Yanshuo Wang, Jie Hong, Ali Cheraghian, Shafin Rahman, David Ahmedt-Aristizabal, Lars Petersson, andMehrtash Harandi. Continual test-time domain adaptation via dynamic sample selection. In Proceedingsof the IEEE/CVF Winter Conference on Applications of Computer Vision, pages 17011710, 2024. 2",
  "Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon.Dynamic graph cnn for learning on point clouds. ACM Transactions on Graphics, 38(5):112, 2019. 1, 3,7, 8": "Yan Wang, Junbo Yin, Wei Li, Pascal Frossard, Ruigang Yang, and Jianbing Shen. Ssda3d: Semi-superviseddomain adaptation for 3d object detection from point cloud. In Proceedings of the AAAI Conference onArtificial Intelligence, volume 37, pages 27072715, 2023. 2 Yi Wei, Zibu Wei, Yongming Rao, Jiaxin Li, Jie Zhou, and Jiwen Lu. Lidar distillation: Bridging thebeam-induced domain gap for 3d object detection. In European Conference on Computer Vision, pages179195. Springer, 2022. 2 Yushuang Wu, Zizheng Yan, Ce Chen, Lai Wei, Xiao Li, Guanbin Li, Yihao Li, Shuguang Cui, andXiaoguang Han. Scoda: Domain adaptive shape completion for real scans. In Proceedings of theIEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1763017641, 2023. 2 Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao.3d shapenets: A deep representation for volumetric shapes. In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition, pages 19121920, 2015. 1, 3, 7 Mutian Xu, Runyu Ding, Hengshuang Zhao, and Xiaojuan Qi. Paconv: Position adaptive convolution withdynamic kernel assembling on point clouds. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 31733182, 2021. 1 Jihan Yang, Shaoshuai Shi, Zhe Wang, Hongsheng Li, and Xiaojuan Qi. St3d: Self-training for unsuperviseddomain adaptation on 3d object detection. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 1036810378, 2021. 2 Jihan Yang, Shaoshuai Shi, Zhe Wang, Hongsheng Li, and Xiaojuan Qi. St3d++: Denoised self-trainingfor unsupervised domain adaptation on 3d object detection. IEEE Transactions on Pattern Analysis andMachine Intelligence, 45(5):63546371, 2022. 2 Senqiao Yang, Jiarui Wu, Jiaming Liu, Xiaoqi Li, Qizhe Zhang, Mingjie Pan, Yulu Gan, Zehui Chen, andShanghang Zhang. Exploring sparse visual prompt for domain adaptive dense prediction. In Proceedingsof the AAAI Conference on Artificial Intelligence, volume 38, pages 1633416342, 2024. 3 Li Yi, Boqing Gong, and Thomas Funkhouser. Complete & label: A domain adaptation approach tosemantic segmentation of lidar point clouds. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition, pages 1536315373, 2021. 2 Xumin Yu, Lulu Tang, Yongming Rao, Tiejun Huang, Jie Zhou, and Jiwen Lu. Point-bert: Pre-training 3dpoint cloud transformers with masked point modeling. In Proceedings of the IEEE/CVF Conference onComputer Vision and Pattern Recognition, pages 1931319322, 2022. 3, 7 Zhiqi Yu, Jingjing Li, Zhekai Du, Fengling Li, Lei Zhu, and Yang Yang. Noise-robust continual test-timedomain adaptation. In Proceedings of the 31st ACM International Conference on Multimedia, pages26542662, 2023. 2 Jinlai Zhang, Lyujie Chen, Bo Ouyang, Binbin Liu, Jihong Zhu, Yujin Chen, Yanmei Meng, and DanfengWu. Pointcutmix: Regularization strategy for point cloud classification. Neurocomputing, 505:5867,2022. 7, 8 Weichen Zhang, Wen Li, and Dong Xu. Srdan: Scale-aware and range-aware domain adaptation networkfor cross-dataset 3d object detection. In Proceedings of the IEEE/CVF Conference on Computer Visionand Pattern Recognition, pages 67696779, 2021. 2 Sicheng Zhao, Yezhen Wang, Bo Li, Bichen Wu, Yang Gao, Pengfei Xu, Trevor Darrell, and KurtKeutzer. epointda: An end-to-end simulation-to-real domain adaptation framework for lidar point cloudsegmentation. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 35, pages35003509, 2021. 2 Qianyu Zhou, Zhengyang Feng, Qiqi Gu, Jiangmiao Pang, Guangliang Cheng, Xuequan Lu, Jianping Shi,and Lizhuang Ma. Context-aware mixup for domain adaptive semantic segmentation. IEEE Transactionson Circuits and Systems for Video Technology (TCSVT), 33(2):804817, 2023. 2 Qianyu Zhou, Qiqi Gu, Jiangmiao Pang, Xuequan Lu, and Lizhuang Ma. Self-adversarial disentanglingfor specific domain adaptation. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI),45(7):89548968, 2023. 2 Qianyu Zhou, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Shouhong Ding, and Lizhuang Ma. Test-timedomain generalization for face anti-spoofing. In Proceedings of the IEEE/CVF Conference on ComputerVision and Pattern Recognition (CVPR), 2024. 2 Qianyu Zhou, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Ran Yi, Shouhong Ding, and Lizhuang Ma.Instance-aware domain generalization for face anti-spoofing. In Proceedings of the IEEE/CVF Conferenceon Computer Vision and Pattern Recognition (CVPR), pages 2045320463, 2023. 2 Longkun Zou, Hui Tang, Ke Chen, and Kui Jia. Geometry-aware self-training for unsupervised domainadaptation on object point clouds. In Proceedings of the IEEE/CVF International Conference on ComputerVision, pages 64036412, 2021. 2"
}