{
  "Abstract": "Data grows in value when joined and combined; likewise the power of voicegrows in ensemble. With 15 UK choirs, we explore opportunities for bottom-updata governance of a jointly created Choral AI Dataset. Guided by a survey ofchorister attitudes towards generative AI models trained using their data, we exploreopportunities to create empowering governance structures that go beyond opt inand opt out. We test the development of novel mechanisms such as a Trusted DataIntermediary (TDI) to enable governance of the dataset amongst the choirs andAI developers. We hope our findings can contribute to growing efforts to advancecollective data governance practices and shape a more creative, empowering futurefor arts communities in the generative AI ecosystem.",
  "Introduction & Related Work": "Current concerns about AI and creativity are often grounded in artists fear of losing control overtheir work when it becomes training data for AI models. While current technical and legal discourseon this topic concentrates on enabling individual opt in and opt out, there are other dimensions ofempowerment worth exploring that may be possible through collective approaches to governancethat can enable further distribution of power between contributors to AI training datasets and AIdevelopers. We introduce the Choral Data Trust Experiment as a case study, in particular ourwork surveying the attitudes of artists who contributed to the project in order to guide the design ofcollective governance infrastructure for the jointly created Choral AI Dataset. Models of data governance have been explored by generative AI initiatives such as the BLOOMLarge Language Model (LLM) and StarCoder LLM , but at present, it is not considered formany model building efforts. As a result, data contributors often remain an unacknowledged anddisempowered group in the model building pipeline. This problem compounds at the intersection ofarts and AI, as the work of artists has been used to train generative AI models that reproduce theirwork often without their knowledge, consent, or benefit. While examples are emerging for waysto expand transparency about the inclusion of art in training datasets such as Spawnings Have IBeen Trained and to enable creator opt out such as BigCodes Am I in The Stack?, governance toolsthat focus on individual opt in or opt out put the burden to act on the individual and do not createaffordances to shape the overall model building process or output. This project aims to challenge this status quo in AI and build upon prior efforts to capture collectiverights and preferences in governance mechanisms such as ethical charters and licences andlegal entities such as data cooperatives, data trusts and Trusted Data Intermediaries toempower data contributors to shape the process and outcomes of generative AI projects.",
  "The Choral Data Trust Experiment": "15 community choirs from across the UK were invited to record performances of a songbookcomposed by artists Holly Herndon and Mat Dryhurst. The compositions and recording methodswere optimised for the collection of a Choral AI Dataset, purpose-built for training Choral AI models.Herndon and Dryhurst worked alongside researchers from IRCAM, a French music research institute,and engineers at Stability AI to train state-of-the-art models for the exhibition The Call, which openedat Serpentine in Fall 2024. This model building process is inspired by previous work by Herndon andDryhurst on Holly+, a voice AI model trained using recordings of Herndons own voice. To collectthe Choral AI Dataset, the artists traveled to each choir for the recording session, which includeduse of an ambisonic microphone to capture higher quality data than stereo sound to future-proofthe dataset (see: ). The Data Card for the Choral AI Dataset documents further technicalinformation about the data collection, processing, and use considerations. Alongside the technical challenge of scaling up data collection and model development to accom-modate hundreds of different voices, this project also presents the challenge of scaling up datagovernance with hundreds of choristers with different backgrounds and preferences. Inspired by theData Trusts Initiative and the investment in human infrastructure such as Data Trustees to facilitategovernance for large groups of diverse data subjects, we test the development of a Trusted DataIntermediary (TDI) to assess the opportunity for collective governance of the Choral AI Dataset. Building Capacity for Collective Data GovernanceThe TDI is composed of a team of Serpentineart curators, legal experts, and an independent data steward, who served as the primary point ofcontact for the choirs. The data steward began by hosting several Data Conversations on Zoomopen to all choristers to share information about the process of training models from the Choral AIDataset and explore points in the model building pipeline where choristers were interested in moreinformation or agency (see: ). Afterwards, a Choral Data Preferences survey was released,which received over 100 responses from each of the 15 choirs, as well as a Licence Preferences Polis,which received over 700 anonymous votes. The responses were used to synthesise overall preferencesand identify distinct preference groups towards use and governance of the Choral AI Dataset. Data Preferences Survey FindingsA key discovery was the recognition of the discomfort aroundusing the term data when referring to choral performance. Choristers described this as dehumanis-ing, disembodied, and disempowering while also exciting and opening up new possibilities. Italso highlights the often disjointed motivations between AI developers and artists (especially liveperformers), where the former are focused on leveraging digital traces of the art as raw material andthe latter are often focused on the ephemeral process of creating or experiencing the art itself. This concern of misalignment was reflected in survey outcomes, as over 25% of participants respondedthat they were not comfortable with use of their data by users beyond the project to train an AImodel. This stood in contrast to only 4% of participants responding that they were not comfortablewith Herndon and Dryhurst creating the Choral AI model for the exhibition. This indicates that",
  ": Changes in preferences around crediting for individual contribution (left) and choircontribution (right) by future users of the Choral AI Dataset": "transparency about data practices can mitigate unease and distrust surrounding datafication and modelbuilding processes. This also indicates that blanket opt in and opt out do not capture critical nuancesof consent preferences, as context of use and user intentions may matter more than the act itself ofsharing data for generative AI. The survey also highlights that participants were more interested ingroup recognition, with over 92% of participants indicating interest in choir level credit, while only34% indicating interest in individual credit (see: ). This is further evidence that governancemechanisms should be able to interface with semantic groups rather than solely individuals. Licence Preferences Polis FindingsAcross the choirs and individuals, there were differences inrisk tolerance and openness to data sharing, important considerations for setting licence terms for theChoral AI Dataset and models. To surface distinct preference groups, a Polis with 20 seed statementswas shared with participants to vote on (Agree, Disagree, Pass/Unsure). These statements describeddifferent scenarios for potential dataset users and use cases. Over anonymous 700 votes were cast by37 voters which resulted in 3 opinion groups (A, B, C). While Group C was more permissive in theirviews towards sharing and wider reuse of the Choral AI Dataset and models, Groups A and B weremore cautious, against public sharing and commercial and profit-generating use cases (see: ).",
  ": Polis statements with the highest levels of disagreement among preference groups": "However, 90% of voters agreed that the Choral AI Dataset should be shared with users who complywith the licence terms and around 80% are interested in sharing for non-commercial use cases thatre-licence under the same terms and credit the choirs for their contribution (see: ). Thesefindings indicate that if the Choral AI Dataset is released, a licence like the Creative CommonsAttribution Non-Commercial Share Alike (CC-BY-NC-SA) would be a good fit to meet grouppreferences. This outcome and the Polis report data will be used in future negotiations with the AIdevelopers when selecting licences and release strategies for the Choral AI Dataset and models.",
  "Prototyping Novel Governance Mechanisms": "Guided by the findings from the group conversations, survey and Polis, the TDI team worked withlegal experts to prototype novel governance mechanisms that aimed to encode contributor preferencesinto actionable and accountable legal structures. These are described below and in : Formalising Serpentine LLC as the legal entity for the Trusted Data Intermediary, whichcan enter into contracts, act as the administrative hub for further sub-licensing of the dataset,and be responsible for enforcing the terms set out in the Performance Rights Agreement andData Rights Mandate Consolidating choristers preferences in the terms of the Performance Rights Agreement,entered into between the Trusted Data Intermediary and choristers. This Agreement lever-ages individual performers rights to set terms for downstream usage of the dataset, whichincludes permissible uses and types of users, expectations around data security, creditingand compensation practices Creating a Data Rights Mandate that enables solo singers whose voices (personally identi-fiable information) are captured in the dataset to mandate the Trusted Data Intermediary theexercise of their GDPR UK data rights",
  "Future Work": "While the experiment is still underway, our findings raise questions about how enabling foundationalcomponents of collective data governance such as providing transparency, building trust, and account-ing for diverse preferences can be managed at scale for datasets with many contributors. Alongsidethe development of automated tools, we propose further investigation into the development anddeployment of Trusted Data Intermediaries to navigate these complex challenges. For the Choral Data Trust Experiment, the TDI has played an important role in capturing, synthesising,and translating preferences across the choirs into practice. By leveraging Serpentine LLC as a trustedlegal entity for the TDI, we have the ability to enter into and uphold legal agreements to sustainongoing gating, maintenance, and governance of the dataset. Whether in the form of an individualrepresentative or team, a TDI can bring flexibility to the process of data governance and a human touchto an otherwise confusing, nonhuman process of transforming art into raw material for producingAI models. We hope to collaborate with more arts and AI communities to advance our sharedunderstanding and best practices for collective and empowering approaches to data governance in thegenerative AI ecosystem.",
  "and Disclosure of Funding": "The Choral Data Trust Experiment is led by Victoria Ivanova and Jennifer Ding, who acted as the datasteward, with Eva Jger, Ruth Waters and Mercedes Bunz. It is a research and development projectassociated with Holly Herndon and Mat Dryhusts commission and solo exhibition at Serpentine, TheCall and incubated by the Future Art Ecosystems project at Serpentine Arts Technologies.",
  "The Choral Data Trust Experiment would not be possible without the following UK choirs:": "Blackburn Peoples Choir, Blackburn Carnoustie Choir, Carnoustie Cunninghame Choir, Beith The Fitzhardinge Consort, Bristol The Fourth Choir, London HIVE Choir, Belfast Leeds Vocal Movement, Leeds London Contemporary Voices, London Musarc, London New London Chamber Choir, London Open Arts Community Choir, Belfast Ordsall Acappella Singers, Salford The Ravenswood Singers, Newcastle South Lakes A Cappella, Windermere Spectrum Singers, Penarth",
  "Hughes, S., H. de Vries, J. Robinson, C. M. Ferrandis, L. B. Allal, L. von Werra, J. Ding,S. Paquet, and Y. Jernite (2023). The bigcode project governance card": "Jernite, Y., H. Nguyen, S. Biderman, A. Rogers, M. Masoud, V. Danchev, S. Tan, A. S. Luccioni,N. Subramani, I. Johnson, G. Dupont, J. Dodge, K. Lo, Z. Talat, D. Radev, A. Gokaslan, S. Nikpoor,P. Henderson, R. Bommasani, and M. Mitchell (2022). Data governance in the age of large-scaledata-driven language technology. In Proceedings of the 2022 ACM Conference on Fairness,Accountability, and Transparency, FAccT 22, New York, NY, USA, pp. 22062222. Associationfor Computing Machinery. Li, R., L. B. Allal, Y. Zi, N. Muennighoff, D. Kocetkov, C. Mou, M. Marone, C. Akiki, J. Li,J. Chim, Q. Liu, E. Zheltonozhskii, T. Y. Zhuo, T. Wang, O. Dehaene, M. Davaadorj, J. Lamy-Poirier, J. Monteiro, O. Shliazhko, N. Gontier, N. Meade, A. Zebaze, M.-H. Yee, L. K. Umapathi,J. Zhu, B. Lipkin, M. Oblokulov, Z. Wang, R. Murthy, J. Stillerman, S. S. Patel, D. Abulkhanov,M. Zocca, M. Dey, Z. Zhang, N. Fahmy, U. Bhattacharyya, W. Yu, S. Singh, S. Luccioni, P. Villegas,M. Kunakov, F. Zhdanov, M. Romero, T. Lee, N. Timor, J. Ding, C. Schlesinger, H. Schoelkopf,J. Ebert, T. Dao, M. Mishra, A. Gu, J. Robinson, C. J. Anderson, B. Dolan-Gavitt, D. Contractor,S. Reddy, D. Fried, D. Bahdanau, Y. Jernite, C. M. Ferrandis, S. Hughes, T. Wolf, A. Guha, L. vonWerra, and H. de Vries (2023). Starcoder: may the source be with you! Pistilli, G., C. Muoz Ferrandis, Y. Jernite, and M. Mitchell (2023). Stronger together: on thearticulation of ethical charters, legal tools, and technical documentation in ml. In Proceedings ofthe 2023 ACM Conference on Fairness, Accountability, and Transparency, FAccT 23, New York,NY, USA, pp. 343354. Association for Computing Machinery. Scao, T. L., A. Fan, C. Akiki, E. Pavlick, S. Ilic, D. Hesslow, R. Castagn, A. S. Luccioni,F. Yvon, M. Gall, J. Tow, A. M. Rush, S. Biderman, A. Webson, P. S. Ammanamanchi, T. Wang,B. Sagot, N. Muennighoff, A. V. del Moral, O. Ruwase, R. Bawden, S. Bekman, A. McMillan-Major, I. Beltagy, H. Nguyen, L. Saulnier, S. Tan, P. O. Suarez, V. Sanh, H. Laurenon, Y. Jernite,J. Launay, M. Mitchell, C. Raffel, A. Gokaslan, A. Simhi, A. Soroa, A. F. Aji, A. Alfassy,A. Rogers, A. K. Nitzav, C. Xu, C. Mou, C. Emezue, C. Klamm, C. Leong, D. van Strien, D. I.Adelani, and et al. (2022). BLOOM: A 176b-parameter open-access multilingual language model.CoRR abs/2211.05100.",
  "Performance RightsAgreement": "Data Preferences SurveySet terms between TDI and choristers thatcollectivises individual performers rightsfor downstream usage of the dataset,which includes permissible uses andtypes of users, expectations around datasecurity, crediting, and compensationpractices. Data Rights MandateLicence Preferences PolisEnable solo singers whose individualvoices (personally identifiable informa-tion) are captured in the dataset to man-date TDI to exercise data rights on behalfof the group."
}