{
  "Abstract": "Foundation models, particularly those that incorporate Transformer architectures,have demonstrated exceptional performance in domains such as natural languageprocessing and image processing. Adapting these models to structured data, liketables, however, introduces significant challenges. These difficulties are even morepronounced when addressing multi-table data linked via foreign key, which isprevalent in the enterprise realm and crucial for empowering business use cases.Despite its substantial impact, research focusing on such linked business tableswithin enterprise settings remains a significantly important yet underexploreddomain. To address this, we introduce a curated dataset sourced from an EnterpriseResource Planning (ERP) system, featuring extensive linked tables. This dataset isspecifically designed to support research endeavors in table representation learning.By providing access to authentic enterprise data, our goal is to potentially enhancethe effectiveness and applicability of models for real-world business contexts.**",
  "Introduction": "Deep learning has made substantial strides in areas like text understanding, language translation,image classification, and object detection. These advancements are largely driven by foundationalmodels trained on diverse datasets and self-supervised training techniques, especially those thatincorporate Transformer architectures. However, using these models on structured, tabular data,essential for enterprise business operations, poses unique challenges. These challenges become morepronounced with multi-table configurations consisting of large tables interconnected by foreign keysand comprising extensive business datasets, a setup to which we refer to as linked business tables.Such setups are common in real-world business scenarios. The challenges in applying foundationalmodels to linked business data are primarily twofold: algorithmic and data-related. Algorithmically, asignificant challenge is adapting models that were originally designed for unstructured internet data tohandle structured data effectively - see (Grinsztajn et al., 2022) for a comprehensive discussion. Thisprocess requires a sophisticated integration of structural knowledge and the unique characteristicsof linked business data, which is inherently more complex and interconnected than straightforwardinternet-scraped table data.One major limitation in the current landscape is the absence of realistic, enterprise-linked multi-tabledatasets at scale. Existing table datasets often originate from HTML pages and do not accuratelyrepresent the complexity and dynamics of expansive database tables used in active enterprise sys-tems (Bodensohn et al., 2024). Moreover, obtaining large, clean, and high-quality datasets for",
  ": Dataset Schemas. Schemas for the four tables constituting the SALT dataset. Primary keysare highlighted in bold letters and with a key symbol. Foreign keys interconnecting tables": "structured tabular applications presents difficulties (Hulsebos et al., 2023; Van Breugel and VanDer Schaar, 2024), particularly in enterprise settings where data privacy, confidentiality, and commer-cial interests restrict data access. This lack of suitable public datasets leads to significant domainadaptation challenges and shifts in data distribution, which pose difficulties for many existing mod-els (Fey et al., 2024). To tackle these issues, we have curated the Sales Autocompletion LinkedBusiness Tables (SALT) dataset, sourced from an Enterprise Resource Planning (ERP) system.ERP systems are comprehensive, multifunctional platforms essential for managing all core businessoperations including finance, human resources, production, and supply chains. As the backboneof organizational data management, ERP systems provide an excellent foundation for developingand evaluating data models that accurately reflect complex, real-world enterprise environments.The SALT dataset, which includes interconnected relational tables with a focus on sales, encom-passes several million entries across various enterprise sales operations (cf. synthetic sales datasetSalesDB Motl and Schulte (2024)). By sharing the SALT dataset with the research community, weaim to stimulate advancements in table representation learning and refine algorithm development toenhance applicability and performance in real-world settings. This initiative is crucial for evolvingdeep learning models that not only understand but also effectively function within the complexitiesof large-scale enterprise data landscapes, thereby promoting the development of enterprise-specificmachine learning applications. Related Work: The majority of existing table datasets originate from scraping the Web, notablyextracted from HTML pages or CSV files from GitHub, which inadequately capture the complexityand dynamics typical of large database tables that are employed in operational enterprise systems.WebTables (Cafarella et al., 2008) corpus includes a massive collection of 233 million tables, sourcedfrom HTML pages via the Common Crawl project. While WebTables offers an extensive quantity oftables, its diversity is constrained because it solely comprises HTML tables from web pages. TURLDeng et al. (2020) provides a cleaner corpus of 580 thousand tables extracted from Wikipedia. Incontrast, GitTables (Hulsebos et al., 2023) contains over 10 million tables extracted from \"comma-separated value\" files (CSVs) found on GitHub. Tables from GitTables generally exhibit structuraldifferences compared to those from WebTables, making GitTables an essential corpus despite itsfocus on a single file type. TabLib (Eggert et al., 2023) comprises 627 million tables across variousfile formats and totaling 69 TiB, sourced from GitHub and Common Crawl. Notably, it comprisesexceptionally large tables of several million rows and columns. LakeBench (Deng et al., 2024) isa collection of benchmarks to resemble enterprise data lakes, containing tables from a variety ofsources such as open government data for the purpose of unionability, joinability, and subset tasks.",
  "Numeric58.1%57.9%51.4%33.6%String38.7%41.6%47.4%61.8%Other3.2%0.5%1.2%4.6%": "predicting fields typically missing in sales orders - see in the Appendix for screenshots ofthe user interface of a sales order application. This dataset is crucial to the sales and distributionprocess, especially for creating the \"Sales Order Document.\" Each of these documents records asingle transaction that includes various items, marking a distinct phase in the sales cycle.Structured around four principal tablessales documents, sales document items, customers, andaddressesthe dataset consolidates data from a single enterprise that underwent anonymization (fordetails see Appendix Sec. A.1). The sales documents table logs vital details such as sales office,sales group, payment conditions, and shipping arrangements, limiting its entries to those specificallycategorized as sales orders. The sales document items table captures detailed information for each lineitem in these documents, including the product sold, the shipping point, and the parties involved inthe transaction. Concurrently, the customer table holds comprehensive master data about customers,further elaborated in the addresses table with specifics like country and region. The input variables inthe dataset include a mix of fields typically populated by users during the creation of a sales order,augmented by master data fields like material number and customer details. The target variables arenot always maintained; they are optional and may not be filled out for certain transactions dependingon particular scenarios or requirements. This intricate structure of SALT not only enhances modeltraining for missing field predictions but also effectively replicates complex ERP interactions. Task:In the dataset, 21 fields are categorized as potential input variables, serving as featuresfor predictive modeling applications, while 8 fields are designated as target variables, intended forprediction based on the input data analysis. The predictive model, which will be trained using thisdataset, is specifically tasked with performing multiclass classification on seven critical variables.These variables are essential for ensuring the seamless execution of sales orders: I_SalesDocument.SalesOffice - Sales activities for specific products and regions I_SalesDocument.SalesGroup - Subdivisions of a distribution chain I_SalesDocument.CustomerPaymentTerms - Payment conditions, i.e., deadlines andearly payment discounts I_SalesDocument.ShippingCondition - Logistics terms I_SalesDocumentItem.ShippingPoint - Dispatch location I_SalesDocumentItem.Plant - Production/ storage facility, critical for inventory control I_SalesDocument.IncotermsClassification andI_SalesDocumentItem.IncotermsClassification - International commercial terms,outline transaction responsibilities like shipping and insurance Structure:The dataset is structured into four primary tables encompassing a totalof 500,908 sales orders (I_SalesDocument), which include 2,319,944 sales order items(I_SalesDocumentItem) associated with 139,611 unique business partners (I_Customer) and1,788,887 (I_AddrOrgNamePostalAddress) addresses - see for the table schemas. The tablefields are filtered to include only the data relevant to the specific use case described above. Afterfiltering, the tables are merged to form a single flat dataset containing 2,319,944 rows, such thateach row in the dataset represents a single sales order item (for details see Appendix Sec. A.4).The entries cover transactions conducted between January 1, 2018, and December 31, 2020. Toassess the datasets predictive modeling utility, data was divided into temporal splits, with validationsegments starting from February 1, 2020, and test segments from July 1, 2020. For an analysis of thedistribution values, see Tab. 1.",
  "minimal pre-processing primarily aimed at addressing privacy concerns. Several challenges arisefrom the nature and quality of the dataset, which need careful consideration:": "Diversity: There is a substantial diversity in certain data fields due to the wide range ofunique values they contain. For instance, the field I_SalesDocumentItem.ShipToPartyincludes 18,097 distinct customer IDs, while I_SalesDocumentItem.Product comprises187,562 unique product identifiers. Class imbalance: The dataset demonstrates a pronounced class imbalance. The distributionof sales offices across sales orders is highly skewed; the most frequently occurring salesoffice is associated with over 60% of the orders, and the two most common sales officescollectively account for 99% of the data. Despite this, there are 41 distinct sales officesrepresented in more than one order, suggesting a long-tail distribution. Noise: A considerable amount of input noise is evident within the dataset. Since data entryis frequently manual, discrepancies may arise as different employees might handle identicalbusiness scenarios differently or make inadvertent errors. Moreover, certain fields may beoccasionally left blank, potentially leading to gaps in the data. Data drift: Technically, the dataset is prone to data drift, a phenomenon where the cate-gorizations, such as sales groups within the ERP system, evolve over time. This drift mayparticularly impact analyses involving temporal splits of the data, as category definitionsmay shift across the time periods. Notably, the target categories are not subject to such drift. : Classification performance of baseline models: Evaluation of baseline models on theeight different tasks on SALT. Top: Simple baselines Middle: Gradient-boosted decision tree modelsBottom: Deep learning methods. Performance metric: Mean Reciprocal Rank.",
  "Experiments & Results": "We evaluate the SALT dataset using several baselines for tabular data on the joined table, exceptfor GraphSAGE (Hamilton et al., 2017), which operates natively in a multi-table setup. The onlypreprocessing applied is filling in missing values with either a constant value (for the categoricalfeatures) or the mean value (for numerical features). The fields related to creation date and time wereonly used to split the data and then discarded. The validation set was used for early stopping andno hyperparameter tuning was performed. See Tab. 2 for the detailed breakdown of performanceevaluation tasks of each task. As can be seen, the Carte (Kim et al., 2024) shows the best performanceon SALT with a margin of (+0.02 p.). The next best approach is AutoGluon (Erickson et al., 2020),followed closely by XGBoost (Chen and Guestrin, 2016). The analysis reveals several noteworthyinsights: i) Certain target variables demonstrate substantial predictability, achieving prediction scoresnear 0.99, indicating a high degree of accuracy. ii) The dataset exhibits significant class imbalance,which is particularly evident from the performance of the majority class baseline. This imbalance ismost pronounced when predicting variables such as the Sales Office. iii) The predictive performanceof the model is adversely affected when tasked with predicting fields like the Sales Group, whichsuffers from high cardinality issues.",
  "Conclusion": "We introduce a novel dataset focused on linked business data, demonstrating the characteristics ofdata within actual enterprise systems. We further assessed the performance of current tabular modelsagainst tree-based and cutting-edge models. The empirical data reveal that most tabular modelseffectively manage the prediction tasks in SALT. To augment the datasets complexity and utilityin future work, we plan to include additional tables from a broader range of scenarios, data frommultiple companies, and enhance the semantic richness of the dataset to present greater challenges. Jan-Micha Bodensohn, Ulf Brackmann, Liane Vogel, Matthias Urban, Anupam Sanghi, and CarstenBinnig. 2024. Llms for data engineering on enterprise data. In Joint proceedings of workshops atthe 50th International Conference on Very Large Data Bases (VLDB 2024), Guangzhou, China,August 26 - August 30, 2023, VLDBW 2024, Tabular Data Analysis Workshop Proceedings.",
  "Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. 2020. Turl: table understanding throughrepresentation learning. Proc. VLDB Endow., 14(3):307319": "Yuhao Deng, Chengliang Chai, Lei Cao, Qin Yuan, Siyuan Chen, Yanrui Yu, Zhaoze Sun, JunyiWang, Jiajun Li, Ziqi Cao, Kaisen Jin, Chi Zhang, Yuqing Jiang, Yuanfang Zhang, Yuping Wang,Ye Yuan, Guoren Wang, and Nan Tang. 2024. Lakebench: A benchmark for discovering joinableand unionable tables in data lakes. Proc. VLDB Endow., 17(8):19251938.",
  "Gus Eggert, Kevin Huo, Mike Biven, and Justin Waugh. 2023. Tablib: A dataset of 627m tables withcontext": "Nick Erickson, Jonas Mueller, Alexander Shirkov, Hang Zhang, Pedro Larroy, Mu Li, and AlexanderSmola. 2020. Autogluon-tabular: Robust and accurate automl for structured data. arXiv preprintarXiv:2003.06505. Matthias Fey, Weihua Hu, Kexin Huang, Jan Eric Lenssen, Rishabh Ranjan, Joshua Robinson,Rex Ying, Jiaxuan You, and Jure Leskovec. 2024. Position: Relational deep learning - graphrepresentation learning on relational databases. In Proceedings of the 41st International Conferenceon Machine Learning, volume 235 of Proceedings of Machine Learning Research, pages 1359213607. PMLR. Leo Grinsztajn, Edouard Oyallon, and Gael Varoquaux. 2022. Why do tree-based models stilloutperform deep learning on typical tabular data? In Thirty-sixth Conference on Neural InformationProcessing Systems Datasets and Benchmarks Track. William L. Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation learning on largegraphs. In Proceedings of the 31st International Conference on Neural Information ProcessingSystems, NIPS17, page 10251035, Red Hook, NY, USA. Curran Associates Inc.",
  "A.1Privacy & Anonymization": "In adherence to established best practices, our study systematically purged all personally identifiable,company-identifying information, and confidential information from the dataset through a compositeof automated and manual processes, thereby mitigating any privacy-related issues. For furtherassurance of privacy preservation, the sanitized data consequentially underwent a meticulous auditingprocess. The resulting sanitized data referred to as the SALT, comprised exclusively encryptedcategorical variables. It is noteworthy to emphasize that our privacy sanitization protocol wasdesigned to preclude any likelihood of data distribution distortion or introduction of bias.",
  "A.2Table Detailed Information": "This section describes the schemas of the four tables that constitute the SALT dataset. shows the schema of the tables. See Tab. 5 for a detailed overview of the SalesDocumentItem, Tab. 3for SalesOrder details, Tab. 6 for customer data detail and Tab. 4 for the customer address details.The column Is Target Field indicates the target fields that should be predicted based on the otherfields in the tables since they are populated in a later stage of the sales order creation.",
  "Additionally, the table fields are also filtered to include only those relevant to the use case,which were listed in the previous section": "After extraction, the tables were joined together to create a flat structure, as described in List. 1, suchthat each row in the final table represents one sales order item. Note that, due to this flat structure,the prediction targets, which are defined on the sales order level, will be repeated across multiple"
}