{
  "Abstract": "Generative AI is revolutionizing engineering design practices by enabling rapidprototyping and manipulation of designs. One example of design manipulationinvolves taking two reference design images and using them as prompts to gen-erate a design image that combines aspects of both. Real engineering designshave physical constraints and functional requirements in addition to aesthetic de-sign considerations. Internet-scale foundation models commonly used for imagegeneration, however, are unable to take these physical constraints and functionalrequirements into consideration as part of the generation process. We considerthe problem of generating a design inspired by two input designs, and propose azero-shot framework toward enforcing physical, functional requirements over thegeneration process by leveraging a pretrained diffusion model as the backbone.As a case study, we consider the example of rotational symmetry in generation ofwheel designs. Automotive wheels are required to be rotationally symmetric forphysical stability. We formulate the requirement of rotational symmetry by theuse of a symmetrizer, and we use this symmetrizer to guide the diffusion processtowards symmetric wheel generations. Our experimental results find that the pro-posed approach makes generated interpolations with higher realism than methodsin related work, as evaluated by Frchet inception distance (FID). We also find thatour approach generates designs that more closely satisfy physical and functionalrequirements than generating without the symmetry guidance.",
  "Introduction": "Generative models () are reshaping design processes by significantly reducing the time andeffort required to create visual content. This trend pushes the effort of grounding the generative modelsin the perspectives of design thinking (e.g., generating diverse designs to support exploration ,converging ideas with potential variations such as combinations between different references ). Applying generative AI to real-world product engineering design, such as a car wheel, requiresa careful balance between creativity and practicality. While generative models can traverse anembedding space of image patterns to output unique visual styles, their application must be compatiblewith existing design workflows and adhere to strict physical and functional requirements . Interpolated combinations of reference designs is a technique well-aligned with a prominent designintent and practice, that can also provide creative surprises . Prior work has considered blendingimages using traditional image processing approaches and more recently has leveraged",
  "E": ": System overview: The proposed model takes a pair of reference images as the inputand generates an intermediate interpolation, where the interpolation is gradually regularized withfunctional constraints in each step of the denoising process. deep representation learning and generative models . Karras et al. takes twodifferent samples to the synthesis network at different levels to mix styles of the two. Wang etal. interpolates reference images in latent space at a sequence of decreasing noise levels togenerate interpolations with diffusion models without additional training data. Research in generativeinterpolation also addresses smoothness of transition between sequential interpolations such asDiffMorpher and Smooth-Diffusion . However, there has not been much work on blending images that represent engineering designs,subject to realism as well as functional constraints. This is critical because blending differentsources of designs can easily create distortion and pose challenges to the generated design to performthe intended functionalities of the product. shows examples of interpolated wheels withdistortion that makes it unlikely to function as wheels. We propose a framework of enforcing functional constraints in interpolation generation by fusinggenerated interpolation and its regularized form in the denoising steps of latent diffusion model. Theregularizer constrains a certain functionality of the generated interpolations such as symmetry. Wepropose two symmetrizers as example constraint regularizers for guiding car wheel generation. Theexperiment results show that the proposed approach improves the realism and diversity (lower FIDscore) of the generated interpolations and make the interpolations better conform to the functionalconstraint of symmetry, as measured by the quantitative symmetry metrics. The framework does notrequire additional training, which significantly reduces the labeling efforts. Our contributions includes: (1) a framework towards enforcing physical constraints and functionalrequirements in the denoising process of interpolation generation; (2) two example regularizers offunctional constraints in terms of symmetry; (3) a weighting mechanism to manage the tradeoffbetween realism and regularization in the projection.",
  "Related Work": "Deep generative models such as generative adversarial networks and diffusion models can catchthe underlying distribution of the training dataset and synthesize plausible and realistic images.Variations of these models have been used to generate interpolated combinations of given referenceimages by mixing their latent representations. The style mixing in StyleGAN employs mixingregularization to allow two latent codes through the mapping network to generate an image. However,GAN based approaches may suffer from challenges such as mode collapse and require ainversion process to map a given real image to the latent code in the latent space, which allowsan image to be faithfully generated from the inverted code.",
  "+": ": Generating a interpolated combination of two different image sources can create distortionthat poses critical challenges to engineering functionality. For example, the distorted spokes are notrotationally symmetrical and hence may distribute force unevenly and affect smooth rolling. Latent diffusion models (LDM) are one of the state-of-the-art models for image generation thathas a more stable training process without the concern of mode collapse and is known for generatinghigh quality images. LDM has been used for generating combined interpolations for imagemorphing with smooth transition. Wang et al. has leveraged the LDM architecture to createa model for interpolating images in the latent space at a sequence of decreasing noise levels, andexplore the way to manipulate the generated interpolations using text and human pose as constraints. The advantages of using diffusion models as a backbone are (1) accommodating control guidancesuch as text and image as constraints and (2) building upon strong pretrained models that allowsfinetuning an transfer learning as well as enabling zero-shot methods . Priorwork has extended the control guidance to a variety types of constraints. ControlNet reusesa pre-trained diffusion model to learn diverse controls such as edge, pose and segmentation maps.However, it requires an adequate amount of training images paired with corresponding controls. Nullspace approach adds linear constraints to diffusion models in a zero-shot setting. However, thesecontrols have not covered the functional constraints required in engineering design and have not beenapplied to interpolation generation. Our proposed interpolation model uses LDM as the backbone and integrate the functional constraintsin the noise schedule at the inference stage. This allows guiding the interpolation subject to functionalconstraint in a zero-shot setting. This is critical for engineering design use cases where data scarcitycould pose challenges for training and functional constraints may be specific to a particular surrogatemodel that are not supported by general vision tasks such as edge detection and pose estimation.",
  "Problem setting": "Given a pair of two physical object images, we want to generate a third image that blends the styleand semantic properties of the two inputs, while respecting a constraint on the generated object. Asa case study, we consider the problem of taking two wheel images and blending them to produce awheel that respects the constraint of rotational symmetry, which is an essential property of functionalwheels.",
  "Latent interpolation": "The backbone of the generated interpolation is based on Latent Diffusion Models . Given a pairof input images, we first encode each image to a latent vector. Following the latent interpolationstrategy suggested in , both latent vectors are added with shared noise and then interpolatedusing spherical linear interpolation. We then denoise the interpolated latent vector z using DDIMsampling to generate an intermediate image. We adopt the noise schedule used in in ourimplementation. Different from that generates interpolation at the end of DDIM sampling, wepropose to regularize the latent interpolation in each step of the DDIM sampling that enforces the",
  "We consider two formalizations of our functional specification: (1) rotate and average, and (2) selectsector and stitch": "Rotate and Average (RA): Given a wheel with a pattern that repeats n times, let {Ak}nk=1 be the setof n rotation matrices, such that each Ak represents a rotation by 2/k. Then, an image x has n-foldrotational symmetry if for all i, j [n], Aix = Ajx. We can project any given image x to this linearsubspace of rotationally symmetric images by computing x = 1",
  "nnk=1 Akx": "Select sector and stitch (SS): Let {Bn} be the set of matrices that select one of the n radial sectorsof the image, i.e. a matrix populated with ones for the pixels corresponding to the relevant sector andzeros everywhere else. An image x has n-fold rotational symmetry in this formalization if all of itssectors are equal, i.e. if Bix = Bjx for all matrices Bi, Bj. Given an image x, we can compute itssymmetric projection by choosing a sector and assigning all of the other sectors equal to it.",
  "Projection": "We propose to integrate an intermediate interpolation with its regularized form at every step of thedenoising process, where the regularized form is computed according to the functional constraintregularization to obtain a projection to the set of rotationally symmetric images. The integrationconsiders two factors: (1) the difference incurred after regularization and (2) the decay of impactfrom the regularization over generation steps. As presented in , in each step t of DDIM sampling the latent interpolation (Sec. 4.1) ztis decoded into xt, which is then regularized by a functional constraint R() such as RA or SSintroduced in Sec. 4.2. The regularized image R(xt) is encoded as zrt , then pooled with zt to obtainzt:",
  "zt = (1 )zt + zrt(4)": "where s(zt, zrt ) is the cosine similarity of z and zrt , and is normalized to 0 to 1. w is a weight setto adjust the impact from zrt and d is a constant set to control the decay speed of that impact. issubject to the similarity of zt and zrt to ensure the the pooling would not induce too much noiseincurred by the difference between the original image and the regularized image. The impact fromthe regularized image is decayed over sampling steps to decrease the intervention to the denoisingprocess which could create additional noise and decrease realism, especially toward the end of thegeneration process. The ablation study for similarity, decay and weight is reported in Sec. 5.4. Our work bears similarities to the work on null-space diffusion of , but differs in the introductionof a decayed pooling between the regularized image and the original, unregularized image in thecontext of generating an interpolated image given a pair of reference images.",
  "Experiments": "We conducted experiments to answer the following research questions: (1) Does FIT generate interpo-lations close to real designs? (5.2) (2) Does FIT generate interpolations that conform to the specifiedfunctional constraint? (5.3) For the first question, we measure the Frchet inception distance (FID) between generated wheel interpolations and real wheels. For the second question, we measure thesymmetry score as subject to the symmetrizing functions used in generating interpolations. We measure a symmetry score by comparing the differences between a generated interpolation andits symmetrized form. Since we consider two different ways to compute the symmetrized image, wereport two different symmetry scores. Using the notation of .3, R(xt) is the regularization",
  "Experiment Setting": "To align with real design use cases, we use a commercial grade vehicle image dataset from EVOX2 as the experiment data. The dataset includes high-resolution images across multiple car modelscollected in year 2022 and 2023. We use a wheel detector trained by YOLO8 3 to extract wheelsfrom the car images. Each wheel is located in the center of an image, and the brand logo in the centeris blurred. Each image is normalized to 512 512 pixels. We first sample 380 different pairs oforiginal wheel images from this dataset as the parent images. Similar to the setting in , each pairof parent images generates one interpolated image, where the generated image and a parent image arethen used to generate another interpolated image in a branching structure. In total, 5,700 interpolatedimages are generated for evaluation. 50% of interpolations are used as the validation set and the restare used as the test data. Note that, the validation set is used to determine the hyperparameters suchas symmetrizing weight (w), the use of decay (d) and similarity (s(zt, zrt )), and the same parametersare applied to the test set. The image prompts for generating the interpolations in the validation setand the test set are separate. The baseline is the diffusion based interpolation model withoutconsidering functional constraints. Both FIT and the baseline use Stable Diffusion 1.5 as the backbonemodels with the same parameter setting.",
  "Realism of Generated Interpolations": "Distortion can occur in generated interpolations and hence affect functionality. We evaluate whetherenforcing functional constraints can reduce the distortion and increase realism. We use FID toevaluate the generated wheel interpolations against real wheels in our dataset. The entire set of 1,439real wheel images are used to be compared with interpolations for measuring FID. As reported in, FIT obtains lower FID than the baseline using either functional regularizer SS or RA. Thisindicates that enforcing functional constraint would help generate more realistic engineering designs. In addition, the strength from the functional constraints (controlled by the weight w of symmetrizing)can affect the realism of the generation. In , as we increase the weight from 0.1, the FIDimproves to a point, but overweighting results in less realism. That is, increasing the weight createsadditional noise that can be a burden for generating realistic designs, and, in our approach, thereexists a trade-off between strong functional compliance (symmetry) and realism.",
  "Discussion": "Similarity and Decay While regularization increases the compliance, we notice that the additionalnoise from regularization can reduce the realism, especially if the noise is large or is added towardthe end of generation. FIT proposes two strategies to address this issue. First, the strength fromthe regularization is subject to the similarity of the generated image in each DDIM step and itsGenerated Wheels",
  "FIT (SS)40.6136.13FIT (RA)264.64197.25": "regularized form. The lower similarity, the higher induced noise and hence a smaller strength fromthe regularization is given to the pooling process. shows that considering similarity (similarity& decay) obtains better FID (more realistic) than without considering similarity. The second strategyis to reduce the strength of regularization over DDIM steps. Without decaying the strength, the FIDcan be dramatically increased as reported in while using the decay mechanism reaches amuch lower FID. Constraint in the middle or at the end We also investigate whether interleaving generation andregularization over steps is better than imposing constraint to a generated image at the end . Theresults in shows that it may depend on the characteristics of the desired functional regularizer.Some regularizer such as RA can induce a considerable amount of noise that reduces realism (right), and thus interleaving generation and regularization allows further denoising to increase therealism (lower FID).",
  ": Example images generated by FIT (RA): Left: Applying the constraint during interpolationgeneration. Right: Applying the constraint at the end of interpolation": "Potential applications to more scientific problems Image interpolation has been used in otherscientific domains such as biomedical imaging and satellite imagery in earth and space science. The concept of guided interpolation may be used to bring domain specific regularization intothe interpolation generation process. The regularization could be visual pattern priors, structure ortopology constraints, which would require modeling of appropriate regularizers subject to domainspecific knowledge. While these are not included in this paper, we hope this work would motivatemore use cases of guided interpolation in more science domains. Limitations Functionality and performance are not necessary reflected in visual patterns; for example,the material and the mass in internal facing parts. The proposed approach would not be able to tacklethe types of regularization that cannot be well represented visually. In addition, the effectivenessof functional constraints is highly dependent on the appropriate surrogate models that can preciselysynthesize the functional requirements and are computationally feasible.",
  "We propose FIT to generate design interpolations subject to functional constraints. FIT generateswheel design drawings with high realism and with high conformance to functional constraint such": "as symmetry. We also found that strength of the functional constraint regularizer in generation hasa tradeoff between realism and regularization, and the performance depends on the noise that aregularizer may produce. The framework may serve other types of functional constraints that can bevisually regularized. In the future we will explore more constraint regularizers beyond symmetry, forexample, structure strength such as width of the spokes, the harmonic frequency, CFD requirements.These require that we have a surrogate model for each of those physical requirements.",
  "Zero-shot image restoration using denoising diffusion null-space model. In InternationalConference on Learning Representations, 2023": "Alice Cai, Steven R Rick, Jennifer L Heyman, Yanxia Zhang, Alexandre Filipowicz, MatthewHong, Matt Klenk, and Thomas Malone. Designaid: Using generative ai and semantic diversityfor design inspiration. In Proceedings of The ACM Collective Intelligence Conference, CI 23,page 111. Association for Computing Machinery, 2023. Jooyoung Choi, Sungwon Kim, Yonghyun Jeong, Youngjune Gwon, and Sungroh Yoon. Ilvr:Conditioning method for denoising diffusion probabilistic models. In 2021 IEEE/CVF Interna-tional Conference on Computer Vision (ICCV), 2021. Richard Lee Davis, Thiemo Wambsganss, Wei Jiang, Kevin Gonyop Kim, Tanja Kser, andPierre Dillenbourg. Fashioning the future: Unlocking the creative potential of deep generativemodels for design space exploration. In Extended Abstracts of the 2023 CHI Conference onHuman Factors in Computing Systems, CHI EA 23. Association for Computing Machinery,2023.",
  "Henrik Hagtvedt and Vanessa Patrick. Consumer response to overstyling: Balancing aestheticsand functionality in product design. Psychology and Marketing, 2014": "Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.Gans trained by a two time-scale update rule converge to a local nash equilibrium. In Proceedingsof the 31st International Conference on Neural Information Processing Systems, NIPS17, page66296640, 2017. Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,Lu Wang, and Weizhu Chen. LoRA: Low-rank adaptation of large language models. InInternational Conference on Learning Representations, 2022.",
  "Abdul Jabbar, Xi Li, and Bourahla Omar. A survey on generative adversarial networks: Variants,applications, and training. ACM Comput. Surv., 2021": "Youngseung Jeon, Matthew K. Hong, Yan-Ying Chen, Kalani Murakami, Jonathan Q. Li,Xiang Anthony Chen, and Matthew Klenk. Weaving ml with human aesthetic assessmentsto augment design space exploration: An automotive wheel design case study. In ExtendedAbstracts of the 2024 CHI Conference on Human Factors in Computing Systems, CHI EA 24.Association for Computing Machinery, 2024. Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for genera-tive adversarial networks. In 2019 IEEE/CVF Conference on Computer Vision and PatternRecognition (CVPR), pages 43964405, 2019.",
  "Shutao Li, Xudong Kang, Leyuan Fang, Jianwen Hu, and Haitao Yin. Pixel-level image fusion:A survey of the state of the art. information Fusion, 33:100112, 2017": "Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray, Chelsea Voss, Alec Radford, MarkChen, and Ilya Sutskever. Zero-shot text-to-image generation. In Proceedings of the 38thInternational Conference on Machine Learning, volume 139, pages 88218831, 1824 Jul2021. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bjrn Ommer. High-resolution image synthesis with latent diffusion models. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition, pages 1068410695, 2022. Kevin Roth, Aurelien Lucchi, Sebastian Nowozin, and Thomas Hofmann. Stabilizing training ofgenerative adversarial networks through regularization. In Proceedings of the 31st InternationalConference on Neural Information Processing Systems, 2017. Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and Kfir Aberman.Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation. InProceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR),June 2023.",
  "Weihao Xia, Yulun Zhang, Yujiu Yang, Jing-Hao Xue, Bolei Zhou, and Ming-Hsuan Yang.Gan inversion: A survey. IEEE Transactions on Pattern Analysis and Machine Intelligence,45(3):31213138, 2023": "Jingxuan Xu, Wuyang Chen, Yao Zhao, and Yunchao Wei. Transferable and principled efficiencyfor open-vocabulary segmentation. In 2024 IEEE/CVF Conference on Computer Vision andPattern Recognition (CVPR), 2024. Thomas Gale Voho Seo Hooman Shayani Ye Wang, Nicole B. Damen. Inspired by ai? a novelgenerative ai system to assist conceptual automotive design. In Proceedings of the ASMEInternational Design Engineering Technical Conferences and Computers and Information inEngineering Conference (IDETC), 2024. Kaiwen Zhang, Yifan Zhou, Xudong Xu, Bo Dai, and Xingang Pan. Diffmorpher: Unleashingthe capability of diffusion models for image morphing. In Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition, pages 79127921, 2024."
}