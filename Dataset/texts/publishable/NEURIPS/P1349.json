{
  "Abstract": "Denoising diffusion models (DDMs) offer a flexible framework for samplingfrom high dimensional data distributions. DDMs generate a path of probabilitydistributions interpolating between a reference Gaussian distribution and a datadistribution by incrementally injecting noise into the data. To numerically simulatethe sampling process, a discretisation schedule from the reference back towardsclean data must be chosen. An appropriate discretisation schedule is crucial toobtain high quality samples. However, beyond hand crafted heuristics, a generalmethod for choosing this schedule remains elusive. This paper presents a novelalgorithm for adaptively selecting an optimal discretisation schedule with respectto a cost that we derive. Our cost measures the work done by the simulationprocedure to transport samples from one point in the diffusion path to the next.Our method does not require hyperparameter tuning and adapts to the dynamicsand geometry of the diffusion path. Our algorithm only involves the evaluationof the estimated Stein score, making it scalable to existing pre-trained modelsat inference time and online during training. We find that our learned schedulerecovers performant schedules previously only discovered through manual searchand obtains competitive FID scores on image datasets.",
  "Introduction": "Denoising Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song et al., 2021) or DDMsare state-of-the-art generative models. They are formulated through considering a forward noisingprocess that interpolates from the target to a reference Gaussian distribution by gradually introducingnoise into an empirical data distribution. Simulating the time reversal of this process then producessamples from the data distribution. Specifically, we evolve data distribution p0 through the forwarddiffusion process on time interval , described by",
  "dXt = f(t)Xtdt + g(t)dWt,X0 p0,(1)": "with drift f(t)Xt, diffusion coefficient g(t) and Brownian noise increment dWt. The coefficientsf(t) and g(t) are chosen such that at time t = 1 the distribution of X1 is very close to a referenceGaussian distribution p1 in distribution. A sample starting at p0 and following Equation (1) until timet will be distributed according to pt which is a mollified version of the data distribution",
  "Optimised Schedule Samples": ": Density estimates of the mollified Cantor distribution (left) using a DDM with scheduleT = {ti}100i=0 generated with 100 linearly spaces discretisation times ti = i/100 (middle), comparedto the optimised schedule T = {ti }50i=0 with 50 discretisation times ti generated by Algorithm 1(right). The eight modes present in our true mollified distribution are shown in grey on each plot. The parameters s(t) and 2(t) define the noising schedule. They can be found in closed form interms of f(t) and g(t) (Karras et al., 2022). To obtain samples from p0, we can reverse the dynamicsof the forward diffusion in Equation (1) to obtain the backward diffusion,",
  "dXt =f(t)Xt g(t)2x log pt(Xt)dt + g(t)dWt,X1 p1.(3)": "By simulating Equation (3) backwards in time, we evolve reference samples X1 p1 from t = 1to t = 0 to obtain samples that are terminally distributed according to the data distribution p0. Tosimulate Equation (3) numerically, we must decide upon a discretisation of time, T = {ti}Ti=0 withtT = 1, t0 = 0, which we refer to as the discretisation schedule. For a given noising schedule, it isimportant to select an appropriate discretisation schedule such that (3) can be simulated accurately,i.e. pti and pti1 should not differ significantly. In this paper, we derive a methodology to computean optimal discretisation schedule. Prior work has often joined together the choice of noising schedule and discretisation schedule. Auniform splitting of time would be chosen, ti = i/T, with the noising schedule dictating the changebetween pti and pti1. Two prominent examples have the form s(t) = (t), 2(t) = 1 (t)with the linear schedule introduced by Ho et al. (2020) having (t) = 1 exp t0 (s)dswithlinear (t) = min + t(max min). Alternatively, Nichol and Dhariwal (2021) introduce the cosineschedule with (t) = f(t)/f(0), f(t) = cos t+ 1+22 for = 0.008. Karras et al. (2022) refines thisapproach by splitting the choice of noising schedule from that of the discretisation schedule, however,picking the discretisation schedule is still a matter of hyperparameter tuning. A good discretisation schedule can drastically impact the efficiency of the training and inference ofthe generative model, but unfortunately can be difficult to select for complex target distributions. Forexample, for a distribution supported on the Cantor set (, left), the default linear schedulefails entirely to capture the modes of the data distribution (, middle). However, our optimisedschedule learned using Algorithm 1 recovers these modes (, right). Without such an automaticalgorithm, finding performant discretisation schedules often reduces to an expensive and laborioushyperparameter sweep. We devise a method for selecting a discretisation schedule that yields high-quality samples fromp0. Our key contribution is defining an appropriate notion of cost incurred when simulating fromone step in the diffusion path to the next. We then choose our discretisation schedule to minimisethe total cost incurred when simulating the entire path from p1 to p0. Our cost purely depends onthe distributional shifts along the diffusion path and assumes perfect score estimation, hence, werefer to our schedules as score-optimal diffusion schedules. The resulting algorithm is cheap tocompute, easy to implement and requires no hyperparameter search. Our algorithm can be appliedto find discretisation schedules for sampling pre-trained models as well as performed online duringDDM training. We demonstrate our proposed method on highly complex 1D distributions and showour method scales to high dimensional image data where it recovers previously known performantdiscretisation schedules discovered only through manual hyperparameter search. To the best of ourknowledge, this is the first online data-dependent adaptive discretisation schedule tuning algorithm.",
  "The Cost of Traversing the Diffusion Path": "To derive our optimal discretisation schedule, we first need to derive a notion of cost of traversingfrom our reference distribution p1 to the data distribution p0 through each intermediate distributionpt, referred to as the diffusion path. We will then later find the discretisation schedule that minimisesthe total cost of traversing this path. Our notion of cost is based on the idea that while integratingEquation (3) from time t to t will always take you from pt to pt, the simulation step will need to domore work to make sure the samples are distributed according to pt if pt and pt are very differentdistributions rather than if they are close. In the following, we will make this intuition precise.",
  "Predictor/Corrector Decomposition of the Diffusion Update": "To begin, let X = Rd and P(X) be the space of Lebesgue probability measures on X with smoothdensities. For t , define the diffusion path pt P(X) as the law of Xt satisfying the forwarddiffusion Equation (1) initialised at the data distribution X0 p0, or equivalently the law of the Xtsatisfying the backward diffusion Equation (3) initialised at the reference distribution X1 p1. Given a sample Xt pt, a sample Xt pt can be generated by integrating the backward diffusionEquation (3). In Song et al. (2021), it was shown that we can further decompose the backwarddiffusion Equation (3) at time t into a deterministic flow governed by the probability flow ODE, andthe stochastic flow driven by Langevin dynamics targeting pt,",
  "(4)": "This decomposition into a deterministic flow and a correction will help us derive our cost in .2 by analysing the work done by the correction to keep the samples on the diffusion path. Here, wewill first expand upon this decomposition by defining a hypothetical two-step sampling procedure thatcould be used to sample the DDM. It consists of: (1) a predictor step that generates a deterministicprediction of Xt and (2) a corrector step that uses Langevin dynamics targeting pt to correct anyaccrued error. Note we are not advocating for the implementation of such a procedure, only that byimagining simulating with this hypothetical predictor-corrector algorithm, it will be helpful for ourtheoretical derivation of a cost intrinsically linked to the sampling of DDMs. The two stages of thepredictor-corrector algorithm are rigorously defined as follows.Definition 2.1. A predictor for t, t is a smooth bijective mapping Ft,t : X X, such thatdet Ft,t = 0, and the predicted distribution is the pushforward of pt by Ft,t denoted F t,tpt. Definition 2.2. A corrector for t , [0, ) is a one-parameter family Markov transitionkernel Lt, : X P(X) such that Z Lt,(z, dz) is the law of Langevin dynamicsstationary distribution pt at time , initialised at z X, and running at speed v(t) > 0,",
  "2v(t)dW.(5)": "The corrector map Lt, is specified through an integration time and time-dependent speed v(t). Weassume is fixed and we will describe the appropriate choice of v(t) in .3. The predictor-corrector algorithm, given Xt pt, first applies the predictor Z0 = Ft,t(Xt) and then uses thecorrector to drive the predicted samples towards pt,",
  "Predictor:Z0 = Ft,t(Xt)Corrector:Xt, Lt,(Z0, dx).(6)": "In general, Z0 will not be a sample from pt exactly because Ft,t may not be a perfect transport frompt to pt. In .2, assessing the work done by Lt, to drive the Z0 towards pt will be key inderiving our cost. Our cost will then depend upon the specific choice for Ft,t. Two natural choicesfor Ft,t are apparent. Setting Ft,t to the identity means our hypothetical sampling algorithm reducesto the annealed Langevin algorithm for DDMs introduced by Song and Ermon (2019). The secondnatural choice is to set Ft,t to the integrator of the probability flow ODE (Song et al., 2021). Example 2.1 (Annealed Langevin). The predictor step is trivial when the predictor map is the identityFt,t(x) = x. In such a case, the predicted state reduces to the initial state, Ft,t(Xt) = Xt pt.The work done by the corrector step will then be related to the full discrepancy between pt and ptbecause the predictor provides no help in transporting the sample. Example 2.2 (Probability Flow ODE). The predictor step is optimal when Ft,t is a transportfrom pt to pt. In such a case, the predicted state produces a sample from the target distribution,Ft,t(Xt) pt, and so the corrector step would have to perform no work. An optimal predictor mapFt,t can be obtained by integrating the probability flow ODE from time t, t,",
  "The Incremental Cost of Correction": "We now focus on deriving a cost related to the work done by the corrector step in the predictor-corrector algorithm. Later, in , we will find the discretisation schedule that minimises thetotal cost. To derive the cost, we will analyse the movement of Z0 under the corrector steps dynamicsLt,(Z0, dx). This requires some care because even if Z0 is already at stationarity, i.e. perfectlydistributed according to pt, applying the Langevin correction step will still result in movement of Z0due to the stochasticity of the update. However, the computed work done by the correction step inthis case should be 0. To correctly assign the work done, we will compare two processes. The first isthe trajectory of Langevin dynamics, Z, defined by the corrector Lt, initialised at Z0 = Ft,t(Xt)targeting pt. The second is a virtual coupled Langevin dynamics Z initialised at Ft,t(Xt), drivenby the same noise and speed but targeting the stationary distribution of the predictor F t,tpt,",
  "2v(t)dW.(10)": "Notably, Zd= Xt, and Zd= Ft,t(Xt) share the same law as the corrected sample and predictedsample respectively. Since Z and Z are coupled to have the same noise, the difference in theirtrajectory, Z Z, isolates the change in corrector dynamics due to discrepancy between F t,tpt andpt. If F t,tpt is very different to pt, then Z Z will be large, signifying the corrector is needingto do lots of work to push the distribution of Z towards the target pt. Conversely, if F t,tpt = pt,then Z Z = 0 and no work is done. For small , (Z Z0)/ is the initial velocity of Z underthe pt corrector dynamics, and similarly for ( Z Z0)/. We can then define the incremental costL(t, t) by taking limits as 0+, measuring the expected L2 norm of the difference,",
  "L(t, t) = v(t)2E log pt(Z0) log F t,tpt(Z0)2= v(t)2D(ptF t,tpt),(13)": "where D(pq) = EXq[ log p(X) log q(X)2] is a statistical divergence on p, q P(X),measuring the L2 distance between the scores of q and p with respect q. D(pq) is referred to as theStein divergence or the Fisher divergence; see e.g. (Johnson, 2004). For a given choice of v(t) andFt,t we now have a cost measuring the change from pt to pt. This cost is intrinsically linked withthe effort performed by a DDM sampling algorithm because it is derived through considering thework done by a hypothetical predictor-corrector style update. We note, however, that this general costcan be used to obtain discretisation schedules for use in any style of DDM sampler.",
  "pt(x)|det Ft,t(x)| .(14)": "In most cases, it is infeasible to efficiently compute the Jacobian correction in Equation (14). WhenFt,t(x) = x is the identity map corresponding to the corrector optimised update from Example 2.1Equation (14) reduces a rescaled Stein discrepancy between pt and pt, and Gt,t(x) = pt(x)/pt(x)reduces to the likelihood-ratio between pt and pt. We will refer to this case as the corrector-optimisedcost denoted Lc(t, t), to distinguished it from the predictor-optimised cost Lp(t, t) derived above,where when relevant, we will use subscripts c and p to distinguish between the two:",
  "Lc(t, t) = v(t)2D(ptpt),Lp(t, t) = v(t)2D(ptF t,tpt).(15)": "The corrector-optimised cost Lc(t, t) provides meaningful information during the update fromreference pt to the target pt. It is worth computing even when the predictor-optimised cost Lp(t, t)is accessible. Lc(t, t) measures the change between the reference and target distribution independentof the predictor, whereas Lp(t, t) measures the residual error between the predictor and target.Notably, Lc(t, t) encodes information about the incremental geometry of the diffusion path, whereasLp(t, t) quantifies information about the incremental efficiency of the predictor. Generally, one doesnot dominate the other, but if the predictor is well-tuned and the predictor flows samples Xt pttowards pt, we would expect Lp(t, t) Lc(t, t). For deriving our optimal discretisation schedule, we require a notion of how L(t, t) increases withsmall increases in t i.e. knowing local changes in incremental cost. In , we use this localcost to assign distances to schedules through time, enabling us to find the best schedule. We derivethe desired local cost in Theorem 2.1, see Appendix A for a PDE and geometric interpretation.Theorem 2.1. Suppose pt(x), Ft,t(x), v(t) and Gt,t(x) are three-times continuously differentiablein t, t, x and let Ft(x) =t Ft,t(x)t=t and Gt(x) =t Gt,t(x)t=t. Suppose the followinghold: (1) for all x X, t , Ft,t(x) = x and (2) there exists V : X R such that for all x Xand t , Gt(x)2 V (x) and supt EXtpt[V (Xt)] < . Then for all t , wehave L(t, t) = (t)t2 + O(t3), where",
  "t log pt + log pt Ft + Tr Ft.(16)": "Theorem 2.1 shows that, under regularity assumptions, then the incremental cost is L(t, t) (t)t2is locally quadratic and controlled by the local cost (t). The (t) measures the sensitivity of theincremental cost L(t, t) to moving samples along the diffusion path to t t. Notably, (t) = 0 ifand only if the predictor satisfies the continuity equation,",
  "Xi Lti,(Fti+1,ti(Xi+1), dxi).(17)": "We want to identify a discretisation schedule that maximises the efficiency of this iterative procedure.This is not generally possible due to the potential complex interactions that arise from the accruederrors. To simplify our analysis, we make the following assumption.Assumption 3.1. For all t, t, if Xt pt and Xt, = Lt,(Ft,t(Xt), dx), then Xt, pt.",
  "Assumption 3.1 is reasonable if, in our hypothetical corrector steps, is set sufficiently large suchthat the Langevin correction converges to stationarity. We find in our experiments that even if the": "schedules derived under Assumption 3.1 are used in sampling algorithms for which Assumption 3.1does not hold, we still obtain high quality samples. Equipped with Assumption 3.1, we can measurethe efficiency of the path update through total accumulated cost L = Ti=1 L(ti+1, ti), which wewill use as our objective to optimise T . In this section, we will identify the optimal schedule T minimising the cost L by considering an infinitely dense limit. We will then provide a tuningprocedure amenable to online schedule optimisation during training. Finally, we will discuss asuitable choice for v(t), the velocity of our hypothetical corrector steps, as well as related work.",
  "Diffusion Schedule Path Length and Energy": "Let : be a strictly increasing, differentiable function such that (0) = 0 and(1) = 1. We will say T is generated by if ti = (i/T) for all i = 0, . . . , T. The schedulegenerator dictates how fast our samples move through their diffusion path. Since every schedule Tof size T is generated by some , optimising T is equivalent to finding a generator minimisingL(, T), the total cost accumulated by the schedule of size T generated by . By Jensens inequality,we have L(, T) (, T)2/T, where for ti = (i/T),",
  "((s)) (s)ds = 10": "(t)dtalong a curve (s) obtains the length , whilst integrating a speed squared, 10 ((s)) (s)2dsobtains a kinetic energy E(). Note that the length is an invariant of the schedule, whereas thekinetic energy is not. The length measures the intrinsic difficulty of traversing the diffusion pathaccording to the cost independent of , whereas E() measures the efficiency of how the path wastraversed using . This geometric intuition hints at the solution to the optimal scheduling problem.The optimal should travel on a geodesic path from p1 to p0, at a constant speed with respect tometric . For this optimal , we then have the kinetic energy being equal to the square of lengthbetween p1 and p0. Theorem 3.1 makes the previous discussion precise.Theorem 3.1. Suppose the assumptions of Theorem 2.1 hold. For all schedule generators ,",
  "(u)du.(21)": "Notably independent of the choice of , as T , the cost L(, T) E()/T. This implies thatthe cost decays to zero at a linear rate, proportional to E() and L(, T) 2/T independent of. Equation (21) provides an explicit formula for the optimal schedule generator that minimises thedense limit of the total cost and obtains the lower bound E() = 2. The intuition for the formula(s) = 1(s) is that this implies ((s)) = s meaning say 10% of the way through theoptimal schedule, we should have traversed 10% of the way along the distance between p1 and p0 i.e.0.1 . This relation holds for constant speed straight lines, meaning is the optimal schedule.For a finite T, Theorem 2.1 implies the optimal schedule T = {ti }Ti=0 generated by ensures theincremental cost is constant L(ti+1, ti ) 2/T 2 for all i = 0, . . . , T 1. Our geometric intuition in the language of differential geometry is that the diffusion path M ={pt}t is Riemannian manifold with metric endowed by the incremental cost L(t, t). Theschedule generator defines a curve s p(s) M reparametrising the diffusion path between p0and p1. Theorem 3.1 shows that is the geodesic of length in M between p1 and p0 that traversesthe diffusion path at a constant speed",
  "Estimation of Score-Optimal Schedules": "Given a schedule T = {ti}Ti=0 and estimates of the incremental cost L(ti+1, ti), Algorithm 1 adaptsAlgorithm 3 from Syed et al. (2021) to estimate the optimal schedule T = {ti }Ti=0 generated by .We can use Algorithm 1 to refine the schedule for a pre-trained DDM or learn the schedule jointly withthe score function. For this joint procedure, we detail in Appendix B.1 how function evaluations can bereused to estimate the cost to minimise computational overhead. For Lc(t, t) we need only evaluate log pt(Xt) and log pt(Xt) both available through our models score estimate. ComputingLp(t, t) is more challenging since there are Hessian terms that arise in Equation (14). Under theassumption that the step size t > 0 is sufficiently small, we can approximate log | det Ft,t(Xt)|through Proposition B.1. This approximation only requires us to compute the gradient trace of theJacobian of our predicted score. With computational cost proportionate to the computational effortfor computing the first derivative. Using a Hutchinson trace (Hutchinson, 1989) like estimator inProposition B.1, we compute this quantity memory-efficiently in high dimensions, requiring onlystandard auto-differentiation back-propagation.",
  "Choice of Velocity Scaling": "Recall that our cost is derived by considering a Langevin dynamics step with velocity v(t). Thisvelocity should be selected so that Langevin dynamics explores the same proportion of our distributionat varying times throughout our diffusion path. Thus, v(t) should be on the same scale as the spreadof the target, pt. Commonly used noising schedules have s(t) 1, and our data distribution isnormalised so the scale of pt is on the order of (t). We therefore set v(t) = (t). This resultsin a (t)-weighted divergence for our incremental cost L(t, t) = (t)2D(pt||pt). This can becompared to the weighted denoising score matching loss used to train DDMs (Song et al., 2021),which is also a squared norm of score differences: (t)EX0,Xts(Xt, t) log pt|0(Xt|X0)2 for some weighting function (t) chosen to equalise the magnitude of the cost over the path. In Songet al. (2021), (t) 1/E[ log pt|0(Xt|X0)2] was chosen, which, as we show in Appendix B.3,is (t) 2(t). This choice of velocity scaling provides an alternative perspective on this commonlyused weighting of squared norms of score differences.",
  "Related Work": "Previous works have devised algorithms and heuristics for designing noising and discretisationschedules. The DDM training objective is invariant to the noising schedule shape, as demonstratedby Kingma et al. (2021), necessitating auxiliary costs and objectives for schedule design. Uniformsteps in the signal-to-noise ratio, log (s(ti)/(ti)), are used by Lu et al. (2022), but this ignores thetarget distributions geometry. Watson et al. (2021) optimise the schedule by differentiating throughsampling to maximise quality, but GPU memory constraints necessitate gradient rematerialisation.We avoid this with a simulation-free cost. Closely related to our work is Sabour et al. (2024), whominimise a pathwise KL-divergence between discretised and continuous processes. They requiremulti-stage optimisation with early stopping to prevent over-optimisation of their objective whichwould otherwise result in worse schedules. Amongst the wider literature, various strategies fordiscretisation schedule tuning have been proposed. Das et al. (2023) derive an equally spacedschedule using the Fisher metric but assume Gaussian data. Santos et al. (2023) assign time pointsproportional to the Fisher information of pt|0(xt | x0), ignoring the true target distribution. Xue et al.(2024) derive a schedule to control ODE simulation error, but their cost depends only on the ODEsolver, and not on the data distribution.",
  "Sampling the Mollified Cantor Distribution": "The Cantor distribution (Cantor, 1884) lacks a Lebesgue density, with its cumulative distributionfunction represented by the Devils staircase and its support being the Cantor set, forming a challeng-ing 1-D test example. When mollified with Gaussian noise, it becomes absolutely continuous andpossesses a Stein score. We mollify by running a diffusion with the linear schedule for time t = 105.With this mollification, our data density has eight pronounced peaks. We train a one-dimensionalDDM for 150,000 iterations using both a fixed linear schedule and our optimisation algorithm Al-gorithm 2 initialised at the linear schedule. We find that the non-data-specific default schedule failsto capture these modes, whilst our adaptive method faithfully reproduces the data distribution. In we show the complexity of the learned score which displays a self-similar fractal structure.",
  "2pright(x), where pleft and pright are normal distributions with means 6 and 6,respectively, and a common variance 2 = 0.12": "We learn two diffusion models, one using the linear schedule, and the other using a schedule thatis learned online during training. We compute the likelihood of the samples generated from eithermodel during training, which is possible in this example because the true probability density is known.It can be seen in that when the schedule is learned during training, the likelihood evaluationincreases and the true score error decreases, in contrast to the linear schedule that remains constant,or worsens, in this regard during training.",
  "Scalable Schedule Learning Diffusion": "Here we demonstrate that jointly learning the schedule and score using our online training method-ology (Algorithm 2) scales to high-dimensional data and converges to a stable solution. We trainDDMs on CIFAR-10 and MNIST initialised at the cosine schedule using the codebase from Nicholand Dhariwal (2021). In (left), we show the incremental costs L(tj+1, tj) for the cosineschedule and our learned schedule, finding that the increments approximately equalise over thediffusion path as expected by the discussion in .1. (right) shows the learnedschedule spends more time at high-frequency details, we visualise a sampling trajectory in . : Sample quality measured by Frchet Inception Distance (FID) versus schedule on CIFAR10(32 32), FFHQ, AFHQv2, ImageNet (64 64). Pretrained models are used from Karras et al.(2022). All FIDs are calculated using 50000 samples. We highlight the best FID in bold. TheImageNet model lacks second-order differentiation, so no predictor optimised schedule is shown.",
  "Convex": "CIFAR10 CorrectorCIFAR10 Predictor : (Left) Costs associated with different schedule choices for the CIFAR10 dataset. Schedulesare ordered from lowest FID to highest FID. We compare our Corrector-optimised (CO) cost andPredictor-optimised (PO) cost versus the Kullback-Leibler Upper Bound (KLUB) from Sabour et al.(2024). The minimum value for each cost is highlighted in bold. Note low cost is associated withlow FID for our cost and not for the KLUB. (Right) Visualisation of schedules during generativesampling with 100 timesteps. rho=3 and rho=7 refer to Eq 22 with = 3 and = 7 respectively.LogLinear from Lu et al. (2022) and a convex schedule are also shown. We show our cost optimisedschedules for CIFAR10 both using the corrector optimised cost and the predictor optimised cost.",
  "Sampling Pre-Trained Models": "In this experiment we demonstrate that our algorithm can recover performant schedules for largeimage models used in practice and our schedules generate high quality samples. We use the pre-trained models from Karras et al. (2022), whose DDM is parameterised such that the forward noisingdistribution is of the form pt|0(xt|x0) = N(xt; x0, 2t I). The scheduling problem then reduces todeciding on a stepping scheme through {i}Ni=1, N = 0. Karras et al. (2022) suggest a polynomialbased schedule with a parameter that controls the curvature of the schedule",
  "1maxand N = 0.(22)": "A lower value results in steps near min being shortened and steps near max being lengthened.Through analysing the truncation error for sampling in Karras et al. (2022), they find that setting = 3 approximately equalises this error, however it is found empirically that = 7 results in bettersample quality. We also compare against a schedule that takes uniform steps in log space Lu et al.(2022) which we refer to as the LogLinear schedule and a schedule that takes a convex shape in logspace. Schedule visualisations are provided in (right). We sampled the pre-trained models using these schedules and computed the sample quality using FID.We use the same number of schedule steps (18 for CIFAR10, 40 for FFHQ and AFHQv2, 256 forImageNet) and solver (Heun second order) as Karras et al. (2022). Our results are shown in .Our optimised schedules are able to achieve competitive FID to the best performing = 7 schedulehand-tuned in Karras et al. (2022). This is expected as our schedules take a similar shape to the = 7 schedule as shown in (right). Therefore, our method provides an entirely automaticand hyperparameter free algorithm to recover this performant schedule that was previously onlydiscovered through trial-and-error. We further analyse how the number of discretisation points, T, used during sampling affects thequality of generated samples for different schedules. We report our results on CIFAR10 in .Notably, the FID decreases with T for all schedules and achieves comparable FID once T is largeenough. However, when T is small, only the optimised schedules maintain stable performance. Thisempirically demonstrates an optimised schedule can improve the sampling efficiency by allowingfor coarser discretisations and, hence, faster sampling, as predicted by Theorem 3.1. We observe anidentical trend for sFID in in the Appendix C.2.",
  ": Comparison of FID across different amounts of discretisation points for different scheduleson CIFAR10. CO stands for our corrector optimised schedule": "We also compare corrector optimised schedules to predictor optimised schedules in . Theyprovide similar performance so, on image datasets, we encourage the use of the cheaper to computecorrector optimised schedule. Finally, in (left), we report the raw values of our correctoroptimised costs and compare these costs to the values of the objective introduced in Sabour et al.(2024). Both algorithms aim to find schedules that minimise these costs and therefore it is desirablefor low values of cost to be associated with good sample quality (i.e. low FID). We find that lowvalues of our cost correlate much more closely with low FID than the objective introduced by Sabouret al. (2024). Indeed, Sabour et al. (2024) introduce a bespoke multi-stage optimisation for their costbecause they found over-optimising their objective can lead to worse schedules which is explained bythe objective not correlating well with FID. We further find that our predictor optimised costs arelower than the corrector optimised costs which is to be expected as the predictor reduces the workdone by the corrector and thus reduces the incremental cost. The overall shape of schedule, however,between the corrector optimised and predictor optimised costs is similar.",
  "Discussion": "We have introduced a method for selecting an optimal DDM discretisation schedule by minimisinga cost linked to the work done in transporting samples along the diffusion path. Our algorithm iscomputationally cheap and does not require hyperparameter tuning. Our learned schedule achievescompetitive FID scores. Regarding limitations, the computation of Lp can be computationallyexpensive due the calculation of second derivatives, however, in .4 we found Lc to providea cheap and performant alternative. Furthermore, our theory is derived assuming perfect scoreestimation. Future work can expand on the geometric interpretation of the diffusion path and links toinformation geometry to further refine the DDM methodology.",
  "Song, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data distribution.In Advances in Neural Information Processing Systems": "Song, Y., Sohl-Dickstein, J., Kingma, D. P., Kumar, A., Ermon, S., and Poole, B. (2021). Score-basedgenerative modeling through stochastic differential equations. In International Conference onLearning Representations. Syed, S., Bouchard-Ct, A., Deligiannidis, G., and Doucet, A. (2021). Non-reversible paralleltempering: a scalable highly parallel MCMC scheme. Journal of the Royal Statistical Society(Series B), 84:321350.",
  "B.1Adaptive training": "We may incorporate Algorithm 1 into an online algorithm used during training. For a fixed scorefunction along the diffusion path, there is an optimal schedule. Similarly, for a fixed schedule, there isan optimal score function that can be learnt from the data. To incorporate these two steps, we proposea two-step algorithm for online training. First, for a fixed schedule, we optimise the score function. Then, using this estimated score function,we compute the optimal schedule through Algorithm 1. To add regularity throughout training, asour score predictions are over batches rather than the entire dataset, we do not replace the currentschedule with our computed optimal one. Instead, we take a weighted combination of the currentschedule with the computed optimal one. The weighting factor (0, 1) is akin to a learning rate for the schedule optimisation. If is set toohigh, our schedule learning may be overly influenced by the current batch, which could negativelyaffect the score training performance.",
  "Score": "Corrector SchedulePredictor ScheduleLinear Schedule : Schedules and density estimates for: linear (blue); Stein score optimised (green); andpredictor optimised (red) schedules. The predictor optimised schedule identifies a bump along thediffusion path where the reference Gaussian density splits into two modes. In the regions where thescore is evaluated (around 6), our trained score is accurate compared to the linear schedule score,which fails to match the slope of the true score, resulting in a wider variance density estimate.",
  "C.11D Density Estimation": "For all 1D experiments, we train a one spatial dimension model with continuous time encodingvia Gaussian Fourier features to embed time values into a higher-dimensional space. The modelarchitecture includes a hidden dimension of 128, five layers, an embedding dimension of 12, and oneresidual time step. It features a combination of residual blocks, both incorporating linear layers withGELU activation and LayerNorm, tailored to integrate time embeddings.",
  "C.1.1Bimodal Example": "We train our model in the form of f(t) = t/2 and g(t) = t using Algorithm 2 with = 0.1.We use the weight function v2tn = (1 tn), where tn = 1 tn and tn = ni=1 ti. Wetrain our model for 5 thousand iterations using both a fixed linear schedule and our optimisationalgorithm initialised at the linear schedule. Due to the non-linear dependence during training of thetransport-optimised schedule, initialisation in this context plays an important role. We initialise ourpredictor-optimised schedule with the optimal schedule generated with respect to Lc without theJacobian term as a first approximation. We then add the Jacobian term, optimise the schedule, andtrain for an additional 5 thousand iterations.",
  "Linear Schedule Score": ": Comparison of sampling from a mollified Cantor distribution using DDMs with twodifferent schedules: linear (blue) and optimised (green). The optimised schedule enables the DDM tocapture eight distinct data modes centered on the mollified Cantor distribution (grey), whereas thelinear schedule does not have clear mode separation. The optimised schedule diffusion accuratelypredicts the score for the mollified Cantor distribution, being near vertical lines interweaving theCantor set, where the linear schedule fails to adequately approximate the score.",
  "C.1.2Mollified Cantor Distribution": "We train our model with f(t) = t/2 and g(t) = t using the online Algorithm 2 with = 0.01.The weight function is v2tn = (1 tn), where tn = 1 tn and tn = ni=1 ti. To capturehigh-frequency details, we train the one-dimensional model for 150,000 iterations using both a fixedlinear schedule and our optimisation algorithm initialised at the linear schedule. The difference insample quality is evident in .",
  "C.2Pretrained Image Models": "For sampling pretrained image models, we use the networks and implementation from Karras et al.(2022), We compute the FID using the provided FID scriptwithin the codebase with the standard 50, 000 samples using the same fixed seeds 0 49999 for allschedules. For each image dataset, we use the default sampling strategy included in the codebaseby Karras et al. (2022). For unconditional CIFAR10 this is a deterministic 2nd order Heun solverwith 18 timesteps, therefore a total of 35 NFE (number of function evaluations) for the underlyingdenoising network. For both unconditional FFHQ and unconditional AFHQv2 the same deterministic2nd order Heun solver is used with 40 timesteps (NFE = 79). For class conditional ImageNet, thebespoke stochastic solver from Karras et al. (2022) is used with 256 timesteps (NFE=511). Thestochasticity settings are left at their default values for this dataset of Schurn = 40, Smin = 0.05,Smax = 50, Snoise = 1.003. To compute the corrector optimised schedule for each dataset, we use Algorithm 1. We use 100data samples for each dataset when computing Lc as we find the variation in learned scheduleis small between different samples from the dataset. Our initial discretisation schedule used tocalculate (t) is LogLinear with 100 steps. We then fit a monotonic spline to the cumulativeestimated (t) and invert this function to find function from which we can derive our schedules.This takes on the order of 5 minutes to find the Corrector Optimised Schedule for CIFAR10 on asingle RTX 2080Ti GPU. For predictor optimised schedules we repeat the same procedure howeveralso include estimation of the Hessian term. We use 5 samples of v for each image datapointwhen using Hutchinsons trace estimator. It takes 5 GPU hours to compute the Predictor Opti-mised Schedule for CIFAR10 due to the extra computational cost of computing the second derivatives. We compare the corrector optimised and predictor optimised schedules for the 4 image datasets in. We find that all of the schedules have the same general shape with increasing step sizes inlog space as the generative process approaches clean data. However, the curvature of the schedulevaries between datasets which is to be expected as the schedule is determined through the score whichwill vary depending on the data distribution. We find that, in general, the higher resolution datasets(FFHQ, AFHQv2 and ImageNet) favour shorter steps nearer the start of the generative process at theexpense of larger steps at low noise levels near the end of the generative process. 0.500.250.000.250.50 t = 1 0.500.250.000.250.50 t = 3 0.500.250.000.250.50 t = 5 0.500.250.000.250.50 t = 7 0.500.250.000.250.50 t = 9 0.500.250.000.250.50 t = 11 0.500.250.000.250.50 t = 13 0.500.250.000.250.50 t = 15 0.500.250.000.250.50 t = 17 0.500.250.000.250.50 t = 19 0.500.250.000.250.50 t = 21 0.500.250.000.250.50 t = 23 0.500.250.000.250.50 t = 25 0.500.250.000.250.50 t = 27 0.500.250.000.250.50 t = 29 0.500.250.000.250.50 t = 31 0.500.250.000.250.50 t = 33 0.500.250.000.250.50 7.5 5.0 2.5 0.0 2.5 5.0 7.5 t = 35 0.500.250.000.250.50 t = 37 0.500.250.000.250.50 t = 39 : Evolution of the estimated score for the mollified Cantor distribution .1 with aCorrector Optimised Schedule. In this case the linear schedule fails to evenly progress the progressionof the score, see showing the terminal score estimate in this case. The estimated scoreexhibits a self-similar nature of interweaving roots around the centers of mass of the mollified Cantordistribution. Identification of these roots amounts to estimated modes in our density estimate, see.",
  "Timestep": "0.0 0.2 0.4 0.6 0.8 1.0 (1t)0.5 Schedule lr=0.05Cosine Schedule : Progression of the length and energy Equation (18) over training of MNIST. Both modelsare trained from initialisation, one with adaptive schedule learning (red) and one without (blue). Wecan see that the energy and length quantities increase during training. Recall that for a fixed pathof scores t log pt that the length is constant. As we are learning the score, this value is notconstant during training. Interestingly, by optimising the schedule during training we observe a largerlength value, possibly indicating that the diffusion path learned with the optimised schedule differsgreatly from the path learned without. : Sample progression of MNIST digits for the standard cosine schedule with = 0.008(top) against our optimised schedule (bottom). As we can see, the cosine schedule spends more timenear the Gaussian reference distribution whereas the optimised schedule quickly determines largescale features and spends more time toward the data distribution.",
  "Length": "Schedule lr=0.1Schedule lr=0.01Cosine Schedule : Progression of the length and cost through online training for CIFAR-10. For the largerlearning rate, Algorithm 2 seems to garner a larger value at a faster rate that the lower schedulelearning rate. For the fixed cosine schedule run, is stable, perhaps because the score estimate hasstabilised for the fixed cosine schedule already during the model training burn-in phase.",
  "with a dropout rate of 0.3. The diffusion process was configured with 500 diffusion steps. Trainingwas conducted with a learning rate of 1e-4": "The schedule was also initialised with the Cosine schedule and trained for 60,000 iterations on anNVIDIA 1080 Ti GPU with 12 GB RAM. The batch size for MNIST was set to 128. We trained twomodels: one with the schedule optimisation and one without. The schedule training rate was set to = 0.05, as stated in Algorithm 2. Training took approximately 12 hours for either model. CIFAR-10: For the CIFAR-10 experiments, we trained a model with an image size of 32, 128channels, and a U-Net architecture with 3 residual blocks per multiplier resolution (described incodebase Nichol and Dhariwal (2021)), without learning sigma, and with a dropout rate of 0.3. Thediffusion process was configured with 1000 diffusion steps and a cosine noise schedule. The schedule was initialised with the Cosine schedule and trained for 160,000 iterations on 4 NVIDIAA40 GPUs, each with 48 GB RAM. The batch size was set to 1,536. After training for 160,000iterations, we trained two models online: one with the corrector schedule optimisation and onewithout, for an additional 50,000 iterations on a single GPU with a batch size of 384. The burn inphase for training took approximately 50 hours, with the individual schedule optimisations after thistaking approximately 24 hours.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-perimental results of the paper to the extent that it affects the main claims and/or conclusionsof the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justification: We provide detailed descriptions of our experimental procedures in Appendix Cand provide the code to run our experiments.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [No]Justification: Our main metric is FID score for which it is standard practice to reportit calculated on the first 50,000 images generated from the model. Standard deviationscould be bootstrapped from this set but this is not standard practice. Furthermore, thecomputational cost to sample large image models 50,000 times multiple times is prohibitivefor our academic compute cluster.",
  ". Broader Impacts": "Question: Does the paper discuss both potential positive societal impacts and negativesocietal impacts of the work performed?Answer: [NA] .Justification: This paper is mostly theoretical and methodological. We do not see immediatesocietal impact of this work. However, we acknowledge that large scale implementation ofour algorithm might suffer from the same societal biases as any other generative models.Indeed it could improve the quality of generative models and hence been used to generatedeepfakes for disinformation.",
  ". Crowdsourcing and Research with Human Subjects": "Question: For crowdsourcing experiments and research with human subjects, does the paperinclude the full text of instructions given to participants and screenshots, if applicable, aswell as details about compensation (if any)?Answer: [NA] .Justification: The paper does not involve crowdsourcing nor research with human subjects. 15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA] .Justification: The paper does not involve crowdsourcing nor research with human subjects."
}