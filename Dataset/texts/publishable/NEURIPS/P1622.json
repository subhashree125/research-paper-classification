{
  "Abstract": "End-to-end transformer-based trackers have achieved remarkable performance onmost human-related datasets. However, training these trackers in heterogeneousscenarios poses significant challenges, including negative interference where themodel learns conflicting scene-specific parameters and limited domain gener-alization, which often necessitates expensive fine-tuning to adapt the models tonew domains. In response to these challenges, we introduce Parameter-efficientScenario-specific Tracking Architecture (PASTA), a novel framework that com-bines Parameter-Efficient Fine-Tuning (PEFT) and Modular Deep Learning (MDL).Specifically, we define key scenario attributes (e.g., camera-viewpoint, lightingcondition) and train specialized PEFT modules for each attribute. These expertmodules are combined in parameter space, enabling systematic generalization tonew domains without increasing inference time. Extensive experiments on MOT-Synth, along with zero-shot evaluations on MOT17 and PersonPath22 demonstratethat a neural tracker built from carefully selected modules surpasses its monolithiccounterpart. We release models and code.",
  "Introduction": "Video Surveillance is essential for enhancing security, supporting law enforcement, improving safety,and increasing operational efficiency across various sectors. In this respect, Multiple Object Tracking(MOT) is a widely studied topic due to its inherent complexity. Nowadays, MOT is commonly tackledwith two main paradigms: tracking-by-detection (TbD) or query-basedtracking (i.e., tracking-by-attention). Although tracking-by-detection methods haveproven effective across multiple datasets, their performance struggles to scale on larger datasets dueto the non-differentiable mechanism used for linking new detections to existing tracks. To this end,query-based methods are being employed to unify the detection and association phase. Nevertheless, training such end-to-end transformer-based methods presents significant challenges,as they tend to overfit specific scenario settings (e.g., camera viewpoint, indoor vs. outdoorenvironments), require vast amounts of data , and incur substantial computational costs. Moreover,these methods degrade under domain shifts, struggling to outperform traditional TbD methods. In light of these challenges, we propose a novel framework, Parameter-efficient Scenario-specificTracking Architecture (PASTA), aimed at reducing the computational costs and enhancing the transfercapabilities of such models. Leveraging Parameter Efficient Fine-Tuning (PEFT) techniques can significantly decrease computational expenses and training time, starting with a frozen backbonepre-trained on synthetic data. However, the model may still experience negative interference [49,",
  ": Given a scene, we select the modules corresponding to its attributes, such as lighting andindoor/outdoor. These modules are composed and then deployed, yielding a specialized model": "50, 37, 55], a phenomenon for which training on multiple tasks (or scenarios) causes the model tolearn task-specific parameters that may conflict. For instance, if the model learns parameters tailoredfor an indoor sports activity, it could detrimentally affect its performance on a novel outdoor scenedepicting people walking. To this end, inspired by Modular Deep Learning (MDL) , we employa lightweight expert module for each attribute, learn them separately, and finally compose themefficiently . This approach depicted in is akin to a chef preparing a pasta dish. Eachingredient (i.e., module) is prepared individually to preserve its unique flavor and then combinedharmoniously to create a balanced dish. Moreover, as pasta must be perfectly al dente to serve as theideal base for various sauces, the pre-trained backbone should be robust and well-tuned to serve asthe foundation for the modules. These modules must be combined effectively to ensure the modelperforms well across diverse scenarios. Conversely, the result will be sub-optimal if incompatiblemodules are mixed analogous to combining ingredients that do not complement each other. Indeed,combining contrasting modules can lead to ineffective handling of diverse tasks. Notably, such a modular framework brings two advantages: it avoids negative interference andenhances generalization by leveraging domain-specific knowledge. Firstly, starting from a pre-trainedbackbone, we train each module independently to prevent parameter conflicts, ensuring that gradientupdates are confined to the relevant module for the specific scenario. This assures that parameterslearned for one attribute do not negatively impact the performance of another. Secondly, the modularapproach allows us to exploit domain knowledge fully, even when encountering a novel attributecombination. Indeed, as shown in Sec. 5.5, our approach is effective even in a zero-shot setting (i.e.,without further fine-tuning on the target dataset). Moreover, the selection of the modules may bedone automatically or in a more realistic production environment by video surveillance operators. To evaluate our approach, we conduct extensive experiments on the synthetic MOTSynth and thereal-world MOT17 and PersonPath22 datasets. The results show that PASTA can effectivelyleverage the knowledge learned by the modules to improve tracking performance on both the sourcedataset and in zero-shot scenarios. To summarize, we highlight the following main contributions:",
  "Related works": "Multiple Object Tracking. The most widely adopted paradigm for Multiple Object Tracking (MOT)is tracking-by-detection (TbD) . First, an object detector (e.g., YOLOX )localizes objects in the current frame. Next, the association step matches detections to tracks fromthe previous frame by solving a minimum-cost bipartite matching problem, with the association costdefined in various forms (e.g., IoU , GIoU , or geometrical cues ). This pairingtypically occurs immediately after propagating the previous tracks to the current frame using a motionmodel (e.g., Kalman Filter ). Notably, methods following such paradigm have succeeded on complex human-related MOT benchmarks . In TbD, the detection and data-associationsteps are equally crucial to accurately localizing and tracking objects. Recent works haveattempted to unify these steps; however, progress toward a fully unified algorithm was constrained bya significant limitation the data association process (e.g., the Hungarian algorithm ) is inherentlynon-differentiable. An initial effort was made by Xu et al. that proposed a differentiable version ofthe Hungarian algorithm, later advanced by end-to-end transformer-based trackers . However, transformer-based trackers (also known as tracking-by-attention) require large amounts ofdata to achieve decent generalization capabilities . Due to the data scarcity in MOT, thesemodels often overfit to the specific domain they were trained on, which hampers their ability togeneralize to different domains . Modular Deep Learning (MDL). Considering recent trends in the field of deep learning, state-of-the-art models have become increasingly larger. Consequentially, fine-tuning these models hasbecome expensive; concurrently, they still struggle with tasks like symbolic reasoning and temporalunderstanding . Recent learning paradigms based on Modular Deep Learning (MDL) can address these challenges by disentangling core pre-training knowledge from domain-specificcapabilities. By applying modularity principles, deep models can be easily edited, allowing for theseamless integration of new capabilities and the selective removal of existing ones . Specifically, lightweight computation functions named modules are employed to adapt a pre-trainedneural network. To do so, several fine-tuning techniques could be used to realize these modules,such as LoRA , (IA)3 , and SSF . These multiple modules can be learned on differenttasks such that they can specialize in different concepts . At inference time, not all modules haveto be active at the same time. Instead, they can be selectively utilized as needed, either based onprior knowledge of the domain or dynamically in response to the current input. To establish whichmodules to activate, it is common practice to rely on a routing function, which can be either learnedor fixed. Finally, the outputs of the selected modules are combined using an aggregation function. Tominimize inference costs, this process is usually performed in the parameter space rather than theoutput space, an activity often referred to as model merging . Specifically, a single forward pass isperformed using weights generated by a linear combination of those selected by the routing function. Domain adaptation and open-vocabulary approaches in MOT. Currently, domain adaptation tech-niques have only been applied to tracking-by-detection methods, with GHOST and DARTH serving as notable examples. In particular, GHOST adapts the visual encoder employed to feedthe appearance model by updating the sufficient statistics of the Batch Normalization layers duringinference. In contrast, our approach regards tracking-by-attention approaches and adapts the entirenetwork. Moreover, DARTH employs test-time adaptation (TTA) and Knowledge Distillation,requiring multiple forward passes and entire sequences, making it computationally heavy and lesspractical for real-time use. In contrast, our method is entirely online and requires only basic targetscene attributes, with no further training during deployment. Recent advances in zero-shot tracking have focused on open-vocabulary tracking, where the modelcan track novel object categories by prompting it with the corresponding textual representation. Inthis respect, methods like OVTrack and Z-GMOT leverage CLIP and language-basedpre-training, while OVTracktor extends tracking to any category. Our method does not useopen-vocabulary models but emphasizes domain knowledge transfer in end-to-end trackers.",
  "Preliminaries": "Efficient fine-tuning. Given the substantial size of recent vision backbones, often consisting ofhundreds of millions of parameters, adapting them to new scenarios is computationally expensive,both in terms of time and memory requirements. To tackle the above problems, Parameter EfficientFine-Tuning (PEFT) started to take place in recent literature. Among these methods, Low-RankAdaptation (LoRA) excels at such purpose. Specifically, LoRA adapts a pre-trained weightmatrix 0 Rdk, with d and k being the dimensions of the matrix, by leveraging a low-rankdecomposition 0 + = 0 + BA, where B Rdr, A Rrk, and r min(d, k). Duringtraining, 0 is kept frozen, while the smaller A and B matrices are instead trainable, making theprocess highly efficient. The forward pass becomes h = 0x + BAx, where x are the input features.",
  "Deployment": ": Overview of our modular architecture. A domain expert selects PEFT modules basedon sequence attributes such as lighting and camera movement. These selected modules are thencomposed and applied to each model layer, adapting the backbone and encoder-decoder architecture. Query-based Multiple Object Tracking. The underlying backbone of our transformer-based trackerfollows the structure of . In a nutshell, such a query-based model forces each query to recallthe same instance across different frames. Specifically, we leverage an end-to-end trainable trackerbuilt upon the Deformable DETR framework conditioned by the image features extracted with aconvolutional backbone (i.e., ResNet ). Following , we further condition the DETR decoderwith a set of detections from an external detector network and a shared learnable query. At time t = 0, new proposals are generated from the objects detected in the scene. These proposalsare then updated through self-attention and interact with image features via the deformable attentionlayer. The final prediction output is the summation of the initial anchors and the predicted offsets.For subsequent frames (t > 0), track queries generated from the previous frame are concatenatedwith learnable proposal queries of the current frame. Moreover, previous predictions are integratedwith current proposals to establish new anchors for the incoming frame. We refer the reader to theoriginal paper for further details. It is noted that the flexibility of this architecture allows for theseamless integration of techniques based on modularity.",
  "Method": "We herein present PASTA, depicted in , a novel approach to Multiple Object Tracking thatleverages PEFT modules to enable attribute-specific module specialization and reuse. This approachallows for the dynamic configuration of an end-to-end tracker by selecting the appropriate modulesfor each input scene, fully leveraging heterogeneous pre-training while avoiding negative transfer. Attribute-based modularity. We devise a set of learnable modules to fine-tune each layer of ourquery-based tracker. Each module is related to an attribute: as shown in , we define N = 5attributes, namely lighting, viewpoint, occupancy, location, and camera motion, and provide a tailoredmodule for each discrete value these attributes take (see Sec. 5.3 for details). For instance, the locationattribute has indoor and outdoor modules. At inference time, prior knowledge about the input sceneis used to determine the appropriate value for each attribute, which in turn selects the correspondingmodules from the inventory, denoted as M. Since the base model relies on heterogeneous layers namely, convolutional (e.g., ResNet) andattention-based blocks (e.g., Deformable DETR) we employ two different strategies to fine-tune themodules. Specifically, after each convolutional layer of the ResNet backbone, we apply a strategy",
  ": Examples of surveillance scenes and their corresponding attributes used by PASTA": "that learns channel-wise scale and shift parameters; for each layer of Deformable DETR, instead, weemploy LoRA-based fine-tuning at each linear layer. In formal terms, considering each convolutionallayer of the ResNet backbone, we deploy |M| pairs {m, m}|M|m=1 of learnable vectors , RC,where C is the number of the output channels. For each linear layer l of the encoder-decoder structureunderlying Deformable DETR, we devise |M| pairs {Am, Bm}|M|m=1 of learnable LoRA matrices. During training, we start with the pre-trained weights and integrate all the modules while keeping theoriginal parameters frozen. To prevent negative interference, we optimize each module independently,randomly sampling one attribute at a time and updating only the corresponding module at eachtraining iteration. By the end of the training process, we obtain a set of specialized parameters(experts), which can be seamlessly merged during inference to improve overall tracking performance. Routing through Domain Expert. During inference, two essential steps are required to exploit thelearned modules: routing and aggregation. With multiple modules available from the inventory M, arouting strategy is required to determine the modules that should be active. To make this selection, wedraw on what is known in the literature as expert knowledge (or Domain Expert in ).In real-world applications such as video analytics, the expertise guiding the selection can come froma video surveillance operator or human analyst, who configures the appropriate modules to reflectdomain- and scene-specific settings, such as camera perspective, lighting conditions, and other criticaldetails. This approach allows users to optimize the tracking module for their unique contexts withoutextensive retraining. Additionally, the modular nature of the system enables easy integration of newmodules to address emerging attributes or scenarios. Relying on Domain Expert to select attributes is a grounded practice in real-world applications. Forinstance, the cameras mounting perspective and whether the scene is indoors or outdoors are typicallyknown factors in fixed-camera scenarios. Additionally, automatic approaches can be envisioned tominimize human intervention further. For example, lighting conditions can be inferred by analyzingbrightness levels, and a detector can count objects of interest in the scene, classifying crowd density. Modules composition. In the final step, we aggregate the selected modules (Modules Compositionin ) and incorporate the result into the pre-trained tracker to create an expert model. Sincethese modules have been obtained by fine-tuning from 0, each module corresponds to a specificdisplacement = 0 in parameter space relative to the initial pre-training parameters 0. Thisdisplacement is known as the task vector . The final composed model f(; c) is defined as:",
  "When i = 1": "N , the formula simplifies to the average of the task vectors corresponding to each attribute.We employ this straightforward strategy for i, giving equal weight to all attributes. However,considering the task vector i associated with the i-th attribute, we employ a more sophisticatedapproach. If there are no domain shifts during inference (i.e., both training and testing occur on thesame dataset, such as MOTSynth), the task vector i is simply set to the displacement producedby the expert module selected by the Domain Expert. In contrast, when domain shifts are present(e.g., training on MOTSynth and testing on MOT17), we adopt a soft strategy that considers all themodules in the inventory associated with the relevant attribute. In doing so, we follow the insightsfrom , where the authors demonstrated that scenarios with shifting tasks benefit from richerrepresentations than those derived from a single optimization episode.",
  "Specifically, given the i-th attribute, let R(i) be the set of its modules. We recall that each attributeadmits multiple discrete values (e.g., R(occupancy) = {low, medium, high}), and different": "attributes may have different cardinalities (e.g., |R(occupancy)|= 3 and |R(lighting)|= 2, as detailedin Sec. 5.3). Building on this, we employ soft routing to create the corresponding task vector,assigning the largest portion of the cake, e.g. = 0.80, to the module selected by the Domain Expert.The remaining modules are weighted by (1 )/(|R(i)|1), ensuring that the total sum equals 1.For example, considering those layers fine-tuned with the LoRA, the corresponding task vector iscomputed as:",
  "|R(i)|1otherwise.(2)": "Note that when = 1, the soft strategy becomes hard, meaning that only the module selected byDomain Expert is utilized. By applying the formula above to all attributes, we obtain N task vectors,which we aggregate following Eq. (1). Similarly, we apply channel-wise scale and shift operations to adapt each backbone layer.Formally, given the output F of a convolutional layer, the i-th module applies a scale & shiftoperation to obtain the edited Fi, such that Fi = i F + i with denoting the Hadamard product.At inference time, we combine the output of different scale & shift modules by noting thatF = Ni=1 i(i F + i) = Ni=1 i(i F) + ii = (Ni=1 ii) F + Ni=1 ii,(3)which means that parametrizing the scale & shift layer with a simple weighted average effectivelyresults in averaging the outputs of the corresponding individual layers. The formula above applies tothe in-domain setting but can be easily generalized to the soft routing scheme outlined by Eq. (2).Eventually, as discussed in , the scale & shift layer can be absorbed into the previous projectionlayer, thus ensuring that the inference process incurs no additional computational costs. The samere-parametrization trick can be employed to extract the task vector underlying scale & shift fine-tuning(refer to appendix A for additional notes).",
  "Datasets": "MOTSynth is a large synthetic dataset for pedestrian detection and tracking in urban scenarios,generated using a photorealistic video game. It comprises 764 full HD videos, each 1800 frames long,showcasing various attributes. In our experiments, following , we reduced the test sequences to600 frames each and further split the training set to extract 48 validation sequences, shortened to 150frames, for validation during training.",
  "Experimental setting": "We evaluate our proposed PASTA on both in-domain and out-of-domain scenarios. For the in-domain evaluation, we train and test PASTA on the MOTSynth synthetic dataset (Sec. 5.4) usingexpert modules in a domain-specific context. As a baseline, we train on MOTSynth without usingmodules, referring to this model as MOTRv2-MS. For the out-of-domain evaluation, we conduct asynth-to-real zero-shot experiment on MOT17 and PersonPath22 (Sec. 5.5). Starting from training onMOTSynth, we test PASTA on these datasets without additional training, showcasing its ability togeneralize under non-identically distributed domains. Finally, we present a series of ablation studiesin Sec. 6 to take a closer look at the effectiveness of our method. Competing trackers and metrics. In addition, we report the performance of other notable methods,including strong tracking-by-detection baselines such as ByteTrack and OC-Sort . We alsoinclude evaluations of query-based trackers, such as TrackFormer and MOTRv2 (seeMOTRv2-MS). To compare their performance, we employ five metrics, ordered from detectionto association, as recommended by . These metrics are DetA , MOTA , HOTA ,IDF1 , and AssA . For the PersonPath22 dataset, we use their official metrics, MOTA andIDF1, supplemented by FP (false positives), FN (false negatives), and IDSW (identity switches).",
  "Implementation details": "We initialize our models using the pre-trained weights from DanceTrack , as provided bythe authors of . We employ YOLOX as the auxiliary detector, exploiting weights fromByteTrack . To provide a shared initialization for both PASTA and MOTRv2-MS training, wetrain a bootstrap model starting from the DanceTrack pre-train for 28k iterations on the MOTSynthtraining set. This bootstrap initialization uses half of the original training sequences from MOTSynthto align our model with the scenarios represented in the dataset. The learning rates are set to 5105for the transformer and 1 106 for the visual backbone. In the second phase, we deploy the PEFT modules to fine-tune the bootstrap model. By excludinghalf the sequences during the bootstrap, we make sure that the modules can still learn valuablefeatures. To ensure a fair comparison, we train each module for a similar number of iterations asMOTRv2-MS, with approximately 17k iterations. Regarding the encoder-decoder model, we applyour modularization strategy to every linear layer except those with output dimension less than 128.For the LoRA hyperparameters, we use r = 16, a weight decay of 0.1, and a learning rate of 3104.The scale & shift layers employ a learning rate of 1 105 and a weight decay of 1 104. Thetraining is performed on a single RTX 4080 GPU with a batch size of 1 for both phases. Due to thesmall batch size, we accumulate gradients over four backward steps before performing an optimizerstep. Each module is trained independently on the entire MOTSynth training set. With 12 modules,our model has approximately 15 million trainable parameters. Attributes. We employ five key attributes to realize our modular architecture: lighting, cameraviewpoint, people occupancy, location, and camera motion. For lighting, we specialize modulesfor good and bad lighting conditions. To do so, we threshold the brightness value V of the HSVrepresentation at 70. The viewpoint attribute includes modules for high, medium, and low cameraangles. We manually annotate this attribute as follows: i) scenes where the camera is parallel tothe ground at or below pedestrian head level are labeled as low-level; ii) high-level viewpointsinclude vertical perspectives or scenes where the camera is positioned very high or far from people;and iii) medium-level includes all other camera angles. For occupancy, we design modules thatreflect the crowd density within the scene: low (up to 10 people), medium (10 to 40 people), andhigh (more than 40 people), based on the count of detections with a confidence score above 0.2. Thelocation attribute differentiates between indoor and outdoor settings. Lastly, the motion attributecomprises modules for both moving and static cameras, enabling the model to adapt to differentcamera movement scenarios. Further details on dataset statistics are provided in appendix C.",
  "Performance in the in-domain setting": "To assess the impact of the negative interference, we conduct several experiments on MOTSynth(see Tab. 1). Given the wide variety of scenarios in such a synthetic dataset, one can appreciate theadvantages of using specialized modules. Indeed, integrating our modules resulted in an overall im-provement w.r.t. its fine-tuning counterpart (MOTRv2-MS). Specifically, we observe an improvementover the association metrics (AssA, IDF1) and the HOTA and MOTA metrics. These enhancementssuggest the benefits of our approach in reducing negative interference during training. By assigningeach module a specific role tailored to particular scenario settings, we achieve improved trainingstability through a deterministic selection process guided by a domain expert.",
  "Performance in the out-of-domain setting": "By designing distinct modules for various input conditions, we can effectively select the appropriatemodules to handle distribution shifts, such as transitions to a new domain. We assess the benefitsof this ability using synthetic data for training, and then evaluate on new, unseen datasets withoutany additional re-training (zero-shot). To do this, we start with our model trained on MOTSynth asdescribed in Sec. 5.4 and evaluate it on MOT17 (Tab. 2) and PersonPath22 (Tab. 3). While thesedatasets share similarities in the attributes we employed, we emphasize that the source dataset issynthetic and the targets are real-world, resulting in a significant shift. The results reported in Tab. 2 and 3 show an improvement over the baseline (i.e., MOTRv2-MS),with +1.4 in HOTA and +1.9 in IDF1 in zero-shot MOT17, and +1.7 in MOTA and +0.7 in IDF1in PersonPath22. Our approach demonstrates better generalization capabilities, helping close thegap with fully-trained methods while less computationally demanding. These results indicate thatmodularity enhances performance within the source dataset and improves domain generalization,leading to more reliable and versatile approach for tracking. Furthermore, other than reporting theresults with the standard module selection (considering only the modules present in the scenes, = 1),we also experiment with the weighted aggregation of all modules ( = 0.8) (detailed in Sec. 4).Interestingly, while the standard strategy shows improvements, the weighted aggregation strategyyields better performance. This suggests that richer representations, obtained by including multiplemodules per attribute, are more effective for zero-shot scenarios than a single-module approach .",
  "Domain Expert63.774.167.9": "Evaluating zero-shot real-to-real transfer.In Tab. 4, we present an additional experiment toevaluate the performance of PASTA in a zero-shot setting, this time using a realistic dataset as thesource, rather than a synthetic one. For comparison, we train MOTRv2 on the MOT17 dataset andassess its performance on PersonPath22. Our approach showcases superior results compared tothe fine-tuned MOTRv2, highlighting that leveraging modules enhances the model, with improvedgeneralization capabilities in new and real-world domains.",
  "Ablation studies": "In Tab. 5, we evaluate the effect of various routing and aggregation strategies in both the in-domainsetting (MOTSynth, left side of Tab. 5) and the zero-shot setting (MOT17, right side of Tab. 5). Inthe in-domain scenario, the results show that averaging the modules selected by the Domain Expert,specifically using Mean avg. ( = 1.0), is the most effective strategy. We also experimented withsummation, as proposed by , but this method produced bad results, which we impute to thealteration of weight magnitudes when summing multiple modules. Another noteworthy approach isthe weighted avg., described in Sec. 4, which incorporates all modules, including those not selected. While using only the selected modules is the optimal strategy in the in-domain scenario, for thezero-shot case (MOT17), incorporating knowledge from the non-selected modules specifically,using Weighted avg. ( = 0.8) enhances tracking performance. This pattern is also consistent whenthe domain shift involves evaluation on the PersonPath22 dataset (see appendix E). Module selection. Should we select only the modules representing the current scenario, as deter-mined by the Domain Expert approach, or would performance improve by incorporating all availablemodules? In Tab. 5, we investigate this matter by comparing these two approaches. To provide amore comprehensive perspective, we also evaluate a strategy that, in stark contrast to the DomainExpert, selects the opposite modules (e.g., selecting the outdoor and poor lighting modules whenpresented with an indoor, well-lit scene). The lowest performance is observed when using oppositemodules, indicating that using the proper modules provides valuable information about the currentscene. Interestingly, the model still performs relatively well despite using opposite attributes, likelydue to contributions from other modules whose general knowledge of the domain sustains overallperformance. This suggests that modules can assist one another in solving tasks. Moreover, reduced base model + lighting + occupancy + motion + location + viewpoint 54.97 50.63 56.87 52.48 57.41 52.79 57.45 52.74 57.48 52.88 57.81 53.02 IDF1HOTA",
  "negative interference achieved by training each module separately prevents the modules fromrelying on each other and allows them to make unique contributions independently": "Furthermore, in , we illustrate how the incremental addition of specialized modules improvesIDF1 and HOTA metrics, showcasing that greater specialization of the modules gradually enhancesoverall performance. For a more detailed analysis, in Tab. 6, we select the opposite modules insteadof the correct one for each attribute. Although the metrics are further reduced, the model performswell due to its robust pre-training, as indicated by the no modules baseline shown in the table. Block-wise analysis. In our approach, attribute-related modules are applied to edit the entire network.However, users may opt to edit selectively specific parts of the architecture, thereby identifying whichcomponents are most critical. In Tab. 7, we conduct an ablation study by excluding our modulesfrom being applied to varying components of the architecture. The results indicate that not applyingtask vectors to the decoder significantly degrades detection and association metrics. We believethat this degradation can be explained by considering the crucial role of the decoder. The decodermust indeed gather information from detection, tracking, and proposal queries while simultaneouslyintegrating visual information from the encoder. Consequently, not adapting the decoder preventsthe architecture from effectively leveraging queries and visual cues. The encoder also contributessubstantially, though to a lesser extent than the decoder, as it primarily refines and contextualizesvisual features from the backbone. Finally, the backbone shows the smallest contribution.",
  "Conclusions": "In this work, we introduce PASTA, a novel framework that enhances domain generalization intracking-by-query methods for Multiple Object Tracking. Our approach features a modular struc-ture with dedicated modules tailored to different attributes of real-world scenes. These modulesutilize Parameter-Efficient Fine-Tuning techniques, enabling the integration of scene-specific parame-ters while minimizing computational load. Comprehensive experiments demonstrate that domain-specialized modules significantly bolster robustness, allowing effective adaptation across domainswithout extensive retraining. PASTA further enables camera operators to configure the optimalmodule for each unique scenario, ensuring precise adaptation to diverse real-world settings.",
  "Alex Bewley, Zongyuan Ge, Lionel Ott, Fabio Ramos, and Ben Upcroft. Simple online and realtimetracking. In IEEE International Conference on Image Processing, 2016": "Dan Biderman, Jose Gonzalez Ortiz, Jacob Portes, Mansheej Paul, Philip Greengard, Connor Jennings,Daniel King, Sam Havens, Vitaliy Chiley, Jonathan Frankle, et al. Lora learns less and forgets less. InTransactions on Machine Learning Research, 2024. Jinkun Cao, Xinshuo Weng, Rawal Khirodkar, Jiangmiao Pang, and Kris Kitani. Observation-centric sort:Rethinking sort for robust multi-object tracking. In Proceedings of the IEEE conference on ComputerVision and Pattern Recognition, 2022. Nicolas Carion, Francisco Massa, Gabriel Synnaeve, Nicolas Usunier, Alexander Kirillov, and SergeyZagoruyko. End-to-end object detection with transformers. In European conference on computer vision,pages 213229. Springer, 2020. Wen-Hsuan Chu, Adam W. Harley, Pavel Tokmakov, Achal Dave, Leonidas J. Guibas, and KaterinaFragkiadaki. Zero-shot open-vocabulary tracking with large pre-trained models. In arXiV preprintarXiV:2310.06992, 2023. Patrick Dendorfer, Aljosa Osep, Anton Milan, Konrad Schindler, Daniel Cremers, Ian Reid, StefanRoth, and Laura Leal-Taix. Motchallenge: A benchmark for single-camera multiple target tracking.International Journal of Computer Vision, 2021. Patrick Dendorfer, Hamid Rezatofighi, Anton Milan, Javen Shi, Daniel Cremers, Ian Reid, Stefan Roth,Konrad Schindler, and Laura Leal-Taix. Mot20: A benchmark for multi object tracking in crowded scenes.arXiv preprint arXiv:2003.09003, 2020. Matteo Fabbri, Guillem Bras, Gianluca Maugeri, Aljoa Oep, Riccardo Gasparini, Orcun Cetintas,Simone Calderara, Laura Leal-Taix, and Rita Cucchiara. Motsynth: How can synthetic data helppedestrian detection and tracking? In IEEE International Conference on Computer Vision, 2021. Emanuele Frascaroli, Aniello Panariello, Pietro Buzzega, Lorenzo Bonicelli, Angelo Porrello, and SimoneCalderara. Clip with generative latent replay: a strong baseline for incremental learning. In British MachineVision Conference, 2024.",
  "Michael McCloskey and Neal J Cohen. Catastrophic interference in connectionist networks: The sequentiallearning problem. In Psychology of learning and motivation, 1989": "Tim Meinhardt, Alexander Kirillov, Laura Leal-Taixe, and Christoph Feichtenhofer. Trackformer: Multi-object tracking with transformers. In Proceedings of the IEEE conference on Computer Vision and PatternRecognition, 2022. Guillermo Ortiz-Jimenez, Alessandro Favero, and Pascal Frossard. Task arithmetic in the tangent space:Improved editing of pre-trained models. Advances in Neural Information Processing Systems, 36, 2024. Aniello Panariello, Gianluca Mancusi, Fedy Haj Ali, Angelo Porrello, Simone Calderara, and RitaCucchiara. Distformer: Enhancing local and global features for monocular per-object distance estimation.arXiv preprint arXiv:2401.03191, 2024. Ethan Perez, Florian Strub, Harm De Vries, Vincent Dumoulin, and Aaron Courville. Film: Visual reason-ing with a general conditioning layer. In Proceedings of the AAAI Conference on Artificial Intelligence,2018.",
  "Zheng Qin, Le Wang, Sanping Zhou, Panpan Fu, Gang Hua, and Wei Tang. Towards generalizablemulti-object tracking. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition,2024": "Zheng Qin, Sanping Zhou, Le Wang, Jinghai Duan, Gang Hua, and Wei Tang. Motiontrack: Learningrobust short-term and long-term motions for multi-object tracking. In Proceedings of the IEEE conferenceon Computer Vision and Pattern Recognition, 2023. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, GirishSastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual models fromnatural language supervision. In International Conference on Machine Learning, 2021. Hamid Rezatofighi, Nathan Tsoi, JunYoung Gwak, Amir Sadeghian, Ian Reid, and Silvio Savarese.Generalized intersection over union: A metric and a loss for bounding box regression. In Proceedings ofthe IEEE conference on Computer Vision and Pattern Recognition, 2019. Ergys Ristani, Francesco Solera, Roger Zou, Rita Cucchiara, and Carlo Tomasi. Performance measuresand a data set for multi-target, multi-camera tracking. In Proceedings of the European Conference onComputer Vision, 2016.",
  "Mattia Segu, Bernt Schiele, and Fisher Yu. Darth: Holistic test-time adaptation for multiple object tracking.In IEEE International Conference on Computer Vision, 2023": "Jenny Seidenschwarz, Guillem Bras, Victor Castro Serrano, Ismail Elezi, and Laura Leal-Taix. Simplecues lead to a strong multi-object tracker. In Proceedings of the IEEE conference on Computer Vision andPattern Recognition, 2023. Bing Shuai, Alessandro Bergamo, Uta Buechler, Andrew Berneshawi, Alyssa Boden, and Joseph Tighe.Large scale real-world multi-person tracking. In Proceedings of the European Conference on ComputerVision, 2022.",
  "Bing Shuai, Xinyu Li, Kaustav Kundu, and Joseph Tighe. Id-free person similarity learning. In Proceedingsof the IEEE conference on Computer Vision and Pattern Recognition, 2022": "Peize Sun, Jinkun Cao, Yi Jiang, Zehuan Yuan, Song Bai, Kris Kitani, and Ping Luo. Dancetrack: Multi-object tracking in uniform appearance and diverse motion. In Proceedings of the IEEE conference onComputer Vision and Pattern Recognition, 2022. Kim Tran, Anh Duy Le Dinh, Tien-Phat Nguyen, Thinh Phan, Pha Nguyen, Khoa Luu, Donald Adjeroh,Gianfranco Doretto, and Ngan Le. Z-GMOT: Zero-shot generic multiple object tracking. In Proceedingsof the Conference of the North American Chapter of the Association for Computational Linguistics, 2024.",
  "Xingjiao Wu, Luwei Xiao, Yixuan Sun, Junhang Zhang, Tianlong Ma, and Liangbo He. A survey ofhuman-in-the-loop for machine learning. Future generations computer systems, 2021": "Yihong Xu, Aljosa Osep, Yutong Ban, Radu Horaud, Laura Leal-Taix, and Xavier Alameda-Pineda. Howto train your deep multi-object tracker. In Proceedings of the IEEE conference on Computer Vision andPattern Recognition, 2020. Enneng Yang, Li Shen, Guibing Guo, Xingwei Wang, Xiaochun Cao, Jie Zhang, and Dacheng Tao. Modelmerging in llms, mllms, and beyond: Methods, theories, applications and opportunities. arXiv preprintarXiv:2408.07666, 2024. En Yu, Songtao Liu, Zhuoling Li, Jinrong Yang, Zeming Li, Shoudong Han, and Wenbing Tao. Generalizingmultiple object tracking to unseen domains by introducing natural language representation. In Proceedingsof the AAAI Conference on Artificial Intelligence, 2023.",
  "En Yu, Tiancai Wang, Zhuoling Li, Yuang Zhang, Xiangyu Zhang, and Wenbing Tao. Motrv3: Release-fetch supervision for end-to-end multi-object tracking. arXiv preprint arXiv:2305.14298, 2023": "Jiazuo Yu, Yunzhi Zhuge, Lu Zhang, Ping Hu, Dong Wang, Huchuan Lu, and You He. Boosting continuallearning of vision-language models via mixture-of-experts adapters. In Proceedings of the IEEE conferenceon Computer Vision and Pattern Recognition, 2024. Fangao Zeng, Bin Dong, Yuang Zhang, Tiancai Wang, Xiangyu Zhang, and Yichen Wei. Motr: End-to-endmultiple-object tracking with transformer. In Proceedings of the European Conference on Computer Vision,2022.",
  "Jinghan Zhang, Junteng Liu, Junxian He, et al. Composing parameter-efficient modules with arithmeticoperation. Advances in Neural Information Processing Systems, 2023": "Yifu Zhang, Peize Sun, Yi Jiang, Dongdong Yu, Fucheng Weng, Zehuan Yuan, Ping Luo, Wenyu Liu, andXinggang Wang. Bytetrack: Multi-object tracking by associating every detection box. In Proceedings ofthe European Conference on Computer Vision, 2022. Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng, and Wenyu Liu. Fairmot: On the fairness ofdetection and re-identification in multiple object tracking. International Journal of Computer Vision, 2021. Yuang Zhang, Tiancai Wang, and Xiangyu Zhang. Motrv2: Bootstrapping end-to-end multi-object trackingby pretrained object detectors. In Proceedings of the IEEE conference on Computer Vision and PatternRecognition, 2023. Zangwei Zheng, Mingyu Ma, Kai Wang, Ziheng Qin, Xiangyu Yue, and Yang You. Preventing zero-shottransfer degradation in continual learning of vision-language models. IEEE International Conference onComputer Vision, 2023.",
  ".(B)": "where W0 RCoutCinHW and b0 RCout represent the original convolution weights andbias, Cout is the number of convolution output channels, Cin is the number of convolution inputchannels, H and W are the height and width of the kernel, h is the output of the preceding layer,and denotes the convolution operation. Notice that, to simplify the notation, we assume to reshapem RCout111 and implicitly broadcast in accordance with the dimensions of W0 beforeapplying the Hadamard product .",
  "CDataset statistics": "Tab. A presents statistics on the employed datasets, detailing attributes at both per-sequence andper-frame levels. We manually annotated these attributes, developing a custom annotation tool thatdisplays the first frame of each sequence and allows for efficient annotation using keybindings. Thisprocess required minimal effort, involving one annotator for approximately three hours on MOTSynthand two hours on PersonPath22. As shown in Tab. A, the statistics indicate an imbalance in certainattributes; to address this, we implemented a custom training sampler to ensure that each modulereceives an equal number of backward iterations.",
  "DForgetting on source dataset": "Recently, there has been growing interest in Continual Learning for large pre-trained models, particu-larly in incrementally fine-tuning these models using parameter-efficient methods . A keychallenge in this process is avoiding the issue of catastrophic forgetting , where a model losesknowledge from earlier training as new tasks are introduced. To this end, we evaluated the extent offorgetting in the model when using task-specific modules versus training the entire model. Namely,we start from the PASTA and MOTRv2-MS trained on MOTSynth as in Tab. 1. Then, we furtherfine-tune such models on MOT17 and evaluate again on MOTSynth to measure the source-domainperformance after the adaptation. As shown in Tab. B, the modular approach trained on MOT17is less prone to forget its pre-training on MOTSynth, achieving superior results compared to fullfine-tuning when tested again on MOTSytnh test split. Specifically, our modular approach PASTA",
  "EAdditional ablation studies": "To further support our claim on leveraging all modules in a zero-shot scenario, we conduct anadditional ablation study on the test split of PersonPath22. As shown in Tab. C, this test confirmsthat retaining knowledge from modules not directly related to the specific scenario is beneficial whendealing with domain shifts. Specifically, our selection strategy outperforms the unweighted averageby empirically assigning a weight = 0.8 to the selected modules and = 0.2 to the others. Comparison with tracking-by-detection. To comprehensively evaluate our method, we hereintest ByteTrack and other tracking-by-detection methods in a zero-shot setting from MOT17 toPersonPath22. We report the results on PersonPath22 in Tab. D. Results indicate that PASTAleads to remarkable improvements compared to the other query-based end-to-end approach (i.e.,MOTRv2 ), even though they are both outperformed by the tracking-by-detection methods (suchas ByteTrack ). To be more comprehensive, PASTA remains competitive in terms of associationperformance (IDF1), but it yields weaker detection capabilities. Such a trend does not surprise us andis in line with what occurs in the more standard evaluation, where fine-tuning on the target dataset isallowed. Indeed, tracking-by-detection approaches are generally more robust than those based on",
  "end-to-end learning, so much so that it is an established practice to present the results in separateparts of a table , to deliver an apple-to-apple comparison": "In a zero-shot setting, we conclude that existing tracking-by-detection trackers are more robust todomain shifts. In these approaches, the only component potentially subject to shifts is the detector(e.g., YOLOX ). Instead, the motion model (e.g., Kalman Filter ) and the associationstrategy are almost parameter-free procedures that are less affected by domain shifts forconstruction, as their design reflects strong inductive biases about human motion. For such a reason, itis our belief that the problem of domain shift in Multiple Object Tracking (MOT) should be primarilyaddressed in parametric approaches such as deep neural networks. For this reason, our researchquestion focuses on query-based trackers (e.g., MOTRv2) that learn entirely from data. Our final goalis to enhance these trackers, as their end-to-end nature results can lead to challenges during domainshifts. ByteTrack thresholds. In Tab. 1, we evaluated ByteTrack on MOTSynth using the default input-parameters provided in the public ByteTrack repository, specifically a minimum confidence score(min_score) of 0.1 and a track threshold (track_thresh) of 0.6. In Tab. E, we present the resultsfor different values of these thresholds. The results are close, with a slight improvement whenreducing the track_thresh to 0.3 or 0.4, while min_score of 0.1 remains optimal.",
  "FOn computational costs": "Memory efficiency. We compare the GPU memory of full fine-tuning versus our approach on theMOTSynth dataset. Our method reduces training GPU memory requirements from 13GB to 8.25GB(for a batch size of 1), a reduction of over 35%. This significant decrease is due to the lower numberof parameters updated by the optimizer: 42M parameters for standard fine-tuning versus 15M for ourPEFT technique, as reported in Tab. 1. Inference speed. Additionally, our approach does not add any overhead during inference, asidefrom weight merging, which is negligible for stationary attributes, compared to MOTRv2, whichmaintains a speed of 6.9 FPS on a 2080Ti GPU. Storage efficiency.Using PEFT techniques significantly reduces storage needs. Without thesetechniques, each attribute would require a fully fine-tuned model, which poses several challenges,especially in memory constraints . Firstly, storing a separate model for each attribute ishighly storage-intensive. For instance, a PASTA module is approximately 5MB, whereas the fullmodel exceeds 350MB. With 12 attributes, the total storage requirement for PASTA would be 410MB",
  "PASTA (Ours)--53.057.662.056.250.4": "(350MB + 12 x 5MB). In contrast, storing 12 fully fine-tuned models would require around 4.2GB(12 x 350MB), representing a tenfold increase in storage needs. Additionally, adapting an entiremodel to each specific condition is more time-consuming than using LoRA, as it involves optimizinga more significant number of parameters. This adaptation process must be repeated for each attribute,making it both impractical and costly. Moreover, fully fine-tuning a transformer-based architecturedemands more data than a parameter-efficient approach.",
  "GLimitations": "One limitation of our approach is the reliance on an expert router, which requires manual dataannotation or intervention by an external domain expert. This process can be resource-intensive andmay not scale well for larger datasets or diverse scenarios. Future work may explore the developmentof automatic routing techniques, which could significantly improve scalability, performance, and easeof deployment in real-world applications by reducing the dependency on manual annotations.",
  "HSocietal impacts": "Positive Impacts.Enhanced security and surveillance is one of the key benefits of this work.Improved accuracy and robustness in tracking can lead to better crime prevention, more efficient lawenforcement, and increased public safety. Additionally, operational efficiency is another positiveimpact, where various sectors, including transportation, retail, and urban planning, can benefitfrom optimized operations and resource allocation. Moreover, customization and adaptability areenhanced by tailoring modules for specific scenarios, increasing versatility in applications rangingfrom healthcare to sports analytics. Negative Impacts. However, there are also potential negative impacts to consider. Privacy concernsarise from increased tracking capabilities, which may lead to unauthorized surveillance and privacyinfringement. Bias and fairness are also issues, as biased training data can perpetuate existing biases,leading to unfair treatment of certain groups."
}