{
  "Abstract": "Link prediction is a critical problem in graph learning with broad applications suchas recommender systems and knowledge graph completion. Numerous researchefforts have been directed at solving this problem, including approaches based onsimilarity metrics and Graph Neural Networks (GNN). However, most existingsolutions are still rooted in conventional supervised learning, which makes itchallenging to adapt over time to changing customer interests and to addressthe inherent dilemma of exploitation versus exploration in link prediction. Totackle these challenges, this paper reformulates link prediction as a sequentialdecision-making process, where each link prediction interaction occurs sequentially.We propose a novel fusion algorithm, PRB (PageRank Bandits), which is thefirst to combine contextual bandits with PageRank for collaborative exploitationand exploration. We also introduce a new reward formulation and provide atheoretical performance guarantee for PRB. Finally, we extensively evaluate PRBin both online and offline settings, comparing it with bandit-based and graph-basedmethods. The empirical success of PRB demonstrates the value of the proposedfusion approach. Our code is released at",
  "Introduction": "Link prediction is an essential problem in graph machine learning, focusing on predicting whether alink will exist between two nodes. Given the ubiquitous graph data in real-world applications, linkprediction has become a powerful tool in domains such as recommender systems and knowledgegraph completion . Considerable research efforts have been dedicated to solving this problem.One type of classic research approaches is heuristic-based methods, which infer the likelihood oflinks based on node similarity metrics . Graph Neural Networks (GNNs) have been widelyutilized for link prediction. For example, Graph Autoencoders leverage Message Passing NeuralNetwork (MPNN) representations to predict links . Recently, MPNNs have been combined withstructural features to better explore pairwise relations between target nodes . Existing supervised-learning-based methods for link prediction are designed for either the static or relatively dynamic environment , they (chrono-logically) split the dataset into training and testing sets. Due to the dynamic and evolving nature ofmany real-world graphs, ideal link prediction methods should adapt over time to consistently meetthe contexts and goals of the serving nodes. For instance, in short-video recommender systems, bothvideo content and user preferences change dynamically over time . Another significant challengeis the dilemma of exploitation and exploration in link prediction. The learner must not only exploitpast collected data to predict links with high likelihood but also explore lower-confidence targetnodes to acquire new knowledge for long-term benefits. For example, in social recommendations, it",
  "arXiv:2411.01410v1 [cs.LG] 3 Nov 2024": "is necessary to prioritize popular users by exploiting knowledge gained from previous interactions,while alsoexploring potential value from new or under-explored users to seek long-term benefits. Furthermore, while existing works often analyze time and space complexity, they generally lacktheoretical guarantees regarding the performance of link prediction. To address these challenges, inthis paper, we make the following contributions: Problem Formulation and Algorithm. We formulate the task of link prediction as sequentialdecision-making under the framework of contextual bandits, where each interaction of link predictionis regarded as one round of decision-making. We introduce a pseudo-regret metric to evaluate theperformance of this decision process. More specifically, we propose a fusion algorithm named PRB(PageRank Bandits), which combines the exploitation and exploration balance of contextual banditswith the graph structure utilization of PageRank . Compared to contextual bandit approaches,PRB leverages graph connectivity for an aggregated representation. In contrast to PageRank, itincorporates the principles of exploitation and exploration from contextual bandits to achieve acollaborative trade-off. Additionally, we extend PRB to node classification by introducing a noveltransformation from node classification to link prediction, thereby broadening the applicability ofPRB. Theoretical Analysis. We introduce a new formulation of the reward function to represent themapping from both node contexts and graph connectivity to the reward. We provide one theoreticalguarantee for the link prediction performance of the proposed algorithm, demonstrating that thecumulative regret induced by PRB can grow sub-linearly with respect to the number of rounds. Thisregret upper bound also provides insights into the relationship between the reward and dampingfactor, as well as the required realization complexity of the neural function class. Empirical Evaluation. We extensively evaluate PRB in two mainstream settings. (1) Online LinkPrediction. In this setting, each link prediction is made sequentially. In each round, given a servingnode, the model is required to choose one target node that has the highest likelihood of forming a linkwith the serving node. The model then observes feedback and performs corresponding optimizations.The goal is to minimize regret over T rounds (e.g., T = 10, 000). We compare PRB with state-of-the-art (SOTA) bandit-based approaches (e.g., ), which are designed for sequential decision-making. PRB significantly outperforms these bandit-based baselines, demonstrating the success offusing contextual bandits with PageRank for collaborative exploitation and exploration. (2) OfflineLink Prediction. In this setting, both training and testing data are provided, following the typicalsupervised learning process. Although PRB is designed for online learning, it can be directly appliedto offline learning on the training data. We then use the trained model to perform link prediction on thetesting data, comparing it with SOTA GNNs-based methods (e.g., ). The superior performanceof PRB indicates that principled exploitation and exploration can break the performance bottleneckin link prediction. Additionally, we conduct ablation and sensitivity studies for a comprehensiveevaluation of PRB.",
  "Related Work": "Contextual Bandits. The first line of works studies the linear reward assumption, typically calculatedusing ridge regression . Linear UCB-based bandit algorithms and linearThompson Sampling can achieve satisfactory performance and a near-optimal regret bound ofO( T). To learn general reward functions, deep neural networks have been adapted to bandits invarious ways . develop L-layer DNNs to learn arm embeddings and apply ThompsonSampling on the final layer for exploration. introduced the first provable neural-based contextualbandit algorithm with a UCB exploration strategy, and later extended to the TS framework. provides sharper regret upper bound for neural bandits with neural online regression. Theirregret analysis builds on recent advances in the convergence theory of over-parameterized neuralnetworks and uses the Neural Tangent Kernel to establish connections with linearcontextual bandits . retains the powerful representation ability of neural networks tolearn the reward function while using another neural network for exploration. integratesexploitation-exploration neural networks into the graph neural networks for fine-grained explorationand exploration. Recently, neural bandits have been adapted to solve other learning problems, such asactive learning, meta learning.",
  "Link Prediction Models. Three primary approaches have been identified for link prediction models.Node embedding methods, as described by previous work , focus on": "mapping each node to an embedding vector and leveraging these embeddings to predict connections.Another approach involves link prediction heuristics, as explored by , which utilizecrafted structural features and network topology to estimate the likelihood of connections betweennodes in a network. The third category employs GNNs for predicting link existence; notableis the Graph Autoencoder (GAE) , which learns low-dimensional representations of graph-structured data through an unsupervised learning process. GAE utilizes the inner product of MPNNrepresentations of target nodes to forecast links but might not capture pairwise relations betweennodes effectively. More sophisticated GNN models that combine MPNN with additional structuralfeatures, such as those by , have demonstrated superior performance by integrating bothnode and structural attributes. One such combined architecture is SF-then-MPNN, as adopted by. In this approach, the input graph is first enriched with structural features (SF) and thenprocessed by the MPNN to enhance its expressivity. However, since structural features change witheach target link, the MPNN must be re-run for each link, reducing scalability. For instance, the SEALmodel first enhances node features by incorporating the shortest path distances and extractingk-hop subgraphs, then applies MPNN across these subgraphs to generate more comprehensive linkrepresentations. Another combined architecture is SF-and-MPNN. Models like Neo-GNN andBUDDY apply MPNN to the entire graph and concatenate features such as common neighborcounts to enhance representational fidelity. In addition, has developed the Neural CommonNeighbor with Completion (NCNC) which utilizes the MPNN-then-SF architecture to achieve higherexpressivity and address the graph incompleteness. Recently, representation learning on temporal graphs for link prediction has also been widely studiedto exploit patterns in historical sequences, particularly with GNN-based methods . However, these approaches are still conventional supervised-learning-based methods thatchronologically split the dataset into training and testing sets. Specifically, these methods train aGNN-based model on the temporal training data and then employ the trained model to predict linksin the test data. In contrast, we formulate link predictions as sequential decision-making, where eachlink prediction is made sequentially. Node classification is also a prominent direction ingraph learning, but it is not the main focus of this paper.",
  "Problem Definition": "Let G0 = (V, E0) be an undirected graph at initialization, where V is the set of n nodes, |V | = n,and E0 V V represents the set of edges. E0 can be an empty set in the cold-start setting orinclude some existing edges with a warm start. Each node vi V is associated with a contextvector x0,i Rd . Then, we formulate link prediction as the problem of sequential decision-makingunder the framework of contextual bandits. Suppose the learner is required to finish a total of Tlink predictions. We adapt the above notation to all the evolving T graphs {Gt = (V, Et)}T 1t=0 andlet [T] = {1, . . . , T}. In a round of link prediction t [T], given Gt1 = (V, Et1), the learner ispresented with a serving node vt V and a set of k candidate nodes Vt = {vt,1, . . . , vt,k} V ,where Vt is associated with the corresponding k contexts Xt = {xt,1, . . . , xt,k} and |Vt| = k. Inthe scenario of social recommendation, vt can be considered as the user that the platform (learner)intends to recommend potential friends to, and the other candidate users will be represented by Vt. Vtcan be set as the remaining nodes Vt = Vt/vt or formed by some pre-selection algorithm Vt Vt. The goal of the learner is to predict which node in Vt will generate a link or edge with vt. Therefore,we can consider each node in Vt as an arm, and aim to select the arm with the maximal reward or thearm with the maximal probability of generating an edge with vt. For simplicity, we define the rewardof link prediction as the binary reward. Let vt,i Vt be the node selected by the learner. Then, thecorresponding reward is defined as rt,i = 1 if the link [vt, vt,i] is really generated; otherwise, rt,i = 0.After observing the reward rt,i, we update Et1 to obtain the new edge set Et, and thus new Gt. For any node vt,i Vt, denote by DY|xt,i the conditional distribution of the random reward rt,i withrespect to xt,i, where Y = {1, 0}. Then, inspired by the literature of contextual bandits, we definethe following pseudo regret:",
  "Proposed Algorithms": "Algorithm 1 describes the proposed algorithm PRB. It integrates contextual bandits and PageRank tocombine the power of balancing exploitation and exploration with graph connectivity. The first step isto balance the exploitation and exploration in terms of the reward mapping concerning node contexts,and the second step is to propagate the exploitation and exploration score via graph connectivity. To exploit the node contexts, we use a neural network to estimate rewards from the node contexts.Let f1(; 1) be a neural network to learn the mapping from the node context to the reward. Denotethe initialized parameter of f1 by 10. In round t, let 1t1 be parameter trained on the collected data ofprevious t1 rounds including all selected nodes and the received rewards. Given the serving node vt,for any candidate node vt,i Vt, f1(xt,i; 1t1), i Vt is the estimated reward by greedily exploitingthe observed contexts, which we refer to as exploitation. Supposei is the index of selected nodes. Toupdate 1t1, we can conduct stochastic gradient descent to update 1 based on the collected training",
  "Denote the updated parameters by 1t for the next round of link prediction": "In addition to exploiting the observed contexts, we employ another neural network to estimate thepotential gain of each candidate node in terms of reward for exploration. This idea is inspired by. Denote the exploration network by f2(; 2). f2 is to learn the mapping from node contexts andthe discriminative ability of f1 to the potential gain. In round t [T], given node context xt,i Vtand its estimated reward f1(xt,i; 1t1), the input of f2 is the gradient of f1(xt,i; 1t1) with respectto 1t1, denoted by (xt,i), and f2((xt,i); 2t1) is the estimated potential gain. After the learnerselects the node xt,i and observes the reward rt,i, the potential gain is defined as rt,i f1(xt,i; 1t1),which is used to train f2. Thus, after this interaction, we conduct the stochastic gradient descent toupdate 2 based on the collected sample ((xt,i), rt,i f1(xt,i; 1t1)) with the squared loss function",
  "L(xt,i), rt,i f1(xt,i; 1t1); 2t1= [f(t,i; 2t1) (rt,i f1(xt,i; 1t1))]2/2. Denote by 2t": ": Transforming Node Classification to Link Prediction. Consider a binary node classi-fication problem. In the left figure, given a graph, the learner tries to classify node 4 into one oftwo classes. First, we add two supernodes to the graph, each representing one of the classes. Thenode classification problem is then transformed into predicting links between node 4 and the twosupernodes in the right figure. Suppose the learner predicts that a link will exist between node 4 andsupernode 0. If node 4 belongs to Class 0, the reward is 1, and an edge is added between node 4 andsupernode 0; otherwise, the reward is 0, and an edge is added between node 4 and supernode 1. the updated parameters of f2 for the next round of link prediction. The reasons for setting (xt,i)as the input of f2 are as follows: (1) it incorporates the information of both xt,i and discriminativeability of f1(; 1t1); (2) the statistical form of the confidence interval for reward estimation can beregarded as the mapping function from (xt,i) to the potential gain, and f2 is to learn the unknownmapping . The previous steps demonstrate the exploitation and exploration of node contexts to facilitate decision-making in link prediction. Since graph connectivity is also crucial, we next introduce our method ofintegrating the bandit principle with PageRank to enable collaborative exploitation and exploration.PageRank calculates the stationary distribution of the random walker starting from some node,iteratively moving to a random neighbor with probability (damping factor) or returning to itsoriginal position with probability 1 . Let vt be the stationary distribution vector calculated basedon the graph Gt. Then, vt satisfies:",
  "i Vt, ht[i] = f1(xt,i; 1t1) + f2(xt,i; 2t1), and i V/Vt, ht[i] = 0.(4.2)": "Therefore, vt is the vector for the final decision-making based on collaborative exploitation andexploration. Some research efforts have been devoted to accelerating the calculation of Eq.4.1 inthe evolving graph, e.g., , which can be integrated into PRB (Line 9 in Algorithm 1) to boost itsefficiency and scalability. PRB for Node Classification. We also extend PRB to solve the problem of node classification as illus-trated in . Consider a k-class classification problem. We add k super nodes {v1, v2, . . . , vk}to the graph, which represents k classes, respectively. Then, we transform the node classificationproblem into the link prediction problem, aiming to predict the link between the serving node andthe k super nodes. To be specific, in round t [T], the learner is presented with the serving node vtand the k candidate (super) nodes Vt = {v1, v2, . . . , vk} associated with k corresponding contextsXt = {xt,1, xt,2, . . . , xt,k}. Recall xt is the context associated with vt. Then, we define the con-texts of super nodes as xt,1 = [xt , 0, . . . , 0], xt,2 = [0, xt , . . . , 0], . . . , xt,k = [0, 0, . . . , xt],xt,i Rkd, i [k]. This context definition is adopted from neural contextual bandits . Then,the learner is required to select one node from Vt. Let vit be the selected node and vit be ground-truthnode (it is the index of ground-truth class of node vt). Then, after observing the reward rt,it, oneedge [vt, vit] is added to the graph Gt1, if vt belongs to the class it, i.e., it = it and reward rt,it = 1.Otherwise, rt,it = 0 and the edge [vt, vit ] is added to Gt1. Then, we can naturally apply PRB tothis problem. We detail our extended algorithm for node classification in Algorithm 2. PRB Greedy. We also introduce a greedy version of PRB which integrates PageRank solely withcontextual bandit exploitation, as outlined in Algorithm 3. We will compare each variant of algorithmsin our experiment section.",
  "Regret Analysis": "In this section, we provide the theoretical analysis of PRB by bounding the regret defined in Eq.3.1.One important step is the definition of the reward function, as this problem is different from thestandard bandit setting that focuses on the arm (node) contexts and does not take into account thegraph connectivity. First, we define the following general function to represent the mapping from thenode contexts to the reward. Given the serving node vt and an arm node vt,i Vt associated with thecontext xt,i, the reward conditioned on vt and vt,i is assumed to be governed by the function:E[rt,i|vt, vt,i] = y (xt,i)(5.1)where y is an unknown but bounded function that can be either linear or non-linear. Next, we providethe formulation of the final reward function. In round t [T], let yt be the vector to representthe expected rewards of all candidate arms yt = [y (xt,i) : vt,i Vt]. Given the graph Gt1, itsnormalized adjacency matrix Pt, and the damping factor , inspired by PageRank, the optimizingproblem is defined as: vt = arg minv v(I Pt)v + (1 )v yt22/2. Then, its optimalsolution isvt = Ptvt + (1 ) yt.(5.2)For any candidate node vt,i Vt, we define its expected reward as Ert,iDY|xt,i [rt,i] = vt [i]. vtis a flexible reward function that reflects the mapping relation of both node contexts and graphconnectivity. is a hyper-parameter to trade-off between the leading role of graph connectivityand node contexts. When = 0, vt turns into the reward function in contextual bandits ;when = 1, vt is the optimal solution solely for graph connectivity. Here, we assume is a priorknowledge. Finally, the pseudo-regret is defined as",
  "The assumption 5.1 is generally made in the literature of neural bandits toensure the existence of a solution for NTK regression": "As the standard setting in contextual bandits, all node contexts are normalized to the unit length. Givenxt,i Rd with xt,i2 = 1, t [T], i [k], without loss of generality, we define a fully-connectednetwork with depth L 2 and width m:f(xt,i; ) = WL(WL1(WL2 . . . (W1xt,i)))(5.4) where is the ReLU activation function, W1 Rmd, Wl Rmm, for 2 l L 1,WL R1m, and = [vec(W1), vec(W2), . . . , vec(WL)] Rp. Note that our analysiscan also be readily generalized to other neural architectures such as CNNs and ResNet . Weemploy the following initialization for : For l [L 1], each entry of Wl is drawn from thenormal distribution N(0, 2/m); each entry of WL is drawn from the normal distribution N(0, 1/m).The network f1 and f2 follows the structure of f. Define y = [y(xt,i) : t [T], i [k]]. Finally, weprovide the performance guarantee as stated in the following Theorem. Theorem 5.1. Given the number of rounds T, for any , (0, 1), suppose m (poly(T, L) k log(1/)), 1 = 2 =T 3m and set rt,i = rt,i, t [T], i [k]. Then, with probability at least 1 over the initialization, Algorithm 1 achieves the following regret upper bound:",
  "Theorem 5.1 provides a regret upper bound for PRB with the complexity of O( d": "kT) (see proofsin Appendix E). Instead, the graph-based methods (e.g., ) lack an upper bound in terms oftheir performance. Theorem 5.1 provides insightful results in terms of PRBs performance. First,PRBs regret can grow sub-linearly with respective to T. Second, PRBs performance is affected bythe number of nodes k. This indicates the larger the graph is, the more difficult the link predictionproblem is. Third, d and S in the regret upper bound reflect the complexity of the required neuralfunction class to realize the underlying reward function vt , i.e., the difficulty of learning vt . d is theeffective dimension, which measures the actual underlying dimension in the RKHS space spanned byNTK. S is to provide an upper bound on the optimal parameters in the context of NTK regression.Both d and S are two complexity terms that commonly exist in the literature of neural contextualbandits. In the general case when 1 > > 0, learning vt proportionally turns into a banditoptimization problem and the upper bound provided in Theorem 5.1 matches the SOTA results inneural bandits . In fact, the regret upper bound is closely related to the graph structure ofGt. In the special case when = 1, learning vt turns into a simple convex optimization problem(Eq. (4.1)) and PRB can really find the optimal solution, which leads to zero regrets. When = 0,the problem turns into a complete bandit optimization problem with the same regret upper bound asTheorem 5.1.",
  "Experiments": "In this section, we begin by conducting a comprehensive evaluation of our proposed method, PRB,compared with both bandit-based and graph-based baselines across online and offline link predictionsettings. Then, we analyze the computational costs associated with each experiment and presentadditional ablation studies related to PRB. In the implementation of PRB, we adapt the efficientPageRank algorithm to solve Eq. (4.1).",
  "Datasets and Setups. We use three categories of real-world datasets to compare PRB with bandit-based baselines. The details and experiment settings are as follows": "(1) Recommendation datasets: Movielens and Amazon Fashion (Bipartite Graph). Giventhe user set U and item set I, let G0 be the graph with no edges, G0 = (V = U + I, E0 = ). Inround t [T], we randomly select a user vt U, and then randomly pick 100 items (arms) from I,including vts 10 purchased items, forming Vt. PRB runs based on Gt1 and selects an arm (node)vt,i Vt. If the selected arm vt,i is the purchased item by ut, the regret is 0 (or reward is 1) and weadd the edge [vt, vt,i] to Gt1, to form the new graph Gt; otherwise, the regret is 1 (or reward is 0)and Gt = Gt1. (2) Social network datasets: Facebook and GR-QC . Given the user set V , we haveG0 = (V, E0 = ). In a round t [T], we randomly select a source node vt that can be thought of asthe serving user. Then, we randomly choose 100 nodes, including vts 10 connected nodes but theiredges are removed, which form the arm pool Vt associated with the context set Xt. Then, PRB willselect one arm vt,i Vt. If vt and vt,i are connected in the original graph, the regret is 0 and add theedge [vt, vt,i] to Gt1; otherwise, the regret is 1 and Gt = Gt1. (3) Node classification datasets: Cora, Citeseer, and Pubmed from the Planetoid citation networks. Recall the problem setting described in Sec. 4. Consider a k-class node classification problem.Given a graph G(V, E0 = ), we randomly select a node vt V to predict its belonging class, in around t [T]. Then, PRB select one super node vit. If vt belongs to class it, the regret is 0 and add[vt, vit] to Gt1. Otherwise, the regret is 1 and Gt = Gt1. Baselines. For bandit-based methods, we apply Neural Greedy that leverages the greedyexploration strategy on the exploitation network, NeuralUCB that uses the exploitation networkto learn the reward function along with an UCB-based exploration strategy, NeuralTS thatadopts the exploitation network to learn the reward function along with the Thompson Samplingexploration strategy, and EE-net that utilizes the exploitation-exploration network to learn thereward function. Following , for all methods, we train each network every 50 rounds forthe first 2000 rounds and then every 100 rounds for the remaining rounds. See Appendix A.1 foradditional experimental setups. Online Link Prediction. We use to depict the regret trajectories over 10,000 rounds, and to detail the cumulative regret after 10,000 rounds for all methods, where the lower is better.Based on the regret comparison, PRB consistently outperforms all other baselines across all datasets.For example, the cumulative regret at 10,000 rounds for PRB on MovieLens is considerably lowerthan the best-performing baseline, EE-Net. Similarly, in the AmazonFashion dataset, PRB achievedthe lowest regret, surpassing the strongest baseline EE-Net over 14%. This trend is consistent acrossthe Facebook and GrQc datasets, where PRB maintains its lead with the lowest regrets respectively.The consistency in PRBs performance across various datasets suggests the importance of utilizingthe graph structure formed by previous link predictions.",
  ": Results on offline link prediction benchmarks. OOM means out of GPU memory": "bandit methods at round 10,000, respectively. Overall, PRB decreases regrets by 3.0%, 1.2%, and3.5% compared to one of the best baselines, NeuralTS. This experiment demonstrates that PRB isversatile enough for applications beyond online link prediction, extending to other real-world taskssuch as online node classification. This highlights PRBs advantage of fusing contextual bandits withPageRank for collaborative exploitation and exploration.",
  "Offline Link Prediction": "In this subsection, we evaluate PRB in the setting of offline link prediction compared with graph-basedbaselines, where training and testing datasets are provided, following the same evaluation process of. Here, we train PRB on the training dataset using the same sequential optimization methodSec. 6.1. Then, we run the trained PRB on the testing dataset. Notice that PRB never sees the testdata in the training process as other baselines. Datasets. In this study, we use real-world link-prediction datasets to compare PRB with graph-basedbaselines. Specifically, we apply Cora, Citeseer, and Pubmed from Planetoid citation networks ;ogbl-collab, ogbl-ppa, and ogbl-ddi from Open Graph Benchmark . (See dataset statistics inAppendix C.)",
  "Setting: We strictly follow the experimental setup in and use the Hits@k metric for evaluation.Please also refer to A.1 for additional setups": "Baselines. For graph-based methods, we choose traditional link-prediction heuristics includingCN , RA , AA and common GNNs including GCN and SAGE . Then, weemploy SF-then-MPNN models, including SEAL and NBFNet , as well as SF-and-MPNNmodels like Neo-GNN and BUDDY. Additionally, we also select the MPNN-then-SF modelNCN and NCNC . The results of the baselines are sourced from of . Comparison with Graph-based Baselines. We present the experimental results in forall methods. The results demonstrate that PRB consistently outperforms other baselines across allsix datasets. Specifically, compared to the most recent method, NCNC, PRB achieves a minimumimprovement of 0.68% on the Collab dataset, a maximum of 4.2%, and an average of 2.42% across",
  "Conclusion": "This paper introduces a fusion algorithm for link prediction, which integrates the power of contextualbandits in balancing exploitation and exploration with propagation on graph structure by PageRank.We further provide the theoretical performance analysis for PRB, showing the regret of the proposedalgorithm can grow sublinearly. We conduct extensive experiments in link prediction to evaluatePRBs effectiveness, compared with both bandit-based and graph-based baselines.",
  "Yikun Ban and Jingrui He. Local clustering in contextual multi-armed bandits. In Proceedingsof the Web Conference 2021, pages 23352346, 2021": "Yikun Ban, Jingrui He, and Curtiss B Cook. Multi-facet contextual bandits: A neural networkperspective. In The 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,Virtual Event, Singapore, August 14-18, 2021, pages 3545, 2021. Yikun Ban, Yunzhe Qi, Tianxin Wei, Lihui Liu, and Jingrui He. Meta clustering of neuralbandits. In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery andData Mining, pages 95106, 2024.",
  "Yuan Cao and Quanquan Gu. Generalization bounds of stochastic gradient descent for wide anddeep neural networks. Advances in Neural Information Processing Systems, 32:1083610846,2019": "Benjamin Paul Chamberlain, Sergey Shirobokov, Emanuele Rossi, Fabrizio Frasca, ThomasMarkovich, Nils Yannick Hammerla, Michael M Bronstein, and Max Hansmire. Graph neuralnetworks for link prediction with subgraph sketching. In The eleventh international conferenceon learning representations, 2022. Weilin Cong, Si Zhang, Jian Kang, Baichuan Yuan, Hao Wu, Xin Zhou, Hanghang Tong, andMehrdad Mahdavi. Do we really need complicated model architectures for temporal networks?arXiv preprint arXiv:2302.11636, 2023.",
  "Simon Du, Jason Lee, Haochuan Li, Liwei Wang, and Xiyu Zhai. Gradient descent finds globalminima of deep neural networks. In International Conference on Machine Learning, pages16751685. PMLR, 2019": "Dongqi Fu, Yikun Ban, Hanghang Tong, Ross Maciejewski, and Jingrui He. Disco: Compre-hensive and explainable disinformation detection. In Proceedings of the 31st ACM InternationalConference on Information & Knowledge Management, pages 48484852, 2022. Dongqi Fu, Liri Fang, Ross Maciejewski, Vetle I. Torvik, and Jingrui He. Meta-learnedmetrics over multi-evolution temporal graphs. In Aidong Zhang and Huzefa Rangwala, editors,KDD 22: The 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,Washington, DC, USA, August 14 - 18, 2022, pages 367377. ACM, 2022. Dongqi Fu and Jingrui He. SDG: A simplified and dynamic graph neural network. In FernandoDiaz, Chirag Shah, Torsten Suel, Pablo Castells, Rosie Jones, and Tetsuya Sakai, editors,SIGIR 21: The 44th International ACM SIGIR Conference on Research and Development inInformation Retrieval, Virtual Event, Canada, July 11-15, 2021, pages 22732277. ACM, 2021. Chongming Gao, Kexin Huang, Jiawei Chen, Yuan Zhang, Biao Li, Peng Jiang, Shiqi Wang,Zhong Zhang, and Xiangnan He. Alleviating matthew effect of offline reinforcement learningin interactive recommendation. arXiv preprint arXiv:2307.04571, 2023. Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neuralmessage passing for quantum chemistry. In International conference on machine learning,pages 12631272. PMLR, 2017. Aditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. InProceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery anddata mining, pages 855864, 2016.",
  "Jure Leskovec and Julian Mcauley. Learning to discover social circles in ego networks. Advancesin neural information processing systems, 25, 2012": "Lihong Li, Wei Chu, John Langford, and Robert E Schapire. A contextual-bandit approach topersonalized news article recommendation. In Proceedings of the 19th international conferenceon World wide web, pages 661670, 2010. Shuai Li, Alexandros Karatzoglou, and Claudio Gentile. Collaborative filtering bandits. InProceedings of the 39th International ACM SIGIR conference on Research and Development inInformation Retrieval, pages 539548, 2016. Zihao Li, Yuyi Ao, and Jingrui He. Sphere: Expressive and interpretable knowledge graphembedding for set retrieval. In Grace Hui Yang, Hongning Wang, Sam Han, Claudia Hauff,Guido Zuccon, and Yi Zhang, editors, Proceedings of the 47th International ACM SIGIRConference on Research and Development in Information Retrieval, SIGIR 2024, WashingtonDC, USA, July 14-18, 2024, pages 26292634. ACM, 2024.",
  "Carlos Riquelme, George Tucker, and Jasper Snoek. Deep bayesian bandits showdown: Anempirical comparison of bayesian deep networks for thompson sampling. arXiv preprintarXiv:1802.09127, 2018": "Emanuele Rossi, Ben Chamberlain, Fabrizio Frasca, Davide Eynard, Federico Monti, andMichael Bronstein. Temporal graph networks for deep learning on dynamic graphs. arXivpreprint arXiv:2006.10637, 2020. Yuan Sui, Jiaru Zou, Mengyu Zhou, Xinyi He, Lun Du, Shi Han, and Dongmei Zhang. Tap4llm:Table provider on sampling, augmenting, and packing semi-structured data for large languagemodel reasoning. arXiv preprint arXiv:2312.09039, 2023. Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. Line: Large-scale information network embedding. In Proceedings of the 24th international conference onworld wide web, pages 10671077, 2015.",
  "Tao Zhou, Linyuan L, and Yi-Cheng Zhang. Predicting missing links via local information.The European Physical Journal B, 71:623630, 2009": "Zhaocheng Zhu, Zuobai Zhang, Louis-Pascal Xhonneux, and Jian Tang. Neural bellman-fordnetworks: A general graph neural network framework for link prediction. Advances in NeuralInformation Processing Systems, 34:2947629490, 2021. Jiaru Zou, Mengyu Zhou, Tao Li, Shi Han, and Dongmei Zhang. Promptintern: Saving inferencecosts by internalizing recurrent prompt during large language model fine-tuning. arXiv preprintarXiv:2407.02211, 2024.",
  "A.1Experiment Setups": "Online Link Prediction Setups. For all bandit-based methods including PRB, for fair comparison,the exploitation network f1 is built by a 2-layer fully connected network with 100-width. For theexploration network of EE-Net and PRB, we use a 2-layer fully connected network with 100-width aswell. For NeuralUCB and NeuralTS, following the setting of , we use the exploitation networkf1 and conduct the grid search for the exploration parameter over {0.001, 0.01, 0.1, 1} and for theregularization parameter over {0.01, 0.1, 1}. For the neural bandits NeuralUCB/TS, following theirsetting, as they have expensive computation costs to store and compute the whole gradient matrix,we use a diagonal matrix to make an approximation. For all grid-searched parameters, we choosethe best of them for comparison and report the average results of 10 runs for all methods. For allbandit-based methods, we use SGD as the optimizer for the exploitation network f1. Additionally, forEE-Net and PRB, we use the Adam optimizer for the exploration network f2. For all neural networks,we conduct the grid search for learning rate over {0.01, 0.001, 0.0005, 0.0001}. For PRB, we strictlyfollow the settings in to implement the PageRank component. Specifically, we set the parameter = 0.85 after grid search over {0.1, 0.3, 0.5, 0.85, 0.9}, and the terminated accuracy = 106. Foreach dataset, we first shuffle the data and then run each network for 10,000 rounds (t = 10, 000). Wetrain each network every 50 rounds when t < 2000 and every 100 rounds when 2000 < t < 10, 000. Offline Link Prediction Setups. For the graph-based methods, we strictly follow the experimentaland hyperparameters settings in to reproduce the experimental results. Offline link predictiontask requires graph links to play dual roles as both supervision labels and message passing links.For all datasets, the message-passing links at training time are equal to the supervision links, whileat test and validation time, disjoint sets of links are held out for supervision that are never seenduring training. All hyperparameters are tuned using Weights and Biases random search, exploringthe search space of hidden dimensions from 64 to 512, dropout from 0 to 1, layers from 1 to 3,weight decay from 0 to 0.001, and learning rates from 0.0001 to 0.01. Hyperparameters yieldingthe highest validation accuracy are selected, and results are reported on a single-use test set. ForPRB, we use setups similar to those in the online setting. We utilize the exploitation network f1 andexploration network f2 both with 500-width. We set the training epoch to 100 and evaluate the modelperformance on validation and test datasets. We utilize the Adam optimizer for all baseline models.For PRB implementation, We utilize the SGD optimizer for f1 and the Adam optimizer for f2.",
  "We conduct all of our experiments on an Nvidia 3060 GPU with an x64-based processor": "Time and space complexity. Let n be the number of nodes, t be the index of the current round oflink prediction, k be the number of target candidate nodes, d be the number of context dimensions,and p be neural network width. For the online setting, let mt be the number of edges at round t. In thesetting of online link prediction, the time complexity of PRB is O(kdp + mtk), where the first termis the cost of calculating the exploitation-exploration score for each candidate node and the secondterm is the cost of running PageRank, following . And, the space complexity is O(n + mt) tostore node weights and edges. For the offline setting, let m be the number of edges in the testingdataset. Let F be the number target links to predict. Then, the inference time complexity of PRB forF links is O(ndp) + O(mF). The first term is the cost of calculating the exploitation-explorationscore for each node. The second term is the cost of PageRank . The comparison with existingmethods is listed in the following table: In , we analyze the running time of the internal components of PRB and PRB-Greedy(Algorithm 3). The comparison of the internal components reveals that the Random Walk phaseaccounts for 10% (PRB) and 6.3% (PRB-Greedy) on average of the total running time across sevendatasets. Previous results also demonstrate that PRB significantly outperforms EE-Net which solelyrelies on the Exploitation-Exploration framework, by dedicating a small additional portion of time tothe Random Walk component. By recording the total training time of 10,000 rounds, we also compare PRB with other bandit-basedbaselines in . Across all datasets, NeuralTS achieves the minimum average running time at10.9 minutes, while PRB has the maximum at 17.5 minutes. Additionally, given that the Random",
  ": Proportion of running time for PRB-Greedy (left) and PRB (right) between exploitation-exploration and random walk": "Walk component takes only a minimal portion of our algorithms running time, the average runningtimes are relatively close between PRB-Greedy (15.4 minutes) and Neural Greedy (14.8 minutes), andbetween PRB (17.5 minutes) and EE-net (16.7 minutes). The comparative analysis reveals that whilePRB incurs a relatively extended running time, it remains competitive with established baselines anddemonstrates a significant enhancement in performance. This observation underscores the efficacy ofPRB and supports its potential utility in practical applications despite its temporal demands. reports the inference time (one round in seconds) of bandit-based methods on three datasetsfor online link prediction. Although PRB takes a slightly longer time, it remains in the same order ofmagnitude as the other baselines. We adopt the approximated methods from for the PageRankcomponent to significantly reduce computation costs while ensuring good empirical performance. reports the inference time (one epoch of testing in seconds) of graph-based methods on threedatasets for offline link prediction. PRB is faster than SEAL and shows competitive inference time ascompared to other baselines.",
  "A.3Additional Ablation and Sensitivity Studies": "PRB variants. To extensively evaluate PRB in our experiments, we provide the following variants.PRB is the direct implementation of Algorithm 1. The initial graph G0 only contains all nodeswithout any edges. PRB-Greedy is the greedy version of Algorithm 1 by removing the explorationnetwork, as specified in Algorithm 3. PRB-Prior (10%-G) is Algorithm 1 with prior knowledge byrevealing 10% of training edges on the initial graph. We apply PRB-Prior in our experiments todemonstrate how extra prior knowledge about the graph improves PRBs decision-making process. and highlights the regret comparison of three PRB variants: PRB, PRB-Greedy,and PRB-Prior. For both online link prediction and node classification, PRB surpasses PRB-Greedyby an average of 5.8%, highlighting the robustness of the exploration network embedded withinPRB. Additionally, in online link prediction, the PRB-Prior (10%-G) variant consistently outperformsits counterparts across a majority of datasets. This is particularly evident in the MovieLens andAmazonFashion datasets, where it achieves notably low cumulative regrets of 1521 and 1408. Samein online node classification, PRB-Prior (10%-G) demonstrates exceptional performance on two outof three datasets, recording cumulative regrets of 1804 in Cora and 2158 in Citeseer. These resultsemphasize the benefits of incorporating prior knowledge within PRB to enhance predictive accuracy. Effectiveness of Bandits and PageRank. In , we compare the performance of PRB withthat of EvePPR and EE-Net , which represent methodologies based on PageRank andcontextual bandits respectively. On one hand, PRB significantly outperforms EvePPR by integratingthe exploitation and exploration strategy, which enhances PageRanks decision-making capabilities.On the other hand, PRB surpasses EE-net by leveraging a more comprehensive understanding ofthe input graphs structure and connectivity through enhanced PageRank. Overall, PRB consistentlyachieves lower regrets compared to both EvePPR and EE-Net, demonstrating the effectiveness ofcombining the exploitation-exploration with PageRank.",
  "BLimitations": "In this paper, we propose the PRB algorithm that integrates the exploitation-exploration of contextualbandits with PageRank. We do not investigate other integration methods, such as combining suchexploitation-exploration with other Random Walk algorithms or GNNs. We also evaluate PRB ononline link prediction and node classification. Several other real-world tasks, such as SubgraphMatching and Node Clustering, remain unexplored. Our future research will extend PRB to these andadditional related tasks to assess its broader implications.",
  "where = O(4/3L3log m))": "Lemma E.5 (User Trajectory Ball). Suppose m, 1, 2 satisfy the conditions in Theorem 5.1. Withprobability at least 1 O(TkL2) exp[(m2/3L)] over randomness of 0, for any R > 0, it holdsuniformly thatt 02 O(R/m1/4), t [T]. Lemma E.6 (Instance-dependent Loss Bound). Let Lt() = (f(xt; ) rt)2/2. Suppose m, 1, 2satisfy the conditions in Theorem 5.1. With probability at least 1 O(TkL2) exp[(m2/3L)]over randomness of 1, given any R > 0 it holds that",
  "The proof is completed": "Corollary E.1. Suppose m, 1, 2 satisfy the conditions in Theorem 5.1. For any t [T], let ibe the index selected by some fixed policy and rt,i is the corresponding reward, and denote thepolicy by . Let 1,t1, 2,t1 be the intermediate parameters trained by Algorithm 1 using the dataselect by . Then, with probability at least (1 ) over the random of the initialization, for any (0, 1), R > 0, it holds that"
}