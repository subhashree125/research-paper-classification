{
  "Abstract": "Online Budgeted Matching (OBM) is a classic problem with important applicationsin online advertising, online service matching, revenue management, and beyond.Traditional online algorithms typically assume a small bid setting, where themaximum bid-to-budget ratio () is infinitesimally small. While recent algorithmshave tried to address scenarios with non-small or general bids, they often relyon the Fractional Last Matching (FLM) assumption, which allows for acceptingpartial bids when the remaining budget is insufficient. This assumption, however,does not hold for many applications with indivisible bids. In this paper, weremove the FLM assumption and tackle the open problem of OBM with generalbids. We first establish an upper bound of 1 on the competitive ratio forany deterministic online algorithm. We then propose a novel meta algorithm,called MetaAd, which reduces to different algorithms with first known provablecompetitive ratios parameterized by the maximum bid-to-budget ratio . Asa by-product, we extend MetaAd to the FLM setting and get provable competitivealgorithms. Finally, we apply our competitive analysis to the design learning-augmented algorithms.",
  "Introduction": "Online Budgeted Matching (OBM) with general bids is a fundamental online optimization problemthat generalizes to many important settings, such as online bipartite matching and Adwords withequal bids . It has applications in various domains, including online advertising, online resourceallocation, and revenue management among others . OBM is defined on a bipartite graphwith a set of offline nodes (bidders) and a set of online nodes (queries). The task is to select anavailable offline node to match with an online query in each round. When an offline node is matchedto an online node, a bid value is subtracted from the budget of the offline node, and a reward equal tothe consumed budget is obtained. If the remaining budget of an offline node is less than the bid valueof an online query, the offline node cannot be matched to the online query. The goal is to maximizethe total reward throughout the entire online matching process. OBM is challenging due to the nature of online discrete decisions. Previous works have studied thisproblem under one of the following two additional assumptions on bids or matching rules: Small bids. The small-bid assumption is a special case of general bids corresponding to themaximum bid-budget ratio 0. That is, while the bid values can vary arbitrarily, the size ofeach individual bid is infinitely small compared to each offline nodes budget, and there is alwaysenough budget for matching. Under this assumption, the first online algorithm was provided by ,",
  "arXiv:2411.04204v2 [cs.GT] 14 Nov 2024": "achieving an optimal competitive ratio of 1 1/e . This competitive ratio has also been attainedby subsequent algorithms based on primal-dual techniques . However, the small-bid assumptionsignificantly limits these algorithms for broader applications in practice. Take the application ofmatching Virtual Machines (VMs) to physical servers as an example. An online VM request typicallytakes up a non-negligible fraction of the total computing units in a server. Fractional last match (FLM). Under FLM, if an offline node has an insufficient budget for an onlinequery, the offline node can still be matched to the query, obtaining a partial reward equal to theremaining budget. Given the limitations of small bids, some recent studies have studiedcompetitive algorithms for OBM with general bids by making the additional assumption of FLM.For example, under FLM, the greedy algorithm (Greedy) achieves a competitive ratio of 1/2, whileother studies aim to achieve a competitive ratio greater than 1/2 under various settingsand/or using randomized algorithms. Although FLM allows fractional matching of a query to anoffline node with insufficient budgets, it essentially assumes that any bids are potentially divisible.This assumption may not hold in many real applications, e.g., allocating fractional physical resourcesto a VM can result in significant performance issues that render the allocation unacceptable, andcharging a fractional advertising fee may not be allowed in online advertising. Despite its practical relevance and theoretical importance, OBM with general bids has remained achallenging open problem in the absence of the small-bid and FLM assumptions. Specifically, anoffline node may have insufficient budget and cannot be matched to a later query with a large value,potentially causing large sub-optimality in the worst case. This issue does not apply to small bids, asthe small-bid setting implies that insufficient budgets will never occur. Additionally, this challenge isalleviated in the FLM setting, where fractional matching in cases of insufficient budgets can reducesub-optimality. Indeed, removing the small-bid and FLM assumptions fundamentally changes andadd significant challenges to the problem of OBM . To further highlight the intrinsic difficultyof OBM with general bids, we formally prove in Proposition 4.1 an upper bound of the competitiveratio, i.e., 1 , achieved by any deterministic online algorithm, where is the maximumbid-budget ratio. Contributions: In this paper, we address OBM without the small-bid or FLM assumptions and designa meta algorithm called MetaAd, which adapts to different algorithms with provable competitiveratios. To our knowledge, MetaAd is the first provable competitive algorithm for general bids withoutthe FLM assumption. Specifically, MetaAd generates a discounted score for each offline node by ageneral discounting function, which is then used to select the offline node. The discounting functionevaluates the degree of budget insufficiency given a bid-budget ratio , addressing thechallenge of infeasible matching due to insufficient budgets. Given different discounting functions,MetaAd yields concrete algorithms, and their competitive ratios are derived from Theorem 4.2,established through a novel proof technique. We show that with small bids (i.e., 0), MetaAdrecovers the optimal competitive ratio of 1 1 e. Furthermore, we show that MetaAd, with discountingfunctions from the exponential and polynomial function classes, achieves a positive competitiveratio for [0, 1). As an extension, we adapt the design of MetaAd to the FLM setting, resultingin a meta-algorithm with provable competitive ratios for (Theorem 4.3). The frameworkof MetaAd potentially opens an interesting direction for exploring concrete discounting functiondesigns that yield high competitive ratios for settings both with and without FLM. Finally, we applyour competitive analysis to the design of LOBM, a learning-augmented algorithm for OBM, whichenhances average performance while still guaranteeing a competitive ratio (Theorem 5.1). We validatethe empirical benefits of MetaAd and LOBM through numerical experiments on the applications of anonline movie matching an VM placement on physical servers.",
  "Related Work": "OBM originates from the online bipartite matching problem defined by 30 years ago. In 2007, generalized the online b-matching problem to OBM (a.k.a. Adwords) . Under the specialcase of small bids, proposes an algorithm that achieves the competitive ratio of 1 1/e, whichis also the optimal competitive ratio under the small-bid setting . In the same year, providesthe primal-dual algorithm and analysis for OBM under the small-bid assumption and achieves thecompetitive ratio of 1 1",
  "e. Subsequently, gives a randomized primal-dual analysis for onlinebipartite matching and generalizes it to OBM. In addition, OBM has also been studied under thestochastic settings": "It is known to be very challenging to go beyond the small-bid assumption and develop a non-trivialcompetitive ratio for OBM with general bids in an adversarial setting. Recently, points outthe inherent difficulty of OBM with general bids and explains the necessity of the assumption ofFLM is needed in easing up the challenges. With the FLM assumption, a greedy algorithm canachieve a competitive ratio of 1/2. Additionally, a deterministic algorithm proposed in achievesa competitive ratio of (1 1 (1+)1/ ), increasing the competitive ratio when the maximumbid-budget ratio is no larger than 0.17. Some other works on OBM with FLM employ randomizedalgorithm designs. For example, proposes a semi-random algorithm that achieves a competitiveratio of 0.5016, which is known as the best competitive ratio achieved by randomized algorithms upto now. Besides, extends the random algorithm of Ranking to OBM and achieves a competitiveratio of 11/e with a strong assumption of the fake budget. Moreover, proposes a randomizedalgorithm without the knowledge of budget for the FLM setting with competitive ratio1",
  "e)parameterized by the maximum bid-budget ratios , which relies on a strong assumption that the bidsare decomposable (i.e. wu,t = wu wt)": "Despite the progress on the OBM settings with FLM, OBM without FLM has remained an openchallenge except for under the small-bid assumption. The recent study points out that OBMwithout FLM is difficult because when the offline node has less leftover budget than the bid valueof an online arrival, the offline node is not allowed to be matched to the arrival, potentially causinga loss equivalent the leftover budget. considers multi-tier budget constraints with a laminarstructure and provides a competitive ratio without FLM, but the result does not apply to the settingswithout the laminar structure. Additionally, proves an online randomized algorithm with thecompetitive ratio (in expectation) upper bound of 0.612, an upper bound for deterministic algorithmsis still lacking to formally evaluate the difficulty of OBM without FLM.",
  "Problem Formulation": "We consider OBM with general bids. Specifically, there is a bipartite graph described as G(U, V, E),where the vertices u U (i.e. offline nodes or bidders) are fixed and the vertices v V (i.e. onlinenodes or queries) arrive sequentially. The edge corresponding to vertices u U and v V has a bidvalue wu,v 0 which is the amount the offline node u would like to pay for the online node v ifmatched. The sizes of the vertex sets are denoted as |U| = U and |V| = V , respectively. We indexeach online node by its arriving order, i.e. online node t arrives at the t-th round. At the beginning, each offline node u U has an initial budget bu,0 = Bu 0, which is themaximum amount the offline node can pay in total. At round t, a query t V arrives, the edgesconnected to this arrival t are revealed, and the agent chooses to match the arrival to an availableoffline node from Ut = {u U | wu,t > 0, bu,t1 wu,t} or skip this query without any matching.We denote the agents action as xt Ut {null}, where null represents skipping this arrival. If atround t, an offline node xt is matched to the query t, a reward rt = wxt,t is earned and a bid valuewxt,t is charged from the offline node xt, i.e., bxt,t = bxt,t1 wxt,t; for the other offline nodesu = xt, the budget remains unchanged bu,t = bu,t1. If xt = null, no reward is earned, i.e. rt = 0and the budgets of all offline nodes remain the same as the last round, i.e. bu,t = bu,t1 u U.The cumulative consumed budget at the end of round t is denoted as cu,t = Bu bu,t, u U andt [V ]. The agent aims to maximize the total reward P = Vt=1 rt over the entire V rounds. The offline version of OBM can be written as Linear Programming (LP) with its primal and dualproblems given in (1), where P is the primal objective and D is the dual objective. While weonly need to solve the primal problem for OBM, we present the dual problem with dual variablesu, u U and t, t V to facilitate the subsequent algorithm design and analysis.",
  "= minGG{P(G)/P (G)},(2)": "where the minimization is taken over the set of all possible bipartite graphs G 1, P(G) = Vt=1 wxt,tis the total reward obtained by an (online) algorithm for a graph G G, and P (G) = Vt=1 wxt ,tis the corresponding offline optimal total reward with xt being the offline optimal solution to (1). Next, we formally define the bid-budget ratio in Definition 1 which is the maximum ratioof the bid value of an offline node to its total budget. We use () to denote the competitive ratio ofan algorithm for OBM with bid-budget ratio .",
  "Definition 1 (Bid-budget ratio). The bid-budget ratio for an example G(U, V, E) is definedas = supuU,tVwu,tBu": "Many previous works assume FLM which allows for accepting partial bids whenremaining budget is insufficient (i.e. modifying each bid wu,t to wu,t = min{wu,t, bu,t1} given theremaining budget bu,t1). Without the FLM assumption, the only known competitive ratio for OBMis for the small-bid setting where is infinitely small and approaches zero . However, thesmall-bid and FLM assumptions do not hold in many real-world applications as illustrated by thefollowing examples:Online VM placement. In this problem, a cloud manager allocates virtual machines (VMs, onlinenodes) to heterogeneous physical servers (offline nodes), each with a computing resource capacityof Bu . When a VM request with a computing load of zt arrives, the manager assigns it toa server. If the VM is placed on server u, the manager receives a utility of wu,v = ruzv due to theheterogeneity of servers. The goal is to maximize the total utility Vt=1 uU wu,txu,t subject tothe computing resource constraint Vt=1 ztxu,t Bu for each server u, which can also be written asVt=1 wu,txu,t Bu with Bu = ruBu. In this problem, VMs are not divisible and consume up anon-negligible portion of the server capacity, violating both the small-bid and FLM assumptions.Inventory management with indivisible goods. Here, a manager must match several indivisiblegoods (online nodes) to various resource nodes (offline nodes), each with a limited capacity (e.g.,matching parcels to mail trucks or food orders to delivery vehicles). Each good can only be assignedto one node without being split, and a good t can occupy a substantial portion of the resource nodescapacity, wu,t. The goal is to maximize the total utilization Vt=1uU wu,txu,t, subject to thecapacity constraint Vt=1 wu,txu,t 1 for each node u. In this problem, neither the small-bid norFLM assumption applies.",
  "An Upper Bound on the Competitive Ratio": "In the absence of small-bid and FLM assumptions, OBM faces a unique challenge: when an onlinequery with large bid arrives, there may be no offline node that both connects to the query and hassufficient remaining budgets for it. This leads to missed matches for the queries with large bids,ultimately resulting in a low competitive ratio. To formally show the inherent difficulty of OBMwithout the small-bid and FLM assumptions, we present an upper bound on the competitive ratio forany deterministic online algorithms in the following proposition.Proposition 4.1. For OBM without small-bid or FLM assumptions, the competitive ratio of anydeterministic online algorithm is upper bounded by 1 for (0, 1]. Specifically, the competitiveratio for any deterministic algorithm is zero when = 1 without the FLM assumption.",
  ": end for": "is no larger than max minGG CR(, G) where G G. Thus, we can prove the upper bound byconstructing a subset G with difficult instances and deriving the best competitive ratio among thedeterministic algorithms for this subset G. In our constructed G, each example has one offline nodeand the bid values for the first V 1 rounds sum up to 1 + with > 0 being infinitely small.We let G = G1 G2 where we have wu,V = Bu for examples in G1, and wu,V = 0 for examplesin G2. The instances in G illustrate the dilemma between matching a query for immediate rewardor saving the budget for future matches. If an algorithm chooses to match all the queries in the firstV 1 rounds, it can lose a bid of Bu for instances in G1 because there is no sufficient budget tomatch the final query. Conversely, if an algorithm chooses to skip some queries in the first V 1rounds to save the budget, it can lose a bid of Bu for the instances in G2 because matching the finalquery of instances in G2 earns zero bid. For these difficult instances in G, we formally derive thelargest reward ratio of a deterministic algorithm to the offline optimal one which is the upper boundof the competitive ratio. The upper bound of the competitive ratio 1 shows that OBM becomes more difficult when thebid-budget ratio gets larger. Intuitively, since the bid value is not fractional for each matching,given a larger , it is more likely for offline nodes to have insufficient budgets (i.e., unable tobe matched to a query with a large bid value). Skipping a query to save budget is also risky becauseit can happen that the following queries have no positive bid. The FLM assumption can alleviatethis difficulty because the remaining budget can be fully spent even if it is insufficient. A greedyalgorithm can achieve a competitive ratio of 1/2 for general bids with FLM . By contrast, theupper bound of the competitive ratio without FLM cannot reach 1/2 when the bid-budget ratio islarger than 1/2. There is even no non-zero competitive ratio when = 1. These observations revealthat without FLM, OBM becomes more difficult. The analysis without FLM assumption will help usto understand OBM better.",
  "We now present MetaAd in Algorithm 1, which is a meta online algorithm that reduces to manyconcrete algorithms with provable competitive ratios for OBM in the absence of small-bid and FLMassumptions": "MetaAd relies on a general discounting function : . Given a new query t, MetaAduses to score each offline node by discounting its bid value in Line 3, and selects the node with thelargest score su,t from Line 4 to Line 7. An offline node is scored zero if it has insufficient budget forthe query t (bu,t1 wu,t < 0) or it has zero bid for the query t (wu,t = 0). If all the offline nodesare scored zero, the algorithm skips this query t. The scoring in MetaAd reflects a balance between selecting an offline node with a large bid andsaving budget for future. To select offline nodes with large bids, the score scales with the bid valuewu,t. Simultaneously, an increasing function maps the normalized remaining budget bu,t1",
  "Competitive analysis": "Given any monotonically increasing function : in Algorithm 1, we can get a concretealgorithm for OBM. For different bid-budget ratio , the competitive ratio of MetaAd is given in themain theorem below.Theorem 4.2. If the function : in Algorithm 1 satisfies that given an integer n 1,i n, (i)(x) > 0 where (x) = 1 (1 x), the competitive ratio of Algorithm 1 is",
  "yni=1 i (i1)(y) (i1)(0)": "By Theorem 4.2, we can easily get a competitive algorithm for OBM with any bid-budget ratio by choosing a function . The only requirement is that the function is a monotonically increasingfunction. In the next section, we will give some concrete examples of competitive algorithms byassigning with different function classes. We defer the complete proof of Theorem 4.2 to Appendix A.2. The analysis is based on thefundamental conditions in Lemma 1 that guarantee the competitive ratio and presents new challengesdue to the absence of the small-bid and FLM assumptions.Lemma 1 (Conditions for competitive ratio). An online algorithm achieves a competitive ratioof if it selects a series of feasible actions {x1, . . . , xV } and there exist dual variables{1, , V }, {1, , U} such that",
  "uU Buu+Vt=1 t": "Without the small-bid and FLM assumptions, the competitive analysis presents the following newchallenges to satisfy the conditions in Lemma 1:Dual construction for general bids. When an offline node has an insufficient budget to match aquery, the remaining budget is almost zero for the small-bid setting, but it can be large and uncertainwithout the small-bid assumption. This introduces a new challenge to construct dual variables thatsatisfy the dual feasibility due to budget insufficiency. To address this challenge, we present a new dual construction in Algorithm 2 where dual variables aredetermined based on the remaining budget and adjusted at the end of the algorithm. The constructeddual variables satisfy the dual feasibility in Lemma 1, as explained below. We define t as the scoreof selected offline node u. For any u with sufficient remaining budget (bu,t1 wu,t), we havet su,t = wu,t(1 ( cu,t1",
  "Bu ), the dual feasibility in Lemma 1 issatisfied for t and u with sufficient budget (bu,t1 wu,t) since by an increasing function , it holdsthat u u,t for any t [T]": "Different from the small-bid setting, we need to adjust the dual variables at the end of the dualconstruction (Line 7 in Algorithm 2) to satisfy dual feasibility. We set u = 1 for any u withinsufficient budget (bu,t1 < wu,t) at the end of the dual construction. This ensures that the dualfeasibility is always satisfied without FLM. Guarantee the primal-dual ratio. The challenges in guaranteeing the primal-dual ratio inLemma 1 come from the unspecified discounting function and the absence of the small-bid andFLM assumptions. To solve this challenge, we derive a condition to satisfy the primal dual ratioPt 1",
  "Exponential Function Class": "Next, we consider an exponential function class (x) = C1ex + C2 with 0 1. To ensure(x) is an increasing function, we choose C1 0. Also, we choose C2 = C1 to simplify theexpression of the competitive ratio. We can observe that (x) has positive nth derivative for anyn 1. Thus, we choose n = in Theorem 4.2 to eliminate the term n+1R. By substituting (x)into () in Theorem 4.2, we get the corollary below.",
  "< 0(5)": "We numerically solve the optimal () for each by adjusting the parameters and C andshow the results in . We observe that MetaAd achieves a non-zero competitive ratio for [0, 1). The competitive ratio for = 0 is the optimal competitive ratio of 1 1 e for small-bidsetting. The competitive ratio monotonically decreases with . This coincides with the intuitionthat when gets larger, it is more likely to trigger budget insufficiency and the problem becomesmore challenging. Also, we can find that for a large enough , the competitive ratio of MetaAd withthe exponential function is very close to the upper bound. However, there can exist other forms ofexponential discounting function that can achieve higher competitive ratio. 0.00.20.40.60.81.0 Bid-budget ratio 0.0 0.2 0.4 0.6 0.8 CR (w/o FLM) MetaAd (Exp)MetaAd (Quad)Upper Bound",
  "Bu ) = 1 (1 bu,t1": "Bu ) be-comes smaller, indicating a more conservativeapproach to budget usage in preparation for po-tentially high future bids. However, as getslarger than , the optimal choice of the discount-ing function becomes (x) = 1 with C = 0,yielding a greedy algorithm. This suggests thatfor large enough , the algorithm benefits more by matching a node with a large bid immediatelythan by conserving more budget for future.",
  "Polynomial Function Class": "In this section, we explore another function class to show that MetaAd is general enough to providecompetitive algorithms given different discounting functions. We consider a function class of nthpolynomial function, i.e. (x) = nj=0 Cjxj. We set nj=1 Cj 1 to ensure (1) 1 and setC0 = 0 to simplify the competitive ratio. We summarize the competitive ratio of the polynomialfunction class and provide a concrete example for quadratic function in the next corollary.",
  ")1.(7)": "We numerically show the results of () in . We observe that MetaAd with a simple quadraticfunction (x) = x2 can also achieve non-zero competitive ratio for [0, 1). However, thiscompetitive ratio is lower than the best competitive ratio achieved by the exponential function(x) = C(ex 1). The examples of exponential functions and quadratic functions demonstrate the strength of MetaAdin providing competitive algorithms for OBM with general bids. While MetaAd provides the firstframework to get non-zero competitive ratio for OBM with [0, 1) (in the absence of the FLMassumption), it is interesting to explore other functions under the MetaAd framework with bettercompetitive ratios.",
  "While MetaAd is designed for the more challenging OBM without FLM, this section demonstratesthat MetaAd can be extended to provide competitive algorithms for OBM with FLM": "Due to the space limitation, we defer the algorithm of MetaAd with FLM (Algorithm 3) and itsanalysis to Appendix B. Instead of scoring based on the true bid wu,t, Algorithm 3 determinesthe scores based on a modified bid min{wu,t, bu,t1}. Based on the modified dual construction inAlgorithm 4, we can get the competitive ratio for OBM with FLM in the next theorem.",
  "The competitive ratio with FLM in Theorem4.3 differs from that in Theorem 4.2 only inthe final terms of the denominators, which are() and ()": "1 respectively. Thus, the compet-itive ratio with FLM is always larger than thatwithout FLM given the same values of and .This improvement arises because FLM allowsfor accepting partial bids when budgets are in-sufficient, thereby reducing the potential budgetwaste. Similar as MetaAd without FLM, we assign anexponential function class (x) = C(ex1) toget a concrete algorithm with competitive ratioin Corollary B.1.1. We numerically solve theoptimal () for each by adjusting and C and compare the results with an existing competitive algorithm BJN2007 for FLM in. As 0, both MetaAd and BJN2007 achieve the optimal competitive ratio 1 1/e in thesmall-bid setting. However, as approaches 1, the competitive ratio of BJN2007 decreases to zerowhile MetaAd, reducing to a greedy algorithm, maintains a competitive ratio of 1",
  "In this section, we demonstrate the application of our competitive analysis for designing learning-augmented algorithms which guarantee a competitive ratio of ML-based solutions for OBM": "Our competitive analysis directly motivates a learning-augmented algorithm for OBM called LOBM.The algorithm of LOBM and analysis are deferred to Appendix C. In LOBM, we apply a ML modelwhich at each round takes the features of the arriving query and the offline nodes as inputs and givesthe output zu,t. Directly using 1 zu,t as a discounting value to set the score as wu,t(1 zu,t) canresult in arbitrarily bad worst-case performance for adversarial examples. To provide a competitiveguarantee for OBM, LOBM projects the ML output zu,t into a competitive solution space Du,t in (28)and obtains a projected value zu,t. The score is then set as wu,t(1 zu,t) based on the projectedML output zu,t. The key design of the competitive solution space is motivated by the conditions inLemma 1, which ensures that any z value in Du,t leads to the satisfactions of the dual feasibilityand primal-dual ratio. The competitive solution space is based on the dual construction given thediscounting function (x) =ex1e1 where > 0 in Algorithm 2. Importantly, we introduce aslackness parameter in the design of Du,t in (28). The parameter controls the size of thecompetitive space Du,t and further regulates the competitive ratio of LOBM. Given a smaller , wecan get a larger competitive space Du,t, and so LOBM has more flexibility to exploit the benefits ofML predictions. However, a smaller also leads to a smaller competitive ratio shown in the theorembelow.",
  "Worst-case0.79410.84290.85240.79030.85380.83240.8113Average0.93290.93400.93440.93550.93720.93710.9343": ": Worst-case and and average normalized reward on the MovieLens dataset. The bestresults among algorithms w/o ML predictions and the best results among ML-based algorithms arehighlighted in bold font. revealed to the matching platform agent. The platform agent needs to match a movie to each query,generating a reward equivalent to the bid value and consuming a budget of the bid value from thetotal budget of the matched movie. The bid value is determined by the relevance of the movie andthe query. For example, if a movie is more relevant to the online query, there is a potentially highervalue. The goal of the advertising platform is to maximize the total reward while satisfying the budgetconstraints of each movie. In this application, the platform agent does not allow a fractional fee forany matching. Thus, this matching problem is a OBM without FLM. We run the online movie matching application based on a real dataset of MovieLens . TheMovieLens dataset provides data on the relevance of movies and users. We generate bipartite graphs,each with U = 10 offline nodes (movies) and V = 100 online nodes (queries/users) based on theMovieLens dataset. For each graph instance, we sample 10 movies uniformly without replacementand 100 users uniformly with replacement. A bid value scaled based on relevance is assigned to eachedge between the offline node and the online node. The total budget for each offline node is sampledfrom a normal distribution with a mean of 1 and a standard deviation of 0.1, and the maximum bidvalue is 0.1 (i.e., = 0.1). We generate 10k, 1k, and 1k samples of graph instances based on theMovieLens dataset for training, validation and testing, respectively. To test the ML performance without-of-distribution/adversarial examples, we also create examples by modifying 10% examples in thetesting dataset and randomly removing edges and/or rescaling the weights.",
  "Empirical Results": "We evaluate the empirical performance of MetaAd and LOBM on two applications. The first applicationis Online Movie Matching where the platform needs to match each query to a movie advertiser withlimited budget. The empirical results are obtained based on the MovieLens Dataset . The mainempirical results are shown in . We compare MetaAd with the algorithms without using ML(Greedy and PrimalDual introduced in Section D.1.1) and show that MetaAd achieves the best worst-case and average performance among them. Additionally, we validate that LOBM with a guarantee ofcompetitive ratio in Theorem 5.1 achieves the best worst-case reward with a good average reward.Other empirical ablation studies can be found in Section D.1.2. The second application is Online VM Placement introduced in . We generate the bipartitegraphs with connections between physical servers and VMs by the BarabsiAlbert method andassign utility values according to the prices of Amazon EC2 compute-optimized instances . Wedefer the empirical results and ablation studies to Appendix D.2.3.",
  "Conclusion": "In this paper, we consider a challenging setting for OBM without the FLM and small-bid assumption.First, we highlight the challenges by proving an upper bound on the competitive ratio for anydeterministic algorithms in OBM. Then, we design the first meta algorithm MetaAd that achievesa provable competitive ratios parameterized by the maximum bid-budget ratio . We alsoextend LOBM under the additional FLM assumption. Additionally, based on the competitive analysis,we propose LOBM to take advantage of ML predictions to improve the performance with a competitiveratio guarantee, followed by its empirical validations. Limitations and Future Directions. While we provide the first provable meta algorithms for OBMwith general bids, determining the best choice of the discounting function remains an open questionand an interesting problem for future exploration. Broader impacts. By introducing a provable algorithm for OBM under more general settings, ourwork has the potential to advance the applications and motivate new algorithms. For applications likeadvertising, if large budget disparities among offline nodes exist, those with larger initial budgetscould have a higher chance of being matched due to their smaller bid-to-budget ratios. This fairnessissue, also observed in prior algorithms , warrants further investigation.",
  "Nikhil Devanur and Aranyak Mehta. Online matching in advertisement auctions, 2022": "Nikhil R Devanur and Thomas P Hayes. The adwords problem: online keyword matching withbudgeted bidders under random permutations. In Proceedings of the 10th ACM conference onElectronic commerce, pages 7178, 2009. Nikhil R Devanur, Kamal Jain, and Robert D Kleinberg. Randomized primal-dual analysis ofranking for online bipartite matching. In Proceedings of the twenty-fourth annual ACM-SIAMsymposium on Discrete algorithms, pages 101107. SIAM, 2013.",
  "Bala Kalyanasundaram and Kirk R Pruhs. An optimal deterministic algorithm for onlineb-matching. Theoretical Computer Science, 233(1-2):319325, 2000": "Michael Kapralov, Ian Post, and Jan Vondrk. Online submodular welfare maximization:Greedy is optimal. In Proceedings of the twenty-fourth annual ACM-SIAM symposium onDiscrete algorithms, pages 12161225. SIAM, 2013. Richard M Karp, Umesh V Vazirani, and Vijay V Vazirani. An optimal algorithm for on-linebipartite matching. In Proceedings of the twenty-second annual ACM symposium on Theory ofcomputing, pages 352358, 1990.",
  "Aranyak Mehta, Amin Saberi, Umesh Vazirani, and Vijay Vazirani. Adwords and generalizedonline matching. Journal of the ACM (JACM), 54(5):22es, 2007": "Vahab S Mirrokni, Shayan Oveis Gharan, and Morteza Zadimoghaddam. Simultaneous ap-proximations for adversarial and stochastic online budgeted allocation. In Proceedings of thetwenty-third annual ACM-SIAM symposium on Discrete Algorithms, pages 16901701. SIAM,2012. Mayank Mishra and Anirudha Sahoo. On theory of vm placement: Anomalies in existingmethodologies and their mitigation using a novel vector based approach. In 2011 IEEE 4thInternational Conference on Cloud Computing, pages 275282. IEEE, 2011. Zhonghong Ou, Hao Zhuang, Jukka K Nurminen, Antti Yl-Jski, and Pan Hui. Exploitinghardware heterogeneity within the same instance type of amazon ec2. In 4th USENIX Workshopon Hot Topics in Cloud Computing (HotCloud 12), 2012.",
  "A.1Proof of Proposition 4.1": "Proof. Proposition 4.1 can be proved as follows. Denote CR(; G) as the competitive ratio of adeterministic algorithm on the graph instance G. The competitive ratio for any deterministicalgorithm is max minGG CR(, G) which is no larger than max minGG CR(, G) whereG G. Thus, we can prove the upper bound of the competitive ratio by constructing an examplesubset G and deriving the resulting competitive ratio for any deterministic algorithm. Specifically, anexample subset G is constructed as below. Example 1. Consider a setting with only one offline node and a total budget of 1. The agent needs todecide whether or not to match an online node with a bid value wu,t , (0, 1] to the offlinenode for V 2 rounds. The bid values for the first V 1 rounds are equivalent to and sum up to1 + where is infinitely small, so we have (0, (1 + )/ 1+ ]. The bid value wu,Vin the last round is either zero or and is not known to the agent. Thus, the constructed examplesubset is composed of two smaller subsets, i.e. G = G1 + G2. In the example of the subset G1, wehave wu,V = , and in the examples of the subset G2, we have wu,V = 0. The offline optimal solutions are different for G1 and G2 in Example 1. For G1 with the last bid valueas wu,V = , the optimal solution is to skip one of the first (V 1) rounds. In this way, the lastonline node with bid can be matched and the total reward is 1 + . For G2 with the last bidvalue as wu,V = 0, the optimal solution is to match all the online nodes for the first V 1 roundsand obtain a total reward of 1 + . For the examples in G in Example 1, the optimal online algorithm can be chosen from the followingtwo. First, the algorithm can choose to match the online node to the offline node in all the first(V 1) rounds. This algorithm is optimal for G2, but for G1 with wu,V = , the total reward is1 + which is less than the offline optimal reward 1 + . Therefore, the competitive ratioof this algorithm in the worst case is lim0 min(0,(1+)/ 1+ ]1+1+ 1 when isinfinitely small. Second, the algorithm can choose to skip one round in the first V 1 rounds such thatthe last online node can be matched if it has a bid value of in G1. However, for G2 with wu,V = 0and the total reward is 1 + which is less than the optimal reward as 1 + . Thus, thecompetitive ratio of this algorithm is lim0 min(0,(1+)/( 1+",
  "BMetaAd for OBM with FLM": "In this section, we extend MetaAd to the setting with FLM by allowing offline nodes with insufficientbudgets to accept fractional bid values equal to their remaining budgets in their last matching. Inother words, by matching an online arrival t to an offline node u U, the agent receives an actualreward of min{wu,t, bu,t1}, where wu,t is the bid value and bu,t1 is the available budget at thebeginning of round t.",
  "B.1Algorithm Design": "Even under the FLM assumption, OBM with general bids is challenging because when an online nodet arrives, if the remaining budget bu,t1 of an offline node u is smaller than the bid wu,t, matchingthe arrival to this offline node can cause a reward loss of wu,t bu,t1, which increases with the bidvalue wu,t. With FLM, the greedy algorithm (Greedy) can achieve a competitive ratio of 0.5 .The competitive ratio achieved by a deterministic algorithm in is (1 1",
  "(1+)1/ )": "For OBM with FLM, we use a different meta algorithm as in Algorithm 3. When the remainingbudget bu,t1 for an offline node u is enough to accept arrival t (i.e. bu,t1 wu,t), the scoringstrategy is the same as Algorithm 1 which sets the score as su,t = wu,t( bu,t1 Bu ). Nonetheless, thescoring strategy is different from Algorithm 1 when the remaining budget bu,t1 of an offline nodeu is insufficient for an online arrival t (i.e. bu,t1 < wu,t). Without FLM, Algorithm 1 directlysets the score su,t as zero to avoid the selection of offline node u. However, FLM allows matchingan offline node u to the online arrival t and consuming all the remaining budget bu,t1 to obtain areward of bu,t1. Thus, Algorithm 3 can be greedier and sets the score as su,t = bu,t1( bu,t1 Bu ) tobalance the actual reward increment and the budget consumption. Given an increasing function , thescore increases with the remaining budget, and it is still possible to select an offline node with aninsufficient but large enough remaining budget.",
  "B.2Competitive Analysis": "In this section, we provide the competitive ratio of Algorithm 3 for OBM with FLM and discussthe insights and analysis techniques. The competitive ratio is given in Theorem B.1 with its proofdeferred to Appendix B.3. To prove the competitive ratio of MetaAd for FLM, we still need to construct dual variables u, u U t, t [V ], which assists with online matching with a provable competitive ratio. The dualconstruction procedure is given in Algorithm 4. At each round t, same as the dual constructionwithout FLM in Algorithm 2, t is set as the score of the selected offline node and u,t is set as( cu,t",
  "Initialization: u U, u,0 = 0, bu,0 = Bu, U = , T = , and t [V ], t = 0.for t=1 to V , a new vertex t V arrives do": "If there exist u such that bu,t1 wu,t < 0, append {u | bu,t1 wu,t < 0} into U and appendt to T .Score su,t, select xt for the arrival t, and update budget bu,t by Algorithm 3.Set the dual variable t = sxt,t, and set the dual variable u,t = ( cu,t",
  "end forFor u / U, set u = u,V ; and for u U, set u as Eqn. (20)": "where t T is the round when budget insufficiency happens. This is to guarantee the dual feasibilityt bu,t1(1 u,t1) wu,t(1 u) when the offline node has an insufficient budget for anarrival. Note that the dual increment u = u u,V at the end of the Algorithm 4 can be less thanthe dual increment at the end of Algorithm 2, thus resulting in a better competitive ratio for OBMwith FLM than without FLM.",
  "C.1Algorithm Design": "A main technical challenge for OBM is to estimate the discounting value that discounts the bid valuesby a factor for the matching decision at round t. Thus, an ML model can be potentially leveraged toreplace the manual design of score assignment. More specifically, we can utilize an ML model to predict a discounting factor zu,t and set the score as su,t = wu,t(1 zu,t) for matching when theoffline node u has a sufficient budget for the online arrival t. That is, we incorporate ML predictionsinto MetaAd (i.e., LOBM) to explore alternative score assignment strategies that can outperform manualdesigns on average while still offering guaranteed competitiveness. In learning-augmented online algorithms , there exists an intrinsic trade-off between followingML predictions for average performance improvement and achieving better robustness in the worstcase. Such trade-off between average and worst-case performances also exist in learning-augmentedOBM ( LOBM). To better control the trade-off, we introduce a slackness parameter to relaxthe competitiveness requirement while allowing LOBM to improve the average performance throughML-based scoring within the competitive solution space. If we blindly use the ML prediction as the discounting factor for matching, competitive ratio cannotbe satisfied due to the lack of worst-case competitiveness for ML predictions. Thus, to ensure thatLOBM still offers guaranteed competitiveness, we consider a competitive solution space based on theconditions for dual variables specified in Lemma 1. Based on the competitive analysis with the exponential function class, we design a learning-augmentedalgorithm (i.e., LOBM) in Algorithm 5, which leverages ML prediction zu,t to improve the averageperformance while guaranteeing the worst-case competitive ratio. The key idea is to construct dualvariables as we solve the primal problem online and utilize the dual variables to calibrate the MLprediction zu,t. In this way, the matching decisions by LOBM are guaranteed to be competitive in theworst case while utilizing the potential benefits of ML predictions. We describe LOBM in Algorithm 5 as follows. At the beginning, we initialize the dual variables as zero.Whenever an online node arrives, the agent receives a ML prediction zu,t indicating the discountingfactors for all the offline nodes u U. Instead of directly using the ML prediction to set the scoresand selecting the offline node, LOBM projects the ML prediction zu,t into the competitive space Du,tby solving the following for all u U,",
  "zu,t = arg minzDu,t |z zu,t| ,(27)": "which is a key step to ensure the competitive ratio. In order to better utilize the potential benefit ofML predictions, we use the projection operation in (27) to select the discounting factor zu,t out ofcompetitive space Du,t, such that the selected zu,t is the closest to the ML prediction zu,t. Then,the projected value zu,t is used to set the scores su,t for offline nodes with sufficient budgets for theonline arrival t, and the scores for offline nodes with insufficient budgets are set as zero and theseoffline nodes are appended to U. The scores based on calibrated ML predictions are then used toselect the offline node for matching. As the key design to guarantee the competitive ratio, the competitive space Du,t is based on theconditions for dual variables in Lemma 1 and the dual construction by the exponential function class(Corollary 4.2.2). The dual variables are constructed as follows. For the selected note xt and itsscore sxt,t, we update the dual variable xt,t as xt,t1 + wxt,tzxt,t",
  "action xt is selected, the primal objective Pt = t=1 wx , increases by wxt,t and the dual objectiveDt = t=1 Bx x , + increases by Bxt(xt,t xt1,t1) + t = wxt,t": "+ Bxtxt,t. Whenan online arrival t is skipped without any matching, both primal and dual objectives remain the samewith no updates. Thus, we can always ensure that the primal objective and the dual objective satisfyDt =1 Pt + t=1 Bx ,x , for each t [T], leading to a bounded ratio of the primal objectiveto the dual objective at the end of each round. The parameter can be used to adjust the bound ofprimal-dual ratio, leading to different competitive ratios.",
  "su,t =1": "wu,t(1 zu,t) for any u U. Thus, as longas the first inequality in (28) is satisfied, we always have the dual feasibility t wu,t wu,tu,t1in Lemma 1 if all the offline nodes have sufficient budgets for the arrival t. For the offline nodes withinsufficient budgets for the online arrival t, we ensure the dual feasibility t wu,t wu,tu,t1by setting their corresponding dual variable u as one after the matching process (Line 14 inAlgorithm 5). The second inequality in (28) sets a target for the increment of the dual variables u,t, which forcesthe dual variable u,t to be larger when the remaining budget becomes less. In this way, the score ofan offline node u with fewer remaining budgets can be set lower to be conservative in consumingbudgets. Also, since u,t is larger when the remaining budget is less, the second inequality in (28)guarantees a large enough dual variable u,t when u has insufficient budget for an arrival t. Thiskeeps the additional dual increment after the matching process (Line 14 in Algorithm 5) bounded andfurther guarantees a bounded primal-dual ratio in the second condition of Lemma 1. As we discussed, if the discounting factor zu,t at each round satisfies the inequalities in (28), theprimal variables and the constructed dual variables will satisfy the conditions in Lemma 1, and so acompetitive ratio for OBM is guaranteed. The size of the set Du,t is controlled by the hyper-parameter: with smaller , the size of Du,t becomes larger because the inequalities are easier to be satisfied.We will rigorously prove that Du,t is always non-empty given any to enable feasiblecompetitive solutions that guarantee the competitive ratio bound in (29) in the robustness analysis ofLOBM in Section C.2. ML model training and inference. Given any ML predictions, Algorithm 5 provides a guarantee forthe competitive ratio. Nonetheless, the average performance EG[P(, G)] depends on the ML modelthat yields the ML prediction. Here, we briefly discuss how to achieve high average performance bytraining the ML model in an environment that is aware of the design of Algorithm 5. Note first thatthe projection operation is differentiable while the discrete matching decision is not differentiable.Thus, we apply policy gradient to train the ML model. Once the ML model is trained offline, it can beapplied online to provide zu,t as advice for scoring and matching by LOBM (Line 3 in Algorithm 5).",
  "where [x]+ = x if x > 0 and [x]+ = 0 if x 0": "Theorem C.1 shows that LOBM can guarantee a competitiveness ratio of () regardless of the MLprediction quality for any slackness parameter . The parameter determinesthe requirement for the worst-case competitive ratio and the flexibility to exploit the benefit of MLpredictions. When = 0, there is no competitiveness requirement, the inequalities in the competitivespace (28) always hold, and LOBM reduces to a pure ML-based algorithm with no competitive ratioguarantee. On the other hand, when = 1, LOBM achieves the highest competitive ratio. When is flexibly chosen between the competitive solution space also varies from whole solution space(with = 0) to the smallest competitive solution space (with = 1) in (28). Thus, LOBM achieves aflexible trade-off between the competitive guarantee and average performance by varying the levelsof trust in ML predictions.",
  "The solution of projection (28) always exists, i.e. the feasible set of (28) is not empty foreach round": "First, we prove the feasibility of dual variables (The first condition in Lemma 1). If t = 0 for around t [T], we have either wu,t = 0 or wu,t > 0 and u = u,V 1 holds for a slot u U byLine 14, so t = 0 wu,t(1 u) holds for the dual construction. On the other hand, if t > 0holds for round t [T], then the score sxt,t must be calculated based on the projected zxt,t. Thus,we have t =1",
  "eand the second inequality holds by the first inequality of the set (28). This proves thefeasibility of the dual variables": "Next, we prove the primal-dual ratio (the second condition in Lemma 1 ) is satisfied. At round t,if no vertex is selected for a vertex t, the primal objective P and dual objective D do not increase.Otherwise, the primal objective increases by wxt,t and dual objective increases by Bxt(xt,t xt1,t1) + t = wxt,t",
  "We compare our algorithms with the most common baselines for OBM as listed below": "OPT: The offline optimal solution is obtained using Gurobi for each graph instance. Greedy: The greedy algorithm matches an online node to the available offline nodethat is connected to the node and has the highest bid value. Greedy has a strong empiricalperformance and is a special case of MetaAd with . PrimalDual: PrimalDual calculates the scores of each bidder for each online nodebased on both the bid values and the remaining budgets, and then selects for an online nodethe available bidder with the highest score. It is a special case of MetaAd with 1. ML: A policy-gradient algorithm that solves the OBM problem . The inputs to the policymodel are the available history information including the current bid value, the remainingbudget of each offline node and the average matched bid value.",
  "We evaluate the performances of MetaAd with the discounting function (x) = ex1": "e1 and LOBM inAlgorithm 5. The illustration of MetaAd for round t is shown in (a). LOBM- is LOBM with theslackness parameter in the competitive solution space (28). The illustration of LOBM for round t isgiven in (b). The The optimal parameter governing the level of conservativeness in MetaAdis tuned based on the validation dataset. We also evaluate the performance of MetaAd under differentchoices of , and evaluate LOBM with ML predictions under different choices of the hyper-parameter and use LOBM- to represent LOBM with the hyper-parameter in Du,t in (28). For a faircomparison, we use the same neural architecture as ML in LOBM. The neural network has two layers,each with 200 hidden neurons. The neural networks are trained by Adam optimizer with a learningrate of 103 for 50 epochs. The training process on a laptop takes around 1 hour, while the inferenceprocess over each instance takes less than one second.",
  "D.1.2Results": "The empirical worst-case and average reward (normalized by the optimal reward) based on theMovieLens dataset are shown in . In this table, the parameter of MetaAd is 0.7 by defaultwhich is obtained by tuning on a validation dataset. We find that MetaAd can achieve a higher = 0.5= 0.7= 1= 4= 160.80 0.85 0.90 0.95",
  ": (a) Worst-case and average reward of MetaAd with different choices of . (b) Worst-casereward of LOBM with different choices of and . (c)Average reward of LOBM with different choicesof and": "worst-case reward ratio than alternative competitive algorithms without predictions (i.e., Greedyand PrimalDual). Through training, ML can achieve a higher average reward than competitivealgorithms without predictions. However, due to the existence of out-of-distribution testing examples,ML has a lower worst-case reward ratio than competitive algorithms that have theoretical worst-caseperformance guarantees. LOBM can significantly improve the worst-case performance of ML. Thisis because the projection of ML predictions onto the competitive solution space in 28 correctslow-quality ML predictions. Interestingly, LOBM with = 0.8 achieves the best empirical worst-case and average performance, demonstrating the superiority of LOBM despite that its competitiveratio is lower than that of MetaAd. The high average performance of LOBM shows that LOBM caneffectively utilize the benefits of good ML predictions to improve the average performance whileoffering guaranteed competitiveness. Importantly, when decreases, the requirements forthe worst-case performance are more relaxed, and hence LOBM achieves a higher average reward but alower worst-case reward.",
  "The effects of in MetaAd. To validate the effects of the hyper-parameter on the performance ofMetaAd with (x) = ex1": "e1 , we give more details of the performances of MetaAd under differentchoices of in (a). We give both the empirical worst-case and average reward of MetaAd withdifferent choices of . The results show that the average reward of MetaAd is not significantly affectedby the choice of , but has a large effect on the empirical worst-case reward. This is because controls the conservativeness of MetaAd and hence is crucial for the worst-case competitive ratiowhen = 0 as discussed in .2. More specifically, a larger worst-case reward can be obtainedwith a smaller for the MovieLens dataset. The reason is that a higher level of conservativeness isneeded when the maximum bid-budget ratio is not zero. The effects of and in LOBM. The empirical worst-case and average rewards of LOBMwith different choices of and are provided in (b) and (c), respectively.Different choices of yield different competitive solution spaces, while the choices of specify the relaxed robustness requirements of the worst-case competitive ratio for LOBM.Thus, we can get a different competitive ratio for LOBM by setting different and asshown in Theorem C.1.These theoretical findings are validated by our numerical results.",
  ": Reward (normalized by the of-fline optimal reward) at high percentiles(95% - 100%). is chosen as 1": "As we can see from (b) and Fig 4(c), when =0, the inequalities in the robust region (28) always hold,and hence LOBM reduces to pure ML and gives the samecompetitive ratio and average reward as ML. When = 1,LOBM guarantees the same competitive ratio as MetaAd,but does not necessarily always follow the solutions ofMetaAd for each problem instance, since there exist othersolutions that also satisfy the robustness requirement forcertain problem instances. Therefore, when = 1, thecompetitive ratio and average reward of LOBM are closeto but can be higher than those of MetaAd when the MLmodel used by LOBM is well trained. When lies between0 and 1, we can find that for some choices of , LOBMcan achieve an even better average reward than ML. Thisimprovement comes from the fact that the competitivesolution space in (28) can correct some low-quality ML predictions on certain problem instances.Also, for certain choices of , LOBM can empirically achieve a better worst-case reward than MetaAd, because LOBM can perform well due to ML predictions on some problem instances where MetaAddoes not perform well. This observation validates that LOBM can effectively utilize the ML predictionsto improve the average performance while guaranteeing a worst-case competitive ratio. Tail reward performance. Last but not least, to evaluate the performance on adversarial/out-of-distribution instances, we show in the reward (normalized by the offline optimal reward) athigh percentiles from 95% to 100%. We observe that the reward of ML quickly decreases when thepercentile becomes higher and becomes the lowest at the high percentiles (larger than 98%), showingthat ML is vulnerable to adversarial instances. Due to the worst-case competitiveness guarantees,MetaAd achieves a relatively higher reward even at high percentiles. Moreover, since LOBM guaranteesthe worst-case performance by the competitive solution space, the rewards of LOBM with different are all higher than ML at high percentiles. The high percentile reward of LOBM increases with because a larger choice of guarantees a higher competitive ratio according to Theorem C.1.Interestingly, we can find that the rewards of LOBM at high percentiles are even larger than MetaAdwhen is 0.6 or 0.8. This validates that when the ML model is well trained to provide high-qualitypredictions, LOBM can become more powerful and explore better matching decisions than the purelymanual design of MetaAd.",
  "D.2.1Problem setting": "Virtual Machine (VM) placement is the process of matching the newly-created VMs to the mostsuitable servers in cloud data centers . In this problem, once an end user send a VMrequest, the cloud operator needs to select a physical server for it. Different VM requests requiredifferent amount of physical computing resources. For example, the compute-optimized instances ofAmazon EC2 have different sizes, each requires different amount of computing resources. Due tothe hardware heterogeneity , the available computing resources on different servers are differentand the utilities of different servers can also be different. Our goal is to optimize the total utility ofVM placement. We consider a setup where the cloud manager allocates V VMs (online nodes) to U different physicalservers (offline nodes). Based on the requirement of VMs, a VM request can be matched to a subsetof the physical servers. The connections between VM requests and physical servers are representedby a bipartite graph G. A VM request t at round t, t V has a computing load in the number ofcomputing units denoted as zt. Each server u U has a limited capacity of the computing units (e.g.,virtual cores) denoted as Bu. If the VM request v is placed on a server u, the manager receives autility proportional to the computing load wu,t = ru zt where ru is the utility of one computing uniton server u. Denoting xu,t {0, 1} as the decision on whether to place request t on server u, theobjective of the VM placement problem can be formulated as an OBM:",
  "D.2.2Experiment setting": "In the experiment, the cloud manager allocates V = 100 VMs (online nodes) to U = 10 differentphysical servers (offline nodes). We randomly generate graphs by BarabsiAlbert method . Foran online node v, we sample its degree (the number of offline nodes connected to it) by a Binomialdistribution B(U, dv/U) where dv is the average degree of node v. The average degrees of onlinenodes are chosen from 4, 2, and 0.5. Each server has a capacity on the number of the computingunits. The capacity Bu is sampled from a uniform distribution on the range . The computingload of a VM request is sampled from a uniform distribution on the range . The utility percomputing unit ru is the price of a computing unit on the server u. We choose the price (in dollars) inthe range [0.08, 0.12] according to the prices of the compute-optimized instances on Amazon EC2",
  "Worst-case0.65280.79370.80270.80050.84320.82530.8277Average0.69500.83430.84490.96260.9340.96190.9610": ": Worst-case and average rewards of different algorithms for VM placement. The worst-case and averagerewards are normalized by optimal rewards. We compare MetaAd with the algorithms without using ML (Greedyand PrimalDual introduced in Section D.1.1). Additionally, we compare our learning-augmented algorithm LOBMwith the ML algorithm. LOBM- means LOBM with a slackness parameter in Eqn. (28).",
  "We compare our algorithms with baselines for OBM listed below. We compare our algorithms withthe most common baselines for OBM as listed below": "OPT: The offline optimal solution is obtained using Gurobi for each graph instance. Greedy: The greedy algorithm matches an online node to the available offline nodethat is connected to the node and has the highest bid value. Greedy has a strong empiricalperformance and is a special case of MetaAd with . PrimalDual: PrimalDual calculates the scores of each bidder for each online nodebased on both the bid values and the remaining budgets, and then selects for an online nodethe available bidder with the highest score. It is a special case of MetaAd with 1. ML: A policy-gradient algorithm that solves the OBM problem . The inputs to the policymodel are the available history information including the current bid value, the remainingbudget of each offline node and the average matched bid value. For learning-based algorithms, we use the neural networks which have two layers, each with 200hidden neurons for fair comparison. The neural networks are trained by Adam optimizer with alearning rate of 103 for 50 epochs. Likewise, we use LOBM- to refer to LOBM with a hyper-parameter governing the competitiveness requirement in (28).",
  "D.2.3Results": "We first show Worst-case and average rewards of different algorithms for VM placement in .We observe that MetaAd achieves a higher worst-case and average reward than the the other algorithmswithout using ML (i.e., Greedy and PrimalDual). This is because MetaAd is more flexible to adjustthe discounting function. Additionally, we can find that ML predictions can significantly improvethe average performance compared to algorithms without ML predictions. In particular, ML evenhas an empirically higher worst-case reward than Greedy and PrimalDual, although it does nothave a theoretical guarantee in terms of the worst-case competitive ratio. Note also that the worst-case reward ratio on the finite testing dataset is an empirical evaluation, and the true competitiveratio of ML without the theoretical guarantee can be even much lower than presented in the table.Importantly, we can find that LOBM can achieve a high average performance while guaranteeing aworst-case competitive ratio theoretically as shown in Theorem 5.1. Moreover, LOBM achieves thehighest empirical worst-case reward among all the algorithms, because LOBM can effectively correctlow-quality ML predictions for some difficult testing examples by learning augmented design andmeanwhile also leverage good ML predictions to improve the performance for other testing examples. Effects of and . Next, we give the ablation study of MetaAd and LOBM for different choices ofparameters and in . The parameter is the constant in the exponential discounting functionand the parameter is the slackness parameter in the competitive space in Eqn. (28). First, wegive the worst-case and average rewards of MetaAd under different choices of in (a). Wecan find that compared with PrimalDual (i.e., = 1), MetaAd can further improve the worst-caseperformance for the general bid settings by decreasing which is consistent with the competitiveanalysis in Corollary4.2.2. Moreover, we provide the worst-case and average rewards for LOBM under different and in(b) and (c), respectively. The results show that when = 0, LOBM reduces to pure MLand achieves the same worst-case and average performances as ML. The worst-case performance can = 0.6= 0.8= 1= 4 0.65 0.70 0.75 0.80 0.85",
  "(c) Average reward of LOBM": ": (a) Worst-case and average rewards of MetaAd with the exponential function class (a) Worst-casereward of LOBM. (b)Average reward of LOBM. The worst-case and average rewards are normalized by optimalrewards and are calculated empirically based on a testing dataset with 1000 samples. be improved by increasing since LOBM with a larger has a higher competitive ratio guaranteeaccording to Theorem C.1. However, the average performance can be affected when becomeslarger, because a larger results in a smaller solution space for increased robustness and hence mayexclude some solutions with high rewards for average cases. When = 1, LOBM shares the sametheoretical competitive ratio bound as MetaAd, but it can still achieve better empirical worst-case andaverage rewards than MetaAd when the ML model is well trained."
}