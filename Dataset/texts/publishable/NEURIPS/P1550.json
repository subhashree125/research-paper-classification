{
  "Abstract": "We investigate the use of sequence analysis for behavior modeling, emphasizingthat sequential context often outweighs the value of aggregate features in under-standing human behavior. We discuss framing common problems in fields likehealthcare, finance, and e-commerce as sequence modeling tasks, and addresschallenges related to constructing coherent sequences from fragmented data anddisentangling complex behavior patterns. We present a framework for sequencemodeling using Ensembles of Hidden Markov Models, which are lightweight,interpretable, and efficient. Our ensemble-based scoring method enables robustcomparison across sequences of different lengths and enhances performance inscenarios with imbalanced or scarce data. The framework scales in real-worldscenarios, is compatible with downstream feature-based modeling, and is appli-cable in both supervised and unsupervised learning settings. We demonstrate theeffectiveness of our method with results on a longitudinal human behavior dataset.",
  "Introduction": "Modeling human behavior is a complex task with applications spanning multiple domains such asuser research, healthcare, payments, trading, and e-commerce. Applications range from classifyinghuman activity (28), distinguishing humans from bots (16), detecting credit card fraud (25) etc. Behavior is often captured as sequences of actions or events over time, and understanding patternswithin these sequences is crucial for tasks like classification, anomaly detection, and user modeling.Disclaimer: This paper was prepared for informational purposes by the Artificial Intelligence Research groupof JPMorgan Chase & Co. and its affiliates (\"JP Morgan) and is not a product of the Research Department ofJP Morgan. JP Morgan makes no representation and warranty whatsoever and disclaims all liability, for thecompleteness, accuracy or reliability of the information contained herein. This document is not intended asinvestment research or investment advice, or a recommendation, offer or solicitation for the purchase or sale ofany security, financial instrument, financial product or service, or to be used in any way for evaluating the meritsof participating in any transaction, and shall not constitute a solicitation under any jurisdiction or to any person,if such solicitation under such jurisdiction or to such person would be unlawful.Preprint. NeurIPS 2024 Workshop on Behavioral Machine Learning.",
  "A key challenge in utilizing the captured sequences is class imbalance, where underrepresentedbehavior profiles or a disproportionate number of anomalous examples hinder model generalization": "Many solutions leverage complex deep learning models (33), focusing on event-level classificationwith extensive feature engineering (6). However, such event-level or feature-aggregated methodsfrequently fall short in capturing the sequential dynamics essential for understanding and modelingbehavior. These approaches are also susceptible to overfitting, with performance rapidly degrading inclass-imbalanced scenarios. Sequential context is crucial for effective behavior modeling. For example, in credit card fraud detec-tion or anti-money laundering, a users transaction history provides deeper insights into behavioralintent than isolated transactions or aggregated features. Yet, many datasets and approaches remainconfined to the event level, overlooking the broader sequential context. In this study, we advocate fora sequence modeling approach to behavior modeling, particularly in scenarios where behaviors arerepresented as action sequences derived from unstructured data. Aggregating this data into coherentsequences that reflect an agents decision-making process is a non-trivial challenge. Our method istested in a real-world setting characterized by extreme class imbalance, with millions of diverse userbehavior examples contrasted against only a few hundred instances of the anomalous class. We propose a novel and lightweight ensemble-based framework for behavior modeling, and showefficacy on downstream (imbalanced) sequence classification tasks. While our approach is model-agnostic, we leverage Hidden Markov Models (HMMs) for their simplicity, interpratibility, andefficacy at capturing temporal dependencies and latent patterns. Our real-world deployment scalesto millions of sequences, while being compatible with downstream machine learning methods. Wedemonstrate its effectiveness on a publicly available human behavior dataset (31). Our contributions: (1) We introduce a behavior modeling framework based on sequences ofevents/actions, applicable to various domains; (2) We outline its application to supervised andunsupervised tasks; (3) We demonstrate its effectiveness on a longitudinal human behavior dataset.",
  "Background & Related Work": "HMMsHidden Markov Models (HMMs) are statistical models for sequential data, which havea long history of use in natural language processing, finance, and bioinformatics (24; 5; 32; 22).HMMs have been used extensively for behavior modeling, including sensor surveillance (21), human-computer interfaces (11), and web user interactions (15), with recent applications in social media botdetection (19). While neural network-based approaches like CNNs, LSTMs, and Transformers haveshown success in settings like sentiment analysis (13) and network intrusion detection (27), they facechallenges such as high computational cost, overfitting, and reduced interpretability. ResolutionEvent-level classification still dominates in areas like anti-money laundering andnetwork security, where sequence-level labels are often missing (1; 8). This lends itself to aggregatefeature based approaches, missing key historical context. While some work has tackled sequencemodeling in network intrusion detection with favorable results (26), much remains to be done. Data Imbalance and Anomaly DetectionMany real-world problems, including intrusion detection(12), credit card fraud (25), and money laundering (2), involve detecting rare events and suffer fromclass imbalance. One-class anomaly detection focuses on robustly modeling the nominal classand identifying deviations (9), while more targeted approaches model both normal and anomaloussequences to detect specific behavioral anomalies (10).",
  "Approach": "Consider a sequence observation O = {a1, a2, ..., aT }, where each ai is drawn from a discrete set ofactions A. Such sequences can represent various behaviors, such as user interactions in an app, tradingactions in financial markets, or other human decision-making processes. Our goal is to model thesebehaviors, either discovering behavior clusters, or classifying behaviors when labels are available(e.g., online bot detection, credit card fraud detection, physical activity recognition (20; 33; 18).",
  "SequenceConstruction": ": Flow diagram of our sequence construction approach, as detailed in .1. Wedisentangle the monolithic dataset D into data streams, then process these further into sets ofobservation sequences. Our subsequent HMM-e ensemble training approach is detailed in .2. While we adopt this approach using HMMs, the framework itself is model agnostic. The trainingdata is broken into random subsets, and a diverse ensemble of learners is trained on these subsets.",
  "One of the primary challenges lies not in modelling but in organizing coherent data streams from raw,fragmented data D, which often contains interwoven behaviors from multiple agents/users": "For instance, in trading, D may span billions of transactions across participants, assets, and exchanges,requiring grouping data streams by participant, and further by exchange or asset to capture specificbehaviors. In network analysis, interactions between devices and servers can be grouped by source IPfor individual user activity, or further by target IP to constitute specific behavior streams. As illustrated in , we begin by disentangling D into separate data streams D1, ..., DH, eachcorresponding to one of H agents. Feature engineering refines these data streams through dimension-ality reduction, tokenization, or discretization, enhancing model generalization, particularly in thepresence of imbalanced or sparse datasets.Continuous features can also be normalized and estimateddirectly, through techniques like Gaussian HMMs (23). Once data is organized into streams Dh, sequences of observations O(1)h , ..., O(n[h])hare then extractedfrom each stream, with domain knowledge or sessions guiding the sequence span (start and end points).For example, web user behavior may span minutes to hours, whereas medical trial observationscould extend over days or weeks. Breaks in continuous data streams often demarcate sequences,with shorter pauses treated as wait events and longer breaks as sequence endpoints. The number ofsequences can vary significantly across agents, reflecting differing activity levels (e.g. power users vsintermittent monthly users).",
  "c(O) = 1{p(O | +) > p(O | )}(1)": "Variable Sequence LengthHMMs excel at sequence analysis (5), but struggle when comparingsequences of varying length, as length influences likelihood computation exponentially. We addressthis through model-driven normalization, computing likelihoods for a given sequence across multiplemodels, and deriving a rank-based composite score (rather than comparing sequence likelhihoods). HMM Ensembles HMMs, while lightweight and efficient, can struggle to capture the complexityof behaviors in training data when using a singular model (per class). Ensemble methods trainmultiple models on subsets of the data (7), enabling each learner to specialize on distinct patternsor behaviors, while collectively capturing the full data distribution. This results in a more robustapproach, particularly in scenarios with data imbalance, where monolithic models skew towardsmodeling the majority class (or underfitting for class specific models) (17). We propose HMM-e, anensemble framework that computes composite scores from individual learners (14). While HMMsare effective for our case, this framework is model-agnostic and can incorporate other model classessuch as neural networks, SVMs, or decision trees.",
  "Formalization and Algorithmic Framework": "First, we train N models {+1 , ..., +N} on the positive class and M models {1 , ..., M} on thenegative class, taking care to ensure diversity among the models by training each on a randomlyselected subset of samples from the training data. Each model sees s% of the training data in itsrelevant class. While we set N = M for all settings, these parameters (M, N, s) can be establishedusing typical hyperparameter optimization approaches. For any given sequence in the training data,the probability of not being selected for any models random subset is (1s)N. The expected numberof unsampled sequences is the same, so it is important to select s and N to keep this proportion ofthe training data small.",
  "j=11{p(O | +i ) > p(O | j )}(2)": "The score s(O) represents the pairwise comparisons where positive-class models assign a higherlikelihood than negative-class models, taking values in [0, N M]. A low score indicates that the se-quence is more likely under the negative-class models, and vice versa. As likelihoods across differentsequence lengths are not directly compared, this composite score acts as an implicit normalizationtechnique. N and M should be chosen such that the score range adequately distinguishes the classes. For our HMM and HMM-e approaches, we use 3 states in each of our models, and converge on anensemble size of 250 and a subset factor of 1%. We perform hyperparameter search for ensemblesize, trying other values in . We settle on 250 for its good performance at arelatively low complexity. Downstream Modeling using HMM-e ScoresGiven a corpus of sequences and correspondingscores {O, s(O)}, we classify sequences using a threshold sthresh: c(Oi) = 1{s(Oi) sthresh}.Alternatively, base learner likelihoods can serve as features for downstream classifiers. For eachsequence Oi, we define a feature vector",
  ": UMAP embeddings of featuresfi, as discussed in .2.1, from a500-model ensemble. Colors correspondto clusters discovered via K-Means": "Clustering HMM-e Scores in Unsupervised SettingsIn label-free settings, behavior clustering can be achievedusing unsupervised learning approaches. We train N mod-els {1, ..., N} on random s% data subsets and gener-ate feature vectors of base learner likelihoods fi (Sec-tion 3.2.1). Unsupervised clustering like K-Means canbe applied to discover behavioral groups, dimensionalityreduction (e.g., PCA) can be helpful when N is large.",
  "Data": "We evaluate our approach on the GLOBEM dataset (31),a longitudinal human behavior study featuring over 3,700attributes from 497 participants across four years (2018-2021). The dataset includes survey, smartphone, and wear-able data, with a focus on depression detection (the task weconsider). Data includes mood assessments, step counts,location variability, and sleep metrics. We utilize the datastandardization platform for reproducibility provided bythe authors (30).",
  ": Balanced Accuracy and AUC-ROC on GLOBEM. Our approach outperforms baselinemachine learning methods and achieves similar results to the best-performing deep learning approach": "While GLOBEM includes thousands of features, we select just four features to employ, each evaluateddaily: smartphone moving/static time ratio, total screen time (minutes), total sleep time (minutes),and total steps. We train Gaussian HMMs on these continuous features, depicted for three anonymousparticipants in 4. Our small feature set allows us to learn meaningful correlations and avoid convergingto degenerate or redundant models due to insufficient samples. Most deep-learning based modelsincluded in the benchmark leverage the 14-day history versions of the provided features, which sumover the prescribed time period. This helps reduce the frequency of missing values, but results in alagging time series. We use the raw feature for the current day, rather than the 14-day history, whichwe find boosts performance by 3% for our HMM-e approach. Sequences are constructed from a28-day history of normalized features, aggregated by participant and preprocessed using the provideddata platform. We filter out days where more than half of these features are missing, and within eachstudy participant, fill remaining missing values using median imputation. After filtering, we have5,393 training samples from 2018, 3,228 from 2019, 2,036 from 2020, and 1,192 from 2020, withclass ratios (not-depressed to depressed) of 1.13, 1.23, 1.29, and 1.14 respectively. EvaluationWe use the \"all-but-one\" validation scheme (30), training on three years and testing onthe fourth. Performance metrics include AUC-ROC and balanced accuracy (average of specificityand sensitivity), which we adopt as in (31) for its robustness to class imbalance (3). We compareour approach to the top-performing model from the GLOBEM study (31), Reorder, a CNN-baseddeep learning algorithm, along with a traditional SVM-based method (Canzian et al. (4)) from thebenchmark. We also compare against a Random Forest-based approach included in the benchmark,based on Wahle et al. (29). We train the Random Forest approach on our selected four features ratherthan the original papers six, using 450 trees, with the number of leaf nodes selected via K-Foldscross validation on a small training subset. Results & DiscussionOur approach using just four features outperforms machine learning ap-proaches like (4) which uses up to 17 features, and performs comparably to or outperforms many othermachine learning approaches included in the benchmark in (31). Our mean AUC-ROC and balancedaccuracy using singleton HMMs beat out (4) by 1.9 and 2 percentage points, respectively. UsingHMM-e , our AUC-ROC and balanced accuracy beat the same by 3.7 and 2.7 percentage points. Interms of balanced accuracy, HMM-e outperforms (29) 1.8 percentage points while achieving the sameAUC-ROC. We also achieve similar performance as the complex deep-learning approach Reorder,falling 2.7 percentage points short in AUC-ROC and 2.2 in balanced accuracy. Notably, we achievethis performance with traditional machine learning techniques, simpler models, and fewer features. For each of our N M base learners with num_states states, on num_features features, we learnnum_states + (num_states num_states) + (num_states num_features) parameters. Inour case, with 4 features and 3 states, this results in 6,000 total parameters versus Reorders 10,099parameters. On our hardware, detailed in C, HMM-e trains on 2019-2021 data in 5 minutes versus 18minutes for Reorder, 3 minutes for Wahle, and 29 seconds for Canzian.",
  "Conclusion": "We explore the connection between human behavior modeling and sequence analysis, providing ageneral framework for extracting coherent sequences from fragmented data. We present HMM-e,an ensemble learning approach that effectively models behavior sequences with minimal featureengineering. Our experiments demonstrate that HMM-e outperforms traditional machine learningbaselines and delivers results comparable to complex deep-learning models, despite using fewerfeatures. This highlights the efficiency and potential of our approach for scalable and interpretablesequence modeling in behavior-driven applications.",
  "Dietterich, T. G. 2000. Ensemble methods in machine learning. In International workshop onmultiple classifier systems, 115. Springer": "Divekar, A.; Parekh, M.; Savla, V.; Mishra, R.; and Shirole, M. 2018. Benchmarking datasetsfor Anomaly-based Network Intrusion Detection: KDD CUP 99 alternatives. In 2018 IEEE 3rdInternational Conference on Computing, Communication and Security (ICCCS). IEEE. Gerych, W.; Agu, E.; and Rundensteiner, E. 2019. Classifying Depression in ImbalancedDatasets Using an Autoencoder- Based Anomaly Detection Approach. In 2019 IEEE 13thInternational Conference on Semantic Computing (ICSC), 124127. Gong, Z.; and Chen, H. 2016. Model-Based Oversampling for Imbalanced Sequence Classi-fication. In Proceedings of the 25th ACM International on Conference on Information andKnowledge Management, CIKM 16, 10091018. New York, NY, USA: Association for Com-puting Machinery. ISBN 9781450340731. Hevizi, G.; Biczo, M.; Poczos, B.; Szabo, Z.; Takics, B.; and Lorincz, A. 2004. Hidden Markovmodel finds behavioral patterns of users working with a headmouse driven writing tool. In2004 IEEE International Joint Conference on Neural Networks (IEEE Cat. No.04CH37541),volume 1, 669674.",
  "Wahle, F.; Kowatsch, T.; Fleisch, E.; Rufer, M.; and Weidt, S. 2016. Mobile Sensing andSupport for People With Depression: A Pilot Trial in the Wild. JMIR Mhealth Uhealth, 4(3):e111": "Xu, X.; Liu, X.; Zhang, H.; Wang, W.; Nepal, S.; Sefidgar, Y.; Seo, W.; Kuehn, K. S.; Huckins,J. F.; Morris, M. E.; Nurius, P. S.; Riskin, E. A.; Patel, S.; Althoff, T.; Campbell, A.; Dey,A. K.; and Mankoff, J. 2023. GLOBEM: Cross-Dataset Generalization of Longitudinal HumanBehavior Modeling. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., 6(4). Xu, X.; Zhang, H.; Sefidgar, Y.; Ren, Y.; Liu, X.; Seo, W.; Brown, J.; Kuehn, K.; Merrill,M.; Nurius, P.; Patel, S.; Althoff, T.; Morris, M. E.; Riskin, E.; Mankoff, J.; and Dey, A. K.2023. GLOBEM Dataset: Multi-Year Datasets for Longitudinal Human Behavior ModelingGeneralization. arXiv:2211.02733.",
  ": Balanced Accuracy and AUC-ROC on GLOBEM data. For each year indicated, we train onthe other 3 years, and hold out that year for testing": "In addition to the aggregated results in , we present results for each of the four years in theGLOBEM dataset in . Each year indicated is the held-out test year, while the other three areused for training. We compare our approaches against the best-overall-performing approach in theGLOBEM study, Reorder (31). Reorder is a deep-learning based approach tailored for the GLOBEMproblem, built on a CNN backbone. We also present results from (4), an SVM-based traditional machine learning approach. We find thatwe are consistently able to outperform (4), and in terms of balanced accuracy, achieve comparableresults to Reorder with far fewer features and much less complex models.",
  "BFeature Selection": "shows the four features we choose to model, across three anonymized participants fromthe 2018 study. While many baseline models included in the benchmark choose to model tens oreven hundreds of features, we use a small feature set. This allows us to learn meaningful correlationsand avoid converging to degenerate models due to insufficient samples. We include two smartphonefeatures (screen time and location-based moving-to-static ratio) and two wearable features (sleeptime and steps). All of these features are computed daily.",
  "s(O)": ": Flow diagram of our HMM-e ensemble training and inference approach, as detailed in.2. While we adopt this approach using HMMs, the framework itself is model agnostic.The training data is broken into random subsets, and a diverse ensemble of learners is trained onthese subsets. At inference time, pairwise matchups of likelihoods given by the models are compared,giving the composite score s. : Samples of the daily features we model, across 3 anonymized 2018 participants. Forvisualization purposes, features are lightly smoothed using an exponential weighted moving averagewith a half-life of 4 days. For modeling, features are normalized.",
  "CHardware and Software Stack": "Our experiments are performed on an AWS r5.24xlarge EC2 instance featuring 96 virtual CPUsand 768 GB of memory. Due to the lightweight nature of the models trained, we do not have toleverage GPU acceleration. The environment is configured with Ubuntu 20.04 LTS as the operatingsystem, and we use Python version 3.8.10. Aside from standard machine-learning libraries likePandas, NumPy, Pytorch, Scikit-Learn, and Tensorflow, we also use HMMLearn to train our HMMs,and Ray to parallelize training and data processing."
}