{
  "Abstract": "Causal understanding is a fundamental goal of evidence-based medicine. Whenrandomization is impossible, causal inference methods allow the estimation oftreatment effects from retrospective analysis of observational data. However, suchanalyses rely on a number of assumptions, often including that of no unobservedconfounding. In many practical settings, this assumption is violated when impor-tant variables are not explicitly measured in the clinical record. Prior work has pro-posed to address unobserved confounding with machine learning by imputing un-observed variables and then correcting for the classiers mismeasurement. Whensuch a classier can be trained and the necessary assumptions are met, this methodcan recover an unbiased estimate of a causal effect. However, such work has beenlimited to synthetic data, simple classiers, and binary variables. This paper ex-tends this methodology by using a large language model trained on clinical notesto predict patients smoking status, which would otherwise be unobserved. Wethen apply a measurement error correction on the categorical predicted smokingstatus to estimate the causal effect of transthoracic echocardiography on mortalityin the MIMIC dataset.",
  "Introduction": "Evidence-based medicine seeks to use data from clinical research to inform best practices[Sackett et al., 1996, Masic et al., 2008].While randomized control trials (RCTs) are the goldstandard of clinical research, randomization is often impossible or unethical [Sanson-Fisher et al.,2007].In the absence of randomization, retrospective causal analyses must control for con-founding variables that could inuence both a patients treatment assignment and their outcome[VanderWeele and Shpitser, 2013]. For example, if a certain medication is only given to the patientswith the highest risk, a naive correlational analysis may suggest that the medication itself increasesthe risk of mortality. Causal inference methods establish causal claims by controlling for confound-ing and other sources of bias [Pearl, 2009]. All causal inference methods rely on assumptions about the underlying data-generating process; acommon but untestable assumption is the absence of unobserved confounding [Groenwold et al.,2009]. If a confounding variable is unobserved, it is in general impossible to estimate the desiredcausal effect without bias [Shpitser and Pearl, 2006]. Even with the wide availability of electronichealth record (EHR) data, it may be difcult to rule out the possibility of unobserved confounding[Groenwold et al., 2008]. Many causal methods attempt to detect and mitigate unobserved confound-ing [Flanders et al., 2011, Baiocchi et al., 2014, Uddin et al., 2016, Tchetgen et al., 2020].",
  "Preprint. Under review": "One such methodological approach considers the case where a necessary confounder is unobserved,but a proxy for that variable is instead observed. A canonical example is Medicaid enrollmentas a proxy for socioeconomic status (SES), because Medicaid eligibility is tied to household in-come [Simpson, 2020]. While a naive approach of treating SES and Medicaid enrollment as equiva-lent variables could introduce bias [Greenland and Robins, 1985, Ogburn and VanderWeele, 2012],methods developed by Pearl and Kuroki and Pearl can recover unbiased causal es-timates through a measurement error correction. When such a proxy (e.g., Medicaid enrollment)is unavailable, one option may be to train a machine learning (ML) classier to predict the valuesof the unobserved confounder and then apply this measurement error correction to account for theclassiers errors [Wood-Doughty et al., 2020]. This paper builds upon this line of work, extending prior methods from simple classiers and syn-thetic data to large language models (LLMs) and two real-world datasets. Following Feng et al., we analyze the causal effect of transthoracic echocardiography (TTE) on 28-day mortalityamong ICU patients diagnosed with sepsis. A limitation of prior work is its inability to account forpatient smoking status; this variable is not explicitly recorded in the EHR data, but tobacco use isconsidered a risk factor for mortality among patients with sepsis [Alroumi et al., 2018, Zhang et al.,2022]. Smoking status could also plausibly affect a clinicians decision to administer TTE, whichwould make it an unobserved confounder. We train and apply an ML classier to predict patientssmoking status and estimate the models error rate [Mulyar et al., 2019]. We extend the measure-ment error correction to categorical variables and use it to debias our causal estimates. Our methodproduces estimates with modest variance and our results provide evidence that TTE prevents mortal-ity, with or without accounting for patient smoking status. This primary contribution of this paper is a methodology for imputing unmeasured variables withlarge language models and then estimating unbiased causal effects with a measurement error correc-tion. We release our code to enable future research.1",
  "ML and LLMs for Clinical Prediction": "Machine learning (ML) methods have advanced over the past decade to provide impressive real-world performance in a wide variety of domains. For text data, large language models (LLMs) havebecome the dominant paradigm for text generation and classication tasks [Zhou et al., 2023]. Themost common approach for training LLMs uses generative pretraining followed by supervised task-specic ne-tuning [Radford et al., 2018]. In the clinical domain, LLMs have been applied to a widevariety of tasks, such as 30-day all-cause readmission prediction, in-hospital mortality prediction, co-morbidity index prediction, length of stay prediction, and insurance denial prediction [Jiang et al.,2023]. While such methods can demonstrate state-of-the-art performance on a variety of datasets,their applications to real-world clinical practice have been somewhat limited [Chen and Asch, 2017].Such models are complicated and often uninterpretable, which may prevent clinicians from trustingthe reasoning underlying their predictions [Tonekaboni et al., 2019]. Additionally, test set evalua-tions may not be fully indicative of real-world performance in the presence of domain shift andother sources of bias [Subbaswamy and Saria, 2020, Finlayson et al., 2021]. We focus on the specic task of predicting patient smoking status from clinical notes, using a la-beled dataset released by Uzuner et al. . Variations on this task have been a sustained focusof ML applications because of the relevance of tobacco use to a wide variety of health outcomes[Sohn and Savova, 2009, Palmer et al., 2019].",
  "Causal Inference": "Whereas practical applications of ML methods to the clinical domain are a relatively recent phe-nomenon [Jiang et al., 2023], many of the foundational methods in causal inference were developedto enable epidemiological studies [Pearl, 2009]. In this work, we use the potential outcomes frame-work that explores the causal effect of a treatment X on an outcome Y : specically, followingFeng et al. , the causal effect of TTE on 28-day mortality among patients with sepsis. We use",
  ": DAG with treatment X, outcome Y , and observed confounders C. U is the observed butnoisy proxy for the unobserved confounder U": "causal do-notation p(Y | do(x)) to denote the distribution of a patients hypothetical mortality hadthey be randomly assigned TTE value x [Pearl, 2012]. In an RCT, E[Y | X = x] is equivalent toE[Y | do(x)] because correlation between the randomly-assigned treatment and outcome implies (inprobability) a causal effect [Pearl, 2009]. Because in our dataset TTE was not randomly assigned,we need additional assumptions to identify the counterfactual distribution E[Y | do(x)] from theobserved data. We use directed acyclic graphs (DAGs) to represent our assumptions about the data [Pearl, 1995]. shows the causal DAG for our problem. In addition to our treatment X and outcome Y ,C represents our vector of observed confounders, including patient age, gender, and several clinicalmarkers. U is smoking status, which is hypothesized as a possible confounder but is unobserved inour data. U , introduced in 2.3, is our noisy proxy.",
  "Measurement Error": "If all confounders C and U were observed, then p(Y | do(x)) is identied as we show in Equation10 below and can be estimated in a number of ways [Glynn and Quinn, 2010]. If U is unobserved,however, then the causal effect of X on Y is unidentied and the problem becomes impossiblewithout additional assumptions [Shpitser and Pearl, 2006]. We assume access to U , a noisy proxywith the same cardinality as U that is governed by some noisy relationship p(U | U). If a matrixrepresentation of this probability p(U | U) can be inverted, then the work of Pearl andKuroki and Pearl show that we can recover p(Y | do(x)). This method is known as andalternatively referred to as matrix adjustment or effect restoration [Kuroki and Pearl, 2014]; wedemonstrate this derivation in 3.2. Throughout this paper, following 3.1, we assume that U ispredicted by an LLM classier and that p(U | U) is the error rate of the classication. Our methodassumes no additional unobserved confounding other than U. An alternative to matrix adjustment methods is simulation-extrapolation (SIMEX), a widely-usedmethod for measurement error [Cook and Stefanski, 1994]. SIMEX generally requires strong para-metric assumptions about the data [Sevilimedu and Yu, 2022], prior knowledge of the known mea-surement error variance [Cook and Stefanski, 1994], and the unknown confounder to be continuous[Lederer and Kchenhoff, 2006]. To overcome these limitations, Kchenhoff et al. proposedMC-SIMEX which avoids parametric assumptions but has weaker theoretical foundations. Whilewe focus on developing matrix correction methods and leave a comprehensive survey of SIMEXmethods for other work [Sevilimedu and Yu, 2022], we compare our proposed methodology againstMC-SIMEX in our experiments.",
  "Methodology": "We divide our methodological approach into two sections. First, we discuss the classier we useto predict smoking status for patients in the MIMIC dataset. We discuss the models training andvalidation procedure and its classication of our data. Then, we incorporate our models predictionsand our estimate of its error rate into the measurement error formulation to estimate causal effects.We discuss our extensions of past work to categorical mismeasured variables and high-dimensionalobserved confounders. shows the high-level overview of our entire methodology, includingthe pretrained LLMs and most important data sources.",
  "Smoking Status Classier": "Our modeling approach most closely follows that of Mulyar et al. . We start with a Clin-icalBERT LLM architecture using the weights that were released by Alsentzer et al. afterpretraining on PubMed abstracts, PMC articles, and all MIMIC-III notes [Alsentzer et al., 2019,Lee et al., 2019]. We then adapt this LLM by training an LSTM on top of its representation to pre-dict categorical smoking status in the 2006 n2c2 smoking dataset [Uzuner et al., 2008]. The trainingdataset contains 398 clinical notes and corresponding labels of the patient as either past smoker, cur-rent smoker, non-smoker, and unknown. These labels were manually annotated by pulmonologists.We follow the hyperparameter choices of Mulyar et al. and train for 1,000 epochs. After training, we evaluate our model on the test set of 101 additional patient records. Our modelachieves 86.1% accuracy with the confusion matrix shown in .2 This confusion matrix, afterdividing by the row sums to produce a stochastic matrix, provides the error-rate matrix p(U | U)that will be used in our measurement error correction in the following section. To apply this model to patients in the MIMIC dataset, we rst preprocess that data using the MIMIC-EXTRACT approach [Wang et al., 2020]. We then follow the preprocessing steps of Feng et al. to enable a direct comparison against their analysis. Our trained classier is then used topredict smoking status for the patients in the evaluation set of MIMIC patients who met the criteriafor sepsis [Angus et al., 2016]. Of those, 2,058 were classied as past smoker, 93 as current smoker,1,413 as non-smoker, and 1,171 as unknown. We discard 64 patients for whom the classier did notmake a prediction due to a condence threshold set by Mulyar et al. . Specically, the modelmakes no prediction if its nal tanh activation outputs a negative logit value for all four classes. 2As accuracy here is equivalent to micro-averaged F1, our model performs lower than the 92.8% accuracyreported by Mulyar et al. . We hypothesize this is simply due to random variation or changes in thePytorch libraries.",
  "Matrix Adjustment": "We can now incorporate our smoking status predictions into our estimate of the causal effect of TTEon 28-day mortality. portrays our assumptions about the underlying data distribution. Ourtreatment X is TTE, our outcome Y is 28-day mortality, and C is a vector of 39 observed covariates.3Patient smoking status U is our unobserved confounder, and U is our classiers prediction. Giventhis notation, we have data on the joint probability p(X, Y, C, U ) from patients in MIMIC. Weadditionally have the error rate P(U | U) from our classiers validation on the n2c2 dataset. Weassume that the classiers error rate remains constant between the two datasets; future work couldrelax this assumption by collecting additional ground-truth annotations on the MIMIC dataset. Wefurther make a non-differential error assumption, that:",
  "p(U | U, X, Y, C) = P(U | U)(3)": "Because our smoking status is a categorical variable with four values, our error rate distributionp(U | U) can be represented as a 4x4 matrix M(U , U) computed from the confusion matrix in by dividing each cell by its corresponding row sum. In general, using ui to denote U = iand uj to denote U = j, this can be written as:",
  "= M(U , U) p(Y, X, C, U)(6)": "Equation 4 holds by rules of probability, (5) holds by (3) above, and (6) is rewritten to formulate thissummation over probability distributions as a matrix multiplication. This follows the approach ofPearl ; for xed values of Y, X, C, p(Y, X, C, U) is a vector of four values. We then multiplythat vector by our 4x4 error matrix M(U , U) to get a different vector of four values.",
  "p(Y, X, C, U) = I(U , U) p(Y, X, C, U )(7)": "This inverse matrix I(U , U) allows us, given p(Y, X, C, U ) and M(U , U), to recoverp(Y, X, C, U).This derivation follows those presented in prior work by Pearl andKuroki and Pearl . To move from p(Y, X, C, U) to our counterfactual p(Y | do(x)), wecan follow a standard do-calculus derivation:",
  "C,Up(Y | X = x, C, U)p(C, U)(10)": "Equation 8 hold by marginalization and chain rule, (9) holds by Rule 2 of do-calculus, and (10)holds by Rule 3 of do-calculus [Pearl, 2012].4 However, the relative simplicity of the proof that thecounterfactual is identied obscures some of the practical challenges of estimating causal effects inour specic domain application. To implement estimators for the risk and odds ratios requires ttingmodels to these probability distributions. Unlike for example in Wood-Doughty et al. wherethere is a single binary observed confounder, we have 39 covariates. As Equation 10 is a function of p(Y | X, C, U) and p(C, U), we can rst use marginalizationand conditioning to derive these from p(Y, X, C, U) as provided to us by Equation 7. To actuallycompute Equation 7, we t three models: logistic regressions for p(Y | X, C, U ) and p(X | C), anda multinomial logit model p(U | X, C).5 All models are t using the predicted smoking statuses(i.e., using U , not on U); we perform the measurement error correction after tting models.",
  "Following our discussion in 2.3, we compare our proposed matrix adjustment method againstMC-SIMEX, another common method for handling measurement error. While the original SIMEX": "4For a gentle and thorough derivation of this, see that replacing p(Y | ) with a linear regression E[Y | ] would trivially extend this to applicationswith continuous outcomes where the risk difference is the estimand of choice. : Comparison of our methods causal estimates against those of the ve methods from Ta-ble 2 of Feng et al. . DR: Doubly Robust; PS: Propensity Score; IPW: Inverse PropensityWeighting. All results indicate a protective effect of TTE against mortality.",
  "DR Unbalanced0.78[0.68, 0.90]DR All0.64[0.52, 0.78]PS IPW0.84[0.78, 0.92]PS Matching0.78[0.66, 0.92]Multivariate0.64[0.53, 0.78]": ": Boostrapped 95% condence intervals for Risk Ratio and Odds Ratio estimates. The Nonerow shows the point estimate without bootstrapping. Each other row is computed across 100 totalresampled datasets, with bootstrapping applied to the MIMIC dataset used to t our models, then2c2 test set used to estimate M(U , U), or both datasets.",
  "None0.880.890.930.90MIMIC[0.85, 0.90][0.87, 0.90][0.89, 0.96][0.76, 0.95]n2c2[0.77, 0.99][0.77, 0.98][0.93, 0.94][0.90, 0.91]Both[0.65, 0.92][0.60, 0.98][0.85, 1.01][0.83, 1.00]": "method was designed for continuous unobserved variables, MC-SIMEX allows for categorical vari-ables [Lederer and Kchenhoff, 2006]. We use the R package released by the authors.6 As indicatedin , SIMEX also requires access to both the noisy imputed U values and our estimate ofthe error rate p(U | U). Despite the similarities of these methods, our matrix adjustment approachhas the benet of more established theoretical foundations, and makes no assumptions about theparametric form of the estimator. It can also be easily applied to more complicated counterfactualestimands where the identifying functional of the observed data is not simply a linear model of thetreatment and covariates, e.g., a front-door or proximal estimator [Bellemare et al., 2020, Cui et al.,2023].",
  "Results": "Our experimental analysis follows in applying both matrix adjustment and MC-SIMEX tothe MIMIC-III dataset as preprocessed and analyzed by Feng et al. . We use our trained LLMclassier to impute patients smoking status, t our models for p(Y | X, U , C), p(U | X, C), andp(X | C), and then incorporate those models and our estimated error rates p(U | U) to produceour causal estimates. Our full experimental code is provided as an appendix. shows a direct comparison of our odds ratio estimates against the ve separate estimationmethods presented by Feng et al. . These numbers being less than 1 indicates our treatment re-duces the probability of the outcome that is, TTE prevents mortality among the patient population.Our results match those of past work, but produce more conservative estimates of the causal effect.This comparison cannot prove or refute the presence of unobserved confounding via smoking sta-tus; it merely shows that when taking smoking status into account, we produce a more conservativeestimate of the protective effect of TTE. If our assumptions from 2 and 3 are valid, our methods should produce unbiased estimates of thecausal effects. However, with any nite sample data sample, we must worry about the variance ofour methodology. Feng et al. also provide (Wald-type) condence intervals for their analyses.To produce the condence intervals for our methods shown in , we use the non-parametric : Comparison of risk ratios overall and within smoker subgroups. The left column shows ourpoint estimates; the other columns show condence intervals from bootstrapping either the MIMICevaluation set or the n2c2 test set.",
  "Overall0.88[0.85, 0.90][0.77, 0.99]0.93[0.86, 1.05][0.93, 0.94]": "Past Smoker0.86[0.76, 0.93][0.32, 1.37]0.93[0.89, 0.96][0.93, 0.93]Current Smoker0.92[0.92, 0.92][0.92, 0.92]0.97[0.91, 0.97][0.98, 0.98]Non-Smoker1.13[0.65, 1.60][0.06, 2.39]0.91[0.84, 0.95][0.91, 0.91]Unknown0.88[0.70, 1.00][0.54, 1.16]0.94[0.91, 0.97][0.94, 0.94] bootstrap [DiCiccio and Efron, 1996]. Bootstrapping our entire analysis from LLM pretraining toeffect estimation is unfortunately prohibitively expensive; we instead use two bootstrap approachesthat can give us a full picture of our methods uncertainty. First, we consider resampling our evaluation subset of MIMIC-III to produce 100 new datasetsof 4,735 patients, with each patient in each new dataset chosen independently with replacementfrom the original dataset. For each of these datasets, we t new models for p(Y | X, U , C),p(U | X, C), and p(X | C). For each of these analysis, we hold xed the estimate for M(U , U)computed with the n2c2 test dataset. The 95% condence interval from this bootstrap alone is shownin the MIMIC row of . Our second, orthogonal bootstrapping method follows Wood-Doughty et al. . Rather thanresampling our analysis dataset of MIMIC patients, we resample the test set of 101 patients in then2c2 data. For each of 100 such resamplings, we recalculate our error matrix M(U , U), invert itto produce I(U , U), and then use that in Equation 11 and (13) to compute our causal effects. Eachrecalculated M(U , U) is used alongside the original MIMIC dataset of 4,735 patients. The 95%condence intervals from these 100 resamplings is shown in the n2c2 row of . The Both row of the table shows a combination of both bootstrap methods. We resample 10new M(U , U) matrices and 10 new MIMIC datasets on which we t our models. Then, for all10 10 = 100 comparisons, we compute our nal estimates of the risk and odds ratios. This givesus 100 resamplings, matching the MIMIC-only and n2c2-only bootstrap intervals. The condenceintervals we showed previously in use this combined bootstrap method, as it has the widestinterval of the three. allows us to highlight and compare two sources of uncertainty in our method. For the matrixadjustment method, it is unsurprising that the n2c2 bootstrap introduces more uncertainty into ournal estimates, as the test set contains only 101 patients. The matrix inverse we compute in Equation7 and use in (11) and (12) implicitly requires us to divide by values in our estimated M(U , U)matrix. As with inverse propensity weighting, this can introduce high variance when dividing bysmall numbers [Ma and Wang, 2020]. We could reduce some of this uncertainty by using a largerdataset to validate the smoking status classier. Interestingly, our MC-SIMEX estimates have muchless variance when bootstrapping the n2c2 test set. This may be related to the lack of theoreticalfoundation to explain valid estimates for standard errors in simulations [Lederer and Kchenhoff,2006]. None of our current methods are able to quantify the uncertainty introduced from the BERTpretraining or classier ne-tuning. While there are some methods that can capture uncertaintyin neural networks (e.g., Gal and Ghahramani ), we leave further sensitivity analyses anduncertainty quantication for future work. shows our risk ratio broken down across our four subgroups of smoking statuses. Whilethe risk and odds ratios are closely related, the former is collapsible, so the risk ratio of the entirepopulation is the weighted average of the risk ratios within each subgroup [Hernan and Robins,2020]. This allows us to easily ask whether TTE is more or less effective among patients withdifferent smoking statuses.7 For the matrix adjustment method, for all categories except current 7In 3.1 we discarded 64 patients for whom the classier made no prediction. If we instead label thosepatients as Unknown, then using Matrix Adjustment and no bootstrapping, the overall risk ratio is 0.90, theodds ratio is 0.82, and the subgroup risk ratios are [0.91, 0.92, 1.15, 0.97]. smokers, the condence intervals in this subgroup analysis widen and several intervals contain 1.0,suggesting we lack the requisite data for such focused analyses. For non-smokers the point estimateof our risk ratio is above 1.0, which indicates that TTE is in fact harmful; while this could warrantfurther study, the wide intervals suggest this may be due to random variability within the smallsample size. Across both methods, an analysis of the coefcients in our p(Y | X, U , C) models forthe smoking status variable indicates that non-smokers have the best overall odds of survival, whichaligns with past investigations of the connection between tobacco use and mortality among sepsispatients [Alroumi et al., 2018, Zhang et al., 2022]. An unlikely but alternative explanation for therisk ratio of 1.13 could additional unobserved confounding if, hypothetically, non-smoker patientsare only administered TTE if they are at higher risk of mortality due to a factor not captured by ourobserved covariates X. In our matrix adjustment subgroup analysis for current smokers, our methods produce a risk ra-tio condence interval that has almost zero width. This is somewhat unintuitive, especially as ourMIMIC classier predicts only 93 current smokers. We believe this is a consequence of our test setconfusion matrix from ; there are no examples in which the model falsely predicts a currentsmoker. Because we do not smooth this confusion matrix, p(U = Current | U = Current) = 0which means that our matrix adjustment represented by Equation 7 has relatively little effect. Thishelps explain the zero-width interval for the n2c2 bootstrap. Homogeneity amongst the patients clas-sied as current smokers could possibly explain the lack of variability from the MIMIC bootstrap. The subgroup analyses for MC-SIMEX show an overall narrowing of condence intervals, despitethe reduced sample sizes. As in , we see very narrow intervals especially for the n2c2 boot-strap. The average width of MC-SIMEX n2c2 bootstrap intervals is 0.05, which is rounded downto 0 with only two signicant digits. We leave for future work simulation studies and theoreticalanalyses that could better explore the unexpectedly low variance of this method.",
  "Conclusions and Future Work": "Our method can control for unobserved confounding using an LLM classier and a measurementerror correction. We have applied this method to estimate a causal effect with implications forclinical care, accounting for a possible violation of the assumptions of past work. Our overall results that TTE protects against mortality comport with prior work and do not suggest any particularchanges to the standards of clinical care. However, our method more broadly offers a straightforwardapproach to predicting unobserved confounders from clinical notes, correcting for measurementerror, and controlling for confounding. As unobserved confounding is an untestable assumptionon which all non-randomized causal analyses rely, our method demonstrates a widely-applicablemethod for exploring the impact of possible confounding. For any analysis of clinical data wherephysicians notes and corresponding classiers are available, our method can be used to controlunobserved confounding or as a sensitivity analysis to test the robustness of the results. Our method relies on a number of important assumptions, and future work could explore relaxingthem. First, our choice of datasets and smoking status requires us to validate the test accuracy of ourLLM classier on the n2c2 dataset and to assume that the classiers performance is the same on theMIMIC dataset we analyze. In general, we would not expect the classier to perform identically ontwo separate datasets, though our bootstrapping analysis suggests our results are robust to variationsin our estimates of the models performance. This assumption could be relaxed in future workby collecting a small test set of labeled smoking statuses amongst the MIMIC patient data. Withunobserved confounders that could hypothetically be labeled by manual chart review, our methodcould be rendered unnecessary when sufcient time and money is available. In practice, however,the large quantity of data involved and possible concerns about manual review of clinical notesprovides strong motivation for our method. Our approach also relies on Equation (3), the assumption of non-differential error. While it seemsplausible that the classier we use should have an error rate independent of patients covariates, thismay not be true. In the most severe case where the error rate depends on X, Y, and C, this wouldrequire tting an additional model p(U | U, X, Y, C). We leave such an exploration to future work.",
  "Fahad Alroumi, Ahmed Abdul Azim, Rachel Kergo, Yuxiu Lei, and James Dargin. The impact ofsmoking on patient outcomes in severe sepsis and septic shock. Journal of intensive care, 6(1):111, 2018": "Emily Alsentzer, John Murphy, William Boag, Wei-Hung Weng, Di Jindi, Tristan Naumann, andMatthew McDermott. Publicly Available Clinical BERT Embeddings. In Proceedings of the2nd Clinical Natural Language Processing Workshop. Association for Computational Linguistics,2019. Derek C Angus, Christopher W Seymour, Craig M Coopersmith, Clifford S Deutschman, MichaelKlompas, Mitchell M Levy, Gregory S Martin, Tiffany M Osborn, Chanu Rhee, and R ScottWatson. A framework for the development and interpretation of different sepsis denitions andclinical criteria. Critical care medicine, 44(3):e113e121, 2016.",
  "Thomas J DiCiccio and Bradley Efron. Bootstrap condence intervals. Statistical science, 11(3):189228, 1996": "Mengling Feng, Jakob I McSparron, Dang Trung Kien, David J Stone, David H Roberts, Richard MSchwartzstein, Antoine Vieillard-Baron, and Leo Anthony Celi. Transthoracic echocardiographyand mortality in sepsis: analysis of the mimic-iii database. Intensive care medicine, 44:884892,2018. Samuel G Finlayson, Adarsh Subbaswamy, Karandeep Singh, John Bowers, Annabel Kupke,Jonathan Zittrain, Isaac S Kohane, and Suchi Saria. The clinician and dataset shift in articialintelligence. New England Journal of Medicine, 385(3):283286, 2021. W Dana Flanders, Mitchel Klein, Lyndsey A Darrow, Matthew J Strickland, Stefanie E Sarnat,Jeremy A Sarnat, Lance A Waller, Andrea Winquist, and Paige E Tolbert. A method for detectionof residual confounding in time-series and other observational studies. Epidemiology (Cambridge,Mass.), 22(1):59, 2011.",
  "MA Hernan and J Robins. Causal inference: What if. Boca Raton: Chapman & Hall/CRC, 2020": "Lavender Yao Jiang, Xujin Chris Liu, Nima Pour Nejatian, Mustafa Nasir-Moin, Duo Wang, AnasAbidin, Kevin Eaton, Howard Antony Riina, Ilya Laufer, Paawan Punjabi, et al. Health system-scale language models are all-purpose prediction engines. Nature, pages 16, 2023. Alistair E. W. Johnson, Tom J. Pollard, Lu Shen, Li-wei H. Lehman, Mengling Feng, MohammadGhassemi, Benjamin Moody, Peter Szolovits, Leo Anthony Celi, and Roger G. Mark. MIMIC-III,a freely accessible critical care database. Scientic Data, 3(160035), 2016. doi: Helmut Kchenhoff, Samuel M. Mwalili, and Emmanuel Lesaffre.A General Method forDealing with Misclassication in Regression: The Misclassication SIMEX.Biometrics, 62(1):8596, 07 2005.ISSN 0006-341X.doi:10.1111/j.1541-0420.2005.00396.x.URL",
  "David L Sackett, William MC Rosenberg, JA Muir Gray, R Brian Haynes, and W Scott Richardson.Evidence based medicine: what it is and what it isnt, 1996": "Robert William Sanson-Fisher, Billie Bonevski, Lawrence W Green, and Cate DEste. Limitationsof the randomized controlled trial in evaluating population-based health interventions. Americanjournal of preventive medicine, 33(2):155161, 2007. Varadan Sevilimedu and Lili Yu.Simulation extrapolation method for measurement error:A review.Statistical Methods in Medical Research, 31(8):16171636, 2022.doi:10.1177/09622802221102619. URL PMID:35607297. Ilya Shpitser and Judea Pearl. Identication of joint interventional distributions in recursive semi-markovian causal models. In Proceedings of the National Conference on Articial Intelligence,volume 21, page 1219. Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press;1999, 2006.",
  "Eric J Tchetgen Tchetgen, Andrew Ying, Yifan Cui, Xu Shi, and Wang Miao. An introduction toproximal causal learning. arXiv preprint arXiv:2009.10982, 2020": "Sana Tonekaboni, Shalmali Joshi, Melissa D McCradden, and Anna Goldenberg. What clinicianswant: contextualizing explainable machine learning for clinical end use. In Machine learning forhealthcare conference, pages 359380. PMLR, 2019. Md Jamal Uddin, Rolf HH Groenwold, Mohammed Sanni Ali, Anthonius de Boer, Kit CB Roes,Muhammad AB Chowdhury, and Olaf H Klungel. Methods to control for unmeasured confound-ing in pharmacoepidemiology: an overview. International journal of clinical pharmacy, 38:714723, 2016. zlem Uzuner, Ira Goldstein, Yuan Luo, and Isaac Kohane.Identifying patient smokingstatus from medical discharge records.Journal of the American Medical Informatics As-sociation, 15(1):1424, 01 2008.ISSN 1067-5027.doi:10.1197/jamia.M2408.URL",
  "Tyler J VanderWeele and Ilya Shpitser. On the denition of a confounder. Annals of statistics, 41(1):196, 2013": "Shirly Wang, Matthew B. A. McDermott, Geeticka Chauhan, Marzyeh Ghassemi, Michael C.Hughes, and Tristan Naumann.Mimic-extract: a data extraction, preprocessing, and rep-resentation pipeline for mimic-iii.Proceedings of the ACM Conference on Health, In-ference, and Learning, page 222235, 2020.doi:10.1145/3368555.3384469.URL Wood-Doughty, Shpitser, and Dredze. Sensitivity analyses for incorporating machine learning pre-dictions into causal estimates. NeurIPS Workshop on Causal Discovery & Causality-InspiredMachine Learning, 2020. Nai Zhang, Yujuan Liu, Chuang Yang, Peng Zeng, Tao Gong, Lu Tao, and Xinai Li. Associationbetween smoking and risk of death in patients with sepsis: A systematic review and meta-analysis.Tobacco Induced Diseases, 20, 2022. Hongjian Zhou, Boyang Gu, Xinyu Zou, Yiru Li, Sam S Chen, Peilin Zhou, Junling Liu, YiningHua, Chengfeng Mao, Xian Wu, et al. A survey of large language models in medicine: Progress,application, and challenge. arXiv preprint arXiv:2311.05112, 2023.",
  "NeurIPS Paper Checklist": "1. ClaimsQuestion: Do the main claims made in the abstract and introduction accurately reect thepapers contributions and scope?Answer: [Yes]Justication: We include the main claims in the abstract and introduction: proposinga methodology to take into account the measurement error caused by an unknown con-founder, smoking status, and providing experiments to show the effects of measurementbias.2. LimitationsQuestion: Does the paper discuss the limitations of the work performed by the authors?Answer: [Yes]Justication: We include discussion of our assumptions and their limitations throughoutthe paper from 3 to 5. These include the assumptions common to the matrix adjustmentmethod and some specic to our data analysis, such as assuming our LLM classier per-forms identically on the MIMIC-III data as it does on the n2c2 testing set.3. Theory Assumptions and ProofsQuestion: For each theoretical result, does the paper provide the full set of assumptions anda complete (and correct) proof?Answer: [Yes]Justication: We provide derivations (as well as assumptions made) on the effects of mea-surement error when considering an unobserved confounder when measuring causal effectsin 3.2. We also provide experiments to demonstrate the practical aspect of such derivationsin 4.4. Experimental Result ReproducibilityQuestion: Does the paper fully disclose all the information needed to reproduce the mainexperimental results of the paper to the extent that it affects the main claims and/or conclu-sions of the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justication: High-level explanations of how experiments were done are included in 4 aswell as the derivation to implement in 3.2. We also provide an anonymized Github thatcontains the implementation of the derivations in 3 and results in 4. We cannot release then2c2 or MIMIC-III datasets due to data usage agreements, but they are publicly availableto anyone who accepts those agreements.5. Open access to data and codeQuestion: Does the paper provide open access to the data and code, with sufcient instruc-tions to faithfully reproduce the main experimental results, as described in supplementalmaterial?Answer: [Yes]Justication: We provide an anonymized Github that contains the implementation of thederivations in 3 and results in 4. We cannot release the n2c2 or MIMIC-III datasets dueto data usage agreements, but they are publicly available to anyone who accepts thoseagreements.6. Experimental Setting/DetailsQuestion: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand theresults?Answer: [Yes]Justication: We explain our hyperparameter choices (following Mulyar et al. ) in 3and the details of our experiments (e.g., bootstrap condence intervals, subgroup analyses)in 4.",
  "Answer: [Yes]": "Justication: We use nonparametric bootstrap resampling to generate 95% condence inter-vals for measuring causal effects to provide additional context when explaining the effectsof measurement error as well as quantify the signicance our results in 4. However, ourmain contribution is the demonstration of our causal methodology applied to a real-worlddataset, not a claim of improved model performance on a given benchmark.",
  "Answer: [No]": "Justication: The scale of experiments done in this paper do not require large numbers ofCPUs and GPUs. Specically, one 3070TI GPU was used to ne-tune the LLM and runexperiments (as most relied on simple linear models) for the proposed methodology. Thelongest experiment (excluding model training) can be done in under an hour.",
  "Answer: [NA]": "Justication: Although the practical application of imputing smoking status as unobservedconfounder and seeing the measurement bias is an important contribution, the main focusof this paper is to propose a methodology that can be used for general causal methodologies,specically seeing the effects of measurement bias when estimating unbiased casual effectsin the presence of an unobserved confounder in a pre-existing relationship between twovariables.",
  "Question: Are new assets introduced in the paper well documented and is the documenta-tion provided alongside the assets?": "Answer: [NA]Justication: We do not provide new assets.14. Crowdsourcing and Research with Human SubjectsQuestion: For crowdsourcing experiments and research with human subjects, does the pa-per include the full text of instructions given to participants and screenshots, if applicable,as well as details about compensation (if any)?Answer: [NA]Justication: This paper does not involve crowdsourcing. We follow the data usage agree-ment for the MIMIC-III and n2c2 data.15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA]Justication: This paper does not involve crowdsourcing. We follow the data usage agree-ment for the MIMIC-III and n2c2 data, and do not require additional IRB approval."
}