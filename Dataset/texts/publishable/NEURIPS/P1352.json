{
  "Introduction": "The goal of a semantic layer. Understanding the meaning of data is crucial for performing dataanalysis, yet for the users to gain insight into the content and structure of their database, a tediousdata exploration process is often required . A common industry practice taken on by specialistssuch as Knowledge Engineers is to explicitly construct an intermediate layer between the databaseand the user a semantic layer abstracting away certain details of the database schema in favorof clearer data semantics . In the era of Large Language Models (LLMs), industry practitionersand researchers attempt to circumvent this costly process using LLM-powered Natural LanguageInterfaces . The promise of such Text-to-SQL solutions is to allow users withouttechnical expertise to seamlessly interact with databases. For example, a new company employeecould effectively issue queries in natural language without programming expertise or even explicitknowledge of the database structure, e.g., knowing the names of entities or properties, the exactlocation of data sources, etc. However, current Text-to-SQL solutions are far from perfect due tomany factors, mainly related to ambiguous representations, such as data and query ambiguity ,schema complexity (e.g., vast schema, wide tables, cryptic column names) , among others. Forthese reasons, we argue that a semantic layer can be useful for human users and AI tools alike. Contribution 1: Semantic layer as a set of distilled views. We propose to define the semantic layeras a set of easy-to-interpret and reusable database views. A view is a virtual table that is the result ofa stored query, that can be used as any other table when writing subsequent queries . Databaseviews are structured objects that can be constructed in-database, allowing for seamless integrationwith existing system components using direct communication in SQL. In particular, we explore theunderlying database in order to discover views that represent entities together with their properties, aswell as relationships between them. Thus, our semantic layer augments a hard-to-interpret existingdatabase schema with additional automatically generated and easy-to-interpret views, which distillthe semantic knowledge into smaller bits. Note that this approach can also be viewed as a schemarefinement process, effectively reformulating the original tables into a larger set of more manageableones, each with fewer columns, and clearly defined semantics. Contribution 2: Agentic programming for schema refinement. Discovering such semanticallymeaningful database views is not a trivial task. If we had access to a vast log of past queries, wecould attempt to mine a set of such views by targeting the queries or subqueries that appear frequently.Instead, we consider an even more challenging scenario where we only have access to the schema andthe database. In this case, it seems impossible to recognize which parts of the data are semanticallymeaningful in an automated way; some form of external knowledge is necessary. Our solution usesLLMs to inject external knowledge into the process and to guide the view discovery.",
  "Q: SELECT i.staff_id, g.revenue FROM intern i, staff_generates_revenue g": "WHERE i.staff_id = g.staff_id ORDER BY revenue LIMIT 1 CREATE VIEW staff_generates_revenue ASSELECT s.staff_id, SUM(o.total_price) AS revenueFROM orders o, staff sWHERE o.staff_id = s.staff_idGROUP BY s.staff_id Views added to the semantic layer set original queryrefinerefine : Example of the schema refinement mechanism on the schema orders( order_id, staff_id,total_price, . . .), staff( staff_id, position, . . .), where each order is handled by a staff member. Bydistilling the views intern and staff_generates_revenue, the query becomes successively more refined. We construct the semantic layer via an autonomous simulation process, leveraging LLM-poweredmulti-agent workflows , i.e., agentic programming. Such workflows incorporate feedback loopsbetween agents, significantly enhancing their generative capabilities through iterative refinement. These systems can create complex simulations with minimal input, since agents autonomouslygenerate both prompts and responses, in contrast to a single-agent workflow where a human explicitlyprovides all prompts. Several tools have emerged to support agentic programming bystreamlining the development and coordination of multi-agent solutions. Further, agents can useexternal tools like APIs and code interpreters, which extend their functionality beyond LLMs, whileadvanced prompting techniques further enhance agents problem-solving abilities. In our multi-agent approach, agents receive access to the database as well as minimal seed instructionsand communicate to discover a set of views via a collaborative simulation. Specifically, we instructthe agents to use a systematic schema refinement mechanism (described in .1) and let themcollaboratively apply the mechanism and to refine their results. The agents analyze the data, discoverviews, reflect on the quality of their proposals, and validate the view correctness using external tools.",
  "Schema refinement mechanism": "The main idea behind view discovery is to start with complex queries and then express them in asimpler way by decomposing them into modular components. These components are separatelydefined as database views that encapsulate distinct portions of the query logic, frequently representingkey entities or relationships within the data. This query refinement process effectively turns intoschema refinement by producing several reusable views as byproduct. We illustrate this process with a database about orders handled by staff members with the followingsimple schema: orders(order_id, staff_id, total_price, . . .), staff(staff_id, position, . . .). Each orderis handled by a staff member and has a total price. shows a query that involves joins,aggregations, and filtering conditions. The query selects staff members that are interns, finds theorders handled by those staff members, calculates the total revenue produced by these orders per staffmember, sorts staff members according to the total revenue generated and finally finds the internthat produced the highest revenue. Attempting to express this query in a simpler way, we could startby defining a view that corresponds to interns effectively omitting this selection from the originalquery. Note that the intern can be interpreted as a distinct entity hidden in the database. We canfurther simplify this query by defining a view that precomputes the aggregate value revenue foreach staff member. With this view we discovered a new property revenue of the entity staff. AnalystCritic SQL generation to solve task Task suggestion",
  "The Verifier validates the views by execution within a database engine, thereby ensuringtheir correctness, and may also use external tools for more sophisticated testing": "Each simulation session receives as input a straightforward textual description of the database schema,supplemented by an optional small data sample. In most cases the schema is particularly large, thusthe agents do not attempt to ingest it all at once. Instead, the process is performed on subsets of tablesthat join with each other, thereby encouraging the creation of views that integrate data from diversesources. In particular, we sample connected components of the schema graph, i.e., the graph thatrepresents tables as nodes and PK/FK pairs as edges. Further, we leverage a GraphRAG algorithm to specialize the sampled subgraphs and thus guide the focus of each multi-agent session. Sincethe algorithm operates on graphs with features, we augment the schema graph with node and edgefeatures that correspond to text embeddings of table and key descriptions, respectively. To achieve comprehensive coverage of the database, multiple sessions can be executed sequentially(b). Agents maintain a history of prior sessions to avoid redundancy and promote diversity intheir exploration of the database schema. This ensures that the process not only scales effectively butalso delivers a broad and diverse semantic understanding of the data.",
  "Experiments": "We report a preliminary study of our framework, quantifying the effects of our schema refinement ona realistic commercial database and showing how our results aid data exploration. We observe thatour method provides a practical normalization of the database into manageable components. Case Study.We studied our approach on a realistic corporate database provided by Braze, acustomer engagement platform, publicly available in Snowflake Marketplace 2. The database containssynthetic data and serves as a demo to Braze clients modelling user behavior and engagement withrespect to events such as marketing campaigns. The provided schema consists of 61 mostly widetables and 1770 columns in total (a). After a few hours of multi-agent simulation, we obtained",
  ": Structural properties of the distilled views composing the semantic layer. We ignore the top1% views in terms of width": "a set of 1146 views, covering 80.79% of the columns in the original schema. Further, 54.84% ofthe original relationships among columns (2 columns co-occurring in a table) are preserved in theviews, while 7229 newly created pairwise relationships are obtained via views that combine dataacross different sources using join operators. In b, we see that most generated views have fewcolumns (median width 3, a) in contrast to tables in the original schema which are often wide(median width 28, a), thus validating that the generated views serve as a refined version of theoriginal schema with tables effectively decomposed into smaller components. We then organize the generated views to better understand their semantics and provide easy useraccess. Specifically, we semantically group the views using embedding and clustering. Then weinstruct an LLM-agent to discover entities, properties, relationships within groups and combine acrossgroups, producing a comprehensive Entity-Relationship model. Note that each entity and relationshipdiscovered is directly mapped to a set of database views, validated for correctness and usefulness viaour multi-agent schema refinement framework. shows a snippet of our results. Starting fromthis collection, a new user can immediately gain insight about the semantic content of the database.Then they can locate exact data sources (tables / columns / derived attributes) by mapping each entityand relation to validated database views expressed in SQL within the database itself.",
  "USERS_CAMPAIGNS_CONVERSION": "Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia LeoniAleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4technical report. arXiv preprint arXiv:2303.08774, 2023. Sihem Amer-Yahia, Georgia Koutrika, Martin Braschler, Diego Calvanese, Davide Lanti,Hendrik Lcke-Tieke, Alessandro Mosca, Tarcisio Mendes de Farias, Dimitris Papadopoulos,Yogendra Patil, Guillem Rull, Ellery Smith, Dimitrios Skoutas, Srividya Subramanian, and KurtStockinger. Inode: Building an end-to-end data exploration system in practice. SIGMOD Rec.,50(4):2329, jan 2022.",
  "Dawei Gao, Haibin Wang, Yaliang Li, Xiuyu Sun, Yichen Qian, Bolin Ding, and JingrenZhou. Text-to-sql empowered by large language models: A benchmark evaluation. PVLDB,17(5):11321145, 2024": "Taicheng Guo, Xiuying Chen, Yaqi Wang, Ruidi Chang, Shichao Pei, Nitesh V. Chawla, OlafWiest, and Xiangliang Zhang. Large language model based multi-agents: A survey of progressand challenges. In IJCAI, pages 80488057, 8 2024. Xiaoxin He, Yijun Tian, Yifei Sun, Nitesh V Chawla, Thomas Laurent, Yann LeCun, XavierBresson, and Bryan Hooi. G-retriever: Retrieval-augmented generation for textual graphunderstanding and question answering. arXiv preprint arXiv:2402.07630, 2024.",
  "Hao Liu, Carmelo Sferrazza, and Pieter Abbeel. Chain of hindsight aligns language modelswith feedback. In ICLR, 2024": "Zhiwei Liu, Weiran Yao, Jianguo Zhang, Liangwei Yang, Zuxin Liu, Juntao Tan, Prafulla KChoubey, Tian Lan, Jason Wu, Huan Wang, et al. Agentlite: A lightweight library for buildingand advancing task-oriented llm agent system. arXiv preprint arXiv:2402.15538, 2024. Pingchuan Ma, Rui Ding, Shuai Wang, Shi Han, and Dongmei Zhang. Insightpilot: An llm-empowered automated data exploration system. In Proceedings of the 2023 Conference onEmpirical Methods in Natural Language Processing: System Demonstrations, pages 346352,2023. Arindam Mitra, Luciano Del Corro, Guoqing Zheng, Shweti Mahajan, Dany Rouhana, AndresCodas, Yadong Lu, Wei-ge Chen, Olga Vrousgos, Corby Rosset, et al. Agentinstruct: Towardgenerative teaching with agentic flows. arXiv preprint arXiv:2407.03502, 2024.",
  "Noah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent withdynamic memory and self-reflection. arXiv preprint arXiv:2303.11366, 2023": "Ruoxi Sun, Sercan Arik, Rajarishi Sinha, Hootan Nakhost, Hanjun Dai, Pengcheng Yin, andTomas Pfister. SQLPrompt: In-context text-to-SQL with minimal labeled data. In Findings ofthe Association for Computational Linguistics: EMNLP 2023, pages 542550, 2023. Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le,Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. InNeurIPS, volume 35, pages 2482424837, 2022. Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, XiaoyunZhang, Shaokun Zhang, Jiale Liu, Ahmed Hassan Awadallah, Ryen W White, Doug Burger,and Chi Wang. Autogen: Enabling next-gen llm applications via multi-agent conversationframework. In COLM, 2024. Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L Griffiths, Yuan Cao, and KarthikNarasimhan. Tree of thoughts: Deliberate problem solving with large language models, 2023.arXiv preprint arXiv:2305.10601, 2023.",
  "A.1Case Study: CMS Data Feeds": "In this section we present an additional case study, this time on data feeds from the Centers forMedicare and Medicaid Services 3. This is a very large diverse database with a star-like schema,where two tables Feeds and Feed Files are both in the center. The schema consists of 113 tables and 6879 columns in total, for which we obtained a set of 632views. In , we see that most generated views have few columns (median width 4, maximumwidth 31) in contrast to tables in the original schema which can be extremely wide (maximum width1130). In this case, although the views cover 18.87% of the columns in the original schema, abstractingaway too detailed information, only 0.5% of the original relationships among columns are preservedin the views. This is expected since 2 columns co-occurring in a table of extreme width do notnecessarily reflect relations in the semantic level, thus the refinement process decomposes these kindsof tables preserving only key relations between columns and discarding the rest. Additionally, theviews contain 1965 newly created pairwise relationships, associating columns from different origintables.",
  "--------------------------------------------------------------------------------Critic (to chat_manager):": "Your approach to creating views for users who interacted with both email andpush notification campaigns, as well as extracting engagement metrics for analysis,is well-structured and effective. The views you created will not only simplifyyour queries but also make them more reusable and maintainable. I appreciate how youve renamed the columns in the views to make them moredescriptive and readable. This will help improve the overall quality ofyour analysis and make it easier for users to understand the data being presented. Your final analysis query combining the engagement metrics of users whointeracted with both types of campaigns looks solid. It provides a clearcomparison between email and push notification engagement metrics, allowingfor insights into user behavior across different communication channels.",
  "--------------------------------------------------------------------------------Analyst (to chat_manager):": "sql-- Count the number of users who have interacted with both email and pushnotification campaignsWITH email_users AS (SELECT DISTINCT USER_IDFROM USERS_MESSAGES_EMAIL_SEND_VIEW),push_notification_users AS (SELECT DISTINCT USER_IDFROM USERS_MESSAGES_PUSHNOTIFICATION_IOSFOREGROUND_VIEW)SELECT COUNT(*) AS total_usersFROM email_usersJOIN push_notification_usersON email_users.USER_ID = push_notification_users.USER_ID; sql-- Analyze the engagement metrics (open rates, click-through rates, etc.)of users who interacted with both email and push notification campaignsWITH email_engagement AS (SELECT USER_ID, OPEN_RATE, CLICK_THROUGH_RATEFROM USERS_MESSAGES_EMAIL_SEND_VIEW),push_notification_engagement AS (SELECT USER_ID, OPEN_RATE, CLICK_THROUGH_RATEFROM USERS_MESSAGES_PUSHNOTIFICATION_IOSFOREGROUND_VIEW)SELECT AVG(email_engagement.OPEN_RATE) AS avg_email_open_rate,AVG(email_engagement.CLICK_THROUGH_RATE) AS avg_email_click_through_rate,AVG(push_notification_engagement.OPEN_RATE) AS avg_push_notification_open_rate,AVG(push_notification_engagement.CLICK_THROUGH_RATE) AS avg_push_notification_click_through_rateFROM email_engagementJOIN push_notification_engagementON email_engagement.USER_ID = push_notification_engagement.USER_ID;",
  "- It will be based on the common user interactionsbetween the two types of campaigns": "2. **View 2: email_engagement_metrics**- This view will extract relevant engagement metrics(open rates, click-through rates, etc.) for email campaigns.- It will provide a cleaner and more focused dataset foremail campaign analysis. 3. **View 3: push_notification_engagement_metrics**- This view will extract relevant engagement metrics forpush notification campaigns.- It will allow for a clearer and more concise analysisof push notification campaign engagement. By creating these views, you can simplify your queries, make them morereusable, and ensure better readability. Its also a good practice torename the columns in the views to makethem more descriptive. Once you have these views in place, you can furtheranalyze the engagement metrics or exploreother aspects of user behavior. If you agree, pleaseincorporate these views into your analysis. Let me know if you need anyfurther clarification or assistance.",
  ");": "-- Creating View 2: email_engagement_metricsCREATE VIEW email_engagement_metrics ASSELECT USER_ID, OPEN_RATE AS email_open_rate,CLICK_THROUGH_RATE AS email_click_through_rateFROM USERS_MESSAGES_EMAIL_SEND_VIEW; -- Creating View 3: push_notification_engagement_metricsCREATE VIEW push_notification_engagement_metrics ASSELECT USER_ID, OPEN_RATE AS push_notification_open_rate,CLICK_THROUGH_RATE AS push_notification_click_through_rateFROM USERS_MESSAGES_PUSHNOTIFICATION_IOSFOREGROUND_VIEW; sql-- Analyzing the combined engagement metrics of users who-- interacted with both email and push notification campaignsSELECT AVG(email.email_open_rate) AS avg_email_open_rate,AVG(email.email_click_through_rate) AS avg_email_click_through_rate,AVG(push.push_notification_open_rate) AS avg_push_notification_open_rate,AVG(push.push_notification_click_through_rate) AS avg_push_notification_click_through_rateFROM email_engagement_metrics emailJOIN push_notification_engagement_metrics pushON email.USER_ID = push.USER_ID;"
}