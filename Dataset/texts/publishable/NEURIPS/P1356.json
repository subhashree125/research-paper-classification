{
  "Abstract": "Bayesian optimization (BO) is a popular method for computationally expensiveblack-box optimization. However, traditional BO methods need to solve new prob-lems from scratch, leading to slow convergence. Recent studies try to extend BO toa transfer learning setup to speed up the optimization, where search space transferis one of the most promising approaches and has shown impressive performanceon many tasks. However, existing search space transfer methods either lack anadaptive mechanism or are not flexible enough, making it difficult to efficientlyidentify promising search space during the optimization process. In this paper,we propose a search space transfer learning method based on Monte Carlo treesearch (MCTS), called MCTS-transfer, to iteratively divide, select, and optimize ina learned subspace. MCTS-transfer can not only provide a well-performing searchspace for warm-start but also adaptively identify and leverage the information ofsimilar source tasks to reconstruct the search space during the optimization process.Experiments on synthetic functions, real-world problems, Design-Bench and hyper-parameter optimization show that MCTS-transfer can demonstrate superior perfor-mance compared to other search space transfer methods under different settings.Our code is available at",
  "Introduction": "In many real-world tasks such as neural architecture search [56; 41; 42], hyper-parameter optimiza-tion [55; 4], and integrated circuit design [19; 30], we often need to solve black-box optimization(BBO) problems, where the objective function has no analytical form and can only be evaluatedby different inputs, regarded as a black-box function. BBO problems are often accompanied byexpensive computational costs of the evaluations, requiring a BBO algorithm to find a good solutionwith a small number of objective function evaluations. Bayesian optimization (BO) [29; 8] is a widely used sample-efficient method for such problems.At each iteration, BO fits a surrogate model, typically Gaussian process (GP) , to approximatethe objective function, and maximizes an acquisition function to determine the next query point.Under the limited evaluation budget, traditional BO methods only have a few observations, whichare, however, insufficient for constructing a precise surrogate model, leading to slow convergence.Thus, traditional BO methods struggle to effectively solve expensive BBO problems, preventing theirbroader applications.",
  "arXiv:2412.07186v1 [cs.LG] 10 Dec 2024": "the knowledge acquired from similar source tasks can be helpful for optimizing the current targettask. They typically gather offline datasets from the source tasks and utilize them to expedite thetarget task. These methods can be categorized based on the learned components of BO, such as theacquisition function [51; 40], initialization point [45; 47], or search space [49; 23; 17]. Among these, learning the search space is a promising research area due to its effectiveness andorthogonal relationship with optimization methods. By learning and partitioning the search space, wecan more effectively utilize potential subspaces and significantly accelerate the algorithms searchfor optimal solutions. While the methods for partitioning the search space have demonstrated greatpotential [22; 14; 23; 17], they still have several limitations, particularly in terms of flexibly adjustingthe search space for the current target task. In many scenarios, we are uncertain about which tasksare truly similar to the target task before optimizing it. Our comprehension about this similaritycan only deepen gradually as we progress in optimizing the target task. Therefore, we hope that asearch space transfer algorithm can automatically identify the most relevant source tasks during theoptimization process, and give them more consideration when constructing the subspaces. However,existing methods have limited flexibility in adjusting in this manner. In this paper, we propose a search space transfer learning method based on Monte Carlo tree search(MCTS), called MCTS-transfer, to iteratively divide, select, and optimize in a learned subspace. Eachnode of MCTS-transfer represents a subspace, whose potential is calculated as a weighted sum of thesource and target sample values, assessing the nodes utilization value. To better identify and leveragethe information from source tasks, we assign different weights to different source tasks based ontheir similarity to the target task, which are adjusted dynamically during the optimization process.These weights are then used to calculate the potential of the node. Our proposed MCTS-transferoffers several notable advantages. First, it can provide a better initial search space for a warm-start ofthe optimization of the target task. Second, it can provide multiple promising compact subspaces byMCTS, to improve optimization efficiency. The upper confidence bound (UCB)-based node selectionof MCTS can also automatically balance the trade-off between exploration and exploitation. Third, itcan automatically identify source tasks similar to the current target task based on new observations,and re-construct the search space to make it more consistent with the current target task. To evaluate the effectiveness of the proposed method, we compare MCTS-transfer with varioussearch space transfer methods and conduct experiments on multiple BBO tasks, including syntheticfunctions, real-world problems, Design-Bench and hyper-parameter optimization problems. Indifferent scenarios, such as varying similarity between the source tasks and target task, MCTS-transfer demonstrates superior performance. We also analyze the effectiveness of the adaptive weightadjustment, showing that MCTS-transfer can identify source tasks that are similar to the targettask and assign them higher weights accordingly. Note that MCTS-transfer can be combined withany BBO algorithm. We only implemented it with the basic BO algorithm (i.e., using GP as thesurrogate model and expected improvement (EI) as the acquisition function) in the experiments, andthe performance can be further enhanced by advanced techniques.",
  "Bayesian Optimization": "We consider the problem maxxX f(x), where f is a black-box function and X RD is thedomain. The basic framework of BO contains two critical components: a surrogate model andan acquisition function. GP is the most popular surrogate model. Given the sampled data points{(xi, yi)}t1i=1, where yi = f(xi) + i and i N(0, 2) is the observation noise, GP at iteration tseeks to infer f GP((), k(, ) + 2I), specified by the mean () and covariance kernel k(, ),where I is the identity matrix of size D. After that, an acquisition function, e.g., probability ofimprovement (PI) , EI or UCB , is optimized to determine the next query point xt,balancing exploration and exploitation.",
  "Transfer Bayesian Optimization": "When solving new BBO problems, traditional BO methods need to conduct optimization from scratch,leading to slow convergence. Transfer learning reuses knowledge from source tasks to boost theperformance of current tasks, and thus can be naturally applied to address this issue, i.e., it can utilize source task data to accelerate the convergence of current target task . The main assumption oftransfer learning for BBO is that many real-world problems exhibit certain similarities, and similartasks often share similar characteristics that can be exploited. Various transfer learning approaches have been explored concerning the surrogate model, acquisitionfunction, initialization, and search space of BO. Several methods learn all available informationfrom both source and target tasks in a single GP surrogate, and make the data comparable throughmulti-task GP [37; 16; 38], noisy GP model [31; 25; 13], and deep kernel learning model [47; 11; 10].Additionally, certain approaches involve training multiple base surrogates and then combining theminto a single surrogate [50; 28]. Transfer learning methods on surrogate models, however, may encounter difficulties when scaling tohigh-dimensional cases, because the influence of the source tasks is easy to diminish progressivelywith the increase of new observation points . Alternatively, transferring knowledge via theacquisition function can circumvent these issues. Previous research has approached transfer learningfor acquisition functions through multi-task BO [37; 20], ensemble GPs , and meta-learningstrategies such as reinforcement learning-driven strategies . Several approaches consider selecting multiple valuable points for better initial evaluations for thewarm-start of optimization. Feurer et al. simply selected the best point from the t most similartasks as the initialization point. Other works [48; 45] achieved warm-start by constructing a meta-loss,organically combining the mean function of the GP model from source tasks, and using gradientdescent to find a set of solutions that minimize the meta-loss. Wistuba and Grabocka tried tofind suitable initial points to warm-start BO by minimizing the loss on the source tasks using anevolutionary algorithm.",
  "Search Space Transfer": "Compared to the aforementioned methods, search space transfer has many advantages, especiallyin not limiting the transfer to a specific algorithm component (e.g., acquisition function in BO), butconsidering the search space that can be used by all BBO algorithms as the transfer object. That is,the learned search space is orthogonal to the optimization process and can be integrated with anyadvanced optimizer. A well-learned search space can greatly improve optimization efficiency andguide the optimization process to a good result. The concept of search space transfer was first proposed by Wistuba et al. , which defined a regionby a center point and a diameter, and pruned away regions deemed less promising. Instead of pruningspace, Perrone and Shen considered designing a promising search space for the target task. Thisapproach extracts an optimal solution xi from each task, and employs a simple geometric form (e.g.,a box or ellipsoid) to define the smallest subspace encompassing all optimal solutions xi . However,it ignores the correlation between tasks, and the space constructed with regular geometry may be tooloose for the target task. To address this issue, Li et al. selected the most similar source tasks tothe target task in a certain proportion, and used a binary classification method to learn good spacesand bad spaces among these tasks. A voting mechanism is then employed to aggregate informationfrom all selected tasks to determine a newly generated search space for the target task. These current space transfer methods, however, lack mechanisms to adjust the search space when itis not well-suited for the target task. Furthermore, when source tasks differ significantly from thetarget task, they tend to devolve into full-space search. The binary nature of evaluating the searchspace as simply good or bad is another limitation. Our proposed method will overcome thesedrawbacks by adapting the search space dynamically according to the similarity between source tasksand the target task, applying MCTS to find a proper subspace, and using a more nuanced and precisenumerical evaluation for the goodness of a search subspace.",
  "Monte Carlo Tree Search": "MCTS is a search algorithm combining random sampling with a tree search structure, whichhas been widely applied in the filed of game-playing and decision-making [32; 34]. A tree noderepresents a particular state in the search space, e.g., stone positions on the board in a GO game. Eachtree node has an UCB value during the search procedure, to balance exploration and exploitation.",
  "log (np) /nm,(1)": "where Cp is a hyper-parameter controlling the balance between exploration and exploitation, and npis the visit times of the parent node. In the iterative process of MCTS, a leaf node is systematically se-lected for expansion, involving four key steps: selection, expansion, simulation, and back-propagation.Initially, the algorithm recursively navigates from the root node to child nodes, prioritizing those withhigher UCB values to identify the leaf node m. Subsequently, an action is executed based on thestate of m, leading to the expansion of a new child node (state), k. In the simulation step, the nodevalue vk is determined through random sampling. Finally, through back-propagation, the value andvisitation count of the ancestors of k are updated. MCTS has been used to select important variables automatically for high dimensional BO .LA-MCTS is a scalable BBO algorithm based on learning space partition. Utilizing MCTS,it iteratively divides the search space into small subspaces for optimization. In this framework,the trees root represents the entire search space denoted as , and each tree node m represents asub-region m. The value vm is determined by the average objective value of the sampled pointswithin the sub-region m. During each iteration, after selecting a leaf node m, LA-MCTS conductsoptimization within m. The sampled points are then employed for clustering and classification,leading to the bifurcation of m into two distinct sub-regions: good and bad. These sub-regionsare expanded as two child nodes, with the left one denoted as good and the right as bad.",
  "MCTS-transfer": "In this section, we propose a search space transfer learning method based on MCTS, called MCTS-transfer, which can be divided into two major stages: pre-learning stage and optimizing stage. Themain idea is to apply MCTS to divide the entire space based on source task data in the pre-learningstage, and adaptively adjust the partition based on newly generated target task data during theoptimition process. MCTS-transfer iteratively chooses one partitioned subspace for search andadjusts the partition after sampling each new data point. Assume that there are K source tasks{fi}Ki=1 and a target task T that we are going to optimize maxx fT (x), where is the entiresearch space. For the i-th source task, we have offline dataset Di = {(xi,j, yi,j)}|Di|j=1, where yi,j isthe observed objective value of xi,j, and |Di| is the number of data points. Let tree T denotes thesearch space division process by MCTS. In the pre-learning stage, T initially has only one root node, representing the entire search space. The expansion of a tree node m corresponds to the division of the search space m that thenode m represents. The node expansion follows the rules below. With a set of source task samples{(xi, yi)}ni=1 in the space m, we use k-means clustering to divide them into two groups. Thecluster with a higher average objective value is regarded as the good cluster, while the other is thebad one. A binary classifier then establishes a decision boundary between the two clusters. In ourapproach, the space associated with the good cluster becomes the left node, while the space of thebad cluster becomes the right node. We recursively apply this partition process within each node,as shown in . The depth of the resulting Monte Carlo tree T is determined by a thresholdhyperparameter : a node is divided if it contains more than samples and the contained samples canbe clustered into two clusters. The tree T generated at this stage can give a suitable space partitionin advance based on source task data, which serves as a warm-start for the following optimizationprocess. Details of pre-learning will be introduced in .1. In the optimization process, we follow the four key steps of MCTS: selection, expansion, simulation,and back-propagation. At each iteration, we select a target node m by tracing the nodes UCB values.That is, starting from the root, we recursively choose the child node with higher UCB value, until aleaf node m is reached, as displayed. The space m represented by m is then considered asa promising search space, where a BO optimizer is used to optimize. The BO optimizer can build asurrogate model using samples in either m or . The newly sampled point will be evaluated andused for expanding the node m after updating the clustering in the node. It will further be utilized inback-propagation, where the number of visits and the potential value of each node will be updated.The potential value of a node is calculated by a weighted sum of objective values of the source andtarget task samples. Note that the tree structure will be reconstructed if there exists a node that the : The workflow of MCTS-transfer. In pre-learning stage, MCTS-transfer builds the treeby clustering and classifying the samples apart recursively, until all nodes are not splitable. Inoptimization stage, the initial search space is based on the pre-learned tree. We will trace child nodewith greater UCB from ROOT and find the target leaf node to do optimization. potential value of its right child exceeds that of the left one, violating the rule of our tree constructionand implying that the current structure is not good. Please see Sections 3.2 and 3.3 for the details ofnode potential update and tree structure reconstruction. Unlike LA-MCTS, MCTS-transfer not only considers the information of the target task whencalculating node values but also takes into account the information from source tasks, enabling it tobe used for search space transfer. Additionally, we propose adaptive weights for source tasks andvalidate their effectiveness through our experiments.",
  "Search Space Pre-Learning": "Compared to standard BBO algorithms, which sample randomly across the entire space at thebeginning, our method leverages information from source tasks to concentrate sampling within agenerally good space, providing a warm-start initialization. In the pre-learning stage, tree T initially has only one node, i.e., ROOT node. All source task samplesare collected in this node, recursively clustered and classified, leading to node expansion. When noneof the leaf nodes can be further bifurcated, i.e., contains more than samples and can be clusteredinto two clusters, T is finally formed. In this process, we keep the rule that the left node is better(i.e., has a larger potential value) than the right node, so that we can easily identify that the leftmostleaf is the best and the rightmost leaf is the worst. The potential value of a node m in the pre-learningstage is estimated by the average yi,j of all source task points within it, i.e.,",
  "This tree embed historically good regions into specific tree nodes. Intuitively, the spaces representedby left leaves have higher potential of being good spaces than right ones": "The first iteration of MCTS-transfer will utilize the resulting tree T generated in the pre-learningstage. Starting from the root node, it recursively selects nodes with higher UCB values until reachinga leaf node. The UCB value is calculated as Eq. (1), where vm is replaced by the potential value pm inEq. (2). In MCTS-transfer, nm and np represent the number of samples, including those from sourceand target tasks, in the subspace m and the parent subspace of m, respectively. Consequently, thealgorithm preferentially samples from those regions that have shown to yield favorable outcomes inthe source tasks.",
  ": A decay factor, which is used to adjust the overall influence of source tasks throughout theoptimization process. A smaller accelerates the forgetting of the source task data": "wi: A weighting factor, which reflects the influence of the i-th source task, and is determinedby the similarity between the i-th source task and the target task. A larger weight representshigher similarity and implies a greater influence of the i-th source tasks samples on the potentialcalculation of a tree node. To calculate wi, we measure the distance Distance(Di, DT ) between the i-th source task and thetarget task by Distance(xi , xT ), where xi and xT denote the mean of the best N sampled pointsof these two tasks, respectively. The source tasks are ranked according to their distances to thetarget task. A smaller rank implies a smaller distance, i.e., a higher similarity. The weight wi is thencalculated as",
  "Nmif ri < Nm0.1otherwise,(4)": "where ri is the rank of the i-th source task, Nm is the number of source tasks that have solutionslocated in m, and . After sampling a new data point in each iteration of MCTS-transfer,the ranks and weights are updated accordingly, which are then used to update the potential value ofeach node. We also consider other ways of calculating distances and weights, which are introducedand empirically compared in Appendix C.",
  "Tree Structure Reconstruction": "When constructing the search tree, the left child of a node is always better than the right child, i.e.,the potential of the left child always exceeds that of the right child. However, after sampling a newdata point and updating the potential of each node in each iteration of MCTS-transfer, this propertymay be violated. If this happens, it indicates that the current space partition is not ideal and needsadjustment. Specifically, we backtrack from the problematic leaf nodes to the highest-level ancestornode that upholds the desired property, and then proceed to reconstruct the subtree from that ancestornode. The subtree reconstruction process is consistent with the process of node expansion. The detailed process is presented in Algorithm 2 in Appendix A. We apply breadth-first search totraverse all tree nodes and use a queue Q to manage the sequence of nodes. In addition, we set aqueue N to store the nodes that need to be reconstructed. If the potential of the right child of a nodeis better than that of the left child (line 6), the subtree of this node is deleted (line 7), and it should bereconstructed and is added into the queue N (line 8). Otherwise, the two child nodes will enter intothe queue Q (lines 1011) and will be examined later. After traversing the tree T , we reconstruct thesubtrees of nodes in N (lines 1519). If a node in N is splitable, i.e., the contained samples in thenode exceeds and can be clustered and divided by a binary classifier, it will be further expanded.Thus, Treeify can fine-tune the tree structure and reserve some history information; meanwhile, it canadaptively be more suitable to the target task.",
  "Details of MCTS-transfer": "The detailed procedure of MCTS-transfer is presented in Algorithm 1. It begins with a pre-learnnedMCTS model T based on source task data (line 1), and initializes an empty set DT to store samplesof the target task (line 2). In each iteration, it selects a leaf node m based on the UCB value (line 4).If the target task already has samples in the space m represented by m, the algorithm conducts BOwithin m and gets a candidate point xT,t (lines 89); otherwise, the candidate point is randomlyselected in m (line 6). The sampled point xT,t is then evaluated and added into DT (line 11). To",
  ": end for": "make full use of the information from the source tasks, we take the similarity between a source taskand the target task into account, and try to assign higher weights to more similar source tasks, asintroduced in .2. With new samples added in DT , the distance between each source taskDi and the target task DT may change. Thus, the distance, rank and weight of each source task arere-calculated in lines 1213 according to Eq. (4), and the potential value of each node in the treeis re-evaluated in line 14 according to Eq. (3). After that, the node m is expanded in lines 1517if it is splitale, i.e., contains more than samples of the target task and can be clustered into twoclusters. Note that for node expansion, only samples of the target task are considered. In line 18,the back-propagation step is performed to refresh the information of each node on the path to m,including the visit times and the contained samples. Finally, we will check whether the updated treeconforms to the property that the left child of a node has a larger potential value than its right node.For any node violating this property, its sub-tree will be reconstructed. This process is accomplishedby employing the Treeify procedure in Algorithm 2 in Appendix A. In MCTS-transfer, the tree structure exhibits several properties that align with the requirements ofsearch space transfer learning. 1) Tree structure is natural to model the search space, where the rootrepresents the entire search space, and the node expansion corresponds to the space partition witheach child node representing a subspace. 2) The node potential evaluation allows for the extraction ofmultiple irregularly shaped promising search subspaces represented by multiple leaf nodes. 3) Thetree can be adjusted by updating and expanding nodes on the basis of the original tree, so that newinformation can be absorbed while historical information can also be retained, i.e., the tree structureis inheritable. This enables the knowledge of space partition from source task data to be transferredto the target task.",
  "Experiments": "In this section, we introduce a simple case to highlight the features of existing search space transferalgorithms and assess the effectiveness of MCTS-transfer. We also conduct experiments across avariety of tasks, including the synthetic benchmark BBOB, real-world problems, Design-Bench,and the hyper-parameter optimization benchmark HPOB. The details of the problems, data andexperimental results can be seen in Appendix B.2, B.3 and E.",
  "GP ), and one state-of-the-art surrogate model transfer BO algorithm PFN . Detailedconfigurations and settings of the hyper-parameters for each algorithm are provided in Appendix B.1": "Basic settings. In our experimental settings, we explore two types of transfer learningsimilarand mixed transferto demonstrate the advantages of MCTS-transfer in handling complex sourcetasks. Similar transfer involves using data from similar source tasks, while mixed transfer uses acombination of similar and dissimilar source task data for pre-training. Given the challenges inreal-world scenarios of determining task similarity and selecting appropriate tasks, our focus will beon evaluating MCTS-transfers performance in the more complex scenario, i.e., mixed transfer.",
  "Motivating Case: Sphere2D": "We first conduct a simple but important experiment on Sphere2D to verify our motivation and evaluatethe performance of existing search space transfer methods. The Sphere2D function is defined asf(x) = (x x)2, with x representing the optimal solution. We generate three source task datasetsD(5,5), D(5,5), and D(5,5), each containing 100 samples, by assigning (5, 5), (5, 5), and(5, 5) to x and sampling with standard BO. The target task is defined as f(x) with x = (4, 4).Unlike the basic setting, we use the mixed setting and the dissimilar setting. Dissimilar setting usesonly D(5,5) and D(5,5) for pre-training, which are most dissimilar to the target task. This settingis to test MCTS-transfers ability to handle extreme cases without similar source tasks. MCTS-transfer-GP is compared against three search space transfer algorithmsBox-GP, Ellipsoid-GP, and Supervised-GPin both mixed and dissimilar settings, as shown in . Box-GP andEllipsoid-GP ignore task similarity and limit the search space to geometric areas encompassing allsource task optima. In the dissimilar transfer setting, these methods fail because the target tasksoptimal solution x = (4, 4) lies outside the defined subspace of source task optima. Supervised-GPtakes task similarity to guide the selection and combination of promising region with a voting system.Although it pays attention to the importance of task similarity and can be applicable in dissimilartransfer, it tends to be an entire-space optimization algorithm when source tasks exhibit high varianceor are dissimilar to the target task. MCTS-transfer recursively divides the search space, dynamicallyajusts task weights and evaluates the subspace potential based on the task similarity. In addition,the method tends to increasingly rely on the target task data due to the decay factor . Therefore,MCTS-transfer achieves convergence with low variance in both mixed and dissimilar transfer. Theright part of displays the weight change curves for the three source tasks, confirming theanticipated results. Higher weights are assigned to datasets D(5,5) and D(5,5), indicating that ourmethod effectively recognizes and prioritizes tasks more similar to the target task.",
  "Synthetic Functions": "BBOB is a popular benchmark for BBO. It offers 24 synthetic functions tailored for the continuousdomain. We randomly select one function from each of the five function classes of BBOB as ourtarget task, i.e., GriewankRosenbrock, Lunacek, Rastrigin, Rosenbrock, and SharpRidge. As shown in a, compared with LA-MCTS, we find that the results can indeed be greatlyimproved after space transfer, proving the effectiveness of MCTS-transfer. In mixed transfer, MCTS-transfer can still maintain warm-start, thanks to its ability to provide multiple compact promisingsubspaces by effective search space pre-learning. Throughout the optimization process, MCTS-",
  "Real-world Problems": "To demonstrate the practical value of MCTS-transfer, we test MCTS-transfer on three real-worldproblems, including LunarLander, RobotPush, and Rover. b shows the comparison under thesettings of similar and mixed transfer. Based on the overall ranking, MCTS-transfer-GP outperformsother search space transfer baselines. In mixed transfer, although its surpassed by PFN initially,MCTS-transfer-GP is finally able to find better solutions even if the dissimilar tasks are misleading.The ability to adaptively correct the search space may come from the efficient utilization of sourcetask data by reasonable node potential evaluation, node expansion, and tree reconstruction.",
  "Design-Bench Problems": "We further verify the performance of MCTS-transfer in more complex and high-dimensional problemsfrom Design-Bench , including three continuous problems, Superconductor, Ant morphology,and DKitty Morphology. In similar and mixed transfer, MCTS-transfer-GP gets the best rankingafter 40 iterations, as shown in a. The stable performance indicates that the algorithm caneffectively transfer and utilize previous experience when facing different source tasks. This ability isparticularly important for black-box optimization problems because it allows the system to quicklyadapt to unseen situations while maintaining high performance.",
  "Hyper-parameter Optimization": "Hyper-parameter optimization (HPO) is a common application of BBO transfer learning. The HPO-Bbenchmark , sourced from OpenML, includes 176 search spaces/algorithms and 196 datasets,totaling 6.4 million HPO evaluations. Details of source task data selection and curves of eachproblem are provided in Appendix B.3 and E, respectively. The HPOB benchmark has severalchallenges. Firstly, for these problems, algorithms are easy to converge to a certain area. Secondly,the source tasks are complex, presenting significant variability in data distribution and scale. Totackle these difficulties, a search algorithm should be able to handle complex source tasks and haverobust optimization capabilities. Experimental results are shown in b, which represent the mean ranks and the variance of allalgorithms on 39 test problems. In both transfer settings, the ranks of baseline algorithms are veryclose, because the gaps among their final convergence values are tiny, as can be seen in Appendix E.However, our method still have clear advantages. Although our method doesnt have enough warm-start strength when the source tasks are diverse and complex, it can still adjust the search tree structureand locate the better search area, exceeding existing search space transfer algorithms.",
  ": Comparison between MCTS-transfer and other algorithms on Design-Bench and HPOB": "RobotPush, and Rover). We divide MCTS-transfer into three main components: evaluation, backpro-pogation, and reconstruction. The evaluation time includes the time required for surrogate modelfitting, candidate solution selection and evaluation, which are the common components shared by alloptimization algorithms. Backpropagation and reconstruction constitute the two principal modulesspecific to MCTS-transfer. As shown in , the additional computational burden introduced by MCTS-transfer (i.e., back-propagation and reconstruction) represents a relatively minor fraction of the total runtime, particularlyin the three expensive real-world problems. That is, for problems with expensive evaluation, MCTS-transfer can bring great improvement while introducing small additional computational overhead.Other details, such as the exact time cost of each component and the frequency of MCTS subtreereconstruction, are provided in Appendix F.",
  "Conclusions and Limitations": "In this paper, we propose MCTS-transfer to solve the expensive BBO problems. MCTS-transfer usesMCTS to perform search space transfer, extracting similar tasks during the optimization process andgiving more accurate space partition results. Compared with other space transfer algorithms, ouralgorithm is more generalizable. Specifically, it can extract the most similar source tasks and givethem higher weights to accelerate optimization. Besides, it is reliable because it can dynamicallyadjust the tree structure, improving the probability that good solutions fall in the search spaceof the chosen node. Comprehensive experiments on BBOB, real-world problems, Design-Benchand HPOB demonstrate the effectiveness of our algorithm. However, there are still limitations,such as the inability of MCTS-transfer to handle search space transfer for problems with differentdomains or different dimensions. Future work will focus on addressing the heterogeneous spacetransfer , exploring more accurate similarity measures, and trying to give theoretical analysis onthe effectiveness of MCTS-transfer.",
  "James Bergstra and Yoshua Bengio. Random search for hyper-parameter optimization. Journalof Machine Learning Research, 13:281305, 2012": "Bernd Bischl, Martin Binder, Michel Lang, Tobias Pielok, Jakob Richter, Stefan Coors, JanekThomas, Theresa Ullmann, Marc Becker, Anne-Laure Boulesteix, Difan Deng, and MariusLindauer. Hyperparameter optimization: Foundations, algorithms, best practices, and openchallenges. WIREs Data. Mining. Knowl. Discov., 13(2), 2023. Cameron Browne, Edward Jack Powley, Daniel Whitehouse, Simon M. Lucas, Peter I. Cowling,Philipp Rohlfshagen, Stephen Tavener, Diego Perez Liebana, Spyridon Samothrakis, and SimonColton. A survey of Monte Carlo tree search methods. IEEE Transactions on ComputationalIntelligence and AI in Games, 4(1):143, 2012.",
  "Harold J. Kushner. A new method of locating the maximum point of an arbitrary multipeakcurve in the presence of noise. Journal of Basic Engineering, 86(1):97106, 1964": "Ho Chung Leon Law, Peilin Zhao, Leung Sing Chan, Junzhou Huang, and Dino Sejdinovic. Hy-perparameter learning via distributional transfer. In Advances in Neural Information ProcessingSystems 32 (NeurIPS18), pages 68016812, Vancouver, Canada, 2018. Yang Li, Yu Shen, Huaijun Jiang, Tianyi Bai, Wentao Zhang, Ce Zhang, and Bin Cui. Transferlearning based search space design for hyperparameter tuning. In Proceedings of the 28th ACMSIGKDD Conference on Knowledge Discovery and Data Mining (KDD22), pages 967977,Washington, DC, 2022. Xingchen Ma and Matthew B. Blaschko. Additive tree-structured covariance function forconditional parameter spaces in bayesian optimization. In Proceedings of the 23rd InternationalConference on Artificial Intelligence and Statistics (AISTATS20, pages 10151025, Palermo,Italy, 2020.",
  "Azalia Mirhoseini, Anna Goldie, Mustafa Yazgan, Joe W. J. Jiang, Ebrahim M. Songhori, ShenWang, Young-Joon Lee, Eric Johnson, Omkar Pathak, Sungmin Bae, Azade Nazi, Jiwoo Pak,": "Andy Tong, Kavya Srinivasa, William Hang, Emre Tuncer, Anand Babu, Quoc V. Le, JamesLaudon, Richard Ho, Roger Carpenter, and Jeff Dean. Chip placement with deep reinforcementlearning. arXiv:2004.10746, 2020. Henry B. Moss, David S. Leslie, and Paul Rayson. Mumbo: Multi-task max-value Bayesianoptimization. In Proceedings of the 31th Machine Learning and Knowledge Discovery inDatabases: European Conference (ECML/PKDD20), pages 447462, Ghent, Belgium, 2020. Samuel Mller, Matthias Feurer, Noah Hollmann, and Frank Hutter. Pfns4bo: In-contextlearning for Bayesian optimization. In Proceedings of the 40th International Conference onMachine Learning (ICML23), pages 2544425470, Honolulu, HI, 2023. Rmi Munos. Optimistic optimization of a deterministic function without the knowledge of itssmoothness. In Advances in Neural Information Processing Systems 24 (NeurIPS11), pages783791, Granada, Spain, 2011. Valerio Perrone and Huibin Shen. Learning search spaces for Bayesian optimization: Anotherview of hyperparameter transfer learning. In Advances in Neural Information ProcessingSystems 32 (NeurIPS19), pages 1275112761, Vancouver, Canada, 2019. Sebastian Pineda-Arango, Hadi S. Jomaa, Martin Wistuba, and Josif Grabocka. HPO-B: Alarge-scale reproducible benchmark for black-box HPO based on openml. In Advances inNeural Information Processing Systems 34 (NeurIPS21), Virtual, 2021. Anil Ramachandran, Sunil Gupta, Santu Rana, and Svetha Venkatesh. Selecting optimalsource for transfer learning in Bayesian optimisation. In Proceedings of the 15th Pacific RimInternational Conference on Artificial Intelligence (PRICAI18), pages 4256, Nanjing, China,2018.",
  "Carl Edward Rasmussen and Christopher K. I. Williams. Gaussian Processes for MachineLearning. The MIT Press, 2006": "Esteban Real, Alok Aggarwal, Yanping Huang, and Quoc V. Le. Regularized evolution forimage classifier architecture search. In Proceedings of the 33rd AAAI Conference on ArtificialIntelligence (AAAI19), pages 47804789, Honolulu, HI, 2019. Nicolas Schilling, Martin Wistuba, and Lars Schmidt-Thieme. Scalable hyperparameter op-timization with products of Gaussian process experts. In Proceedings of the 27th MachineLearning and Knowledge Discovery in Databases: European Conference (ECML/PKDD16),pages 199214, Riva del Garda, Italy, 2016.",
  "Yunqi Shi, Ke Xue, Lei Song, and Chao Qian. Macro placement by wire-mask-guided black-boxoptimization. In Advances in Neural Information Processing Systems 36 (NeurIPS23), NewOrleans, LA, 2023": "Alistair Shilton, Sunil Gupta, Santu Rana, and Svetha Venkatesh. Regret bounds for transferlearning in Bayesian optimisation. In Proceedings of the 20th International Conference onArtificial Intelligence and Statistics (AISTATS17), pages 307315, Fort Lauderdale, FL, 2017. David Silver, Aja Huang, Chris J. Maddison, Arthur Guez, Laurent Sifre, George van denDriessche, Julian Schrittwieser, Ioannis Antonoglou, Vedavyas Panneershelvam, Marc Lanctot,Sander Dieleman, Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya Sutskever, Timothy P.Lillicrap, Madeleine Leach, Koray Kavukcuoglu, Thore Graepel, and Demis Hassabis. Master-ing the game of Go with deep neural networks and tree search. Nature, 529(7587):484489,2016. David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, ArthurGuez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Timothy P. Lillicrap,Karen Simonyan, and Demis Hassabis. Mastering chess and shogi by self-play with a generalreinforcement learning algorithm. arXiv:1712.01815, 2017. David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, ArthurGuez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen, Timothy P.Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche, Thore Graepel, and Demis Hassabis.Mastering the game of Go without human knowledge. Nature, 550(7676):354359, 2017. Lei Song, Ke Xue, Xiaobin Huang, and Chao Qian. Monte Carlo tree search based variableselection for high dimensional Bayesian optimization. In Advances in Neural InformationProcessing Systems 35 (NeurIPS22), New Orleans, LA, 2022. Niranjan Srinivas, Andreas Krause, Sham M. Kakade, and Matthias W. Seeger. Information-theoretic regret bounds for Gaussian process optimization in the bandit setting. IEEE Transac-tions on Information Theory, 58(5):32503265, 2012.",
  "Kevin Swersky, Jasper Snoek, and Ryan Prescott Adams. Multi-task Bayesian optimization. InAdvances in Neural Information Processing Systems 26 (NeurIPS13), pages 20042012, LakeTahoe, NV, 2013": "Petru Tighineanu, Kathrin Skubch, Paul Baireuther, Attila Reiss, Felix Berkenkamp, andJulia Vinogradska. Transfer learning with Gaussian processes for Bayesian optimization.In Proceedings of the 25th International Conference on Artificial Intelligence and Statistics(AISTATS22), pages 61526181, Virtual, 2022. Brandon Trabucco, Xinyang Geng, Aviral Kumar, and Sergey Levine. Design-bench: Bench-marks for data-driven offline model-based optimization. In Proceedings of the 39th InternationalConference on Machine Learning (ICML22), pages 2165821676, Baltimore, MD, 2022. Michael Volpp, Lukas P. Frhlich, Kirsten Fischer, Andreas Doerr, Stefan Falkner, Frank Hutter,and Christian Daniel. Meta-learning acquisition functions for transfer learning in Bayesianoptimization. In Proceedings of the 8th International Conference on Learning Representations(ICLR20), Addis Ababa, Ethiopia, 2019.",
  "Linnan Wang, Yiyang Zhao, Yuu Jinnai, Yuandong Tian, and Rodrigo Fonseca. Alphax:exploring neural architectures with deep neural networks and monte carlo tree search.arXiv:1903.11059, 2019": "Linnan Wang, Rodrigo Fonseca, and Yuandong Tian. Learning search space partition forblack-box optimization using monte carlo tree search. In Advances in Neural InformationProcessing Systems 33 (NeurIPS20), pages 1951119522, Virtual, 2020. Zi Wang, Clement Gehring, Pushmeet Kohli, and Stefanie Jegelka. Batched large-scale Bayesianoptimization in high-dimensional spaces. In Proceedings of 21st International Conference onArtificial Intelligence and Statistics (AISTATS18), pages 745754, Playa Blanca, Spain, 2018. Ying Wei, Peilin Zhao, and Junzhou Huang. Meta-learning hyperparameter performanceprediction with neural processes. In Proceedings of the 38th International Conference onMachine Learning (ICML21), pages 1105811067, Virtual, 2021.",
  "Martin Wistuba and Josif Grabocka. Few-shot Bayesian optimization with deep kernel sur-rogates. In Proceedings of the 9th International Conference on Learning Representations(ICLR21), Virtual, 2021": "Martin Wistuba, Nicolas Schilling, and Lars Schmidt-Thieme.Learning hyperparameteroptimization initializations. In Proceedings of the 2nd IEEE International Conference on DataScience and Advanced Analytics (DSAA15), pages 110, Paris, France, 2015. Martin Wistuba, Nicolas Schilling, and Lars Schmidt-Thieme. Hyperparameter search spacepruning - A new component for sequential model-based hyperparameter optimization. InProceedings of the 26th Machine Learning and Knowledge Discovery in Databases: EuropeanConference (ECML/PKDD15), pages 104119, Porto, Portugal, 2015. Martin Wistuba, Nicolas Schilling, and Lars Schmidt-Thieme. Two-stage transfer surrogatemodel for automatic hyperparameter optimization. In Proceedings of the 27th Machine Learningand Knowledge Discovery in Databases: European Conference (ECML/PKDD16), pages 199214, Riva del Garda, Italy, 2016.",
  "Jian Wu and Peter Frazier. Practical two-step lookahead bayesian optimization. In Advances inNeural Information Processing Systems 32 (NeurIPS19), 2019": "Shangda Yang, Vitaly Zankin, Maximilian Balandat, Stefan Scherer, Kevin T. Carlberg, NeilWalton, and Kody J. H. Law. Accelerating look-ahead in bayesian optimization: Multilevelmonte carlo is all you need. In Proceedings of the 41st International Conference on MachineLearning (ICML24), Vienna, Austria, 2024. Xin-She Yang and Suash Deb. Eagle strategy using lvy walk and firefly algorithms forstochastic optimization. In Proceedings of the 4th Nature Inspired Cooperative Strategies forOptimization (NICSO10), pages 101111, Granada, Spain, 2010. Quanming Yao, Mengshuo Wang, Hugo Jair Escalante, Isabelle Guyon, Yi-Qi Hu, Yu-Feng Li,Wei-Wei Tu, Qiang Yang, and Yang Yu. Taking human out of learning applications: A surveyon automated machine learning. arXiv:1810.13306, 2018.",
  "ATreeify Pseudocode": "To maintain the property that the potential of the left child should exceed the potential of the rightchild for each node, tree reconstruction should be implemented in each iteration. The process ofadjusting the tree structure, i.e., deleting and reconstructing subtrees that violate the desired property,is called Treeify. The pseudocode is provided below, as shown in Algorithm 2.",
  "We use the authors reference implementations for LA-MCTS3, Box-GP4, Ellipsoid-GP5, Supervised-GP6 and PFNs4BO7. The hyper-parameters of all compared algorithms are summarized as follows:": "GP-EI. We use the GP model in Scikit-learn8 and the ExpectedImprovement acquisition .The kernel is set to be ConstantKernel(1.0)*Matern(length_scale=1.0, nu=2.5). To optimizethe acquisition function, we generate 10000 points randomly and then select the one with themaximum expected improvement to be evaluated, which is similar to LA-MCTS . LA-MCTS . We set Cp = 0.1, = 10. We adopt global GP as the modeling approach.SVM with rbf kernel is used for space division in Sphere2D, BBOB, and HPOB, while LogisticRegression is applied for real-world problems. In the sampling process, we sample the entirespace 10,000 times, retaining qualifying candidate points, and repeat this process three times.The parameters of GP are consistent with GP-EI. All other parameters are set to their defaultvalues.",
  "We consider the following three real-world problems in our experiments": "LunarLander.9 This problem is to learn the parameters of a controller for a lunar lander, which isimplemented in OpenAI gym.10 It involves a 12-dimensional continuous input space depicting thelanders actions. Our goal is to enhance the control algorithm to maximize the mean terminal rewardacross a consistent batch of 50 randomly generated landscapes, incorporating varying initial positionsand velocities. RobotPush.11 This function computes the distance between a predefined target location and twoobjects that are manipulated by a pair of robotic appendages. The movement trajectory of these objectsis governed by a set of 14 parameters, which encapsulate attributes such as position, orientation,speed, and direction of motion. We need to control the robot to push items to a designated location.This is implemented with a physics engine Box2D12. Rover.13 The task optimizes 2D trajectories for a rover by defining start and goal positions and acost function over the state space . The trajectory costs c(x) is computed for solutions x within a60-dimensional unit hypercube. We need to design a reasonable trajectory to minimize the cost.",
  "To verify the performance of MCTS-tranfer in more complex and high-dimensional cases, we considerthe 3 continuous problems from Design-Bench14": "Superconductor. Its a critical temperature maximization for superconducting materials. This task istaken from the domain of materials science, where the goal is to design the chemical formula for asuperconducting material that has a high critical temperature. The search space is a continuous spacewith 86 dimensions. Ant morphology. Its a robot morphology optimization. The goal is to optimize the morphologicalstructure of Ant from OpenAI Gym15 to make this quadruped robot to run as fast as possible. Thesearch space is a continuous space with 60 dimensions. DKitty Morphology. Its robot morphology optimization. The goal is to optimize the morphologyof DKitty robot to navigate the robot to a fixed location. The search space is a continuous space with56 dimensions.",
  "B.3Source Task Data Construction for Similar and Mixed Transfer": "Data collection The source task data for pre-training is generated by seven optimization algorithms:Random Search , Shuffled Grid Search, Hill Climbing, Regularized Evolution , Eagle Strat-egy , and GP-EI . These methods span heuristic, evolutionary, and BO techniques, providinga diverse set of optimization behaviors for our analysis. BBOBIn order to obtain similar source task data of function f, we perform some similar trans-formations on f to obtain function family Ff with seed from 0 to 499. Then we use the samplingalgorithms mentioned above with randomly selected seed to collect 300 samples on each functionin Ff. In this section, we randomly select 20 datasets from datasets of Ff for function f. In thesimilar setting, We only use selected datasets of Ff. In mixed setting, we use selected datasets of all5 synthetic functions. Real-world problems and Design-Bench problemsSince it is difficult to find data with thesame dimensions in real-world problems, we choose to use the artificial function Sphere of thesame dimension to generate similar data and dissimilar data and mix it into the source task data set.Among them, to simulate similar functions, we set the optimal point x of the sphere function tobe the optimal point of all these algorithms found so far; the optimal point of the Sphere functionthat simulates dissimilar functions is set to 1 x. In the similar setting, we randomly select 20trajectories from the problem with different seeds and function transformations, combined with datagenerated by similar sphere function, as the dataset. In the mixed setting, we further add 7 trajectoriesfrom dissimilar sphere function. In this section, it is a problem with significantly more similar sourcetasks than dissimilar tasks. HPOBWe choose search spaces from HPO-B-v3 and divide them into 4 groups based on dimen-sions. Specailly, we obtain group 5860 and 5970 with dimension 2, group 5859 and 5889 withdimension 5, group 7607 and 7609 with dimension 9, group 5806 and 5971 with dimension 16. Inthe similar setting, we only use the training data from the search space itself for pre-learning. In themixed setting, we use all training data of search spaces in the same group.",
  "C.1Task Similarity": "Measuring the similarity of two tasks based on the dataset of a source task Di and the dataset ofthe target task DT is a complex task. We define task distance as a measure of similarity. Smallerdistances between tasks represent greater similarity. Here we mainly focus on two types of methods:point-based similarity measures and distribution-based similarity measures. The former includesoptimal solutions distance, best N solutions mean distance, best N percent solutions mean distance;and the latter includes Kendall coefficient of datasets, Kullback-Leibler Divergence(KL Divergence)of distributions. Detailed description are as follows:",
  "Optimal solutions distanceLet xT be the best solution of target task, and xi be the best solutionof target task. The task distance is calculated as Distance(xT , xi )": "Best N (or N percent) solutions mean distanceSimilar to optimal solutions distance, we replacexi and xi with the mean of best N (or N percent) of target task and source task i, denoted as xT andxi . The task distance is Distance(xT , xi ). Intuitively, its more robust than directly using the bestsolution. Kendall coefficientKendall coefficient is a measure of rank correlation, which can be used toevaluate the consistency of two datasets. We first build a surrogate model (usually GP) Mi on Di,and then predict all sample values in DT . According the ranking results of all these data, we get thesimilarity of the two tasks by Eq (5), where I is the indicator function and is the exclusive-noroperation, in which the statement value is true only if the two sub-statements return the same value.",
  "C.2Weight Assignment": "Based on the similarity between the source tasks and the target task, we can rank the source tasks, andthe smaller rank ri means higher weight assigned. We can choose different weight change strategies,for example, Linear Change Strategy in Eq. (7) , Exponential Change Strategy in Eq. (8) or All OneStrategy, i.e., all source task weights are set to be 1, to control the proportion of influencial sourcetasks.",
  "C.3Discussion on Conditional search space": "MCTS-transfer can also be applied in conditional search space, which is common in hyper-parameteroptimization. For conditional optimization, we consider the problem minxXRd f(x). Specifically,the search space is tree-structured, formulated as T = {V, E}, where v V is a node representingsubspace and e E is an edge representing condition. The objective function is also defined basedon T , formulated as fT (x) := fpj,T (x|lj), where pj is a condition and x|lj is the restriction of x tolj . In the pre-learning stage, it builds subtrees for each v V and generates the MCTS modelT based on T . In each iteration, followed by UCB value, it finds the target node m located in thesubtree of v with condition pi, optimizes in m, selects and evaluates the candidate using fpi,T (x|li).After that, it updates the task weights and node potential in the whole tree T and tries to reconstructthe tree. Note that the tree reconstruction only happens in each subtree of v V .",
  "C.4Discussion between the state value in MCTS of AlphaZero and MCTS-Transfer": "MCTS measures state value differently in reinforcement learning and black box optimization. Forexample, AlphaZero is designed to master complex games through self-play without relying onhuman knowledge or guidance. MCTS plays a crucial role in AlphaZeros decision-making process,whose state value is used to predict the expected future reward from the current state to the end,rather than the historical information. Different from that a states future reward of AlphaZero canbe obtained through multi-step simulations, i.e., alternating decisions through self-play, evaluationvalues in BBO can only be obtained through actual evaluations. Consequently, MCTS-transfer utilizeshistorical information. We have observed that some recent look-ahead BO works [52; 53] have beenused to predict the expected value of future steps in BBO problems, which have the potential to beapplied in MCTS-transfer as estimates for state values to further improve the performance.",
  ": Experimental results on mixed real worldproblems (with MCTS-transfer-PFN)": "MCTS-transfer is a general search space trans-fer learning framework, which can be com-bined with other advanced algorithms.Weequip MCTS-transfer with PFN and test MCTS-transfer-PFN on mixed real-world problems. Asshown in , MCTS-transfer-PFN makesfurther improvements compared to MCTS-transfer-GP and PFN after around 80 iterations,and its ranking is stable and excellent through-out the optimization. This result demonstratesthe versatility of MCTS-transfer combining withadvanced BO algorithms.",
  "DSensitivity Analysis of Hyper-parameters of MCTS-transfer": "Main hyper-parameters of MCTS-transfer includes modeling approach, similarity measures, weightassignment strategies, decay factor , important source task ratio , exploration factor Cp, splitingthreshold and the binary classifier. We conduct sensitivity analysis of these important parameterson real-world problems LunarLander, RobotPush, Rover under mixed setting. Modeling approachIn MCTS-transfer, we can choose to train GP on full DT dataset or on theselected points in m. As shown in , the global GP can utilize more global information,demonstrating enhanced search capabilities in these three problems.",
  ": Sensitivity Analysis of Local and Global Modeling Approaches": "Similarity measuresWe propose 5 similarity measures in this paper, including optimal solutionsdistance, best N or N percent solutions mean distance, Kendall coefficient and KL divergence, as C.1displayed. The first three methods are point-based measures and the last three are distribution-basedmethods. Here we set N=5 and N=30% separately for best N solutions and best N percent solutions,and use Gaussian KDE to evaluate KL divergence of distributions. The results can be seen in .The distribution-based methods give more precise measure of similarity, but the point-based methodsare designed to focus on the optimal region. Each problem has its own suitable measure of similarity.In mixed transfer real-world problems, KL divergence is more appropriate to the problem. Optimal solutions distanceBest 30% solutions distanceKL divergence Best 5 solutions distanceKendall coefficient Number of evaluations",
  ": Sensitivity Analysis of Similarity Measures": "Weight assignmentTo assign weights to source tasks, we consider three strategies: linear-changestrategy(i.e., Eq. (7)), the exponential-change strategy (i.e., Eq. (8)) and all-one strategy. We set = 0.5 for linear-change strategy, = 0.5 for exponential-change strategy. As shown in , the exponential-change strategy, since the weight decaying rapidly with the rank, can only effectivelyleverages the 1-3 source datasets. So it tends to have faster convergence speed if the similar tasksare effectively identified at the initial stage, as demonstrated in Rover. The all-one strategy areeasy to be disturbed by dissimilar data but can fully utilize information, so it may have a higherconvergence value at later stage. The linear-change strategy is relatively more stable because it takesthe advantages of the above two strategies into account.",
  ": Sensitivity Analysis of Weight Change Strategy": "Decay factor . The decay factor is used to control the influence of source tasks. A higher decayfactor results in a quicker decay of source tasks influence, thus making the node potential relymore on the target tasks data. However, an excessively rapid decay of source task lead unstableevaluation outcomes and under-utilization of source task data. Specially, for the nodes preferredby source tasks, if they cant be selected as the sampling node at first, their potential will decreaserapidly and these nodes will be less likely to be selected. The analysis experiment of can be seen infigure 10, and the result is as expected. The curves of MCTS-transfer with = 0.99 and = 1.0overlap, better than = 0.1 in most cases, due to data exploitation. And an appropriate decay factorwill help to combine information from source and target tasks to accelerate optimization.",
  ": Sensitivity Analysis of Decay Factor": "Important source task ratio In linear-change strategy, we can set to determine the ratio ofimportant source tasks that have high weights. We choose = 10%, 50% and 100% and he result isshown in . A higher means that more source tasks are influencial on the evaluation ofthe tree node potential. However, this also increases the risk of the interference from dissimilar data.MCTS-transfer with a smaller only trusts the most similar tasks and under-utilizing informationfrom the source task, leading to slower convergence in early stage.",
  ": Sensitivity Analysis of Exploration Factor Cp": "The splitting threshold The threshold controls the depth of the tree: a node is only allowed tobe further divided when it contains more solutions than . A smaller leads to a deeper tree. In ourexperiment (), = 100 means the tree nodes wont be splitted in the optimization, so thesuggesting search space will be bigger, which is less efficient. = 10= 3= 100 Number of evaluations",
  ": Sensitivity Analysis of The Splitting Threshold": "Binary classifierThe binary classifier decides the boundary of good and bad clusters. We trythe following classifiers: Logistic Regression and SVM (with rbf, linear, or poly kernel). Accordingto the results in , SVM with linear kernel and Logistic Regression give more effectivesearch space partition. We can choose a binary classifier with higher partition efficiency according tospecific scenarios.",
  "FDetails of runtime analysis": "In order to analysis the additional computational overhead introduced by MCTS-transfer, we calculatethe time cost and the corresponding proportion of each component, and record the frequency ofsubtree reconstruction in each iteration. Specifically, we divide MCTS-transfer into three main components: evaluation, backpropagationand reconstruction. The evaluation component includes the time required for surrogate model fitting,candidate solution selection and evaluation, which is a common component shared by all comparedoptimization algorithms. Backpropagation and reconstruction components are the two principalmodules specific to MCTS-transfer. We test MCTS-transfer on BBOB benchmark and three real-world tasks (i.e., LunarLander, Robot-Push, and Rover). Among them, the evaluation process of the real-world tasks is more time-consumingand the evaluation cost of BBOB are relatively cheaper. As illustrated in , the additional computational burden introduced by MCTS-transfer(i.e., backpropagation and reconstruction) represents a relatively minor fraction of the total runtime,particularly in the three real-world scenarios. These scenarios precisely exemplify the computationallyintensive cases that transfer BO is designed to address, wherein MCTS-transfer demonstrates smalladditional computational overhead.Furthermore, our result reveals that the average frequency of treereconstructions is low, with the corresponding reconstruction time being almost negligible whencompared to the evaluation time.",
  "GVisualization of Weight Change Curve of Source Tasks": "Here we show the weight change curve of three mixed real-world problems. We set the weightassignment stategy to be the linear change strategy with = 0.5 and the decay factor to be = 0.99. shows that the weights of real-world problem and similar sphere problem exceed thoseof dissimilar sphere problem in most cases, regardless of any inconsistencies in initialization. Theresults prove that the weight change strategy can prioritize similar source task data, which will leadto more accurate node potential evaluation and search space partition.",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-perimental results of the paper to the extent that it affects the main claims and/or conclusionsof the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justification: The detailed information is provided in Appendix B and C.Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible is important, regardless ofwhether the code and data are provided or not.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  ". Experimental Setting/Details": "Question: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand theresults?Answer: [Yes]Justification: The detailed information is provided in Appendix B and C.Guidelines: The answer NA means that the paper does not include experiments. The experimental setting should be presented in the core of the paper to a level of detailthat is necessary to appreciate the results and make sense of them.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [Yes]Justification: The error bars are already shown in figures in paper.Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
  "Guidelines:": "The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  "According to the NeurIPS Code of Ethics, workers involved in data collection, curation,or other labor should be paid at least the minimum wage in the country of the datacollector": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA]Justification: The paper does not involve crowdsourcing nor research with human subjects.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}