{
  "Abstract": "In minimax optimization, the extragradient (EG) method has been extensivelystudied because it outperforms the gradient descent-ascent method in convex-concave (C-C) problems. Yet, stochastic EG (SEG) has seen limited success in C-Cproblems, especially for unconstrained cases. Motivated by the recent progress ofshuffling-based stochastic methods, we investigate the convergence of shuffling-based SEG in unconstrained finite-sum minimax problems, in search of convergentshuffling-based SEG. Our analysis reveals that both random reshuffling and therecently proposed flip-flop shuffling alone can suffer divergence in C-C problems.However, with an additional simple trick called anchoring, we develop the SEGwith flip-flop anchoring (SEG-FFA) method which successfully converges in C-Cproblems. We also show upper and lower bounds in the strongly-convex-strongly-concave setting, demonstrating that SEG-FFA has a provably faster convergencerate compared to other shuffling-based methods.",
  "i=1fi(x, y),(1)": "can be found in many interesting applications, such as generative adversarial networks , refiningdiffusion models , adversarial training , optimal transport based generative models ,multi-agent reinforcement learning , and so on. Deterministic methods for minimax problems,such as gradient descent-ascent (GDA) and extragradient (EG) , have been extensively studiedin the literature. It is though known that, unlike gradient descent (GD) for minimization problems,GDA may diverge even when f is convex on x and concave on y. On the other hand, EG employsa two-step update procedure, named extrapolation and update steps (see for details), whichallows it to find an optimum under this convex-concave setting , and moreover, attains aconvergence rate faster than GDA when f is strongly convex on x and strongly concave on y.",
  "arXiv:2501.00511v1 [cs.LG] 31 Dec 2024": "in the deterministic GDA. To make matters worse, stochastic extragradient (SEG) methods have alsohad limited success on unconstrained convex-concave problems. As we elaborate in inmore detail, existing versions of SEG and their analyses have limitations that hinder its application togeneral unconstrained finite-sum convex-concave problems, requiring additional assumptions such asbounded domain, increasing batch size, convex-concavity of each component fi, uniformly boundedgradient variance, and/or absence of convergence rates. In the context of finite-sum optimization, most of the theoretical studies on stochastic methods havelong been based on the with-replacement sampling scheme, where an index i(t) is independentlyand uniformly sampled among {1, . . . , n} at each iteration t. Such a sampling scheme is relativelyeasy to theoretically analyze, because the sampled fi(t) is an unbiased estimator of the full objectivefunction f. In practice, however, inspired by the empirical observations of faster convergence infinite-sum minimization , the without-replacement sampling schemes have been the de factostandard. Among them, the most popular is the random reshuffling (RR) scheme, where in everyepoch consisting of n iterations, the indices are chosen exactly once in a randomly shuffled order. This gap between theory and practice in minimization problems is being closed by the recentbreakthroughs in stochastic gradient descent (SGD), namely that SGD with RR leads to a provablyfaster convergence compared to with-replacement SGD when the number of epochs is large enough . This has motivated further studies on finding other shuffling-based samplingschemes that can improve upon RR, resulting in the discoveries such as the flip-flop scheme and gradient balancing (GraB) . The flip-flop scheme is a particularly simple yet interestingmodification of RR with improved rates in quadratic problems: a random permutation is used twicein a single epoch (i.e., two passes over n components in an epoch), but the order is reversed in thesecond pass. The aforesaid progress in minimization also triggered the study of stochastic minimax methods withshuffling. Similar to minimization problems, SGDA with RR indeed converges faster than the with-replacement SGDA, under assumptions such as strongly-convex-strongly-concave objectives orf satisfying the Polyak-ojasiewicz condition . Despite the superiority of EG over GDA, theSEG with shuffling has not been shown to have a solid theoretical advantage over the SGDA withshuffling yet. This motivated us to study the following question:",
  "Can shuffling schemes provide convergence guarantees for SEG, improved upon SGDAwith shuffling, in unconstrained finite-sum (strongly-)convex-(strongly-)concave settings?": "There are two types of SEG: same-sample SEG, where a sample chosen is used both for the extrapola-tion step and the update step, and independent-sample SEG, where two independently chosen samplesare used in each step. We will particularly focus on the same-sample SEG because it combinesmore naturally with shuffling-based schemes than independent-sample SEG. Therefore, to be morespecific, we are interested in developing shuffling-based variants of same-sample SEG in uncon-strained finite-sum minimax problems with minimal modifications to the algorithm. We show that(a) in convex-concave settings, our new method reaches an optimum with a guarantee on the rate ofconvergence, overcoming the limitations of existing results; (b) in strongly-convex-strongly-concavesettings, the method converges faster than other SGDA/SEG variants.",
  "Our Contributions": "In this paper, we study various same-sample SEG algorithms under different shuffling schemes, andpropose the stochastic extragradient with flip-flop anchoring (SEG-FFA) method, which is SEGamended with the techniques of flip-flop shuffling scheme and anchoring. Here, by anchoring we referto a step of taking a convex combination between the initial and final iterates of an epoch, resemblingthe celebrated Krasnoselski-Mann iteration as we discuss in . With such minimalmodifications to SEG, we show that SEG-FFA achieves provably improved convergence guarantees.More precisely, our contributions can be listed as follows (see for a summary). For clarity,we use SEG-US to refer to with-replacement SEG, where US stands for uniform sampling.",
  "We first study the same-sample versions of SEG-US, SEG with RR (SEG-RR), and SEGwith flip-flop (SEG-FF). We show that they all can diverge when f is convex-concave,1": "1This does not contradict the result in , which shows that the independent-sample SEG with carefullydesigned step sizes rule converges to optima for convex-concave settings, albeit without a convergence rate. : Summary of upper/lower convergence rate bounds of same-sample SEG for unconstrainedfinite-sum minimax problems, without requiring increasing batch size, convex-concavity of eachcomponent, and uniformly bounded gradient variance. Pseudocode of algorithms can be found inAppendix A. We only display terms that become dominant for sufficiently large T and K. To comparethe with-replacement versions (-US) against shuffling-based versions, one can substitute T = nK. Theoptimality measure used for SC-SC problems is E[z z2] for the last iterate z. For C-C problems,we consider mint=0,...,T E[F zt2] for with-replacement methods and mink=0,...,K E[F zk02] forshuffling-based methods.",
  "K1/3 ) (THM. 5.4)": "show upper bounds for SEG-US, but they require increasing batch sizes as well as other assumptions (see Appendix B.1). shows that independent-sample SEG-US converges for stepsizes t, t decaying at different rates, but gives no conv. rate. Unfortunately, the proof of this convergence bound in this recent AISTATS 2024 paper seems to be incorrect: see Appendix B.4.",
  "by constructing an explicit counterexample (Theorem 4.1). This shows that shuffling alonecannot fix the divergence issue of SEG-US": "We next investigate the underlying cause for the nonconvergence of SEG-US, SEG-RR, andSEG-FF. In particular, we identify that either they fail to match the update equation of thereference method EG beyond first-order Taylor expansion terms, or attempting to match boththe first- and second-order Taylor expansion terms results in divergence (Proposition 5.2). By adopting a simple technique of anchoring on top of flip-flop shuffling, we devise ouralgorithm SEG-FFA, whose epoch-wise update deterministically matches EG up to second-order Taylor expansion terms (Proposition 5.3). We prove that SEG-FFA enjoys improvedconvergence guarantees, as anticipated by our design principle. Most importantly, we showthat SEG-FFA achieves a convergence rate of O(1/K1/3) when f is convex-concave, whereK denotes the number of epochs. This is in stark contrast to other baseline algorithms thatdiverge under this setting (see the last column of ). Moreover, we show that when f is strongly-convex-strongly-concave, SEG-FFA achievesa convergence rate of O(1/nK4) (Theorem 5.5). In addition, by proving (1/nK3) lowerbounds for the convergence rates of SGDA-RR and SEG-RR under the same setting (Theo-rem 5.6), we show that SEG-FFA has a provable advantage over these baseline algorithms.",
  "Related Works": "Extragradient and EG+Extragradient (EG) method is a widely used minimax optimizationmethod, well-known for resolving the nonconvergence issue of GDA on convex-concave problems.In this paper, we also consider EG+ , which is a generalization of EG. The update rule of EG+ isdefined, for stepsizes {1,k}k0 and {2,k}k0, asuk xk 1,kx f(xk, yk)",
  "both the extrapolation and the update steps, we get the same-sample SEG, which we focus on in thispaper; see Appendix A for the pseudocode": "While EG improves upon GDA, unfortunately, SEG has not been able to show a clear advantage overSGDA. On one hand, analyses of SEG on strongly-convex-strongly-concave problems have shownsome success; see, e.g., . Yet, on the other hand, for general unconstrained convex-concaveproblems, to the best of our knowledge, the existing stochastic variants of EG and their analysesface several limitations.23 Assumptions commonly imposed in the existing literature include: (i)the domain is bounded, either explicitly or implicitly , (ii) one must increase the batch sizeto achieve convergence ,4 and (iii) each component fi is convex-concave , and(iv) the components have uniformly bounded gradient variance . For further details, seeAppendix B.1 and therein. Notably, Hsieh et al. prove convergence of the independent-sample SEG without these four restrictions, but the result lacks an explicit convergence rate. Our proposed SEG-FFA overcomes all the aforementioned limitations, and reaches an optimum withan explicit rate in unconstrained convex-concave problems, under relatively mild conditions. Thereaders may also refer to for a comprehensive overview on this topic. Meanwhile, under the finite-sum setting, variance reduction schemes have also been considered,achieving some promising results . Yet, although theoretically appealing, variance reduction isless widely used in practice due to their curiously inferior performance in training neural networks .On top of this practical issue, variance reduction techniques share the aforementioned limitation (ii),as accessing full gradients can be viewed as increasing the batch size. In contrast, our main goal inthis paper is to study how a carefully chosen sampling scheme, with minimal modifications to thealgorithm, can improve the convergence of SEG without the need for increased batch size; therefore,we believe that our work is not directly comparable to variance reduction-based EG. Taylor Expansion Matching and Convergence GuaranteesIt has been repeatedly reported thatthe convergence of an optimization method is deeply related to the degree to which the Taylorexpansion (with respect to the step size) of its update equation matches with that of an already knownconvergent method. For example, Mokhtari et al. observed that the advantage of EG over GDAcomes from the Taylor expansion of update equations of EG matching that of the proximal point (PP)method up to second-order terms, whereas GDA matches PP only up to first-order terms. The advantages of the shuffling scheme over the with-replacement sampling can be explained in asimilar way. One key property of shuffling-based methods is that, while the individual estimators arebiased as they are dependent to other estimators within the same epoch, the overall stochastic erroracross the epoch decreases dramatically compared to using n independent unbiased estimators. Forinstance, in SGD with RR and in SGDA with RR , the overall progress made within eachepoch exactly matches their deterministic counterparts up to the first-order, leaving an error as smallas O(2), where is the stepsize. Rajput et al. observed that, when each component functionsare convex quadratics, then using flip-flop on SGD can reduce the error further to O(3), resulting inan even faster convergence. As we further elaborate in , the motivation behind our designprinciple of SEG-FFA is also based on this line of observations.",
  "The derivative of an operator will be denoted with a prefix D. For example, the derivative of F isdenoted by DF . Often a single vector will be used to denote the minimization and the maximization": "2Most of these results are carried out assuming access to a stochastic oracle of f, which indeed subsumes thefinite-sum setting as a special case. However, it seems unlikely that these limitations of the existing studies willbe easily resolved by simply narrowing the focus down to the finite-sum setting; see Appendix B.3.3Recently, Emmanouilidis et al. claimed the convergence of SEG-RR in the convex-concave setting.Unfortunately, however, there seems to be a flaw in their proof. We defer a discussion on this to Appendix B.4.4In fact, for the methods studied in it is possible to show that increasing the batch size is strictlynecessary and unavoidable for convergence; see Appendix H.2.",
  "If (3) holds for = 0, then we say that F is monotone": "Thus, from now on, we will use the term strongly monotone (respectively, monotone) problems ratherthan strongly-convex-strongly-concave (respectively, convex-concave) problems. Notice that we onlyassume that the full saddle gradient F is (strongly) monotone, not the individual Fis. In addition, we remark that our convergence analysis under the monotonicity of F , Theorem 5.4, infact requires only a relaxed version of monotonicity, known as star-monotonicity. This conditionimposes the inequality (3) with = 0, but only when w = z, where z is a point such thatF z = 0. This relaxation allows for a certain degree of nonconvex-nonconcavity in f. For a moredetailed discussion on the star-monotonicity condition, see Appendix G.1.",
  "for any x Rd1 and y Rd2, exists in Rd1+d2": "Because the problem is unconstrained and f is convex-concave, a point z is an optimum if andonly if F z = 0. For strongly monotone problems, Assumption 3.2 is not explicitly required,as it is guaranteed a priori [5, Proposition 22.11]. For monotone problems, we explicitly imposeAssumption 3.2 in order to exclude pathological problems such as f(x, y) = x y.",
  "nni=1 Fi, it is clear thatAssumption 3.3 implies f being L-smooth and F being M-smooth": "The L-smoothness assumption on the objective functions is standard in the optimization literature,while the M-smoothness assumption on the saddle gradients may look less standard. This smoothnessassumption on the saddle gradient, in other words the Lipschitz Hessian condition, for analyzing SEG-FFA stems from the analysis of the flip-flop sampling scheme . In particular, this is needed forbounding the high-order error terms between the (deterministic) EG and SEG-FFA in .1.The existing analysis of flip-flop sampling is limited to quadratic functions that trivially have0-Lipschitz Hessians (M = 0), so our analysis is a step forward.",
  "i=1Fiz F z2 ( F z + )2z.(4)": "For strongly monotone problems, Assumption 3.4 is not explicitly required, because it can be obtainedas a consequence of the preceding assumptions: see Lemma C.9. Nevertheless, for convenience, wewill keep the notations and as in (4) for the strongly monotone setting as well. In many existing works on stochastic optimization methods for minimax problems, Assumption 3.4with = 0 is imposed. This uniform bound on the variance simplifies the convergence analyses, butit is also fairly restrictive especially in the unconstrained settings. Already for bilinear finite-summinimax problems f(x, y) = 1 nni=1 xBiy, one can easily check that setting = 0 forces thematrices Bi to be exactly equal to each other. For machine learning applications, it has been alsoreported that the assumption with = 0 often fails to hold . Therefore, allowing the variance togrow with the gradient F z makes the assumption much more realistic. The Lipschitz Hessian condition and the component variance assumption for monotone problemsmay still look rather strong. We leave the study on how one can relax such assumptions to proveupper bounds for convergence rates as an interesting future direction. On the other hand, while ourlower bound results in Theorems 4.1 and 5.6 are derived under those strong assumptions, they stillserve as lower bound results also for larger function classes that do not have those assumptions. Inother words, the value of those results are not limited because of those assumptions being imposed.",
  "Under the settings we have discussed, we study the SEG with shuffling-based sampling schemes.First we describe the precise methods of our consideration, namely the SEG-RR and SEG-FF": "For k 0, in the beginning of an epoch, a random permutation k is sampled from a uniformdistribution over Sn. Then, for n iterations, we use each of the component functions once, in theorder determined by k. That is, for i = 0, 1, . . . , n 1 we do",
  "for some stepsizes k and k. In case of SEG-RR, the epoch is completed here, and we setzk+10 zkn as the initial point for the next epoch": "In case of SEG-FF, we additionally perform n more iterations in the epoch, as proposed in Rajputet al. . In these additional iterations, the component functions are each used once more, but in thereverse order. That is, for i = n, n + 1, . . . , 2n 1, we do",
  "Then we set zk+10 zk2n as the initial point for the next epoch. The full pseudocode of these methodscan be found in Appendix A": "When F is strongly monotone, it is possible to show that both SEG-RR and SEG-FF indeed providespeed-up over SEG-US. The well-known rate of SEG-US under strong monotonicity of F is (1/T),where T is the total number of iterations . Translating this rate to our shuffling-based setting,where there are (n) iterations per epoch, this rate amounts to (1/nK). Recently, Emmanouilidiset al. have shown that SEG-RR, under the same setting as ours, attains a convergence rate ofO(1/nK2), on par with the rate of SGDA-RR . In Appendix F, we also show that SEG-FF attainsa similar rate of convergence. However, it turns out that the benefit of shuffling does not extend further beyond the strongly monotonesetting. In fact, when F is merely monotone, then in the worst case, SEG-RR and SEG-FF suffersfrom nonconvergence, just as in the case of SEG-US.",
  "Theorem 4.1. For n = 2, there exists a minimax problem with f(x, y) = 1": "22i=1 fi(x, y) having amonotone F , consisting of L-smooth quadratic fis satisfying Assumption 3.4 with (, ) = (1, 0),such that SEG-US, SEG-RR and SEG-FF diverge in expectation for any positive stepsizes. We provide the explicit counterexample and the proof of divergence in Appendix H.1. Note thatTheorem 4.1 and its proof in Appendix H.1 imply that mint=0,...,T E[F zt2] = (1) for SEG-USand mink=0,...,K E[F zk02] = (1) for SEG-RR and SEG-FF, as summarized in .",
  "SEG-FFA: SEG with Flip-Flop Anchoring": "In this section, we investigate the underlying cause for nonconvergence of SEG-RR and SEG-FFfrom the perspective of how accurately they match the convergent EG or PP methods in terms of theTaylor expansions of updates. We then propose adding a simple anchoring step at the end of eachepoch of SEG-FF. It turns out that adding the anchoring step, which is a step of taking a convexcombination of an iterate with a previously computed iterate, reduces the stochastic noise and leadsto a method with improved convergence properties.",
  "Design Principle: Second-Order Matching": "As observed by , the key feature of EG behind its superior convergence properties compared toGDA is its update rule closely resembling PP, while the error of GDA as an approximation of PP isso large that it hinders convergence. The difference between the updates of EG and PP, in the Taylorexpansion, is as small as O(3) per iteration, where is the stepsize. On the other hand, GDA andPP show a difference of O(2), and this greater error explains why GDA diverges while EG andPP converge. Of course, EG and PP are not the only two algorithms that converge in the monotonesetting; let us recall the update rule of EG+ method , and Taylor-expand it as the following:",
  "EG+ is known to converge for unconstrained monotone problems if 1 2. When 1 = 2, itrecovers EG and matches PP up to second-order terms": "Based on these observations, we now state our key principle for designing a convergent version ofSEG: second-order matching. We would like to choose proper stepsizes, sampling scheme, andanchoring scheme so that our without-replacement SEG can deterministically match the updateequation of a convergent algorithm (EG/PP or EG+) up to the O(2) terms (i.e., second-order termsin the Taylor expansion), thereby satisfying a small O(3) approximation error. We show that (a) thissecond-order matching can be achieved with flip-flop anchoring, but not solely by permutation-basedsampling such as RR and flip-flop (without anchoring), and (b) second-order matching indeed grantsconvergence for monotone problems. In particular, we demonstrate that",
  ". SEG-FFA, the method we propose, matches EG up to second-order terms to get an error ofO(3) (Proposition 5.3), achieving convergence in monotone problems (Theorem 5.4)": "To this end, let us consider a general form of SEG that incorporates any arbitrary sampling scheme.More precisely, in the k-th epoch consisted of N iterations, the components are chosen in the orderof T k0 , T k1 , , T kN1, where T ki {F1, . . . , Fn} for each i. For our purpose, we assume that N issome multiple of n (e.g., N = n for SEG-RR, N = 2n for SEG-FF). Then, given and weperform SEG updates, for i = 0, 1, . . . , N 1,",
  "(11)": "must hold. Clearly, without-replacement sampling will make (10) hold. However, it is easy tocheck that random reshuffling falls short of making (11) hold. This is because, if RR is used, thenT k0 , T k1 , . . . , T kn1 is nothing but a reordering of F1, . . . , Fn into F(1), . . . , F(n), so the RHS of(11) can only contain terms DF(j)(zk0)F(i)zk0 with i j. This observation motivates the use offlip-flop sampling, because choosing T ki = T k2n1i lets all the required terms DFj(zk0)Fizk0 toappear in the RHS of (11).",
  "2zkN + zk0,(12)": "after finishing the N updates (8), instead of zk+10 zkN. This is our Stochastic ExtraGradientwith Flip-Flop Anchoring (SEG-FFA) method, named after the design of combining the flip-flopsampling scheme and the anchoring step. We note that this idea of taking a convex combinationhas originally appeared in the Krasnoselski-Mann iteration , and also under the name ofLookahead methods . This slightly differs from the more widely used Halpern iteration based anchoring (cf. ), which would have used the initial point z00 instead of zk0 in (12). This anchoring step changes (9) accordingly, and essentially amounts to dividing the right-hand sidesof (10) and (11) each by 2 (see Appendix D for the detailed derivations). We show that choosing = /2 in fact leads to the second-order matching to EG, i.e., EG+ with 1 = 2.Proposition 5.3. Suppose that Assumptions 3.3 and 3.4 hold. Then, for k = and k = k/2,SEG-FFA becomes an approximation of EG with error at most O(3). In other words, we achievezk0 nF (zk0 nF zk0) zk+10 = O(3).",
  "Convergence Analysis of SEG-FFA": "As a result of the second-order matching, we obtain SEG-FFA, a stochastic method that has an errorof O(3) as an approximation of EG. Achieving this order of magnitude for the approximation errorturns out to be the key to the exact convergence to an optimum under the monotone setting.Theorem 5.4. Suppose that F is (star-)monotone, Assumptions 3.2, 3.3, and 3.4 hold, and we arerunning SEG-FFA. Then, for any K 1, by choosing the stepsizes sufficiently small and decayingas k = O(1/k1/3 log k) and k = k/2, the iterates generated by SEG-FFA achieves the bound",
  "Theorem 5.5 actually stems from a unified analysis that encompasses all the shuffling-based SEGmethods introduced in this paper, including SEG-RR and SEG-FF. See Appendix F for the details": "Notice the exponent 4 of the number of epochs K in the convergence rate, which is twice as large asthe exponent 2 of SGDA-RR and SEG-RR. In fact, this gain in the rate of convergence turns out tobe fundamental. As we show in the following theorem, the theoretical lower bounds of convergencefor SGDA-RR and SEG-RR with constant stepsize are both (1/nK3). This exhibits that there is aprovable gap between those methods and SEG-FFA, which attains O(1/nK4).Theorem 5.6. Suppose n 2. For both SGDA-RR with constant stepsize k = > 0 andSEG-RR with constant stepsize k = > 0, k = > 0, there exists a -strongly monotoneminimax problem f(z) = 1",
  "Monotone CaseWe ran the experiment on 5 random instances of (13) with the stepsizes scheduledas k = 0/(1+k/10)0.34 where 0 = min{0.01, 1": "L} for SEG-FFA, and k = k = k for SEG-US, SEG-RR, and SEG-FF. The exponent 0.34 is to ensure a sufficient decay rate required byTheorem 5.4, and the convergence of SEG-FFA under such a stepsize scheduling is validated inRemark G.5. The value of 0 is, however, a heuristically determined small number. The results of thegeometric mean over the 5 runs are plotted in . As expected by our theory, SEG-FFA suc-cessfully shows convergence, while all of SEG-FF, SEG-RR, and SEG-US diverge in the long run. Strongly monotone caseAlong with the variants of SEG, we also compare the performances ofSGDA-RR and SGDA-US. We ran the experiment on 5 random instances of (13) with stepsizesk = 0.001, and the results are plotted in . Additional results obtained from using otherstepsizes can be found in Appendix I.4. We again observe an agreement between the empirical resultsand our theory; SEG-FFA eventually finds the point with the smallest gradient norm among themethods that are considered.",
  "SGDA-RRSGDA-US": ": Experimental results on the (left) monotone and (right) strongly monotone examples,comparing the variants of SEG. For a fair comparison, we take the number of passes over the fulldataset as the abscissae. In other words, we plot F zt/202/F z002 for SEG-FFA and SEG-FF, asthey pass through the whole dataset twice every epoch, and F zt02/F z002 for the other methods, asthey pass once every epoch.",
  "Conclusion": "We proposed SEG-FFA, a new stochastic variant of EG that uses flip-flop sampling and anchoring.While being a minimal modification from the vanilla SEG, SEG-FFA attains the crucial second-order matching property to the deterministic EG, leading to a two-fold improved convergence. Onone hand, SEG-FFA reaches an optimum in the monotone setting, unlike many baseline methodssuch as SEG-US, SEG-RR, and SEG-FF that diverge. Moreover, in the strongly monotone setting,SEG-FFA shows a faster convergence with a provable gap from the other methods. An interesting future direction would be to extend our work to more general nonconvex-nonconcaveproblems, further exploring the potentials of the second-order matching technique. It would also beappealing to further study whether it is possible to devise a new method that achieves second-order(or higher) matching without the anchoring step, potentially enhancing our understanding of theeffectiveness of the matching technique.",
  "and Disclosure of Funding": "This work was supported in part by the National Research Foundation of Korea (NRF) grant fundedby the Korea government (MSIT) (No. RS-2019-NR040050). JC and DK acknowledge support fromthe NRF grant (No. RS-2022-NR071715) funded by the Korea government (MSIT), and the SamsungScience & Technology Foundation grant (No. SSTF-BA2101-02). CY acknowledges support fromthe NRF grant (No. RS-2023-00211352) funded by the Korea government (MSIT). Kwangjun Ahn, Chulhee Yun, and Suvrit Sra. SGD with shuffling: optimal rates withoutcomponent convexity and large epoch requirements. Advances in Neural Information ProcessingSystems, 33:1752617535, 2020.",
  "Hanseul Cho and Chulhee Yun. SGDA with shuffling: faster convergence for nonconvex-Pminimax optimization. In The Eleventh International Conference on Learning Representations,2023": "Sayantan Choudhury, Eduard Gorbunov, and Nicolas Loizou. Single-call stochastic extragra-dient methods for structured non-monotone variational inequalities: Improved analysis underweaker conditions. Advances in Neural Information Processing Systems, 36:6491864956,2023. Aniket Das, Bernhard Schlkopf, and Michael Muehlebach. Sampling without replacementleads to faster rates in finite-sum minimax optimization. Advances in Neural InformationProcessing Systems, 35:67496762, 2022.",
  "Aaron Defazio and Lon Bottou. On the ineffectiveness of variance reduced optimization fordeep learning. Advances in Neural Information Processing Systems, 32, 2019": "Jelena Diakonikolas, Constantinos Daskalakis, and Michael I. Jordan. Efficient methods forstructured nonconvex-nonconcave min-max optimization. In International Conference onArtificial Intelligence and Statistics, pages 27462754. PMLR, 2021. Konstantinos Emmanouilidis, Ren Vidal, and Nicolas Loizou. Stochastic extragradient withrandom reshuffling: Improved convergence for variational inequalities. In International Confer-ence on Artificial Intelligence and Statistics, pages 36823690. PMLR, 2024. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, SherjilOzair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neuralinformation processing systems, 27, 2014. Eduard Gorbunov, Hugo Berard, Gauthier Gidel, and Nicolas Loizou. Stochastic extragradient:General analysis and improved rates. In International Conference on Artificial Intelligence andStatistics, pages 78657901. PMLR, 2022. Eduard Gorbunov, Nicolas Loizou, and Gauthier Gidel. Extragradient method: O(1/K) last-iterate convergence for monotone variational inequalities and connections with cocoercivity. InInternational Conference on Artificial Intelligence and Statistics, pages 366402. PMLR, 2022.",
  "Benjamin Halpern. Fixed points of nonexpanding maps. Bulletin of the American MathematicalSociety, 73(6):957961, 1967": "Charles R. Harris, K. Jarrod Millman, Stfan J. van der Walt, Ralf Gommers, Pauli Virtanen,David Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J. Smith, Robert Kern,Matti Picus, Stephan Hoyer, Marten H. van Kerkwijk, Matthew Brett, Allan Haldane, Jaime Fer-nndez del Ro, Mark Wiebe, Pearu Peterson, Pierre Grard-Marchant, Kevin Sheppard, TylerReddy, Warren Weckesser, Hameer Abbasi, Christoph Gohlke, and Travis E. Oliphant. Arrayprogramming with NumPy. Nature, 585(7825):357362, September 2020. Yu-Guan Hsieh, Franck Iutzeler, Jrme Malick, and Panayotis Mertikopoulos.Exploreaggressively, update conservatively: Stochastic extragradient methods with variable stepsizescaling. Advances in Neural Information Processing Systems, 33:1622316234, 2020.",
  "Konstantin Mishchenko, Ahmed Khaled, and Peter Richtrik. Random reshuffling: Simpleanalysis with vast improvements. Advances in Neural Information Processing Systems, 33:1730917320, 2020": "Konstantin Mishchenko, Dmitry Kovalev, Egor Shulgin, Peter Richtrik, and Yura Malitsky.Revisiting stochastic extragradient. In International Conference on Artificial Intelligence andStatistics, pages 45734582. PMLR, 2020. Aleksander M adry, Aleksandar Makelov, Ludwig Schmdit, Dimitris Tsipras, and Adrian Vladu.Towards deep learning models resistant to adversarial attacks. In International Conference onLearning Representations, 2018. Aryan Mokhtari, Asuman Ozdaglar, and Sarath Pattathil. A unified analysis of extra-gradientand optimistic gradient methods for saddle point problems: Proximal point approach. InInternational Conference on Artificial Intelligence and Statistics, pages 14971507. PMLR,2020. Dheeraj Nagaraj, Prateek Jain, and Praneeth Netrapalli. SGD without replacement: Sharperrates for general smooth convex functions. In International Conference on Machine Learning,pages 47034711. PMLR, 2019.",
  "Yurii Nesterov. Lectures on convex optimization, volume 137 of Springer Optimization and ItsApplications. Springer, second edition, 2018": "Lam M. Nguyen, Quoc Tran-Dinh, Dzung T. Phan, Phuong Ha Nguyen, and Marten Van Dijk.A unified convergence analysis for shuffling-type gradient methods. The Journal of MachineLearning Research, 22(1):93979440, 2021. Thomas Pethick, Olivier Fercoq, Puya Latafat, Panagiotis Patrinos, and Volkan Cevher. Solvingstochastic weak Minty variational inequalities without increasing batch size. In InternationalConference on Learning Representations, 2023.",
  "Mikhail V. Solodov and Benar F. Svaiter. A hybrid approximate extragradientproximal pointalgorithm using the enlargement of a maximal monotone operator. Set-Valued Analysis, 7(4):323345, 1999": "Pauli Virtanen, Ralf Gommers, Travis E. Oliphant, Matt Haberland, Tyler Reddy, DavidCournapeau, Evgeni Burovski, Pearu Peterson, Warren Weckesser, Jonathan Bright, Stfan J.van der Walt, Matthew Brett, Joshua Wilson, K. Jarrod Millman, Nikolay Mayorov, AndrewR. J. Nelson, Eric Jones, Robert Kern, Eric Larson, CJ Carey, Ilhan Polat, Yu Feng, Eric W.Moore, Jake VanderPlas, Denis Laxalde, Josef Perktold, Robert Cimrman, Ian Henriksen, E. A.Quintero, Charles R. Harris, Anne M. Archibald, Antnio H. Ribeiro, Fabian Pedregosa, Paulvan Mulbregt, and SciPy 1.0 Contributors. SciPy 1.0: Fundamental Algorithms for ScientificComputing in Python. Nature Methods, 17:261272, 2020.",
  "B.1A Summary of the Limitations of the Existing Works in the Monotone Setting": "In , we have summarized the settings considered in each of the previous works on stochasticvariants of EG discussed in , and compare them with our settings. Please note that we focuson the monotone F setting in the table. Entries that are worth further discussions are marked, withthe corresponding explanations below.",
  "Pethick et al. constant": "(*)The methods proposed in these works are not stochastic variants of EG in a strict sense. Themethod introduced by Cai et al. is rather a hybrid of EG and the Halpern iteration , whilethe method by Choudhury et al. is a stochastic version of the so-called optimistic gradientmethod . Hence, determining whether these methods fall into the category of same-samplemethods or not is unnecessary. Nonetheless, as these works focus on solving a similar problem toours, we include them as references. ()Under the assumptions that Gorbunov et al. make in their paper, one can show that each ofthe components must necessarily be (star-)monotone when the full F is (star-)monotone. For furtherexplanations on why this is the case, see the following Appendix B.2. ()Yet, to be precise, what Gorbunov et al. have shown in the monotone case is that SEG-UScan find an optimal solution if we increase the batch size each iteration. If the batch size is fixed as aconstant, then they were only able to show that the iterates will be bounded in the (star-)monotonesetting. In particular, they did not provide a guarantee that the iterates will be necessarily convergent.",
  "()Hsieh et al. show that independent-sample SEG-US converges for stepsizes t, t decayingat certain different rates, but gives no convergence rates": "()Mishchenko et al. assume a uniformly bounded gradient variance in the strongly monotonecase. In the monotone case, the bound they derived depends on the supremum of the gradient varianceover the domain that is under consideration. Hence, in the monotone case, either the domain has tobe (implicitly) bounded, or the uniform gradient variance assumption should be imposed.",
  "F z, z z z z2 .(14)": "In the notion of -quasi strong monotonicity they also allow 0. In particular, if (14) holdswith = 0, then F is called a star-monotone operator. In Appendix G.1 we further discuss onstar-monotone operators. Meanwhile, let us further elaborate on why in the (star-)monotone setting, the assumptions made bythe authors of lead to each component being star-monotone. In their work the authors require, asequation (10) therein, that1n",
  "i:i<0|i| .(16)": "However, if any of i is strictly negative, then the rightmost sum in (16) becomes strictly positive,hence cannot be less than or equal to if = 0. Therefore, the only possible case is when therightmost sum is an empty sum. In other words, (15) can hold with = 0 only when i 0 for all i,so that each Fi is star-monotone. We would like to remind the readers that our analyses, on the otherhand, do not have any restrictions on the individual components.",
  "B.3Finite Sum Structure vs. General Stochastic Setting": "The works mentioned in usually assume that we have access to a stochastic oracle thatreturns a stochastic estimator of F . Indeed, having a finite sum structure is a special case of having astochastic oracle, as each Fi can be seen as an estimator of F . One might then ask whether assumingthe finite sum structure can help the works mentioned in overcome the mentioned limitations.We strongly believe that this is not the case. Recall Theorem 4.1, where we have constructed anexplicit counterexample that SEG-US, SEG-RR, and SEG-FF all diverge. Because the set ofproblems with a finite sum structure is a subset of the set of problems with a stochastic oracle, the(counter-)example in Theorem 4.1 also works as an example that displays the nonconvergence ofSEG-US, SEG-RR, and SEG-FF in the general stochastic setting. That is, a variant of SEG thatonly modifies the stepsizes and/or the sampling scheme into a without-replacement based one willsuffer from nonconvergence, due to the counterexample in Theorem 4.1. It is also true that there aresome methods that cannot exactly be classified as one of SEG-US, SEG-RR, or SEG-FF, but thiscounterexample demonstrates that, unless explicitly proven otherwise, there is not a good reason tobelieve that the existing convergence analyses will be easily extended beyond the assumptions theyare each based on.",
  "B.4On the Claimed Convergence of SEG-RR in the Monotone Setting by Emmanouilidiset al": "Recently, a paper focusing on the study of SEG-RR has been published. As we have brieflyintroduced in with a discussion in , the authors have established a convergence rateO(1/nK2) of SEG-RR in the strongly monotone setting, using an independent analysis of ours. On the other hand, the authors of furthermore claim that SEG-RR is capable of finding anoptimum in the monotone setting, which is seemingly contradictory to our analyses. We assert thatthis is not the case, as their proof, at least in their AISTATS 2024 version, seems to have a flaw.",
  "Gk zk0": "holds by Jensens inequality, where G 6 is a fixed constant. However, Jensens inequality cannotbe applied here, because not only F ()2 is possibly nonconvex, but also the weights multipliedto the iterates, namely 1/KGk, do not sum up to 1. Hence, the averaged iterate is not in the formof a convex combination. So, even if F ()2 was convex, if we were to properly apply Jensensinequality, at least the averaged iterate should be multiplied by1Kk=0 1/Gk instead of 1",
  "G1 is bounded above by a constant independent of K, and the right hand sideof the equation right above (85) in shall no longer be divided by K. Therefore, their claimedconvergence is unobtainable": "We would also like to remark that the linear decay rate of 1/Gk can make the seriesk=01Gk E[F (zk0)2] convergent even when E[F (zk0)2] grows exponentially as k , aslong as its rate of exponential growth is less than G. In particular, once their (85) is corrected, thereis no contradiction with our divergence result in Theorem 4.1.",
  "a1 + + an2 na12 + + an2": "Proof. We use induction on n. If n = 1 then p1 = 1, so there is nothing to show. For the inductivestep, suppose that the statement holds for some n 1. Say we are given nonnegative scalarsp1, . . . , pn+1 such that p1 + + pn+1 = 1, and vectors a1, . . . , an+1. For the moment, supposethat pn+1 < 1. Applying Lemma C.3 with =pn+1",
  "j=0(1 + aj)": "So, we show that (24) holds, by induction on k. For the base case k = 0, the recurrence relation tellsus thatb0 c0 (1 + a0)d0 d1which is exactly (24) when k = 0. Now suppose that (24) holds for some k 0. Using the inductionhypothesis and the recurrence relation we get",
  "+ (27)": "is performed so that z is used as the initial point of the next epoch. Notice that (27) is a generalizedanchoring step that incorporates all the settings we are considering, as the versions of SEG whereanchoring is not used correspond to taking = 0, and the anchoring step (12) that is used in SEG-FFA corresponds to taking = 1. In this section we would like to prove the following statementregarding this update rule.",
  "(28)for some N = o( + )2": "Proof. Equation (28) immediately follows from Proposition D.2, with (30) giving us the precisedefinition of N. To show that N = o( + )2, we begin with noting that both zj z0 andwj z0 are of O( + ), because both zj and wj are obtained from z0 by performing at mostj updates following (26). Thus, the first term in the right hand side of (30) is of O(( + )2) byLemma C.6, and the remaining terms are of O(( + )3) by the L-smoothness of the operatorsF1, . . . , Fn.",
  "D.2Insufficiency of Only Using Flip-Flop Sampling": "Here we prove the following.Proposition D.3 (Proposition 5.2). Suppose we use flip-flop sampling only. In order to make (10)and (11) hold, we must choose = 1/n and = /2. However, this leads to 2 = 21, which is theset of parameters that fails to make EG+ converge. Proof. Suppose that we have already established the upcoming Lemma D.4. Then, we can see bysetting = 0 in the result of Lemma D.4 that for (11) to hold, the following system of equationsshould be satisfied:",
  "All the upper bounds for SEG-RR, SEG-FF, and SEG-FFA in this paper are established by followingthe two steps below": "The first step is to decompose the cumulative updates made within an epoch by using the method intoa sum of an exact EG update and a within-epoch error term, which we denote by rk. In particular,we show that the error term rk occurring from any of SEG-RR, SEG-FF, and SEG-FFA can beexpressed in a specific unified form (described in Theorem E.1). This will be the main focus of thissection. The second step is establishing a convergence rate that can be applied to any method whose updatecan be decomposed into a sum of an exact EG update and an error term that is of the specific unifiedform mentioned above. By doing so, the convergence rates of SEG-RR, SEG-FF, and SEG-FFAwill automatically follow as special cases of the general convergence result. This step will be dealt inAppendices F and G.",
  "zk+10= zk0 knF (zk0 knF zk0) + rk": "The quality of the method will depend on how small the noise term rk is, as the noise will ingeneral hinder the convergence. As mentioned above, it turns out that, regardless of the method thatis in use, the noise term can be bounded in a unified format, as follows. Theorem E.1. Suppose that Assumptions 3.3 and 3.4 hold. Then, for each of SEG-RR, SEG-FF,and SEG-FFA, there exists a choice of stepsizes that makes the following hold: for an exponent athat depends on the method, there exist constants C1, D1, V1, C2, D2, and V2, all independent of kand n, such that the error term rk satisfies a deterministic boundrk aknaC1F zk0 + aknaD1F zk02 + aknaV1(31)",
  "Furthermore, the exponent is a = 2 for SEG-RR and SEG-FF, and a = 3 for SEG-FFA": "In other words, SEG-FFA has an error that is an order of magnitude smaller than other methods.Thus, it is now intuitively clear that SEG-FFA should have an advantage in the convergence. Theproof of Theorem E.1 is quite long and technical, so we defer it to Appendix E.2. Within the remaining of this section only, although it is an abuse of notation, for convenience we willwrite Fi to denote the saddle gradient of the component function chosen in the ith iteration. Moreprecisely, for indices i = 0, 1, . . . , n 1 we denote F(i+1) by Fi. Similarly, in cases of consideringSEG-FF or SEG-FFA, for i n we denote F(2ni) by Fi. Also, we omit the superscripts andsubscripts denoting the epoch number k unless strictly necessary, as all the iterates that we considerwill be from the same epoch.",
  "E.2Upper Bounds of the Within-Epoch Errors": "The full proof of Theorem E.1 is quite long and technical, so we divide it into several parts. First weshow that (31) and (32) holds with a = 3 when SEG-FFA is in use. Then we show that Theorem E.1also holds for SEG-FF in Appendix E.2.3, and for SEG-RR in Appendix E.2.4.",
  "22n (63)": "where 2n is defined as in (30). Recall that Fi = F2n1i for all i = 0, 1, . . . , 2n 1, and moreover,n1i=0 Fi = 2n1i=n Fi = nF . Thus, the first sum in the above is equal to 2nF z0, and the secondsum is equal to 2 n1j=0 DFj(z0)Fjz0. For the last sum, observe that",
  "r := nF (z0 nF z0) nF z0 + 2n2DF (z0)F z0 + 2n.(80)": "Noticing the resemblence between (62) and the equations in (79) and (80), we can repeat thesame reasoning used for Theorem E.9 and Theorem E.13, but with replacing the bounds given byProposition E.3 to those in Proposition E.4 (and plugging in /2 in place of in the statement ofProposition E.4) to conclude that",
  "0j<kn1DFj(z0)Fkz0": "Let us definer := nF (z0 nF z0) nF z0 + 2n2DF (z0)F z0 + n.(84)Comparing the sums (62b)(62d) to (83), we can repeat the same reasoning used for Theorem E.9and Theorem E.13, but with replacing the bounds given by Proposition E.3 to those in Proposition E.4,to conclude thatr 3n3 C1A F z0 + 3n3 D1A F z02 + 3n3 V1A",
  "When F is -strongly monotone with > 0, all of SEG-RR, SEG-FF, and SEG-FFA do notdiverge. In fact, it is possible to establish the following unified analysis of the methods": "Theorem F.1 (Theorem F.5, simplified). Suppose that F is -strongly monotone with > 0,Assumption 3.3 holds, and an optimization method whose within-epoch error satisfies (31) and (32)for some constant a > 0 is run for K epochs. Then, for a sufficiently small constant that does notdepend on K, we achieve the bound",
  "which is exactly (98). This completes the proof": "Remark F.6. To compare the convergence rate of SEG-FFA in the strongly monotone setting withthat of SEG-RR by Emmanouilidis et al. more in depth, let us make an estimation on the size of appearing in Theorem F.5 when a = 3. To this end, we need estimates on the constants C1A, D1A, V1A, C2A, and D2A. From their definitionsin (59)(61), (72), and (73) we have C1A L2, D1A M, V1A M + L2, C2A L4, andD2A M 2. In general, there is not a direct relation between L and M. For example, recall thatif all components are quadratic, then M = 0. Meanwhile, Gorbunov et al. has argued that Mcan be much larger than L in certain cases, by providing an example where M L3/2. For ourpurposes, however, let us allow M to be even as large as M L2, so that the situation is simplifiedinto C1A D1A V1A L2 and C2A D2A L4.",
  "G.1Star-monotonicity": "Notice that we only used Assumptions 3.3 and 3.4 in deriving the results in Appendices D and E, andin particular, the monotonicity assumption on F was not necessary. Moreover, among the lemmatalisted in Appendix C, Lemma C.10 is the only one that possibly uses the (non-strongly) monotoneassumption, but that lemma is not used in this section. In fact, as it turns out in Appendix G.2, in the convergence analysis of SEG-FFA, we need not fullyexploit the inequality (3) provided by the monotonicity assumption. Rather, all the results on theperformance of SEG-FFA can be established with only assuming the following condition (which hasbeen also briefly mentioned in Appendix B.2).Assumption G.1 (Star-monotonicity). Given an operator F with a point z Rd1+d2 such thatF z = 0, we say that F is star-monotone if, for any z Rd1+d2, it holds that",
  "F z, z z 0.(103)": "Monotone and strongly-monotone operators are clearly star-monotone, as they satisfy (3). On the otherhand, there exist operators that are star-monotone but not monotone: see, e.g., [31, Appendix A.6]. Recall that when F is monotone, Assumption 3.2 is equivalent to assuming the existence of a pointz that satisfies F z = 0. Hence, after simply replacing the optimality condition in Assumption 3.2with F z = 0, our convergence analyses not only will show that our SEG-FFA finds an optimumon monotone problems, but also that it can be also used to find stationary points in star-monotoneproblems, allowing the objective function f to be nonconvex-nonconcave.",
  "which shows that (111) also holds when k is replaced by k + 1. This completes the proof": "Theorem G.4 (Formal version of Theorem 5.4). Let F be a (star-)monotone operator with a pointz that satisfies F z = 0, and suppose that Assumptions 3.3 and 3.4 hold. Say that we are usingSEG-FFA, or any optimization method whose within-epoch error satisfies (58) and (71), withk = k =03",
  ".(120)": "We now claim that, if one accepts a slight sacrifice of the convergence rate from O(1/K1/3) toO (1/K12q) for 1/3 < q < 1/2, one can simply choose the stepsizes as k = 00/(k+1)q for asufficiently small 00. To see why this is the case, let us fix 0 to be a number that satisfies theinequalities (113) and (114). Then, because 00/(k+1)q = o1",
  "H.1Proof of the Divergence of SEG-US, SEG-RR and SEG-FF": "We prove the divergence of SEG-US, SEG-RR and SEG-FF in each proposition below, using thesame worst-case problem for n = 2. These constitute the proof of Theorem 4.1.Proposition H.1 (Part of Theorem 4.1). For n = 2, there exists a convex-concave minimax problemf(x, y) = 1 22i=1 fi(x, y) having a monotone F , consisting of L-smooth quadratic fis satisfyingAssumption 3.4 with (, ) = (1, 0) such that SEG-US diverges in expectation for any choice ofstepsizes {t}t0 and {t}t0. That is, for all t 0,",
  "Ezk+102> Ezk02,EF zk+102> EF zk02": "Proof. The proof uses the same example as Proposition H.1, outlined in (121). We prove thatSEG-FF also diverges for this f. For k 0, the (k + 1)-th epoch of SEG-FF starts at zk0, and thealgorithm randomly chooses a permutation k : [n] [n], as in the case of SEG-RR. The algorithmthen goes through a series of updates for i = 0, . . . , n 1:",
  "H.2Proof of Limited Convergence of SEG-US in Monotone Cases": "In , the authors study the same-sample and independent-sample versions of SEG-US, withstep sizes t and t satisfying a constant ratio: t = t for (0, 1]. While the authors showconvergence in the monotone F case, there is one important limitation shared by the existing analyses.In order to achieve mint=0,...,T E[F zt2] 2 for an arbitrarily chosen , the algorithms mustrepeat the same query to the stochastic gradient oracle b = O( 1",
  ") times at every iteration to reducethe gradient variance from 2 to 2": "b . In other words, the convergence bounds for SEG-US in themonotone case have an additive term O(2) that cannot be reduced to zero by proper choices ofstepsizes. Below, we prove that such a 2 term is in fact inevitable for any choices of stepsizes, if theratio is fixed constant. This indicates that SEG-US considered in the existing results can neverconverge all the way to the optimum if b = 1 is maintained throughout training. In contrast, ourSEG-FFA shows convergence in the monotone case even when b = 1.",
  ", our example f indeed satisfies Assumption 3.4 with (, ) = (0, )": "The proof is outlined as follows. For the example constructed above, we will calculate the E[zt+12]and show that the expectation is identical for both same-sample and independent sample versionsof SEG-US. We will then show that the update on the expected squared distance to equilibriumE[zt+12] for given zt can only belong to two categories: either zt2 E[zt+12] (expectedsquared distance increases) or zt2 E[zt+12] 2 2L (expected squared distance shrinks but isbounded from below by a constant). Since the two cases hold for any t 0 and any choices of t andt = t, we show that the convergence can happen only up to a neighborhood of equilibrium. At iteration t, SEG-US samples component indices i(t), j(t) {1, 2} for its extrapolation step andupdate step, respectively. In the independent-sample version i(t) and j(t) are independently sampledfrom Unif({1, 2}), and in the same-sample version i(t) is sampled uniformly at random and j(t) isset to be equal to i(t). With the indices sampled as above, SEG-US then makes an update",
  "L2 }, and F z = L z for our example f": "The remaining proof is simple, by noticing that zt2 E[zt+12] is equivalent to2ttL2 2t L2(1 + 2t L2)zt2 2t 2(1 + 2t L2).(125)Hence, if t, t, and zt satisfies (125), we belong to the first category. Otherwise, we are in thesecond category, for which we need to additionally show E[zt+12] 2",
  "This finishes the proof": "Remark H.5. We remark that, while Theorem H.4 successfully shows that SEG-US as studied in cannot converge to an optimal point unless the batch size is increased every iteration, it doesnot contradict the (almost sure) convergence result of independent-sample SEG by Hsieh et al. .Indeed, in , the stepsizes {t}t0 and {t}t0 are chosen so that they decay to 0 with a differentrate and hence the corresponding ratio approaches 0, while Theorem H.4 considers the case wheret and t differ by a constant factor .",
  "nK3 )bounds for strongly convex quadratic functions and (1": "nK2 ) bounds for strongly convexnon-quadratic functions . Upper bounds that match the lower bounds in n and K arealso known, indicating that SGD-RR is one of the rare examples of minimization algorithms whosetight convergence rates for quadratic vs. non-quadratic functions differ, within the narrow scopeof strongly convex and smooth functions. While it is tempting to aim for a tighter (1",
  "nK2 ) lowerbound for our algorithms of interest, we note that the existing (1": "nK2 ) bounds for SGD-RR areproven for piecewise-quadratic functions whose Hessian is discontinuous. Since the discontinuousHessian violates our Assumption 3.3, we instead adhere to the quadratic case to prove lower bounds(1 nK3 ) for both SGDA-RR and SEG-RR (when K L/). These bounds may not be the tightestpossible (since they are restricted to quadratics), but they still suffice to demonstrate that SEG-FFAis provably superior to both SGDA-RR and SEG-RR.",
  "H.3.3Proof of Lower Bound for SEG-RR": "In this subsection, we prove the lower bound for SEG-RR. We will first define a new probleminstance f to be used here, and verify that the assumptions in the theorem statement are indeedsatisfied by this new f. We will then spell out the update equation of SEG-RR for this example,which will serve as a basis for the case analysis that follows: we will divide the choices of stepsizes",
  "I.1Problem Constructions for Experiments in": "For an experiment for the monotone case, the random components are sampled as follows. We chooseBi so that each element is an i.i.d. sample from a uniform distribution over the interval , andti so that each element is an i.i.d. sample from a standard normal distribution. We chose Ai to bediagonal matrices in the following procedure: for each j = 1, . . . , 20 we randomly chose a subset Ijof n",
  "(Ai)j,j =2if i Ij2otherwise": "We repeat the exact same procedure for Ci as well. Notice that ni=1 Ai = ni=1 Ci = 0 by design.Hence, each of the component functions will be a nonconvex-nonconcave quadratic function ingeneral, but the objective function itself becomes a convex-concave function. For the experiment in the strongly monotone case, we sample Bi and ti in the same way as in themonotone case, but we use different choices of Ai and Ci to ensure the objective function to bestrongly-convex-strongly-concave. In particular, for each i = 1, . . . , n, we sample Ai by computingAi = QiDiQi , where Di is a random diagonal matrix whose diagonal entries are i.i.d. samplesfrom a uniform distribution over the interval [ 1 2, 1], and Qi is a random orthogonal matrix obtainedby computing a QR decomposition of a 20 20 random matrix whose elements are i.i.d. samplesfrom a standard normal distribution. We sample Ci by the exact same method.",
  "I.2Monotone Case & Ablation Study on the Anchoring Step": "In , we compared the empirical performance of various SEGs, namely SEG-FFA, SEG-FF,SEG-RR, and SEG-US. Here, as an ablation study on the anchoring technique, we additionallycompare SEG-RRA and SEG-USA, which are each SEG-RR and SEG-US with an additionalanchoring step, respectively. For these two methods, we take the anchoring step after every niterations. We ran those methods on the same 5 random instances used in . For both SEG-RRA and SEG-USA, we ran the method with two different stepsize choices, namely k = k = k(inspired by the stepsize used in deterministic EG) and k = k/2 = k/2 (the stepsize used forSEG-FFA) where we again set k = 0/(1+k/10)0.34 with 0 = min{0.01, 1",
  "plot the geometric mean over the 5 runs": "From the performance of SEG-RRA with k = k and the two variants of SEG-USA, it is possibleto observe that adding the anchoring step does improve the performance of the method up to acertain level, but it alone does not fully resolve the nonconvergence issue. On the other hand, quiteinterestingly, SEG-RRA with k = k/2 shows a hint of convergence. While its performance isslightly worse compared to SEG-FFA, it is nonetheless still notable as it is the only other methodfrom SEG-FFA that seems to be capable of converging to an optimum. We conjecture that this intriguing performance of SEG-RRA with k = k/2 is because it achievesan expected second order matching to the (deterministic) EG. Indeed, following the notations ofProposition D.1, one can deduce from Proposition D.1 that using SEG-RRA with = /2 will resultin an epoch-level update of",
  "Comparing this to (7) when 1 = 2 = n/2, we indeed see that the update rule of SEG-RRA with = /2 achieves a second-order matching on expectation to the (deterministic) EG update withstepsize n/2": "We also conjecture that the relatively worse performance of SEG-RRA with = /2 comparedto SEG-FFA is because the error over an epoch is O(3) only on expectation, and thus the actualerror occurring in each epoch can be larger than O(3). Unfortunately, our convergence analysison SEG-FFA relies on the error over an epoch being O(3) deterministically (cf. Proposition 5.3),hence cannot be directly applied to SEG-RRA with = /2. We leave the search for a theoreticalexplanation on this alluring performance of SEG-RRA with = /2 as a stimulating direction forfuture work.",
  "zk+1 zk 2,kFi(2,k)wk": "where i(1, k) and i(2, k) are random indices that are independently drawn from [n] for each k. Thestepsizes are chosen in the form of 1,k = (1/kr1) and 2,k = (1/kr2), where setting r1 r2 isthe key point of DSEG. Two choices of the exponent pair (r1, r2) proposed in are (1/3, 2/3) forgeneral monotone problems and (0, 1) exclusively for the case when F is affine. We again use the same component functions as in the previous experiment. The setup for runningSEG-FFA are kept the same. For DSEG, we use the default choices suggested by Hsieh et al. ,namely 1,k = 0/(k+19)r1 and 2,k = 0/(k+19)r2, where (0, 0) = (1, 0.1) for the bilinear casewith (r1, r2) = (0, 1) and (0, 0) = (0.1, 0.05) for the general case with (r1, r2) = (1/3, 2/3).",
  "I.4Strongly Monotone Case Again, with Various Stepsizes": "We also ran the experiment on strongly monotone problems described in , but with changingthe stepsizes. We tested six different values of k; we have tested with k = a 10b wherea {1, 2, 5} and b {4, 3}. Notice that the case k = 103 is exactly the experiment conductedin . The results are plotted in . The overall details are the same as described in , as theonly difference is the stepsize choice. We can observe that, while the initial speed of convergencemay not be the fastest depending on the stepsize, SEG-FFA is always the method that eventuallyfinds the point with the smallest gradient. In other words, as predicted by our theoretical analyses, thesupremacy of SEG-FFA is in general not affected by the choice of the stepsize, as long as the chosenstepsize is reasonably small. number of passes (t) Fzt02 Fz002 or Fzt/202 Fz002",
  ". Limitations": "Question: Does the paper discuss the limitations of the work performed by the authors?Answer: [Yes]Justification: While we do not have a separate \"Limitations\" sections, in wethoroughly discuss about the assumptions we have imposed. The paper is highly theoretical,hence the other factors listed in the guidelines below are either not applicable to this paper,or apparent from the statements of the theorems/lemmata/propositions and the discussionsthat follow.Guidelines:",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-perimental results of the paper to the extent that it affects the main claims and/or conclusionsof the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justification: In Appendix I, we provide full explanations on how the experiments have beenconducted. We have also submitted the exact code that we used for our experiments as asupplemental material.Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible is important, regardless ofwhether the code and data are provided or not.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example(a) If the contribution is primarily a new algorithm, the paper should make it clear howto reproduce that algorithm.",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited in",
  ". Open access to data and code": "Question: Does the paper provide open access to the data and code, with sufficient instruc-tions to faithfully reproduce the main experimental results, as described in supplementalmaterial?Answer: [Yes]Justification: We have submitted the exact code that we used for our experiments as asupplemental material, so that it becomes revealed to the public once our paper gets accepted.Guidelines:",
  ". Experimental Setting/Details": "Question: Does the paper specify all the training and test details (e.g., data splits, hyper-parameters, how they were chosen, type of optimizer, etc.) necessary to understand theresults?Answer: [Yes]Justification: The overall settings are discussed in Appendix I. The code we submit alongwith the paper is an exact copy of the one we used in the reported experiments, so the detailsnot included in the paper shall be found in the code itself.Guidelines: The answer NA means that the paper does not include experiments. The experimental setting should be presented in the core of the paper to a level of detailthat is necessary to appreciate the results and make sense of them.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [No]Justification: Our paper is mainly theoretical, and the experiments are to demonstratethat our analyses are correct. Hence, we claim that error bars or information about thestatistical significance are not necessary, and rather, the interpretations we made regardingour experiments in the relevant section(s) are enough.Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
  ". Experiments Compute Resources": "Question: For each experiment, does the paper provide sufficient information on the com-puter resources (type of compute workers, memory, time of execution) needed to reproducethe experiments?Answer: [No]Justification: The experiments are numerical validations of our theoretical analyses usingsimple quadratic functions, so they should be executable on any modern computer with areasonable CPU.Guidelines: The answer NA means that the paper does not include experiments. The paper should indicate the type of compute workers CPU or GPU, internal cluster,or cloud provider, including relevant memory and storage.",
  ". Code Of Ethics": "Question: Does the research conducted in the paper conform, in every respect, with theNeurIPS Code of Ethics [Yes]Justification: We have read through the Code of Ethics, but due to the theoretical nature ofthe paper, there are no risks regarding ethical issues.Guidelines: The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. If the authors answer No, they should explain the special circumstances that require adeviation from the Code of Ethics.",
  "Guidelines:": "The answer NA means that the paper poses no such risks. Released models that have a high risk for misuse or dual-use should be released withnecessary safeguards to allow for controlled use of the model, for example by requiringthat users adhere to usage guidelines or restrictions to access the model or implementingsafety filters.",
  "The authors should state which version of the asset is used and, if possible, include aURL": "The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  ". New Assets": "Question: Are new assets introduced in the paper well documented and is the documentationprovided alongside the assets?Answer: [NA]Justification: Our paper provides novel theoretical results rather than datasets or models,hence this question is not applicable.Guidelines: The answer NA means that the paper does not release new assets. Researchers should communicate the details of the dataset/code/model as part of theirsubmissions via structured templates. This includes details about training, license,limitations, etc.",
  "According to the NeurIPS Code of Ethics, workers involved in data collection, curation,or other labor should be paid at least the minimum wage in the country of the datacollector": "15. Institutional Review Board (IRB) Approvals or Equivalent for Research with HumanSubjectsQuestion: Does the paper describe potential risks incurred by study participants, whethersuch risks were disclosed to the subjects, and whether Institutional Review Board (IRB)approvals (or an equivalent approval/review based on the requirements of your country orinstitution) were obtained?Answer: [NA]Justification: This paper does not involve crowdsourcing nor research with human subjects.Guidelines:",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}