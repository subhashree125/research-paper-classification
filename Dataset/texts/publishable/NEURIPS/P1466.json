{
  "Abstract": "This work explores the intersection of continual learning (CL) and differentialprivacy (DP). Crucially, continual learning models must retain knowledge acrosstasks, but this conflicts with the differential privacy requirement of restrictingindividual samples to be memorised in the model. We propose using pre-trainedmodels to address the trade-offs between privacy and performance in a continuallearning setting. More specifically, we present necessary assumptions to enableprivacy-preservation and propose combining pre-trained models with parameter-free classifiers and parameter-efficient adapters that are learned under differentialprivacy. Our experiments demonstrate their effectiveness and provide insights intobalancing the competing demands of continual learning and privacy.",
  "Introduction": "Continual learning (CL, ) develops models that learn from a stream of tasks while retainingprevious knowledge, a key requirement for real-world applications where data arrives sequentially.However, CL faces the challenge of catastrophic forgetting, where the model loses performance onearlier tasks as it learns new ones . While CL fights for memorising prototypical aspects of thedata, the paradigm known as differential privacy (DP, ) aims at not memorising any individualsdata in the first place. DP offers a framework to ensure that the inclusion or exclusion of a singledata point does not significantly impact the outcome of the learning process while providing provableprivacy guarantees. In turn, DP gives means to enable machine learning (ML) models to, e.g., complywith privacy regulations (e.g. GDPR) to ensure personal data is untraceable and mitigating modelinversion attacks . While DP is crucial for privacy-preserving ML, it introduces a trade-off:stronger privacy often degrades model accuracy . Combining CL and DP presents unique challenges to satisfy the demands of mitigating catastrophicforgetting without violating privacy. Prior works have focused on learning how to generate DPsynthetic samples for training the classifier and retaining previous knowledge to circumvent the needto store real data . Lai et al. focus on the privacy loss accumulation when learning manytasks sequentially with an episodic memory . However, these methods either require using DPlearning of additional networks or on the synthetic samples to enable privacy-preservation",
  "in the classifier. Recently, using pre-trained models has been studied separately in DP andCL , but remains to be explored whether this can ease the balance between privacy andperformance over time": "In this work, we explore using pre-trained models that can learn new tasks continually under DP con-straints. We present necessary assumptions to obtain a privacy-preserving CL model, and experimentwith two common approaches in CL with pre-trained models: (i) parameter-free classifiers , and(ii) parameter-efficient adapters . We demonstrate the effectiveness of these methods and provideinsights into how to balance privacy-utility trade-offs in CL under DP.",
  "Related Work": "Differential Privacy In terms of privacy-preserving ML, DP is considered the gold standard toprovide provable privacy guarantees, where the DP-SGD algorithm is the standard learningapproach. The main challenge is the trade-off between privacy and utility, i.e., how to achieve thesame model behaviours and performance as a non-private model without memorising individualdata records. Ensuring privacy in deep learning models has recently gained great interest due to their high utility on large-scale data sets. The usage of pre-trained models has increasedin popularity with most state-of-the-art models relying on theassumption that the pre-training data is public. However, following the discussion of Tramr et al., we utilise pre-trained models trained on pre-training data that is small enough in size as carefullycurating large pre-training data sets is very resource intensive/expensive . If private information iscontained in the pre-trained data, the DP privacy guarantees in regard to the fine-tuning data becomemeaningless. Differentially Private Continual Learning In the intersection of CL and DP, previous works havefocused on continually training classifiers with DP synthetic samples either by training a generativemodel under DP or learn a small set of synthetic samples optimised towards the downstreamtask . However, these methods have only demonstrated results on MNIST or CIFAR-10, possiblysince learning how to generate synthetic samples of a larger size is challenging. Moreover, Lai et al. introduce a formal definition of how to preserve lifelong DP when having episodic memory for mitigating catastrophic forgetting. However, their method requires significant modifications ofthe CL pipeline by also learning an auto-encoder under DP with noise injection that processes whichoutput is passed to the classifier. In this paper, we take a rehearsal-free approach and explore how tocontinually learn DP image classifiers with pre-trained backbones. More specifically, we experimentwith using parameter-free classifiers similar to , as well as using parameter-efficient finetuning(PEFT) adapters with FiLM layers to achieve both DP and good performance.",
  "Methods": "Continual Learning Setting We focus on the continual learning of image classification tasks, wherewe let a model f parameterised by learn T tasks sequentially from the data sets D1, . . . , DT . Wedenote Ct as the set of classes in task t and the total number of classes as C = Tt=1 |Ct|. The tth dataset Dt = {(x(i)t , y(i)t )}Nti=1 consists of Nt samples where x(i)t Rhwc and y(i)t N are the i-thdata point and class label respectively. Note that the data sets are inaccessible in the succeeding tasks.Recently, using pre-trained models as f has gained interest in CL where the task classifiers can be (i)linear layers learned via the cross-entropy loss for new tasks , or (ii) storing class-specific featurevectors and use a parameter-free classifier . Differential PrivacyWe use the definition of DP as presented in Ponomareva et al. : Amechanism A guarantees (, )-differential private if for any two datasets D and D that only differin exactly one example, and for any outcome S Range(A) satisfies",
  "P(A(D) S) exp () P(A(D) S) + ,(1)": "where and 1 are non-negative scalars that control the allowed privacy loss and Range(A) is theset of all possible outcomes of A. Note that smaller values of and correspond to a stronger privacyguarantee. In deep learning, the mechanism A can be the optimisation method (e.g., SGD) whichproduces a parameter set , or the mechanism is the method for computing class-specific featuresfor producing a parameter-free classifier. The most common training approach is using DP-SGD which minimises an empirical loss while clips and adds noise to the per-example gradients to protectprivacy (see for details). Every access of the data D during training accumulates the privacyloss. Thus, the privacy loss is accumulated per training step and the training is stopped when theallowed loss is reached. In a CL context, in addition to learning new tasks, the privacy loss alsoneeds to account for remembering past tasks, e.g., by training a generative model or replaying storedsamples. More background on DP in Appendix A. Assumptions As combining DP into CL settings is challenging, we make the following assumptions:For S1, we assume that the total set of class labels is known. This assumption is necessary under DPas releasing information about which classes have been seen at a task t will leak private informationabout individual samples. In practice, we release the parameters for all classes at every task t,including untrained output heads for future classes and other tasks than t. For S2, we assume that thetask boundaries are non-overlapping and that storing previous samples is forbidden. This simplifiesthe privacy accounting as each task data set Di is independent and only used once. Thus, we can baseour privacy accounting on parallel composition instead of sequential composition whichwould lead to worse privacy-utility trade-off, and possibly more complicated algorithms. Based onthese assumptions, we propose two approaches for enabling DP CL using a pre-trained model: Cosine Similarity Classifier (Algorithm A4) We use the pre-trained model f as a frozen featureextractor without additional training during CL . At each task t, we compute a per-class sum offeatures with the Gaussian mechanism for all classes:",
  "xDt,c f(x) + N(0, I)if c CtxDt,c N(0, I)if c Ct,c Ti=1Ci,(2)": "where N(0, I) is standard Gaussian noise with scale corresponding to the desired (, )-DPprivacy budget, Dt,c are all samples from class c at task t, and Ct is the set of classes for task t. Wecompute the sum-of-features rather than the mean-of-features to avoid the need for countingthe number of examples per class. At test time, we predict the label of a test sample x by assigningthe class label from which the per-class feature sum that x is closest to in the feature space using thecosine similarity:y = arg maxc CosineSimilarity(f(x), sc).(3)",
  "We assume that the features and sums are normalised to unit norm in Equations (2) and (3)1. Notethat we only need to store the per-class sums and the pre-trained model in the memory": "PEFT Ensemble (Algorithm A5) We construct a parameter-efficient fine-tuning (PEFT) ensembleby initialising task-specific output heads gt(u) with parameters t using DP-SGD. Let the featurevector of the pre-trained model be denoted as u = f(x) RK where K is the feature dimension. Inour case, every task-specific head is a mapping gt : K C to the total number of classes C, sincewe must avoid leaking the number of seen classes at task t when releasing the model (see assumptionS2 above). At test time, we predict the label of a test feature u = f(x) by selecting the predictedclass label that has the largest logit across all T heads:",
  "Experiments": "In all experiments, we utilise a ViT-Base-16 (ViT-B) network pre-trained on the ImageNet-21K dataset. We assume that the pre-training data is public and learn tasks with private data setsDt that needs to be protected with DP. All experiments are in the class-incremental learning settingwhere no task labels are available . See Appendix C for full experimental details.",
  "Naive (Lower): We adapt a single output head with DP-SGD by learning all T tasks sequen-tially, which is a lower bound as no means to mitigate catastrophic forgetting are in place (SeeAlgorithm A3)": "Full Data (Upper): We adapt a single output head with DP-SGD with all data from the currentand previous tasks ti=1 Di as an upper bound. While this is DP at each single task, the collectionof models as a whole has weaker DP guarantees (See Algorithm A2)2. Furthermore, the baselinerequires storing all data. Split-CIFAR-100 and Table A1 display the results of our proposed methods in comparisonto the baselines. The PEFT ensemble trains only a linear layer for each task t, as there are onlyminor benefits of using more advanced fine-tuning techniques . The PEFT ensemble outperformsthe other CL methods in all experiments in terms of accuracy and forgetting measure, but requiresstoring T times more parameters than the Cosine Similarity Classifier and is computationally moreexpensive, as it only requires forward passes, whereas the PEFT ensemble relies on DP-SGD.",
  ": Median performance on 5-dataset (ViT-B pre-trained on ImageNet-21k). The error bars arethe min/max accuracies obtained over all ordering permutations when fine-tuning three models per t": "Split ImageNet-R In , we observe that the cosine classifier outperforms the PEFT ensemble,which is based on training a linear layer, for all privacy budgets but = 8, but we see room forimprovement in future work. Our methods perform on-par with prior simple baselines in thenon-DP setting but leveraging a PEFT ensemble with FiLM seems promising. 2Note that when releasing a model at every task t (this is what we would expect in a CL setting), task data isreleased multiple times under DP. The Full Data baseline is still DP with regards to all D, but with a weaker(, )-DP privacy guarantee. E.g., as D1 (data of t = 1) gets released T times under DP.",
  "Discussion and Conclusion": "We present necessary assumptions for DP CL, and introduce two approaches: PEFT Ensemble clearlyworks well in settings where most data for a single class is in a single task, but might suffer if this isnot the case. The cosine similarity classifier is invariant to splitting the data into tasks. Developingflexible methods that work for distributed data configurations is an interesting future challenge.Generalising beyond our assumptions opens new possibilities. Assumption S1 will be very difficultto avoid, but assumption S2 could be circumvented for example by using DP generative models.",
  "and Disclosure of Funding": "This work was supported by the Research Council of Finland Flagship programme Finnish Centerfor Artificial Intelligence FCAI, Research Council of Finland grants 358247 and 339730 as wellas the European Union (Project 101070617). Views and opinions expressed are however thoseof the author(s) only and do not necessarily reflect those of the European Union or the EuropeanCommission. Neither the European Union nor the granting authority can be held responsible forthem. The authors wish to thank the CSC IT Center for Science, Finland for supporting this projectwith computational and data storage resources. We thank Aki Rehn for the helpful discussions.",
  ", 14": "M. Abadi, A. Chu, I. J. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang. Deep learningwith differential privacy. In E. R. Weippl, S. Katzenbeisser, C. Kruegel, A. C. Myers, and S. Halevi,editors, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security,Vienna, Austria, October 24-28, 2016, pages 308318. ACM, 2016. doi: 10.1145/2976749.2978318. URL 2, 3, 10, 11 B. Balle and Y. Wang. Improving the gaussian mechanism for differential privacy: Analytical calibrationand optimal denoising.In J. G. Dy and A. Krause, editors, Proceedings of the 35th InternationalConference on Machine Learning, ICML 2018, Stockholmsmssan, Stockholm, Sweden, July 10-15,2018, volume 80 of Proceedings of Machine Learning Research, pages 403412. PMLR, 2018. URL 3, 12",
  "Y. Bulatov.notMNIST dataset, 2011.URL 4, 14": "Y. Cattan, C. A. Choquette-Choo, N. Papernot, and A. Thakurta. Fine-tuning with differential privacynecessitates an additional hyperparameter search. CoRR, abs/2210.02156, 2022. doi: 10.48550/arXiv.2210.02156. URL 2 A. Chaudhry, P. K. Dokania, T. Ajanthan, and P. H. S. Torr. Riemannian walk for incremental learning: Un-derstanding forgetting and intransigence. In V. Ferrari, M. Hebert, C. Sminchisescu, and Y. Weiss, editors,Computer Vision - ECCV 2018 - 15th European Conference, Munich, Germany, September 8-14, 2018,Proceedings, Part XI, volume 11215 of Lecture Notes in Computer Science, pages 556572. Springer, 2018.doi: 10.1007/978-3-030-01252-6\\_33. URL 13 D. Chen, R. Kerkouche, and M. Fritz.Private set generation with discriminative informa-tion.In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh, edi-tors, Advances in Neural Information Processing Systems 35:Annual Conference on NeuralInformation Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA, November 28- December 9, 2022, 2022.URL 1, 2",
  "S. De, L. Berrada, J. Hayes, S. L. Smith, and B. Balle. Unlocking high-accuracy differentially privateimage classification through scale. ArXiv preprint, abs/2204.13650, 2022. URL 2": "M. De Lange, R. Aljundi, M. Masana, S. Parisot, X. Jia, A. Leonardis, G. Slabaugh, and T. Tuytelaars. Acontinual learning survey: Defying forgetting in classification tasks. IEEE transactions on pattern analysisand machine intelligence, 44(7):33663385, 2021. 1 A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner, M. Dehghani,M. Minderer, G. Heigold, S. Gelly, J. Uszkoreit, and N. Houlsby. An image is worth 16x16 words:Transformers for image recognition at scale.In 9th International Conference on Learning Repre-sentations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net, 2021. URL 3, 13, 14",
  "A. Douillard and T. Lesort. Continuum: Simple management of complex continual learning scenarios,2021. 13": "C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves: Privacy viadistributed noise generation. In S. Vaudenay, editor, Advances in Cryptology - EUROCRYPT 2006,25th Annual International Conference on the Theory and Applications of Cryptographic Techniques, St.Petersburg, Russia, May 28 - June 1, 2006, Proceedings, volume 4004 of Lecture Notes in ComputerScience, pages 486503. Springer, 2006. doi: 10.1007/11761679_29. URL 3, 10",
  "C. Dwork, F. McSherry, K. Nissim, and A. D. Smith. Calibrating noise to sensitivity in private data analysis.J. Priv. Confidentiality, 7(3):1751, 2016. doi: 10.29012/JPC.V7I3.405. URL 1, 2": "S. Ebrahimi, F. Meier, R. Calandra, T. Darrell, and M. Rohrbach. Adversarial continual learning. InA. Vedaldi, H. Bischof, T. Brox, and J. Frahm, editors, Computer Vision - ECCV 2020 - 16th EuropeanConference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XI, volume 12356 of Lecture Notesin Computer Science, pages 386402. Springer, 2020. doi: 10.1007/978-3-030-58621-8\\_23. URL 3",
  "R. M. French. Catastrophic forgetting in connectionist networks. Trends in cognitive sciences, 3(4):128135, 1999. 1": "Q. Gao, C. Zhao, Y. Sun, T. Xi, G. Zhang, B. Ghanem, and J. Zhang. A unified continual learningframework with general parameter-efficient tuning. In IEEE/CVF International Conference on ComputerVision, ICCV 2023, Paris, France, October 1-6, 2023, pages 1144911459. IEEE, 2023. doi: 10.1109/ICCV51070.2023.01055. URL 2 S. Gopi, Y. T. Lee, and L. Wutschitz. Numerical composition of differential privacy. In M. Ranzato,A. Beygelzimer, Y. N. Dauphin, P. Liang, and J. W. Vaughan, editors, Advances in Neural InformationProcessing Systems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS2021, December 6-14, 2021, virtual, pages 1163111642, 2021. URL 10",
  "N. Haim, G. Vardi, G. Yehudai, O. Shamir, and M. Irani. Reconstructing training data from trained neuralnetworks. Advances in Neural Information Processing Systems, 35:2291122924, 2022. 1": "D. Hendrycks, S. Basart, N. Mu, S. Kadavath, F. Wang, E. Dorundo, R. Desai, T. Zhu, S. Parajuli, M. Guo,et al. The many faces of robustness: A critical analysis of out-of-distribution generalization. In Proceedingsof the IEEE/CVF international conference on computer vision, pages 83408349, 2021. 4, 14 N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. de Laroussilhe, A. Gesmundo, M. Attariyan, andS. Gelly. Parameter-efficient transfer learning for NLP. In K. Chaudhuri and R. Salakhutdinov, editors,Proceedings of the 36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019,Long Beach, California, USA, volume 97 of Proceedings of Machine Learning Research, pages 27902799.PMLR, 2019. URL 13 E. J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen. Lora: Low-rankadaptation of large language models. In The Tenth International Conference on Learning Representations,ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net, 2022. URL 13 P. Janson, W. Zhang, R. Aljundi, and M. Elhoseiny. A simple baseline that questions the use of pretrained-models in continual learning. CoRR, abs/2210.04428, 2022. doi: 10.48550/ARXIV.2210.04428. URL 2, 3, 4, 12, 14 A. Koskela, J. Jlk, and A. Honkela. Computing tight differential privacy guarantees using FFT. InS. Chiappa and R. Calandra, editors, The 23rd International Conference on Artificial Intelligence andStatistics, AISTATS 2020, 26-28 August 2020, Online [Palermo, Sicily, Italy], volume 108 of Proceedings ofMachine Learning Research, pages 25602569. PMLR, 2020. URL 10 A. Koskela, J. Jlk, L. Prediger, and A. Honkela. Tight differential privacy for discrete-valued mechanismsand for the subsampled gaussian mechanism using FFT. In A. Banerjee and K. Fukumizu, editors, The24th International Conference on Artificial Intelligence and Statistics, AISTATS 2021, April 13-15, 2021,Virtual Event, volume 130 of Proceedings of Machine Learning Research, pages 33583366. PMLR, 2021.URL 10",
  "A. Kurakin, S. Chien, S. Song, R. Geambasu, A. Terzis, and A. Thakurta. Toward training at imagenet scalewith differential privacy. CoRR, abs/2201.12328, 2022. URL 2": "P. Lai, H. Hu, H. Phan, R. Jin, M. T. Thai, and A. M. Chen. Lifelong DP: consistently bounded differentialprivacy in lifelong machine learning. In S. Chandar, R. Pascanu, and D. Precup, editors, Conferenceon Lifelong Learning Agents, CoLLAs 2022, 22-24 August 2022, McGill University, Montral, Qubec,Canada, volume 199 of Proceedings of Machine Learning Research, pages 778797. PMLR, 2022. URL 1, 2",
  "H. Mehta, A. G. Thakurta, A. Kurakin, and A. Cutkosky. Towards large scale transfer learning fordifferentially private image classification.Trans. Mach. Learn. Res., 2023, 2023.URL 2": "S. I. Mirzadeh, M. Farajtabar, D. Gorur, R. Pascanu, and H. Ghasemzadeh. Linear mode connectivity inmultitask and continual learning. In International Conference on Learning Representations, 2021. 4, 13 P. K. Mudrakarta, M. Sandler, A. Zhmoginov, and A. G. Howard. K for the price of 1: Parameter-efficientmulti-task and transfer learning. In 7th International Conference on Learning Representations, ICLR2019, New Orleans, LA, USA, May 6-9, 2019. OpenReview.net, 2019. URL 13 Y. Netzer, T. Wang, A. Coates, A. Bissacco, B. Wu, and A. Y. Ng. Reading digits in natural images withunsupervised feature learning. In NIPS Workshop on Deep Learning and Unsupervised Feature Learning,2011. 4, 14 A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen, Z. Lin, N. Gimelshein,L. Antiga, A. Desmaison, A. Kpf, E. Z. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy,B. Steiner, L. Fang, J. Bai, and S. Chintala. Pytorch: An imperative style, high-performance deeplearning library. In H. M. Wallach, H. Larochelle, A. Beygelzimer, F. dAlch-Buc, E. B. Fox, andR. Garnett, editors, Advances in Neural Information Processing Systems 32: Annual Conference onNeural Information Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,Canada, pages 80248035, 2019. URL 10, 13 M. Patacchiola, J. Bronskill, A. Shysheya, K. Hofmann, S. Nowozin, and R. E. Turner. Contextualsqueeze-and-excitation for efficient few-shot image classification. In S. Koyejo, S. Mohamed, A. Agarwal,D. Belgrave, K. Cho, and A. Oh, editors, Advances in Neural Information Processing Systems 35: AnnualConference on Neural Information Processing Systems 2022, NeurIPS 2022, New Orleans, LA, USA,November 28 - December 9, 2022, 2022. URL 13 M. Pelikan, S. S. Azam, V. Feldman, J. H. Silovsky, K. Talwar, and T. Likhomanenko. Federatedlearning with differential privacy for end-to-end speech recognition. CoRR, abs/2310.00098, 2023. doi:10.48550/ARXIV.2310.00098. URL 2 E. Perez, F. Strub, H. de Vries, V. Dumoulin, and A. C. Courville. Film: Visual reasoning with a generalconditioning layer. In S. A. McIlraith and K. Q. Weinberger, editors, Proceedings of the Thirty-SecondAAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of ArtificialIntelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial Intelligence(EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018, pages 39423951. AAAI Press, 2018. URL 2, 3, 13 N. Ponomareva, H. Hazimeh, A. Kurakin, Z. Xu, C. Denison, H. B. McMahan, S. Vassilvitskii, S. Chien,and A. G. Thakurta. How to dp-fy ML: A practical guide to machine learning with differential privacy. J.Artif. Intell. Res., 77:11131201, 2023. doi: 10.1613/JAIR.1.14649. URL 1, 2, 3 A. Rajkumar and S. Agarwal. A differentially private stochastic gradient descent algorithm for multipartyclassification. In N. D. Lawrence and M. A. Girolami, editors, Proceedings of the Fifteenth InternationalConference on Artificial Intelligence and Statistics, AISTATS 2012, La Palma, Canary Islands, Spain,April 21-23, 2012, volume 22 of JMLR Proceedings, pages 933941. JMLR.org, 2012. URL 2, 10 S.-A. Rebuffi, A. Kolesnikov, G. Sperl, and C. H. Lampert. icarl: Incremental classifier and representationlearning. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages20012010, 2017. 3, 12 O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bern-stein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. InternationalJournal of Computer Vision (IJCV), 115(3):211252, 2015. doi: 10.1007/s11263-015-0816-y. 3, 13 A. Shysheya, J. Bronskill, M. Patacchiola, S. Nowozin, and R. E. Turner. FiT: parameter efficient few-shot transfer learning for personalized and federated image classification. In The Eleventh InternationalConference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net,2023. URL 3, 13 S. Song, K. Chaudhuri, and A. D. Sarwate. Stochastic gradient descent with differentially private updates.In IEEE Global Conference on Signal and Information Processing, GlobalSIP 2013, Austin, TX, USA,December 3-5, 2013, pages 245248. IEEE, 2013. doi: 10.1109/GlobalSIP.2013.6736861. URL 2, 10",
  "D. Thiel. Identifying and eliminating csam in generative ml training data and models. Technical report,Technical Report. Stanford University, Palo Alto, CA., 2023. URL 2": "R. Tito, K. Nguyen, M. Tobaben, R. Kerkouche, M. A. Souibgui, K. Jung, L. Kang, E. Valveny, A. Honkela,M. Fritz, and D. Karatzas. Privacy-aware document visual question answering. CoRR, abs/2312.10108,2023. doi: 10.48550/ARXIV.2312.10108. URL 2 M. Tobaben, A. Shysheya, J. Bronskill, A. Paverd, S. Tople, S. Z. Bguelin, R. E. Turner, and A. Honkela.On the efficacy of differentially private few-shot image classification. Transactions on Machine LearningResearch, 2023. ISSN 2835-8856. URL 2, 3, 4,13, 14 F. Tramr, G. Kamath, and N. Carlini. Position: Considerations for differentially private learning withlarge-scale public pretraining. In Forty-first International Conference on Machine Learning, ICML 2024,Vienna, Austria, July 21-27, 2024. OpenReview.net, 2024. URL 2",
  "L. Wang, X. Zhang, H. Su, and J. Zhu. A comprehensive survey of continual learning: theory, method andapplication. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2024. 1": "Z. Wang, Z. Zhang, S. Ebrahimi, R. Sun, H. Zhang, C.-Y. Lee, X. Ren, G. Su, V. Perot, J. Dy, et al.Dualprompt: Complementary prompting for rehearsal-free continual learning. In European Conference onComputer Vision, pages 631648. Springer, 2022. 2, 4, 14 Z. Wang, Z. Zhang, C. Lee, H. Zhang, R. Sun, X. Ren, G. Su, V. Perot, J. G. Dy, and T. Pfister. Learning toprompt for continual learning. In IEEE/CVF Conference on Computer Vision and Pattern Recognition,CVPR 2022, New Orleans, LA, USA, June 18-24, 2022, pages 139149. IEEE, 2022. doi: 10.1109/CVPR52688.2022.00024. URL 2",
  "H. Xiao, K. Rasul, and R. Vollgraf. Fashion-mnist: a novel image dataset for benchmarking machinelearning algorithms. CoRR, abs/1708.07747, 2017. URL 4, 14": "Z. Xu, Y. Zhang, G. Andrew, C. A. Choquette-Choo, P. Kairouz, H. B. McMahan, J. Rosenstock, andY. Zhang. Federated learning of gboard language models with differential privacy. In S. Sitaram, B. B.Klebanov, and J. D. Williams, editors, Proceedings of the The 61st Annual Meeting of the Association forComputational Linguistics: Industry Track, ACL 2023, Toronto, Canada, July 9-14, 2023, pages 629639.Association for Computational Linguistics, 2023. doi: 10.18653/V1/2023.ACL-INDUSTRY.60. URL 2",
  "J. Yoon, D. Madaan, E. Yang, and S. J. Hwang. Online coreset selection for rehearsal-based continuallearning. In International Conference on Learning Representations, 2022. 4, 13": "A. Yousefpour, I. Shilov, A. Sablayrolles, D. Testuggine, K. Prasad, M. Malek, J. Nguyen, S. Gosh,A. Bharadwaj, J. Zhao, G. Cormode, and I. Mironov. Opacus: User-friendly differential privacy library inpytorch. ArXiv preprint, abs/2109.12298, 2021. URL 10, 13 D. Yu, S. Naik, A. Backurs, S. Gopi, H. A. Inan, G. Kamath, J. Kulkarni, Y. T. Lee, A. Manoel, L. Wutschitz,S. Yekhanin, and H. Zhang. Differentially private fine-tuning of language models. In The Tenth InternationalConference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net,2022. URL 2",
  "A.1.1Privacy Accounting": "DP-SGD introduces a trade-off between privacy and utility. Stronger privacy guarantees requireintroducing more noise, which proportionately degrades model accuracy. (, )-DP has a privacybudget consisting of 0 and , where smaller values of each correspond to a strongerprivacy guarantee. The privacy guarantee of a DP-SGD run is based on the hyper-parameters used for running DP-SGDand can be quantified using privacy accountants . The following hyper-parameters havean influence on the privacy guarantee of DP-SGD:",
  "Noise multiplier 2: A higher noise multiplier 2 results in a higher privacy guarantee": "The learning rate does not influence the privacy guarantee as it only scales the final update that isalready DP. The clipping bound C is an important hyperparameter in DP-SGD but it is not influencingthe privacy guarantee as a higher clipping bound C will also lead to more noise being added to theaggregation the gradient as can be seen in line 8 of Algorithm A1. One needs to adjust the clippingbound C in a way that not too much information is lost due to the clipping of gradients but at thesame time not too much noise is added to aggregate.",
  "xDt,c N(0, I)if c Ct,c Ti=1Ci,(A1)": "where N(0, I) is standard Gaussian noise with scale corresponding to the desired (, )-DPprivacy budget, Dt,c are all samples from class c, and Ct is the set of classes for task t. We computethe sum-of-features rather than the mean-of-features to avoid the need for counting thenumber of examples per class. At test time, we predict the label of a test sample x by assigning theclass label from which the per-class feature sum that x is closest to in the feature space using thecosine similarity:y = arg maxc CosineSimilarity(f(x), sc).(A2)We assume that the features and sums are normalized to unit norm in Equations (2) and (3). Note thatwe only need to store the per-class sums and the pre-trained model in the memory.",
  "B.4PEFT Ensemble": "We construct an parameter-efficient fine-tuning (PEFT) ensemble by training a model Mt on the dataset Dt contained in task t using DP-SGD and storing all the models. Note that under DP the width ofthe final layer needs to be constant, as otherwise the number of classes seen at a task t will be leaked.At test time, we predict the label of a test sample x by assigning the class label from which the logitis the largest:y = arg maxc,t Mt(x).(A3) Note while we need to store all models, this can be done storage efficiently with parameter-efficientfine-tuning with adaptation methods such as LoRA when only the adapter weights, the finalclassification layer and the pre-trained model need to be stored.",
  "CExperimental Details": "Pre-trained ModelThroughout all experiments, we utilise a Vision Transformer VIT-Base-16(VIT-B) with 85.8M parameters, pretrained on the ImageNet-21K dataset. We assume thatthe pre-training data (ImageNet-21K) is public, and the downstream data D is private and needs tobe protected with DP. We set the weights of the last linear layer of the ViT-B to zero and alwayslearn them when fine-tuning on D. Additionally, we employ parameter-efficient fine-tuning in someexperiments by learning FiLM layers. Although there are many other such adapters such asModel Patch , LoRA , CaSE etc., we chose FiLM as it has proven to be highly effectivein prior works on (DP) parameter-efficient few-shot transfer learning . We implement ourmethods using PyTorch , tensorflow datasets , continuum , and opacus .",
  "Split CIFAR-100: Split CIFAR-100 which is CIFAR-100 split into 10 tasks with 10classes/task. We randomly permute the class order for each seed we run": "5-Datasets: This data set concatenates the five 10-class data sets, MNIST , SVHN ,notMNIST , FashionMNIST and CIFAR-10 . Each data set is considered a task, suchthat there are 5 tasks with 10 classes/task. We run experiments with all permutations of the tasks. Split ImageNet-R: This data set consists 30,000 images of renditions (art, cartoons, etc.) of200 ImageNet classes and was introduced by Wang et al. as a benchmark for CL withpre-trained models. As in , we split the classes into 10 tasks with 20 classes/task. We makea random 80/20% train/test split across the whole dataset. The samples per class are imbalanced inthe original data set, and we obtain a 41-334 samples/class in our training sets with our split.",
  "C.1Hyperparameters": "We tune the hyperparameters of DP-SGD for each combination privacy budget (, ) and seed onceand use them for the PEFT Ensemble, Full Data Baseline and Naive Baseline for all data sets. Whilethis provides us with reasonable results, we believe that future work should tune the hyperparametersmore carefully to obtain better trade-offs between privacy and utility.",
  "MethodAA ()AF ()AA ()AF ()AA ()AF ()": "Naive15.93 1.350.85 0.0517.56 1.350.90 0.0213.15 5.840.79 0.12Cosine classifier58.54 0.350.01 0.0059.78 0.070.00 0.0059.87 0.000.00 0.00PEFT Ensemble79.69 3.510.05 0.0487.83 0.000.03 0.0265.75 15.070.14 0.11 The drop in performance for non-DP PEFT on the 5-dataset is something to investigate in futurework. One would expect that non-DP always performs better than DP, but this is not the case for the5-dataset experiment with the PEFT Ensemble. Without CL the individual models that are formingthe PEFT Ensemble are performing better without DP than with DP (see Figure A.1), but in theensemble this is not the case as can be seen in ."
}