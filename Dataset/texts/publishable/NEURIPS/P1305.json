{
  "Abstract": "Embedding models are crucial for tasks in Information Retrieval (IR) and semanticsimilarity measurement, yet their handling of longer texts and associated positionalbiases remains underexplored. In this study, we investigate the impact of contentposition and input size on text embeddings. Our experiments reveal that embeddingmodels, irrespective of their positional encoding mechanisms, disproportionatelyprioritize the beginning of an input. Ablation studies demonstrate that insertionof irrelevant text or removal at the start of a document reduces cosine similaritybetween altered and original embeddings by up to 12.3% more than ablations at theend. Regression analysis further confirms this bias, with sentence importance de-clining as position moves further from the start, even with with content-agnosticity.We hypothesize that this effect arises from pre-processing strategies and chosenpositional encoding techniques. These findings quantify the sensitivity of retrievalsystems and suggest a new lens towards embedding model robustness.*",
  "Introduction": "Embedding models are increasingly used to encode text in critical applications like document searchsystems. However, their effectiveness diminishes when dealing with long-context inputs, particularlyin larger documents that cannot entirely fit into these models context windows. To address theselimitations, techniques such as document chunking are used to segment large documents into smallerpieces of text as model inputs . Despite its utility, research into optimal chunking strategies isstill an emerging field and improvements can often be highly domain-specific or underexplored inpractical environments. . In this study, we investigate the influence of content position and input size on the resulting textembedding vector from eight embedding models. Our findings reveal a systematic bias in whichembedding models, regardless of their positional encoding mechanisms, disproportionately weigh thebeginning of a text input. This results in greater importance being assigned to the initial sentencesof multi-sentence or long-context inputs. To demonstrate this, we conducted two types of ablationstudies: one involving the insertion of irrelevant text (\"needles\") at different positions in the document",
  "arXiv:2412.15241v3 [cs.CL] 1 Jan 2025": ", and another involving the removal of varying text chunks. We observe that inserting irrelevanttext at the beginning of a document reduces the cosine similarity between the altered and originaldocument embeddings by up to 8.5% more than when inserted in the middle, and 12.3% more thanwhen inserted at the end. Similarly, removal experiments show that the largest decreases in similarityoccur when text is removed from the beginning of the document. To further explore this bias, we employ regression analysis to measure sentence-level importance ona complete document-level embedding, isolating model position bias from human writing patterns.Our analysis shows a significant decline in regression coefficients as the sentence position movesfurther from the beginning of the document, reinforcing the bias toward earlier content. To ruleout dataset-specific effects, we repeat all experiments with randomly shuffled sentences and obtainsimilar results, confirming that this bias arises from the models internal mechanisms rather thandocument structure. We hypothesize that this bias stems from common pre-processing strategies, particularly truncation,used during training when the input exceeds the models context window . This has importantimplications for real-world retrieval tasks, where documents with key information located later in thetext may be overlooked due to the models disproportionate weighting of early content . We conclude by discussing the broader implications of these biases in embedding models andhighlight the need for future research to develop methods that can better handle the entirety oflong-context inputs without disproportionately prioritizing the beginning.",
  "Bidirectional encoding in embedding models": "Embedding models, particularly those utilizing transformer encoder architectures , employ layersof bidirectional self-attention blocks to process text . These models are distinct from decodersin that they generate a fixed-length vector representing the entire input text. This is achieved byproducing an output matrix L D (where L is the sequence length and D is the dimensionality ofthe embeddings), and then applying either mean or max pooling across the L dimension . Suchpooling operations are position-invariant, theoretically suggesting an unbiased treatment of inputpositions in terms of attention and representation . We use cosine similarity to compare the output embeddings from these models, especially to study theeffects of textual modifications such as insertions or deletions. Cosine similarity measures the cosineof the angle between two vectors, thus providing a scale- and orientation-invariant metric to assessthe similarity between two text representations . Due to the invariance of the architecture andsimilarity measurement we employ, the last systematic source of bias stems from learned positionalembeddings used in our models and the models training methodology, which are heavily connected.",
  "Positional Encoding Techniques": "Absolute Positional Embedding (APE) assigns fixed position-specific vectors based off of positionid to each token embedding. This was first popularized by BERT and remains the most commontechnique to add positional information in encoder-style models today. Rotary Positional Embedding (RoPE): RoPE encodes positions by applying a rotation to eachtokens embedding in the 2D subspaces of the embedding space. For each embedding vector x, itapplies a rotation matrix R() based on the position pos:",
  "100002i/d , i indexes the embedding dimensions, and d is the dimensionality": "3. Attention with Linear Biases (ALiBi): ALiBi introduces a relative bias into the attention scoresrather than modifying the embeddings. The bias is linear with respect to the distance between tokens.The attention score A(i, j) between token i and token j is modified by adding a bias term m(|i j|),where |i j| is the distance between tokens:",
  "Noise from Document Chunking for IR Tasks": "In practical applications, documents often exceed the context length capabilities of embedding models,necessitating chunking strategies like naive, recursive, or semantic chunking . This processdivides a document into smaller pieces that fit within a models context window, then embeds eachchunk separately for insertion into a vector database and downstream use in Retrieval-AugmentedGeneration (RAG) tasks. This causes an unintentional, outsized amount of noise in the beginningand end of documents as a function of selected chunking strategies.",
  "Embedding Models Robustness": "The performance of decoder models has been shown to vary significantly with the position ofcontent within the models context window, with pronounced degradation observed for inputs thatexceed the context length seen during training . Positional encoding methods have been studiedto address these challenges from both decreasing the effect of content position within trainingcontext length, and generalizing to longer contexts from itself. However, these works exhibitlimitations: The former provides limited analysis of diverse encoding mechanisms, and the latteremphasizes generalization to longer inputs rather than robustness to positional shifts. Moreover, both studies focus exclusively on decoder-only architectures, whose causal attention maskprovides the ability for the model to generalize without explicit positional information itself,and remains underexplored as a research direction. Existing work on embedding model robustnesspredominantly centers on improving training data quality or diversity, with relatively littleattention paid to architectural components such as positional encoding mechanisms.",
  "Experimental setup": "We investigate the impact of adding irrelevant or adversarial text (\"needle\") to a document. Afterinserting the needle, we generate a new embedding for the altered text and compare it to the originalusing cosine similarity. We vary the needles length (5%, 10%, 25%, 50%, and 100% of the originaltexts token count) and position (beginning, middle, end) across 15 experimental conditions. We usean extended version of Lorem Ipsum placeholder text that exceeds the length of our longestdatapoint and is structured in paragraph format to achieve a needle with structural similarity to ourdata while avoiding a confounding effect on the embedding model. In a parallel experiment, we remove portions of text (10%, 25%, 50% of sentences, rounded up) fromdifferent positions (beginning, middle, end) in the document. The resulting text is then embedded,and its similarity to the original embedding is measured using cosine similarity. We test variousmodels, segmented by their positional encodings, to demonstrate the consistency of our results acrossmultiple popular embedding models. We used six open-source models utilizing various positionalencoding methods - BGE-m3 and E5-Large-V2 using APE; Nomic-Embed-Text-v1.5 and E5-RoPE base using RoPE; and Jina-Embeddings-v2-Base and Mosaic-Bert-Base(sequence length 1024) using ALiBi. We additionally test Coheres Embed-English-v3.0 due to their popularity and real-world applicability. Although we picked these models due to theirvarying positional encoding methods and performance, we acknowledge these may not generalizeto other architectures and datasets. Context lengths or additional information such as parameter counts or benchmark performance for these models can be found in Appendix A. For texts exceedingthese limits, we truncate from the end to fit the models context windows. For datasets, we use200 examples each from the PubMed Publications , Paul Graham Essay Collection , AmazonReviews , Argumentative Analysis , and Reddit Posts datasets, selected for their range ofwriting categorizations and lengths. More details on these datasets can be found in appendix B.",
  ": Cosine similarity vs. needle size and position": "Our results indicate a pronounced drop in similarity when irrelevant text is inserted at the beginningof documents, with less impact observed when additions occur in the middle or end. Specifically, forAPE models, introducing an insertion equal to 20% of the total content at the beginning results in anaverage cosine similarity of 0.885, compared to 0.963 at the enda relative decrease of approximately8%. RoPE-based models show a stronger sensitivity to this disruption, with cosine similarity droppingto 0.819 at the beginning, a 15.4% decrease compared to the 0.968 similarity at the end. By contrast,AliBi models are the most robust, maintaining a high cosine similarity of 0.981 at the beginning and0.999 at the end, reflecting only a 1.8% decrease. This suggests that earlier positions in the inputsequence play a more critical role in model performance, and different positional encoding methodsvary in their resilience to this type of input perturbation. This trend persists across all insertion sizes, with larger insertions intensifying the drop in similarity.Even though the magnitude of the degradation varies by model, we find the trend robust to modeldifferences. Across all five models tested, the average decrease in cosine similarity is approximately7%, indicating a consistent pattern of sensitivity to input alterations at the beginning of the sequence. Additionally, we observe that removal ablations yield similar results, although the overall similarityscores are higher in comparison to insertion ablations. This suggests that while the models areaffected by both insertion and removal disruptions, the impact of irrelevant insertions at the beginningof sequences may introduce greater noise into the representations. Similar trends are observed in the removal experiments, where the largest impacts on similarityoccur when sentences are removed from the beginning. Removing half of the sentences from thebeginning results in a median similarity that is 10.6% lower than when sentences are removed fromthe end, with no significant difference between middle and end removalsunlike the insertionexperiments. Interestingly, even a 50% text removal from the middle maintains a median similarityof 95%, corroborating our findings from the insertion experiments, where a large drop in similaritywas expected but not observed. These results suggest that while the position of removed content hasa clear impact, it is somewhat less disruptive than insertions.",
  "Analysis of embedding decomposition": "Recent advancements in embedding interpretability have demonstrated that certain dimensions inhigh-dimensional semantic spaces may correspond to specific linguistic or semantic features, such assentiment or subject matter . Further research has shown that vector operations, such as addingembeddings, can produce new vectors that represent the semantic meaning of their components . Building from these works, we explore the impact of sentence-level positioning on the final documentembedding vector through regression analysis, which offers a more direct method to quantify thecontribution of individual sentences to a documents embedding representation. Human writing often emphasizes key information at the beginning and end of documents, a techniquethat may introduce biases in datasets and reason for embeddings to skew towards these positions. Toaddress these, we employ additional data augmentation and ablation techniques aimed at isolatingand understanding these effects, to ensure that our findings more accurately reflect model behaviorrather than dataset peculiarities.",
  "Reconstructing embedding vectors through linear combinations of constituents": "To start, we wanted to validate the assumption that the sentence embeddings of a larger document canmeaningfully be used as a proxy for the original document embedding . To test this, we wantedto determine how much reconstruction loss we would incur from using an optimal linear combinationof sentence embedding vectors instead of a full multi-sentence embedding vector. Optimizing fortrain R2, we use Ordinary Least Squares (OLS) regression to reconstruct the document embeddingfrom its sentence embeddings, with the multi-sentence embedding vector as our response and eachsentence vector as a predictive datapoint for our regression. Our model choice is notable for its directinterpretability , though we acknowledge and check for potential issues posed by OLS, suchas multicollinearity. Our regressions use normalized embeddings (L2 norm of 1) to ensure scaleinvariance . We separate our data points into their component sentences by use of punctuationsuch as periods, and new lines. When we regress the sentence embedding vectors onto the multi-sentence embedding vector, wefind that our train R2 across the eight models and five datasets we used ranges from 0.75 to 0.99,with an average R2 or 0.876 when reconstructing the multi-sentence embedding vector. This resultindicates that approximately 87.6% of the variance in a long-content document embedding can beaccounted for by analyzing the embeddings of the individual sentences constituting the document.The Mean Squared Error (MAE) summed over all dimensions of this reconstruction across all modelsand datasets ranged from 0.001 and 0.01 with an average of 0.0069, suggesting minimal deviation inthe reconstructed vectors.",
  "Analyzing regression coefficients as importance weights": "Given the high explanatory power of our regression models, the coefficients given to each sentence(datapoint) in our regression are strong indicators to determine their relative importance to the totaldocument. To standardize our comparisons across documents, we standardized each coefficient vectorby its L2 norm. One potential issue to note with this approach is the presence of negative coefficientvalues, but these tended to be rare and very low in magnitude, with very little influence on our finalanalysis. We judge the importance of a sentence by its regression coefficient. For example, if a regression ona two-sentence document yielded weights 0.8 and 0.6, we conclude that the first sentence is 33.3%more important to the final semantic meaning of the text than the second sentence. As shown in , there is a downward trend in coefficient values with increasing sentenceposition, suggesting a positional bias where earlier sentences generally have a greater impact onthe documents overall semantic representation. To quantify this observation, we plot regressioncoefficients against sentence positions over all the documents in our dataset.",
  "Embedding positional bias is robust to human-level writing bias": "To validate that this observed bias is not solely a byproduct of dataset-specific characteristics, namelyhuman-level writing bias, we conducted additional regression experiments where all sentences fromthe above pre-processing steps were shuffled before their embeddings were generated. Using thesenew embeddings, remarkably, the results mirrored the original findings, with the randomly selectedfirst sentence in the shuffled document consistently receiving a higher weight, thereby disambiguatingour results from potential dataset biases.",
  "More specifically, we expect the weight assigned to the first sentence to follow a uniform weight of1": "num_sentences. However, this analysis shows a distinct negative correlation between sentence positionand importance score, with significant deviations from the expected uniform distribution ( 0.001),confirming a systematic positional influence within document embeddings as shown in table 1. Thesefindings suggest that the embedding models may inherently prioritize the initial information presentedin any text sequence, irrespective of its original position in the document.",
  "Isolating the role of training methodology in model biases": "During training, input data is processed sequentially, starting at the beginning of the context window.Variable-length training samples are packed into this fixed window, often necessitating truncationwhen the input exceeds the windows length. Truncation typically discards content from the end,leading to a systematic bias where earlier positions in the sample receive disproportionate attention. For a given position i [0, N] within a context window of length N, the model observes ti, thenumber of non-padding tokens encountered at position i. The importance of position i can then bemodeled as imp(ti) = u(ti), where u() represents the models updates based on the presence ofnon-padding tokens at ti. As traditional truncation favors earlier positions, the frequency with which tokens are seen at thebeginning of the context window is inherently higher than at the end. This can be modeled as amonotonically decreasing function, where the quantity of non-padding tokens at ti diminishes asi increases. As a result, the relative importance of earlier positions imp(t1) imp(t2) imp(tN) is systematically higher, introducing an implicit bias that prioritizes early context over latercontent. Although this monotonic impact on position can theoretically be removed by maintaining an equalnumber of effective updates throughout the context, it is unknown what the impacts on computa-tional costs, and model performance would be. Future pre-training, as well as employing novelcontext-length enhancement methods, with this bias in mind will require additional research to fullyunderstand the impacts, leading us to believe that this bias will continue in future models.",
  "Conclusion": "Our study uncovers a positional bias in embedding models, where sentences at the beginning of adocument disproportionately influence the resulting embeddings. This bias is consistently observedacross various models with different context sizes and datasets and is evident in both text insertion andremoval experiments. We further quantified this effect through regression analysis, which highlightsthe extent of the models preference for earlier content. Our findings suggest that this bias is intrinsicto the models training methodologies, particularly the use of truncation strategies, rather than aconsequence of dataset-specific patterns. This positional bias poses challenges in critical applications like information retrieval in documentsearch systems, highlighting the need for alternative positional encoding methods to mitigate thesebiases and achieve more balanced semantic representations. Additionally, growing research intoextending context lengths offers a promising avenue for further exploration of this phenomenon andpotential solutions.",
  "N. Reimers and I. Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks,2019": "L. K. Senel, I. Utlu, V. Yucesoy, A. Koc, and T. Cukur. Semantic structure and interpretabilityof word embeddings. IEEE/ACM Transactions on Audio, Speech, and Language Processing,26(10):17691779, Oct. 2018. ISSN 2329-9304. doi: 10.1109/taslp.2018.2837384. URL H. Steck, C. Ekanadham, and N. Kallus. Is cosine-similarity of embeddings really aboutsimilarity? In Companion Proceedings of the ACM on Web Conference 2024, WWW 24. ACM,May 2024. doi: 10.1145/3589335.3651526. URL",
  "T. Soczynski. Interpreting ols estimands when treatment effects are heterogeneous: Smallergroups get larger weights, 2020": "G. Team, M. Reid, N. Savinov, D. Teplyashin, Dmitry, Lepikhin, T. Lillicrap, J. baptiste Alayrac,R. Soricut, A. Lazaridou, O. Firat, J. Schrittwieser, I. Antonoglou, R. Anil, S. Borgeaud, A. Dai,K. Millican, E. Dyer, M. Glaese, T. Sottiaux, B. Lee, F. Viola, M. Reynolds, Y. Xu, J. Molloy,J. Chen, M. Isard, P. Barham, T. Hennigan, R. McIlroy, M. Johnson, J. Schalkwyk, E. Collins,E. Rutherford, E. Moreira, K. Ayoub, M. Goel, C. Meyer, G. Thornton, Z. Yang, H. Michalewski,Z. Abbas, N. Schucher, A. Anand, R. Ives, J. Keeling, K. Lenc, S. Haykal, S. Shakeri, P. Shyam,A. Chowdhery, R. Ring, S. Spencer, E. Sezener, L. Vilnis, O. Chang, N. Morioka, G. Tucker,C. Zheng, O. Woodman, N. Attaluri, T. Kocisky, E. Eltyshev, X. Chen, T. Chung, V. Selo,S. Brahma, P. Georgiev, A. Slone, Z. Zhu, J. Lottes, S. Qiao, B. Caine, S. Riedel, A. Tomala,M. Chadwick, J. Love, P. Choy, S. Mittal, N. Houlsby, Y. Tang, M. Lamm, L. Bai, Q. Zhang,L. He, Y. Cheng, P. Humphreys, Y. Li, S. Brin, A. Cassirer, Y. Miao, L. Zilka, T. Tobin, K. Xu,L. Proleev, D. Sohn, A. Magni, L. A. Hendricks, I. Gao, S. Ontanon, O. Bunyan, N. Byrd,A. Sharma, B. Zhang, M. Pinto, R. Sinha, H. Mehta, D. Jia, S. Caelles, A. Webson, A. Morris,B. Roelofs, Y. Ding, R. Strudel, X. Xiong, M. Ritter, M. Dehghani, R. Chaabouni, A. Karmarkar,G. Lai, F. Mentzer, B. Xu, Y. Li, Y. Zhang, T. L. Paine, A. Goldin, B. Neyshabur, K. Baumli,A. Levskaya, M. Laskin, W. Jia, J. W. Rae, K. Xiao, A. He, S. Giordano, L. Yagati, J.-B.Lespiau, P. Natsev, S. Ganapathy, F. Liu, D. Martins, N. Chen, Y. Xu, M. Barnes, R. May,A. Vezer, J. Oh, K. Franko, S. Bridgers, R. Zhao, B. Wu, B. Mustafa, S. Sechrist, E. Parisotto,T. S. Pillai, C. Larkin, C. Gu, C. Sorokin, M. Krikun, A. Guseynov, J. Landon, R. Datta,A. Pritzel, P. Thacker, F. Yang, K. Hui, A. Hauth, C.-K. Yeh, D. Barker, J. Mao-Jones, S. Austin,H. Sheahan, P. Schuh, J. Svensson, R. Jain, V. Ramasesh, A. Briukhov, D.-W. Chung, T. vonGlehn, C. Butterfield, P. Jhakra, M. Wiethoff, J. Frye, J. Grimstad, B. Changpinyo, C. L. Lan,A. Bortsova, Y. Wu, P. Voigtlaender, T. Sainath, S. Gu, C. Smith, W. Hawkins, K. Cao, J. Besley, S. Srinivasan, M. Omernick, C. Gaffney, G. Surita, R. Burnell, B. Damoc, J. Ahn, A. Brock,M. Pajarskas, A. Petrushkina, S. Noury, L. Blanco, K. Swersky, A. Ahuja, T. Avrahami, V. Misra,R. de Liedekerke, M. Iinuma, A. Polozov, S. York, G. van den Driessche, P. Michel, J. Chiu,R. Blevins, Z. Gleicher, A. Recasens, A. Rrustemi, E. Gribovskaya, A. Roy, W. Gworek,S. M. R. Arnold, L. Lee, J. Lee-Thorp, M. Maggioni, E. Piqueras, K. Badola, S. Vikram,L. Gonzalez, A. Baddepudi, E. Senter, J. Devlin, J. Qin, M. Azzam, M. Trebacz, M. Polacek,K. Krishnakumar, S. yiin Chang, M. Tung, I. Penchev, R. Joshi, K. Olszewska, C. Muir,M. Wirth, A. J. Hartman, J. Newlan, S. Kashem, V. Bolina, E. Dabir, J. van Amersfoort,Z. Ahmed, J. Cobon-Kerr, A. Kamath, A. M. Hrafnkelsson, L. Hou, I. Mackinnon, A. Frechette,E. Noland, X. Si, E. Taropa, D. Li, P. Crone, A. Gulati, S. Cevey, J. Adler, A. Ma, D. Silver,S. Tokumine, R. Powell, S. Lee, K. Vodrahalli, S. Hassan, D. Mincu, A. Yang, N. Levine,J. Brennan, M. Wang, S. Hodkinson, J. Zhao, J. Lipschultz, A. Pope, M. B. Chang, C. Li,L. E. Shafey, M. Paganini, S. Douglas, B. Bohnet, F. Pardo, S. Odoom, M. Rosca, C. N.dos Santos, K. Soparkar, A. Guez, T. Hudson, S. Hansen, C. Asawaroengchai, R. Addanki,T. Yu, W. Stokowiec, M. Khan, J. Gilmer, J. Lee, C. G. Bostock, K. Rong, J. Caton, P. Pejman,F. Pavetic, G. Brown, V. Sharma, M. Lucic, R. Samuel, J. Djolonga, A. Mandhane, L. L. Sjsund,E. Buchatskaya, E. White, N. Clay, J. Jiang, H. Lim, R. Hemsley, Z. Cankara, J. Labanowski,N. D. Cao, D. Steiner, S. H. Hashemi, J. Austin, A. Gergely, T. Blyth, J. Stanton, K. Shivakumar,A. Siddhant, A. Andreassen, C. Araya, N. Sethi, R. Shivanna, S. Hand, A. Bapna, A. Khodaei,A. Miech, G. Tanzer, A. Swing, S. Thakoor, L. Aroyo, Z. Pan, Z. Nado, J. Sygnowski, S. Winkler,D. Yu, M. Saleh, L. Maggiore, Y. Bansal, X. Garcia, M. Kazemi, P. Patil, I. Dasgupta, I. Barr,M. Giang, T. Kagohara, I. Danihelka, A. Marathe, V. Feinberg, M. Elhawaty, N. Ghelani,D. Horgan, H. Miller, L. Walker, R. Tanburn, M. Tariq, D. Shrivastava, F. Xia, Q. Wang, C.-C.Chiu, Z. Ashwood, K. Baatarsukh, S. Samangooei, R. L. Kaufman, F. Alcober, A. Stjerngren,P. Komarek, K. Tsihlas, A. Boral, R. Comanescu, J. Chen, R. Liu, C. Welty, D. Bloxwich,C. Chen, Y. Sun, F. Feng, M. Mauger, X. Dotiwalla, V. Hellendoorn, M. Sharman, I. Zheng,K. Haridasan, G. Barth-Maron, C. Swanson, D. Rogozinska, A. Andreev, P. K. Rubenstein,R. Sang, D. Hurt, G. Elsayed, R. Wang, D. Lacey, A. Ilic, Y. Zhao, A. Iwanicki, A. Lince,A. Chen, C. Lyu, C. Lebsack, J. Griffith, M. Gaba, P. Sandhu, P. Chen, A. Koop, R. Rajwar,S. H. Yeganeh, S. Chang, R. Zhu, S. Radpour, E. Davoodi, V. I. Lei, Y. Xu, D. Toyama,C. Segal, M. Wicke, H. Lin, A. Bulanova, A. P. Badia, N. Rakicevic, P. Sprechmann, A. Filos,S. Hou, V. Campos, N. Kassner, D. Sachan, M. Fortunato, C. Iwuanyanwu, V. Nikolaev,B. Lakshminarayanan, S. Jazayeri, M. Varadarajan, C. Tekur, D. Fritz, M. Khalman, D. Reitter,K. Dasgupta, S. Sarcar, T. Ornduff, J. Snaider, F. Huot, J. Jia, R. Kemp, N. Trdin, A. Vijayakumar,L. Kim, C. Angermueller, L. Lao, T. Liu, H. Zhang, D. Engel, S. Greene, A. White, J. Austin,L. Taylor, S. Ashraf, D. Liu, M. Georgaki, I. Cai, Y. Kulizhskaya, S. Goenka, B. Saeta, Y. Xu,C. Frank, D. de Cesare, B. Robenek, H. Richardson, M. Alnahlawi, C. Yew, P. Ponnapalli,M. Tagliasacchi, A. Korchemniy, Y. Kim, D. Li, B. Rosgen, K. Levin, J. Wiesner, P. Banzal,P. Srinivasan, H. Yu, aglar nl, D. Reid, Z. Tung, D. Finchelstein, R. Kumar, A. Elisseeff,J. Huang, M. Zhang, R. Aguilar, M. Gimnez, J. Xia, O. Dousse, W. Gierke, D. Yates, K. Jalan,L. Li, E. Latorre-Chimoto, D. D. Nguyen, K. Durden, P. Kallakuri, Y. Liu, M. Johnson, T. Tsai,A. Talbert, J. Liu, A. Neitz, C. Elkind, M. Selvi, M. Jasarevic, L. B. Soares, A. Cui, P. Wang,A. W. Wang, X. Ye, K. Kallarackal, L. Loher, H. Lam, J. Broder, D. Holtmann-Rice, N. Martin,B. Ramadhana, M. Shukla, S. Basu, A. Mohan, N. Fernando, N. Fiedel, K. Paterson, H. Li,A. Garg, J. Park, D. Choi, D. Wu, S. Singh, Z. Zhang, A. Globerson, L. Yu, J. Carpenter,F. de Chaumont Quitry, C. Radebaugh, C.-C. Lin, A. Tudor, P. Shroff, D. Garmon, D. Du,N. Vats, H. Lu, S. Iqbal, A. Yakubovich, N. Tripuraneni, J. Manyika, H. Qureshi, N. Hua,C. Ngani, M. A. Raad, H. Forbes, J. Stanway, M. Sundararajan, V. Ungureanu, C. Bishop,Y. Li, B. Venkatraman, B. Li, C. Thornton, S. Scellato, N. Gupta, Y. Wang, I. Tenney, X. Wu,A. Shenoy, G. Carvajal, D. G. Wright, B. Bariach, Z. Xiao, P. Hawkins, S. Dalmia, C. Farabet,P. Valenzuela, Q. Yuan, A. Agarwal, M. Chen, W. Kim, B. Hulse, N. Dukkipati, A. Paszke,A. Bolt, K. Choo, J. Beattie, J. Prendki, H. Vashisht, R. Santamaria-Fernandez, L. C. Cobo,J. Wilkiewicz, D. Madras, A. Elqursh, G. Uy, K. Ramirez, M. Harvey, T. Liechty, H. Zen,J. Seibert, C. H. Hu, A. Khorlin, M. Le, A. Aharoni, M. Li, L. Wang, S. Kumar, N. Casagrande,J. Hoover, D. E. Badawy, D. Soergel, D. Vnukov, M. Miecnikowski, J. Simsa, P. Kumar,T. Sellam, D. Vlasic, S. Daruki, N. Shabat, J. Zhang, G. Su, J. Zhang, J. Liu, Y. Sun, E. Palmer,A. Ghaffarkhah, X. Xiong, V. Cotruta, M. Fink, L. Dixon, A. Sreevatsa, A. Goedeckemeyer,A. Dimitriev, M. Jafari, R. Crocker, N. FitzGerald, A. Kumar, S. Ghemawat, I. Philips, F. Liu,Y. Liang, R. Sterneck, A. Repina, M. Wu, L. Knight, M. Georgiev, H. Lee, H. Askham, A. Chakladar, A. Louis, C. Crous, H. Cate, D. Petrova, M. Quinn, D. Owusu-Afriyie, A. Singhal,N. Wei, S. Kim, D. Vincent, M. Nasr, C. A. Choquette-Choo, R. Tojo, S. Lu, D. de Las Casas,Y. Cheng, T. Bolukbasi, K. Lee, S. Fatehi, R. Ananthanarayanan, M. Patel, C. Kaed, J. Li,S. R. Belle, Z. Chen, J. Konzelmann, S. Pder, R. Garg, V. Koverkathu, A. Brown, C. Dyer,R. Liu, A. Nova, J. Xu, A. Walton, A. Parrish, M. Epstein, S. McCarthy, S. Petrov, D. Hassabis,K. Kavukcuoglu, J. Dean, and O. Vinyals. Gemini 1.5: Unlocking multimodal understandingacross millions of tokens of context, 2024.",
  "BDataset details": "PubMed Publications :We use PubMed publication abstracts to assess the impact of ourablations on scientific writing. Scientific texts are characterized by their structured presentation ofinformation and specialized vocabulary. Understanding how embeddings capture this complexity canprovide insights into their utility in academic and research applications. This dataset is comprised of270,000 datapoints. Paul Graham Essay Collection :We analyze over 200 essays written by Paul Graham, varyingfrom 400 to 70,000 words. Paul Grahams essays are known for their thoughtful, reflective style andcoherent argument structure, making them ideal for studying how embeddings handle nuanced andcomplex idea development over long texts. This dataset is comprised of 215 datapoints. Amazon Reviews :Drawn from MTEBs Amazon Polarity dataset, this helps us examineconsumer review text. Reviews are direct and opinion-rich, offering a perspective on how embeddingsprocess everyday language and sentiment, which is crucial for applications in consumer analytics.This dataset is comprised of 4 million datapoints. Argumentative Analysis :From the BiER benchmarks Argumentative Analysis (ArguAna)dataset, we explore embeddings of formal persuasive writing. This dataset includes well constructedarguments that are ideal for testing how embeddings capture logical structure and the effectiveness ofrhetoric. This dataset is comprised of 10,000 datapoints. Reddit Posts :More Informal and diverse writing styles can be found on Reddit. This datasetintroduces grammar, style, and subject matter diversity into our tests, extending our findings to bemore robust and adaptable to a wide range of writing styles. This dataset is comprised of 450,000datapoints."
}