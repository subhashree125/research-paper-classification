{
  "Abstract": "Implicit models such as Deep Equilibrium Models (DEQs) have emerged as promis-ing alternative approaches for building deep neural networks. Their certified robust-ness has gained increasing research attention due to security concerns. Existingcertified defenses for DEQs employing deterministic certification methods suchas interval bound propagation and Lipschitz-bounds can not certify on large-scaledatasets. Besides, they are also restricted to specific forms of DEQs. In this paper,we provide the first randomized smoothing certified defense for DEQs to solvethese limitations. Our study reveals that simply applying randomized smoothingto certify DEQs provides certified robustness generalized to large-scale datasetsbut incurs extremely expensive computation costs. To reduce computational re-dundancy, we propose a novel Serialized Randomized Smoothing (SRS) approachthat leverages historical information. Additionally, we derive a new certified ra-dius estimation for SRS to theoretically ensure the correctness of our algorithm.Extensive experiments and ablation studies on image recognition demonstratethat our algorithm can significantly accelerate the certification of DEQs by upto 7x almost without sacrificing the certified accuracy. Our code is available at",
  "Introduction": "The recent development of implicit layers provides an alternative and promising perspective for neuralnetwork design (Amos & Kolter, 2017; Chen et al., 2018; Agrawal et al., 2019; Bai et al., 2019, 2020;El Ghaoui et al., 2021). Different from traditional deep neural networks (DNNs) that build standardexplicit deep learning layers, implicit layers define the output as the solution to certain closed-formfunctions of the input. These implicit layers can represent infinitely deep neural networks using onlyone single layer that is defined implicitly. The unique definition endows implicit models with thecapability to model continuous physical systems, a task that traditional DNNs cannot accomplish(Chen et al., 2018). Additionally, the implicit function theorem enhances memory efficiency byeliminating the need to store intermediate states during forward propagation (Chen et al., 2018; Baiet al., 2019). Furthermore, implicit models offer a valuable accuracy-efficiency trade-off, makingthem adaptable to varying application requirements (Chen et al., 2018). These advantages underscorethe significant research value of implicit models. Deep equilibrium models (DEQs) are one promising class of implicit models that construct theoutput as the solution to input-dependent fixed-point problems (Bai et al., 2019). With a fixed-pointsolver, DEQs can be seen as infinite-depth and weight-tied neural networks. The modern DEQ-basedarchitectures have shown comparable or even surpassing performance compared with traditionalexplicit models (Bai et al., 2019, 2020; Gu et al., 2020; Chen et al., 2022). Due to the superior",
  "arXiv:2411.00899v1 [cs.LG] 1 Nov 2024": "performance of DEQs, their adversarial robustness has gained increasing research interest. Recentresearch has revealed that DEQs also suffer from similar vulnerabilities as traditional DNNs, whichraises security concerns (Gurumurthy et al., 2021; Yang et al., 2022). Multiple works proposeempirical defenses to improve the adversarial robustness of DEQs using regularization methods (Chuet al., 2023; El Ghaoui et al., 2021) and adversarial training (Yang et al., 2023; Gurumurthy et al.,2021; Yang et al., 2022). These empirical defenses measure models adversarial robustness by therobust performance against adversarial attacks. However, they do not provide rigorous securityguarantees and often suffer from the risk of a false sense of security (Athalye et al., 2018), leading totremendous challenges for reliable robustness evaluation. As alternatives to empirical defenses, It is worth noting that certified defenses certify that no ad-versarial example can ever exist within a neighborhood of the test sample regardless of the attacks,providing reliable robustness measurements and avoiding the false sense of security caused by weakattacking algorithms. Recent works have explored interval bound propagation (IBP) (Wei & Kolter,2021; Li et al., 2022) and Lipschitz bounding (LBEN) (Havens et al., 2023; Jafarpour et al., 2021)for certifiable DEQs. However, IBP usually estimates a loose certified radius due to the error accu-mulation in deep networks (Zhang et al., 2021) and the global Lipschitz constant tends to providea conservative certified radius (Huang et al., 2021). Due to the conservative certification, IBP andLBEN generate trivial certified radii (namely, close to 0) in some cases such as deep networks,especially in large-scale datasets (e.g., ImageNet) (Zhang et al., 2021; Li et al., 2023). Moreover,the design of IBP and LBEN relies on specific forms of DEQs and can not be customized to variousmodel architectures, restricting the application of these methods. Given the inherent limitations of existing works, the objective of this paper is to explore the certifiedrobustness of DEQs via randomized smoothing for the first time. Randomized smoothing approachesconstruct smoothed classifiers from arbitrary base classifiers and provide certified robustness viastatistical arguments (Cohen et al., 2019) based on the Monte Carlo probability estimation. Therefore,compared with IBP and LBEN methods, randomized smoothing has better flexibility in certifying therobustness of various DEQs of different architectures. More importantly, the probabilistic certificationradius provided by randomized smoothing can be larger and generalized to large-scale datasets. Our study reveals that applying randomized smoothing to certify DEQs can indeed provide bettercertified accuracy but it incurs significant computation costs due to the expensive fixed point solvers inDEQs and Monte Carlo estimation in randomized smoothing. For instance, certifying the robustnessof one 256 256 image in ImageNet dataset with a typical DEQ takes up to 88.33 seconds. Thisraises significant efficiency challenges for the application of certifiable DEQs in real-world appli-cations. In this paper, we further delve into the computational efficiency of randomized smoothingcertification of DEQs. Our analysis reveals the computation redundancy therein, and we propose aneffective approach, named Serialized Random Smoothing (SRS). Importantly, the certified radiusand theoretical guarantees of vanilla randomized smoothing can not be applied in SRS. Therefore,we develop a new certified radius with theoretical guarantees for the proposed SRS. Our methodtremendously accelerates the certification of DEQs by leveraging their unique property and reducingthe computation redundancy of randomized smoothing. The considerable acceleration of SRS-DEQallows us to certify DEQs on large-scale datasets such as ImageNet, which is not possible in previousworks. In a nutshell, our contributions are as follows: We provide the first exploration of randomized smoothing for certifiable DEQs. Our studyreveals significant computation challenges in such certification, and we provide insightfulcomputation redundancy analyses. We propose a novel Serialized Randomized Smoothing approach to significantly acceler-ate the randomized smoothing certification for DEQs and corresponding certified radiusestimation with new theoretical guarantees. We conduct extensive experiments on CIFAR-10 and ImageNet to show the effectiveness ofour SRS-DEQ. Our experiments indicate that SRS-DEQ can speed up the certification ofDEQs up to 7 almost without sacrificing the certified accuracy.",
  "z = f(z, x),(1)": "where z is the output representation of implicit neural networks and x is the input data. Therefore,the computation of DEQs for each input data point x requires solving a fixed-point problem to obtainthe representation z. Fixed-point solvers. Multiple fixed-point solvers have been adopted for DEQs, including the naivesolver, Anderson solver, and Broyden solver (Geng & Kolter, 2023). The naive solver directly repeatsthe fixed-point iteration until it converges:",
  "N(0, 2I),(5)": "where Y is the label space, and 2 is the variance of Gaussian distribution. Intuitively, the smoothedclassifier outputs the most probable class over a Gaussian distribution. If we denote pA and pB as theprobabilities of the most probable class cA(x) and second probable class cB(x), Neyman-Pearsontheorem (Neyman & Pearson, 1933) provides a 2-norm certified radius R for the smoothed classifierg:g(x + ) = cA(x) for all 2 < R,(6)",
  "Serialized Randomized Smoothing": "As introduced in .1, the Monte Carlo method is employed in randomized smoothing toestimate the prediction probability, typically necessitating over 10, 000 times inference computationfor certifying one data point. Despite the independent sampling of Gaussian noises, these noises {i}are added to the same certified data point x to form noisy data samples {x + i}. Notably, thesesamples are numerically and visually similar to each other as can be seen in . Moreover,in randomized smoothing, the base classifier is trained on Gaussian-augmented data to be resistantto noises added to data points, yielding robust features and base classifiers. Therefore, the featurerepresentation of these noisy samples computed in the forward computation of DEQs shares significantsimilarities, resulting in a substantial computation redundancy in the fixed-point solvers. Thecomputation redundancy contributes to the inefficient DEQ certification with randomized smoothingas a primary factor. Consider a DEQ with 50 layers as an illustrative example. In the Monte Carloestimation with N = 10, 000, it requires the forward computation of 50 10, 000 = 500, 000 layers.However, if we can estimate the intermediate representation at the 45th layer, the required forwarditerations reduce to 5 10, 000 = 50, 000 layers, bringing a 10 acceleration. Motivated by the above challenges and analyses, we propose a novel solution, Serialized RandomizedSmoothing (SRS), to effectively reduce the computation redundancy in the certification of DEQs. Thekey idea of Serialized Randomized Smoothing is to accelerate the convergence of fixed-point solversof DEQs by harnessing historical feature representation information z computed from different noisysamples, thereby mitigating redundant calculations. While the hidden representation z0 is initializedas 0 in standard DEQs (Bai et al., 2021a), we propose to choose a better initialization of z0 toaccelerate the convergence of DEQs (Bai et al., 2021a), which can potentially reduce the number offixed-point iteration S and computation cost. Specifically, our Serialized Randomized Smoothingapproach leverages the representation zSi computed from the previous noisy sample x + i as theinitial state of the fixed-point solver of the next noisy sample:",
  "(b) Serialized Randomized Smoothing": ": Illustrations of the standard DEQ and our SRS-DEQ. The representation for each samplegoes through D layers in standard DEQ. Our SRS-DEQ uses the previous representation as theinitialization and converges to the fixed point with a few layers (S D). After get all the predictions,SRS-DEQ makes use of correlation-eliminated certification to estimate the certified radius.",
  "i1{f(x + i) = c},(8)": "where 1{} is the indicator function, and i N(0, 2I) is the i-th random perturbation sampledfrom Gaussian distribution. However, it introduces computation challenges due to the large samplingnumber N. Our empirical study (.2) indicates that applying randomized smoothing to certifyMDEQ (Bai et al., 2020) on one 32 32 image in CIFAR-10 takes 12.89 seconds, and 88.33 secondsfor one 256 256 image in ImageNet. The computation challenges raise tremendous limitations inreal-world applications. We provide an analysis for the slow randomized smoothing certification of DEQs. First, each forwarditeration of DEQs can be very expensive. This is because DEQs are typically weight-tied neuralnetworks so one layer f(z, x) of DEQs needs to be complex to maintain the expressiveness. Second,the fixed-point solver needs many iterations for convergence. To maintain the best performance, thesolvers usually set a small value for the error tolerance (e.g., 0.001). Although second-order solverslike Broydens method have faster convergence, their computation cost per iteration is higher. Third,the Monte Carlo estimation in randomized smoothing further exacerbates the expensive inference ofDEQs, leading to significant computation challenges, as shown in a.",
  "zSi = Solver(f, x + i, zSi1),(9)": "where i = 1, 2, . . . , N. As shown in b, due to the similarity between zi1( zSi1) andzi ( zSi ) as analyzed in the motivation, it only takes a few fixed-point iterations to adjust the featurerepresentation from zSi1 to zi ( zSi ), which significantly accelerates the prediction of DEQs. Though a better initialization accelerates the inference of DEQs, it introduces an unnecessarycorrelation within the framework of randomized smoothing. In standard randomized smoothing, eachprediction is made independently. However, the predictions are linked through previous fixed pointsas defined by Solver(f, x + i, zSi1). To exemplify this, consider an extreme case where the solverfunctions as an identity mapping. In such a case, all subsequent predictions merely replicate the firstprediction. This pronounced correlation effectively reduces the process to an amplification of thefirst prediction, breaking the confidence estimation for Monte Carlo. Therefore, we develop a newestimation of the certified radius with theoretical guarantees in the next subsection.",
  "Correlation-Eliminated Certification": "The primary challenge is to confirm how much the initialization of the fixed-point solver influencesthe final predictions. For different data samples x + i and initialization zSi , the cases can bedifferent depending on the complex loss landscape of the fixed-point problem and the strength of thesolver. Nonetheless, comparing all predictions from SRS with standard predictions, which necessitatenumerous inference steps, is impractical. Such a comparison contradicts the fundamental requirementfor efficiency in this process. To maintain the theoretical guarantee of randomized smoothing, we propose correlation-eliminationcertification to obtain a conservative estimate of the certified radius. The core idea involves discardingthose samples that are misclassified as the most probable class, cA(x), during the Monte Carloprocess. Let pm represent the probability that a sample is predicted as class cA(x) using SRS butfalls into other classes with the standard DEQ. We can drop the misclassified samples as follows:",
  "N EA = NA pmNA,(10)": "where NA represents the count of samples predicted as class cA(x) and N EA refers to the subset ofthese effective samples that are predicted as class cA(x). Utilizing N EA and N, we are ultimatelyable to estimate the certified radius. For the reason that pm is intractable, we employ an additionalhypothesis test using a limited number of samples to approximate its upper bound. During the MonteCarlo sampling of SRS, we randomly select K of samples (a small number compared to N) alongwith their corresponding predictions, which are then stored as Xm and Ym, respectively. After theMonte Carlo sampling, these samples, Xm, are subjected to predictions using the standard DEQ toyield the labels Yg, which serve as the ground truth. Mathematically, we estimate pm as follows:",
  "pm = 1 LowerConfBound(N1, N2, 1 ),(13)": "where = /2 is for keeping the confidence level of the two-stage hypothesis test. Besides,LowerConfBound(k, n, 1) returns a one-sided (1) lower confidence interval for the Binomialparameter p given that k Binomial(n, p). In other words, it returns some number p for whichp p with probability at least 1 over the sampling of k Binomial(n, p). Intuitively, a smaller pm indicates a higher consistency between the predictions of SRS and those of the standard DEQ,yielding a greater number of effective samples. To enhance comprehension, we include an examplein Appendix I to demonstrate the workflow of correlation-eliminated certification. In the end, weestimate the certified radius with the following equation:",
  "R = 1(pA)(15)": "To implement SRS-DEQ efficiently, we stack the noisy samples into mini-batches for faster parallelcomputing as shown in Algorithm 1. Given a certified point, we sample batch-wise noisy data. Aftersolving the fixed-point problem for the first batch, the subsequent fixed-point problem is initializedwith the solution of the previous one. By counting the effective predictions using Eq. (10), thealgorithm finally returns the certified radius as in standard randomized smoothing (Cohen et al., 2019).The following Theorem 3.1 theoretically guarantees the correctness of our algorithm (proof availablein Appendix A):Theorem 3.1 (Correlation-Eliminated Certification). If Algorithm 1 returns a class cA(x) with aradius R calculated by equation 14 and 15, then the smoothed classifier g predicts cA(x) withinradius R around x: g(x + ) = g(x) for all < R, with probability at least 1 .",
  "Experiments": "In this section, we conduct comprehensive experiments in the image classification tasks to demonstratethe effectiveness of the proposed SRS-MDEQ. First, we introduce the experimental settings in detail.Then we present certification on CIFAR-10 and ImageNet datasets to demonstrate the certifiedaccuracy and efficiency. Finally, we provide comprehensive ablation studies to understand itseffectiveness.",
  "Experiment Settings": "Datasets. We use two classical datasets in image recognition, CIFAR-10 (Krizhevsky et al., 2009) andImageNet (Russakovsky et al., 2015), to evaluate the certified robustness. It is crucial to emphasizethat this is the first attempt to certify the robustness of DEQs on such a large-scale dataset. DEQ Architectures and Solvers. We select MDEQ with Jacobian regularization (Bai et al., 2020), atype of DEQs specially designed for image recognition, to serve as the base classifier in randomizedsmoothing. Specifically, we choose MDEQ-SMALL and MDEQ-LARGE for CIFAR-10, and MDEQ-SMALL for ImageNet. To obtain a satisfactory level of certified accuracy, all the base classifiers aretrained on the Gaussian augmented noise data with mean 0 and variance 2. Detailed informationregarding the model configuration and training strategy is available in Appendix B. We closely follow the solver setting in MDEQ (Bai et al., 2020). For the standard MDEQ on CIFAR-10, we use the Anderson solver with the step of {1, 5, 30}. For the standard MDEQ on ImageNet,we use the Broyden solver with the step of {1, 5, 14}. We apply Anderson and Naive solvers onCIFAR-10 and Broyden solver on ImageNet for the proposed SRS-MDEQ with the step of {1, 3}.We adopt a warm-up technique, where we use multi-steps to solve the fixed-point problem for thefirst batch in Algorithm 1. The warm-up steps for our SRS-MDEQ are set as 30 and 14 steps forCIFAR-10 and ImageNet, respectively. The details of warm-up strategy are shown in Appendix K.For notation simplicity, we use a number after the algorithm name to represent the number of layersof the model, and we use N, A, and B to denote the Naive, Anderson, and Broyden solvers.For instance, SRS-MDEQ-3A denotes SRS-MDEQ method with 3 steps of Anderson iterations. Randomized smoothing. Following the setting in randomized smoothing (Cohen et al., 2019),we use four noise levels to construct smoothed classifiers: {0.12, 0.25, 0.50, 1.00}. We report theapproximate certified accuracy as in (Cohen et al., 2019), which is defined as the fraction of thetest data that is both correctly classified and certified with a 2-norm certified radius exceeding aradius threshold r. In our experiments, we set the failure rate as = 0.001 and the sampling numberas N = 10, 000 in the Monte Carlo method, unless specified otherwise. All the experiments areconducted on one A100 GPU.",
  "Baselines. We majorly use standard Randomized Smoothing for MDEQs as our baseline for compar-ison. It is also important to compare our method with state-of-the-art certified defenses. Note that the": "results of randomized smoothing are not entirely comparable to deterministic methods. Althoughrandomized smoothing can provide better certified radii, its certification is probabilistic, even if thecertified probability is close to 100%. Therefore, we only show the comparison in Appendix D forreference. However, our results indicate that the certified radii can be more promising in certain caseswhen using deterministic methods as references.",
  "SRS-MDEQ-1B40%34%32%27%21%16%10%15.21 (6)SRS-MDEQ-3B44%39%33%28%22%17%11%27.48 (3)": "We compare the certified accuracy and the running time of standard MDEQ and our SRS-MDEQacross various layers to further validate the efficiency and robustness of the models. The experimentalresults of the large and small architectures on the CIFAR-10 with = 0.5 are presented in Tables 1and 2, and the results on Imagenet with = 1.0 are shown in . The results for models usingdifferent values of are provided in the Appendix E. Based on these results, we make the followingobservations from several aspects. Number of layers. We delve into a detailed study of the impact of layers in MDEQ. The resultsin , , and indicate that the certified accuracy of both MDEQ and SRS-MDEQ increases with the increase of layers. Moreover, with a few layers, our SRS-MDEQ-1 andSRS-MDEQ-3 can significantly outperform the MDEQ-1 and MDEQ-5 and achieve comparableperformance to MDEQ-30. For instance, for CIFAR-10, SRS-MDEQ-3A can outperform MDEQ-1/MDEQ-5 by an average of 28.5%/12.1% (large) and 24.3%/8.8% (small), respectively. The resultswith other noise levels are shown in Appendix E. 0.00.20.40.60.81.0 RRD normalized frequency MDEQ-A1SRS-MDEQ-A1 0.00.20.40.60.81.0 RRD normalized frequency MDEQ-A3SRS-MDEQ-A3",
  ": Gap histogram of MDEQ-LARGE and pm histogram of MDEQ-LARGE with 10 bins": "Running Time. The running time summarized in , , and shows significantefficiency improvements of our SRS-DEQ method compared with standard randomized smoothing.In general, the time cost almost linearly increases with the number of layers. The standard MDEQrequires 30 layers to certify each image to a satisfactory extent, which costs 12.89 seconds per imagefor the large model and 3.08 seconds per image for the small model on CIFAR-10. This processleads to a heavy computational burden in the certification process. Fortunately, this process can besignificantly accelerated by our SRS-MDEQ. To be specific, for CIFAR-10, large SRS-MDEQ-1Nis near 11 faster than large MDEQ-30A with a 2.5% certified accuracy drop. Besides, smallSRS-MDEQ-3A outperforms small MDEQ-30A in efficiency by 7 with only a 1% accuracy drop.On Imagenet, our SRS-MDEQ-1B can speed up the certification by 6 while enhancing certifiedrobustness compared to MDEQ-14B.",
  "Ablation Study": "In this section, we conduct comprehensive ablation studies to investigate the instance-level consistencyand the effectiveness of our correlation-eliminated certification. We also provide more ablationstudies on the hyperparameter of MDEQ solvers in Appdenix F and G. Finally, we show the empiricalrobustness performance of our method in Appendix L. Instance-level consistency. Besides providing global measurements for the SRS-MDEQ with thecertified accuracy in .2, we study how closely SRS-MDEQ matches accurate MDEQ at theinstance level based on our proposed Relative Radius Difference (RRD). RRD compares the relativedifference between the certified radius of SRS-MDEQ and the accurate MDEQ for each instance xi:",
  "where rib and ris represent the certified radius of xi with MDEQ-30A and SRS-MDEQ, respectively.We compute RRD over the instances with a positive certified radius to avoid the singular value": "We present the histograms of RRD in . As shown in .3, only with one layer, thecertified radius achieved by SRS-MDEQ-1A is quite close to the accurate MDEQ since these relativedifferences are mostly small and close to 0, and it significantly outperforms the standard MDEQ-1Awith one layer. Moreover, with 3 layers as shown in .3, the RRD values become even moreconcentrated around 0, which shows a very consistent certified radius with the accurate MDEQ. Theinstance level measurement for other settings of MDEQs are shown in Appendix H. Power of correlation-eliminated certification. The correctness of our method is based on estimatingthe upperbound of pm. In this ablation study, we investigate the effectiveness in the following twoaspects. We provide additional analysis for this technique in Appendix I. (1) The magnitude of the upperbound. A large pm indicates that we need to drop many predictions incA, showcasing strong correlation in SRS-DEQ. We plot the histogram of pm to show the magnitude.a and 3b illustrates that the majority of pm values fall within lower intervals, even with justa single step. This trend is more pronounced with three layers, as depicted in b. Theseobservations suggest that an increase in the number of steps reduces the correlation in predictions,resulting in a certified radius calculated by our method closer to the one obtained through standardrandomized smoothing for DEQs. The inner reason is that our approach does not necessitate theexclusion of a large number of samples for most certified points. (2) The empirical correctness of the upperbound, i.e., if the estimated value is larger than the numberof samples we should drop. For each certified point, we calculate the gap between those two values:",
  "n=11{ynb = yns and yns = cA},(17)": "where NA is the number of samples classified as cA with SRS. As shown in c and 3d, thehistogram of the gap, the value is always larger than 0, meaning that the estimation effectively coversthe samples that we should drop. Moreover, the gap distribution is notably skewed towards 0. Forexample, more than 95% of the gaps are less than 0.2, signifying that our estimation is not onlyeffective but also tight. More results can be found in Appendix I.",
  ": Comparison of certified accuracy for ResNet-110 and the MDEQ-LARGE architecture with = 0.5 on CIFAR-10. The best certified accuracy for each radius is in bold": "Compared to explicit neural networks. To demonstrate the superior performance of certificationwith DEQs, we also compare our results against those of explicit neural networks. Despite surpassingthe performance of explicit neural networks is not our target, we claim the performance of DEQs cancatch up with them, as shown in . We provide a comparison between DEQs and ResNet-110under the same training and evaluation setting, and the results are consistent with those reportedin (Cohen et al., 2019). Results on Other Randomized Smoothing methods. In addition to the standard version of random-ized smoothing (Cohen et al., 2019), there are more advanced methods available. To demonstratethe general adaptability of our approach to randomized smoothing, we conduct experiments usingSmoothAdv (Salman et al., 2019). For these experiments, we utilize PGD (Kurakin et al., 2016) asthe adversarial attack method, setting the number of adversarial examples during training to 4. Theresults, presented in , show that SmoothAdv improves certified accuracy for both standardrandomized smoothing and our SRS approach.",
  "Deep Equilibrium Models": "Recently, there have been many works on deep implicit models that define the output by implicitfunctions (Amos & Kolter, 2017; Chen et al., 2018; Bai et al., 2019; Agrawal et al., 2019; El Ghaouiet al., 2021; Bai et al., 2020; Winston & Kolter, 2020). Among these, deep equilibrium modeldefines the implicit layer by solving a fixed-point problem (Bai et al., 2019, 2020). There are manyfundamental works investigating the existence and the convergence of the fixed point (Winston& Kolter, 2020; Revay et al., 2020; Bai et al., 2021b; Ling et al., 2023). With many advantages,DEQs achieve superior performance in many tasks, such as image recognition (Bai et al., 2020),image generation (Pokle et al., 2022), graph modeling (Gu et al., 2020; Chen et al., 2022), languagemodeling (Bai et al., 2019), and solving complex equations (Marwah et al., 2023). Though DEQscatch up with the performance of DNNs, the computation inefficiency borders the deployment ofdeep implicit models in practice (Chen et al., 2018; Dupont et al., 2019; Bai et al., 2019). Relatedworks focus on reusing information from diffusion models and optical flows, demonstrating theeffectiveness of reducing computational redundancy of DEQs (Bai & Melas-Kyriazi, 2024; Bai et al.,2022). However, this paper focuses on the certified robustness of DEQs and provides a theoreticalanalysis of our proposed method.",
  "Certified Robustness": "Empirical defenses like adversarial training are well-known in deep learning (Goodfellow et al., 2014).Some existing works improve the robustness of DEQs by applying adversarial training (Gurumurthyet al., 2021; Yang et al., 2023, 2022). Different from the empirical defense like adversarial training,certified defenses theoretically guarantee the predictions in a small ball maintain as a constant (Wong& Kolter, 2018; Raghunathan et al., 2018; Gowal et al., 2018; Cohen et al., 2019). The most commonway to certify robustness is to define a convex program, which lower bounds the worst-case perturbedoutput of the network (Raghunathan et al., 2018; Wong & Kolter, 2018). The increasing computationcomplexity in high-dimension optimization hinders the generalization of these methods. Intervalbound propagation (IBP) is another certification method for neural networks, which computes an upperbound of the class margin through forward propagation (Gowal et al., 2018). However, the layer-by-layer computation mode brings a potentially loose certified radius. Recently, randomized smoothinghas drawn much attention due to its flexibility (Cohen et al., 2019). Randomized smoothing certifies2-norm robustness for arbitrary classifiers by constructing a smoothed version of the classifier. Thereare some existing works certifying robustness for DEQs. Most of them adapt IBP to DEQs byconstructing a joint fixed-point problem (Wei & Kolter, 2021; Li et al., 2022). Others design specificforms of DEQs to control the Lipschitz constant of the models (Havens et al., 2023; Jafarpour et al.,2021). Yet, no existing work explores randomized smoothing for certifiable DEQs.",
  "Conclusion": "In this work, we provide the first exploration of randomized smoothing certification for DEQs.Our study shows that randomized smoothing for DEQs can certify more generalized architecturesand be applied to large-scale datasets but it incurs significant computation costs. We delve intothe computation bottleneck of this certified defense and point out the new insight of computationredundancy. We further propose a novel Serialized Random Smoothing approach to significantlyreduce the computation cost by leveraging the computation redundancy. Finally, we propose anew estimation for the certified radius for our SRS. Our extensive experiments demonstrate thatour algorithm significantly accelerates the randomized smoothing certification by up to 7 almostwithout sacrificing the certified accuracy. Our discoveries and algorithm provide valuable insight anda solid step toward efficient robustness certification of DEQs. Our work significantly improves thesecurity of artificial intelligence, especially applicable in sensitive domains, enhancing the applianceof the models and maintaining the integrity of AI-driven decisions. Though our paper speeds up thecertification of DEQs with randomized smoothing, it cannot be directly applied to other architecture.We regard the speedup for the general method as our future research.",
  "Gurumurthy, S., Bai, S., Manchester, Z., and Kolter, J. Z. Joint inference and input optimizationin equilibrium networks. Advances in Neural Information Processing Systems, 34:1681816832,2021": "Havens, A. J., Araujo, A., Garg, S., Khorrami, F., and Hu, B. Exploiting connections betweenlipschitz structures for certifiably robust deep equilibrium models. In Thirty-seventh Conferenceon Neural Information Processing Systems, 2023. Huang, Y., Zhang, H., Shi, Y., Kolter, J. Z., and Anandkumar, A. Training certifiably robust neuralnetworks with efficient local lipschitz bounds. Advances in Neural Information Processing Systems,34:2274522757, 2021.",
  "Li, M., Wang, Y., and Lin, Z. Cerdeq: Certifiable deep equilibrium model. In International Conferenceon Machine Learning, pp. 1299813013. PMLR, 2022": "Ling, Z., Xie, X., Wang, Q., Zhang, Z., and Lin, Z. Global convergence of over-parameterizeddeep equilibrium models. In International Conference on Artificial Intelligence and Statistics, pp.767787. PMLR, 2023. Marwah, T., Pokle, A., Kolter, J. Z., Lipton, Z. C., Lu, J., and Risteski, A. Deep equilibriumbased neural operators for steady-state pdes. In Thirty-seventh Conference on Neural InformationProcessing Systems, 2023. Neyman, J. and Pearson, E. S. Ix. on the problem of the most efficient tests of statistical hypotheses.Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of aMathematical or Physical Character, 231(694-706):289337, 1933.",
  "Revay, M., Wang, R., and Manchester, I. R. Lipschitz bounded equilibrium networks. arXiv preprintarXiv:2010.01732, 2020": "Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Karpathy, A.,Khosla, A., Bernstein, M., Berg, A. C., and Fei-Fei, L. ImageNet Large Scale Visual RecognitionChallenge. International Journal of Computer Vision (IJCV), 115(3):211252, 2015. doi: 10.1007/s11263-015-0816-y. Salman, H., Li, J., Razenshteyn, I., Zhang, P., Zhang, H., Bubeck, S., and Yang, G. Provably robustdeep learning via adversarially trained smoothed classifiers. Advances in Neural InformationProcessing Systems, 32, 2019.",
  "AProofs of Theorem 3.1": "Theorem. With probability at least 1 over Algorithm 1. If Algorithm 1 returns a class cA with aradius R, then the smoothed classifier g predicts cA within radius R around x: g(x + ) = g(x) forall < R. Proof. From the contract of the hypothesis test, we know that with the probability of at least 1 over all the samplings 1, 2, , N, we have pm > P(yis = cA and yib = cA) = pm, where yis andyib represent the predictions of x + i given by SRS and the standard DEQ, respectively. Denote thenumber of samplings as follows:",
  "N EA = NA pmNA,(18)N EA = NA pmNA,(19)": "where N EA is the fact number that the predictions of the standard DEQs are class cA, while N EA isthe number we estimate. In this way, LowerConfBound( N EA , N, ) < LowerConfBound(N EA , N, ).Suppose the standard randomized smoothing returns R with N EA and N, we conclude that R < Rwith the probability of at least 1. With Proposition 2 in the standard randomized smoothing (Cohenet al., 2019), g(x + ) = g(x) for all < R for all < R. Denote the event that the radiusof SRS is smaller than the radius of RS as A and the event that the radius of RS can certify thedata points B. We can conclude that P( A) = P( B) = following the hypothesis tests. The finalprobability of successfully certifying the data point is:",
  "B.1Model Architecture": "Multi-resolution deep equilibrium models (MDEQ) are a new class of implicit networks that aresuited to large-scale and highly hierarchical pattern recognition domains. They are inspired by themodern computer vision deep neural networks, which leverage multi-resolution techniques to learnfeatures. These simultaneously learned multi-resolution features allow us to train a single modelon a diverse set of tasks and loss functions, such as using a single MDEQ to perform both imageclassification and semantic segmentation. MDEQs are able to match or exceed the performance ofrecent competitive computer vision models, achieving high accuracy in sequence modeling. We report the model hyperparameters in . For CIFAR-10, we utilize both MDEQ-SMALLand MDEQ-LARGE architectures, while for ImageNet, we only employ MDEQ-SMALL. Most ofthe hyperparameters remain consistent with the ones specified in work (Bai et al., 2021b). MDEQsdefine several resolutions in the implicit layer to align with ResNet in computer vision. Consequently,the primary distinction between the models lies in the channel size and resolution level. Additionally,all the models are equipped with GroupNorm, as presented in the standard MDEQ (Bai et al., 2020).",
  "B.2Training Setting": "We report the training hyperparameters in . Following work (Bai et al., 2021b), we use Jacobianregularization to ensure stability during the training process. Moreover, to prevent overfitting, weemploy data augmentation techniques such as random cropping and horizontal flipping, which arecommonly utilized in various computer vision tasks. Gaussian Augmentation: As mentioned in .2, randomized smoothing requires the baseclassifier to be robust against Gaussian noise. Therefore, we train the MDEQs with Gaussianaugmentation. Following the standard randomized smoothing (Cohen et al., 2019), we augment theoriginal data with noise sampled from N(0, 2I), where denotes the noise level in the smoothedclassifier. Intuitively, the training scheme forces the base classifier to be robust to the Gaussian noise,which is used in randomized smoothing. Formally, under the cross-entropy loss, the objective is tomaximize the following:",
  "cY exp fc(xi + ).(22)": "The equation within the expectation represents the softmax output of the logits produced by the baseclassifier f. This can be seen as a soft version of the argmax function. Consequently, the expectationapproximates the probability of class ci when Gaussian augmentation is applied. By doing so, weaim to maximize the likelihood of the smoothed classifier g(x):",
  "i=1log P(f(xi + ) = ci).(23)": "To demonstrate our method is general to DEQs with any training scheme, we conduct ablation studiesof Jacobian regularization. Jacobian regularization stabilizes the training of the backbones but it isnot crucial for the certification (Bai et al., 2021b). The results in show that using Jacobianregularization can help stabilize the fixed-point solvers but will almost not affect the final performancewith enough fixed-point iterations. Our conclusion is consistent with Bai et al. (2021b) where theregularization does not increase the accuracy but decreases the number of fixed-point iterations.Though the experiments show that using Jacobian regularization is not crucial in the certification, werecommend to use the regularization in the training for more stable performance.",
  "DComparsion with Baselines": "In certified defenses, 2-norm and -norm are widely used. Since randomized smoothing provides2-norm certified radii, we choose baselines with the same certified norm. We compare the per-formance with the state-of-the-art DEQ certification methods on CIFAR-10 (Havens et al., 2023)including SLL (Araujo et al., 2023) and LBEN (Revay et al., 2020), which certify robustness withLipschitz bound. To align with the numbers reported in Havens et al. (2023), we adopt the samecertified radius in the table. We present the certified accuracy for the large SRS-MDEQ under differentcertified radii. Since the code of SLL and LBEN is not publicly available, our comparison is basedon reported results in their papers for CIFAR-10.",
  ": Comparison with existing certification methods and SRS-MDEQ-LARGE. The best certifiedaccuracy is in bold": "As shown in , our SRS-MDEQ-1 already significantly outperforms existing certificationmethods across all the certified radii. It also verifies that randomized smoothing defense providestighter certification bounds. We want to emphasize again that the results of randomized smoothingare not entirely comparable to deterministic methods. Although randomized smoothing can providebetter-certified radii, its certification is probabilistic, even if the certified probability is close to 100%.",
  "EOther Noise Levels": "In the main paper, we present results using a noise level of = 0.5 for CIFAR-10 and = 1.0 forImageNet. In this appendix, we present the results on other noise levels in Tables 10 to 17. ForImageNet, we adopt a larger noise level as suggested in paper (Cohen et al., 2019). The reason behindthis choice is that images can tolerate higher levels of isotropic Gaussian noise while still preservingtheir high-resolution content. Since the noise level does not affect the running time, we do not showthe running time in these tables. Tendency: The observed performance trend aligns with standard randomized smoothing techniques.When using a smaller noise level , the models exhibit higher certified accuracy within a smallerradius. However, the models are unable to provide reliable certification for larger radii due to thebase classifiers lack of robustness against high-level noise. For example, the smoothed classifier with = 0.12 on CIFAR-10 can certify up to 70% accuracy within a radius of 0.25, but its certificationcapability is truncated when the radius exceeds 0.5. Conversely, when employing a larger noise level, the model can certify a larger radius, but this results in a drop in accuracy on clean data.",
  ": Certified accuracy for MDEQ-LARGE with = 0.25 on CIFAR-10": "The strength of the solvers influences the certified accuracy. With a stronger Anderson solver, theSRS-MDEQ performs better than the naive one. For ImageNet, the high-resolution difficulty evenrequires us to use a quasi-Newton method to keep the convergence of the model. The number ofsteps is another crucial factor for the performance. The model has better performance no matter whatsolver you use.",
  ": Certified accuracy for the MDEQ-SMALL with = 1.0 on CIFAR-10": "with slight discrepancies. This ablation study extends the process to 5 steps to evaluate potentialperformance improvements. We replicate the experimental settings from the main paper but withthe increased step count. The outcomes, detailed in Tables 18 to 20, reveal that while there is someenhancement in performance, the gains are marginal. Given that our method prioritizes efficiency, wefind that three steps are sufficient for all the experiments conducted in our paper.",
  "GMDEQs with Different Solvers": "In the main paper, our presentation of MDEQ results exclusively features the Anderson solverapplied to CIFAR-10. Complementary to this, in the appendix, we provide results obtained withthe naive solver on CIFAR-10 to show whether the choice of the solver significantly affects theperformance. For the experiments conducted on MDEQs applied to ImageNet, our primary focus lieson the Broyden solver, as detailed in the main paper. It is worth noting that the fixed-point problem",
  "encountered in high-dimensional data introduces heightened complexities, necessitating a solver withsuperior convergence properties, as elaborated upon in (Bai et al., 2020)": "The outcomes obtained with various solvers are detailed in . Notably, while MDEQsemploying the naive solver exhibit slightly faster certification compared to those with the Andersonsolver, both the large and small architectures encounter some accuracy drops, with deviations ofup to 3%. Given that our objective is to establish MDEQs as a baseline with superior performance,we exclusively present results obtained with the Anderson solver in the main paper for meaningfulcomparison.",
  "HInstance-Level Consistency": "In the main paper, we utilize RRD as the measurement to validate the effectiveness of our method.In this appendix, we extend our evaluation to observe the performance of RRD specifically onMDEQ-SMALL architectures. As illustrated in , our method demonstrates strong performance for MDEQ-SMALL atthe instance level. Regarding RRD, SRS-MDEQ exhibits a notable concentration of small values,indicating the efficacy of our serialized randomized smoothing in aligning radii. Further insight isgained from b, where the RRDs of all samples for SRS-MDEQ-A3 are consistently smallerthan 0.2, contrasting with MDEQ-A3, which features numerous samples with large LADs. Notably,with an increasing number of steps, both MDEQ and SRS-MDEQ exhibit a trend toward increasedconcentration, with SRS-MDEQ consistently outperforming MDEQ. Besides, we also exhibit themean RRD values over the whole dataset in , consistently showing the better performance ofour SRS-MDEQ.",
  "I.1Detailed Illustration": "In this appendix, we delve deeper into the nuances of our approach to correlation-eliminated certifica-tion. As shown in , the correlation-eliminated certification is based on dropping unreliablepredictions. To be specific, our method compares the predictions of SRS-DEQ with the ones withstandard DEQ and then drops the inconsistent predictions in the most probable class cA. Thisprocess intuitively reassigns all incorrectly classified predictions from class cA to class cB, effectivelyaligning them with the predictions made by the standard DEQ. Finally, we estimate pm to get aconservative estimation of these converted samples. 0.00.20.40.60.81.0 RRD normalized frequency MDEQ-A1SRS-MDEQ-A1",
  "'": ": The illustration of our correlation-eliminated certification. If we input the noisy pandaimages into the standard DEQ and our SRS-DEQ, there will be some misalignment due to thecorrelation introduced by SRS. Our method conservatively converts these predictions back to thecorrect ones. For instance, the predictions of x + 2 are different with RS and SRS. Therefore,the prediction of x + 2 will not be counted as the most probable class cA. Finally, we use theseconverted predictions to calculate the certified radius to recover the standard DEQs predictions. Inthe implementation, we try to estimate the number of these converted predictions instead of using thestandard DEQ to get the inferences.",
  "I.2Cut-off Radius": "Given the noise variance , a sampling number N, and failure tolerance , the cut-off radius meansthe maximum radius that can be certified, i.e., the radius when all samples are classified correctly.With SRS, since we have an upper bound on pm, the maximum empirical confidence pA could belower. Here we provide analysis for the cut-off radius comparison. To be specific, we present thecomparison of the radius with different correct ratios (the percentage of class A) when there are nowrong predictions from our method (pm 0). More formally,",
  "pm = LowerConfBound(B, B, )(25)": "We provide the numerical cut-off radius with the hyperparameters used in our paper: N = 10, 000,B = 1, 000, = 0.001. The results are shown in . As a special case (when the ratio is 1),the cut-off radius of our method is 1.594, and the cut-off radius of the original method is 1.860. Forthe samples with smaller ratios, the gap between the standard method and our method will furtherdecrease because of the marginal effect (Cohen et al., 2019).",
  "I.3More Results": "In this appendix, we extend our analysis to include additional results for the correlation-eliminatedcertification, focusing particularly on the distribution of the gap and pm for MDEQ-SMALL models.These results are illustrated in and . Regarding the gap, we observe a trend consistentwith that for MDEQ-LARGE models: a predominant skew towards 0 while maintaining positivevalues, which underscores the efficacy of our estimation approach. As for pm, its distribution appearsmore uniform in MDEQ-SMALL with one step, compared to MDEQ-LARGE. This aligns with theobserved phenomenon where the certified accuracy is somewhat lower than that achieved throughstandard randomized smoothing for DEQs with a single step.",
  "JThe Number of Samplings": "We investigate the effect of the number of samplings in our randomized smoothing approach byconducting experiments with = 0.5 depicted in Figures 8 and 9. Notably, these results align wellwith those reported in (Cohen et al., 2019). Across all results, a consistent trend emerges, revealingthat there are no substantial differences observed between N = 10, 000 and N = 100, 000 acrossmost radii. This insight underscores the robustness and stability of the results, emphasizing that thechoice of the number of samplings within this range does not significantly impact the outcomes. 0.000.250.500.751.001.251.501.752.00 radius 0.0 0.2 0.4 0.6 0.8 1.0 certified accuracy N=1,000N=10,000N=100,000",
  "KWarm-up Strategy": "In our implementation, we employ a warm-up strategy to enhance the initial performance of serializedrandomized smoothing during certification. In this appendix, we delve into the effectiveness of thistechnique. The Number of Steps: We investigate the influence of the number of warm-up steps on the per-formance of our method. As shown in Figures 10a and 10b, there is a marginal improvement inthe performance of MDEQ-LARGE when the number of warm-up steps is increased to 30. Theperformance of MDEQ-SMALL remains stable. For the sake of time efficiency, we adopt 10 as thedefault parameter in our main experiments. The Warm-Up Solver: We explore whether utilizing different solvers during the warm-up phaseimpacts the performance of our method, denoting the model with the \"solver-solver\" format. Forexample, \"Anderson-Naive\" signifies the warm-up solver as Anderson and the solver for MDEQas the naive one. Conducting experiments with 10 warm-up steps and 3-step solvers, the resultsin Figures 11a and 11b indicate that the choice of warm-up solvers does not significantly affectperformance when the solvers for MDEQ are the same (as evidenced by the nearly overlapping lines)for both large and small models. In our main experiments, we consistently use pairwise solvers,where the solver for warming up aligns with that used for MDEQ. Restart: Considering the potential accumulation of fixed-point errors due to the distance of samplings,we investigate the necessity of a restart strategy for our method. Specifically, we implement thisstrategy by warming up every K batches. Employing pairwise solvers with 10 warm-up steps, theresults in Figures 12a and 12b exhibit the findings from the warm-up steps. Implementing a restartstrategy with varying intervals yields a slight performance increase. For the sake of time efficiency,we default to 10 as the parameter in our main experiments. 0.00.20.40.60.81.01.21.4 radius 0.0 0.2 0.4 0.6 0.8 1.0 certified accuracy step=10step=20step=30",
  ": Different warm-up restart intervals for SRS-MDEQ-3A": "Start Points: There are two choices for the start points of the warm-up strategy: (1) start from theclean data point x for all the noisy data x + ; (2) start from previous noisy data in each batch. Wechoose to start from the previous noisy data because it performs better than using the fixed-pointsolution of the clean data. This is because the previous noisy data provides smaller pm in thecorrelation-eliminated certification. The certified accuracy is shown in . The differencesbetween the two start initialization come from the correlated-elimination certification. The final radiuswill depend on the estimated pm (smaller pm is better). With the previous fixed point, our certificationprocess accumulates randomness to avoid the bad guess at the beginning. The distribution of pm willbe more concentrated to 0 with our method that starts from the previous solutions. It means we needto drop more predictions if we start from the clean data. As a result, the certified accuracy of startingfrom the previous fixed points is better.",
  ": The empirical performance of the randomized smoothing on SMALL-SRS-MDEQ-3A": "Projected Gradient Descent (PGD) leverages the principles of gradient descent to iteratively updateinput data. It begins with an initial input, calculates the gradient of the models loss concerning theinput, and adjusts the input in the direction that maximizes the increase in the loss. This adjustment isconstrained by a small perturbation limit to ensure that the changes remain within acceptable bounds.In the context of randomized smoothing, PGD is employed to directly target the base classifier. Weutilize a fixed step size of 0.1 for each iteration, and the total number of iterations is set at 20. Given that PGD does not directly target the smoothed classifier, we also employ Smooth-PGD toattack our model, following the methodology outlined in (Salman et al., 2019). The indirect attackproves ineffective due to the obfuscated gradient phenomenon (Athalye et al., 2018). Smooth-PGDinitially utilizes a soft version to approximate the gradient of the smoothed classifier, mitigating thenon-differentiable nature of the classifier. It then employs the Monte Carlo method to estimate thevalue of the gradient. Finally, standard PGD is employed to generate adversarial examples usingthe estimated gradient. Smooth-PGD demonstrates increased effectiveness compared to PGD whengiven sufficient samplings in Monte Carlo. Throughout our experiments, we maintain consistency inhyperparameter use between Smooth-PGD and standard PGD.",
  "Attackr = 0.25r = 0.5r = 0.75r = 1.0r = 1.25r = 1.5": "PGD6% / 0%8% / 0%13% / 0%16% / 0%20% / 0%23% / 0%m=110% / 0%22% / 0%28% / 0%32% / 0%35% / 0%39% / 0%m=410% / 0%22% / 0%28% / 0%32% / 0%34% / 0%37% / 0%m=89% / 0%21% / 0%28% / 0%33% / 0%35% / 0%39% / 0%m=1610% / 0%22% / 0%30% / 0%33% / 0%36% / 0%40% / 0% : The point-wise successful attack rate of on SMALL-SRS-MDEQ-3A.The first number isthe rate of successfully attacking the uncertified points. The second number is the rate of successfullyattacking the certified points. show the correctness of the randomized smoothing. The results are shown in Tables 25 and 26, wherer represents the attack budget. r = 0 means the predicted accuracy on clean data. It is observed thatSmooth-PGD exhibits superior strength compared to the standard PGD. The most important findingis that the certified accuracy is lower than the accuracy under all the adversarial attacks, meaning allthe attacks can not break the certified robustness in randomized smoothing. In essence, these resultsunderscore the robustness of our method, showcasing reliable certified accuracy empirically. Based on the preceding analysis, certified accuracy serves as a global metric for evaluating modelrobustness. However, to substantiate the efficacy of certification, the model must ensure that eachcertified point remains invulnerable within its corresponding certified radius. This appendix conductsan instance-level analysis to demonstrate this aspect. Specifically, we quantify the percentage ofpoints successfully attacked within the certified and uncertified subsets, respectively. The outcomesare detailed in Tables 27 and 28. The first number is the rate of successfully attacking the uncertifiedpoints, while the second number is the rate of successfully attacking the certified points. As mincreases, the first number gets larger, meaning the attack is getting stronger. In this case, the secondnumber consistently keeps as 0, meaning the certified points can not be attacked at all. Despitethe minimal failure probability in randomized smoothing certification, our point-wise empiricalinvestigation underscores the robustness and reliability of our method."
}