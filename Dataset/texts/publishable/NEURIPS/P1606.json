{
  "Abstract": "Traditional time series forecasting models mainly rely on historical numeric valuesto predict future outcomes. While these models have shown promising results, theyoften overlook the rich information available in other modalities, such as textual de-scriptions of special events, which can provide crucial insights into future dynamics.However, research that jointly incorporates text in time series forecasting remainsrelatively underexplored compared to other cross-modality work. Additionally, themodality gap between time series data and textual information poses a challenge formultimodal learning. To address this task, we propose Text2Freq, a cross-modalitymodel that integrates text and time series data via the frequency domain. Specifi-cally, our approach aligns textual information to the low-frequency components oftime series data, establishing more effective and interpretable alignments betweenthese two modalities. Our experiments on paired datasets of real-world stock pricesand synthetic texts show that Text2Freq achieves state-of-the-art performance, withits adaptable architecture encouraging future research in this field.",
  "Introduction": "The importance of incorporating textual information into time series forecasting is increasinglyevident. Real-world time series data is often influenced by external factors, such as news events,consumer feedback, and special occasions, which traditional models fail to account for . Several approaches have been proposed in response to the growing need for multimodal learning intime series forecasting. However, these methods face three significant challenges. First, the scarcityof paired datasets that combine time series and text makes the learning process difficult. Second,techniques from other cross-modality tasks, such as cross-attention, are hard to directly apply dueto the significant modality gap between time series and text. This gap is due to differences such astext being discrete and rich in semantic content, while time series are continuous, focus on temporalchanges, and often contain noise. Finally, text often encapsulates high-level patterns, such as overalltrends, leading to a one-to-many problem when directly mapping text to time series (see ). To overcome these challenges, we propose Text2Freq, a framework that align textual information totime series data through the frequency domain. Our approach includes a pre-trained text-to-frequencymodule, trained on a boarder dataset to address the issue of limited paired data. Additionally, byaligning text with the low-frequency components of time series, Text2Freq effectively bridges themodality gap and extracts clear patterns from text, enhancing interpretability. We validate Text2Freq using real-world stock price data paired with synthetic text generated byGPT-4 . To the best of our knowledge, Text2Freq is the first method to align textual informationwith low-frequency series components, leading to improved performance in mulitimodal forecastingwith more effective alignment.",
  "arXiv:2411.00929v1 [cs.LG] 1 Nov 2024": ": Illustration of alignment issues between time series and text. Starting with only the lowestfrequency NLF = 1 captures slow-changing patterns like sinusoidal waves but loses details, causingmany-to-one mapping issues from text to series. Increasing the frequency components to NLF = Tadds detail from a series but introduces noise, leading to one-to-many mapping issues. Since textencapsulates high-level patterns, this work aims to map text to an optimal subset of frequencycomponents Nopt that balances noise and information loss.",
  "Stage 1: The Pre-trained Text-To-Frequency Transformer": "As depicted in , we employ a pre-trained BERT to extract text features. These embeddingsare then mapped to the latent space of low-frequency components in a time series using a TransformerEncoder architecture . The mapped embeddings are then decoded back into the time series domainfor multimodal fusion in the next stage. Specifically, we apply the Discrete Fourier Transform(DFT) to convert the time series into the frequency domain and extract the leading low-frequencycomponents, excluding the DC component due to series normalization. To enhance the latent spacerepresentation in the frequency domain, we utilize a Variational Autoencoder (VAE) architecture,as inspired by .",
  "Stage 2: The Multimodal Fusion": "In this stage, we freeze the pre-trained Transformer Encoder from Stage 1 and focus on training theremaining components of our model: the unimodal time series forecasting model and the fusionlayer. Our objective is to effectively integrate information from both the text and the time seriespredictions into a unified representation, i.e., the time series. Specifically, we employ patching andchannel-independence architecture for the unimodal forecasting model. The fusion layer thenconcatenates the output series from text-to-frequency pre-trained model with the output from the timeseries forecasting model. This combined information is subsequently processed through an attentionmechanism to generate the final prediction. : Overview of Text2Freq. Left panel: Stage 1 - Pre-training. Text embeddings are mappedto the latent space of frequency components using a Transformer Encoder. Right panel: Stage 2 -Multimodal Fusion. The pre-trained Transformer is frozen, and the outputs from both modalities arefused using an attention mechanism.",
  "Dataset": "For our experiment, we utilized a weekly stock price dataset featuring Apple (AAPL), Microsoft(MSFT), and Google (GOOG) stocks from December 1, 2006, to November 30, 2016. To addressthe challenge of obtaining insightful textual information for each stock, we used GPT-4 to generateaccurate descriptions of future patterns by providing it with the actual future series for each instance. For our pre-trained model that aim to solve the limited dataset problem, we used the TRUCE dataset, which contains a more extensive range of paired time-series and text data. This dataset includesweekly stock prices from seven companies, totaling 1900 instances, each with a sequence lengthof 12. To enhance the models capacity, we use the same way to augment the paired text data withdescriptions generated by GPT-4.",
  "Experiment Setup": "We evaluate Text2Freq against two baseline approaches: unimodal time series forecasting models thatuse only time series data, and multimodal models that integrate both time series and text data. Forunimodal forecasting, we use PatchTST , a representative model in time series forecasting, as ourbaseline. For multimodal forecasting, we employ a attention-based methodology similar to , whereseries data is processed through a unimodal forecasting model and text data through a TransformerEncoder, with outputs combined using an attention mechanism. All models are configured with alook-back window of 36 and a prediction length of 12. Furthermore, we compared the alignment by mapping the text sequence directly to the original timeseries with mapping it to the frequency domain, to evaluate whether the frequency domain provides amore effective learning framework. Additionally, to validate the alignment phenomenon discussed in Introduction 1 and , weexamined how varying amounts of low-frequency information extracted from the original series affectthe alignment between text embeddings and time-series embeddings in the latent space.",
  "MSE0.8970.8550.8530.7640.7880.8410.840MAE0.7340.7380.7300.6860.6820.7100.700": ": Comparison of different mapping strategies. The MSE and MAE metrics are calculated basedon the loss between the output series and the original series. Text-Series maps text embeddingsdirectly to the time-series latent space, while Text-Freq maps text to the number of leading low-frequency components. Since our original series sequence length is 12, the maximum number offrequency components is 6. The best values are in bold and second best are underlined.",
  "Aligning Text to Low-Frequency Components of a Series is Beneficial": "Our method, Text2Freq, shows a 14% improvement in MSE compared to an attention-based multi-modal model. This underscores our assertion that directly learning from both time series and textcan lead to a one-to-many problem, where text may align with noisy information that should bedisregarded. Additionally, by analyzing the effect of various low-frequency components from the original series onalignment (see ) using the TRUCE dataset, we observe that including all frequency componentsduring mapping can cause one-to-many mapping issues, as previously noted. In contrast, using onlythe lowest frequency components can lead to a many-to-one problem, where multiple pieces of textualinformation map to similar wave patterns. Both scenarios present challenges for convergence and canresult in either missing or noisy information. Therefore, by carefully selecting the optimal amount oflow-frequency components, we can better capture the global trend patterns of a series, improvingmodel convergence and addressing alignment issues.",
  "Learning in Frequency Domain Yields Better Alignment": "Learning series patterns from the frequency domain offers advantages like a global view and energycompaction . This approach enhances the extraction of high-level patterns and key componentsfrom a series. As shown in , mapping via the frequency domain (with all frequency compo-nents) surpasses direct text-to-series mapping by over 6% in MSE, demonstrating that the frequencydomain serves as a more effective medium for bridging the modality gap between text and time series.",
  "Conclusion and Future Works": "In this work, we introduce Text2Freq, a novel approach that integrates textual information with timeseries through a frequency-domain learning process. Our evaluation using a real-world stock pricedataset demonstrates that mapping text to the low-frequency components of the series and combiningthis with series predictions significantly enhances time series forecasting. Furthermore, we believethat integrating our pre-trained framework with various advanced models from the fields of timeseries forecasting and natural language processing, such as foundation models, could further improvethe performance and interpretability of multimodal learning. Future work will focus on effectivelycombining models across different modalities to optimize overall performance in diverse scenarios.",
  "Harsh Jhamtani and Taylor Berg-Kirkpatrick. Truth-conditional captioning of time series data. CoRR,abs/2110.01839, 2021": "Kun Yi, Qi Zhang, Wei Fan, Shoujin Wang, Pengyang Wang, Hui He, Ning An, Defu Lian, LongbingCao, and Zhendong Niu. Frequency-domain mlps are more effective learners in time series forecasting. InNeurIPS, 2023. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, GirishSastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learningtransferable visual models from natural language supervision. In ICML, volume 139 of Proceedings ofMachine Learning Research, pages 87488763. PMLR, 2021. Dongchao Yang, Jianwei Yu, Helin Wang, Wen Wang, Chao Weng, Yuexian Zou, and Dong Yu. Diffsound:Discrete diffusion model for text-to-sound generation. IEEE ACM Trans. Audio Speech Lang. Process.,31:17201733, 2023.",
  "Ching Chang, Wen-Chih Peng, and Tien-Fu Chen. LLM4TS: two-stage fine-tuning for time-seriesforecasting with pre-trained llms. CoRR, abs/2308.08469, 2023": "Ming Jin, Shiyu Wang, Lintao Ma, Zhixuan Chu, James Y. Zhang, Xiaoming Shi, Pin-Yu Chen, YuxuanLiang, Yuan-Fang Li, Shirui Pan, and Qingsong Wen. Time-llm: Time series forecasting by reprogramminglarge language models. In ICLR. OpenReview.net, 2024. Abdul Fatir Ansari, Lorenzo Stella, Caner Turkmen, Xiyuan Zhang, Pedro Mercado, Huibin Shen, Olek-sandr Shchur, Syama Sundar Rangapuram, Sebastian Pineda Arango, Shubham Kapoor, et al. Chronos:Learning the language of time series. arXiv preprint arXiv:2403.07815, 2024. Defu Cao, Furong Jia, Sercan . Arik, Tomas Pfister, Yixiang Zheng, Wen Ye, and Yan Liu. TEMPO:prompt-based generative pre-trained transformer for time series forecasting. In ICLR. OpenReview.net,2024. Litton J. Kurisinkel, Pruthwik Mishra, and Yue Zhang. Text2timeseries: Enhancing financial forecastingthrough time series prediction updates with event-driven insights from large language models. CoRR,abs/2407.03689, 2024.",
  "ARelated Works": "Cross-modality Learning in Time SeriesRecent advances in multimodal studies have explored inte-grating text with various data types, such as images and audio . However, the intersection of textand time series remains relatively underexplored, This is largely due to the scarcity of paired datasets and thefundamental differences between time series data and textual information. Current approaches mainly transformor reprogram time series into a text modality , , to leverage large language models for forecastingor other downstream tasks. Despite these efforts, significant advancements in transforming text into time-seriesremains limited. Integrating Text with Time Series ForecastingResearch on text-guided time series forecasting is stillemerging, with a few notable contributions. TEMPO integrates textual information by decomposing seriesand using a transformer architecture. TGForecaster employs PatchTST as a backbone model with across-attention mechanism to incorporate text into forecasting. Text2TimeSeries integrates real-world eventsinto time series predictions, refining stock price forecasts by mapping event-induced changes to directional pricemovements. While these approaches improve performance over unimodal models that only take time seriesas inputs, they do not fully address the modality gap or the text-series mapping relationship. In this work, webridge the divergence between time series and text by proposing a framework that integrates textual informationinto time series forecasting in a more interpretable and effective manner.",
  "CDetail Explanation of Model Architecture": "As outlined in the main section, the proposed Text2Freq model comprises two stages: the pretraining phase andthe overall fusion model. Below, we provide further details on the architecture of each component. Details of the Pretrained Text-to-Frequency TransformerAs shown in , Stage 1 of the pretraining process includes two primary substeps: constructing aVariational Autoencoder (VAE) architecture to learn the latent space of time series data and using a TransformerEncoder to align text embeddings with corresponding series latent representations. Inspired by , we design a VAE to capture the latent space of frequency components within time series data.First, we transform each series to its frequency spectrum using the Discrete Fourier Transform (DFT). To focuson low-frequency information, we apply zero-padding to the higher frequencies, preserving a predefined numberof low-frequency components. These components are then fed into the VAE, where the encoder compresses theinput to a latent representation, and the decoder reconstructs the frequency spectrum from this latent space. To align text with series data, we adapt the approach in . Text features are extracted from a pre-trained BERTmodel, providing robust embeddings that capture semantic nuances. These embeddings are then mapped to thelatent space of the leading low-frequency components of the series using a Transformer Encoder, effectivelyaligning the text and series representations. Details of the Overall Multimodal FusionFollowing the first stage of pretraining, we freeze the pretrained Text2Freq model and assess its effectivenesswithin a multimodal framework that integrates both text and time series inputs to evaluate combined performance. For the time series input, we process the past series data through a unimodal forecasting model, as shown on theright side of . This model is designed with channel independence and a patching structure to handlesequential data effectively. For the text input, we begin by extracting features using a pre-trained BERT model, which captures the semanticcharacteristics of the text. These text embeddings are then passed through the frozen Text2Freq model to generatecorresponding series patterns. Once we obtain outputs from both modalities, we fuse them using an attention mechanism to allow effectiveinteraction between the time series and text representations, enhancing multimodal predictive performance.",
  "DLimitation": "We validate the effectiveness of the Text2Freq model using stock price data. Experimental results indicate thataligning text embeddings to the frequency domain significantly outperforms existing methods. However, weacknowledge a limitation in the dataset, as it contains information leakage: the text input used in stage 2 is basedon the ground truth description of future patterns, due to limited available data. To address this, future work willfocus on evaluating our model with real-world textual data sources, such as news articles or event descriptions,to ensure robust validation. In this paper, we also highlight the inherent challenges of aligning time series data with textual information.This alignment task presents opportunities for further research on multimodal fusion in time series forecasting,advancing the integration of diverse data types for improved forecasting accuracy."
}