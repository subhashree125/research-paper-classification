{
  "Abstract": "We present a novel approach to generating mathematical conjectures using LargeLanguage Models (LLMs). Focusing on the solubilizer, a relatively recent con-struct in group theory, we demonstrate how LLMs such as ChatGPT, Gemini, andClaude1 can be leveraged to generate conjectures. These conjectures are pruned byallowing the LLMs to generate counterexamples. Our results indicate that LLMsare capable of producing original conjectures that, while not groundbreaking, areeither plausible or falsifiable via counterexamples, though they exhibit limitationsin code execution.",
  "Introduction": "Artificial intelligence, specifically deep learning, has created much discussion around the possibilityto augment human creativity with computational capability. Among the leading technologies pushingthis discussion are large language models (LLMs) such as OpenAIs ChatGPT, Anthropics Claude,and Googles Gemini . While LLMs have been widely recognized for their competence intext generation, their interactions within abstract academic fields such as mathematics, specificallywith conjecture creation, remain under-explored. Initial work has evaluated LLMs ability to passexams like the SAT and MBA qualifying exams . More recently, efforts have focused onbench-marking their capacity to generate mathematical proofs . However, there has been littlework on bench-marking the ability of language models to act as a creative agent towards coming upwith new conjectures. In this study, we use the Claude Sonnet, Gemini 1.5, and GPT-4 APIs to both generate conjecturesand write GAP computer algebra code to check them for plausibility. GAP (Groups, Algorithms, andProgramming) is a computer algebra system designed for computational group theory and relatedareas in abstract algebra. However, GAP is not a proof assistant so does not give the user proofsfor theorems, but it can be used to check conjectures for immediate counterexamples. We workspecifically on the solubilizer subset which is a relatively new/unexplored construction in grouptheory that contains much potential for novel conjectures (see Appendix A.2). GAP computer algebracan check the conjecture for chosen groups and allows for language models to \"guess and check\".The system provides a method to mine for conjectures using language models and a pruning step toremove conjectures that are false for obvious (or sometimes non-obvious) reasons. This approachoffers a systematic method for generating and validating conjectures, combining model output withautomated computational verification without requiring a strong formal theorem prover.",
  "Related Work": "Recent studies have explored LLMs role in conjecture generation. Johansson and Smallbone observethat many of the symbolic structures generated by LLMs may already exist in training data, raisingconcerns about genuine originality . They note that GPT-4 appears to have been trained on prooflibraries like QuickSpec, Hipster, and Isabelle/HOL, providing a potential caveat for verifying theoriginality of any generated conjectures. We mitigate this challenge by deliberately focusing on a mathematical area with limited prior exposure:the solubilizer (see Appendix A.2). By iteratively updating prompts, we also attempt to steer themodels away from generating as many redundant conjectures which they also found to be a problembecause GPT-4 usually produces the same kind of generic lemmas every time . Other studies, such as Davies et al. , use machine learning to assist mathematicians in proofcreation rather than conjecture generation. In Wu et al. , LLMs are shown to autoformalize naturallanguage math into formal theorem provers like Isabelle, translating competition problems into formalproofs with impressive accuracy. In Si et al. , LLMs are evaluated on the ability to be creativeagents in coming up with research ideas, however math was touched minimally. They additionallycorroborate the claim that LLMs lack diversity in idea generation. These approaches focus onproof generation, formalization, or assistance, whereas our work emphasizes the initial creative stepof formulating new conjectures, and then provides an immediate guess-and-check step to verifyplausibility.",
  ". The LLM then generates GAP code and the GAP code is run": "If the code compiles and runs, then the outcome is recorded. If the code does not compile the LLM is prompted again to fix the code, provided withthe output of the failing program. It is given the chance to do two revisions (in practiceallowing for further revision almost never results in working code). 3. If the result is that the conjecture is false, the theorem and its result is added to the prompt,and the process is repeated with the false conjecture added to the set of ideas that are knownto fail. This process was run with three models: ChatGPT 4 (gpt-4o-2024-05-13), Claude Sonnet(claude-3-5-sonnet-20240620), and Gemini 1.5 (gemini-1.5-flash). LLMs have a Tem-perature parameter which varies the level of randomness in the outputs to a given prompt. Thisis sometimes taken as a proxy for Creativity, although this description is dispuited . Thetemperature for the Claude model was set to 1 for conjecture generation and .1 for code generation.The GPT-4 conjecture was set to 1.08 for conjecture generation and was left at default for codegeneration. The Gemini 1.5 conjecture generation was set to 1.5 (top_k: 5, top_p:.99) anddefault for code generation. The values were generated by trial and error where the authors observedqualitatively the most consistent conjecture variation without extreme hallucinations2.",
  "Examples": "The following is an example with no counter-examples from Claude:Conjecture 4.1. Let G be a non-solvable group. For any element x in G, if SolG(x) is a subgroup,then the Frattini subgroup of SolG(x) is contained in the Frattini subgroup of G. This result is simple enough that the model can be prompted to prove the conjecture with slightmodification. See appendix A.5.1. The following is a conjecture that failed from Gemini (see A.5.2):Conjecture 4.2. Let G be a non-solvable group, and let x G. If |SolG(x)| is divisible by exactlytwo primes, then one of them is 2.Output 4.3. Conjecture failed for group: PSL(3, 2) Where PSL(3, 2) is the projective special linear group of 3x3 matrices over the finite field F2. Lastly,we have an example where code could not be executed from GPT-4:Conjecture 4.4. Let G be a finite non-solvable group and x G. Then for every abelian subgroupA of G, we have SolG(x) A = {1}.",
  "Similarity Analysis": "To quantitatively measure diversity, we calculated the cosine self-similarity, and similarity betweenconjecture sets/literature. The similarity results are summarized in . Where we see a maintainedlevel of similarity throughout the experiments and between models. See Appendix A.8 for heatmaps. Scaling the system further by increasing the number of trials or generating more variations in theprompt failed to yield significantly more diverse conjectures. However the quality did not decreaseeither. This finding suggests that a different approach, such as multi-modal model interaction orcombining LLMs with automated theorem provers, could help diversity.",
  "Observations": "Among the 757 outputs generated by the LLMs, 420 unique conjectures were identified. The highnumber of duplicates shows a considerable redundancy in the results, as approximately 55.48% ofthe conjectures were deemed to be unique. While not unexpected, the duplicates suggest that LLMslikely rely on similar patterns when prompted similarly across trials as described in . However,this did not significantly hinder overall performance other than increase the number of total iterationsneeded to yield a desirable number of conjectures. Not all of the conjectures generated by the models were entirely original and was verified by one ofthe authors of the seven original solubilizer papers for all 420 unique conjectures. For example,Theorem 5.1. Let G be an insoluble group and x an element of G. Then the cardinality of cannot beequal to p2 for any prime p.",
  "shows up in and GPT-4 conjectured:Conjecture 5.2. Let G be an insoluble group and x G. Then the cardinality of SolG(x) cannot beequal to p2 for any prime p": "That being said, this result was contained in the system prompt and can be ignored. In all other casesthe models output conjectures that were distinct from anything found in literature or their systemprompt. In 109 cases (25.95%), the generated code successfully identified counterexamples, which is criticalfor falsifying conjectures. Secondly, of the 420 unique outputs, only 40 (9.52%) produced conjectureswith no counterexamples. ChatGPT significantly outperformed both Claude and Gemini in this area,generating 26.60% valid conjectures compared to Geminis 4.64% and Claudes 4.49%. This showsthat ChatGPT was more effective at producing conjectures that are plausible at first glance. However,a large portion of the GPT-4 conjectures were looking at the size of the solubilizer rather than aboutinteractions with other groups, group structure, or subgroup properties. Therefore, one could arguethat they were easier to write code for, or at least more likely to succeed based on similarity. Furtherstill, results classified as having \"no counterexamples\" by GPT-4 seemed to be qualitatively moreobvious than those by Claude or Gemini (see Conjecture A.5 vs. Conjecture A.4 vs. Conjecture A.9).Lastly, the fact that the models are able to generate novel, original conjectures at all provides promisefor these models to be used as useful tools when developing the theory of a new construction.",
  "Limitations": "A limitation observed in both models was the generation of non-executable code, which occurred in271 instances (64.52% of unique outputs). Gemini and Claude struggled more with code execution,having 81.86% and 49.44% instances of non-executable code respectively, compared to ChatGPTs37.76%. This potentially points to differences in how the models handle code syntax in GAP, howeverthe models were prompted to have a near identical code format (see Appendix A.3). This corroboratesthe idea that some conjectures set by Claude/Gemini are more difficult to write code for, and thereforemore likely to fail in this system. Interestingly, there are some examples that Claude/Gemini gave that would be much harder to check in GAP with a constrained time limit where Claude/Geminicould not write executable code (see Appendix A.5.6). Lastly, we note that the models had differentapproaches to generating code to test conjectures, with Claude and Gemini being more similar.We found that ChatGPT liked to preemptively restrict the groups it would consider. For example,ChatGPT conjectured that the solubilizer couldnt be bigger than or that it couldnt be exactly equalto any of the following numbers (for all non-solvable groups) in seperate conjectures: . While this study focuses on group theory and solubilizers, a relatively unexplored area, the approachcould be generalized to other domains. We acknowledge limitations of using GAP, an algebrasoftware. However, future work could easily extend this methodology to fields like number theory,geometry, representation theory, or combinatorics by integrating tools like SageMath, MAGMA, orother computational solvers.",
  "Future Work": "We propose the investigation of conjecture generation in fields where existing conjectures are sparseor absent. For example, LLMs could be applied to generate conjectures in newer or less exploredareas such as tropical geometry or higher homotopy theory, where automated tools exist but have yetto be fully integrated with LLMs . Furthermore, the study above was limited to using a singleLLM. If one model is better at writing code and the other is better at conjectures, using a combinationstructure could yield better results. We remark that a quantitative metric for interestingness of amath conjecture or problem seems to be elusive, nontrivial, yet useful (see Appendix A.7).",
  "Conclusion": "The study opens up several promising avenues for the use of LLMs in research. Our work, whilesmall, shows the potentially impactful way that LLMs augmented with other computational capacitycan solve more complex problem. For example, further work integrating conjecture generation withproof validation systems could streamline the process of discovery. That being said, LLM-based conjecture generation is still very limited to existing knowledge. Ratherthan producing fundamentally new ideas, LLMs are likely to lean on known results, limiting theirability to drive groundbreaking discoveries . Indeed, when thinking of language models asstatistical traversers of some sort of higher dimensional surface built from training data, it is easy toimagine that the models are not able to stray too far from what they are fed to generate the surface.Specifically, conjectures and theorems involving well-understood subgroups on which the solubilizeris inspired (think centralizer and normalizer) can serve as an incredibly large well from which anLLM can sample a new direction about the solubilizer. This may all be permissible to a practitioner ifone is only interested in clearing out the brush around a new construct such as the solubilizer; but asof writing, it should not be expected that these models will conjecture something profound. We demonstrate that combining LLMs with computational resources like GAP can successfullygenerate and test original, albeit simple math conjectures. Performance suggests that LLMs likeChatGPT, Claude, and Gemini have potential, but only on conjectures that are similar to existingideas or are otherwise simple. Furthermore, the models face significant challenges in generatingexecutable code and avoiding duplicate conjectures. Indeed, ChatGPT-4 demonstrated strongerperformance in generating conjectures that could not be immediately falsified, Claude was slightlymore effective at identifying counterexamples, and Gemini had the least redundancy likely due to thelonger context window. The high percentage of non-executable code reinforces the need for robusterror-checking and handling within the models. GAP is limited in the variety of error codes that areproduced when code fails, so other more verbose computational algebra solvers could help with errorcorrection. Lastly, further analysis of failed code generation to find patterns of failure could lead tobetter prompting for avoiding common bugs. Further work would likely include adding a formalautomated theorem prover or another form of neuro-symbolic proof engine, giving an end-to-endsystem that can generate new conjectures and prove them in a single pass. The authors arealso interested to see other new approaches for accurate conjecture generation in various abstractfields, or more generally, improvements to conjecture generation by non-LLM based models.",
  "A.2.1Background": "The solubilizer is a construct that can be attributed to Doron Hai-Reuven in from 2013. Much ofthe work in the area can be atributed to Banafsheh Akbari et al. in . The constructitself should be intelligible for anyone who has taken an introductory university algebra course,although can be potentially unpredictable to work with. It is therefore also simple for the models tounderstand, but non-trivial to produce conjectures. All of the models claim to have not heard of theconstruction before, meaning that the training data either excluded this information or did not haveenough for it to be in the knowledge base. In either case, the models seem to be able to understandthe definition once it is given, and provide often accurate assumptions about how the set behaves. Forexample, when testing these ideas on GPT-4, the model responded with the following:",
  "{e} = G0 G1 G2 Gn = G": "such that each Gi is a normal subgroup of Gi+1 and the quotient group Gi+1/Gi is abelian. Solvablegroups generalize the notion of abelian groups. Solvability is an important property in group theoryand plays a key role in Galois theory, which connects group theory with field theory. If you had adifferent concept in mind or need more information about solvable groups or another topic, pleaseclarify, and Ill be happy to assist further!\" We also further note that the model presents an almost identical response to solvabilizer instead ofsolubilizer which is another name that the set can be found under in the literature. We then presentthe definition to the model so that it can begin to formulate an understanding of the area.",
  ". The solubilizer SolG(x) is then the set of all elements y in G for which this condition holds": "This is an interesting definition, and it essentially captures the elements in G that, when paired withx, produce a solvable subgroup. The concept seems to be related to understanding the structure andsolvability properties of subgroups within G. Do you have specific questions about this definition orits properties?\" This output shows three correct assertions about the subset, so we test to see if the model can expandfurther on its understanding without more input. The model is then asked to provide some conjecturesbased on the newly learned definition. The idea is to gauge the models understanding of a singledefinition and to see what material the model relates to the new definition to conjecture somethingthat it considers to be new material. Input: Based on this definition, can you conjecture any theorems that might apply to this set?Output: Certainly! Given the definition of the solubilizer SolG(x) in a finite group G, we canpropose some conjectures or theorems. Here are a few ideas:",
  ". Non-Empty Solubilizer: For any element x in G, x belongs to SolG(x) because thesubgroup x (generated solely by x) is cyclic and hence solvable.Theorem: For any x G, x SolG(x)": "2. Subgroup Containment: If y belongs to SolG(x), then y1 (the inverse of y) also belongsto SolG(x). This is because if x, y is solvable, then x, y1 is also solvable.Theorem: For any y SolG(x), y1 SolG(x). 3. Closure under Solvability: If y1, y2 SolG(x) and their product y1y2 belongs to x, y1or x, y2, then y1y2 should also belong to SolG(x).Theorem (Conditional): For y1, y2 SolG(x), if y1y2 x, y1 or y1y2 x, y2, theny1y2 SolG(x).",
  ". Entire Group Solvability: If G itself is solvable, then for any x G, SolG(x) = G.Theorem: If G is solvable, then for all x G, SolG(x) = G": "5. Size of the Solubilizer: The size of SolG(x) provides information about the complexity ofthe groups structure in relation to solvability.Conjecture: For certain classes of groups (e.g., simple groups), the size of SolG(x) relativeto the order of G may have particular bounds or properties. All five of these ideas are true. The first four are easily proved to be correct mathematical statementsand the fifth is just a general statement that presents the (correct) expectation that the solubilizer maybe informative to studying the structure of the group.",
  "SolG(x) := {y G | x, y is soluble}": "In general, SolG(x) is not necessarily a subgroup of G. However, there are specific conditions underwhich this set does form a subgroup. It has been proven in that SolG(x) is a subgroup of G forany element x G if and only if G is a soluble group. A well-known result, attributed to Thompson , states that a finite group G is soluble if and onlyif, for every x, y G, the subgroup x, y is soluble. Thus, a finite group G is soluble if and only iffor any element x G SolG(x) = G. An important related concept is the soluble radical R(G), the largest soluble normal subgroup ofG. Guralnick et al. demonstrated that for an element x G, x R(G) if and only if x, y issoluble for all y G. Consequently, x R(G) if and only if SolG(x) = G. A common question is how the structure of a single solubilizer influences the structure of the entiregroup. For instance, it was shown in that if G contains an element x such that all elementsof SolG(x) commute pairwise, then G must be abelian. Another example, generalizes thisby proving that if there exists x G such that for every u1, u2, u3 SolG(x), the commutator[u1, u2, u3] = 1, then 3(G) = 1, implying that the group is nilpotent. Here, 3(G) is the third term",
  "in the lower central series of G. These are ideas that are more often explored by Claude and Gemini,although are harder to verify": "The arithmetic properties of solubilizers also play a crucial role in determining group structure. Forexample, if G contains an element x whose solubilizer has order p or p2 (where p is a prime), then Gis a p-group, as discussed in . These ideas seem to be of heavy focus for ChatGPT. Thompsons theorem demonstrated that a finite group G is soluble if and only if every two-generated subgroup of G is soluble. This motivates the definition of the solubilizer and highlightsits significance. Moreover, the solubilizer operates similarly to the centralizer in a group, with thesoluble radical R(G) functioning in a way comparable to the center of a group. Analogous to thecentralizer CG(x) = {y G | x, y is abelian}, the solubilizer describes solvability rather thancommutativity. However, unlike the centralizer, the solubilizer is not always a subgroup which wasinitially tough for the models to rememeber, leading to this fact requiring repetition in the prompting.",
  "A.4.1Claude": "Example with no counterexamples from Claude:Conjecture A.1. Let G be a non-solvable group. For any two elements x, y G, if SolG(x)SolG(y)is non-empty, then SolG(x) SolG(y) contains a non-trivial normal subgroup of G. The following conjecture failed:Conjecture A.2. Let G be a non-solvable group. For any element x in G, if SolG(x) is a subgroupof G, then the derived subgroup [SolG(x), SolG(x)] is contained in the Fitting subgroup of G.Output A.3. Conjecture failed for group: A5 In a similar example, the model could not write code that executed properly:Conjecture A.4. Let G be a non-solvable group. For any element x in G, if SolG(x) is a propersubgroup of G, then the intersection of SolG(x) with its normalizer in G is always properly containedin the normalizer of the Fitting subgroup of G.",
  "The following had no counterexamples from ChatGPT 4:Conjecture A.5. For any finite non-solvable group G and any element x G, the set SolG(x) is nota cyclic group": "Similarly GPT-4 suggested that the following be true although it was immediately obvious to be false:Conjecture A.6. For any element x G of a non-solvable finite group G, the set SolG(x) containsall elements of a certain conjugacy class in GOutput A.7. Conjecture failed for group: A5 Where A5 is the alternating group on five elements (see A.5.4). Lastly, an example where GPT-4could not execute code for the conjecture:Conjecture A.8. For any finite non-solvable group G, there exists an element x G such thatSolG(x) is a nilpotent subgroup of G.",
  "A.4.3Gemini": "The following is a conjecture with no counterexample:Conjecture A.9. Let G be a finite non-solvable group and suppose x G is not an element ofthe soluble radical R(G) of G. Assume that x, xy is not solvable for any element y G. Thenx, SolG(x) = SolG(x) for all x G. The following is a conjecture that is false:Conjecture A.10. Let G be a finite non-solvable group. For any element x of G, the probability thata randomly chosen element y G is contained in SolG(x) is less than or equal to the probabilitythat y is contained in the radical of G.Output A.11. Conjecture failed for group: A5",
  "Where, again, A5 is the alternating group on 5 elements (see A.5.5). The following is a conjecturewhere code could not be executed:": "Conjecture A.12. Let G be a finite non-solvable group. Let x, y be two non-commuting elements ofG such that the subgroups generated by x and y, x, y, is solvable. Then the probability of findinga third element, w G, that commutes with both x and y, subject to the additional condition thatat least one of the two groups x, w or y, w is solvable must be equal to at most the product ofprobabilities of a non-commutation of x and y and the existence of w that commutes with y and x.",
  "The following conjectures are just a couple of the conjectures that had code that was unable to be runbut are still potentially interesting from Claude:": "Conjecture A.13. Let G be a non-solvable group. For any element x in G, if SolG(x) is a propersubgroup of G, then the intersection of SolG(x) with all of its conjugates in G is always contained inthe hypercenter of G.Conjecture A.14. Let G be a non-solvable group. For any element x in G, if SolG(x) is a propersubgroup of G, then the normalizer of SolG(x) in G contains at least one element from each non-abelian composition factor of G.Conjecture A.15. Let G be a non-solvable group. For any element x in G, if SolG(x) is a propersubgroup of G, then the commutator subgroup [SolG(x), G] contains at least one non-identity elementfrom each non-abelian composition factor of G.Conjecture A.16. Let G be a non-solvable group. For any element x in G, if SolG(x) is a propersubgroup of G, then the intersection of SolG(x) with its normalizer in G is always metabelian.Conjecture A.17. Let G be a non-solvable group. For any element x in G, the subgraph of the powergraph of G induced by SolG(x) is always connected.",
  "No Counter-Examples22Couldnt Execute Code1Conjecture Failed28": "Perhaps unsurprisingly, the new model was able to execute code properly roughly 98% of thetime. Furthermore, the model only once needed to take a debug step. The authors believe that theconjectures are not any significantly more interesting than the other ones given by Gemini and Claude,although this model does give more interesting conjectures than GPT-4 in terms of the willingnessto give conjectures about relation of the solubilizer to other subgroups, conjugacy classes, etc. Wenote that this model was more willing to stray from the system prompt in the GAP code wherein itgenerated code that checked non-solvable groups that were not simple. Lastly, observe that all ofthe conjectures are unique, which leaves this model so far being (albeit with a lower than desireablenumber of samples to make a strong claim) the best one to use for this task in all aspects. The authorsintend to explore this further in the coming weeks.",
  "A.6.1OpenAI o1 Examples:": "The following are four randomly chosen examples and their output.Conjecture A.18. In any finite non-solvable group G, the intersection of SolG(x) over all x G \\ R(G) is equal to R(G), the solvable radical of G.Output A.19. No Counter-examples!Conjecture A.20. In any finite non-solvable group G, for any element x G \\ R(G), there does notexist an element y SolG(x) such that x, y = G.Output A.21. No Counter-examples!Conjecture A.22. In any finite non-solvable group G, for any elements x, y G \\ R(G), ify SolG(x), then x / SolG(y).Output A.23. Conjecture failed for group: A5Conjecture A.24. In any finite non-solvable group G, for any elements x, y G \\ R(G), if x, y issolvable, then x and y are both contained in a common solvable maximal subgroup of G.",
  "A.7Conjecture Interestingness": "In mathematics, evaluating the interestingness of a conjecture or problem is inherently subjectiveand resists quantification. However, if one seeks a quantitative approach, there are several aspectsto be considered: the conjectures depth, its generality or specificity, its implications for otherfields, simplicity of solution, and whether it leads to significant advancements or novel methods.Indeed, some of these are impossible to predict, and are not always necessary for a conjecture tobe labeled interesting. Some conjectures, like the Riemann Hypothesis, have clear applications to awide range of fields, yet others garner interest without obvious practical use. Consider the CollatzConjecture: despite its straightforward formulation, the conjecture resists resolution and has fewknown applications, yet it draws wide attention due to its seemingly simple, though elusive nature.Furthermore, a conjectures interestingness often depends on historical context, cultural influencewithin mathematical communities, and its perceived difficulty or elegance. Another difficulty in quantifying interestingness is the risk of conflating technical complexity withprofundity. A conjecture could be formally intricate yet lack broader appeal or connection toother domains. Additionally, highly specialized conjectures may be overlooked by non-specialistsdespite their beauty or importance for those knowledgebale in the field. Further, the evolving natureof mathematical interest itself becomes an issue; conjectures once regarded as obscure can gainrecognition as foundational connections become clearer. Nevertheless, certain conjectures seem almost universally intriguing. The Poincar Conjecture andFermats Last Theorem captivated broad attention due to their simplicity, profound implications, andhistorical legacy. If just pieces of these ideas could somehow be built into a standardized metric,many studies will surely benefit.",
  "A.8Similarity Analysis": "We include figures that show the similarity heatmaps between conjectures below. It is visuallyapparent from these maps that Claude in general had the most syntactic similarity. Indeed, withconjectures exampled as the following A.27A.28, the entire structure of the first conjecture is heldwithin the second but they are not the same idea. Conjecture A.27. \"Let G be a finite non-solvable group. Then for any element x in G, if SolG(x) isa proper subgroup of G, there exists a prime p dividing |G| such that SolG(x) intersects at least twodistinct Sylow p-subgroups of G non-trivially.\" Conjecture A.28. Let G be a finite non-solvable group. Then for any element x in G, if SolG(x) is aproper subgroup of G, there exists a prime p dividing |G| such that SolG(x) intersects at least twodistinct Sylow p-subgroups of G non-trivially, but does not contain any full Sylow p-subgroup of G. GPT-4 clearly has the most syntactic differences in the conjectures. While many of the conjecturesreference the same idea, the way that they are stated is highly variable. Claude and Gemini both havea more methodical approach which show up as lighter colored squares. One can see that Geminialso had a period of runtime where the conjectures were mostly structured similarly with differentmodifiers at the end of the conjecture. The authors are unsure why these structural loops seem tooccur periodically throughout the repeated process, but they are interesting to note regardless. Inthese patches there didnt seem to be a significant difference in the quality of conjecture. With regards to the similary with the literature, non-surprisingly GPT-4 had the highest similarity dueto the reproduction of a conjecture from literature as noted above. Otherwise, the distinction in themodels between themselves was roughly comparable with that in literature. We note that Claude hadthe lowest maximum similarity, that all of the models had a minimum similarity of zero, and that onaverage, the models were slightly more disjoint from literature than they were from each other."
}