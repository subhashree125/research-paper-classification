{
  "Abstract": "Federated Learning (FL) is a form of distributed learning that allows multipleinstitutions or clients to collaboratively learn a global model to solve a task. Thisallows the model to utilize the information from every institute while preserv-ing data privacy. However, recent studies show that the promise of protectingthe privacy of data is not upheld by existing methods and that it is possible torecreate the training data from the different institutions. This is done by utilizinggradients transferred between the clients and the global server during training orby knowing the model architecture at the client end. In this paper, we proposea federated learning framework for semantic segmentation without knowing themodel architecture nor transferring gradients between the client and the server,thus enabling better privacy preservation. We propose BlackFed - a black-boxadaptation of neural networks that utilizes zero order optimization (ZOO) toupdate the client model weights and first order optimization (FOO) to updatethe server weights. We evaluate our approach on several computer vision andmedical imaging datasets to demonstrate its effectiveness. To the best of ourknowledge, this work is one of the first works in employing federated learningfor segmentation, devoid of gradients or model information exchange. Code:",
  "Introduction": "With data-driven methods becoming immensely popular in Artificial Intelligence (AI) research andapplications, there has been a surge in data collection and curation across the world. This has, inturn, led to the development of AI models that require substantial amounts of data to train. FederatedLearning (FL) was developed as a viable approach towards training such models by effectivelyharnessing the data collected at different centers across the world. Through FL, it becomes possible formultiple institutions to collaborate and build a joint model that learns from all of them, while reducingthe burden of collecting more data individually. However, collaborations between different institutionspresent a non-trivial challenge due to disparity in data distributions as well as the imperative ofsafeguarding data privacy. Consequently, FL aims to jointly learn a shared model that performs wellon data from all participating institutions without exchanging raw data. Various FL approaches havebeen proposed in the literature . Among",
  "arXiv:2410.24181v1 [cs.CV] 31 Oct 2024": ": Comparison of our method against traditional FL methods. Existing FL methods areprimarily \"white-box\" as they involve transfer of model weights , or gradients. In contrast,our method only utilizes forward passes to update the client and does not require sharing weights orgradients, making it a \"black-box\" model. these, FedAvg was one of the pioneering FL methods, which proposes training local models atevery center using local data and periodically averaging the local model weights to craft a globalserver model. Various subsequent works improve FedAvg by improving the local model updates or global updates . While FL was primarily proposed for classification tasks, it is also suited for other computer visiontasks such as segmentation. Generating annotations in segmentation entails creating pixel-levelannotations per image, that are more tedious to label than classification tasks. Consequently, itis not always possible for a single institution to collect a large amount of data, underscoring theimportance of collaborative efforts. A few approaches have been proposed in the literature forFL-based segmentation . However, all these methods for segmentation andclassification, while not involving raw data transfer, employ techniques like model informationtransfer or gradient transfer , as shown in . However, recent researchhas revealed that these techniques are vulnerable to attacks that can recreate training data from theparticipating centers, thus undermining the privacy preserving characteristic of FL . These attacks employ methods like gradient inversion or adaptingmodel architecture and weights . In this work, we propose a new approach, named BlackFed,for segmentation using FL that does not involve gradient transfer between the server and the clientand at the same time, passes no knowledge about the client model architecture to the server, therebyavoiding the necessary conditions for these attacks, as shown in . This is done by formulatingthe FL learning problem as a distributed learning problem using split neural networks (split-nn) and combining first order and zero order optimization techniques for training. Our contributions areas follows: 1. We introduce BlackFed - a black-box algorithm that facilitates distributed learning forsemantic segmentation without transferring model information or gradients between theclient and the server. For this, we formulate the FL problem using split-nn and use first andzero order optimization for training the server and the clients, respectively.",
  "Related Work": "Federated Learning for Segmentation:FL for the segmentation tasks was motivated by itsimmense application in the medical domain. Consequently, various methods were introduced in thisfield . For instance, attempts to learn a model for brain tumor segmentation by utilizing data from multiple institutions. FedSM attempts to mitigate theeffect of non-iid nature of the data from different centers on the global server model. However, mostof the approaches for medical segmentation focus on the problem of segmenting out the foregroundfrom the background (one class problem). There are relatively fewer works in the literature formulti-class segmentation . FedSeg deals with the class label inconsistencyproblem that may be present at the local clients. In other words, it builds a robust system that workswell even when the clients have annotations for only a subset of the classes. FedDrive , on theother hand, sets up various benchmarks for FL algorithms on multi-class datasets like Cityscapes .However, all the existing algorithms require the global server to know the model architecture used inthe clients and thus, these methods are vulnerable to recent attacks . In our work, we developan algorithm to perform multi-class segmentation which does not require gradients or client modelsharing. Split Neural Networks:Split networks were introduced as an alternative to FedAvg-liketechniques which require model sharing. They offer an approach to perform collaborative learningby splitting a larger network into two segments. The latter segment of the network is shared acrossall centers and placed at the global server, while the former part is distributed such that each centerpossesses its own sub-network. During training, the clients perform a forward pass using their dataand send the encoded features to the server, which further passes the features to the subsequentlayers in the network. The server and client models are trained using backpropagation, where thegradients from the first layer of the server model are sent back to each of the clients. Split networkshave mainly been used in the literature for the task of classification, mostly in the medical domain. Our work marks one of the initial explorations of split learning in the context of semanticsegmentation. Furthermore, split networks are shown to be more robust to reconstruction attackswhich arise from sharing model information . Nonetheless, they remain susceptible to gradientleakage attacks since there is gradient transfer between the server and the client. In this work, weformulate the problem of distributed semantic segmentation using split network and introduce atraining algorithm that does not require gradient-sharing.",
  "Preliminaries": "The setting of FL consists of N clients, denoted by Ci, where i1, 2, ..., N and aglobal server G.Each of the clients has a local dataset, consisting of images Xi=xij RHW C; j {1, 2, ..., ni}and their corresponding ground truth segmentation mapsYi =yij RHW Nc; j {1, 2, ..., ni}. Here, xij and yij represent the jth image and its cor-responding segmentation mask, while ni represents the number of data points in client i and Ncrepresents the number of classes in the output. Note that the distributions of the input images varyamong the clients. Each client uses its dataset to learn a function f i : RHW C RHW Nc,which is parameterized by i, that minimizes its local loss function as follows:",
  "Proposed Algorithm": "Proposed Problem Formulation: In this work, we model the problem of distributed learning usinga split neural network, which takes away the requirement of the server being aware of the clientarchitecture. In this case, each client learns a function f i : RHW C RHW C, which isparameterized by i. Similarly, the global server learns a function g : RHW C RHW Nc,which is parameterized by . Thus, the forward pass for a given center is given as follows:",
  "j=1l(yij, yij; i, ).(5)": "As in the existing FL literature, the goal of our approach is that after training, all clients should benefitfrom each other. Hence, during evaluation, given any client, we aim to perform well on data fromother clients as well as its own data, thus showing good generalization. More specifically, we want tooptimize any combination of data and client as follows:",
  "j=1l(yij, yij; k, ).(6)": "One way to optimize this equation is by attending to every client in a round-robin fashion. Thisinvolves selecting a client, performing the forward pass, as defined in Eq. 4 and then performingbackpropagation to update the server and client using the client loss function defined in Eq. 5.Performing this operation several times in a round-robin fashion enables the server to learn from allclient sources, and hence, improves the overall performance. We term this method as \"White-boxRound-Robin FL\", and is similar to the existing methods in the literature . However, recentworks have shown that such a method which involves transfer of gradients between the server andclient can be utilized to regenerate the training data, thus undermining the privacy preservationprinciple of FL . Hence, we add one more constraint - i.e. no gradient can flow back from theserver to the client in Eq. 5. BlackFed Algorithm: To optimize the clients without using gradients, we utilize a ZOO methodcalled Simultaneous Perturbation Stochastic Approximation with Gradient Correction (SPSA-GC) which involves perturbing the weights of the client model slightly and approximating a two-sidedgradient based on the change in the loss function due to the perturbations. However, this method wasdeveloped to perform black-box adaptation of pretrained foundation models and hence, expects theserver model to be initialized with good weights, which is not the case in our formulation, making itnon-trivial. To overcome this, we propose to iteratively use an alternating optimization technique,which factorizes the optimization problem in Eq. 5 into two optimization problems as follows:",
  "(7)": "During training, we first select a client using the round-robin policy. Next, keeping the server weightsfixed, we train the client weights using SPSA-GC for a few iterations. Next, we fix the client weightsand use a first order optimizer (i.e. Adam-W) to optimize the server for a few iterations. This processis repeated multiple times. During inference for a client, we simply run the forward pass as describedin Eq. 4 using the final weights of the client and server. The training process is described in Algorithm1. We refer to this approach as BlackFed v1.",
  "end forReturn: , End": "Reducing the Effect of Catastrophic Forgetting: Since the model at the server is shared among allthe clients and is updated in a round-robin fashion, it may happen that training with the data from agiven client may cause it to unlearn patterns for the previous client. This phenomenon is often calledcatastrophic forgetting. This effect is observed in BlackFed v1 especially when the number of clientsincreases or if there is a significant change in the data distribution among clients. This causes thealgorithm to perform well on certain clients and poorly on the rest of the clients. To reduce the effectof catastrophic forgetting, we propose a simple additional step during training with Algorithm 1.After updating the server weights for a given client during training, we store the updated weights ofthe server model in a hashmap indexed by the index of the client. During inference for a given client,we use the latest weights of the client model and the indexed weights of the server model to performthe forward pass. Note that the server state is loaded from the hashmap only during inference. Duringtraining, the server still benefits from the data from all clients and updates its weights as well as thehashmap. This approach is visualized in . We refer to this method as BlackFed v2.",
  "Experiments and Results": "Datasets:For evaluating our method, we consider four publicly available datasets, namely (i)Cityscapes (ii) CAMVID , (iii) ISIC and (iv) Polypgen . Cityscapes andCAMVID are two road-view semantic segmentation datasets with 19 and 32 classes of interestrespectively, collected from multiple cities. In the FL setup, we consider each of the cities as separateclients. While CAMVID has predefined train, test and validation splits, for Cityscapes, we dividethe data from each client into training, validation and testing splits for that client in a 60:20:20 ratio.In this manner, we generate 18 clients for Cityscapes and 4 clients for CAMVID. Further detailsabout the dataset size in each center is provided in the supplementary document. The ISIC datasetcorresponds to a skin lesion segmentation challenge. We generate three clients for this dataset, whichutilize the datasets from ISIC 2016 , ISIC 2017 and ISIC 2018 , respectively. The dataevery year is collected from different centers and hence, has different distribution amongst centers.Finally, PolypGen is a colon polyp segmentation dataset which was collected from six differentcenters. The training, validation and testing splits for each of these were done in a 60:20:20 ratio forPolypgen whereas they were already provided for ISIC. We visualize the pixel-intensity histogramsof the CAMVID and ISIC datasets to verify different data distributions amongst clients in .",
  "Experimental Setup: We use a two-layer convolutional network for modeling f in the client andDeepLabv3 for modeling g in the server. The number of output channels from the client is kept": ": The BlackFed v2 Algorithm. During training, the client is selected in a round-robin fashion.Then (a) client performs a forward pass using its part of the network (b) Server performs a forwardpass using its part of the network (c) With server weights fixed, client weights updated using ZOO(d) Keeping client weights fixed, server weights updated using FOO (e) The best server weights arestored in the hashmap corresponding to client index. During inference, the client performs a forwardpass and calls the server with the output. Server queries the hashmap using the client index and getsits set of weights, using which the prediction is obtained. Note that there is no gradient transfer, thusmaking this a black-box setup. : Pixel Density distribution of (L) the CAMVID Dataset and (R) the ISIC Dataset. Sincemajority of ISIC pixels are either 0 or 255 for all centers, these have been omitted for bettervisualization. Since each of the clients has a different distribution, data from one client can beconsidered as Out-of-Distribution (OOD) for other clients. as 64. Consequently, we start the DeepLabv3 network in the server from the second layer, whichexpects a 64-channel input. During training, we use c_e = 10 and s_e = 10. The server is optimizedusing an Adam optimizer and the client is optimized using SPSA-GC. The learning rates of boththe client and the server are set to 104, based on validation set performance. The batch size for allexperiments is 8, and all images undergo random brightness perturbation with brightness parameterset as 2. The images for Cityscapes and CAMVID are resized to 256 512 to maintain their aspectratio, whereas the images for ISIC and Polypgen are resized to 256 256. All experiments are doneusing a single Nvidia RTX A5000 GPU per client and a single Nvidia RTX A5000 GPU at the server. Results: Given the trained client models and the trained server model, we assess a given clientsperformance with test datasets from its own local data repository and present the mIoU in the \"Local\"column. This metric represents the local performance of the model on its own dataset. In addition,we assess each client on test data from other centers and note down the average mIoU scores in theOut-of-Distribution (\"OOD\") column. This metric serves as an estimate of the general performanceof a given client post-training. We consider the latter more important as it can be considered to bethe direct outcome of the FL paradigm. These results are presented in for CAMVID andCityscapes, and in for ISIC and Polypgen. For both tables, in the first row, each client is : Comparison of our method against individual training. The third and fourth columns denotetesting with the local test data, while the fifth and sixth columns denote OOD testing. Our methodimproves OOD performance of clients without harming their local performance. trained on its own dataset, independently of others, indicating no collaboration. For this case, whilethe client performance on its own test set is high, its general performance suffers. The next tworows represent our method (BlackFed v1 and v2). Notably, BlackFed v2 generally exhibits betterperformance than v1 since it addresses the catastrophic forgetting that occurs during training. Thefollowing three rows represent the expected upper bounds to our performance. \"Combined Training\"represents the scenario where raw data can be freely shared and a single model is trained usingthe combined data from all clients. \"White-box training\" represents the case where gradients canflow freely between the server and the client. Thus, instead of the ZOO optimization, we use FOOto optimize the client part of the model. Finally, the last three rows represent the performance oftraditional FL using FedAvg, and recent methods like FedPer and FedSeg, where model sharing isallowed. Here, all the clients follow the same model architecture as the server (DeepLabv3) and theserver can aggregate weights from the client models. All three methods represent a relaxation overthe constraints imposed in our approach, thus acting as an upper bound to the black-box performance.During training, the client and server models are trained for the same number of epochs per client.This produces a more uniform distribution of results across centers, in contrast with traditional FLmethods like FedAvg, where the aggregation of weights is weighed by the client dataset size. Weobserve that for the Polypgen dataset, BlackFed v1 and v2 perform slightly better or on par withindividual client performance for OOD case. For this case, there is little difference between theperformance of v1 and v2. This behavior may be related to the data distribution of Polypgen andsuggests that BlackFedv2 is not able to correctly avoid the catastrophic forgetting for centers C5 andC6. However, for rest of the scenarios, we see that v2 significantly outperforms v1 as well as theindividual training cases on OOD mIoU metric. At the same time, the performance on local data doesnot suffer significantly as compared to the individual training. Moreover, BlackFed v2 performs onpar with \"Combined\" and \"White-box\" Training. All results of BlackFed have a p-value less than0.001, showing the statistical significance of our black-box approach. The visual comparisons for ourmethod with the individual training is given in . As can be seen in all four rows, individualtraining can lead to overfitting, which harms the general OOD performance. Using our method,we are able to improve the OOD results across all datasets without significant decrease in the localresults. Additional Model Architectures While we evaluate a DeepLabv3-based server in our main exper-iments, we show the effectiveness of our method on additional segmentation architectures. Morespecifically, for the CAMVID dataset, we choose UNext and SegFormer as the servermodels and present average mIoU results across the test datasets from each client in . As canbe seen from the table, using our approach can improve the performance over individual trainingfor all three models. As the model complexity increases from UNext to DeepLab to Segformer, we : mIoU scores for BlackFed v1 and v2 in comparison with individual and FL-based trainingstrategies for natural datasets. \"Local\" represents test data from the center. \"OOD\" represents meanmIoU on test data from rest of the centers. For FedAvg and Combined Training, just one model istrained. Hence, its performance is noted only in each of the local test datasets. For Cityscapes, weonly present the average local and OOD performance across centers for brevity. The supplementarycontains an expanded version for Cityscapes.",
  "BlackFed v10.550.670.790.650.780.680.660.660.710.71BlackFed v20.700.720.780.660.810.700.750.720.750.74": "Combined Training0.74-0.81-0.84-0.77-0.77-White-box Training0.670.730.810.720.800.680.740.700.750.75FedAvg 0.64-0.76-0.84-0.76-0.79-FedSeg 0.71-0.79-0.83-0.77-0.81-FedPer 0.650.570.770.680.820.710.760.660.780.72 : mIoU scores for BlackFed v1 and v2 in comparison with individual and FL-based trainingstrategies for medical datasets. \"Local\" represents test data from the center. \"OOD\" represents meanmIoU on test data from rest of the centers. For FedAvg and Combined Training, just one model istrained. Hence, its performance is noted only in each of the local test datasets.",
  "BlackFed v10.590.550.630.510.640.560.550.470.340.530.280.400.840.820.890.800.50.69BlackFed v20.590.560.640.490.650.510.500.470.350.490.260.410.860.800.880.800.770.88": "Combined Training0.71-0.79-0.81-0.67-0.57-0.60-0.87-0.89-0.76-White-box Training0.60640.770.590.720.580.610.570.480.620.590.620.560.700.730.660.770.68FedAvg 0.68-0.78-0.83-0.61-0.54-0.64-0.87-0.87-0.78- observe a decrease in individual training performance. This trend is reversed for the combined casewhere there is more training data. This observation indicates overfitting in the individual case due toless individual training data. Using our method, we are able to correctly match the performance andtrend of combined training.",
  "Ablation Studies": "Analysis of the Order of Optimization: In the alternating optimization proposed in Eq. 7, wechoose to first update the client followed by the server. This order is important since it allows us tostore the correct server weights in the hashmap. If the server is trained before the client, we found thatSPSA-GC often gives unstable results and reduces the metric on the validation set after an epoch. Thisis corrected only when its the turn of the same client again. Conversely, in the case where the clientis updated first, the server adapts in a stable manner to the client weights since backpropagation isallowed in the server. Consequently, in the same epoch, we get a higher and more stable performance",
  "for each client, which can be saved in the hashmap for usage during inference. We demonstrate thisempirically by comparing the performance of the two training strategies in": "Analysis of Computational Cost: For each of the three model architectures, namely DeepLabV3,UNext and Segformer, we calculate the floating point operations required in a single forward pass atthe institution end. These are shown in . If the clients were to train individual models withtheir local data, they would require running the entire forward pass on their local systems. This isalso the case in existing FL approaches like FedAvg. In the proposed approach, as can be seen fromRow 3 in the table, the client has a significantly reduced load, with the majority of computation beingoffloaded to the server. The server uses the respective architectures starting from the second layer,while all the clients use a two-layer convolution network, with the second convolutional layer beingsimilar to the first layer of the respective architecture.",
  "Conclusion": "In this work, we introduce BlackFed, an FL algorithm that enables distributed learning without transferof gradients or model weights. This characteristic distinguishes our approach as a black-box modelcompared to existing FL methods, which can be considered as white-box approaches. Recent researchon attacking FL methods require the knowledge of either the gradients or the model information, thusrendering BlackFed more resistant to such attacks since gradients or weights are not shared. BlackFedconsists of a global server and multiple clients, each possessing their own data. The server is optimizedusing first order optimization while the client weights are updated using zero order optimization in around-robin fashion. This introduces the effect of catastrophic forgetting in the network, for whichwe propose a simple hashmap-based approach. During training, we store the client weights per server so that they can be utilized during inference. With these modifications, our approach demonstratessuperior results compared to non-collaborative training and matches the performance of white-boxmethods, despite being a black-box method itself. Extensive experimentation on the natural andmedical domain datasets highlights the effectiveness of BlackFed. Through this endeavor, we aimto propel research towards the development of better privacy preserving federated learning systems.Potential directions for future research can include analysis of other policies for selecting client orderduring training, and its relation with the disparity in data distribution. One more interesting directionfor future research would be the effect of adversarial attacks using generative models on this method.Since masks are shared between the client and server, it would be interesting to check if existingmethods are able to recreate client data using them.",
  "Chen, L.C., Papandreou, G., Schroff, F., Adam, H.: Rethinking atrous convolution for semanticimage segmentation (2017)": "Codella, N.C.F., Gutman, D., Celebi, M.E., Helba, B., Marchetti, M.A., Dusza, S.W.,Kalloo, A., Liopyris, K., Mishra, N., Kittler, H., Halpern, A.: Skin lesion analysis to-ward melanoma detection: A challenge at the 2017 international symposium on biomedi-cal imaging (isbi), hosted by the international skin imaging collaboration (isic). In: 2018IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018). pp. 168172 (2018). Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U.,Roth, S., Schiele, B.: The cityscapes dataset for semantic urban scene understanding. 2016IEEE Conference on Computer Vision and Pattern Recognition (CVPR) pp. 32133223 (2016), Dayan, I., Roth, H.R., Zhong, A., Harouni, A., Gentili, A., Abidin, A.Z., Liu, A., Costa, A.B.,Wood, B.J., Tsai, C.S., Wang, C.H., Hsu, C.N., Lee, C.K., Ruan, P., Xu, D., Wu, D., Huang, E.,Kitamura, F.C., Lacey, G., de Antnio Corradi, G.C., Nino, G., Shin, H.H., Obinata, H., Ren, H.,Crane, J.C., Tetreault, J., Guan, J., Garrett, J.W., Kaggie, J.D., Park, J.G., Dreyer, K., Juluru, K.,Kersten, K., Rockenbach, M.A.B.C., Linguraru, M.G., Haider, M.A., AbdelMaseeh, M., Rieke,N., Damasceno, P.F., e Silva, P.M.C., Wang, P., Xu, S., Kawano, S., Sriswasdi, S., Park, S.Y.,Grist, T.M., Buch, V., Jantarabenjakul, W., Wang, W., Tak, W.Y., Li, X., Lin, X., Kwon, Y.J.,Quraini, A., Feng, A., Priest, A.N., Turkbey, B., Glicksberg, B., Bizzo, B., Kim, B.S., Tor-Dez,C., Lee, C.C., Hsu, C.J., Lin, C., Lai, C.L., Hess, C.P., Compas, C., Bhatia, D., Oermann, E.K.,Leibovitz, E., Sasaki, H., Mori, H., Yang, I., Sohn, J.H., Murthy, K.N.K., Fu, L.C., de Mendona,M.R.F., Fralick, M., Kang, M.K., Adil, M., Gangai, N., Vateekul, P., Elnajjar, P., Hickman,S., Majumdar, S., McLeod, S.L., Reed, S., Grf, S., Harmon, S., Kodama, T., Puthanakit,T., Mazzulli, T., de Lavor, V.L., Rakvongthai, Y., Lee, Y.R., Wen, Y., Gilbert, F.J., Flores,M.G., Li, Q.: Federated learning for predicting clinical outcomes in patients with covid-19.Nature Medicine 27(10), 17351743 (Oct 2021).",
  "Fowl, L., Geiping, J., Czaja, W., Goldblum, M., Goldstein, T.: Robbing the fed: Directlyobtaining private data in federated learning with modified models (2022)": "Gao, L., Fu, H., Li, L., Chen, Y., Xu, M., Xu, C.Z.: Feddc: Federated learning with non-iid datavia local drift decoupling and correction. In: IEEE Conference on Computer Vision and PatternRecognition (2022) Geiping, J., Bauermeister, H., Drge, H., Moeller, M.: Inverting gradients - how easy is it tobreak privacy in federated learning? In: Proceedings of the 34th International Conference onNeural Information Processing Systems. NIPS 20, Curran Associates Inc., Red Hook, NY,USA (2020) Gong, X., Sharma, A., Karanam, S., Wu, Z., Chen, T., Doermann, D., Innanje,A.: Ensemble attention distillation for privacy-preserving federated learning. In: 2021IEEE/CVF International Conference on Computer Vision (ICCV). pp. 1505615066 (2021). Guo, P., Yang, D., Hatamizadeh, A., Xu, A., Xu, Z., Li, W., Zhao, C., Xu, D., Harmon, S.,Turkbey, E., Turkbey, B., Wood, B., Patella, F., Stellato, E., Carrafiello, G., Patel, V.M., Roth,H.R.: Auto-fedrl: Federated hyperparameter optimization for multi-institutional medical imagesegmentation (2022)",
  "Li, T., Sahu, A.K., Zaheer, M., Sanjabi, M., Talwalkar, A., Smith, V.: Federated optimization inheterogeneous networks (2020)": "Li, W., Milletar, F., Xu, D., Rieke, N., Hancox, J., Zhu, W., Baust, M., Cheng, Y., Ourselin, S.,Cardoso, M.J., Feng, A.: Privacy-preserving federated brain tumour segmentation. In: Suk, H.I.,Liu, M., Yan, P., Lian, C. (eds.) Machine Learning in Medical Imaging. pp. 133141. SpringerInternational Publishing, Cham (2019) Liu, Q., Chen, C., Qin, J., Dou, Q., Heng, P.A.: Feddg: Federated domain generalizationon medical image segmentation via episodic learning in continuous frequency space. TheIEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (2021) McMahan, B., Moore, E., Ramage, D., Hampson, S., Arcas, B.A.y.: Communication-EfficientLearning of Deep Networks from Decentralized Data. In: Singh, A., Zhu, J. (eds.) Proceedingsof the 20th International Conference on Artificial Intelligence and Statistics. Proceedingsof Machine Learning Research, vol. 54, pp. 12731282. PMLR (2022 Apr 2017),",
  "Michieli, U., Ozay, M.: Prototype guided federated learning of visual feature represen-tations. ArXiv abs/2105.08982 (2021),": "Naeem, A., Anees, T., Naqvi, R.A., Loh, W.K.: A comprehensive analysis of recent deepand federated-learning-based methodologies for brain tumor diagnosis. Journal of Personal-ized Medicine 12(2) (2022). Oh, C., Hwang, H., Lee, H.y., Lim, Y., Jung, G., Jung, J., Choi, H., Song, K.: Blackvip:Black-box visual prompting for robust transfer learning. In: Proceedings of the IEEE/CVFConference on Computer Vision and Pattern Recognition (CVPR). pp. 2422424235 (June2023)",
  "Reddi, S., Charles, Z.B., Zaheer, M., Garrett, Z., Rush, K., Konecn, J., Kumar, S., McMahan,B. (eds.): Adaptive Federated Optimization (2021),": "Sheller, M.J., Reina, G.A., Edwards, B., Martin, J., Bakas, S.: Multi-institutional deep learn-ing modeling without sharing patient data: A feasibility study on brain tumor segmentation.In: Crimi, A., Bakas, S., Kuijf, H., Keyvan, F., Reyes, M., van Walsum, T. (eds.) Brainle-sion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries. pp. 92104. SpringerInternational Publishing, Cham (2019) Shenaj, D., Fani, E., Toldo, M., Caldarola, D., Tavera, A., Michieli, U., Ciccone, M.,Zanuttigh, P., Caputo, B.: Learning across domains and devices: Style-driven source-freedomain adaptation in clustered federated learning. In: 2023 IEEE/CVF Winter Confer-ence on Applications of Computer Vision (WACV). pp. 444454. IEEE Computer Soci-ety, Los Alamitos, CA, USA (jan 2023).",
  "Vepakomma, P., Singh, A., Gupta, O., Raskar, R.: Nopeek: Information leakage reduction toshare activations in distributed deep learning (2020)": "Wang, J., Jin, Y., Wang, L.: Personalizing federated medical image segmentation via localcalibration. In: Avidan, S., Brostow, G., Ciss, M., Farinella, G.M., Hassner, T. (eds.) ComputerVision ECCV 2022. pp. 456472. Springer Nature Switzerland, Cham (2022) Wu, Y., Zeng, D., Wang, Z., Shi, Y., Hu, J.: Federated contrastive learning for volumetricmedical image segmentation. In: de Bruijne, M., Cattin, P.C., Cotin, S., Padoy, N., Speidel, S.,Zheng, Y., Essert, C. (eds.) Medical Image Computing and Computer Assisted Intervention MICCAI 2021. pp. 367377. Springer International Publishing, Cham (2021) Xie, E., Wang, W., Yu, Z., Anandkumar, A., Alvarez, J.M., Luo, P.: Segformer: Simple andefficient design for semantic segmentation with transformers. In: Neural Information ProcessingSystems (NeurIPS) (2021) Xu, A., Li, W., Guo, P., Yang, D., Roth, H., Hatamizadeh, A., Zhao, C., Xu,D., Huang, H., Xu, Z.:Closing the generalization gap of cross-silo federated med-ical image segmentation. In:2022 IEEE/CVF Conference on Computer Vision andPattern Recognition (CVPR). pp. 2083420843. IEEE Computer Society, Los Alami-tos, CA, USA (jun 2022). Yao, C., Gong, B., Qi, H., Cui, Y., Zhu, Y., Yang, M.: Federated multi-target domainadaptation. In: 2022 IEEE/CVF Winter Conference on Applications of Computer Vision(WACV). pp. 10811090. IEEE Computer Society, Los Alamitos, CA, USA (jan 2022). Zhang, H., Hong, J., Deng, Y., Mahdavi, M., Zhou, J.: Understanding deep gradient leakagevia inversion influence functions. In: Oh, A., Neumann, T., Globerson, A., Saenko, K., Hardt,M., Levine, S. (eds.) Advances in Neural Information Processing Systems. vol. 36, pp. 39213944. Curran Associates, Inc. (2023), Zhang, L., Shen, L., Ding, L., Tao, D., Duan, L.Y.: Fine-tuning global model via data-free knowl-edge distillation for non-iid federated learning. In: Proceedings of the IEEE/CVF conference oncomputer vision and pattern recognition. pp. 1017410183 (2022)",
  "ACenterwise Dataset Information": "In this section, we describe the number of data points in the training, validation and testing splits ofeach center of each dataset. The center represents the client in FL, where each center is in possessionof data that cannot be shared directly with the other centers or to the public. CAMVID has 4centers, which are described in . Cityscapes has 18 centers, which are described in .These centers represent the different cities from which the data is collected for these datasets. ISIC has 3 centers and Polypgen has 4 centers, which represent the different hospitals fromwhich the data is collected. These results are present in .",
  "BCenterwise Performance for Cityscapes Dataset": "While the average mIoU is presented in the main paper, we also present the centerwise performanceof DeepLabv3-based server for the Cityscapes dataset in Tables 9 and 10. It can be seen from thetables that individual training performs poorly, the reason being that each of the centers has limitedamount of data. In contrast, our method makes use of data from all clients to improve performance.Here, we also see that BlackFed v2 performs better than v1 in all cases, thus showing the effectivenessof the server hashmap in countering catastrophic forgetting. With our approach, the performanceof the model reaches close to the white-box methods, but without sharing any gradients or modelinformation. : mIoU scores for BlackFed v1 and v2 in comparison with individual and FL-based trainingstrategies for Cityscapes. \"Local\" represents test data from the center. \"OOD\" represents mean mIoUon test data from rest of the centers. For FedAvg and Combined Training, just one model is trained.Hence, its performance is noted only in each of the local test datasets.",
  "BlackFed v10.760.720.670.710.770.710.750.710.660.700.740.710.710.710.660.720.700.70BlackFed v20.780.740.710.740.810.740.770.740.700.730.760.740.750.730.660.750.710.72": "Combined Training0.82-0.71-0.82-0.78-0.74-0.78-0.76-0.67-0.74-White-box Training0.790.740.710.750.810.750.780.750.700.740.780.750.740.740.660.760.730.76FedAvg 0.85-0.75-0.84-0.80-0.74-0.80-0.78-0.70-0.76- : mIoU scores for BlackFed v1 and v2 in comparison with individual and FL-based trainingstrategies for Cityscapes. \"Local\" represents test data from the center. \"OOD\" represents mean mIoUon test data from rest of the centers. For FedAvg and Combined Training, just one model is trained.Hence, its performance is noted only in each of the local test datasets.",
  "The answer NA means that the paper has no limitation while the answer No means thatthe paper has limitations, but those are not discussed in the paper": "The authors are encouraged to create a separate \"Limitations\" section in their paper. The paper should point out any strong assumptions and how robust the results are toviolations of these assumptions (e.g., independence assumptions, noiseless settings,model well-specification, asymptotic approximations only holding locally). The authorsshould reflect on how these assumptions might be violated in practice and what theimplications would be. The authors should reflect on the scope of the claims made, e.g., if the approach wasonly tested on a few datasets or with a few runs. In general, empirical results oftendepend on implicit assumptions, which should be articulated. The authors should reflect on the factors that influence the performance of the approach.For example, a facial recognition algorithm may perform poorly when image resolutionis low or images are taken in low lighting. Or a speech-to-text system might not beused reliably to provide closed captions for online lectures because it fails to handletechnical jargon.",
  "If applicable, the authors should discuss possible limitations of their approach toaddress problems of privacy and fairness": "While the authors might fear that complete honesty about limitations might be used byreviewers as grounds for rejection, a worse outcome might be that reviewers discoverlimitations that arent acknowledged in the paper. The authors should use their bestjudgment and recognize that individual actions in favor of transparency play an impor-tant role in developing norms that preserve the integrity of the community. Reviewerswill be specifically instructed to not penalize honesty concerning limitations.",
  ". Experimental Result Reproducibility": "Question: Does the paper fully disclose all the information needed to reproduce the main ex-perimental results of the paper to the extent that it affects the main claims and/or conclusionsof the paper (regardless of whether the code and data are provided or not)?Answer: [Yes]Justification: We will be releasing the code, data splits and pretrained models after review.The algorithm for the approach is included in the paper. The experimental settings are alsoprovided in the main paper.Guidelines: The answer NA means that the paper does not include experiments. If the paper includes experiments, a No answer to this question will not be perceivedwell by the reviewers: Making the paper reproducible is important, regardless ofwhether the code and data are provided or not.",
  "If the contribution is a dataset and/or model, the authors should describe the steps takento make their results reproducible or verifiable": "Depending on the contribution, reproducibility can be accomplished in various ways.For example, if the contribution is a novel architecture, describing the architecture fullymight suffice, or if the contribution is a specific model and empirical evaluation, it maybe necessary to either make it possible for others to replicate the model with the samedataset, or provide access to the model. In general. releasing code and data is oftenone good way to accomplish this, but reproducibility can also be provided via detailedinstructions for how to replicate the results, access to a hosted model (e.g., in the caseof a large language model), releasing of a model checkpoint, or other means that areappropriate to the research performed. While NeurIPS does not require releasing code, the conference does require all submis-sions to provide some reasonable avenue for reproducibility, which may depend on thenature of the contribution. For example",
  "(b) If the contribution is primarily a new model architecture, the paper should describethe architecture clearly and fully": "(c) If the contribution is a new model (e.g., a large language model), then there shouldeither be a way to access this model for reproducing the results or a way to reproducethe model (e.g., with an open-source dataset or instructions for how to constructthe dataset). (d) We recognize that reproducibility may be tricky in some cases, in which caseauthors are welcome to describe the particular way they provide for reproducibility.In the case of closed-source models, it may be that access to the model is limited insome way (e.g., to registered users), but it should be possible for other researchersto have some path to reproducing or verifying the results.",
  ". Experiment Statistical Significance": "Question: Does the paper report error bars suitably and correctly defined or other appropriateinformation about the statistical significance of the experiments?Answer: [Yes]Justification: All results of BlackFed have a p-value less than 0.001, showing statisticalsignificance.Guidelines: The answer NA means that the paper does not include experiments. The authors should answer \"Yes\" if the results are accompanied by error bars, confi-dence intervals, or statistical significance tests, at least for the experiments that supportthe main claims of the paper. The factors of variability that the error bars are capturing should be clearly stated (forexample, train/test split, initialization, random drawing of some parameter, or overallrun with given experimental conditions).",
  ". Experiments Compute Resources": "Question: For each experiment, does the paper provide sufficient information on the com-puter resources (type of compute workers, memory, time of execution) needed to reproducethe experiments?Answer: [Yes]Justification: Provided in the experiment setupGuidelines: The answer NA means that the paper does not include experiments. The paper should indicate the type of compute workers CPU or GPU, internal cluster,or cloud provider, including relevant memory and storage.",
  ". Broader Impacts": "Question: Does the paper discuss both potential positive societal impacts and negativesocietal impacts of the work performed?Answer: [Yes]Justification: Introduction discusses about our methods positive impacts. There are noapparent negative impacts.Guidelines: The answer NA means that there is no societal impact of the work performed. If the authors answer NA or No, they should explain why their work has no societalimpact or why the paper does not address societal impact. Examples of negative societal impacts include potential malicious or unintended uses(e.g., disinformation, generating fake profiles, surveillance), fairness considerations(e.g., deployment of technologies that could make decisions that unfairly impact specificgroups), privacy considerations, and security considerations. The conference expects that many papers will be foundational research and not tiedto particular applications, let alone deployments. However, if there is a direct path toany negative applications, the authors should point it out. For example, it is legitimateto point out that an improvement in the quality of generative models could be used togenerate deepfakes for disinformation. On the other hand, it is not needed to point outthat a generic algorithm for optimizing neural networks could enable people to trainmodels that generate Deepfakes faster. The authors should consider possible harms that could arise when the technology isbeing used as intended and functioning correctly, harms that could arise when thetechnology is being used as intended but gives incorrect results, and harms followingfrom (intentional or unintentional) misuse of the technology. If there are negative societal impacts, the authors could also discuss possible mitigationstrategies (e.g., gated release of models, providing defenses in addition to attacks,mechanisms for monitoring misuse, mechanisms to monitor how a system learns fromfeedback over time, improving the efficiency and accessibility of ML).",
  ". Safeguards": "Question: Does the paper describe safeguards that have been put in place for responsiblerelease of data or models that have a high risk for misuse (e.g., pretrained language models,image generators, or scraped datasets)?Answer: [NA]Justification: No risk posed by the work.Guidelines: The answer NA means that the paper poses no such risks. Released models that have a high risk for misuse or dual-use should be released withnecessary safeguards to allow for controlled use of the model, for example by requiringthat users adhere to usage guidelines or restrictions to access the model or implementingsafety filters.",
  "Justification: We use public datasets that have been cited in the paper.Guidelines:": "The answer NA means that the paper does not use existing assets. The authors should cite the original paper that produced the code package or dataset. The authors should state which version of the asset is used and, if possible, include aURL. The name of the license (e.g., CC-BY 4.0) should be included for each asset. For scraped data from a particular source (e.g., website), the copyright and terms ofservice of that source should be provided. If assets are released, the license, copyright information, and terms of use in thepackage should be provided. For popular datasets, paperswithcode.com/datasetshas curated licenses for some datasets. Their licensing guide can help determine thelicense of a dataset.",
  ". New Assets": "Question: Are new assets introduced in the paper well documented and is the documentationprovided alongside the assets?Answer: [Yes]Justification: Code will be released post review and the novel algorithm is described in thepaper.Guidelines: The answer NA means that the paper does not release new assets. Researchers should communicate the details of the dataset/code/model as part of theirsubmissions via structured templates. This includes details about training, license,limitations, etc.",
  "The answer NA means that the paper does not involve crowdsourcing nor research withhuman subjects": "Depending on the country in which research is conducted, IRB approval (or equivalent)may be required for any human subjects research. If you obtained IRB approval, youshould clearly state this in the paper. We recognize that the procedures for this may vary significantly between institutionsand locations, and we expect authors to adhere to the NeurIPS Code of Ethics and theguidelines for their institution."
}