{
  "Abstract": "Investigating the marginal causal effect of an intervention on an outcome fromcomplex data remains challenging due to the inflexibility of employed modelsand the lack of complexity in causal benchmark datasets, which often fail toreproduce intricate real-world data patterns. In this paper we introduce FrugalFlows, a novel likelihood-based machine learning model that uses normalisingflows to flexibly learn the data-generating process, while also directly inferringthe marginal causal quantities from observational data. We propose that thesemodels are exceptionally well suited for generating synthetic data to validate causalmethods. They can create synthetic datasets that closely resemble the empiricaldataset, while automatically and exactly satisfying a user-defined average treatmenteffect. To our knowledge, Frugal Flows are the first generative model to bothlearn flexible data representations and also exactly parameterise quantities suchas the average treatment effect and the degree of unobserved confounding. Wedemonstrate the above with experiments on both simulated and real-world datasets.",
  "Introduction": "Simulating realistic datasets such that the marginal causal effect is constrained to take a specific formis a significant challenge in causal inference. Many methods for inferring these effects exist, butsimulating from them is a significant challenge (Young et al., 2008; Havercroft and Didelez, 2012;Keogh et al., 2021). In particular, it is difficult to simulate complex benchmarks from generativemodels in such a way that a custom marginal effect exactly holds. The frugal parameterisation (Evans and Didelez, 2024) provides a solution to this problem byconstructing a joint distribution that explicitly parameterises the marginal causal effect and builds therest of the model around it. Frugal models typically represent the dependency between an outcomeand pretreatment covariates using copulae. Standard multivariate copulae are parametric, leading topotential model misspecification. In this paper we show how one can construct frugally parameterised marginal causal models usingnormalising flows (NFs, Rezende and Mohamed, 2015; Dinh et al., 2016) to target the causal margin ofthe distribution (a conditional univariate marginal density of an outcome conditioned on a treatment).We name the resulting model a Frugal Flow (FF). To the best of our knowledge, FFs offer the firstlikelihood-based framework for learning a marginal causal effect while modelling the outcome andpropensity nuisance parameters using flexible generative models. FFs are exceptionally well suited for generating benchmark datasets for causal method validation.Since FFs enable direct parameterisation of the causal margin, they provide a framework for gener-ating causal benchmark datasets which resemble real-world datasets, but which also allow users toencode causal properties in order to validate novel inference models. FFs can be used to generatebenchmarks with customisable degrees of unobserved confounding. This can aid in the validation",
  "arXiv:2411.01295v2 [cs.LG] 5 Dec 2024": "of model robustness under conditions where the assumption of conditional ignorability does nothold. Here, conditional ignorability (or conditional exchangeability) means that marginal distributionof the potential outcomes is independent of the value of treatment, conditional on the observedcovariates (Pearl, 2009). FFs offer marked improvements over current benchmarking generation methods, which use softconstraint optimisation to enforce the desired causal restrictions (Kendall, 1975; Parikh et al., 2022).As a result, post hoc checks are required to see whether these conditions are present in the syntheticdata. FFs do not require this second step, as relevant conditions are explicitly encoded in theunderlying likelihood. Finally, FFs allow for outcomes to be sampled from marginal logistic andprobit models, making them the first generative benchmarking model to facilitate the simulation ofbinary outcomes with a choice of user specified risk differences, risk ratios, or odds ratios.",
  "Background": "In this paper we consider a static treatment model with an outcome Y Y R and T a binarytreatment in T = {0, 1}. Let the set of measured pretreatment covariates be Z Z RD.Additionally, we will use the notation of Pearl (2009) where intervened distributions are indicatedby the presence of a do() operator, with its absence indicating that the distribution is from theobservational regime.",
  "Marginal Causal Models": "Causal inference methods are generally developed to estimate the average effect of a treatment (T)on an outcome (Y ) for a population defined by a set of pretreatment covariates (Z) (Hernn andRobins, 2020). Let the variables be distributed according to (Z, T, Y ) PZTY with density pZTY .We make the standard assumptions of a stable unit treatment value (commonly referred to as SUTVA),positivity, and conditional ignorability (equivalent to conditional exchangability) outlined in Pearl(2009). Additionally, the covariate set Z must only include pretreatment covariates. The conditionaldistribution of Y and Z after an intervention on T is equal to",
  "Zdz pY |Z,do(T )(y | z, t) pZ(z).(1)": "The difference between the means of Y under this margin between different values of T is called theaverage treatment effect (ATE), where, = E[Y | do(T = 1)]E[Y | do(T = 0)]. Models whichtarget this marginal quantity are known as marginal structural models (MSMs, Robins, 1998) and arefrequently used in epidemiological and medical domains to account for time-varying confounding. Inparticular, they are effective at quantifying the effect of an intervention over a population, where thespecific relationships between the outcome and (possibly high dimensional) pretreatment covariatesare not relevant, and are modelled as nuisance parameters. The semiparametric question of estimatingfinite dimensional quantities in the presence of high dimensional nuisance parameters has a longhistory (Robins et al., 1995; Robins and Rotnitzky, 1995), but has undergone a renaissance sincethe development of methods such as targeted maximum likelihood estimation (van der Laan andRose, 2011) and double machine learning (Chernozhukov et al., 2018), which allow for generalmachine learning algorithms to flexibly describe the nuisance models and still have valid inferenceon a low-dimensional treatment effect.",
  "Frugal Parameterisations": "Frugally parameterised distributions consist of three distinct components: the distribution of the past,ZT ; the intervened causal quantity of interest, Y |do(T ); and an intervened dependency measurebetween Y and Z conditional on T, ZY |do(T ). The key idea is to explicitly parameterise themarginal causal effect, and build the rest of the model around it. In this paper we encode all thedependence among covariates in the copula, so the past is really just the propensity for treatment (also called the propensity score) and the product of the univariate margins (Evans and Didelez, 2024). provides an illustrative summary of our framework, and outline which models are used toparameterise each component of a frugal model.",
  "C1 F1Y |do(T ), F1Z1 , . . . , F1ZD": ": A visual abstract outlining the different components of a frugal model, and how eachspecific component is parameterised. Univariate CDFs are denoted by F, and copula distributionfunctions are denoted by C. The marginal causal effect, Y |do(T ), is modelled with a univariatenormalising flow, which we denote by F (see .4). The intervened dependency measure,ZY |do(T ), is modelled with a copula flow which we denote by C (see .5). The past,ZT , is modelled by the combination of univariate normalising flows (for the univariate pretreatmentcovariate distributions) and a copula flow (for the propensity of treatment). Variation IndependenceAny smooth and regular dependency measure can be chosen for pa-rameterising ZY |do(T ); this is defined as a quantity which, when combined with the marginaldistributions, smoothly parameterises the joint distribution. It is desirable that the three parametersets (ZT , Y |do(T ), ZY |do(T )) are variation independent (Barndorff-Nielsen, 2014) of each other;such parameterisations have the benefit of allowing the measure ZY |do(T ) to be freely specifiedwithout restricting the rest of the model. Copulae are an example of such a dependency measure,and are a natural choice for frugally modelling dependencies in continuous and mixed datasets. Forfurther detail we refer the reader to Appendix A.",
  "Copulae": "A multivariate copula, denoted by C : d is a multivariate cumulative distributionfunction (CDF) defined over a set of d uniform margins, with an associated density c() if it iscontinuous with respect to its arguments (Sklar, 1959; Joe, 2014). Copulae are often used toparameterise the dependency structure of a joint distribution independent of its univariate margins.Large, complex dependency structures are often modelled by pair-copula constructions (PCCs) orvine copulae (Czado and Nagler, 2022; Joe and Kurowicka, 2011). These methods factorise thedependency structure into a set of non-overlapping bivariate copulae. However, these approachestypically impose the constraints of a finite dimensional parameterisation on the dependency structurein the bivariate copulae used. A more comprehensive introduction to copulae can be found inAppendix B. Copulae in Machine LearningMore complex ML models have been developed to more flexiblylearn copula distributions. Several alternatives have been proposed, some targeting specific copulaclasses (Ling et al., 2020; Wilson and Ghahramani, 2010), and others constraining a neural network-based architecture to estimate valid copulae, though often with limited scalability (Zeng and Wang,2022; Chilinski and Silva, 2020) or using variational approximations (Letizia and Tonello, 2022).However, the most active research area in this field makes use of normalising flows, leveraging theirlikelihood-based, composable and invertible nature to chain transformations of marginal quantities tothe fitting of the copula density.",
  "Paper MotivationA key motivation for this paper is the search for a flexible parameterisation ofthe copulaZY |do(T )(z, y | t) = c(FY |do(T )(y | t), FZ1(z1), . . . , FZD(zD))(2)": "between the probability integral transforms of the univariate pretreatment covariates and a conditionalunivariate quantity which parameterises the causal margin. Evans and Didelez (2024) show that thiscan be done using parametric copulae, and also prove that it targets the marginal causal rather thanthe conditional distribution when ZY |do(T ) is parameterised by a multivariate copula. Consider themultivariate copula for the distribution of Z and Y conditional on T:",
  "pY |Z,do(T ) = pY |do(T ) c(FY |do(T ), FZ1, . . . , FZD),": "where pY |do(T ) is the marginal causal effect of T on Y . The final propensity score density pX|Zdoes not affect the marginal densities in the observational model as there is a parameter cut betweenpT|Z and pY |Z,do(T ) (Barndorff-Nielsen, 2014). However, Y |do(T ) and ZY |do(T ) are functions ofpY |Z,do(T ) and thus should be estimated jointly. If pY |do(T ) is estimated separately from the copula,the marginal conditional effect will be inferred rather than the marginal causal effect. Generative ML methods allow for estimating more flexible and general copulae, but have struggledso far to learn copulae together with conditional univariate quantities. We resolve this problem anddesign a NF-based copula inference method that allows for these quantities to be estimated jointly asrequired by the frugal parametrisation (see .5). The model is then trained on real-world dataand used for generating customised causal benchmarks which closely resemble the original dataset.",
  "Normalising Flows": "Normalising flows (NFs) (Tabak and Turner, 2013; Rezende and Mohamed, 2015; Dinh et al., 2016)allow for density estimation via learning a diffeomorphic transformation F that maps the unknowntarget distribution pX(x), x RD to a simple and known base distribution pU(u), u RD, so thatwhen X pX and U pU then U = F1(X) . F is usually a composition of invertible and differentiable transformations Fi parametrised by neuralnetworks, and is often trained by maximising the log-likelihood of observed {xi}Ni=1. This can beconveniently done in closed form exploiting the change of variable formula",
  ",(3)": "provided that the chosen model for F allows for efficient computation of the Jacobian determinantdet((F1(x))/x). The implementation of F1 then allows for density evaluation, whereas Fcan be used for sampling from the joint. As for the choice of F, the literature has explored a number of implementations that retain invertibilitywhile allowing for computational tractability of the determinant. See Papamakarios et al. (2021) foran introduction and overview. Our implementation relies on neural spline flows (NSF, Durkan et al.,2019), a particular type of autoregressive flows that will be further illustrated in .5.",
  "Copula Flows": "Our Frugal Flow approach builds upon the copula-based flow model proposed by Kamthe et al.(2021) for synthetic data generation. The authors start by considering a copula C(FX1, . . . , FXD)defined over the marginal probability integral transforms FX1, . . . , FXD of a random vector X =[X1, . . . , XD]. Assuming the copula density exists, the joint density of X can be written as",
  "For the rest of this paper, we will let U UniformD represent a vector of independent uniforms,and let V C represent a vector of dependent uniforms as a multivariate copula C. The generative": "procedure for this NF takes samples U from a base distribution of independent uniforms and firstpushes them through the copula flow CX, obtaining correlated uniform samples V = CX(U).Then V is mapped through the marginal flows FX = [FX1, . . . , FXD] to obtain the random vectorX = FX(V ). The composed flow X = FX(CX(U)) is also a valid flow, and via the change of variable formulaas in eq. (3) it induces a specific factorisation of the density of X Here, we quote the result fromKamthe et al. (2021):",
  ".(5)": "As the univariate mapping from a uniform to a random variable is uniquely defined by the CDF, theflows F1X = [F1X1 , . . . , F1XD] target the marginal CDFs FX1, . . . , FXD. Note how eq. (5) factorisesthe density of X into a copula density and a product of marginal densities as in eq. (4). CX is estimated with a NSF, a NF of the autoregressive flow class. Autoregressive flows (Papamakar-ios et al., 2017; Huang et al., 2018) factorise CX as a recursive sequence of univariate conditionalflows:",
  "V1 := C1(U1)Vd := Cd|1...d1(Ud | V1, . . . , Vd1)2 d D.(6)": "In principle, since the input U is a vector of independent uniforms, the conditional flows wouldapproximate the inverse of the Rosenblatt transform (Rosenblatt, 1952) and thus be universal approxi-mators if the flows were sufficiently expressive (Papamakarios et al., 2021). The Rosenblatt transformsequentially maps each component Sd of any random vector S with strictly positive density throughits corresponding conditional CDF FSd|S1,...,Sd1, obtaining a vector U of independent uniforms. Itis known to be a diffeomorphism, so its inverse bears the same structure as eq. (6)), but uses inverseconditional CDFs C1d|1,...,d1 for each Vd. We use the notation C1 to emphasise that in the copulaflow case we are dealing with inverse copula CDFs, whose codomain is also uniform. Autoregressive flows estimate each univariate conditional flow Cd|1...d1 with a strictly monotonefunction whose parameters are only allowed to depend on dimensions 1, . . . , d 1. The monotonicityof the function ensures invertibility, while the autoregressive structure in the function parameterdependence gives a triangular Jacobian whose determinant is tractable. Kamthe et al. (2021) use aNSF, where the monotone function is given by a monotone rational quadratic spline, whose knotparameters are provided by a neural network where weights are appropriately masked to ensure theautoregressive structure. The univariate marginal flows FX are estimated with separate NSFs beforetraining the copula flow using the transformed data V . While a NSF can constrain the support of both the base and target distributions, it cannot control theform of the marginal distribution. If marginal and copula flows are learned simultaneously, neitherwill be correctly inferred due to the infinite possible combinations of (FX, CX) which yield the samecomposite flow W = FX CX. These flows must be learned sequentially if C is to model a copula. In our application, we wish to infer a multivariate copula which models the joint dependencebetween univariate pretreatment covariates and conditional univariate quantities such that the latterparameterises the causal margin. Inferring the MOD separately from the copula, as copula-basedflows do, will target the conditional causal effect rather than the marginal causal effect. We propose asolution in the form of Frugal Flows, which we introduce in .1.1. Moreover, for discretevariables we use a dequantised form of the empirical CDF rather than a NSF adaptation (seeAppendix B.2 for further details).",
  "Validating and Benchmarking Causal Methods": "Methods for validating causal models can be broadly categorised into two groups. The first comprisesauxiliary analyses conducted after fitting a causal model and estimating a treatment effect. Theseinclude but are not limited to sensitivity analyses (Imai et al., 2010), subgroup analyses (Cochran andChambers, 1965), placebo tests (Eggers et al., 2023), and negative controls (Shi et al., 2020). The second set of validation methods is where we see FFs having a significant impact. These methodsare used to construct synthetic datasets while allowing the causal practitioner to customise specificfeatures of the data-generating process. For example, when validating an inference method whichestimates an ATE under certain confounding assumptions, it is crucial that generated data follow theground truth ATE and confounding assumptions one wishes to measure. However, synthetic datarisk being oversimplified and contrived, failing to reflect the complexity of real world datasets. To mitigate this, generative models are trained on real-world data and calibrated to generate sampleswith modifiable causal constraints. Such constraints include the average causal treatment effect,unobserved confounding, and positivity. To our knowledge, the FF framework proposed in this paperis the first method to allow all of these conditions to adjusted by the user. Existing methods (Nealet al., 2020; Athey et al., 2021; Parikh et al., 2022) encode these effects through soft optimisationconstraints, hence there is no guarantee that the constraints are satisfied. Enforcing these constraintstoo strongly may negatively impact model optimisation, and may affect the reconstructive abilityof the underlying model. Furthermore, since these approaches do not explicitly parameterise thecausal effect, samples from trained models must be tested post hoc to ensure the desired constraintsare present in the sampled data. A key benefit of frugal models is that the marginal causal effect isdirectly parameterised by the user through the likelihood. As a result, synthetic data samples willexactly satisfy these constraints.",
  "Building the Joint Distribution": "In this section we parameterise the full observational joint using FFs. .1.1 outlines how theFF is constructed; we first learn the probability integral transforms of the pretreatment covariates,and then infer the causal margin jointly with an extended copula flow, the Frugal Flow. To infer thecausal margin, this is sufficient. Nevertheless, the propensity score is needed to complete the joint inorder to generate benchmarks which are confounded in a similar fashion to the original real-worlddataset. We describe the fitting of the propensity score in .1.2",
  "Constructing Frugal Flows": "The first step involves learning the margins for the pretreatment covariates Z. This is done in asimilar fashion to that of Kamthe et al. (2021)s copula-based flows, as described in .5. Theoutcome, treatment, and the inferred ranks VZ of the pretreatment covariates are then used to trainthe Frugal Flow (see bottom part of ) that models F1Y |do(T ) together with the copula flow.This is required in order to learn the causal marginal pY |do(T ) rather than the conditional pY |T . The Frugal Flow of dimension D + 1 transforms the joint input of (Y, VZ | do(T)) into a randomvector U which we set to be distributed according to an independent uniform base distribution. In thefirst subflow of the composition, Y is pushed through a univariate flow F1Y |do(T ) conditioned on T toobtain VY |do(T ), while the VZ remain untransformed. Subsequently, VY |do(T ) is kept fixed, whilea copula is learnt over VZ conditional on VY |do(T ) via an NSF. Importantly, a specific ordering ofthe variables is imposed, such that the causal margin is ranked first. In this way, we ensure that U1and VY |do(T ) have the same distribution, and VY |do(T ) is therefore constrained to be uniform. Themarginal flow F1Y |do(T ) thus targets the CDF of the marginal causal effect, FY |do(T ). In summary, we construct a flow Q1 : (Y, VZ1, . . . , VZD | T) V as a composition ofa marginal flow F1Y |do(T ) and conditional copula distribution C1(vY |do(T ), vZ1, . . . , vZD) =C(vZ1, . . . , vZD | vY |do(T )). More on the implementation details can be found in Appendix C.",
  "U1U2:(D+1)": ": Structure for learning a Frugal Flow. The top line outlines the process for learning theunivariate marginal flows of the pretreatment covariates Z. The bottom transform illustrates theFrugal Flow, which learns the conditional copula c(vZ | vY |do(T )) jointly with the causal marginalflow FY |do(T ) by enforcing VY |do(T ) to be marginally uniform. Inferring the above is sufficient for identifying the causal margin. However, to generate realisticsamples for causal method validation, one also needs to learn the propensity score, pT |Z = pT cT|Z.By decoupling the marginal treatment density pT from the conditional copula cT|Z, one can canmodify the marginal treatments while retaining the dependence of the original data. We thereforelearn an approximate probability integral transform of the discrete treatment T (see Appendix B.2.1for further details), followed by the conditional copula flow of T on Z, C1T |Z : VT VT|Z | Z. One could directly model pT|Z using a normalising flow, which would also constitute a valid frugalmodel. We instead choose to model the conditional copula using a flow, CT|Z = C1T|Z, allowing usersto encode a degree of unobserved confounding in the generated data by sampling the ranks VT|Z andVY |do(T ) from a non-independence copula. Assuming ignorability, these ranks would be independent.However, unobserved confounders imply dependence between these ranks. Sampling them from acopula can replicate this effect, as demonstrated in the far-right plots in Figures 3 and 4. The above section describes how one can estimate the propensity of treatment from a real-worlddataset. However, we remark that one can choose any custom propensity score function to generatetreatments conditional on the pretreatment covariates via inverse probability integral transforms onVT |Z. Hence, one can fully control the overlap/positivity of FF generated benchmark datasets.",
  "Data generated from a fitted FF can be customised with a range of properties, allowing for modelvalidation against a range of customisable causal assumptions. We describe these below": "Modifying the Causal MarginThe central output of the Frugal Flow is a method for samplingranks for each of the margins in PY |do(T ), PZ1, . . . , PZd. Any causal marginal density qY |do(T ) canbe used to generate samples of Y via inverse probability integral transforms. Since the Frugal Flowreturns ranks for the intervened causal effect, these can be inverse transformed by any valid CDF.Unlike other methods, this constraint is strictly enforced by the the frugal likelihood. Simulating from Discrete OutcomesSince FFs return VY |do(T ) ranks, one can sample fromany custom causal margin. This extends to both continuous and discrete causal margins. One cansimulate from a logistic marginal effect Y | do(T) Bernoulli(p = expit(T + c)) or probitmodel Y | do(T) Bernoulli(p = (T + c)) where () is a univariate standard GaussianCDF. This is non-trivial, because logistic regression is not collapsible, meaning that if (for example)Y | T = t, Z = z is a logistic regression, then Y | do(T = t) generally will not be. Hence it isinfeasible for a fully conditional method of simulation to produce outcomes where the causal marginuses a logistic link. For experimental results see Appendix D.2.1. Modifying the Degree of Unobserved ConfoundingOne can sample data from FFs as if theoutcome is affected by unobserved confounding. The variables VY |do(T ) and VT|Z are independent ofeach other if no unobserved confounding is assumed. Introducing a dependence between these ranksreplicates the effect of unobserved confounding. This can be achieved by sampling (VY |do(T ), VT |Z)from a Gaussian bivariate copula, c(vY |do(T ), vT |Z; ), where quantifies the degree of unobservedconfounding in the sampled data. Customising Treatment Effect HeterogeneityConsider a stationary treatment with pretreamentcovariate set Z = (W , W ) where W Z with |Z| = D, |W | = d, and |W | = D d. Weproceed considering the case where 0 < d < D. Interest may lie in the causal treatment marginconditional on the subset of variables W :",
  "Wdw pY |Z,do(T )(y | w, w, t) pW |W (w | w)(7)": "We propose a method to exactly parameterise heterogeneous treatment effects using a subset ofpretreatment covariates, W Z. FFs offer exact parameterisation of pY |W,do(T ), allowing forcustomisation of heterogeneity while capturing complex dependencies between other covariates.Specifically, the model infers the conditional treatment margin, pY |W,do(T )(y | w, t), ensuring properinference of the joint pretreatment covariate distribution, pZ(). Thus, one may simulate data wherecausal effects are conditional on a selected subset of variables, offering flexible and precise controlover treatment heterogeneity. Further details may be found in Appendix D.2.2. Customising the Propensity ScoreSince the propensity score is variation independent from therest of the model, one has complete flexibility on how to parameterise the propensity score. Anydistribution PT|Z can be used to generate treatments with varying degrees of overlap in a manner thatis completely customisable by the user.",
  "Inference": "We generate simulated data from three models. The first two are parameterised by four pretreatmentcovariates Z = {Z1, . . . , Z4} with a binary treatment T, a linear Gaussian causal margin Y |do(T) N( = T + 1, = 1), and a copula dependence measure c(vY |T , vZ1, . . . , vZ4). Inthe first model M1, all four covariates follow a gamma distribution. In the second M2, the data isgenerated from an even split of gamma and binary covariates. Additionally, we generate data frommodel M3 with ten pretreatment covariates comprising five gamma and five binary variables. Amore quantitative description of the simulated data generating process and hyperparameter values arepresented in Appendix D.1. : Mean and 2 confidence interval of the inferred ATE, bootstrapped over 25 different runsand with a data size of N = 25,000. The number of pretreatment covariates in each model is denotedby D. Bold confidence intervals contain the true ATE. OR quotes the results obtained by linearoutcome regression, and CNF reports the ATE estimted by causal normalising flows.",
  "ModelTrue ATEDFrugal FlowORMatchingCNF": "M1140.98 0.121.28 0.060.78 1.060.73 0.16M1545.00 0.245.29 0.044.68 1.064.23 0.20M2141.01 0.101.46 0.071.36 0.721.01 0.20M2545.01 0.185.44 0.055.55 0.885.03 0.44M31101.00 0.091.13 0.060.90 0.480.87 0.15M35105.18 0.305.13 0.264.90 0.474.73 0.28 We generated datasets with a sample size of N = 25,000 across B = 25 different runs. FrugalFlows (FFs) were compared against outcome regression (OR), traditional causal propensity scorematching (Stuart, 2010), and state-of-the-art causal normalising flows (CNFs) (Javaloy et al., 2024).Further details on the methods can be found in Appendix D.3.3. A default set of hyperparameterswas used for all models. The estimated ATEs are shown in . OR models, which estimatethe conditional rather than the marginal effect of T on Y , consistently exhibited bias, pulling the",
  "estimates away from the true value. In contrast, FFs achieved the lowest error in identifying the trueATE, outperforming both statistical matching and CNFs": "Our results demonstrate that Frugal Flows can correctly identify causal relationships under idealconditions, confirming that they are a valid, efficient way to parameterise a causal model using deeplearning architectures. A drawback of FFs is that they need large datasets to accurately infer causalmargins. Additionally, the complexity of data dependencies might require careful hyperparametertuning to prevent the copula from overfitting, which could bias the inference of the causal relationships.Because of these challenges, we do not recommend using FFs on real-world datasets for statisticallyinferring treatment effect sizes, as causal benchmark datasets are usually small.",
  "Benchmarking and Validation": "In this section we present the results of multiple causal inference methods on data generated from FFstrained on two real-world datasets. The first is the Lalonde data, taken from a randomised control trialto study the effect of a temporary employment program in the US on post intervention income level(LaLonde, 1986). The second is an observational dataset used to quantify the effect of individuals401(k) eligibility on their accumulated net assets, in the presence of several relevant covariates(Abadie, 2003). Both datasets have a binary treatment and continuous outcome. Appendix D.3 can bereferred to for a more comprehensive description of the data. In addition, we present diagnostics onthe quality of the model fit in Appendix D.3.6, and the loss optimization for both datasets is presentedin Appendix D.3.7.",
  "With Hidden Confounding = 0.5": ": Boxplot of ATE estimates from 10 inference methods, estimated across 50 different samplesfrom a FF trained on the Lalonde dataset. The dotted red line represents the customized ATE ofsamples generated from the trained Frugal Flow. FFs were fitted to both datasets and used to simulate data with an ATE of 1000. We simulate 50datasets of size N = 1000 from three different cases each: i) no confounding, ii) with confoundingaccording to the propensity flow inferred in the model fitting, and iii) with propensity flow confound-ing and unobserved confounding introduced via a Gaussian copula. A variety of causal inferencemethods (see Appendix D.3.4 for a more detailed description) were fit to the data sets, includinga difference of means (DoMs) estimate which is an unbiased estimator of the treatment effect forrandomised data. The inferred ATEs across all runs are presented in and . In both cases, all inference methods demonstrate no bias when fitted to unconfounded data. Withreal-world confounding, most methods estimate the correct ATE in , whereas the DoMsshows a substantial bias from the ground truth. In however, all methods infer the correctATE including DoMs. This is not surprising as the original data was randomised; the propensity flowhere appears to simply add more noise to the outcomes. Finally, we note that all causal inferencemethods show confounding bias in the far right hand plots, demonstrating that FFs can simulate datawith replicate the effects of hidden confounding.",
  "Conclusions": "We introduce Frugal Flows, a novel likelihood-based model that leverages NFs to flexibly learnthe data-generating process while directly targeting the marginal causal quantities inferred fromobservational data. Our proposed model addresses the limitations of existing methods by expliclitlyparameterising the causal margin. FFs offer significant improvements in generating benchmarkdatasets for validating causal methods, particularly in scenarios with customizable degrees of un-observed confounding. To our knowledge, FFs are the first generative model that allows for exactparameterisation of causal margins, including binary outcomes from logistic and probit margins.",
  "Limitations and Future Work": "Our experiments validated the empirical effectiveness of FFs, showing that they can infer the correctform of causal margins on confounded data simulations. Despite these promising results, FFscome with certain limitations that need to be addressed in future research. NFs require extensivehyperparameter tuning, which can be computationally intensive and time-consuming. Moreover,we see that FFs perform better in inference tasks with larger datasets. Future work could explorealternative ML copula methods and architectures that may be more effective for smaller datasets.Fortunately, this is less problematic for simulation as specification of the exact causal margin is leftto the user. Additionally, the dequantising mechanism used by FFs implicitly shuffles the order ofdiscrete samples, potentially losing some inherent structure in the data, making FFs less suitable forcategorical datasets without implicit ordering. In summary, Frugal Flows offer a novel approach to causal inference and model validation thatcombines flexibility with exact parameterisation of causal effects. Future work will refine theinference capabilities and extend the applicability of FFs to a wider range of data types and sizes.",
  "Acknowledgements": "The authors express their deep gratitude to Stefano Cortinovis and Silvia Sapora for their valuablesuggestions regarding the development of the software and experiments. We also thank ChristopherWilliams for his insightful advice on the framing of the paper. We thank Geoff Nicholls for hissuggestions and fruitful discussions on the paper and opportunities for future development. Last butcertainly not least, special thanks must go to Shahine Bouabid for his invaluable assistance with boththe coding aspects of this paper and his recommendations on clarity.",
  "Ole E. Barndorff-Nielsen. Information and exponential families: in statistical theory. John Wiley &Sons, 2014": "James Bradbury, Roy Frostig, Peter Hawkins, Matthew James Johnson, Chris Leary, Dougal Maclau-rin, George Necula, Adam Paszke, Jake Vanderplas, Skye Wanderman-Milne, and Qiao Zhang.JAX: composable transformations of Python+NumPy programs, 2018. Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whit-ney Newey, and James Robins. Double/debiased machine learning for treatment and structuralparameters. The Econometrics Journal, 21(1), 2018.",
  "YT": ": A generalised example of a static causal treatment model. The past P(T, Z) (black) can befreely specified separately from the causal effect (blue). However, the dependency measure betweenZ and Y (red), should be parameterised in such a way that the margins P(Z) and P(Y |do(T))are invariant to changes in . We specify the notation used in this appendix. Functions labelled Fi() are CDFs for the variable i.Apart from this, in general density functions will be labelled with a lower case letter, whereas CDFswill be named with the upper case (e.g. we contrast the copula density c(u1, u2) with the distributionfunction C(u1, u2)). Consider firstly the case of a static treatment model with a single outcome Y , a single treatmentT and an effective pretreatment covariate set Z. Assume that any of these covariates occur priorto treatment even if they do not causally affect the treatment directly. Evans and Didelez (2024)construct frugal models in three parts:",
  "The causal distribution of interest P(Y | do(T)) The past P(Z, T) The intervened variation independent dependency measure (Y, Z | do(T))": "The three frugal components are variation independent in the sense that they characterise non-overlapping components of the full observational joint. We quote the following definition from Evansand Didelez (2024): Definition 1 Take a set and two functions defined on it , . We say that and are variationindependent if ( )() = () (); i.e. the range of the pair of functions together is equalto the Cartesian product of the range of them individually. Variation independence (VI) is a highly desirable property for a parameterization, since it allowsdifferent components to be specified entirely separately. This is extremely useful if one is trying touse a link function in a GLM, or to specify independent priors for a Bayesian analysis. In addition,VI is important in semiparametric statistics. The definition simply states that the Cartesian product ofthe images is the same as the image of the joint map. For example, in a bivariate gamma-distributionwith positive responses, then 1 R+ and 2 R+ is a variation independent parameterization,since(1 2)() = R+ R+ = 1() 2().However, if we replace 2 with 2 = 21 (for example), then although the range of this parameteris R,(1 2)() = {(x, y) : x > 0, y > x} = R+ R = 1() 2().",
  "Central to this is the choice of . This dependency measure should encode dependencies between Zand Y | do(T), but not provide information about their marginal distributions": "Discrete frugal models can be parameterised by conditional odds ratios, while continuous variablestypically use copulae. Both allow for variation independent parameterisation of the full joint dis-tribution. The methodology facilitates the creation and simulation of models with parametricallydetermined causal distributions, enabling fitting using likelihood-based techniques, including fullyBayesian methods. Furthermore, this parameterisation covers a range of causal quantities, such as theaverage causal effect and the effect of treatment on the treated.",
  "BCopula Theory": "Copulae present a powerful tool to model joint dependencies independent of the univariate margins.This aligns well with the requirements of the frugal parameterisation, where dependencies needto be varied without altering specified margins (the most critical being the specified causal effect).Understanding the constraints and limitations of copula models ensures that causal models remainaccurate and consistent with the intended parameterisation.",
  "B.1Sklars Theorem": "Sklars theorem (Sklar, 1959; Czado, 2019) is the fundamental foundation for copula modelling, as itprovides a bridge between multivariate joint distributions and their univariate margins. It allows oneto separate the marginal behaviour of each variable from their joint dependence structure, with thelatter being represented by the copula itself. Theorem 1 For a d-variate distribution function F1:d F(F1, . . . , Fd), with jth univariate marginFj, the copula associated with F is a distribution function C : d with uniform marginson (0, 1) that satisfiesF1:d(y) = C(F1(y1), . . . , Fd(yd)), y Rd.",
  "where fi() is the univariate density function of the ith variable": "Note that Sklars theorem explicitly refers to the univariate marginals of the variable set{Y1, . . . , Yd} to convert between the joint of univariate margins C(u) and the original distribu-tion F(y). For absolutely continuous random variables, the copula function C is unique. Thisuniqueness no longer holds for discrete variables, but this does not severely limit the applicability ofcopulae to simulating from discrete distributions. The non-uniqueness does play a more problematicrole in copula inference, however (Genest and Nevslehova, 2007).",
  "B.2Copulae for Discrete Variables": "Accurately modelling the univariate marginal CDFs of pretreatment covariates is a crucial step intraining Frugal Flows, particularly when the dataset includes discrete variables. For continuouscovariates, the mapping between observations and ranks is unique, allowing for straightforward estimation of the marginal distribution. However, with discrete covariates, this mapping becomesone-to-many, as the same observation can be transformed from different ranks. This non-uniquenessintroduces significant challenges when modelling the joint distribution via copulae, as the joint set ofranks for discrete covariates lacks a unique representation. As a result, estimating the dependencystructure between variables becomes more complex and less reliable. To extend Frugal Flows to accommodate mixed data types, it is essential to generate empiricalranks for discrete covariates in a way that allows the model to capture their dependencies. Ourgoal is to obtain valid rank samples that can be used to train a Frugal Flow without introducingdistortions in the copula structure. While this issue has been widely explored in the copula literaturefor parametric models, there remains a gap in effectively addressing it within more flexible, non-parametric frameworks. In this work, we implement a generalised distributional transform fordiscrete covariates (presented in Appendix B.2), which allows Frugal Flows to be trained effectively,maintaining the flexibility of the model while accurately capturing the relationships between variables.",
  "B.2.1Challenges and Motivation": "In addition to the above, copulae encode a degree of ordering in the joint as probability integraltransforms are inherently ranked, and hence should only be used for variables that have an inherentordering of their own (e.g. count or ordinal data models). While approaches to model discretevariables exist in parametric copulae models (Zilko and Kurowicka, 2016; Panagiotelis et al., 2017),more flexible non-parametric copulae struggle to capture the dependencies of empirical copulae.Similar to Kamthe et al. (2021) we use the approach suggested by Rschendorf (2009). An outline ofthis method is presented in Appendix B.2.2. However, unlike Kamthe et al. we use the empiricalCDF inferred from the discrete data as opposed to modelling the CDF with a marginal flow.",
  "B.2.2Empirical Copula Processes for Discrete Variables": "In order to deal with discrete variables, we use a similar approach as taken by Kamthe et al. (2021),who quote the generalised distributional transform of a random variable found originally proposed byRschendorf (2009). We quote the main result from Rschendorf (2009) below. Theorem 2 On a probability space (, A, P) let X be a real random variable with distributionfunction F and let V U(0, 1) be uniformly distributed on (0, 1) and independent of X. Themodified distribution function F(x, ) is defined by",
  "The Frugal Flow component builds a flow of the form in the bottom part of . It allows us toimplement FY |T with either (i) a customised CDF conditioned on T, of a known parametric family;": "(ii) a univariate NSF on the interval modified to allow a location translation parameter thatrepresents the ATE for T, where the input is mapped from the real line via a tanh transform; or finally(iii) a univariate NSF on the interval that is not conditional on T, where the input is mappedfrom via an affine transform. As for known parametric families, only the Gaussian CDF iscurrently implemented, but the architecture allows us to define any different parametric class providedthat it constitutes a diffeomorphism. As for the univariate NSF in (iii), it does not explicitly learnan ATE in the training phase, but can be used for simulation of e.g. binary outcomes by applying asubsequent logistic transformation to its outcome. The multivariate NSF element is a composition of multiple modified NSF subflows. In each subflowthe first transform is fixed to be an identity, while the other dimensions are transformed with amonotone rational quadratic spline whose knot parameters are produced by masked multilayerperceptrons (MLPs) implemented as in Germain et al. (2015), conditional on the first dimension.In order to increase expressivity, dimension permutation is usually applied between the differentsubflows in the NSF composition. We still allow this permutation but excluding the first dimension,that is fixed to be at the top in each subflow. The NSF acts on the on the interval and ismapped from and back to the quantile space with affine transforms. Tunable hyperparameters to the Frugal Flow component are the number of subflows of the multivariateNSF, the width and depth of the MLPs and the number of spline knots, together with the specifichyperparameters of the chosen FY |T .",
  "Marginal flows architecture for continuous variables": "Each marginal flow for the continuous covariates maps each variable from the real line to the interval with a tanh transform, then applies a univariate NSF on the interval, and maps backto the standard uniform base distribution via an affine transform. Tunable hyperparameters are thenumber of subflows of the NSF, the width and depth of the MLPs and the number of spline knots.",
  "Propensity score model architecture": "To map a discrete T to the ranks VT , we compute its empirical CDF and then apply the procedureoutlined in Appendix B.2.2. A univariate NSF flow with a uniform base distribution is then applied tolearn the copula CDF of T on the support, conditioned on Z. The Z conditioning is obtainedby adding Z as an (unmasked) input to the MLP that produces the knot parameters for the rationalquadratic spline. This is standard in NF literature. Tunable hyperparameters are the number ofsubflows of the NSF, the width and depth of the MLPs and the number of spline knots. The propensity score model can be inverted to generate T samples conditioned on a given Z. Uniformsamples are pushed through the trained univariate propensity score flow to obtain ranks, that are thenmapped to the discrete space via the inverse of the empirical CDF of T.",
  "Training the Frugal Flow and the propensity score flow": "In order to train a FF, one must fit the marginal flows first. The marginal flows are trained (forcontinuous variables) via maximising the log-likelihood with stochastic gradient descent, and/or thediscrete Z are mapped to the rank space via the procedure in Appendix B.2.2. Next, the FF is trainedvia maximum likelihood estimation (MLE), taking as input the outcome Y together with the ranksVZ, and conditioning the flow for the causal margin on treatment T where required by the chosenmethod. For MLE optimisation, we take advantage of JAX automatic differentiation capabilitiesand use the Adam optimiser (Kingma and Ba, 2015), whose hyperparameters can also be tuned. Ifrequired, the propensity flow is likewise trained on VT conditioning on Z via MLE with an Adamoptimiser.",
  ". Push VY |do(T ) through the desired causal margin transform to obtain outcome samplesconditioned on T. Currently, the package supports:": "(a) Sampling from an inverse CDF provided by the user, taking VY |do(T ) as input and con-ditioning on the given univariate T. Currently a Gaussian inverse CDF is implemented,where the coefficient on T can be chosen to impose the desired ATE. The user is freeto define different inverse CDFs. (b) Sampling a binary outcome with probabilities produced from a logistic function takingVY |do(T ) as input and conditioning on the given univariate T. The coefficient on T canbe chosen to impose the desired odds ratio. (c) Sampling from the univariate NSF learnt during the FF training, but with a user-definedlocation translation parameter representing the ATE and conditioning on the giventreatment T. This method exploits the flexible margin distribution learnt for T = 0during FF training, but allows to choose a different ATE for the location-translationeffect produced by T = 1.",
  "The simulated data generated for the inference experiments was generated using the causl packagewritten in R, which was called in Python via the rpy2 package (Evans, 2021; Evans and Didelez,2024)": "The covariates were either selected to be binary (marginally distributed according to Bernoulli(p =0.5) or continuous (marginally distributed according to Gamma( = 1, = 1). The marginal causaleffect was chosen to be a linear Gaussian; Y | do(T) N(T, 1). The underlying data generating process uses a multivariate Gaussian copula to generate dependenciesbetween the marginal covariates and the causal effect. The Spearman correlation matrix used togenerate the data for models M1 and M2 is",
  "Y | do(T) Bernoulli(p = Sigmoid(2X 1))": "A dataset size of N = 1000 was generated from the model, and fit using two models. The first isa Bernoulli outcome regression model, and the second uses inverse propensity weighting (IPW) toestimate the logistic parameters instead. The outcome regression (OR) estimates are biased indicatinga clear confounding effect, whereas the IPW estimates comfortably contain the true parameters withintheir 2 bounds. These results are presented in . : Mean and 2-sigma confidence interval of the logistic parameter estimates. The ground-truth estimates are contrasted alongside the IPW estimates and OR methods, the latter of whichdemonstrates clear data confounding.",
  "Zdz pY |Z,do(T )(y | z, t) pZ(z).(8)": "However, one may wish to simulate from more complex heterogeneous treatment effect models.Consider a stationary treatment with pretreament covariate set Z = {W , W } where W Z and|Z| = D, |W | = d, and |W | = D d. We proceed considering the case where 0 < d < D.",
  "Wdw pY |Z,do(T )(y | w, w, t) pW |W (w | w)(9)": "which we call the conditional treatment margin. We infer this effect by constructing a Frugal Flowwhich ensures that the pretreatment covariate joint pZ() is correctly inferred and that the conditionaltreatment margin ranks are uniformly distributed. A modified version of the Frugal Flow illustrated is used to account for this change. The choice of F1Y |W,do(T )() can be left to the user forinferring the Frugal Flow. For simulating benchmarks, the conditional treatment margin can be freeset to any valid CDF, for example:",
  "D.3.1Lalonde Temporary Employment Program": "The Jobs dataset by LaLonde is a benchmark in causal inference studies, where job training serves asthe treatment and the outcomes are post-training income and employment status. Originating fromthe National Support Work Demonstration (NSW), this randomized controlled trial (RCT) examinesthe impact of a temporary employment program (i.e. the treatment) in the US on participants incomelevels (LaLonde, 1986). Due to its design the treatment assignment is random, eliminating unobservedconfounding. The measured features, all recorded in 1975, are:",
  "Propensity score matching is implemented using the R package MatchIt for estimating theATE (Stuart et al., 2011)": "Causal normalising flow (CNF) (Javaloy et al., 2024) is trained using the causal abductivemodel with one layer, that the paper reports to be the best-performing model variation(Paragraph 6.1). We use the hyperparameter settings recommended in the package and donot perform hyperparameter tuning. For the flow architecture, we use neural spline flows, asthe paper reports in Appendix D.3 that they yield a better performance than simple maskedautoregressive flows, plus this resembles our architecture choice in Frugal Flows. We do notadd uniform independent noise to the binary inputs as recommended in paragraph 3.1 as wefind this worsens the ATE estimates for the model.",
  "D.3.6Realism of Datasets": "We conducted additional validation of the proposed Frugal Flows method to enhance its robustness incomparison to current state-of-the-art methods such as Credence (Parikh et al., 2022) and RealCause.Credence allows for the exact specification of conditional average treatment effect (CATE) in genera-tive samples, whereas RealCause adjusts the causal effect post hoc, preventing it from realisticallymodelling a null hypothesis where the average treatment effect (ATE) is zero. Additionally, FrugalFlows and Credence both model unobserved confounding, a feature absent in RealCause, makingCredence the more suitable method for direct comparison. We ran the benchmarking simulations in .2 with Credence, using its default parameters,evaluating model performance on Lalonde and the e401(k) dataset. We compared the correlationmatrices of the pretreatment covariates and outcomes for the original data, Frugal Flows-generateddata, and two Credence-generated datasets with different causal constraints. The results, illustrated in and , show that Frugal Flows produce samples closely resembling the original data,especially for the larger e401(k) dataset. While Credence also performs well on the e401(k) dataset, altering its causal constraints significantlyaffects the covariate dependencies. In contrast, Frugal Flows optimise the model once, allowing forcausal constraint modifications without altering the covariate joint distribution or propensity score. : Lalonde: Correlation matrices across covariates and the outcome (re78), comparingthe second moments of distributions for the Lalonde observed real data, as well as synthetic datagenerated by a trained Frugal Flow (2nd column) and Credence (3rd column) models. The comparisonis further extended to models with default settings and those with modified bias rigidity (4th column). : e401(k): Correlation matrices across covariates and the outcome (net_tfa), comparingthe second moments of distributions for the e401(k) observed real data and synthetic data generatedby trained Frugal Flow (2nd column) and Credence (3rd column) models. The comparison is furtherextended to models with default settings and those with modified bias rigidity (4th column).",
  "D.3.7Loss Optimisation": "In training, we perform a train-val split and use a patience criterion on the validation loss as acriterion to stop the training. Namely, we monitor the validation loss and stop training if the validationloss does not improve for a specified number of epochs (we set the patience value to 100). This aimsto prevent overfitting and saves computational resources by not continuing training unnecessarily. Itis standard in machine learning model training and was implemented in the FlowJax package that weuse as code-base to build the Frugal Flow package from."
}