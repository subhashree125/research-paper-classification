{
  "Abstract": "Rational design of next-generation functional materials relied on quantitative pre-dictions of their electronic structures beyond single building blocks. First-principlesquantum mechanical (QM) modeling became infeasible as the size of a materialgrew beyond hundreds of atoms. In this study, we developed a new computationaltool integrating fragment-based graph neural networks (FBGNN) into the fragment-based many-body expansion (MBE) theory, referred to as FBGNN-MBE, anddemonstrated its capacity to reproduce full-dimensional potential energy surfaces(FD-PES) for hierarchic chemical systems with manageable accuracy, complexity,and interpretability. In particular, we divided the entire system into basic buildingblocks (fragments), evaluated their single-fragment energies using a first-principlesQM model and attacked many-fragment interactions using the structurepropertyrelationships trained by FBGNNs. Our development of FBGNN-MBE demon-strated the potential of a new framework integrating deep learning models intofragment-based QM methods, and marked a significant step towards computation-ally aided design of large functional materials.",
  "Introduction": "Discovery of complex materials that exhibited exceptional quantum mechanical (QM) properties andfunction beyond single monomers and equilibrium structures, such as metalorganic frameworks(MOF) , organic semiconductors (OSC) , and branched deoxyribonucleic acids (DNA) ,was crucial in emergent scientific and technological areas, such as carbon neutrality , renewableenergy , and next-generation optoelectronics . Computational chemistry eliminated expensivetrial-and-error experiments and explored the vast chemical space. In the present study, we aimed toaccomplish a computational design for these complex materials based on their aggregate and dynamicQM properties, which required a rapid and rigorous evaluation of their full-dimensional potentialenergy surfaces (FD-PES) on the fly. This job cannot be done by first-principles QM models likesecond-order MllerPlesset perturbation theory (MP2) or density functional theory (DFT) due to the prohibitive costs for large systems because their computational complexity scaled as thefifth and third power of the number of basis functions . Motivated by this problem, many fragment-based divide-and-conquer methods were developedto accelerate typical QM approaches while maintaining the accuracy . Among all thesetheories, many-body expansion (MBE) stood out due to its straightforward implementation and rapidconvergence for many-body interactions . MBE partitioned a complex system into manageablefragments (bodies) and expanded the total electronic energy or other relevant properties into a seriesof one-body (1B) and many-body (nB) terms with progressively diminishing contributions. This",
  "arXiv:2411.01578v1 [cond-mat.mtrl-sci] 3 Nov 2024": "hierarchical treatment not only streamlined a calculation with a reduced computational complexity butalso enabled a deeper analysis of the electronic structure landscape and the intricate many-fragmentinteractions, both of which were critical properties for computational material discovery. The Herbert group and the Xantheas group made prominent and complementary contributions inrecent methodology of MBE for both static and dynamic behaviors of condensed-phase systems.Herbert and coworkers developed the generalized many-body expansion (GMBE) framework tohandle systems with ill-defined or overlapping fragments like fluoride-water complexes. Theyalso introduced energy-screened MBE with enhanced efficiency and intact accuracy by selectivelyincluding only sizable many-body contributions in the total electronic energy . Xantheasand coworkers leveraged MBE for potential energy surfaces (PES) and demonstrated that MBE canprovide a more quantitative understanding of molecular properties than simpler pairwise-additivemodels. They further incorporated MBE into molecular dynamics (MD) simulations to involve subtleQM phenomena for electrons and nuclei . Despite these advances, applying QM-basedMBE to functional materials with more sophisticated structures and more intense interactions thanwater clusters remains a challenge due to the large numbers of n-fragment interactions for high ns. The integration of neural networks (NNs) offered a revolutionary approach to accelerate QM methodslike MBE . In particular, Parkhill and coworkers merged NN into MBE (NN-MBE) anddemonstrated its strong predictive power for the FD-PES of methanol (CH3OH) clusters with meanabsolute errors (MAEs) of 9.79 and 12.55 kcal/mol for two-body (2B) and three-body (3B) energiescompared to MP2 but a reduced computational cost by six orders of magnitude . However,intrinsic problems of traditional NNs in terms of the missing physical information , thelimited transferability and interpretability , and inability to handle graph-structured data compromised their capacity in QM modeling . Instead, the development of graph neural networks (GNNs) experienced exceptional success in chem-ical systems because their nodeedge structures naturally aligned with three-dimensional atombondstructures and encoded mechanical information about chemical bonds and intermolecular interactions. Outstanding examples included SchNet , GeoMol , FP-GNN (fingerprints-GNN) , and dyMEAN (dynamic multi-channel equivariant graph network) which incorpo-rated complex geometric information in the graph representation, PhysNet , DimeNet/DimeNet++(directional message passing NN) , E(n) EGNN (equivariant GNN) , SEGNN (steerableE(3) equivariant GNN) , and ViSNet (vector-scalar interactive GNN) which integrateddirectional message passing framework and physical principles, and ml-QM-GNN (QM-augmentedGNN) , MD-GNN (mechanism-data-driven graph neural network) , MP-GNN (multiphysicalGNN) , and SS-GNN (simple-structured graph neural network) which implemented quan-titative mechanical and electronic properties. Most of these GNN models demonstrated enhancedperformance in molecular representation learning but they treated all atoms on equal footing withoutconsidering the chemical hierarchy, which impacted their descriptive and predictive capacity forcomplex systems with many building blocks. State-of-the-art GNN models with subgraph of fragment-based frameworks, such as SubGNN (sub-graph NN) , FragGraph , subGE (subgraph embedding) , MXMNet (multiplex molecularGNN) , and PAMNet (physics aware multiplex GNN) , all represented building blocks likemolecules or monomers into subgraphs or local graphs, and captured interatomic, intermolecular andinterfragment interactions using local and global message-passing architectures. Such an analogybetween hierarchic graph structures and hierarchic chemical systems rendered these models outstand-ing methods for studying complex systems. In particular, MXMNet and PAMNet developed by Xieand coworkers significantly advanced the representation learning of hierarchic systems by integratingmolecular mechanics and multiplex graph representations and proved successful in reproducingthe molecular properties from the QM9 data set , the proteinligand binding affinities from thePDBBind data set , and the three-dimensional (3D) structures of ribonucleic acids (RNA) . In the present study, we developed a novel computational model named FBGNN-MBE (fragment-based graph neural network driven many-body expansion) to address all problems mentioned above.Our ultimate goal was to accomplish a rapid, precise, transferable, and interpretable scheme toevaluate FD-PES for any functional materials with many building blocks and important dynamicproperties. Our major contributions include:",
  "Many-Body Expansion Theory": "MBE decomposed any aggregate property, such as the total ground state energy (E), into contributionsfrom individual fragments (1B) and many-fragment (nB) interactions. Truncated at a vanishinghigh-order term, MBE facilitated an efficient approximation of the property in question. Beyondreducing the computational cost, MBE also enabled the capture of the natures and strengths ofmany-fragment interactions in a chemical system. The generic MBE theory partitioned a system intoN fragments and expands E until the a higher order tuncation (3 here) :",
  "E2Bij = Eij E1Bi E1Bj(3)": "E3Bijk = Eijk E2Bij E2Bik E2Bjk E1Bi E1Bj E1Bk(4)Although higher-order terms captured more complex interactions, we neglected beyond 3B energiesdue to vanishing contributions, tolerable errors, and exponentially-growing sizes. We discussed ourfragmentation strategies in Section A.2. In FBGNN-MBE, we utilized a hybrid strategy by calculating1B energies using MP2 or DFT but leveraging FBGNNs for 2B and 3B energies (). partition MP2 or DFT GNN MBE systemfragments one-body energiesapproximatetotal energy 1 body2 body3 body many-body energies",
  "General Architecture of GNNsA GNN typically employed multiple convolution layers to trans-form input features into node embeddings, followed by graph pooling to generate a graph representa-": "tion, which can then be used for various downstream tasks such as predicting 2B and 3B energies . In chemical applications, the input graph was structured with features, including nodesrepresenting individual atoms and edges capturing pairwise interatomic interactions as functions ofatomistic structures. Each node was initialized with features that described its atomic properties,such as atomic number, charge, electronegativity, and even orbitals, while each edge reflected aninteratomic distance or a bond length. These features iteratively updated the node embeddings byaggregating information from neighboring nodes and effectively extract the local environment eachatom resided in. Backbone MXMNet and PAMNet ModelsWe employed MXMNet and PAMNet asour backbone FBGNN models. Building on the general GNN framework, MXMNet and PAMNetleveraged multiplex globallocal architectures to align with hierarchic chemical systems. Theyrepresented the entire material as the global graph (Gg) and every single building block as a localgraph (Gl, or subgraph). They also represented short-range interatomic interactions as local edges(El) within a local graph, and long-range interfragment interactions as global edges (Eg) betweenlocal graphs. Both models applied a two-layer multiplex graph (G = Gg, Gl). The global graphviewed the entire system as a network of pre-defined fragments (local graphs) and many-fragmentinteractions (global edges), symbolized as Gg = (Gl, Eg). Each local graph, containing a singlefragment, viewed this fragment as a network of atoms [nodes (V)] and chemical bonds (local edges),symbolized as Gl = (V, El). The cross mapping modules and the message passing algorithms integrated all information from the global and local layers (). This scheme allowed us toimplement the geometric information about a chemical system directly into the global and local graphrepresentations for downstream tasks and to seamlessly connect to the next-stage model design tofurther refine and process these models. The architecture of MXMNet included three modules ( in burgundy boxes). The embeddingmodule converted the Coulomb matrix , which contained atomic charges and interatomic dis-tances, into a trainable embedding vector as the initial node feature for the multiplex graph. Themultiplex molecular (MXM) module incorporated the local message passing mechanism, the globalmessage passing mechanism , and the cross layer mapping for interactively updating node embed-dings and local graph representation, and was the foundational component in the multiplex moleculargraphs. The prediction module leveraged the final node embeddings to predict fragment-specific andsystem-wide properties in question . An overall heterogeneous structure like this proved superiorto conventional GNNs . Building upon MXMNet, PAMNet implemented an additionalfusion module to integrate different types of interactions into the final prediction while ensuring theE(3)-invariance of the presentations ( in orange boxes). This fusion model not only enhancedthe model accuracy and efficiency in capturing key features from geometric and electronic structuresbut also simplified the process . Given the complexity of the data structure, we utilized the Adamoptimizer for faster convergence and higher suitability for complex systems. We provided thepseudo-algorithms of MXMNet and PAMNet in the context of MBE in Section A.1. system local message passing local layer global layer global graph local graphs global message passing cross layer mapping attentionpooling many-body properties multiplexmolecular modulefusion moduleprediction module attentionpooling pooling MXMNetPAMNet embedding module",
  "To provide a proof-of-concept of our MXMNet-MBE and PAMNet-MBE models and assess theirrobustness, accuracy, and efficiency to reproduce 2B and 3B interactions, we established benchmark": "systems with three molecular clusters whose structures and behaviors depended on weak or moderateinteractions between building blocks, including pure water (H2O) with moderate or strong hydrogenbonds, pure phenol (C6H5OH) with weak hydrogen bonds and van der Waals interactions, and a 1:1waterphenol (H2O:C6H5OH) mixture showing a synergistic effect of the two interactions .We carved all systems from condensed phases, and designed every single water or phenol moleculeas a single fragment, and collected all possible dimers and trimers for the evaluation of 2B and 3Benergies in Equation (1). We calculated 1B energies using DFT or MP2 and predicted 2B and 3Benergies using MXMNet and PAMNet models.",
  "H2O:C6H5OH10:10694190,000228,0000.50.10.1": "To sample an ergodic and sufficient data set for each benchmark system, we included high-energypoints from its FD-PES. We employed MD simulations at the canonical ensemble (constant NV T)using GROMACS at a doubled (2) density, and generated their initial configurations usingPACKMOL . We also set temperatures close to or above the boiling point to ensure a fasterequilibration. For each simulation we performed energy minimization (tem), equilibration (teq), andproduction (tpr), and collected a large number of snapshots. We summarized all the details of ourMD simulations in . From each snapshot, we collected all dimers and trimers to create adata set with a broad representation of geometric configurations and interfragment interactions. Foreach data set, we randomly split them into an 80:5:15 ratio for training, validation, and test sets. Toestablish the training set and calibrate the validation and test sets, we calculated all monomer, dimer,and trimer energies using QM methods, which were MP2 with the aug-cc-pVDZ basis set for water clusters and DFT with the B97X-D3 exchangecorrelation functional and the6-311+G(d,p) basis set for phenol-involving clusters , all in Q-Chem 6.2 . Following the QMcalculations, we calculateed 2B and 3B energies (E2Bij and E3Bijk) as outlined in Equations (3) and (4).",
  "Hyperparameter Tuning": "Hyperparameter tuning was executed using the validation set for each benchmark system . Weidentified six critical hyperparameters: the number of epochs (Nepoch), the number of convolutionallayers (Nlayer), the local cutoff distance (Dlc), the global cutoff distance (Dgc), the batch size (Nbatch),and the learning rate (klearn), because they demonstrated significant impact on GNN performance inmolecular modeling . During this process we evaluated the model performance after each epochby monitoring the validation loss and employed an early stopping mechanism to prevent overfitting.",
  "Results and Discussions": "To confirm the potential of FBGNN-MBE models in reproducing FD-PES for functional materials, weexhibited their state-of-the-art performance in predicting 2B and 3B energies for all three benchmarksystems. In Figures 3 and 4, we compared 2B and 3B energies evaluated using MP2 or DFT withtheir counterparts predicted by MXMNet-MBE and PAMNet-MBE. We also summarized their valuesof R-squared coefficient (R2), mean signed errors (MSE), MAE, and average CPU/GPU times forfirst-principles (FP) and GNN treatments in , with their definitions in the Section A.4.",
  "Overall Performance Assessment": "We herein analyzed the overall performance of MXMNet-MBE and PAMNet-MBE to provide aproof-of-concept for these two models using benchmark systems. In the tasks of predicting 2Band 3B energies, both MXMNet-MBE and PAMNet-MBE demonstrated extremely high accuracyand efficiency, with only subtle differences between each other. For 2B energies, they achievedR2 > 0.92, |MSE| < 0.003 kcal/mol, and MAE < 0.28 kcal/mol for pure water, and R2 > 0.99,|MSE| < 0.008 kcal/mol, and MAE < 0.15 kcal/mol for pure phenol and waterphenol mixture.Regarding 3B energies, they arrived at the best performance of R2 > 0.999, |MSE| < 0.002 kcal/mol,and MAE < 0.013 kcal/mol for pure water, and R2 > 0.84, |MSE| < 0.001 kcal/mol, and MAE< 0.06 kcal/mol for pure phenol and waterphenol mixture. The values of MSEs were universallynegligible compared to the typical error bars of MP2 and DFT , indicating the absenceof systematic errors or biases in FBGNN-MBE. Similarly, all MAEs fell significantly below thethreshold of chemical accuracy of 1 kcal/mol. Along with large values of R2 they implied thepotential of well-trained FBGNN models to replace MP2 or DFT in generating lower order termsin MBE with minimal deviations from the actual values. Additionally, the significant reductions incomputational costs by more than 91.5% or higher confirmed that FBGNN-MBE can accelerate the",
  ": Comparison between PAMNet-predicted and MP2/DFT-evaluated 2B and 3B energies forall three benchmark systems": "fragment-based calculations by two to four orders of magnitude. This was because the computationalcomplexity was decreased from N 5M 5 for MP2 and N 3M 5 for MP2-MBE to NM 5 for MP2-basedFBGNN-MBE, or N 3M 3 for DFT and DFT-MBE to NM 3 for DFT-based FBGNN-MBE, for asystem containing N fragments with M basis functions each fragment.",
  "Comparison between MXMNet-MBE and PAMNet-MBE": "We herein proved the marginally stronger performance of PAMNet-MBE compared to MXMNet-MBE due to the inclusion of the fusion module. Behaviors of MXMNet-MBE and PAMNet-MBEwere similar, with PAMNet-MBE slightly outperforming MXMNet-MBE in accuracy and slightlyunderperforming in efficiency for 2B energies. For example, for pure phenol, MXMNet-MBE attainedimpressive R2 = 0.9955 and MAE = 0.1483 kcal/mol and reduced the time cost by 99.92%, whilePAMNet-MBE achieved R2 = 0.9963 and MAE = 0.1348 kcal/mol and reduced the time cost by99.88%. This result indicated that the implementation of the fusion module in PAMNet enhancedthe capacity to capture moderate two-fragment interactions but introduced a minor increase in thecomputational cost. Regarding the larger and more sophisticated 3B energy data sets, PAMNet-MBEshowed a higher efficiency in addition to a higher accuracy. From these observations we concludedthat PAMNet was the preferred choice as a FBGNN for our current and future FBGNN-MBE tasks.",
  "Comparison across Data Sets": "We herein discussed the relationship between the natures and strengths of 2B and 3B interactions in asystem and the behaviors of PAMNet-MBE and MXMNet-MBE. A comparison across different datasets reflected the character of these benchmark systems in addition to the accuracy of the FBGNN-MBE models. For example, all MAEs of 2B energies were significantly higher than 3B counterparts,because the magnitudes of 2B energies were usually greater than 3B energies. For a similar reason,due to the stronger hydrogen bonds in pure water (a few kcal/mol), its MAEs associated with 2Benergies were also considerably higher than pure phenol and waterphenol mixture which weredominated by weaker van der Waals interactions. Moreover, for pure water both MXMNet-MBEand PAMNet-MBE exhibited a stronger performance in 3B energies than 2B energies, which wasintriguing and counterintuitive but can be attributed to several factors. (a) Water trimers encompassedbroader ranges of geometries and QM effects and a larger data set and offered more informative datafor model training, while dimers were usually oversimplified by missing some critical interactions. (b)3B terms from the 2-density clusters incorporated both attractive (negative) and repulsive (positive)",
  "Comparison with Conventional GNN Models": "We herein demonstrated the state-of-the-art accuracy of FBGNN-MBE. We conducted a comparativeanalysis against MBE approaches built upon several established GNN architectures at the frontier ofcomputational chemistry and molecular representation learning, including SchNet , DimeNet DimeNet++ , and ViSNet . Using 2B and 3B energies of pure water clusters, we comparedtheir accuracy in terms of the values of R2 and MAEs (). For 2B energies, MXMNet-MBEand PAMNet-MBE achieved the highest R2 values of 0.9400 and 0.9230, respectively, and the lowestMAEs of 0.2604 and 0.2766 kcal/mol, respectively. These results substantially outperformed anyother model, which all showed R2 < 0.67 (without obvious trends) and MAE > 0.86 kcal/mol(more than three times as much). The performance gap was equally pronounced for the 3B energies,where MXMNet-MBE and PAMNet-MBE achieved nearly-perfect R2 values of 0.9998 and 0.9999,respectively, with remarkably low MAE values of 0.0121 and 0.0109 kcal/mol, respectively. Whileother models like DimeNet++-MBE also performed well on 3B energies (R2 = 0.9986, MAE= 0.0214 kcal/mol), MXMNet-MBE and PAMNet-MBE still maintained a clear edge in accuracy.These results underlined the enhanced predictive accuracy of FBGNN-MBE models for both 2B and3B interactions in water clusters characterized by moderate-strength hydrogen bonds, due to the theefficacy of FBGNNs in capturing the complexities of both attractive and repulsive interactions.",
  "Deeper Performance Analysis": "We herein conducted a deeper analysis to understand the impact of the molecular density on thecharacter of the electronic structures. We reported the average 2B and 3B energies from MP2 orDFT calculations as EFP in . Across all benchmark systems, the values of EFP for the 2Benergies were always sizable positive values, while those for the 3B energies were either positive ornegative but still negligible considering the error bars of MP2 and DFT. The behaviors of 2B energieswere counterintuitive at first sight because we had expected attractive hydrogen bonds and van derWaals interactions, but can actually be attributed to the 2 densities of these sampled clusters. Weemployed such 2 densities because we wanted to ensure an inclusion of high energy configurationsin the samples to treat the increased complexity, amplify the importance of hydrogen bonds, andpromote the precise reproduction of 2B/3B interactions. However, this treatment also altered thephysics of the interacting clusters. For example, by increasing the density and pressure, low-densitywater (LDW) transitions into high-density water (HDW) through the disruption of hydrogen bondsbetween the first and second coordination shells, resulting in significant structural shifts and morelinear hydrogen bonding configurations . At the same time, HDW illustrated a stronger (Pauli)repulsion between closely packed molecules to counteract the attractive hydrogen bonds. Both factorsintroduced sizable positive contributions for the 2B energies . The behaviors of 3B energies,though smaller in magnitude, were not significantly impacted by the high density and still reflected acomplex interplay of cooperative and anti-cooperative effects .",
  "Conclusions and Future Directions": "We presented FBGNN-MBE, a novel computational framework that hybridized FBGNNs withthe MBE theory and exhibited enhanced robustness, accuracy, transferability, and interpretabilityfrom conventional NN- and GNN-accelerated QM models. Our method addressed the prohibitivecomputational costs of pure QM or QM-MBE methods in modeling aggregate and dynamic propertiesof large functional materials. In contrast to existing QM-MBE, we only evaluated 1B energies fromfirst principles but generated nB (n 2) energies based on structureenergy relationships trainedby FBGNN. Instead of conventional GNN models, we implemented fragment-based MXMNet andPAMNet formalisms as backbone GNN approaches for a more intuitive alignment between modelarchitecture and chemical hierarchy. Benchmarked on three clusters with different natures andstrengths of intermolecular interactions, including pure water, pure phenol, and 1:1 waterphenolmixture, we revealed that well-trained FBGNN-MBE reached state-of-the-art chemical agreementwith traditional QM-MBE models, with MAEs < 0.3 kcal/mol for 2B energies and < 0.02 kcal/molfor 3B energies, but reduced the computational cost by two to four orders of magnitude. While our FBGNN-MBE framework was promising in both efficiency and accuracy, it exhibitedat least two limitations that required our attentions in future developments. First, our training setswere created using 2 molecular densities, which allowed us to sample high-energy configurationsand enhance ergodicity and diversity of the data set, but also introduced biases towards repulsive 2Binteractions . Second, the present study focused on molecular aggregates with weak to moderatemany-fragment interactions and the current fragmentation strategy did not cleave chemical bonds,so that the model transferability remained elusive. Finally, the present study did not implementthe predictions for potential energy gradients (forces) or excited state energies. Looking ahead, wewill apply FBGNN-MBE in the place of QM and QM-MBE in producing aggregate and dynamicproperties that require on-the-fly evaluations of a FD-PES, such as Monte Carlo (MC) and MDsimulations, and will extend the present framework beyond ground state electronic energies, such asoptical band gaps and vibrational frequencies. We will enhance the model transferability to variouschemical systems by implementing transfer learning . We will improve the model capacity inphysical interpretation by implementing the energy decomposition analysis (EDA) so thatwe can quantitatively fraction the nB energies into different attractive and repulsive terms, such aselectrostatics, Pauli repulsion, exchangecorrelation, and dispersion. These applications will enhancethe model potentials in the rational design of next-generation functional materials.",
  "Acknowledgement": "Z.L. and H.G. thank the financial support provided by UMass Amherst Start-Up Funds and NSF-UMass ADVANCE Collaborative Research Seed Grant. All authors thank the high-performancesupercomputing resources provided by UMass/URI Unity Cluster and MIT Supercloud . Kaili Yao, Yujian Xia, Jun Li, Ning Wang, Jingrui Han, Congcong Gao, Mei Han, GuoqiangShen, Yongchang Liu, Ali Seifitokaldani, Xuhui Sun, and Hongyan Liang. Metalorganicframework derived copper catalysts for CO2 to ethylene conversion. In: Journal of Ma-terials Chemistry A 8 (22 2020), pp. 1111711123. URL:",
  "Ryan M. Richard, Ka Un Lao, and John M. Herbert. Understanding the many-body expansionfor large systems. I. Precision considerations. In: The Journal of Chemical Physics 141.1(2014), p. 014108. URL:": "Ka Un Lao, Kuan-Yu Liu, Ryan M. Richard, and John M. Herbert. Understanding the many-body expansion for large systems. II. Accuracy considerations. In: The Journal of ChemicalPhysics 144.16 (2016), p. 164105. URL: Jie Liu and John M. Herbert. PairPair Approximation to the Generalized Many-BodyExpansion: An Alternative to the Four-Body Expansion for ab Initio Prediction of ProteinEnergetics via Molecular Fragmentation. In: Journal of Chemical Theory and Computation12.2 (2016), pp. 572584. URL: Kuan-Yu Liu and John M. Herbert. Understanding the many-body expansion for largesystems. III. Critical role of four-body terms, counterpoise corrections, and cutoffs. In: TheJournal of Chemical Physics 147.16 (2017), p. 161729. URL: Kuan-Yu Liu and John M. Herbert. Energy-Screened Many-Body Expansion: A Practical YetAccurate Fragmentation Method for Quantum Chemistry. In: Journal of Chemical Theoryand Computation 16.1 (2020), pp. 475487. URL: Dustin R. Broderick and John M. Herbert. Scalable generalized screening for high-orderterms in the many-body expansion: Algorithm, open-source implementation, and demon-stration. In: The Journal of Chemical Physics 159.17 (2023), p. 174801. URL: Joseph P Heindel and Sotiris S. Xantheas. The many-body expansion for aqueous systemsrevisited: I. Waterwater interactions. In: Journal of Chemical Theory and Computation16.11 (2020), pp. 68436855. URL: Joseph P. Heindel and Sotiris S. Xantheas. The Many-Body Expansion for Aqueous SystemsRevisited: II. Alkali Metal and Halide IonWater Interactions. In: Journal of ChemicalTheory and Computation 17.4 (2021), pp. 22002216. URL:",
  "Joseph P. Heindel and Sotiris S. Xantheas. Molecular Dynamics Driven by the Many-BodyExpansion (MBE-MD). In: Journal of Chemical Theory and Computation 17.12 (2021),pp. 73417352. URL:": "Joseph P. Heindel, Mikhail V. Kirov, and Sotiris S. Xantheas. Hydrogen bond arrangementsin (H2O)20,24,28 clathrate hydrate cages: Optimization and many-body analysis. In: TheJournal of Chemical Physics 157.9 (2022), p. 094301. URL: Kristina M. Herman, Joseph P. Heindel, and Sotiris S. Xantheas. The many-body expansionfor aqueous systems revisited: III. Hofmeister ionwater interactions. In: Physical ChemistryChemical Physics 23 (19 2021), pp. 1119611210. URL:",
  "Kristina M. Herman, Anthony J. Stone, and Sotiris S. Xantheas. A classical model forthree-body interactions in aqueous ionic systems. In: The Journal of Chemical Physics 157.2(2022), p. 024101. URL:": "Kristina M. Herman, Anthony J. Stone, and Sotiris S. Xantheas. Accurate Calculation ofMany-Body Energies in Water Clusters Using a Classical Geometry-Dependent InductionModel. In: Journal of Chemical Theory and Computation 19.19 (2023), pp. 68056815.URL: Kristina M. Herman and Sotiris S. Xantheas. An extensive assessment of the performanceof pairwise and many-body interaction potentials in reproducing ab initio benchmark bindingenergies for water clusters n = 2 25. In: Physical Chemistry Chemical Physics 25 (102023), pp. 71207143. URL: Kristina M. Herman and Sotiris S. Xantheas. A Formulation of the Many-Body Expansion(MBE) for Periodic Systems: Application to Several Ice Phases. In: The Journal of PhysicalChemistry Letters 14.4 (2023), pp. 989999. URL:",
  "Theodore Depastas, George A. Souliotis, Demeter Tzeli, and Sotiris S. Xantheas. Many-body expansion for light nuclear systems. In: Physical Review C 107 (4 2023), p. 044004.URL:": "Kristof T Schtt, Farhad Arbabzadah, Stefan Chmiela, Klaus R Mller, and AlexandreTkatchenko. Quantum-Chemical Insights From Deep Tensor Neural Networks. In: NatureCommunications 8.1 (2017), p. 13890. URL: John A Keith, Valentin Vassilev-Galindo, Bingqing Cheng, Stefan Chmiela, MichaelGastegger, Klaus-Robert Mller, and Alexandre Tkatchenko. Combining Machine Learningand Computational Chemistry for Predictive Insights Into Chemical Systems. In: ChemicalReviews 121.16 (2021), pp. 98169872. URL: Yaolong Zhang, Qidong Lin, and Bin Jiang. Atomistic neural network representationsfor chemical dynamics simulations of molecular, condensed phase, and interfacial systems:Efficiency, representability, and generalization. In: WIREs Computational Molecular Science13.3 (2023), e1645. URL:",
  "Kun Yao, John E Herr, and John Parkhill. The Many-Body Expansion Combined WithNeural Networks. In: The Journal of Chemical Physics 146.1 (2017), p. 014106. URL:": "Stefan Chmiela, Alexandre Tkatchenko, Huziel E. Sauceda, Igor Poltavsky, Kristof T. Schtt,and Klaus-Robert Mller. Machine learning of accurate energy-conserving molecular forcefields. In: Science Advances 3.5 (2017), e1603015. URL: Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl.Neural Message Passing for Quantum Chemistry. In: Proceedings of the 34th Interna-tional Conference on Machine Learning. Ed. by Doina Precup and Yee Whye Teh. Vol. 70.Proceedings of Machine Learning Research. PMLR, 2017, pp. 12631272. URL: Kun Yao, John E. Herr, David W. Toth, Ryker Mckintyre, and John Parkhill. The TensorMol-0.1 model chemistry: A neural network augmented with long-range physics. In: ChemicalScience 9 (8 2018), pp. 22612269. URL:",
  "Giuseppe Carleo and Matthias Troyer. Solving the quantum many-body problem withartificial neural networks. In: Science 355.6325 (2017), pp. 602606. URL:": "Chi Chen, Weike Ye, Yunxing Zuo, Chen Zheng, and Shyue Ping Ong. Graph networks as auniversal machine learning framework for molecules and crystals. In: Chemistry of Materials31.9 (2019), pp. 35643572. URL: Minyi Dai, Mehmet F Demirel, Yingyu Liang, and Jia-Mian Hu. Graph neural networks foran accurate and interpretable prediction of the properties of polycrystalline materials. In: npjComputational Materials 7 (2021), p. 103. URL: Minyi Dai, Mehmet F Demirel, Yingyu Liang, and Jia-Mian Hu. Author Correction: Graphneural networks for an accurate and interpretable prediction of the properties of polycrystallinematerials. In: npj Computational Materials 8 (2022), p. 122. URL: Kristof T. Schtt, Huziel E. Sauceda, Pieter-Jan Kindermans, Alexandre Tkatchenko, andKlaus-Robert Mller. SchNet A Deep Learning Architecture for Molecules and Materials.In: The Journal of Chemical Physics 148.24 (2018), p. 241722. URL: Octavian Ganea, Lagnajit Pattanaik, Connor Coley, Regina Barzilay, Klavs Jensen, WilliamGreen, and Tommi Jaakkola. GeoMol: Torsional Geometric Generation of Molecular 3DConformer Ensembles. In: Advances in Neural Information Processing Systems. Ed. byM. Ranzato, A. Beygelzimer, Y. Dauphin, P.S. Liang, and J. Wortman Vaughan. Vol. 34.Curran Associates, Inc., 2021, pp. 1375713769. URL: Hanxuan Cai, Huimin Zhang, Duancheng Zhao, Jingxing Wu, and Ling Wang. FP-GNN: aversatile deep learning architecture for enhanced molecular property prediction. In: Briefingsin Bioinformatics 23.6 (2022), bbac408. URL: Xiangzhe Kong, Wenbing Huang, and Yang Liu. End-to-End Full-Atom Antibody Design.In: Proceedings of the 40th International Conference on Machine Learning. Ed. by AndreasKrause, Emma Brunskill, Kyunghyun Cho, Barbara Engelhardt, Sivan Sabato, and JonathanScarlett. Vol. 202. Proceedings of Machine Learning Research. PMLR, 2023, pp. 1740917429. URL: Oliver T Unke and Markus Meuwly. PhysNet: A neural network for predicting energies,forces, dipole moments, and partial charges. In: Journal of Chemical Theory and Computa-tion 15.6 (2019), pp. 36783693. URL:",
  "Johannes Gasteiger, Shankari Giri, Johannes T Margraf, and Stephan Gnnemann. Fast anduncertainty-aware directional message passing for non-equilibrium molecules. In: arXiv(2020), p. 2011.14115. URL:": "Vctor Garcia Satorras, Emiel Hoogeboom, and Max Welling. E(n) Equivariant Graph NeuralNetworks. In: Proceedings of the 38th International Conference on Machine Learning. Ed. byMarina Meila and Tong Zhang. Vol. 139. Proceedings of Machine Learning Research. PMLR,2021, pp. 93239332. URL: Johannes Brandstetter, Rob Hesselink, Elise van der Pol, Erik J. Bekkers, and Max Welling.Geometric and Physical Quantities improve E(3) Equivariant Message Passing. In: Interna-tional Conference on Learning Representations. 2022. URL: Yusong Wang, Tong Wang, Shaoning Li, Xinheng He, Mingyu Li, Zun Wang, NanningZheng, Bin Shao, and Tie-Yan Liu. Enhancing geometric representations for moleculeswith equivariant vector-scalar interactive message passing. In: Nature Communications 15.1(2024), p. 313. URL: Thijs Stuyver and Connor W. Coley. Quantum chemistry-augmented neural networks forreactivity prediction: Performance, generalizability, and explainability. In: The Journal ofChemical Physics 156.8 (2022), p. 084104. URL: Saian Chen, Aziguli Wulamu, Qiping Zou, Han Zheng, Li Wen, Xi Guo, Han Chen, TaohongZhang, and Ying Zhang. MD-GNN: A mechanism-data-driven graph neural network formolecular properties prediction and new material discovery. In: Journal of MolecularGraphics and Modelling 123 (2023), p. 108506. URL: Xiao-Shuang Li, Xiang Liu, Le Lu, Xian-Sheng Hua, Ying Chi, and Kelin Xia. Multiphysicalgraph neural network (MP-GNN) for COVID-19 drug design. In: Briefings in Bioinformatics23.4 (2022), bbac231. URL: Shuke Zhang, Yanzhao Jin, Tianmeng Liu, Qi Wang, Zhaohui Zhang, Shuliang Zhao, andBo Shan. SS-GNN: a simple-structured graph neural network for affinity prediction. In:ACS Omega 8.25 (2023), pp. 2249622507. URL: Emily Alsentzer, Samuel Finlayson, Michelle Li, and Marinka Zitnik. Subgraph NeuralNetworks. In: Advances in Neural Information Processing Systems. Ed. by H. Larochelle,M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin. Vol. 33. Curran Associates, Inc., 2020,pp. 80178029. URL:",
  "William L Hamilton. Graph Representation Learning. In: Synthesis Lectures on ArtificalIntelligence and Machine Learning 14.3 (2020), pp. 1159. URL:": "Matthias Rupp, Alexandre Tkatchenko, Klaus-Robert Mller, and O. Anatole von Lilienfeld.Fast and Accurate Modeling of Molecular Atomization Energies with Machine Learning.In: Physical Review Letters 108 (5 2012), p. 058301. URL: Xunqiang Jiang, Yuanfu Lu, Yuan Fang, and Chuan Shi. Contrastive Pre-Training of GNNson Heterogeneous Graphs. In: Proceedings of the 30th ACM International Conference onInformation & Knowledge Management. CIKM 21. Association for Computing Machinery,2021, pp. 803812. URL: Xiao Wang, Deyu Bo, Chuan Shi, Shaohua Fan, Yanfang Ye, and S Yu Philip. A survey onheterogeneous graph embedding: methods, techniques, applications and sources. In: IEEETransactions on Big Data 9.2 (2023), pp. 415436. URL:",
  "Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In: arXiv(2017), p. 1412.6980. URL:": "Gennady Yu Gor, Salla Tapio, Alexandra V Domanskaya, Markku Rsnen, Alexander VNemukhin, and Leonid Khriachtchev. Matrix-isolation study of the phenolwater complexand phenol dimer. In: Chemical Physics Letters 517.1-3 (2011), pp. 915. URL: Ning Zhang, Xuehua Ruan, Yuechun Song, Zhao Liu, and Gaohong He. Molecular dynamicssimulation of the hydration structure and hydrogen bonding behavior of phenol in aqueoussolution. In: Journal of Molecular Liquids 221 (2016), pp. 942948. URL: Mark James Abraham, Teemu Murtola, Roland Schulz, Szilrd Pll, Jeremy C Smith, BerkHess, and Erik Lindahl. GROMACS: High performance molecular simulations throughmulti-level parallelism from laptops to supercomputers. In: SoftwareX 1 (2015), pp. 1925.URL: Leandro Martnez, Ricardo Andrade, Ernesto G Birgin, and Jos Mario Martnez. PACK-MOL: A package for building initial configurations for molecular dynamics simulations.In: Journal of Computational Chemistry 30.13 (2009), pp. 21572164. URL:",
  "Jr. Dunning Thom H. Gaussian basis sets for use in correlated molecular calculations. I. Theatoms boron through neon and hydrogen. In: The Journal of Chemical Physics 90.2 (1989),pp. 10071023. URL:": "Rick A. Kendall, Thom H. Dunning Jr., and Robert J. Harrison. Electron affinities of the first-row atoms revisited. Systematic basis sets and wave functions. In: The Journal of ChemicalPhysics 96.9 (1992), pp. 67966806. URL: You-Sheng Lin, Guan-De Li, Shan-Ping Mao, and Jeng-Da Chai. Long-range correctedhybrid density functionals with improved dispersion corrections. In: Journal of ChemicalTheory and Computation 9.1 (2013), pp. 263272. URL: R. Krishnan, J. S. Binkley, R. Seeger, and J. A. Pople. Self-consistent molecular orbitalmethods. XX. A basis set for correlated wave functions. In: The Journal of Chemical Physics72.1 (1980), pp. 650654. URL: Evgeny Epifanovsky, Andrew T. B. Gilbert, Xintian Feng, Joonho Lee, Yuezhi Mao, NarbeMardirossian, Pavel Pokhilko, Alec F. White, Marc P. Coons, Adrian L. Dempwolff, Zhengt-ing Gan, Diptarka Hait, Paul R. Horn, Leif D. Jacobson, Ilya Kaliman, Jrg Kussmann,Adrian W. Lange, Ka Un Lao, Daniel S. Levine, Jie Liu, Simon C. McKenzie, Adrian F.Morrison, Kaushik D. Nanda, Felix Plasser, Dirk R. Rehn, Marta L. Vidal, Zhi-Qiang You,Ying Zhu, Bushra Alam, Benjamin J. Albrecht, Abdulrahman Aldossary, Ethan Alguire,Josefine H. Andersen, Vishikh Athavale, Dennis Barton, Khadiza Begam, Andrew Behn,Nicole Bellonzi, Yves A. Bernard, Eric J. Berquist, Hugh G. A. Burton, Abel Carreras, KevinCarter-Fenk, Romit Chakraborty, Alan D. Chien, Kristina D. Closser, Vale Cofer-Shabica,Saswata Dasgupta, Marc de Wergifosse, Jia Deng, Michael Diedenhofen, Hainam Do, Sebas-tian Ehlert, Po-Tung Fang, Shervin Fatehi, Qingguo Feng, Triet Friedhoff, James Gayvert,Qinghui Ge, Gergely Gidofalvi, Matthew Goldey, Joe Gomes, Cristina E. Gonzlez-Espinoza,Sahil Gulania, Anastasia O. Gunina, Magnus W. D. Hanson-Heine, Phillip H. P. Harbach,Andreas Hauser, Michael F. Herbst, Mario Hernndez Vera, Manuel Hodecker, Zachary C.Holden, Shannon Houck, Xunkun Huang, Kerwin Hui, Bang C. Huynh, Maxim Ivanov, dmJsz, Hyunjun Ji, Hanjie Jiang, Benjamin Kaduk, Sven Khler, Kirill Khistyaev, JaehoonKim, Gergely Kis, Phil Klunzinger, Zsuzsanna Koczor-Benda, Joong Hoon Koh, DimitriKosenkov, Laura Koulias, Tim Kowalczyk, Caroline M. Krauter, Karl Kue, Alexander Ku-nitsa, Thomas Kus, Istvn Ladjnszki, Arie Landau, Keith V. Lawler, Daniel Lefrancois,Susi Lehtola, Run R. Li, Yi-Pei Li, Jiashu Liang, Marcus Liebenthal, Hung-Hsuan Lin,You-Sheng Lin, Fenglai Liu, Kuan-Yu Liu, Matthias Loipersberger, Arne Luenser, AadityaManjanath, Prashant Manohar, Erum Mansoor, Sam F. Manzer, Shan-Ping Mao, Aleksandr V.Marenich, Thomas Markovich, Stephen Mason, Simon A. Maurer, Peter F. McLaughlin,Maximilian F. S. J. Menger, Jan-Michael Mewes, Stefanie A. Mewes, Pierpaolo Morgante,J. Wayne Mullinax, Katherine J. Oosterbaan, Garrette Paran, Alexander C. Paul, SuranjanK. Paul, Fabijan Pavoevic, Zheng Pei, Stefan Prager, Emil I. Proynov, dm Rk, Eloy Ramos-Cordoba, Bhaskar Rana, Alan E. Rask, Adam Rettig, Ryan M. Richard, Fazle Rob,Elliot Rossomme, Tarek Scheele, Maximilian Scheurer, Matthias Schneider, Nickolai Ser-gueev, Shaama M. Sharada, Wojciech Skomorowski, David W. Small, Christopher J. Stein,Yu-Chuan Su, Eric J. Sundstrom, Zhen Tao, Jonathan Thirman, Gbor J. Tornai, TakashiTsuchimochi, Norm M. Tubman, Srimukh Prasad Veccham, Oleg Vydrov, Jan Wenzel, JonWitte, Atsushi Yamada, Kun Yao, Sina Yeganeh, Shane R. Yost, Alexander Zech, Igor YingZhang, Xing Zhang, Yu Zhang, Dmitry Zuev, Aln Aspuru-Guzik, Alexis T. Bell, NicholasA. Besley, Ksenia B. Bravaya, Bernard R. Brooks, David Casanova, Jeng-Da Chai, SoniaCoriani, Christopher J. Cramer, Gyrgy Cserey, A. Eugene DePrince, Robert A. DiSta-sio, Andreas Dreuw, Barry D. Dunietz, Thomas R. Furlani, William A. Goddard, SharonHammes-Schiffer, Teresa Head-Gordon, Warren J. Hehre, Chao-Ping Hsu, Thomas-C. Jagau,Yousung Jung, Andreas Klamt, Jing Kong, Daniel S. Lambrecht, WanZhen Liang, Nicholas J.Mayhall, C. William McCurdy, Jeffrey B. Neaton, Christian Ochsenfeld, John A. Parkhill,Roberto Peverati, Vitaly A. Rassolov, Yihan Shao, Lyudmila V. Slipchenko, Tim Stauch,Ryan P. Steele, Joseph E. Subotnik, Alex J. W. Thom, Alexandre Tkatchenko, Donald G.Truhlar, Troy Van Voorhis, Tomasz A. Wesolowski, K. Birgitta Whaley, H. Lee Woodcock,Paul M. Zimmerman, Shirin Faraji, Peter M. W. Gill, Martin Head-Gordon, John M. Herbert,and Anna I. Krylov. Software for the Frontiers of Quantum Chemistry: An Overview ofDevelopments in the Q-Chem 5 Package. In: The Journal of Chemical Physics 155 (8 2021),p. 084801. URL: James Bergstra, Rmi Bardenet, Yoshua Bengio, and Balzs Kgl. Algorithms for Hyper-Parameter Optimization. In: Advances in Neural Information Processing Systems. Ed. byJ. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K.Q. Weinberger. Vol. 24. CurranAssociates, Inc., 2011. URL: Dejun Jiang, Zhenxing Wu, Chang-Yu Hsieh, Guangyong Chen, Ben Liao, Zhe Wang, ChaoShen, Dongsheng Cao, Jian Wu, and Tingjun Hou. Could graph neural networks learnbetter molecular representation for drug discovery? A comparison study of descriptor-basedand graph-based models. In: Journal of Cheminformatics 13.1 (2021), pp. 123. URL: Kevin E. Riley, James A. Platts, Jan Rezc, Pavel Hobza, and J. Grant Hill. Assessment ofthe Performance of MP2 and MP2 Variants for the Treatment of Noncovalent Interactions.In: The Journal of Physical Chemistry A 116.16 (2012), pp. 41594169. DOI: 10.1021/jp211997b. URL:",
  "Lili Zhao, Moritz von Hopffgarten, Diego M. Andrada, and Gernot Frenking. Energydecomposition analysis. In: WIREs Computational Molecular Science 8.3 (2018), e1345.URL:": "Albert Reuther, Jeremy Kepner, Chansup Byun, Siddharth Samsi, William Arcand, DavidBestor, Bill Bergeron, Vijay Gadepally, Michael Houle, Matthew Hubbell, Michael Jones,Anna Klein, Lauren Milechin, Julia Mullen, Andrew Prout, Antonio Rosa, Charles Yee, andPeter Michaleas. Interactive Supercomputing on 40,000 Cores for Machine Learning andData Analysis. In: 2018 IEEE High Performance extreme Computing Conference (HPEC).2018, pp. 16. URL: F. Zahariev and M. S. Gordon. Combined quantum Monte Carlo effective fragmentmolecular orbital method: fragmentation across covalent bonds. In: Physical ChemistryChemical Physics 23 (26 2021), pp. 1430814314. URL:",
  "Daniel Herschlag and Margaux M. Pinney. Hydrogen Bonds: Simple after All? In: Bio-chemistry 57.24 (2018), pp. 33383352. URL:": "Xin Liu, Yuxiang Zhang, Meng Wu, Mingyu Yan, Kun He, Wei Yan, Shirui Pan, XiaochunYe, and Dongrui Fan. Revisiting Edge Perturbation for Graph Neural Network in GraphData Augmentation and Attack. In: arXiv (2024), p. 2403.07943. URL: Anjan Chowdhury, Sriram Srinivasan, Animesh Mukherjee, Sanjukta Bhowmick, and Kun-tal Ghosh. Improving Node Classification Accuracy of GNN through Input and OutputIntervention. In: ACM Transactions on Knowledge Discovery from Data 18.1 (2023). URL:",
  "Alessandro Rognoni, Riccardo Conte, and Michele Ceotto. How many water moleculesare needed to solvate one? In: Chemical Science 12 (6 2021), pp. 20602064. URL:": "Hongfei Wu, Lijun Wu, Guoqing Liu, Zhirong Liu, Bin Shao, and Zun Wang. SE3Set:Harnessing equivariant hypergraph neural networks for molecular representation learning.In: arXiv preprint arXiv:2405.16511 (2024). URL: Ilyes Batatia, Dvid Pter Kovcs, Gregor N. C. Simm, Christoph Ortner, and Gbor Csnyi.MACE: Higher Order Equivariant Message Passing Neural Networks for Fast and AccurateForce Fields. In: Advances in Neural Information Processing Systems. Ed. by S. Koyejo,S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh. Vol. 35. Curran Associates,Inc., 2022, pp. 1142311436. URL: Zaixi Zhang, Qi Liu, Hao Wang, Chengqiang Lu, and Chee-Kong Lee. Motif-basedGraph Self-Supervised Learning for Molecular Property Prediction. In: Advances in Neu-ral Information Processing Systems. Ed. by M. Ranzato, A. Beygelzimer, Y. Dauphin,P.S. Liang, and J. Wortman Vaughan. Vol. 34. Curran Associates, Inc., 2021, pp. 1587015882. URL: Mesfin Diro Chaka, Chernet Amente Geffe, Alex Rodriguez, Nicola Seriani, Qin Wu, andYedilfana Setarge Mekonnen. High-Throughput Screening of Promising Redox-ActiveMolecules with MolGAT. In: ACS Omega 8.27 (2023), pp. 2426824278. URL: Mengyao Yu, Yundian Zeng, Mingyang Wang, Chenqing Hua, Sunliang Cui, Peichen Pan,Chang-Yu Hsieh, Tingjun Hou, Odin Zhang, Yufei Huang, Shicheng Chen, Xujun Zhang,Haitao Lin, Zhenxing Wu, Huifeng Zhao, Zaixi Zhang, and Yu Kang. FragGen: Towards 3DGeometry Reliable Fragment-based Molecular Generation. In: Chemical Science (2024),pp. -. URL: Gihan Panapitiya, Peiyuan Gao, C. Mark Maupin, and Emily G. Saldanha. FragNet: A GraphNeural Network for Molecular Property Prediction with Four Layers of Interpretability. In:arXiv (2024), p. 2410.12156. URL: Kha-Dinh Luong and Ambuj K Singh. Fragment-based Pretraining and Finetuning onMolecular Graphs. In: Advances in Neural Information Processing Systems. Ed. by A. Oh,T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine. Vol. 36. Curran Associates,Inc., 2023, pp. 1758417601. URL:",
  "Guy Bar-Shalom, Beatrice Bevilacqua, and Haggai Maron. Subgraphormer: Unifying Sub-graph GNNs and Graph Transformers via Graph Products. In: arXiv (2024), p. 2402.08450.URL:": "Zuoyu Yan, Junru Zhou, Liangcai Gao, Zhi Tang, and Muhan Zhang. An Efficient Sub-graph GNN with Provable Substructure Counting Power. In: Proceedings of the 30th ACMSIGKDD Conference on Knowledge Discovery and Data Mining. KDD 24. Associationfor Computing Machinery, 2024, pp. 37023713. URL: Joseph P. Heindel, Kristina M. Herman, and Sotiris S. Xantheas. Many-Body Effects inAqueous Systems: Synergies Between Interaction Analysis Techniques and Force FieldDevelopment. In: Annual Review of Physical Chemistry 74 (2023), pp. 337360. URL:",
  "Algorithm 1: MXMNet-MBEInput: Molecule data, including atom types, geometries (3D coordinates), and energies (1B, 2B,3B) derived from MBE": "Output: Predicted 2B and 3B energiesStep 1: Initialize embeddings and compute geometric featuresh initialize_node_embeddings(x)(edge_indexg, distg) radius(pos, cutoffg)(edge_indexl, distl) remove_self_loops(edge_index)idx_angles compute_angle_indices(edge_indexl)Step 2: Encode geometric informationrbfg BesselBasis(distg)rbfl BesselBasis(distl)angle1 compute_angles(pos, idx_angles.two_hop)angle2 compute_angles(pos, idx_angles.one_hop)sbf1 SphericalBasis(distl, angle1)sbf2 SphericalBasis(distl, angle2)Step 3: Message passing layersnode_sum 0for l 1 to n_layers do Global message passingh GlobalMP(h, rbfg, edge_indexg)Local message passing(h, t) LocalMP(h, rbfl, sbf1, sbf2, idx_angles)node_sum node_sum + tendStep 4: Global pooling and prediction output global_add_pool(node_sum, batch)return output",
  "Algorithm 2: PAMNet-MBEInput: Molecule data, including atom types, geometries (3D coordinates), and energies (1B, 2B,3B) derived from MBE": "Output: Predicted 2B and 3B energiesStep 1: Initialize embeddings and compute geometric featuresh initialize_node_embeddings(x)(edge_indexg, distg) radius(pos, cutoffg)(edge_indexl, distl) remove_self_loops(edge_index)idx_angles compute_angle_indices(edge_indexl)Step 2: Encode geometric informationrbfg BesselBasis(distg)rbfl BesselBasis(distl)angle1 compute_angles(pos, idx_angles.two_hop)angle2 compute_angles(pos, idx_angles.one_hop)sbf1 SphericalBasis(distl, angle1)sbf2 SphericalBasis(distl, angle2)Step 3: Message passing with attentionout_global [], out_local []att_global [], att_local []for l 1 to n_layers do Global message passing(h, outg, attg) GlobalMP(h, rbfg, edge_indexg)Append outg to out_globalAppend attg to att_globalLocal message passing(h, outl, attl) LocalMP(h, rbfl, sbf2, sbf1, idx_angles)Append outl to out_localAppend attl to att_localendStep 4: Feature fusion with attentionatt_scores concat(att_global, att_local)att_weights softmax(LeakyReLU(att_scores))out concat(out_global, out_local)out (out att_weights).sum()Step 5: Final pooling and predictionoutput global_pool(out, batch)return output",
  "A.2Fragmentation Strategies": "At the current development stage of FBGNN-MBE, the fragmentation strategy was determinedcase-by-case and depended on the chemical properties the systems in question. We currently focusedon the total ground state energy of a system and will investigate the excited state energy soon. Wehave so far implemented a top-down fragmentation strategy with two principles: (1) We maintainthe smallest functionally meaningful unit. (2) We break only single bonds or non-bonding interactions. In the present proof-of-concept work we studied water aggregates, phenol aggregates, and waterphenol mixtures. In these systems every single molecule was a natural fragment and an intermolecularinteraction like hydrogen bond and van der Waals force plays an essential role in n-body energies(n 2). For our future studies about organic polymers, we have tentatively planned to extend thefragmentation strategy by treating each monomer as a fragment, cleaving the carboncarbon (C C)bonds, and considering each solvent molecule as a fragment too (if any). We will try our best not tobreak any complete functional groups like phenyl ( C6H5) and carboxylic acid ( COOH) or knownunit like an amino acid and a DNA base. For a new system, we will run a low-level first-principles MBE2 calculation where the total energy istruncated at the two-fragment interactions to make sure the fragmentation does not introduce hugeestimated error to damage the chemistry. In this way the system will maintain the smallest functional or repeating unit such as a full -conjugation, and our model can capture short-range and long-rangeinteractions to simulate the real chemical systems, such as covalent bonds, ionic bonds, hydrogenbonds, London dispersions, dipoledipole interactions, stacking, and solvation effects. If a system does not exhibit natural or obvious fragments, such as polyacetylene and polytethlyene, wewill consider an alternative bottom-up strategy, where we will construct fragments from individualatoms, functional groups, or monomers until some convergence is reached using a low-level first-principles MBE2 calculation. In this way we will allow fragments to grow around each unit andaccommodate underlying effects from local electronic environment and molecular conformations. We foresaw great room for us to explore and validate our fragmentation strategies and enhance ourmodel versatility and accuracy. However, due to the time constraints, we were unfortunately not ableto perform a systematic discussion in the present study. We did validate our top-down fragmentationstrategy using a series of water clusters (H2O)n (n = 7, 10, 13, 16, and 21) by showing first-principlesMP2-MBE2 and MP2-MBE3 results in in Section A.5. When we treated each water moleculeas a single fragment, we reached an average of 3.00% and 0.39% relative errors for these waterclusters using MP2-MBE2 and MP2-MBE3, confirming a favorable choice of fragmentation strategy.",
  "A.3Sensitivity Analysis": "Number of LayersNlayer had a significant impact on the capacity of a GNN model in capturingchemical features and its optimal value was data set-dependent. Our analysis found thatincreasing Nlayer from 2 to 4 improved the values of R2 and MAE for MXMNet-MBE and PAMNet-MBE, indicating a better fit to the training data. However, setting Nlayer = 6 usually led to marginallydiminishing returns with a slight decrease in R2 and a slight increase in MAE, suggesting possibleoverfittings (. This result supported recent findings that while a deeper GNN architecture canenhance model performance it did not always yield better generalization particularly in molecularproperty prediction tasks due to overfittings .",
  ": Effects of Nlayer values on MXMNet-trained and PAMNet-trained values of R2 and MAEfor all benchmark systems": "Local and Global Cut-Off DistancesDlc and Dgc controled the range of interatomic, inter-molecular, and interfragment interactions considered by our FBGNN-MBE. They were sensitiveto the character of the system in question and were also crucial to the model performance. Forpure water clusters, Dlc = 1.7 and Dgc = 5.0 provided optimal results for 3B interactions.These values confirmed that the short-range oxygenhydrogen bond (O H, length 0.96 )and hydrogen bonds (O H O, length 2.5 to 4.0 ) dominate the water clusters. For example, MXMNet-MBE reached R2 = 0.9400 and MAE = 0.2604 kcal/mol. For pure phenolclusters, these two values became 3 to 5 and 15 to effectively capture the long-range van derWaals interactions. For water-phenol mixtures, intermediate cutoff values balanced the short-rangeand long-range interactions. This result suggested that for a system with medium interfragmentinteractions like hydrogen bonds, capturing moderate-range interactions provided the best balancebetween incorporating essential chemical information that can be missed by a smaller cut-off distanceand avoiding overfitting due to a larger cut-off distance . Number of BatchesNbatch emerged as a key factor affecting the model performance. Smallervalues of Nbatch like 64 consistently resulted in lower MAE values for both MXMNet-MBE andPAMNet-MBE. This result suggested that smaller batches facilitated more frequent weight updatesand allowed the GNN models to fine-tune their parameters more effectively. In contrast, larger valuesof Nbatch like 256 or 512 were associated with higher MAE values, likely due to less frequent updatesand convergence to suboptimal solutions . Learning Rateklearn also impacted the model performance. A low value of klearn like 0.0001consistently outperformed higher ones for both MXMNet-MBE and PAMNet-MBE. For example,for the pure water data set, increasing klearn to 0.01 for PAMNet-MBE led to a sharp decline inperformance, with R2 dropping to as low as 0.5981 and a notable increase in MAE to up to 0.9468kcal/mol. This result confirmed the earlier finding that selecting an appropriate klearn can ensurestable and effective convergence during training .",
  "Real-Life SystemsThe ultimate goal of our development of FBGNN-MBE formalisms is to replaceQM or QM-MBE methods when an on-the-fly evaluation of FD-PBE is needed for any complex": "many-fragment chemical systems. Therefore, it is also worthwhile to validate their capacity in thereal-life application scenarios through a systematic assessment of their accuracy, efficiency, andreliability. In the present study in progress, we plan to evaluate the behaviors of MXMNet-MBE andPAMNet-MBE on normal-density water clusters in reproducing three physical properties that canalso be generated using MP2 and MP2-PBE, including the total energies of water clusters [(H2O)n],the one-dimensional (1D) projection of the FD-PES, and the trajectories of MD simulations. Thesetasks require us to retrain the MXMNet-MBE and PAMNet-MBE using a mixed data set of normaland 2 density clusters. We will select a series of sizes [(H2O)n] where the size grows from a smallisolated molecular complex (n = 7) to an actual droplet that solvates the central molecule equally toone in the liquid phase (n = 21) . In our preliminary study, we select random water complexes with n = 7, 10, 13, 16, and 21 moleculesand validate the need of performing MBE even at the MP2 level. Here MP2-MBEm represents aMP2-based first-principles MBE truncated at the m-body terms, and MXMNet-MBEm and PAMNet-MBEm represents FGBNN-based MBE truncated at the m-body terms as discussed in the presentstudy. We summarized the absolute and relative errors for MP2-MBEm (m = 1, 2, 3) using thesefive random clusters (), and estimated the upper limits for absolute and relative errors forMXMNet-MBEm and PAMNet-MBEm (m = 2, 3) by adding the errors of MP2-MBEm from to the MAEs of FBGNN-MBE-generated 2B and/or 3B calculations accumulated from (). We extracted the total CPU times needed for first-principles MP2 (without MBE) usingthese clusters (), and estimated the total CPU/GPU times needed for MXMNet-MBEm andPAMNet-MBEm (m = 2, 3) by adding the accumulated times needed for 1B calculations and theFBGNN-MBE-based 2B and 3B generations.",
  "(H2O)71562.949.129.05(H2O)1018914.9318.2417.94(H2O)13128084.3935.7334.43(H2O)1651249.3862.8959.69(H2O)21121046.76135.07125.79": "From these results, we can see that the truncation at the 1B terms for water clusters introduce hugerelative errors up to 0.025%. (This number appears small but is still too high for a chemical accuracy.) Inclusion of the 2B and 3B terms significantly enhance the results by reducing the relative errors to upto 0.0056% and 0.0011%, respectively, because an intermolecular interaction, even as weak as van derWaals force or hydrogen bond, play essential roles in chemical properties. This conclusion validatesthe necessity of applying MBE theory beyond the 1B terms and suggests a truncation at 3B terms orhigher. Due to the differences between MP2-MBE and FBGNN-MBE for these water clusters, theestimated maximum errors of FBGNN-MBE are larger than MP2-MBE but still acceptable, all below0.011%. In addition, our FBGNN-MBE calculations can reduce the computational cost by at leastthree orders of magnitude for water clusters compared to single-shot MP2 calculations for the wholeclusters. These two pieces of findings, although made based on estimated errors and computationalcosts, tentatively validates the efficiency and accuracy of FBGNN-MBE methods. Planned Comparison with Other Conventional GNN ModelsIn the near future, we will make amore complete assessment of the model performance of FBGNN-MBE by comparing with latest ad-vanced fragment-based NN or GNN models designed for molecular properties, such as SE3Set ,MACE , MGSSL , MolGAT , FragGen , FragNet , GraphFP , Sub-graphormer , and ESC-GNN . Utility in Molecular DynamicsIn the present set up, we approximated the first-principles FD-PESs, or in other words, geometry-dependent electronic energies under the BornOppenheimerapproximation at T = 0 K, using FBGNN-MBE-generated counterparts. We can evaluate all relevantforces as the gradients of these potential energies . In this way, we expected to replace afirst-principles FD-PES with a FBGNN-MBE-generated FD-PES in ab initio molecular dynamics(AIMD). Because of this equivalent substitution, the obedience or violations to some underlyingrules for FGBNN-MBE-generated forces, such as energy conservation, will depend on the overallset up of the AIMD simulation. If the AIMD simulation is set up at constant NV E (microcanonicalensemble), the energy will be conserved. However, if AIMD simulation is set up at constant NV T(canonical ensemble) or V T (grand canonical ensemble), the temperature remains a constantthrough a computational thermostat but the energy will no longer be conserved."
}