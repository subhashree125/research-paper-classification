{
  "Abstract": "Bumblebee is a foundation model for particle physics discovery, inspired by BERT.By removing positional encodings and embedding particle 4-vectors, Bumble-bee captures both generator- and reconstruction-level information while ensuringsequence-order invariance. Pre-trained on a masked task, it improves dileptonictop quark reconstruction resolution by 10-20% and excels in downstream tasks,including toponium discrimination (AUROC 0.877) and initial state classification(AUROC 0.625). The flexibility of Bumblebee makes it suitable for a wide rangeof particle physics applications, especially the discovery of new particles.",
  "Introduction": "The intersection of machine learning (ML) and particle physics offers immense potential to improveour understanding of fundamental particles and their interactions (4). Foundation models likeBERT (19) excel in capturing complex relationships and achieving state-of-the-art results, but theirinherent sequence sensitivity presents challenges in particle physics, where events, represented byparticle 4-vectors, are naturally invariant to order. Additionally, developing an effective pre-trainingobjective that aids in particle discovery remains nontrivial. We propose Bumblebee, a foundation model inspired by BERT but tailored for particle physics. Byremoving positional encoding, we ensure sequence-order invariance and modify the embedding tocapture particle 4-vectors instead of words, allowing Bumblebee to learn both generator-level (truth)and reconstruction-level (observed) information. Our pre-training objective, akin to BERTs Clozetask (37), trains Bumblebee to learn the kinematics within the event topology and the transformationbetween the generator and reconstruction levels. This intricate knowledge of the interactions and",
  "event topology required to predict any decay product four momenta enables Bumblebee to performstate-of-the-art regression and classification tasks": "Bumblebee significantly outperforms state-of-the-art methods in dileptonic top quark reconstruction,a challenging task due to the presence of two neutrinos, which only manifest as missing transverseenergy (MET) in Large Hadron Collider (LHC) detectors. Moreover, the pre-trained model can befine-tuned to search for a potential top quark-antiquark (tt) bound state (toponium) and to enhancethe degree of quantum entanglement in pair-produced top quarks at the LHC (1). This opens newpathways for precision measurements in quantum information science at the highest energies yetachieved.",
  "Related Work": "Foundation models have been successfully created for data domains such as images (32, 35, 26),text (19, 10, 42), and speech (38, 36). So far, applications of foundation models in particle physicshave focused on the reconstruction of particle objects\" such as jets (25, 9) and tracks (27) andfine-tuning for downstream tasks. Beyond foundation models, the transformer architecture hasbeen successful in particle physics from generating events (21, 11) to achieving state-of-the-artperformance in the jet-parton assignment problem (39). This strongly motivates building a foundationmodel with the transformer architecture for particle physics discovery.",
  "Bumblebee": "The Bumblebee model is a transformer-based model (43) designed for particle physics. Similar toBERT (19) and other foundation models, our framework consists of a pre-training and fine-tuningstep. We will be using the event topology of the dileptonic tt as a case study. Dileptonic tt meansthat we have a lepton (antilepton), a b antiquark (quark), and an antineutrino (neutrino) in the finalstate for each top antiquark (quark).",
  "Model architecture": "Bumblebee is a multilayer bidirectional transformer encoder based on the original implementationdetailed in Ref. (43). Unlike traditional transformer encoders, which rely on positional encodingsto handle sequence order, Bumblebee eliminates positional encodings to ensure that they remaininvariant to the order in which particles are processed. This architectural decision reflects the physicalreality that particles in an event are not ordered in any meaningful way, and thus preserving thispermutation invariance is critical for accurately modeling particle physics collisions. We use L to denote the number of layers, the hidden size as dmodel, and the number of heads ofself-attention as A. Specifically, the Bumblebee model as reported here is (L=8, dmodel=768, A=16,Total Parameters=57M).",
  "Input representation": "Bumblebee takes as input the 4-vectors of particles at both the generator and reconstruction levels,allowing it to learn correlations between partonic truth and reconstructed observables, improvingdownstream prediction quality. Each 4-vector consists of the transverse momentum pT, pseudora-pidity , azimuthal angle , and mass m of the particle. Due to color confinement, generator-levelquarks form jets (31). Bumblebee receives b-tag scores to indicate the likelihood of a jet originatingfrom a b quark. Non-jet particles and generator-level b quarks are assigned b-tag scores of 0 and 1,respectively. Neutrinos manifest as MET because of the conservation of momentum, with assignedpseudorapidity and mass of zero, because their z-momentum and energy are unmeasured. Thesefive-dimensional vectors are linearly embedded in the dmodel-dimensional space. Additionally, Bumblebee uses three learned embedding tables:(1) to differentiate betweenreconstruction-level (isReco) and generator-level (isNotReco) particles, (2) to distinguish par-ticle types using a modified PDG ID scheme where b-tagged jets are assigned a PDG ID of 5, nonb-tagged jets 41, and MET 40, with all IDs shifted by +50 to map to positive indices, and (3) toindicate whether particles are masked (isMasked) or not (isNotMasked). This masking is essential",
  "Pre-training Bumblebee": "We pre-train Bumblebee using the Cloze task (37), where particles are randomly masked with a(1/nparticles)% probability for half of the training. The other half involves masking all 4-vectors atthe generator or reconstruction level. Only the particle vector embedding is masked in both scenarios,shown as 0 in . The model minimizes the batch-average mean squared error (MSE) on thepredicted masked 4-vectors. Validation and testing of Bumblebee focus on predicting generator-level 4-vectors from reconstruction-level information, framed as dileptonic top quark reconstruction.During pre-training, we use a linearly decaying learning schedule with a warm-up of 9,000 iterations,peaking at a learning rate of 104. The Adam optimizer (29) is used with 1 = 0.9, 2 = 0.999,and weight decay for regularization. Epsilon, dropout, batch size and weight decay are set to 108,0.05, 16, and 103, respectively. Training is carried out on 2 V100 GPUs for 10 epochs, and themodel with the lowest validation loss is used for test predictions.",
  "Fine-tuning": "After pre-training Bumblebee on the tt system, we fine-tune the model for downstream tasks. Forclassification, a masked vector (1, 0, 0, 0, 0) is added for signal and (0, 0, 0, 0, 0) for background, witha PDG ID\" of 50, using the reconstruction-level (isReco) and masked (isMasked) embeddings.Generator-level information is omitted during fine-tuning, and the model is trained to predict thisvector, similar to the CLS token in BERT. To avoid catastrophic forgetting (33), the learning rate isreduced by an order of magnitude. Hyperparameters such as weight decay, dropout, batch size, and are optimized during this phase and trained for 4 epochs.",
  "Datasets": "To test the performance of Bumblebee, we generate a 7M tt Monte Carlo sample at next-to-leadingorder using POWHEGV2 (23, 22, 34, 5). Additionally, we use a toy model (24) to generate a 1MMonte Carlo sample of the ground state, t, of the tt bound state toponium at leading order withMADGRAPH5_AMC@NLO (6). Both processes perform parton showering and hadronization withPYTHIA (40). Detector simulation is performed with DELPHES (18) using the default card for the",
  "We conducted several experiments to evaluate the ability of Bumblebee to learn foundational ttphysics and fine-tune on downstream tasks": "Dileptonic top quark reconstructionOur pre-training task doubles as a dileptonic top quarkreconstruction challenge. The reconstructed top quark is the sum of predicted generator-leveldaughter four-vectors. A 10-20% improvement in the resolution of the tt systems invariant mass(m(tt)) is achieved compared to a supervised transformer, as shown in C. The improved m(tt)reconstruction resolution at high invariant mass is of great importance for heavy resonance searchesof physics beyond the Standard Model (14). Toponium discriminationWe benchmark the ability of Bumblebee to discover new particles usingthe ground state of toponium (t), a hypothetical particle predicted by the Standard Model (24, 30,28, 41, 20). Due to the low resolution in m(tt) relative to ts width (3 GeV) (3), observation of tis challenging and an appropriate benchmark for Bumblebee. We fine-tune Bumblebee on weightedbinary cross-entropy. With early stopping and a class imbalance of 10:1, the model achieves an AUCof 0.877, as seen in A. Initial state classificationTop quark pairs at the LHC originate from gluon-gluon or quark-antiquark interactions with a rich dependence on this origination (1, 15). Initial-state discriminationenhances the search for new physics (2). Bumblebee achieves a 0.625 AUC in this task, marking thefirst attempt at initial-state classification and outperforming supervised machine learning models, asshown in B.",
  "Limitations": "The primary limitation of this work is its focus on the dileptonic decays of top quark pairs at the LHC,driven by the computational cost of generating Monte Carlo for each process. Although photons areabsent in dileptonic decays, there is nothing in our embedding procedure that inherently restrictsBumblebee from handling photons at the reconstruction or generator level. Another limitationis the event topology: in dileptonic decays, the main challenge is not jet-parton assignment butreconstructing the missing neutrino 3-vectors from MET. More complex topologies, such as ttH (12,7) and tttt (16, 8), feature numerous jets and multiple neutrinos, offering further avenues forexploration.",
  "Ablation study": "We present an ablation study where we remove embeddings in the input representation and measurethe performance regarding the MSE loss on the validation set. In , it is clear that the mostimportant embedding is the PDG ID embedding as this results in the largest increase of MSE loss.This is expected as this defines the event topology at the generator and reconstruction levels. The nextmost important embedding is the level type embedding which is obvious when considering scenarioswhere a particle is masked both at the reconstruction and generator level.",
  "Conclusion": "The Bumblebee model has demonstrated its ability to outperform state-of-the-art methods in dileptonictop quark reconstruction, while also generalizing this knowledge to various downstream tasks. Itsflexibility may extend beyond the tt process, as any particle with kinematics can be embedded, makingit highly versatile for a wide range of applications. Although we focused on specific discriminationand pre-training tasks, Bumblebee can be fine-tuned for other uses. With its strong performance andadaptability, Bumblebee shows evidence of being a possible path to constructing foundation modelsapplicable to many particle physics processes. 0.20.40.60.81.0 Toponium FPR 0.0 0.2 0.4 0.6 0.8 1.0 Toponium TPR",
  "C": "DNNTransformerBumblebee Gen mtt (GeV) 0.5 1.0 AllDNN :A) The receiver operating characteristic (ROC) curve for Bumblebee fine-tuned ondiscriminating toponium against tt. Two supervised models, DNN and Transformer, are shown forcomparison. B) The ROC curve for Bumblebee fine-tuned on discriminating the initial state of tt.The positive class is the gluon-gluon initial state. Two supervised models, DNN and Transformer, areshown for comparison. C) The resolution of m(tt) given as the difference between the 16th and 84thpercentiles of the m(tt) residuals (P84 P16) as a function of the true m(tt). MSE Loss",
  "and Disclosure of Funding": "This material is based upon work supported by the U.S. Department of Energy program under AwardNumber(s) DE-SC00023700 and AI for a more precise future of the top quark. The authors declareno competing interests. AW thanks M.W. Kerrigan for insightful discussions regarding foundationmodels and A. Anuar for providing help in producing t Monte Carlo.",
  "J. A. Aguilar-Saavedra. Toponium hunters guide, 2024": "K. Albertsson, P. Altoe, D. Anderson, J. Anderson, M. Andrews, J. P. A. Espinosa, A. Aurisano,L. Basara, A. Bevan, W. Bhimji, D. Bonacorsi, B. Burkle, P. Calafiura, M. Campanelli, L. Capps,F. Carminati, S. Carrazza, Y. fan Chen, T. Childers, Y. Coadou, E. Coniavitis, K. Cranmer,C. David, D. Davis, A. D. Simone, J. Duarte, M. Erdmann, J. Eschle, A. Farbin, M. Feickert, N. F.Castro, C. Fitzpatrick, M. Floris, A. Forti, J. Garra-Tico, J. Gemmler, M. Girone, P. Glaysher,S. Gleyzer, V. Gligorov, T. Golling, J. Graw, L. Gray, D. Greenwood, T. Hacker, J. Harvey,B. Hegner, L. Heinrich, U. Heintz, B. Hooberman, J. Junggeburth, M. Kagan, M. Kane, K. Kan-ishchev, P. Karpinski, Z. Kassabov, G. Kaul, D. Kcira, T. Keck, A. Klimentov, J. Kowalkowski,L. Kreczko, A. Kurepin, R. Kutschke, V. Kuznetsov, N. Khler, I. Lakomov, K. Lannon, M. Lass-nig, A. Limosani, G. Louppe, A. Mangu, P. Mato, N. Meenakshi, H. Meinhard, D. Menasce,L. Moneta, S. Moortgat, M. Neubauer, H. Newman, S. Otten, H. Pabst, M. Paganini, M. Paulini,G. Perdue, U. Perez, A. Picazio, J. Pivarski, H. Prosper, F. Psihas, A. Radovic, R. Reece,A. Rinkevicius, E. Rodrigues, J. Rorie, D. Rousseau, A. Sauers, S. Schramm, A. Schwartzman,H. Severini, P. Seyfert, F. Siroky, K. Skazytkin, M. Sokoloff, G. Stewart, B. Stienen, I. Stockdale,G. Strong, W. Sun, S. Thais, K. Tomko, E. Upfal, E. Usai, A. Ustyuzhanin, M. Vala, J. Vasel,S. Vallecorsa, M. Verzetti, X. Vilass-Cardona, J.-R. Vlimant, I. Vukotic, S.-J. Wang, G. Watts,M. Williams, W. Wu, S. Wunsch, K. Yang, and O. Zapata. Machine learning in high energyphysics community white paper, 2019.",
  "J. Alwall, M. Herquet, F. Maltoni, O. Mattelaer, and T. Stelzer. Madgraph 5: going beyond.Journal of High Energy Physics, 2011(6), 2011. doi: 10.1007/jhep06(2011)128": "ATLAS Collaboration. Observation of higgs boson production in association with a top quarkpair at the lhc with the atlas detector. Physics Letters B, 784:173, 2018. doi: 10.1016/j.physletb.2018.07.035. ATLAS Collaboration. Observation of four-top-quark production in the multilepton final statewith the atlas detector. The European Physical Journal C, 83(6), 2023. doi: 10.1140/epjc/s10052-023-11573-0.",
  "J. Birk, A. Hallin, and G. Kasieczka. Omnijet-: The first cross-task foundation model forparticle physics, 2024": "T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child,A. Ramesh, D. M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray,B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei.Language models are few-shot learners, 2020.",
  "P. Nason. A new method for combining NLO QCD with shower Monte Carlo algorithms. JHEP,11:040, 2004. doi: 10.1088/1126-6708/2004/11/040": "M. Oquab, T. Darcet, T. Moutakanni, H. Vo, M. Szafraniec, V. Khalidov, P. Fernandez, D. Haziza,F. Massa, A. El-Nouby, M. Assran, N. Ballas, W. Galuba, R. Howes, P.-Y. Huang, S.-W. Li,I. Misra, M. Rabbat, V. Sharma, G. Synnaeve, H. Xu, H. Jegou, J. Mairal, P. Labatut, A. Joulin,and P. Bojanowski. Dinov2: Learning robust visual features without supervision, 2024.",
  "S. Schneider, A. Baevski, R. Collobert, and M. Auli. wav2vec: Unsupervised pre-training forspeech recognition, 2019": "A. Shmakov, M. J. Fenton, T.-W. Ho, S.-C. Hsu, D. Whiteson, and P. Baldi. Spanet: Generalizedpermutationless set assignment for particle physics using symmetry preserving attention. SciPostPhysics, 12(5), 2022. doi: 10.21468/scipostphys.12.5.178. T. Sjstrand, S. Ask, J. R. Christiansen, R. Corke, N. Desai, P. Ilten, S. Mrenna, S. Prestel, C. O.Rasmussen, and P. Z. Skands. An introduction to pythia 8.2. Computer Physics Communications,191:159, 2015. doi: 10.1016/j.cpc.2015.01.024."
}