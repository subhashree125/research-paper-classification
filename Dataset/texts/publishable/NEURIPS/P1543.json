{
  "Abstract": "The adoption of increasingly complex deep models has fueled an urgent need for insight intohow these models make predictions. Counterfactual explanations form a powerful tool forproviding actionable explanations to practitioners. Previously, counterfactual explanationmethods have been designed by traversing the latent space of generative models. Yet, theselatent spaces are usually greatly simplified, with most of the data distribution complexitycontained in the decoder rather than the latent embedding. Thus, traversing the latentspace naively without taking the nonlinear decoder into account can lead to unnaturalcounterfactual trajectories.We introduce counterfactual explanations obtained using aRiemannian metric pulled back via the decoder and the classifier under scrutiny.Thismetric encodes information about the complex geometric structure of the data and thelearned representation, enabling us to obtain robust counterfactual trajectories with highfidelity, as demonstrated by our experiments in real-world tabular datasets.Keywords: Counterfactual Explanations, Riemannian Geometry, Deep Generative Models",
  ": Optimizationinthela-tentspaceofgenerativemodels endowed with Eu-clidean metric cannot guar-antee paths stay on the datamanifold. Our Riemannianapproach produces realistictrajectories": "Counterfactual explanations are useful to gain in-sights into classifier behavior, as they can be seenas answering the question how should I transformmy input data to, as efficiently as possible, changethe prediction of the classifier while retaining itsidentity features?.In situations where machinelearning algorithms are used to make decisions thataffect our lives, counterfactual explanations couldbe used to give individuals feedback on how theymight most easily change themselves to alter the al-gorithms decision. Wachter et al. (2017) proposedto optimize the objective function,",
  "Pegios Feragen Hansen Arvanitidis": "Work on this project was partially funded by the Pioneer Centre for AI (DNRF grant nrP1), the DIREC project EXPLAIN-ME (9142-00001B), and the Novo Nordisk Foundationthrough the Center for Basic Machine Learning Research in Life Science (NNF20OC0062606).The funding agencies had no influence on the writing of the manuscript nor on the decisionto submit it for publication.",
  ". Riemannian latent space geometry": "A Riemannian manifold (do Carmo, 1992; Lee, 2019) is a well-defined metric space, wherewe can compute the shortest path between two points. A manifold M can be seen as asmooth d-dimensional surface embedded within a higher dimensional ambient space X, forexample RD. We assume that there exists a parametrization g : Z Rd U, where Z isthe parameter space. The columns of the Jacobian Jg(z) RDd of g() span the tangentspace TxM at a point x M, so a tangent vector can be written as v = Jg(z)v, wherev Rd are the intrinsic coordinates of the tangent vector on the associated tangent space.A positive definite matrix MX : X RDD0that changes smoothly across the ambientspace X is a Riemannian metric, and can be used to define the inner product between twotangent vectors u, vx = u, MX (x)v = u, Jg(z)MX (g(z))Jg(z)v. Note that the ma-trix MZ(z) := Jg(z)MX (g(z))Jg(z) Rdd is positive definite, and also changes smoothlyif g() is at least twice differentiable, hence, it is a Riemannian metric in the space Z.This metric MZ() captures the geometry of M, while respecting the geometry induced byMX (), and intuitively, shortest paths prefer regions where its magnitude is small.In the ambient space X, we expect the given data {xn}Nn=1 to lie near a low-dimensionalmanifold M that has an unknown geometric structure (Bengio et al., 2013). We can approx-imate the data by considering latent representations zn and learning a function x g(z).This function does not correspond to the true parametrization g() of M, yet it can approx-imate relatively well the implicit data manifold M g(Z), and hence, induce a pull-back",
  "and MZ, b) the data space with the two proposed options for the ambient metrics": "ID and MX , and c) the representation space and the linear classifier. The ambientmetric MX in X captures the geometry of the hidden representation manifold,and we pull it back in Z to get MZ, while the metric MZ captures only thegeometry of the data manifold. See for further details.",
  ". Counterfactual explanations": "Recently, different counterfactual explanation (CE) methods have been proposed (Vermaet al., 2020).Early works address key aspects of counterfactual analysis, such as spar-sity (Guidotti et al., 2018; Dandl et al., 2020), actionability (Ustun et al., 2019), diver-sity (Russell, 2019; Mothilal et al., 2020), and causality (Mahajan et al., 2019; Karimiet al., 2020b). Borisov et al. (2022) underlines two categories of CE methods: One assum-ing feature independence (Karimi et al., 2020a) and one focusing on feature dependencies,exploring data geometry (Pawelczyk et al., 2020; Downs et al., 2020). Note that CEs aredifferent from counterfactual editing whose goal is not to explain changes in classifiers pre-dictions (Melistas et al., 2024). When data lie on a manifold, attempts have been made tomaintain CEs close to the data by constructing connective graphs (Poyiadzi et al., 2020) oremploying distance measures that can identify feasible paths (Domnich and Vicente, 2024).Other approaches approximate manifold spaces with latent generative models, includingVAE- (Dhurandhar et al., 2018; Joshi et al., 2019; Antoran et al., 2020), GAN- (Singlaet al., 2019), flow- (Dombrowski et al., 2021; Duong et al., 2023), and diffusion-based meth-ods (Jeanneret et al., 2022; Weng et al., 2025; Pegios et al., 2024; Madaan and Bedathur,2023).In this work, we employ VAEs to induce a Riemannian latent space geometry,enabling the generation of realistic CEs with trajectories that remain on the data manifold.",
  "Let a dataset {xn, yn}Nn=1 in an ambient space X = RD where yn {0, 1}. Dombrowski et al": "(2023) generate CEs by applying SGD in the latent space Z = Rd of a generative model,moving through latent space taking steps with size of the form: z = z (c(g(z)), y).Yet, this risks falling off the data manifold, forcing the generative model to extrapolatebeyond its training data, resulting in unrealistic counterfactual paths (see ).",
  ". Basic pull-back metric": "The standard VAE is used for learning stochastic generative models with Gaussian decoders(Kingma and Welling, 2014). Specifically, we consider the stochastic decoder x = g(z) =(z) + (z) , with N(0, ID) and being the point-wise product. When the ambientspace X is endowed with the Euclidean metric MX (x) = I, x X, the expected pull-backmetric in the latent Z = Rd space is equal to",
  "MZ(z) = E[Jg(z)Jg(z)] = J(z)J(z) + J(z)J(z)(2)": "where : Z X and : Z R>0 are neural networks (Arvanitidis et al., 2018). We inducea meaningful geometric structure in the latent space whether the generators uncertainty iswell-calibrated, i.e, (z) 0 when z is near the training latent codes, otherwise (z) +(Hauberg, 2018). We ensure a well-calibrated uncertainty by using (z) = 1/ (z), with : Z R>0 a Radial Basis Function network (Que and Belkin, 2016) based on the latentrepresentation, satisfying the criteria above (Arvanitidis et al., 2018).Under the mild conditions on the smoothness of g() and the behavior of (), MZ(z) RDD0constitutes a Riemannian metric in Z, which captures the geometry of the datamanifold in the ambient space M X, and hence the shortest paths between points in Zrespect this geometry. Therefore, as the cost of moving off the data manifold increases withthe VAE uncertainty, the result is the corresponding shortest paths to prefer staying nearthe data manifold. Thus, the topology of the data manifold is preserved in a soft sense: Itis possible, but expensive, for shortest paths, and hence counterfactual trajectories to moveoutside the data manifold, meaning they do not do so unless necessary. This allows us togenerate CEs using RSGD w.r.t. the pull-back metric defined in Equation (2),",
  "r2,wherer = M1Z (z)zfy(z)andfy(z) = (c(E[g(z)]), y).(3)": "We normalize the Riemannian gradient r as we are interested in the update direction, and toavoid vanishing gradients near the boundary of the latent data support in Z. Note that thisRiemannian metric makes the optimization trajectory invariant under reparametrization,i.e., another latent representation that generates the same density in X will provide thesame trajectory on the data manifold. Hence, using RSGD, we encourage trajectories toalign with the geometric structure of the latent codes, staying on the data manifold.",
  "Counterfactual Explanations via Riemannian Latent Space Traversal": "and is USA native. The continuous features are age, final weight, years of education, weeklywork hours, as well as capital gain and loss which we log-transform. The input features sex,race, and age are considered immutable.Give Me Some Credit: We use the processed data by Pawelczyk et al. (2021), whichincludes 116K samples after removing missing data with D = 10 continuous features.Furthermore, we log-transform depht ratio input feature. The goal is to predict whether anindividual will face financial distress within two years (y = 1, 93% of samples). The inputfeature age is considered immutable.We normalize features in and split datasets into 75%/25% for train/test.",
  "MX (x) = Jh(x)Jh(x).(4)": "This metric represents in X the corresponding local geometry of the learned representationH. Assuming well-separated classes in H, we expect MX (x) to be small in regions of Xwhere the classes remain constant and to increase near the decision boundary. In principle,Equation (4) could used for counterfactual optimization directly in X that respects thegeometry of the learned representation. Yet, as X is typically high-dimensional, it is moreadvantageous to exploit a generative model and pull MX (x) back to the associated latentspace Z using the stochastic generator x = g(z) to get the Riemannian metric,",
  ". Experiments": "First, we show that, unlike Normalizing Flows (Dombrowski et al., 2021), our induced geom-etry softly preserves the dataset topology by heavily penalizing counterfactual trajectoriesthrough data-sparse regions. Next, we compare Euclidean SGD on VAEs latent space withour proposed Riemannian optimizers, RSGD and RSGD-C, on real-world tabular datasets.Our source code is publicly available at",
  ". Topology preservation and counterfactual trajectories": "We construct a surface in X = R3 as x = [z, 0.25 sin(z1)] + where zj U(0, 2), j = 1, 2and N(0, 0.12 I3), with a hole in the middle by removing the points in the center withradius ||z||2 < 0.2 before the mapping in R3, and assign labels y = (sign(z22.5z21)+1)0.5.We train a Normalizing Flow with a latent space of d = D = 3, a VAE with d = 2, and aclassifier with a representation space of H = 32 to pull geometry back to the latent space.The proposed metric is illustrated in (a), with a black-white-red color schemerepresenting traversal costs in the latent space, from low to high. The red area in the centerindicates the high cost of crossing the data-sparse hole, while the white-and-red boundaryhighlights the high cost of leaving the data-populated region. Figures 3(b) and 3(c) show,",
  ": Optimization paths in the latent space of Normalizing Flow": "from the viewpoint of the latent space and ambient space, respectively, that naive Euclideanlatent space traversal using standard SGD fails to respect the data manifolds topology as itis neither encoded by the classifier nor the latent space geometry, allowing counterfactualsto stray from the data distribution. In contrast, using pullback metrics from the ambientspace (RSGD) or the target of the classifier (RSGD-C) addresses this by making it costlyfor counterfactual trajectories to deviate from the data. Next, (a) displays the priordistribution of trained Normalizing Flow, which poorly represents the hole. Figures 4(b)and 4(c) show its trajectories in the latent and ambient spaces, respectively, revealing theirfailure to capture data topology resulting in paths that pass through the hole.",
  ": Adult Dataset. Distance to closest training sample as a function of gradient steps": "features, intending to predict whether an individuals income exceeds $50K/year. Give MeSome Credit (GMC) (Kaggle-Competition, 2011) includes D = 10 continuous features,aiming to predict whether an individual will face financial distress. Both datasets include asubset of features that are considered immutable, e.g., age, as altering them cannot provideactionable feedback. More information can be found in the Appendix.",
  ". Evaluation Metrics": "We follow the evaluation protocol of Pawelczyk et al. (2021), by measuring violation, i.e,how often a CE method breaches user-defined constraints (immutable features), as well asvalidity with Flip Ratio (FR), representing the success rate of CEs classified as the targetlabel, along with their confidence c(xCE). The quality of valid CEs is measured by theircloseness to the original factual input using L0, L1, L2 and L distances. To measurerealism, i.e., how close the CE is to the data manifold, we compute the local Euclideandistance of CE to the closest training data point in the ambient space denoted as LD.",
  "Average Gradient Steps": ": GMC Dataset. Evaluation of CEs as a function of confidence threshold (CT).Confidence Threshold Ratio (CRT) quantifies confidence success, i.e., the propor-tion of CEs achieving a specified CT. LD measures fidelity to the data manifold(realism), L2 the fidelity to the initial data point (closeness), and #Iter the num-ber of required gradient steps to achieve a specific confidence level.",
  ". Experimental Setup": "We train a VAE with d = 5, and a classifier with a representation space of H = 24 to pullgeometry back to the latent space, for both datasets. Implementation details can be foundin the Appendix. We evaluate different optimizers for generating CEs by traversing thelatent space of the VAE, using Equation (2), where standard SGD uses an Euclidean metricwith M1Z (z) = I, and setting = 0.1 for all methods. To standardize comparison, we fixthe number of iterations across methods. Following Pawelczyk et al. (2021), we generateCEs for correct negative predictions, resulting in 7859 samples from 9268 negatives in theAdult test set and 1220 from 1913 in the GMC test set, with the target label set to thepositive class. Joshi et al. (2019) introduce fidelity constraints to keep CEs close to theoriginal input x during optimization in the VAEs latent space, using the counterfactual loss: = BCE(c(g(z))) + g(z) x2, where BCE is binary cross entropy and regularizationparameter. However, our Riemannian optimizers, namely RSGD and RSGD-C, naturallyrespect the datas topology, eliminating the need for such constraints. To showcase this, weevaluate all optimizers both with ( = 0.1) and without ( = 0) fidelity regularization.",
  ". Results": "lists results for Adult dataset, with illustrating local Euclidean distance LDacross gradient steps. Both RSGD and RSGD-C maintain counterfactuals close to the datamanifold (LD) and the original input (L0, L1, L2, L) without requiring fidelity constraintsduring optimization. After 100 iterations, our optimizers generate CEs closer to the originalinput compared to SGD with fidelity constraints and 50 steps while maintaining comparablevalidity and fewer violations of immutable features. As expected our Riemannian approachrequires more gradient steps to achieve high-confidence CEs. To compare optimizers acrossvarying confidence thresholds (CTs), we assess the proportion of CEs successfully generatedat each threshold, measured by the Confidence Threshold Ratio (CTR), by selecting thefirst CE reaching a CT from the counterfactual trajectories. illustrates the averagerequired gradient steps, as well as the fidelity to both the data manifold and the originalinput, where our approach demonstrates improved fidelity across different confidence levels.",
  ". Discussion": "We generate CEs via Riemannian latent space traversal by employing the Riemannian metricinduced by the stochastic generator of a deep generative model. Using RSGD we performCE optimization in the latent space of a VAE, where the metric acts as a preconditionerthat keeps the trajectory near the latent data manifold. In addition, we explore a classifier-guided enhanced latent space Riemannian metric, which pulls back the Riemannian metricfrom the ambient space and captures the geometry of the learned hidden representationmanifold induced by the classifier under observation, yielding our RSGD-C optimizer.Different from SGD in the latent space of a Normalizing Flow (Dombrowski et al., 2021),we ensure that the CE trajectories stay on the data manifold without crossing unpopulatedregions in the data (Figures 3 and 4). Our experiments in real-world datasets demonstratethat our approach results in CEs that indeed stay closer to the data manifold ()compared to SGD, giving high fidelity with respect to the original factual input and com-parable validity ( and ). In general, RSGD and RSGD-C perform similarlybut for the GMC dataset, we observe that trajectories for RSGD-C are pushed further fromthe original input compared to RSGD to achieve comparable confidence levels ().However, as RSGD-C is guided by the classifier under observation, we hypothesize thatthese counterfactual trajectories might represent more realistic and actionable paths. Thisis also illustrated by case 4 in where RSGD and RSGD-C generate very differentpaths, with RSGD running more smoothly through the data. Societal impact.Counterfactual explanations are widely used to analyze classifier be-havior. A method that generates more realistic counterfactuals can positively impact societyby providing debugging tools and promoting fairness. However, like many AI models, thisapproach could also be misused for malicious purposes. Limitations and outlook.We rely on a well-calibrated stochastic generator to approx-imate the data and provide reliable uncertainty estimates.Without this, the Rieman-nian metric in the latent space cannot effectively capture the geometry of the data man-ifold. While VAEs help induce Riemannian geometry in the latent space, existing meth-ods (Detlefsen et al., 2019; Arvanitidis et al., 2018) for handling uncertainty are limited tolow-dimensional spaces. For relatively higher-dimensional data, decoder ensembling (Syrotaet al., 2024) or Laplacian Autoencoders (Miani et al., 2022) may be more suitable. Eventhough frameworks, e.g., Stochman (Detlefsen et al., 2021) support Jacobian computation,the computational complexity increases for complex architectures. Adapting our methodto modern models like Diffusion Models (Dhariwal and Nichol, 2021), where understandingRiemannian latent space geometry (Park et al., 2023) or developing Riemannian DiffusionModels (Huang et al., 2022) is an open area of research, remains a topic for future work.",
  "Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning: A reviewand new perspectives. IEEE transactions on pattern analysis and machine intelligence,35(8):17981828, 2013": "Vadim Borisov, Tobias Leemann, Kathrin Seler, Johannes Haug, Martin Pawelczyk, andGjergji Kasneci. Deep neural networks and tabular data: A survey. IEEE Transactionson Neural Networks and Learning Systems, 2022. Susanne Dandl, Christoph Molnar, Martin Binder, and Bernd Bischl. Multi-objective coun-terfactual explanations. In International Conference on Parallel Problem Solving fromNature, pages 448469. Springer, 2020.",
  "Michael Downs, Jonathan L Chu, Yaniv Yacoby, Finale Doshi-Velez, and Weiwei Pan.Cruds: Counterfactual recourse using disentangled subspaces. ICML WHI, 2020:123,2020": "Tri Dung Duong, Qian Li, and Guandong Xu. Ceflow: A robust and efficient counter-factual explanation framework for tabular data using normalizing flows. In Pacific-AsiaConference on Knowledge Discovery and Data Mining, pages 133144. Springer, 2023. Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, andFosca Giannotti. Local rule-based explanations of black box decision systems. arXivpreprint arXiv:1805.10820, 2018.",
  "Kaggle-Competition. give me some credit. improve on the state of the art in credit scoringby predicting the probability that somebody will experience financial distress in the nexttwo years, 2011": "Dimitrios Kalatzis, David Eklund, Georgios Arvanitidis, and Soren Hauberg. Variationalautoencoders with riemannian brownian motion priors. In International Conference onMachine Learning, pages 50535066. PMLR, 2020. Amir-Hossein Karimi, Gilles Barthe, Borja Balle, and Isabel Valera. Model-agnostic coun-terfactual explanations for consequential decisions. In International conference on artifi-cial intelligence and statistics, pages 895905. PMLR, 2020a. Amir-Hossein Karimi, Julius Von Kugelgen, Bernhard Scholkopf, and Isabel Valera. Algo-rithmic recourse under imperfect causal knowledge: a probabilistic approach. Advancesin neural information processing systems, 33:265277, 2020b.",
  "Divyat Mahajan, Chenhao Tan, and Amit Sharma. Preserving causal constraints in coun-terfactual explanations for machine learning classifiers. arXiv preprint arXiv:1912.03277,2019": "Thomas Melistas, Nikos Spyrou, Nefeli Gkouti, Pedro Sanchez, Athanasios Vlontzos, Gior-gos Papanastasiou, and Sotirios A Tsaftaris. Benchmarking counterfactual image gener-ation. arXiv preprint arXiv:2403.20287, 2024. Marco Miani, Frederik Warburg, Pablo Moreno-Munoz, Nicki Skafte, and Sren Hauberg.Laplacian autoencoders for learning stochastic representations. Advances in Neural In-formation Processing Systems, 35:2105921072, 2022. Ramaravind K Mothilal, Amit Sharma, and Chenhao Tan. Explaining machine learningclassifiers through diverse counterfactual explanations. In Proceedings of the 2020 con-ference on fairness, accountability, and transparency, pages 607617, 2020. George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, and Bal-aji Lakshminarayanan. Normalizing flows for probabilistic modeling and inference. Jour-nal of Machine Learning Research (JMLR), 2021. Yong-Hyun Park, Mingi Kwon, Jaewoong Choi, Junghyo Jo, and Youngjung Uh. Under-standing the latent space of diffusion models through the lens of riemannian geometry.Advances in Neural Information Processing Systems, 36:2412924142, 2023.",
  "Martin Pawelczyk, Klaus Broelemann, and Gjergji Kasneci. Learning model-agnostic coun-terfactual explanations for tabular data. In Proceedings of The Web Conference 2020,pages 31263132, 2020": "Martin Pawelczyk, Sascha Bielawski, Johan Van den Heuvel, Tobias Richter, and GjergjiKasneci. Carla: A python library to benchmark algorithmic recourse and counterfactualexplanation algorithms.In Thirty-fifth Conference on Neural Information ProcessingSystems Datasets and Benchmarks Track (Round 1), 2021. Paraskevas Pegios, Manxi Lin, Nina Weng, Morten Bo Sndergaard Svendsen, Zahra Bashir,Siavash Bigdeli, Anders Nymark Christensen, Martin Tolsgaard, and Aasa Feragen.Diffusion-based iterative counterfactual explanations for fetal ultrasound image qualityassessment. arXiv preprint arXiv:2403.08700, 2024. Rafael Poyiadzi, Kacper Sokol, Raul Santos-Rodriguez, Tijl De Bie, and Peter Flach. Face:feasible and actionable counterfactual explanations. In Proceedings of the AAAI/ACMConference on AI, Ethics, and Society, pages 344350, 2020.",
  "B.1. Datasets": "Adult: The dataset includes 49K census records with D = 13 features. The goal isto predict whether an individuals income exceeds $50K/year (y = 1, 24% of samples).Following Pawelczyk et al. (2021), we binarize categorical features as aggregated versionsof original categories indicating whether the individual works in private industry, is notmarried, has an other occupation, is not a husband, identifies as white (race), male (sex),",
  "B.2. Models": "For both datasets, the binary classifier c under observation is a 4-layer MLP with 2 H,2H, H, H neurons including Batch Normalization (Ioffe, 2015) layers, and Tanh activationfunctions before the last layer, where H = 24 is the size of representation space. We trainedthe classifiers with a batch size of 1024, a learning rate of 105, and applied 2-regularizationof 0.05 for 20 epochs using the RMSprop optimizer, resulting in 77.5% (77.6%) and 73.6%(73.8%) balanced test (train) accuracy for Adult and GMC datasets, respectively.Our VAEs employ Gaussian generative models with a 3-layer MLP mirrored encoder-decoder, with D, 512, 256 neurons with Batch Normalization layers and Tanh activationsfunctions, a latent space of d = 5, and Sigmoid activation function in decoders mean output.Following Detlefsen et al. (2019) and Kalatzis et al. (2020), we deterministically warmed upthe encoders together with the decoders mean for 100 epochs, with -regularization (Hig-gins et al., 2017) of 104. Consecutively, we freeze them while optimizing for 300 epochs de-coders uncertainty , parameterized by Radial Basis Function networks (Que and Belkin,2016) with a 0.01 bandwidth and 200 and 350 centers for Adult and GMC, respectively.During training, we used a batch size of 512, and the Adam (Kingma, 2014) optimizer, witha learning rate of 103, expect for GMCs for which we used 102. During inference andCE optimization, we used Stochman (Detlefsen et al., 2021) to track Jacobians through theVAEs decoder and the classifier."
}