{
  "Abstract": "Current neural network models of primate vision focus on replicating overall levelsof behavioral accuracy, often neglecting perceptual decisions rich, dynamic nature.Here, we introduce a novel computational framework to model the dynamicsof human behavioral choices by learning to align the temporal dynamics of arecurrent neural network (RNN) to human reaction times (RTs). We describe anapproximation that allows us to constrain the number of time steps an RNN takesto solve a task with human RTs. The approach is extensively evaluated againstvarious psychophysics experiments. We also show that the approximation can beused to optimize an ideal-observer RNN model to achieve an optimal tradeoffbetween speed and accuracy without human data. The resulting model is found toaccount well for human RT data. Finally, we use the approximation to train a deeplearning implementation of the popular Wong-Wang decision-making model. Themodel is integrated with a convolutional neural network (CNN) model of visualprocessing and evaluated using both artificial and natural image stimuli. Overall,we present a novel framework that helps align current vision models with humanbehavior, bringing us closer to an integrated model of human vision.",
  "Introduction": "Categorizing visual stimuli is crucial for survival, and it requires an organism to make informeddecisions in dynamic and noisy environments. This critical aspect of visual perception has driven thedevelopment of computational models to understand and replicate these processes. Traditionally, thefield has followed two distinct paths. On the one hand, image-computable vision models are used to predict behavioral decisions during(rapid) visual categorization tasks ranging from models of early- , mid- and high-levelvision (see for a review). More recently, these earlier models were superseded by deepconvolutional neural networks (CNNs), which have become the de-facto choice for modeling behav-ioral decision . Models are typically evaluated by estimating confidence scores computed forindividual images, which are then correlated with similar scores derived for human observers(suchas the proportion of correct human responses for each image). Such metrics ignore human reactiontimes (RTs); hence, current vision models only partially account for human decisions. On the other hand, decision-making models have been used to explain how visual information getsintegrated over time predicting behavioral choices and RTs jointly. Notably, mathematical models,exemplified by evidence accumulation models such as the drift-diffusion and linear ballistic",
  "Threshold": "StimuliNeural Network : Illustration of our RTify method. The input is a visual stimulus represented by randommoving dots, but the model can also accommodate color images and video sequences. We takea pretrained task-optimized RNN and use a trainable function fw to transform the activity of thenetwork into a real-valued evidence measure, et, that will be integrated over time by an evidenceaccumulator, t. When the evidence accumulator reaches the threshold , processing stops, and adecision is taken. The time step at which the accumulated evidence passes this threshold is takenas the model RT for this stimulus. accumulators , have been quite successful in modeling an array of behavioral data (see fora review). In addition, mechanistic models, including the Wong-Wang (WW) model, have providedinsights into the underlying neural mechanisms . However, these efforts have primarily reliedon traditional psychophysics tasks using simple, artificial stimuli, such as Gabor patterns andrandom moving dots . Beyond these easily parameterizable stimuli, these models have not beenextended to deal with more complex, natural stimuli. While both vision and decision-making models have contributed distinctively to our understanding ofvisual processes, a complete understanding of human vision will require their integration to explainthe whole dynamics of visual decision-making. Recent neuroscience studies have leveraged recurrentneural network (RNN) models as the starting point for this integration (see for a review).More generally, recurrent processing has been shown to be necessary to account for both behavioraland neural recordings in object recognition tasks . Two promising approaches have been described that leverage RNNs to bridge the gap betweendecision-making and vision models . In , an RNN was trained to solve a visual classi-fication task using the backpropagation-through-time (BPTT) learning algorithm. The entropy ofthe RNN outputs is computed at each timestep and used as a proxy for the network confidence. Adecision is taken when the entropy reaches the threshold, halting further recurrent computation. Inthis approach, the recurrence steps are not differentiable, which prevents the use of gradient methodsand inherently limits the complexity of the corresponding decision function. The resulting modelmay have difficulty predicting the entire distribution of RTs. Besides, the method is only applicablewhen human RTs are available because it requires an extensive search for the correct threshold valueto fit human RT data. An alternative approach was described in . In , a convolutional RNN was trained on avisual classification task using contractor recurrent back-propagation (C-RBP). Besides, instead ofsearching for an optimal threshold to fit human RT data, a surrogate time-evolving uncertainty metric was estimated with evidential deep learning . In this framework, model outputs are treatedas parameters of a Dirichlet distribution, with the width of the distribution reflecting uncertainty.Remarkably, the resulting approach fits a range of experimental data well, without any supervisionfrom human data. It is true that uncertainty and RTs are tightly coupled and are both affected by taskdifficulty. However, uncertainty and RTs are conceptually different. Experimental results show thatuncertainty and RTs can be positively or negatively correlated , and even double dissociated under different experimental conditions. Therefore, a good model of uncertainty is not guaranteed tobe a good model of RTs. Here, based on extensive cognitive neuroscience research , we introduce a novel trainablemodule called RTify to allow an RNN to dynamically and nonlinearly accumulate evidence. First,this module can be trained to learn to make human-like decisions using direct human RT supervision.Our results suggest that incorporating a dynamic evidence accumulation process, compared to theentropy heuristics used in , can help better capture human RTs. Second, we show how the samegeneral approach can also be used to train an RNN to learn to solve a task with an optimal numberof time steps via self-penalty. Our results show that human-like RTs naturally emerge from suchideal-observer models without explicit supervision from human RT data. Hence, our framework isgeneral enough to allow the fitting of human RT data as done in and/or the training of a neuralarchitecture that can optimally trade speed and accuracy via self-penalty as done in . Contributions:Overall, our work makes the following contributions: (i) We present RTify, anovel computational approach to optimize the recurrence steps of RNNs to account for human RTs.This enables dynamic nonlinear evidence accumulation learned through back-propagation (a) to fithuman data or (b) optimally balance speed and accuracy. (ii) We comprehensively demonstrate theeffectiveness of our framework for modeling human RTs across a diverse range of psychophysicstasks and stimuli. Our method consistently outperforms alternatives with and without explicit trainingon human data. (iii) As an illustrative example of the frameworks potential, we extend the WWdecision-making model to create a biologically plausible, multi-class compatible, and fullydifferentiable RNN module. We show that the enhanced neural circuit can be used as a drop-inmodule for CNNs to fit human RTs.",
  "First, we explain how our RTify module is applied to a pre-trained RNN. Then, we will explainhow to tune a deep-learning RNN-based implementation of the WW model to RTify feedforwardnetworks": "We start with a task-optimized RNN with hidden state ht, which remains frozen. We then train alearnable mapping function fw : Rk R that summarizes the state of the neural population at eachtime step t by mapping the RNN hidden state ht to some \"evidence\": et = fw(ht). At every time step,the evidence is integrated via an evidence accumulator t = ti=1 ei, and when the accumulatedevidence passes a learnable threshold , the model is read out, and a decision is made. The time stepat which the accumulated evidence first passes this threshold is given by () = min{t : t > },and is treated as model RTs. In summary, () is directly influenced by the threshold and by wthrough t. To align the model RTs with human RTs, or to penalize the model for excessive time steps, we needto optimize a loss function over (). In the most general case, we first consider F(()) as ourloss function to illustrate how we approximate its gradient. Since our goal is to minimize F, we willneed to calculate the gradient F (())",
  "Predicting human decisions with direct supervision": "Human behavioral decisions in the random dot motion (RDM) tasks used in decision-making stud-ies are typically summarized as histograms similar to those shown in . Here,histograms are computed for RTs for correct and incorrect trials corresponding to individual experi-mental conditions (such as coherence levels shown here; see section 3 for details). Moreover, RTs forincorrect trials are turned into negative RTs. Combined with correct RTs (which stay positive), onesingle histogram is used for capturing both accuracy (the proportion of positive values) and RTs. Tomeasure the goodness of fit between human RTs and model RTs, we use a mean squared error loss(MSE) between histograms of model RTs and human RTs. In the object recognition task , only RTs averaged across all participants were available. We canmatch human data on a stimulus-by-stimulus basis using the negative correlation loss between modeland human RTs.",
  "Predicting human decisions with self-penalty": "Our framework allows us to develop an ideal-observer RNN model explicitly trained to balance thecomputational time required for solving a particular classification task and its own accuracy for thetask, i.e., a speed-accuracy trade-off. To achieve this, we add a regularizer to the cross-entropy loss to encourage the RNN to jointlymaximize task accuracy while minimizing the computational time needed to solve the task. With l asthe output logits of the network, y as the output probabilities of the network, and y as the groundtruth, we can write our penalty term for a single sample as:",
  "RTifying feedforward networks": "To integrate temporal dynamics into feedforward neural networks (e.g., CNNs), we describe anRNN module that approximates the WW neural circuit model . The original WW model isa biophysically-realistic neural circuit model of two-alternative forced choices via the temporal A IncorrectCorrect Extracting RTs with supervision (fitting human RTs) Extracting RTs via self penalty (leveraging RNN dynamics)B IncorrectCorrectIncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrectIncorrectCorrectIncorrectCorrect : RTified model evaluation on a RDM task . Human data are shown as a gray shadedarea, and model fits are shown for (A) the supervised setting where human behavioral responsesare used to train the models and (B) the self-penalized setting where no human data is used. Ourapproach (green) outperforms the two alternative approaches (brown), i.e., entropy-thresholding for the supervised and uncertainty proxy for the self-penalized settings (see for MSEcomparisons and Fig. S3 for all coherences). accumulation of sensory evidence in two distinct neural populations. It takes a constant scalar input(representing a stimulus parameter such as the degree of coherence for randomly moving dot stimuli).It outputs an RT when the activity of either population reaches a decision threshold. However, the original WW model has limitations: its parameters must be manually tuned to fitobserved data, and it is restricted to binary classification tasks with simple artificial parametricstimuli (e.g., Gabor patterns). To overcome these limitations, we extend the WW model. First,we replace the scalar input with a feedforward neural network (e.g., a CNN), enabling the modelto process complex stimuli such as natural images. Second, we generalize the model from twopopulations to M populations, effectively increasing the number of neural populations to handlemulti-class classification problems. Third, we RTify the model to make all parameters trainable viabackpropagation. This allows the model to automatically learn the optimal parameters to fit humanRTs (see for an illustration of the multi-population case and SI Fig. A.2 for an illustration ofthe two-population case).",
  "Experiments": "In this section, we validate our RTify framework on two psychophysics datasets: the RDM dataset and a natural image categorization dataset . As a side note, all models were trained on singleNvidia RTX GPUs (Titan/3090/A6000) with 24/24/48GB of memory each. All training can becompleted in approximately 48 hours. Code and data are available at A B Excitatory ConnectionInhibitory Connection C : Illustration of RTifying feedforward neural networks. We develop a multi-classcompatible and fully differentiable RNN module based on the WW model . This module isimplemented as an attractor-based RNN, and is stacked on top of a feedforward neural network. Thefeedforward neural network first takes an image as the input. Outputs from classification units of thenetwork are then sent to RTified WW (A). Information is accumulated by multiple populations ofneurons in RTified WW while they compete with each other (B). A decision is made and the processstops when one of the populations reaches a threshold. The number of time steps needed for theRTified WW to reach the threshold is used to predict human RT (C).",
  "Random dot motion task": "The RDM task is a classic experimental paradigm used to test temporal integration that hasbeen extensively used in psychophysics , human imaging , and electrophysiology stud-ies . The stimuli in this task consist of dots moving on a screen toward a predefined di-rection vs. randomly. For each time step, each dot only has a specific probability (coherence)(0.8%, 1.6%, 3.2%, 6.4%, 12.8%, 25.6%, or 51.2%) to move towards the pre-defined direction, mak-ing the task non-trivial. The participants must integrate motion information across time and reportit when they are sufficiently confident. The original experimental data are from , where 21young adult participants performed around 40,000 trials in total over 4 consecutive days. First, we trained an RNN consisting of 5 convolutional blocks (Convolution, BatchNorm, ReLU, Maxpooling) and a 4096-unit LSTM with BPTT. In the original experiment, the stimuli were shown on a75 Hz CRT monitor for up to 2 seconds, and therefore, we also trained our RNN for the RDM stimulifor 150 frames. The RNN was trained for 100 epochs using the Adam optimizer with a learning rateof 1e-4 at full coherence (c = 99.9%) for the first 10 epochs as a warm-up and 1e-5 at all coherencelevels for the remaining 90 epochs. Next, we trained our two different RTify modules. For fittinghuman RTs, it was trained for 10,000 epochs, and for self-penalty, it was trained for 20,000 epochs. Inboth cases, the Adam optimizer were used, and the weights of the task-optimized RNN were frozenwhile training the RTify modules. We trained the first RTify module to predict human RTs by fitting human RT distributions. Here,positive RTs refer to RT with correct choices, and negative RTs refer to RTs with incorrect choices.Therefore, one distribution incorporates both speed and accuracy information from behavioral choices.Results are shown in . Our RTify model can predict the full RT distribution across all coherencelevels. In comparison, the entropy-thresholding approach by fails to capture the full distribution(see for coherence = 51.2% to 6.4% and Fig. S3 for all coherences). Importantly, our method AB : (A) MSE comparisons for the RDM task for all coherence levels. The RTifiedmodel trained in the supervised setting (i.e., with human behavioral responses; green solid line)performs better (lower MSE) than entropy-thresholding (brown solid line) under all coherencelevels. Similarly, the RTified model trained in the self-penalized setting (i.e., without human data;green dash line) performs better than uncertainty proxy (brown dash line). With the help ofour RTified WW module (orange solid line), a convolution neural network (C3D) can also fit thedata better than entropy-thresholding . (B) Classification accuracy comparisons betweenpretrained and RTified models for the RDM task . The RTified model trained with human RTsdata in the supervised setting (green solid line) and in the self-penalized setting (green dash line)achieve human-like classification accuracy under all coherence levels compared with the pretrainedmodel without RTify (green dotted line). With the help of our RTified WW module (orange solidline), a CNN (C3D) matches human accuracy better than the pretrained model without RTify (orangedotted line).",
  "surpasses entropy-thresholding approach (two-sided Wilcoxon signed-rank test, p < .05; forMSE comparisons, see )": "It is well known that there is a trade-off between RTs and accuracy in cognitive tasks. To investigatethis relationship further, we extended our analysis to examine whether the models accuracy wouldapproximate human accuracy when it was fitted solely on human RTs without using human accuracydata. Given that conventional RT distributions encompass both RTs and accuracy information, werestricted our fitting procedure to the positive part of the distribution. That is, RTs corresponding tocorrect responses to prevent inadvertently incorporating human accuracy into the model. Remarkably,by fitting the model on human RTs only, the model naturally reached a classification accuracycomparable to human performance (see ). We also trained a self-penalized RTify module without any human data. This ideal-observer RNNmodel was trained to minimize the time steps needed for solving the RDM task (see section 2.2 fordetails). Human-like RTs emerge naturally in this neural network (See ). Our model predictsRT data much better than previous approaches, which use a measure of uncertainty computed overthe RNN as a surrogate metric. As can be seen, the resulting model tends to overfit the modes ofthe distribution.(see for coherence = 51.2% to 6.4% and Fig. S3 for all coherences). Ourmethod surpasses uncertainty proxy approach (two-sided Wilcoxon signed-rank test, p < .05,for MSE comparison, see ). We also checked the model classification accuracy before and afterself-penalized RTify. Interestingly, we also found the self-penalized RTified RNN demonstrated ahuman-like classification accuracy (see ).",
  "Object recognition task": "Unlike previous visual decision-making models, we want to show that our method can also beapplied to natural images and multi-class datasets. Specifically, we consider an object recognitiontask, a classic paradigm used extensively in computer vision and cognitive neurosciencestudies . The original data is from , where 88 participants perform the task through Mturk.The stimuli in this task belong to 10 categories, and for each category, there are 20 natural images Extracting RTs via self penalty (leveraging RNN dynamics) Extracting RTs with supervision (fitting human RTs)A B : RTified model evaluation on an object categorization task . Model vs. human RTpredictions for our RTified model (green) vs. alternative approaches (brown) (A) in the supervisedsetting where human behavioral responses are used to train the model and (B) the self-penalizedsetting where no human data is used. Solid lines are linear regression fits between model and humanRTs. Crossed-shaded areas and the dashed lines are controls to show the fits after removing the highestmodel RTs. Our approach outperforms the two alternative approaches, i.e., entropy-thresholding for the supervised setting and uncertainty proxy for the self-penalized setting.",
  "taken from the COCO dataset and 112 synthetically generated images with different backgroundsand object positions": "We first train our RNN with BPTT to perform a 10-way classification task. In the original study,participants performed a binary classification task. However, since the individual binary pairs werenot saved, we trained the model in a 10-class classification task. We used Cornet-S pretrained onthe Imagenet dataset because it was used in the original study and it achieves a relatively highbrainscore in terms of explaining neural activities . We trained the network for 100 epochs, usingthe Adam optimizer with a learning rate of 1e-4 and a learning scheduler (StepLR) with a step sizeof 2,000. We used 20 timesteps (instead of 2 in the original model) for the IT layer in the Cornetto achieve high temporal resolution. Results show that our RNN achieves 75.2% on a held-out testset. Similarly, we trained our two different RTify modules. For fitting human RTs, it was trained for100,000 epochs, while for self-penalty, it was trained for 10,000 epochs with a learning scheduler(StepLR) with a step size of 2,000 and a gamma of 0.3. In both cases, Adam optimizers were used,and the weights of the task-optimized RNN were frozen while training the RTify modules.",
  "We then extracted RTs from our RNN to fit human RTs. Notably, model RTs significantly correlatewith the human RT observed in the psychophysics experiment (r = .51, p < .001). Besides, our": "IncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrect BA : RTified WW model evaluation. We combine our RTified WW module with (A) a 3DCNN to fit human RTs collected in an RDM task (see for MSE comparisons with othermethods) and (B) a VGG to fit human RTs in a rapid object categorization task (Crossed-shadedareas and the dashed lines are controls to show the fits after removing the highest model RTs). method also surpasses entropy-thresholding (bootstrapping shows that our method is superior totheirs with a probability of 99.9%). We also extract RTs from an ideal-observer RNN model trainedwith a time self-penalty (see section 2.2 for details). We show here that model RTs are significantlycorrelated with human RTs (see , r = .40, p < .001). This failed to be captured by uncertaintyproxy . We argue this in two ways. First, bootstrapping shows that our method is superior totheirs with a probability of 87.1%. Second, and most importantly, although the uncertainty seems tocorrelate with human RTs in the dataset (r = .36, p < .001), it only applies to high-uncertainty cases.When trials with high model uncertainty are excluded, uncertainty shows no significant correlationwith human RTs (r = .05, p = 0.32). However, using our method, the correlation remains strong andsignificant (r = .41, p < .001).",
  "RTifying feedforward neural networks": "Given the prevalence of feedforward networks (e.g. CNNs) and their incredible performance in visualtasks, a natural question is how to align such networks in the temporal domain of decision-making.We thus developed a biologically plausible, multi-class, differentiable RNN module based on theWW recurrent circuit model . This module can be stacked on top of any neural network, evenif not recurrent, and can be used to align model RTs with human RTs. For the RDM task, we take a 3D CNN with 6 convolutional blocks (convolution, BatchNorm, ReLU,Max pooling) and an MLP. We train the network for 100 epochs using the Adam optimizer with alearning rate of 1e-4 at full coherence (c = 99.9%) for the first 10 epochs as a warm-up and 1e-5 at allcoherence levels for the remaining 90 epochs. Since this model is not an RNN, it has no temporaldynamics. Therefore, we drop in our WW module and further train the WW module for 5,000 epochsusing the Adam optimizer with a learning rate of 1e-4, a StepLR scheduler with a step size of 1,000and gamma of 0.3, and a grad clip at 1e-5. Interestingly, when we RTify the C3D model using theWW module, it is able to capture the distribution of human RTs across all coherence levels, seeA for coherence = 51.2% to 6.4% and Fig. S4 for all coherences, for MSE comparison see). Furthermore, we also observed a human-like classification accuracy for the model when it issolely trained to fit human RTs but not human accuracy (see ). Similarly, we take a VGG-19 pre-trained on Imagenet for the object recognition task and fine-tune iton the dataset provided by Kar et al. in a 10-class classification way for the abovementionedreasons. We train the model for 100 epochs using a batch size of 32. The optimizer was AdamW, with a learning rate of 1e-5. We use a OneCycleLR scheduler adjusted after 10 epochs of warm-up.Results show that our RNN achieves 81.6% on a held-out test set. We further train the WW modulefor 100,000 epochs using the Adam optimizer with a learning rate of 1e-4 and a grad clip at 0.0001.By using the multi-class version of the WW model, we show that the RTify VGG also exhibited asignificant correlation with human data (r = .49, p < .001, see B).",
  "Conclusion": "We have described a computational framework to train RNNs to learn to dynamically accumulateevidence nonlinearly so that decisions can be made based on a variable number of time steps toapproximate human behavioral choices, including both decisions and RTs. We showed that suchoptimization can be used to fit an RNN directly to human behavioral responses. We also showed thatsuch a framework can be extended to an ideal-observer model whereby the RNN is trained withouthuman data but with self-penalty that encourages the network to make a decision as quickly as possible.Under this setting, human-like behavioral responses naturally emerge from the RNN consistentwith the hypothesis that humans achieve a speed-accuracy trade-off. Finally, we provided an RNNimplementation of a popular neural circuit decision-making model, the WW model, as a trainabledeep learning module that can be combined with any vision architecture to fit human behavioralresponses. Our computational framework provides a way forward to integrating image-computablemodels with decision-making models, advancing toward a more comprehensive understanding of thebrain mechanisms underlying dynamic vision. LimitationsCertain limitations will need to be addressed in future work. Most of the human dataused in our study remains relatively small-scale and is limited primarily to synthetic images becausemore naturalistic benchmarks only include behavioral choices and lack RT data. To properlyevaluate our approach and that of others, larger-scale psychophysics datasets using more realisticvisual stimuli will be needed. There is already evidence that large-scale psychophysics data canbe used to effectively align AI models with humans . We hope this work will encourageresearchers to collect novel internet-scale benchmarks that include both behavioral choices and RTs. Broader ImpactsAs AI vision models become more prevalent in our daily lives, ensuring theirtrustworthy behavior is increasingly important . Our framework contributes to this effort byexploring how to align certain aspects of models behavior with human responses in specific contexts.While our approach is limited to predicting RT distributions, it constitutes a first step toward morehuman-aligned AI models.",
  "Kheradpisheh, S.R., Ghodrati, M., Ganjtabesh, M., Masquelier, T.: Deep networks can resemble humanfeed-forward vision in invariant object recognition. Scientific Reports 6(1) (September 2016)": "Eberhardt, S., Cader, J.G., Serre, T.: How deep is the feature analysis underlying rapid visual categorization?In Lee, D., Sugiyama, M., Luxburg, U., Guyon, I., Garnett, R., eds.: Advances in Neural InformationProcessing Systems. Volume 29., Curran Associates, Inc. (2016) Rajalingham, R., Issa, E.B., Bashivan, P., Kar, K., Schmidt, K., DiCarlo, J.J.: Large-scale, high-resolutioncomparison of the core visual object recognition behavior of humans, monkeys, and state-of-the-art deepartificial neural networks. J Neurosci 38(33) (Aug 2018) 72557269",
  "Kreiman, G., Serre, T.: Beyond the feedforward sweep: feedback computations in the visual cortex. Ann.N. Y. Acad. Sci. 1464(1) (March 2020) 222241": "Kar, K., Kubilius, J., Schmidt, K., Issa, E.B., DiCarlo, J.J.: Evidence that recurrent circuits are criticalto the ventral streams execution of core object recognition behavior. Nat. Neurosci. 22(6) (June 2019)974983 Van Kerkoerle, T., Self, M.W., Dagnino, B., Gariel-Mathis, M.A., Poort, J., Van Der Togt, C., Roelfsema,P.R.: Alpha and gamma oscillations characterize feedback and feedforward processing in monkey visualcortex. Proceedings of the National Academy of Sciences 111(40) (2014) 1433214341 Spoerer, C.J., Kietzmann, T.C., Mehrer, J., Charest, I., Kriegeskorte, N.: Recurrent neural networks canexplain flexible trading of speed and accuracy in biological vision. PLOS Computational Biology 16(10)(10 2020) 127 Goetschalckx, L., Govindarajan, L.N., Karkada Ashok, A., Ahuja, A., Sheinberg, D., Serre, T.: Computinga human-like reaction time metric from stable recurrent vision models. Advances in Neural InformationProcessing Systems 36 (2024) Sensoy, M., Kaplan, L., Kandemir, M.: Evidential deep learning to quantify classification uncertainty. InBengio, S., Wallach, H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., Garnett, R., eds.: Advances inNeural Information Processing Systems. Volume 31., Curran Associates, Inc. (2018)",
  "Rahnev, D.: A robust confidenceaccuracy dissociation via criterion attraction. Neuroscience of Con-sciousness 2021(1) (2021) niab039": "Winkel, J., Keuken, M.C., van Maanen, L., Wagenmakers, E.J., Forstmann, B.U.: Early evidence affectslater decisions: Why evidence accumulation is required to explain response time data. Psychonomicbulletin & review 21 (2014) 777784 Bogacz, R., Brown, E., Moehlis, J., Holmes, P., Cohen, J.D.: The physics of optimal decision making: aformal analysis of models of performance in two-alternative forced-choice tasks. Psychological review113(4) (2006) 700",
  "Cisek, P., Puskas, G.A., El-Murr, S.: Decisions in changing conditions: the urgency-gating model. Journalof Neuroscience 29(37) (2009) 1156011571": "Cochrane, A., Sims, C.R., Bejjanki, V.R., Green, C.S., Bavelier, D.: Multiple timescales of learningindicated by changes in evidence-accumulation processes during perceptual decision-making. npj Scienceof Learning 8(1) (2023) 19 Kar, K., Kubilius, J., Schmidt, K., Issa, E.B., DiCarlo, J.J.: Evidence that recurrent circuits are criticalto the ventral streams execution of core object recognition behavior. Nature neuroscience 22(6) (2019)974983",
  "Serre, T., Oliva, A., Poggio, T.: A feedforward architecture accounts for rapid categorization. Proceedingsof the national academy of sciences 104(15) (2007) 64246429": "Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan, D., Dollr, P., Zitnick, C.L.: Microsoftcoco: Common objects in context. In: Computer VisionECCV 2014: 13th European Conference, Zurich,Switzerland, September 6-12, 2014, Proceedings, Part V 13, Springer (2014) 740755 Kubilius, J., Schrimpf, M., Kar, K., Rajalingham, R., Hong, H., Majaj, N., Issa, E., Bashivan, P., Prescott-Roy, J., Schmidt, K., et al.: Brain-like object recognition with high-performing shallow recurrent anns.Advances in neural information processing systems 32 (2019) Schrimpf, M., Kubilius, J., Lee, M.J., Ratan Murty, N.A., Ajemian, R., DiCarlo, J.J.:Integrativebenchmarking to advance neurally mechanistic models of human intelligence. Neuron 108(3) (November2020) 413423 Hebart, M.N., Contier, O., Teichmann, L., Rockter, A.H., Zheng, C.Y., Kidder, A., Corriveau, A., Vaziri-Pashkam, M., Baker, C.I.: Things-data, a multimodal collection of large-scale datasets for investigatingobject representations in human brain and behavior. eLife 12 (feb 2023) e82580",
  "Fel, T., Rodriguez, I.F., Linsley, D., Serre, T.: Harmonizing the object recognition strategies of deep neuralnetworks with humans. Advances in Neural Information Processing Systems (NeurIPS) (2022)": "Linsley, D., Rodriguez, I.F., Fel, T., Arcaro, M., Sharma, S., Livingstone, M., Serre, T.: Performance-optimized deep neural networks are evolving into worse models of inferotemporal visual cortex (2023) Liang, W., Tadesse, G.A., Ho, D., Fei-Fei, L., Zaharia, M., Zhang, C., Zou, J.: Advances, challenges andopportunities in creating data for trustworthy ai. Nature Machine Intelligence 4(8) (2022) 669677",
  "Steps": "Figure S2: Illustration of the RTified WW circuit. To RTify feedforward neural networks, weused an RNN based on the WW circuit. Here, we consider a binary classification on random movingdots for illustration (A). When receiving a visual input, the two populations sensitive to left/rightdirections compete with each other (B) and accumulate evidence until one of them reaches a threshold(C). The number of time steps needed for the RNN to reach the threshold is defined as the modelRT\" and is used to predict human RT. We provide pseudo-code for a more detailed description of thecircuit (D). Here, f(x) = max(ax b, 0)/(1 exp(d(ax b))) is a fixed nonlinear function.And the model and equations marked blue are how we extend WW model.",
  "A.3Extended results for RDM task": "AExtracting RTs with supervision (fitting human RTs) Extracting RTs via self penalty (leveraging RNN dynamics)B IncorrectCorrectIncorrectCorrectIncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrectIncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrectIncorrectCorrect Figure S3: RTified model evaluation on a RDM task across all coherences. Human dataare shown as a gray shaded area, and model fits are shown for (A) the supervised setting wherehuman behavioral responses are used to train the models and (B) the self-penalized setting whereno human data is used. Our approach (green) outperforms the two alternative approaches (brown),i.e., entropy-thresholding for the supervised and uncertainty proxy for the self-penalizedsettings. IncorrectCorrectIncorrectCorrectIncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrectIncorrectCorrect Extracting RTs with supervision (fitting human RTs) Figure S4: RTified WW model on a RDM task across all coherences. We combined ourRTified WW module with a 3D CNN to fit human RTs collected in an RDM task . Human dataare shown as a gray shaded area and model results are shown as orange solid lines.",
  "A.4Additional Experiment for RDM task": "Recurrent neural networks generate a sequence of outputs across time steps, raising the question ofhow to convert these multiple outputs into a single final prediction. In the main text, we combine allthe networks outputs up until the decision time point. Here, as an additional experiment, we only usethe networks output at the decision time point. In both \"supervised\" and \"self-penalized\" settings,our approach surpasses two alternative approaches (see Fig. S5). AExtracting RTs with supervision (fitting human RTs) Extracting RTs via self penalty (leveraging RNN dynamics)B C IncorrectCorrectIncorrectCorrectIncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrectIncorrectCorrectIncorrectCorrect IncorrectCorrectIncorrectCorrectIncorrectCorrect Figure S5: RTified model evaluation on a RDM task across all coherences.Human dataare shown as a gray shaded area, and model fits are shown for (A) the supervised setting wherehuman behavioral responses are used to train the models and (B) the self-penalized setting whereno human data is used. Our approach (green) outperforms the two alternative approaches (brown),i.e., entropy-thresholding for the supervised and uncertainty proxy for the self-penalizedsettings. MSE comparison is shown in (C)."
}