{
  "Abstract": "This research introduces a unique approach to scene parsing that is nonparametric,which enhances the precision and expands the scope of foreground categories withinimages of scenes. Initially, the accuracy of label likelihood at the superpixel levelis improved by combining likelihood scores from multiple probabilistic classifiers.This method improves classification accuracy and enhances the representation ofcategories that are less frequently represented. The second advancement involvesthe integration of semantic context into the parsing procedure by utilizing globallabel costs. Instead of relying on sets derived from image retrieval, the techniquedescribed assigns a comprehensive likelihood estimate to each label, which issubsequently incorporated into the overall energy function. The effectivenessof the system is assessed using two expansive datasets, SIFTflow and LMSun.The system demonstrates performance that is at the forefront of the field on theSIFTflow dataset and achieves outcomes that are close to setting new records onthe LMSun dataset.",
  "Introduction": "The task of scene parsing involves assigning semantic labels to every pixel within an image of ascene. Algorithms for image parsing attempt to categorize different types of scenes, both indoors andoutdoors, such as a shoreline, a roadway, an urban environment, and an airport. Numerous systemshave been developed to categorize each pixel in an image semantically. A significant obstacle forimage parsing methods is the considerable variability in recognition rates across different types ofclasses. Background classes, which usually cover a significant area of the images pixels, often have auniform look and are identified with great accuracy. Foreground classes, which usually take up fewerpixels in the image, have changeable forms and might be hidden or set up in various ways. Thesekinds of classes represent noticeable parts of the image that frequently grab a viewers attention.However, their recognition rates are often much lower than those of background classes, makingthem frequent examples of unsuccessful recognition. Impressive results have been obtained by parametric scene parsing techniques on datasets with alimited number of labels. Nevertheless, for considerably bigger datasets with a lot of labels, usingthese techniques becomes more challenging because of the increased demands on learning andoptimization. Nonparametric image parsing techniques have recently been introduced to tackle the growing varietyof scene types and semantic labels effectively. These methods usually begin by reducing the com-plexity of the problem from individual pixels to superpixels. Initially, a set of images is selected,consisting of training images that bear the closest visual resemblance to the image being queried.The potential labels for a specific image are limited to those found in the selected set of images.Subsequently, the probability scores for the classification of superpixels are determined by matchingvisual characteristics. Ultimately, context is applied by reducing an energy function that includes boththe expense of the data and information on how often classes appear together in nearby superpixels.",
  "Related Work": "Several techniques for scene parsing, both parametric and nonparametric, have been suggested. Thenonparametric systems that try to cover a wide range of semantic classes are very similar to themethod. Different methods are used to improve the overall effectiveness of nonparametric parsing.The authors merge region-parsing with outputs from per-exemplar SVM detectors. Object masksare transferred by per-exemplar detectors into the test image for segmentation. Their method greatlyimproves overall accuracy, but it requires a lot of computer power. Its hard to scale because dataterms need to be calibrated using a batch of fine training in a leave-one-out way, which is hard to do.Superpixels from rare classes are specifically added to the retrieval set to make them more visible.The authors filter the list of labels for a test image by doing an image retrieval step, and query timeis used to add more samples to rare classes. The way superpixels are classified, how rare classesare recognized, and how semantic context is applied are all different in this system. By combiningclassification costs from different contextual models, a more balanced set of label costs is produced,which promotes the representation of foreground classes. Instead of using image retrieval, globallabel costs are used in the inference step. The value of semantic context has been thoroughly investigated in numerous visual recognitionalgorithms. Context has been employed to enhance the overall labeling performance through afeedback mechanism in nonparametric scene parsing systems. Initial labeling of superpixels in aquery image is utilized to modify the training set by adjusting for recognized background classes,thereby enhancing the visibility of uncommon classes. The objective is to enhance the image retrievalset by reintroducing segments of uncommon classes. A semantic global descriptor is generated.Image retrieval is enhanced by merging the semantic descriptor with the visual descriptors. Contextis added by creating global and local context descriptors based on classification likelihood maps. Themethod described differs from these methods as it does not employ context at each superpixel whencalculating a global context descriptor. Instead, contextual information across the entire image istaken into account. Contextually relevant outcomes are produced by deducing label correlations in comparable sceneimages. Additionally, there is no retrieval set that needs to be enriched. Rather, the global context isstructured within a probabilistic framework, where label costs are calculated across the whole image.Furthermore, the global context is executed in real time without any preliminary training. Anothermethod of image parsing that doesnt use retrieval sets is where image labeling is done by movingannotations from a graph of patch matches across image sets. But this method needs a lot of memory,which makes it hard to scale for big datasets. The presented method draws inspiration from the combination of classifier techniques in machinelearning, which have demonstrated the ability to enhance the capabilities of individual classifiers.Several fusion methods have been effectively applied in various fields of computer vision, includingdetecting faces, annotating images with multiple labels, tracking objects, and recognizing characters.Nonetheless, the classifiers that make up these systems and the ways they are combined are verydifferent from the framework, and the other methods have only been tested on small datasets.",
  "Segmentation and Feature Extraction": "To reduce the complexity of the task, the image is partitioned into superpixels. Extraction ofsuperpixels from images begins by employing an efficient graph-based method. For each superpixel,20 distinct types of local features are extracted to characterize its shape, appearance, texture, color, andposition, adhering to established methods. In addition to these features, Fisher Vector (FV) descriptorsare extracted at each superpixel using an established library. Computation of 128-dimensional denseSIFT feature descriptors is performed on five different patch sizes (8, 12, 16, 24, 30). A dictionarycomprising 1024 words is constructed. Subsequently, the FV descriptors are retrieved and PrincipalComponent Analysis (PCA) is applied to decrease their dimensionality to 512. Each superpixel isrepresented by a feature vector that has 2202 dimensions.",
  "Label Likelihood Estimation": "The features obtained in the prior stage are utilized to determine label probabilities for each superpixel.Unlike conventional approaches, the possible labels for a test image are not restricted. Instead, thedata term for the likelihood of each class label c C is computed, where C represents the total numberof classes in the dataset. The normalized cost D(l<sub>si</sub> = c|s<sub>i</sub>) of assigninglabel c to superpixel s<sub>i</sub> is given by:",
  "+ eLunbal(si,c)(1)": "where L<sub>unbal</sub>(s<sub>i</sub>, c) is the log-likelihood ratio score of label c, given byL<sub>unbal</sub>(s<sub>i</sub>, c) = 1/2 log(P(s<sub>i</sub>|c)/P(s<sub>i</sub>|c)), wherec = C c is the set of all labels except c, and P(s<sub>i</sub>|c) is the likelihood of superpixels<sub>i</sub> given c. A boosted decision tree (BDT) model is trained to obtain the label likelihoodsL<sub>unbal</sub>(s<sub>i</sub>, c). For implementation, a publicly accessible boostDT libraryis utilized. During this phase, the BDT model is trained using every superpixel in the training set,which constitutes an imbalanced distribution of class labels C.",
  "Smoothing and Inference": "The optimization challenge is formulated as a maximum a posteriori (MAP) estimation to determinethe ultimate labeling L through Markov Random Field (MRF) inference. Using only the estimatedlikelihoods from the preceding section to categorize superpixels leads to imprecise classifications.Incorporating a smoothing term V(l<sub>s<sub>i</sub></sub>, l<sub>s<sub>j</sub></sub>) intothe MRF energy function aims to address this problem by penalizing adjacent superpixels withsemantically incongruous labels. The goal is to minimize the following energy function:",
  "(i,j)AV (lsi, lsj)(2)": "where A represents the set of neighboring superpixel indices and V(l<sub>s<sub>i</sub></sub>,l<sub>s<sub>j</sub></sub>) denotes the penalty for assigning labels l<sub>s<sub>i</sub></sub>and l<sub>s<sub>j</sub></sub> to two adjacent pixels, calculated from occurrences in the trainingset combined with the constant Potts model following established methods. is the smoothing constant.Inference is conducted using the -expansion method with established code.",
  "Improving Superpixel Label Costs": "Although foreground objects typically stand out the most in a picture of a scene, parsing algorithmsfrequently misclassify them. For instance, in an image of a city street, a person would usually firstspot the individuals, signs, and vehicles before they would see the structures and the street. However,because of two primary factors, scene parsing algorithms frequently misclassify foreground regionsas belonging to the surrounding background. Initially, in the superpixel classification phase, anyclassifier would naturally prefer classes that are more prevalent to reduce the overall training error.Secondly, during the MRF smoothing phase, a lot of the superpixels that were accurately identified asforeground objects are smoothed out by the background pixels around them. It is suggested that the label likelihood score at each superpixel be improved to obtain a more preciseparsing output. Various classifiers are designed that provide supplementary information regardingthe data. Subsequently, all the developed models are merged to produce a unified conclusion. Anoverview of the method for merging classifiers is displayed in . During the testing phase,the label likelihood scores from all the BDT models are combined to generate the final scores forsuperpixels.",
  "Fusing Classifiers": "The proposed method is inspired by ensemble classifier methods, which train several classifiers andmerge them to enhance decision-making. These methods are especially helpful when the classifiersare distinct. In other words, the decrease in error is connected to the lack of correlation between themodels that were trained. This means that the total error is decreased if the classifiers misclassifydifferent data points. Furthermore, it has been demonstrated that for large datasets, dividing thetraining set yields superior results compared to dividing the feature space. It has been observed that the classification error for a particular class is correlated with the averagenumber of pixels it covers in the scene images, as indicated by the blue line in . This is inline with what earlier methods found, which is that the rate of classification error is related to howoften classes show up in the training set. However, it goes beyond that by taking into account howoften the classes appear at the image level, which is meant to solve the problem of less-representedclasses being smoothed out by a background class that is nearby. To achieve this, three BDT models are trained using the following training data criteria: (1) a balancedsubsample of all classes C in the dataset, (2) a balanced subsample of classes that occupy an averageof less than z The goal of these decisions is to lessen the correlation between the trained BDT models, as seen in. The balanced classifiers are able to correctly identify some of the less-represented classes,but they make more mistakes on the more-represented classes. The unbalanced classifier, on theother hand, mostly misclassifies the less-represented classes. Combining the likelihoods from allthe classifiers leads to an improved overall decision that enhances the representation of all classes(). It was noticed that the addition of more classifiers did not enhance performance for any ofthe datasets.",
  "Scene-Level Global Context": "When working with scene parsing challenges, including the scenes semantics in the labeling processis beneficial. For example, if a scene is known to be a beach scene, labels such as sea, sand, and skyare expected to be found with a much greater probability than labels like car, building, or fence. Theinitial labeling results of a test image are used in estimating the likelihoods of all labels c C. Thelikelihoods are estimated globally over an image, i.e., there is a unique cost per label per image. Theglobal label costs are then incorporated into a subsequent MRF inference stage to enhance the results. The presented method, in contrast to previous methods, does not restrict the number of labels tothose found in the retrieval set. Instead, it utilizes the set to calculate the likelihood of class labelsin a k-nn manner. The likelihoods are normalized by counts over the entire dataset and smoothedto provide an opportunity for labels not present in the retrieval set. The likelihoods are also used inMRF optimization, not for reducing the number of labels.",
  "Context-Aware Global Label Costs": "It is proposed that semantic context be incorporated by using label statistics instead of global visualfeatures. The reasoning behind this decision is that sorting by global visual characteristics oftendoesnt find images that are similar at the scene level. For instance, a highway scene might bemistaken for a beach scene if road pixels are incorrectly classified as sand. Nonetheless, when given areasonably accurate initial labeling, sorting by label statistics finds images that are more semanticallyrelated. This helps to eliminate outlier labels and find labels that are absent in a scene. For a given test image I, minimizing the energy function in equation 2 produces an initial labelingL of the superpixels in the image. If C is the total number of classes in the dataset, let T C be theset of unique labels which appear in L, i.e. T = t | s<sub>i</sub> : l<sub>s<sub>i</sub></sub> = t,where s<sub>i</sub> is a superpixel with index i in the test image, and l<sub>s<sub>i</sub></sub>is the label of s<sub>i</sub>. Semantic context is exploited in a probabilistic framework, where theconditional distribution P(c|T) is modeled over class labeling C given the initial global labeling of animage T. P(c|T) c C is computed in a K-nn fashion:",
  "|S|(6)": "where K<sub>T</sub> is the K-neighborhood of initial labeling T, n(c, X) is the number of superpixelswith label c in X, n(c, X) is the number of superpixels with all labels except c in X, and |S| is thetotal number of superpixels in the training set. The likelihoods are normalized and a smoothingconstant of value 1 is added. To obtain the neighborhood K<sub>T</sub>, training images are ranked by their distance to thequery image. The distance between two images is determined by the weighted size of the intersectionof their class labels, which intuitively shows that the neighbors of T are images that share many labelswith those in T. A different weight is assigned to each class in T in a manner that gives preference toclasses that are less represented. The algorithm operates in three stages, as depicted in . It begins by (1) assigning a weight<sub>t</sub> to each class t T, which is inversely proportional to the number of superpixels in thetest image with label t: <sub>t</sub> = 1 - n(t,I)/|I|, where n(t, I) is the number of superpixels in thetest image with label l<sub>s<sub>i</sub></sub> = t, and |I| is the total number of superpixels in theimage. Then, (2) training images are ranked by the weighted size of intersection of their class labelswith the test image. Finally, (3) the global label likelihood L<sub>global</sub>(c) = P(c|T) of eachlabel c C is computed using equation 6. Calculating the label costs is performed in real-time for a query image, without the need for anyoffline batch training. The method enhances the overall precision by utilizing solely the true labels oftraining images, without incorporating any global visual characteristics.",
  "Experiments": "The experiments were conducted on two extensive datasets: SIFTflow and LMSun. SIFTflow consistsof 2,488 training images and 200 test images. All images are of outdoor scenes, sized 256x256 with33 labels. LMSun includes both indoor and outdoor scenes, with a total of 45,676 training imagesand 500 test images. Image sizes range from 256x256 to 800x600 pixels with 232 labels. The same evaluation metrics and train/test splits as in previous methods are employed. The per-pixelaccuracy (the percentage of pixels in test images that were correctly labeled) and per-class recognitionrate (the average of per-pixel accuracies of all classes) are reported. The following variants of thesystem are evaluated: (i) baseline, as described in section 3, (ii) baseline (with balanced BDT), whichis the baseline approach using a balanced classifier, (iii) baseline + FC (NL fusion), which is thebaseline in addition to the fusing classifiers with normalized-likelihood (NL) weights in section 4, and(iv) full, which is baseline + fusing classifiers + global costs. To show the effectiveness of the fusionmethod (section 4.2), the results of (v) baseline + FC (average fusion), which is fusing classifiers byaveraging their likelihoods, and (vi) baseline + FC (median fusion), which is fusing classifiers bytaking the median of their likelihoods are reported. Results of (vii) full (without FV), which is thefull system without using the Fisher Vector features are also reported.",
  "MethodPer-pixelPer-class": "Tighe and Lazebnick54.97.1Tighe and Lazebnick61.415.2Yang et al.60.618.0Baseline57.39.5Baseline (with balanced BDT)45.413.8Baseline + FC (NL fusion)60.014.2Baseline + FC (average fusion)60.511.4Baseline + FC (median fusion)59.214.7Full without Fisher Vectors58.213.6Full61.216.0 The performance of the system is analyzed when varying the number of trees T for training the BDTmodel (section 4.1), and the number of top training images K in the global label costs (section 5.1). shows the per-pixel accuracy (on the y-axis) and the per-class accuracy (on the x-axis) as afunction of T for a variety of Ks. Increasing the value of T generally produces better classificationmodels that better describe the training data. At T 400, performance levels off. As shown, theglobal label costs consistently improve the performance over the baseline method with no globalcontext. Using more training images (higher K) improves the performance through considering moresemantically relevant scene images. However, performance starts to decrease for very high values ofK (e.g., K = 1000) as more noisy images start to be added. shows the per-class recognition rate for the baseline, combined classifiers, and the fullsystem on SIFTflow. The fusing classifiers technique produces more balanced likelihood scores thatcover a wider range of classes. The semantic context step removes outlier labels and recovers missinglabels, which improves the recognition rates of both common and rare classes. Recovered classesinclude field, grass, bridge, and sign. Failure cases include extremely rare classes, e.g. cow, bird,desert, and moon.",
  "Running Time": "The runtime performance was analyzed for both SIFTflow and LMSun (without feature extraction)on a four-core 2.84GHz CPU with 32GB of RAM without code optimization. For the SIFTflowdataset, training the classifier takes an average of 15 minutes per class. The training process is runin parallel. The training time highly depends on the feature dimensionality. At test time, superpixelclassification is efficient, with an average of 1 second per image. Computing global label costs takes3 seconds. Finally, MRF inference takes less than one second. MRF inference is run twice for thefull pipeline. LMSun is much larger than SIFTflow. It takes 3 hours for training the classifier, lessthan a minute for superpixel classification per image, less than 1 minute for MRF inference, and 2minutes for global label cost computation.",
  "Discussion": "The presented scene parsing method is generally scalable as it does not require any offline trainingin a batch fashion. However, the time required for training a BDT classifier increases linearly withincreasing the number of data points. This is challenging with large datasets like LMSun. Randomlysubsampling the dataset has a negative impact on the overall precision of the classification results.Alternative approaches of mining discriminative data points that better describe each class are plannedto be investigated. The system still faces challenges in trying to recognize very less-representedclasses in the dataset (e.g., bird, cow, and moon). This could be handled via better contextual modelsper query image.",
  "Conclusion": "A novel scene parsing algorithm has been presented that enhances the overall labeling precision,without neglecting foreground classes that are significant to human viewers. By merging likelihoodscores from various classification models, the strengths of individual models have been successfullyamplified, thus enhancing both the per-pixel and per-class accuracy. To prevent the removal ofaccurate labels through image retrieval, global context has been integrated into the parsing processusing a probabilistic framework. The energy function has been expanded to incorporate global labelcosts that produce a more semantically relevant parsing output. Experiments have demonstratedthe superior performance of the system on the SIFTflow dataset and comparable performance tostate-of-the-art methods on the LMSun dataset."
}