{
  "Abstract": "This study examines distributed stochastic variational inequalities (VIs) withinunbounded domains, where the problem data is heterogeneous, meaning it is non-identically distributed and spread across numerous devices. We adopt a broadassumption regarding the computational network, which encompasses fully de-centralized computations with dynamic networks and the centralized structurescommonly employed in Federated Learning. Additionally, we allow multiple localupdates on the workers to reduce how often they communicate. We adapt thestochastic extragradient method to this versatile framework, and conduct theoreti-cal analysis on its convergence rate, specifically in strongly-monotone, monotone,and non-monotone scenarios (given that a Minty solution is available). The rateswe provide demonstrate a clear relationship with various network properties likemixing time, the number of iterations, data heterogeneity, variance, the quantityof devices, and other typical parameters. As a particular application, our methodand analysis can be used for distributed stochastic saddle-point problems (SPP),such as the training of Deep Generative Adversarial Networks (GANs), which isknown to be very difficult when using decentralized training. The experiments weperform for decentralized GANs training demonstrate the efficacy of our proposedapproach.",
  "Introduction": "In extensive machine learning (ML) situations, training data is often split among multiple deviceslike data centers or mobile devices. Decentralized training methods can produce an ML modelwith the same accuracy as if all data were on a single server. Moreover, decentralized training hasadvantages over traditional centralized methods including data ownership, privacy, fault tolerance, andscalability. Federated Learning (FL) is a decentralized learning approach where the training processis managed by a single device or server that communicates with all the participating clients. However,in fully decentralized learning (FD) scenarios, devices only communicate with their neighbors via acommunication network with an arbitrary structure. Therefore, decentralized algorithms are valuablewhen centralized communication is expensive, undesirable, or impossible. Recently, significant advances have been made in the creation, design, and understanding of decen-tralized training methods. In particular, aspects such as data heterogeneity, communication efficiency,which includes local updates or compression, and personalization have been explored. However,these advancements have focused on training with single-criterion loss functions, which lead tominimization problems, and are not applicable to more general types of problems. For instance,training Generative Adversarial Networks (GANs) requires the simultaneous competing optimizationof the generator and discriminator objectives, which translates to solving a non-convex-non-concavesaddle-point problem (SPP). This kind of problem structure makes GANs extremely challenging totrain, even in the single-node setting, let alone when training over decentralized datasets. This study centers around solving decentralized stochastic SPPs and, more broadly, decentralizedstochastic Minty variational inequalities (MVIs). In a decentralized stochastic MVI, data is distributed",
  "m=1fm(x, y)(2)": "The connection to VI can be seen by setting z = (x, y) and the gradient field F(z) = (xf(x, y), -yf(x,y)). In cases where f(x,y) is convex-concave, the operator F(z) is monotone. However, in the contextof GANs training, where x and y are parameters of the generator and discriminator, respectively, thelocal losses fm(x, y) are generally non-convex-non-concave in x, y, and monotonicity of F cannot beassumed. In this study, we develop a new algorithm for addressing problems (1) and (2). Because gradientdescent-ascent for problem (2) can diverge even in simple convex-concave settings with a singledevice, we use extragradient updates and combine them with a gossip-type communication protocolon arbitrary, possibly dynamic, network topologies. One challenge arising from communicationconstraints is a network error that stems from the inability of all devices to achieve exact consensus.Therefore, each device uses a local variable, with only approximate consensus among devicesachieved through gossip steps. Our method avoids multiple gossip steps per iteration, leading tobetter practical performance on dynamic networks. It also allows multiple local updates betweencommunication rounds to reduce communication overhead, making it suitable for communication-and privacy-restricted FL or fully decentralized scenarios.",
  "Our Contributions:": "1. We have created an algorithm that uses extragradient updates to tackle distributed stochas-tic MVIs, and consequently distributed stochastic SPPs, with heterogeneous data. Thisframework offers a flexible communication protocol that supports centralized settings likeFederated Learning, fully decentralized configurations, local steps in both centralized anddecentralized setups, and dynamic network topologies. 2. Using this general communication protocol, we have demonstrated the convergence of ouralgorithm in three MVI settings, namely where the operator is strongly-monotone, monotone,or non-monotone (assuming a Minty condition is met). The rates of convergence dependexplicitly on several problem parameters, such as network characteristics, data heterogeneity,data variance, number of devices, and other relevant factors. These theoretical resultstranslate directly to the corresponding SPP settings (strongly-convex-strongly-concave,convex-concave, and non-convex-non-concave under the Minty condition). All theoreticalresults are valid when using heterogeneous data, and allow quantifying how factors like dataheterogeneity, noise in the data, and network characteristics influence convergence rate. Wehave also shown that for decentralized settings, our results are novel for time-varying graphsand the three different monotonicity settings. 3. We have verified our theoretical results through numerical experiments and demonstrated theeffectiveness of our strategy in practice. Specifically, we have trained a DCGAN architectureon the CIFAR-10 dataset.",
  "Related Work": "Research on MVIs dates back to at least 1962, and has been continued in recent works. VIs areused in diverse applications: image denoising, game theory and optimal control, robust optimization,and non-smooth optimization using smooth reformulations. In ML, MVIs and SPPs arise in GANstraining, reinforcement learning, and adversarial training. The extragradient method (EGM) was first introduced and later expanded to include deterministicproblems and stochastic problems with bounded variance. However, if the stochastic noise is notuniformly bounded, EGM can diverge.",
  "Algorithm": "This section details our proposed algorithm (Algorithm 1) based on two main concepts: (i) the extra-gradient step (as seen in classical methods for VIs), and (ii) gossip averaging (used in decentralizedoptimization and diffusion strategies in distributed learning). Instead of using gradient descent, asin similar algorithms, ours uses the extragradient method. It is designed for VIs and SPPs. It alsoincludes local steps between communication rounds, supports dynamic networks, and comes withnon-asymptotic theoretical convergence guarantees. Each step of Algorithm 1 has two phases. The local phase (lines 46) involves a step of the stochasticextragradient method at each node using only local data. Nodes make an extrapolation step tolook into the future and then update using the operator value at the future point. Next is thecommunication phase (line 7), during which nodes share local iterates with their neighbors Nm in thecommunication network graph for each iteration k. Averaging is done using weights w k m,i, whichare matrix Wk elements called the mixing matrix. Definition 2.1 (Mixing matrix). A matrix W [0; 1]MM is a mixing matrix if it satisfies: 1) W issymmetric, 2) W is doubly stochastic (W1 = 1, 1TW = 1T, where 1 is the vector of all ones), 3) W isaligned with the network: wij 0 if and only if i = j or the edge (i, j) is in the communication networkgraph. Reasonable choices of mixing matrices include Wk = IM Lk /max(Lk), where Lk is the Laplacianmatrix of the network graph at step k and IM is the identity matrix, or by using local rules based onthe degrees of the neighboring nodes. Our setting offers great flexibility because the communicationgraphs topology can change between iterations. The matrix Wk, which encodes the current network,also changes. This is encoded in line 2, where Wk is generated using a rule Wk that can vary.Examples include the deterministic choice of a matrix sequence Wk or sampling from a dynamicprobability distribution on matrices. Local steps without communication can be encoded with adiagonal matrix Wk. Algorithm 1 Extra Step Time-Varying Gossip Methodparameters: stepsize> 0, {Wk}k0 rules or distributions for mixing matrix in iteration k.initialize: z0Z, m : z0 m = z01: for k = 0, 1, 2, . . . do2: Sample matrix Wk from Wk3: for each node m do4: Generate independently mk+1/3Dm5:zk+1/3 m = zk mFm(zk m, mk+1/3 )6: Generate independently mk+2/3Dm7:zk+1 =Wk m,i zk+1/38:zk+1/3end for9: end for",
  "K1/4 (14)": "The proof of the theorem can be found in the supplementary materials, where the dependence ofrates on the stepsize before optimal selection are given. In contrast to other analyses, our analysisaddresses the fact that problem (1) has no feasible bounded set, which is important for analysis inboth monotone and non-monotone settings. Furthermore, our algorithm includes a communicationstep that introduces a bias in the oracle, which needs to be analyzed over unbounded feasible sets.We overcome this by bounding the bias, and proving the boundedness in expectation of the sequenceof iterates for both monotone and non-monotone cases. We also analyze stochastic extragradientmethod with biased oracles on unbounded domains which has not been done before. We achieve thisunder a general Assumption 2.2, with time varying graphs and all three monotonicity settings. The convergence rates explicitly depend on the network, characterized by mixing time and mixingfactor p, and on data heterogeneity D, which appear only as the quantity , the variance 2, Lipschitzconstant L, strong monotonicity parameter , and the number of nodes M. These results help usdetermine how data heterogeneity, noise, and network characteristics influence convergence. Thisopens meta-optimization opportunities to design networks and set parameters such as M, , and p toimprove convergence. The convergence results presented in the theorem have a similar multi-term structure. The first termis from the deterministic case and mirrors existing methods for smooth VIs in a non-distributedsetting. The second term is stochastic and is also standard for the non-distributed setting. The leadingstochastic term is proportional to 2/M, decreasing with the number of nodes. Other terms representa consensus error, due to imperfect communication between nodes. In all the cases this does notworsen the convergence, because dependence on K is no worse than the stochastic term. Theorem 4.1 is given for a fixed iteration budget K, and corresponding stepsizes that depend on K,which is standard in literature. We also offer a procedure that allows extending the result to all-timeconvergence without a priori fixed K, by restarting the algorithm after K iterations, which are doubledeach time. In the strongly monotone case, our rate is slightly better than other results. The other methodsstepsize is limited asp/(L2), slowing convergence. For decentralized settings, our rate is worse,probably because Assumption 2.2 is more general, but our algorithm is more practical because itavoids multiple gossip steps per iteration and works with time-varying topologies. In the monotonecase, we use the Gap function as a measure of suboptimality. And in the non-monotone setting we areable to obtain convergence up to a certain accuracy. It is important to note that we use assumptionsabout iterates that we can obtain only when they are generated by the algorithm. We manage to obtaincorresponding results that can be used for establishing that the algorithm behaves nicely under certaininitial conditions. The experimental section will demonstrate these theoretical findings.",
  "To obtain stochastic gradients, unbiased Gaussian noise with variance 2 is added": "Convergence Behaviour. The convergence of Algorithm 1 with a fixed stepsize in both the strongly-monotone (a = 1) and monotone (a = 0) settings. In the strongly monotone setting we observe linearconvergence up to an error floor determined by the noise and problem parameters. The monotonecase converges more slowly, but is still linear up to a level. This is expected for bilinear problems. Wesee that when a constant stepsize is used in stochastic optimization algorithms, convergence is usuallylimited to a certain neighborhood, see Theorem 2 in a previous study. Theorem 4.1 also reflects this;convergence with zero error requires a diminishing stepsize. In the supplementary material, we alsovalidate with decreasing stepsize. We verify the dependence on the heterogeneity parameter D and set the noise 2 = 0. Based onthe theory, we expect that the error when = 0 scales as O(D2K2). We conduct experiments bysetting b = 1 and a = 1, and measuring how many iterations are needed for1M",
  "while varying D. The step size is tuned for every experiment": "The number of iterations scale as K 4, confirming that the error depends on K as O(K1/2).The middle plot shows that iterations scale proportionally to D (D K). Lastly, we see the numberof iterations to reach = 0.01 while varying the graph parameter p, and observe D p K. Thismeans that experiments confirm the O1pDK2term in the convergence rate.",
  "Training GANs": "Our method allows for combining communication graph topologies and local steps during distributedlearning. This section explores our method on GANs training. In Section A.1, we discuss therelevance of our theoretical results to GANs training. Data and model. We use the CIFAR-10 dataset which includes 60,000 images across 10 classes. Weincrease the dataset four times by adding transformations and noise, and simulate a distributed setup using 16 nodes on two GPUs with Ray. We create heterogeneity by splitting the dataset into 16subsets where a major class makes up 20% of the data and the rest is split uniformly between all theother classes. We use the DCGAN architecture, conditioned by class labels, similar to a previouspaper. We use Adam as the optimizer. We make one local Adam step and one gossip averaging stepwith time-varying matrices Wk, similarly to Algorithm 1.",
  "Conclusion": "We have developed an effective algorithm to solve decentralized stochastic MVIs and SPPs, assuminga highly flexible network topology and communication constraints. This method represents the firstdecentralized extragradient approach that supports local steps for dynamic network topologies. Wetheoretically demonstrated the convergence rate of the algorithm for SM, M, and NM cases. Innumerical experiments, we validated that the dependency on the data heterogeneity parameter D istight in the SM case and impossible to improve in general. By training DCGAN in a decentralizedmanner, we showed our methods effectiveness for practical DL tasks. Future work could extendthese algorithms to infinite-dimensional problems."
}