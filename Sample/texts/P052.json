{
  "Abstract": "Genetic programming (GP) is currently the leading method for automated feature generation in financial applica-tions. It utilizes reverse Polish notation to denote features and subsequently performs an evolutionary procedure.Nevertheless, with the advancements in deep learning, more effective feature extraction instruments have becomeaccessible. This research introduces the Alpha Discovery Neural Network (ADNN), a customized neural networkarchitecture designed to autonomously generate a variety of financial technical indicators using establishedknowledge. Our primary contributions are threefold. Firstly, we employ domain-specific expertise in quantitativetrading to formulate sampling guidelines and the objective function. Secondly, we substitute genetic programmingwith pre-training and model pruning techniques to enable a more streamlined evolutionary process. Thirdly, thefeature extraction components within ADNN can be interchanged with various other feature extractors, resultingin the creation of diverse functions. Empirical findings demonstrate that ADNN can produce more distinct andinformative features in comparison to GP, thereby effectively augmenting the existing pool of factors. Fullyconnected and recurrent networks demonstrate superior performance in extracting information from financialtime series compared to convolutional neural networks. In practical scenarios, the features generated by ADNNconsistently enhance the revenue, Sharpe ratio, and maximum drawdown of multi-factor strategies when contrastedwith investment strategies that do not incorporate these factors.",
  "Introduction": "Predicting the future returns of stocks is a paramount and demanding endeavor in the field of quantitative trading. Numerousfactors, including historical price, volume, and a companys financial information, can be employed to forecast the future returns ofstocks. Typically, researchers categorize features derived from price and volume as technical indicators, while those derived froma companys financial data are classified as fundamental data. Various well-known multi-factor models have been introduced toaddress this task, and numerous established technical and fundamental factors have been developed. For instance, the Fama-FrenchThree-Factor Model utilizes three crucial factors that furnish the majority of the information required to elucidate stock returns.Subsequently, the Fama-French Five-Factor Model and numerous other factors have been formulated by domain experts. Nonetheless,two limitations exist. Firstly, recruiting human specialists is quite costly. Secondly, humans are unable to create certain nonlinearfeatures from data with high dimensionality. Consequently, both academic scholars and institutional investors have increasinglyfocused on the task of automated financial feature engineering. Feature engineering is a procedure that uncovers the connections between features and expands the feature space by deducing orgenerating novel features. During this operation, new features can be created by combining pre-existing features. A more explicitexplanation is that algorithms employ operators, hyper-parameters, and existing features to construct a new feature. Occasionally,feature construction and feature selection can be integrated into a single process. These methodologies encompass wrapper, filtering,and embedded techniques. Filtering is straightforward but yields suboptimal results; it merely employs certain criteria to select afeature and can sometimes aid in overseeing the feature construction process. The wrapper method exhibits strong performanceby directly utilizing the models outcomes as an objective function. Consequently, it can treat an independently trained model asa newly generated feature. Nevertheless, a substantial quantity of computational resources and time are necessary. Embedded isan approach that employs generalized factors and a pruning method to choose or amalgamate features, serving as an intermediateoption between filtering and wrapper techniques.",
  "Related Work": "With the progression of deep learning, an increasing number of researchers are utilizing neural networks to derive features from rawdata and subsequently incorporating a fully connected layer to modify the features output. Similarly, a trained model signifies anewly developed feature. Researchers have leveraged it on pattern recognition tasks, employing a CNN model to construct facialdescriptors, and this method generates features that possess considerably more information than the previous method. Experiments have been conducted on this task, employing a deeper and wider convolutional neural network. Recurrent neural networks havebeen used to pre-locate feature-rich regions and successfully construct more refined features. In a text classification task, recurrentneural networks have been utilized to build a rule-based classifier among text data, wherein each classifier represents a portionof the text. A network structure that uses both a recurrent neural network and a convolutional neural network to extract textinformation has been proposed. Utilizing a neural networks robust fitting capability, we can generate highly informative features bycustomizing the network architecture for diverse industries. In financial feature engineering tasks, researchers have commencedemploying neural networks to provide an embedding representation of financial time series. More specifically, LSTM has beenutilized to embed various stock time series, followed by adversarial training to perform binary classification on a stocks futurereturn. Well-designed LSTM has been adopted to extract features from unstructured news data, subsequently forming a continuousembedding. The experimental outcomes indicate that these unstructured data can furnish substantial information and are highlybeneficial for event-driven trading. A Skip-gram architecture has been employed to learn stock embedding, inspired by a valuableknowledge repository formed by fund managers collective investment behaviors. This embedding can more effectively representthe varying affinities across technical indicators. Adopting a similar concept, we employ a neural network to provide a conciseembedding of extended financial time series.",
  "Methodology": "The ADNNs network architecture is structured in a specific way. The primary contributions of this innovative network structure are:1) ADNN employs Spearman Correlation as its loss function, mirroring the practices of human quantitative investment. Furthermore,the sampling guidelines adhere to economic principles. 2) A significant, derivable kennel function is introduced as a substitute forthe non-derivable operator. 3) We utilize pre-training and pruning in place of the GPs evolutionary process, resulting in enhancedefficiency. In each back-propagation cycle, ADNN randomly selects data from a certain number of trading days and subsequently computes theSpearman Coefficient between the factor value and factor return for each of those days. The number of days should be greater than 3,and incorporating information from multiple trading days enables the neural network to achieve a more consistent convergence.Quantitative investors prioritize the relative strength of each stock on a given trading day over its absolute strength. Therefore,performing calculations for each trading day and employing the Spearman Coefficient as the loss function is justifiable. We posit that there are a certain number of stocks pertaining to a given trading day in each batch. The input tensor has a specificshape because there are a certain number of samples, and five categories of time series: the opening price, high price, low price,closing price, and volume. Each time series has an input length. We also designate the output tensor as the factor value, possessing aparticular shape. The factor return tensor has a specific shape, denoting the profit we can obtain from this asset over an extendedduration. The holding periods length is defined. Here, we presume that all feature extractors are Multi-layer Perceptrons (MLPs),simplifying the provision of a general mathematical description. In the experimental section, we will present the experimentaloutcomes based on more intricate and varied feature extractors.",
  "Experiments": "We utilize daily trading data from the Chinese A-share stock market, encompassing the daily opening, high, low, closing prices, andtrading volume over the preceding 30 trading days. The raw data is standardized using its time-series mean and standard deviationderived from the training set. Both the mean and standard deviation are computed from the training set. We endeavor to employthese inputs to forecast the stock return for the subsequent 5 trading days (utilizing 3-15 trading days is advisable). Furthermore, wemust adhere to market regulations when devising a trading strategy. Extensive experiments have been performed to identify appropriate hyper-parameters. For each experiment, 250 trading daysconstitute the training set, the ensuing 30 trading days serve as the validation set, and the subsequent 90 trading days function as thetesting set. The generated factors maintain a high Information Coefficient (IC) throughout the subsequent 90 trading days. Mostsignificantly, we emphasize a counter-intuitive configuration: the training period should not surpass 250 trading days due to thenon-stationary nature of financial features. If we mandate a feature to function effectively over an extended duration, we will onlyencounter this feature in an over-fitting scenario. Consequently, we devise a rolling forecast framework wherein we automaticallyidentify potent features for each trading day. Each autonomously generated feature will have its own period of prominence on thatparticular trading day. Moreover, these factors not only perform effectively on this single day but also maintain their efficacy forseveral trading days, exhibiting a gradual decline. To ensure an equitable comparison, the identical configuration is implemented for the GP algorithm. The logic of this algorithmreferences related work. Moreover, the input datas period and type must be consistent. In this paper, we scrutinize the performanceof the constructed features from diverse angles. Typically, institutional investors employ the Information Coefficient (IC), toquantify the amount of information conveyed by a feature. For diversity, cross-entropy is utilized to gauge the distance between thedistributions of two distinct features on the same trading day.",
  "Results": "The network structure can equip ADNN with different deep neural networks. In order to show the general situation, we equip ADNNwith 4 fully-connected layers. Each layer has 128 neural, tanh activate function, L2 Regularization, and dropout technic. Thisgeneral and simple setting is enough to beat the GP. We put forward three schemes help to show how ADNN beat the GP. Only GPmeans only using genetic programming, Only ADNN means only use ADNN to construct factors, GP&ADNN means use GPsvalue to initialize ADNN and then construct factors. All the experiments are conducted out of the sample.",
  "Only GP0.09417.21GP&ADNN0.12225.44Only ADNN0.10721.65": "In real practice, we should leverage the constructed factors to form a multi-factor strategy and compare its performance with GP. Thespecific strategy setting is same as section 3.4, and we have repeated this experiment on different periods of time. The long-termbacktest result is shown in , Only ADNN always has better performance than the Only GP. It shows that ADNN has alsobeaten the SOTA in real practice. Similar to the conculsions made above, if we combine these two methods together, the combinedfactors strategy has the best performance in backtesting.",
  "TimeOnly GPGP&ADNNOnly ADNNZZ500": "Train:2015.01-2015.12 Test: 2016.02-2016.03+2.59%+5.74%+4.52%+1.67%Train:2016.01-2016.12 Test: 2017.02-2017.03+5.40%+10.26%+8.33%+2.53%Train:2017.01-2017.12 Test: 2018.02-2018.03-5.27%-4.95%-4.16%-6.98%Train:2018.01-2018.12 Test: 2019.02-2019.03+13.00%+15.62%+15.41%+13.75% All the results shown above is based on the most basic feature extractors. So will there be more powerful feature extractors todiscover knowledge from financial time series? And what is the suitable input data structure for financial time series? shows that, basically, all neural networks can produce more diversified features than using GP. But temporal extractors areespecially better at producing diversified features, such as LSTM and Transformer. As for TCN, the author who put forward thisnetwork structure proves its ability to capture the temporal rules buried in data. However, there is a huge difference. TCN relieson a convolution neural network, but LSTM and Transformer still contain recurrent neural networks (Normally, the transformeruses a recurrent neural network to embedded the input data). The existence of a recurrent neural network structure may contributeto the difference in diversity. For Le-net and Resnet, they dont provide us with more informative features. It looks like that theconvolution network structure is not suitable to extract information from the financial time series. : The higher are the information coefficient (IC) and diversity, the better is their performance. Normally, a good featureslong-term IC should be higher than 0.05, but it cannot be higher than 0.2 in an A-share market.",
  "TypeNetworkICDiversityTime": "BaselineGP0.07217.5320.215 hoursVanillaFCN0.12422.1510.785 hoursLe-net0.12320.1941.365 hoursSpatialResnet-500.10821.4033.450 hoursLSTM0.17024.4691.300 hoursTemporalTCN0.10521.1392.725 hoursTransformer0.11125.2574.151 hours In practical applications, we integrate conventional factors with those generated by ADNN to formulate a quantitative investmentstrategy. Our objective is to ascertain whether ADNN can enhance the factor pool and improve upon the traditional multi-factorstrategy. We establish a commonly employed multi-factor strategy to assess its performance in a real-world context. Within the training set,samples whose returns rank in the top 30% for each trading day are designated as 1, while those ranking in the bottom 30% arelabeled as 0. The remaining samples in the training set are discarded. Following the training of these features using XGBoost in binary logistics mode, the prediction outcome reflects the probability of a stock exhibiting exceptional performance in the subsequent5 trading days. It designates the 50 features constructed by human experts as PK 50, the features constructed by ADNN as New 50,and the features constructed by both GP and PK as GP-PK 50. In separate experiments, we use XGBoost to pre-train both PK 50and New 50 in the training set and then using the weight score from XGBoost to choose the 50 most important features as Combined50. This feature selection process only happens once, and only be conducted in training set.",
  "TypeTargetGroupRevenueMDSR": "ZZ500Stock Index19.60%13,50%1.982BaselineHS300Stock Index18.60%20.30%1.606PKPK 5024.70%18.90%2.314GP 5017.60%25.30%1.435GPGP-PK 5025.40%14.80%2.672New 5020.60%15.80%2.189VanillaFCNCombined 5029.60%15.70%3.167New 5018.00%16.90%1.800Le-netCombined 5027.50%16.40%2.921SpatialNew 5019.90%15.40%1.962Resnet-50Combined 5029.30%17.20%2.787New 5019.50%13.00%2.205LSTMCombined 5029.90%15.00%3.289TemporalNew 5022.40%14.70%2.440TCNCombined 5026.90%16.80%2.729New 5021.10%15.90%2.203TransformerCombined 5027.20%15.10%2.806 As shown in , HS300 and ZZ500 are important stock indices in the A-share stock market. Revenue represents the annualizedexcess return, by longing portfolio and shorting the index. The max drawdown is the worst loss of the excess return from its peak.The Sharpe ratio is the annually adjusted excess return divided by a certain level of risk. These indicators can show the strategysperformance from the perspective of both return and risk. For the New 50, although they have higher IC than the PK 50, their overall performance is not always better than PK 50. Because theoverall performance of a multi-factor strategy is determined by both diversity and information volume (IC), we guess the diversity ofPK 50 is remarkably higher than the diversity of New 50. We also did experiment to verify this guess. Thus, although every singlenew factor is better than the old factor, their overall performance not always be better. ADNNs diversity is larger than the GP, butfor further research, making ADNNs diversity even larger is still badly needed. In the real world use case, all investors have theirown reliable and secret factor pool, what they want is that the new constructed factors can bring in margin benefits. Thus, they willuse both new and old factors to do trading. Thats the reason why Combined 50 can represent ADNNs contribution in the realsituation. In all cases, Combined 50 is better than PK 50 and GP-PK 50, which means that the ADNN not only perform better thanGP, but also can enrich investors factor pool.",
  "Conclusion": "In this research, we introduce the Alpha Discovery Neural Network (ADNN), a system capable of autonomously generating financialfeatures from raw data. We have meticulously crafted its network architecture in accordance with economic principles and furnishedit with a variety of sophisticated feature extractors. Empirical results indicate that ADNN can generate features that are moreinformative and diverse than those produced by the benchmark method in this specific application. In practical scenarios, ADNN alsodemonstrates superior revenue, Sharpe ratio, and maximum drawdown compared to genetic programming. Furthermore, differentfeature extractors assume distinct roles. We have conducted numerous experiments to validate this observation and endeavor tocomprehend its functionality. For future research, we intend to employ this framework to automatically generate valuable featuresbased on companies fundamental data and sentiment data."
}