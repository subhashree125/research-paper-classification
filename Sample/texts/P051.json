{
  "Abstract": "This research introduces a method for real-time unsupervised domain adaptation(DA) that can be applied incrementally as new information arrives. This method isespecially useful when conventional batch DA is unfeasible. Through evaluationsfocused on part-of-speech (POS) tagging, we observe that real-time unsupervisedDA achieves accuracy levels on par with those of batch DA.",
  "Introduction": "Unsupervised domain adaptation is a frequently encountered challenge for developers aiming tocreate robust natural language processing (NLP) systems. This situation typically arises when labeleddata is available for a source domain, but there is a need to enhance performance in a target domainusing only unlabeled data. A majority of the current NLP research on unsupervised domain adaptationemploys batch learning, which presumes the availability of a substantial corpus of unlabeled datafrom the target domain before the testing phase. However, batch learning is impractical in numerousreal-world situations where data from a new target domain must be processed without delay. Further,in many practical scenarios, data may not be neatly categorized by domain, making it difficult toimmediately discern when an input stream begins providing data from a new domain. For instance, consider an NLP system within a company that is tasked with analyzing a continuousstream of emails. This stream evolves over time without any explicit signals indicating that thecurrent models should be adjusted to the new data distribution. Given that the system is expected tooperate in real-time, it would be beneficial for any system adaptation to be done in an online manner,as opposed to the batch method, which involves halting the system, modifying it, and then restartingit. This paper introduces real-time unsupervised domain adaptation as an enhancement to conventionalunsupervised DA. In this approach, domain adaptation is carried out incrementally as data is received.Specifically, our implementation involves a type of representation learning, where the focus is onupdating word representations in our experiments. Every instance a word appears in the data streamduring testing, its representation is refined. To our understanding, the research presented here is the first to examine real-time unsupervisedDA. In particular, we assess this method for POS tagging tasks. We analyze POS tagging outcomesusing three different methods: a static baseline, batch learning, and real-time unsupervised DA. Ourfindings indicate that real-time unsupervised DA performs comparably to batch learning, yet it doesnot require retraining or pre-existing data from the target domain.",
  "Experimental setup": "Tagger. We have adapted the FLORS tagger, which is recognized for its speed and simplicity,and is particularly effective in DA scenarios. This tagger approaches POS tagging as a multi-labelclassification problem within a window-based framework, rather than a sequence classificationone. FLORS is well-suited for real-time unsupervised DA because its word representations include distributional vectors, which can be updated during both batch learning and real-time unsupervisedDA. Each words representation in FLORS consists of four feature vectors: one for its suffix, one forits shape, and one each for its left and right distributional neighbors. Suffix and shape features arestandard in the literature, and we utilize them as described previously.",
  "xi = tf(freq(bigram(ci, w)))(1)": "where ci is the word with frequency rank i in the corpus, freq(bigram(ci, w)) is the occurrence countof the bigram \"ci w\", and non-zero frequencies are weighted logarithmically: tf(x) = 1 + log(x). Theright distributional vector is defined similarly. We limit the set of indicator words to the 500 mostfrequent. To avoid zero vectors, an additional element xn+1 is added to each vector to account foromitted contexts:",
  "where 2295 is vector concatenation. FLORS then tags token vi based on this representation": "FLORS operates under the assumption that the fundamental relationship between distributionalfeatures and labels remains consistent when transitioning from the source to the target domain. Thiscontrasts with other studies that select \"stable\" distributional features and discard \"unstable\" ones.The central hypothesis of FLORS is that fundamental distributional POS characteristics are relativelystable across different domains, unlike semantic or more intricate tasks. The effectiveness of FLORSsuggests the validity of this hypothesis. Data. Test set. Our evaluation utilizes the development sets from six different target domains (TDs):five SANCL domains (newsgroups, weblogs, reviews, answers, emails) and sections 22-23 of theWall Street Journal (WSJ) for in-domain testing.",
  "Two training sets of varying sizes are employed. In the l:big condition (large labeled data set), FLORSis trained on sections 2-21 of the WSJ. The l:small condition uses 10% of the l:big data set": "Data for word representations. We also adjust the size of the datasets used for computing wordrepresentations before training the FLORS model. In the u:big condition, distributional vectors arecomputed on the combined corpus of all labeled and unlabeled text from both source and targetdomains (excluding test sets), along with 100,000 WSJ sentences from 1988 and 500,000 sentencesfrom a large external corpus. In the u:0 condition, only labeled training data is utilized.",
  "BATCH. Before testing, count vectors are updated by freq(bigram(ci, w)) += freq*(bigram(ci, w)),where freq*(00b7) denotes the bigram \"ci w\" occurrences in the entire test set": "ONLINE. Before tagging a test sentence, both left and right distributional vectors are updated viafreq(bigram(ci, w)) += 1 for each \"ci w\" bigram appearance in the sentence. The sentence is thentagged using the updated word representations. As tagging progresses, distributional representationsbecome increasingly specific to the target domain (TD), converging to the representations that BATCHuses at the end of the tagging process.",
  "newsgroupsreviewsweblogsanswersemailswsjALLOOVALLOOVALLOOVALLOOVALLOOVALLOOV": "TnT88.6654.7390.4056.7593.3374.1788.5548.3288.1458.0995.7588.30Stanford89.1156.0291.4358.6694.1577.1388.9249.3088.6858.4296.8390.25SVMTool89.1453.8291.3054.2094.2176.4488.9647.2588.6456.3796.6387.96C&P89.5157.2391.5859.6794.4178.4689.0848.4688.7458.6296.7888.65S&S90.8666.4292.9575.2994.7183.6490.3062.1689.4462.6196.5990.37S&S (reimpl.)90.6865.5293.0075.5094.6482.9190.1861.9889.5362.4696.6089.70BATCH90.8771.1893.0779.0394.8686.5390.7065.2989.8465.4496.6391.86ONLINE90.8571.0093.0779.0394.8686.5390.6865.1689.8565.4896.6291.69 shows that the accuracy rates for ONLINE and BATCH methods are generally superiorto those of the STATIC method, as indicated by the numbers in bold. It also demonstrates thatperformance improves with an increase in both training data and unlabeled data. The performance of ONLINE is similar to that of BATCH. It is slightly lower than BATCH in theu:0 condition, with the most significant difference in accuracy being 0.29, and it is at most 0.02different from BATCH in terms of overall accuracy in the u:big condition. The reasons for ONLINEoccasionally outperforming BATCH, particularly in certain conditions, are discussed subsequently.",
  "Time course of tagging accuracy": "The ONLINE model introduced here has a unique characteristic not commonly found in otherstatistical NLP research: its predictive accuracy evolves as it processes text due to the modification ofits representations. To analyze the progression of these changes over time, a substantial application domain is necessarybecause subtle changes might be too inconsistent in the smaller test sets of the SANCL TDs. TheWSJ corpus is the only labeled domain that is sufficiently large for this purpose. Consequently, weinvert the usual setup by training the model on the development sets of the five SANCL domains(l:big) or on the initial 5000 labeled words of reviews (l:small). In this reversed setup, u:big utilizesthe five unlabeled SANCL datasets along with a large external corpus as before. Given the importanceof performance variability, we conduct 100 trials on randomly selected 50% samples of WSJ andreport both the average and standard deviation of tagging errors across these trials. The results presented in indicate that ONLINEs error rates are only marginally higher than,or comparable to, those of BATCH. Specifically, in the l:small/u:0 condition, the error rate for knownwords is lower for ONLINE (0.1186) than for BATCH, similar to observations in .",
  "u:0u:bigALLKNSHFTOOVALLKNSHFTOOV": "l:smallSTATIC87.0290.8771.1257.1689.0291.4881.5358.30ONLINE87.9990.8776.1065.6489.8492.3882.5867.09newsgroupsl:bigBATCH88.2891.0877.0166.3789.8292.3782.6567.03STATIC89.6993.0082.6557.8289.9392.4184.9458.97ONLINE90.5193.1382.5167.5790.8593.0484.9471.00BATCH90.6993.1283.2469.4390.8793.0385.2071.18 l:smallSTATIC89.0891.9666.5565.9091.4592.4780.1170.81ONLINE89.6792.1470.1469.6792.1193.6281.4678.42reviewsl:bigBATCH89.7992.2369.8671.2792.1093.6081.5178.42STATIC91.9693.9482.3067.9792.4293.5384.6569.97ONLINE92.3394.0383.5972.5093.0794.3685.7179.03BATCH92.4294.0983.5373.3593.0794.3685.7179.03 l:smallSTATIC91.5894.2979.9572.7493.4294.7789.8077.42ONLINE92.5194.5281.7680.4694.2195.4091.0884.03weblogsl:bigBATCH92.6894.6082.3481.2094.2095.4291.0383.87STATIC93.4595.6490.1572.6894.0995.5491.9076.94ONLINE94.1895.8289.8080.3594.8695.8192.6086.53BATCH94.3495.8590.0381.8494.8695.8292.6086.53 l:smallSTATIC86.9390.8966.5153.4388.9891.0977.6357.36ONLINE87.4891.1868.0756.4789.7192.4278.1164.21answersl:bigBATCH87.5691.1168.2558.4489.7192.4378.2364.09STATIC89.5492.7678.6556.2290.0692.1880.7058.25ONLINE89.9892.9779.0759.7790.6893.2181.4865.16BATCH90.1493.1079.0160.7290.7093.2281.5465.29 l:smallSTATIC85.4390.8557.8551.6587.7690.3570.8656.76ONLINE86.3091.2660.5655.8388.4592.3171.6761.57emailsl:bigBATCH86.4291.3161.0356.3288.4692.3271.7161.65STATIC88.3192.9871.3852.7189.2191.7473.8058.99ONLINE88.8693.0872.3857.7889.8593.3075.3265.48BATCH88.9693.1172.2858.8589.8493.3075.2765.44 l:smallSTATIC94.6495.4483.3882.7295.7395.8890.3687.87ONLINE94.8695.5385.3785.2295.8096.2189.8989.70wsjl:bigBATCH94.8095.4685.5185.3895.8096.2289.8989.70STATIC96.4496.8592.7585.3896.5696.7293.3588.04ONLINE96.5096.8593.5586.3896.6296.8993.3591.69BATCH96.5796.8293.4886.5496.6396.8993.4291.86 also includes data on \"unseens\" along with unknowns, as prior research indicates that unseenslead to at least as many errors as unknowns. Unseens are defined as words with tags not present inthe training data, and error rates for unseens are calculated across all their occurrences, includingthose with both seen and unseen tags. As shown in , the error rate for unknowns is higher thanthat for unseens, which in turn is higher than the error rate for known words. When examining individual conditions, ONLINE generally outperforms STATIC, showing betterresults in 10 out of 12 cases and only slightly underperforming in the l:small/u:big condition forunseens and known words (0.1086 vs. 0.1084, 0.0802 vs. 0.0801). In four conditions, ONLINE issignificantly better, with improvements ranging from 0.005 to over 0.06. The differences betweenONLINE and STATIC in the remaining eight conditions are minimal. For the six u:big conditions,this is expected as the large unlabeled dataset is from the news domain, similar to WSJ. Therefore, iflarge unlabeled datasets similar to the target domain are available, using STATIC tagging may sufficesince the additional effort for ONLINE/BATCH may not be justified.",
  "l:bigSTATIC.14512020.00114.1042.00100.0732.00052.0690.00042.0534ONLINE.1404.00125.10372217.00098.0727.00051.06892217.00051.0529BATCH.13822020.00140.1033.00112.0723.00065.0680.00062.0528": "Increasing the amount of labeled data consistently reduces error rates, as does increasing unlabeleddata. The differences are significant for ONLINE tagging in all six cases, marked by 2217 in thetable. There is no significant difference in variability between ONLINE and BATCH, suggesting thatONLINE is preferable due to its equal variability and higher performance, without requiring a datasetavailable before tagging begins. The progression of tagging accuracy over time is illustrated in . BATCH and STATICmaintain constant error rates as they do not adjust representations during tagging. ONLINEs errorrate for unknown words decreases, approaching BATCHs error rate, as more is learned with eachoccurrence of an unknown word.",
  "Related Work": "Online learning typically refers to supervised learning algorithms that update the model after process-ing a few training examples. Many supervised learning algorithms are online or have online versions.Active learning is another supervised learning framework that processes training examples 2014usually obtained interactively 2014 in small batches. All of this work on supervised online learning isnot directly relevant to this paper since we address the problem of unsupervised domain adaptation.Unlike online supervised learners, we keep the statistical model unchanged during domain adaptationand adopt a representation learning approach: each unlabeled context of a word is used to update itsrepresentation. There is much work on unsupervised domain adaptation for part-of-speech tagging, including workusing constraint-based methods, instance weighting, self-training, and co-training. All of this workuses batch learning. For space reasons, we do not discuss supervised domain adaptation.",
  "Conclusion": "This study introduces a method for real-time updating of word representations, a new form of domainadaptation designed for scenarios where target domain data are processed in a stream, makingBATCH processing unfeasible. We demonstrate that real-time unsupervised domain adaptationachieves performance levels comparable to batch learning. Moreover, it significantly reduces errorrates compared to STATIC methods, which do not employ domain adaptation."
}