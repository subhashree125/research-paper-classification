{
  "Abstract": "The limited capacity of deep networks to generalize beyond their training dis-tribution presents a significant challenge in semantic segmentation. Traditionalapproaches have operated under the assumption of a fixed model post-training,with parameters remaining constant during testing. This research introduces aself-adaptive methodology for semantic segmentation that modifies the inferencemechanism to accommodate each input sample individually. This adaptation in-volves two principal operations. First, it refines the parameters of convolutionallayers based on the input image, employing a consistency-based regularization.Second, it modifies the Batch Normalization layers by dynamically blending thetraining distribution with a reference distribution extracted from a single test sam-ple. Although these techniques are individually recognized in the field, theircombined application establishes new benchmarks in accuracy for generalizationfrom synthetic to real-world data. The empirical evidence from this study indicatesthat self-adaptation can effectively enhance deep network generalization to out-of-domain data, serving as a valuable complement to the established methods ofmodel regularization during training.",
  "Introduction": "State-of-the-art models in semantic segmentation exhibit a notable deficiency in robustness whenconfronted with out-of-distribution data, where the distributions of training and testing sets diverge.While numerous studies have examined this challenge, with a predominant focus on image classifica-tion, it has been observed that Empirical Risk Minimization (ERM), which presumes independent andidentically distributed training and testing samples, remains remarkably competitive. This contrastswith the evident advancements in domain adaptation for both image classification and semanticsegmentation. The domain adaptation setup, however, typically requires access to an unlabeledtest distribution during training. In the generalization scenario considered here, only a single testsample is accessible during inference, and no information sharing must occur between subsequenttest samples. This study investigates the generalization challenge in semantic segmentation, specifically fromsynthetic data to real-world scenarios, by employing an adaptive approach. Unlike prior researchthat has concentrated on modifying model architecture or training procedures, this work revises thestandard inference procedure using a technique derived from domain adaptation methods. Termedself-adaptation, this technique utilizes a self-supervised loss function to facilitate adaptation toindividual test samples through a limited number of parameter updates. In addition to these loss-basedupdates, self-adaptation incorporates feature statistics from the training data with those of the testsample within the Batch Normalization layers.",
  "Methodology": "In traditional inference, the parameters of the segmentation model are assumed to remain fixed. Incontrast, adaptive systems are capable of learning to specialize to their environment. Analogously,this study allows the segmentation model to update its parameters during inference. It is important tonote that this setup differs from domain adaptation scenarios, as the updated parameters are discardedafter processing each sample, aligning with the principles of domain generalization. The proposed approach creates mini-batches of images for each test sample using data augmentation.Starting with the original test image, a set of N augmented images is generated through multi-scaling,horizontal flipping, and grayscaling. These images form a mini-batch that is processed by the CNN.The resulting softmax probabilities are transformed back to the original pixel space using inverse",
  "affine transformations, producing multiple predictions for each pixel. The mean of these probabilitiesis computed along the mini-batch dimension for each class and pixel on the spatial grid": "A threshold value is computed from the maximum probability of every class to create a class-dependent threshold. For each pixel, the class with the highest probability is extracted. Low-confidence predictions are ignored by setting pixels with a softmax probability below the threshold toan ignore label, while the remaining pixels use the dominant class as the pseudo-label. This pseudoground truth is used to fine-tune the model for a set number of iterations using gradient descent withthe cross-entropy loss. After this self-adaptation process, a single final prediction is produced usingthe updated model weights. The weights are then reset to their initial values before processing thenext test sample, ensuring that the model does not accumulate knowledge about the entire target datadistribution. Batch Normalization (BN) has become an integral part of modern CNNs. Although originallydesigned to improve training convergence, it is now recognized for its role in model robustness,including domain generalization. During training, BN computes the mean and standard deviationacross the batch and spatial dimensions. The normalized features are derived using these statistics.At test time, it is common practice to normalize feature values with running estimates of the meanand standard deviation across training batches, rather than using test-batch statistics. This is referredto as train BN (t-BN). In the context of out-of-distribution generalization, the running statistics derived from the source datacan differ substantially from those computed using target images, a problem known as covariate shift.Domain adaptation methods often mitigate this issue by replacing source running statistics with thoseof the target, a technique known as Adaptive Batch Normalization (AdaBN). Recent studies havealso explored prediction-time BN (p-BN), which uses the statistics of the current test batch instead ofrunning statistics from training. This study assumes the availability of only a single target sample during inference. Alternatives likeAdaBN and p-BN are not directly applicable in this scenario. Instance Normalization (IN) layerscould replace BN layers, but this might lead to covariate shift issues, as sample statistics may onlyapproximate the complete test distribution. Additionally, such a replacement could interfere with thestatistics of activations in intermediate layers. Self-adaptive normalization (SaN) is proposed as a solution. It combines the inductive bias fromthe source domains running statistics with statistics extracted from a single test instance. Thesource mean and variance are averaged with sample statistics from the target domain, weighted bya parameter 1. This parameter represents the shift from the source domain ( 1 = 0) to a referencedomain ( 1 = 1). During inference, new mean and variance are computed using this weighted average,and these are used to normalize the features of the single test sample. This approach does not affectthe behavior of BN layers during training and applies only during testing.",
  "Experiments": "In this study, the evaluation protocol is revised to adhere to principles of robustness and generalization.The supplier has access to two data distributions: the source data for model training and a validationset for model validation. The generalization ability of the model is assessed on three distinct targetsets, providing an estimate of the expected model accuracy for out-of-distribution deployment. Thedatasets used are restricted to traffic scenes for compatibility with previous research. Source data for model training comes from two synthetic datasets, GTA and SYNTHIA, which offerlow-cost ground truth annotation and exhibit visual discrepancies with real imagery. The validation setused is WildDash, which is understood to be of limited quantity but bears a closer visual resemblanceto potential target domains. The model is evaluated on three target domains: Cityscapes, BDD, andIDD, chosen for their geographic diversity and differences in data acquisition. The average accuracyacross these target domains estimates the expected model accuracy. Additionally, the Mapillarydataset is used for comparison with previous works, although it does not disclose the geographicorigins of individual samples. The framework is implemented in PyTorch, and the baseline model is DeepLabv1 without CRF post-processing. The models are trained on the source domains for 50 epochs using an SGD optimizer witha learning rate of 0.005, decayed polynomially. Data augmentation techniques include random-size",
  "crops, random aspect ratio adjustments, random horizontal flipping, color jitter, random blur, andgrayscaling": "Experiments were conducted to investigate the influence of the parameter 1 in Self-adaptive Nor-malization (SaN) on segmentation accuracy and the Intersection over Union (IoU) for both sourcedomains (GTA, SYNTHIA) and all main target domains (Cityscapes, BDD, IDD). The optimal 1 wasdetermined based on the IoU on the WildDash validation set. The segmentation accuracy with thisoptimal 1 was reported, showing that SaN improves the mean IoU over both the established t-BNbaseline and the more recent p-BN. The improvement was consistent across different backbone archi-tectures and target domains. Additionally, model calibration, measured by the expected calibrationerror (ECE), was found to improve with SaN, which was competitive with the MC-Dropout methodand showed complementary effects when used jointly. Self-adaptation was compared to Test-Time Augmentation (TTA), which involves augmenting testsamples with flipped and grayscaled versions at multiple scales and averaging the predictions. Self-adaptation outperformed TTA by a clear margin, aligning with reported ECE scores and demonstratingthat self-adaptation effectively uses calibrated confidence to generate reliable pseudo-labels. Self-adaptation was compared with state-of-the-art domain generalization methods, showing consis-tent improvements over carefully tuned baselines, regardless of backbone architecture or source data.The method outperformed previous methods without modifying the model architecture or trainingprocess, altering only the inference procedure. A comparison with Tent, which also updates model parameters at test time but minimizes entropyinstead of using pseudo-labels, showed that self-adaptation outperformed Tent substantially. Thiswas demonstrated by training HRNet-W18 on GTA and comparing the IoU on Cityscapes, whereself-adaptation achieved a 7.5% improvement in IoU. The influence of the number of iterations for self-adaptation was investigated, showing that self-adaptation balances accuracy and inference time by adjusting iteration numbers and layer choices.It was found to be more efficient and accurate than model ensembles. Self-adaptation can trade offaccuracy vs. runtime by using fewer update iterations or updating fewer upper network layers. Hyperparameter sensitivity analysis revealed that self-adaptation is robust to the choice of hyperpa-rameters 1, 8, and 7. The optimal values were determined using the validation set, and the modelaccuracy declined moderately with deviations from these values. Qualitative results showed thatself-adaptation improves segmentation quality and reduces pathological failure modes. The integration of self-adaptation with state-of-the-art architectures like DeepLabv3+, HRNet-W18,HRNet-W48, and UPerNet with a Swin-T backbone demonstrated substantial improvements insegmentation accuracy across all target domains. Evaluation on the ACDC dataset, which includesadverse weather conditions, showed that self-adaptation outperformed the baseline by 13.57% onaverage. Additional qualitative results and failure cases were discussed, showing that self-adaptation canstruggle with cases of mislabeling regions with incorrect but semantically related classes. However,these failure cases were relatively rare, and the majority of image samples benefited from self-adaptation, with accuracy improvements of up to 35% IoU compared to the baseline.",
  "Results": "The empirical results demonstrate that self-adaptive normalization (SaN) consistently enhancessegmentation accuracy in out-of-distribution scenarios. For instance, when training on the GTAdataset and testing on Cityscapes, BDD, and IDD, SaN improved the mean IoU by 4.1% with ResNet-50 and 5.1% with ResNet-101 compared to the t-BN baseline. Furthermore, SaN outperformed themore recent p-BN method, showing improvements irrespective of the backbone architecture andthe target domain tested. In terms of calibration quality, measured by the expected calibration error(ECE), SaN not only improved the baseline but also showed competitiveness with the MC-Dropoutmethod, even exhibiting complementary effects when both methods were combined. Self-adaptation was found to outperform traditional Test-Time Augmentation (TTA) across bothsource domains (GTA, SYNTHIA) and three target domains (Cityscapes, BDD, IDD). Despite TTAimproving the baseline, self-adaptation provided a clear and consistent margin of 2.19% IoU on",
  "average. This aligns with the reported ECE scores, demonstrating that self-adaptation effectivelyexploits the calibrated confidence of predictions to yield reliable pseudo-labels": "In comparison to state-of-the-art domain generalization methods, self-adaptation showed substantialimprovements even over carefully tuned baselines. It outperformed methods like DRPC and FSDRon most benchmarks, despite these methods using individual models for each target domain andresorting to target domains for hyperparameter tuning. Self-adaptation achieved superior segmentationaccuracy without requiring access to a distribution of real images for training or modifying the modelarchitecture, unlike previous methods such as ASG, CSG, DRPC, and IBN-Net. The study also compared self-adaptation with Tent, which updates model parameters at test timeby minimizing entropy. Self-adaptation, which constructs pseudo-labels based on well-calibratedpredictions, substantially outperformed Tent. Specifically, when training HRNet-W18 on GTA andevaluating on Cityscapes, self-adaptation achieved a 7.5% improvement in IoU compared to Tentunder a comparable computational budget. Further analysis revealed that self-adaptation provides a flexible mechanism for trading off accuracyand runtime by varying the number of update iterations and the layers to adjust. It was found to bemore efficient and accurate than model ensembles. Hyperparameter sensitivity analysis indicated thatself-adaptation is robust to the choice of hyperparameters, with optimal values determined using thevalidation set. Qualitative results demonstrated that self-adaptation visibly improves segmentation quality, reducingartifacts and mislabeling compared to the baseline. The methods effectiveness was consistent acrossdifferent architectures, including DeepLabv3+, HRNet-W18, HRNet-W48, and UPerNet with aSwin-T backbone, showing substantial improvements in segmentation accuracy on all target domains.",
  "Conclusion": "The traditional learning principle of Empirical Risk Minimization (ERM) assumes independent andidentically distributed training and testing data, which often results in models that are not robust todomain shifts. To address this, a self-adaptive inference process was introduced, bypassing the needfor explicit assumptions about the test distribution. This study also outlined four principles for arigorous evaluation process in domain generalization, adhering to best practices in machine learningresearch. The analysis demonstrated that even a single sample from the test domain can significantly improvemodel predictions. The self-adaptive approach showed substantial accuracy improvements withoutaltering the training process or model architecture, unlike previous works. These results suggestthat self-adaptive techniques could be valuable in other application domains, such as panopticsegmentation or monocular depth prediction. While the presented self-adaptation method is not yet real-time, it offers a favorable trade-off betweenaccuracy and computational cost compared to model ensembles. Future research could explorereducing the latency of self-adaptive inference through adaptive step sizes, higher-order optimization,or low-precision computations. Overall, this work demonstrates the potential of self-adaptation toenhance model generalization and robustness in various applications."
}