{
  "Abstract": "This paper presents the Disentanglement-PyTorch library, which has been devel-oped to assist in the research, application, and assessment of novel variationalalgorithms. This modular library allows for independent and reliable experimen-tation across diverse variational methodologies, through the decoupling of neuralarchitectures, the dimensionality of the latent space, and training algorithms. Fur-thermore, the library manages training schedules, logging, and the visualizationof reconstructions and traversals in the latent space. It also provides evaluationof the encodings using various disentanglement metrics. Currently, the libraryincludes implementations of the following unsupervised algorithms: VAE, -VAE,Factor-VAE, DIP-I-VAE, DIP-II-VAE, Info-VAE, and -TCVAE. Additionally,conditional approaches such as CVAE and IFCVAE are also supported. This librarywas utilized in some Disentanglement Challenge, where it achieved a 3rd rank inboth the first and second phases of the competition.",
  "Introduction": "In the field of representation learning, two primary paths can be identified. One path concentrateson learning transformations that are specific to a given task, often optimized for particular domainsand applications. The other path involves learning the inherent factors of variation, in a mannerthat is both disentangled and task-invariant. The task of unsupervised disentanglement of latentfactors, where changes in a single factor shift the latent encoding in a single direction, representsan unresolved problem in representation learning. Disentangled representations offer significantadvantages across various domains of machine learning including few-shot learning, reinforcementlearning, transfer learning, and semi-supervised learning. This work introduces a library developedusing the functionalities of the PyTorch framework. This library has been designed to facilitate theresearch, implementation, and evaluation of new variational algorithms, with a specific emphasison representation learning and disentanglement. This library was created in conjunction with theDisentanglement Challenge of NeurIPS 2019. The Disentanglement-PyTorch library is publiclyavailable under the GNU General Public License.",
  "Unsupervised Objectives": "The library currently offers implementations of the following unsupervised variational algorithms:VAE, -VAE, -TCVAE, Factor-VAE, Info-VAE, DIP-I-VAE, and DIP-II-VAE. The algorithmsare incorporated as plug-ins to the variational Bayesian framework. They are specified by theirrespective loss terms. Consequently, if the loss terms from two learning algorithms (e.g., A and B)are compatible, they can be integrated into the objective function by setting the appropriate flag. Thisallows researchers to combine loss terms that optimize for related objectives.",
  "Conditional and Attribute-variant Objectives": "The library provides support for conditional methods such as CVAE, where extra known attributes (i.e.,labels) are utilized in both the encoding and decoding procedures. It also offers support for IFCVAE.This is a method that enforces certain latent factors to encode known attributes through a set of positiveand negative discriminators in a supervised manner. The librarys modular construction allows theuse of any of the previously mentioned unsupervised loss terms in conjunction with conditional andinformation factorization techniques. This allows for the encouragement of disentanglement acrossattribute-invariant latents.",
  "Experiments and Results": "The -TCVAE algorithm yielded the most effective disentanglement outcomes on the mpi3d realdataset during the second phase of the disentanglement challenge. Given the limited 8-hour timeframeallocated for training, the model was pre-trained on the mpi3d toy dataset. The model was trainedusing the Adam optimizer for a total of 90,000 iterations, with a batch size of 64. The value for the-TCVAE objective function was set at 2. The learning rate was initially set to 0.001. It was reducedby a factor of 0.95 when the objective function reached a plateau. The capacity parameter, C, wasincreased gradually from 0 to 25. The dimensionality of the z-space was set to 20. The encoder comprised 5 convolutional layers. The number of kernels increased gradually from 32 to256. The encoder concluded with a dense linear layer. This layer was used to estimate the posteriorlatent distribution as a parametric Gaussian. The decoder network included one convolutional layer.This was followed by 6 deconvolutional (transposed convolutional) layers. The number of kernelsgradually decreased from 256 down to the number of channels in the image space. ReLU activationswere used for all layers, except for the final layers of both the encoder and decoder networks. The performance of the model on unseen objects from the mpi3d realistic and mpi3d real datasets isshown in . The model consistently performed better on the mpi3d realistic and mpi3d realdatasets. This is despite the fact that the model was only pre-trained using the mpi3d toy dataset.",
  "[width=0.8]latenttraversalfigure": ": Latent factor traversal of the trained -TCVAE model on a random sample of the mpi3drealistic dataset. The disentanglement is not complete as some features are encoded in the same latentfactor. A latent space of size 20 was used, however, changes in the other 13 latent factors had noeffect on the reconstruction; thus, these feature-invariant factors were not included for brevity."
}