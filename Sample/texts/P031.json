{
  "Abstract": "Islamophobic language on online platforms fosters intolerance, making detectionand elimination crucial for promoting harmony. Traditional hate speech detectionmodels rely on NLP techniques like tokenization, part-of-speech tagging, andencoder-decoder models. However, Graph Neural Networks (GNNs), with theirability to utilize relationships between data points, offer more effective detectionand greater explainability. In this work, speeches are represented as nodes andconnect them with edges based on their context and similarity to develop the graph.A novel paradigm using GNNs to identify and explain hate speech towards Islam isintroduced. The model leverages GNNs to understand the context and patterns ofhate speech by connecting texts via pretrained NLP-generated word embeddings,achieving state-of-the-art performance and enhancing detection accuracy while pro-viding valuable explanations. This highlights the potential of GNNs in combatingonline hate speech and fostering a safer, more inclusive online environment.",
  "Introduction": "Detecting and eliminating hate speech on social media platforms is of utmost importance for thepromotion of harmony and tranquility in society. The escalating presence of hate speech specificallytargeting Islam or Muslim communities on online discussion platforms is a growing concern. Thisform of hate speech not only fosters an environment of intolerance and hostility but can also havesevere psychological impacts on individuals and communities, leading to real-world violence anddiscrimination. To address this issue, researchers have increasingly turned to advanced technologies; using text-processing approaches in AI. Natural Language Processing (NLP) techniques are frequently employedfor hate speech detection, with some offering severity assessment of hate speech. These methodsutilize sophisticated algorithms to analyse vast amounts of textual data, identifying patterns andfeatures indicative of hate speech. For instance, deep learning models, like recurrent neural networks(RNNs), can learn complex representations of text data, enabling them to detect subtle and context-dependent instances of hate speech. Modern NLP techniques, on the other hand, can enhance thesemodels by providing richer linguistic insights. Tokenization, part-of-speech tagging, and namedentity recognition are just a few NLP techniques that help in breaking down and understanding thetexts structure and meaning. Moreover, the integration of latest NLP model and transformers, likeBERT and GPT, has significantly improved the ability of models to understand context, sarcasm, andimplicit hate speech, which are often challenging to detect. Another interesting approach is to usehuman-centric perspectives of AI using some benchmark dataset. Researchers have tried to employ GNNs in hate speech classification, but still needs more focuson this area. Despite their potential, GNNs have not been actively employed for the purpose ofinterpretable identification of hate speech, particularly in Islamic contexts. Islamophobic contentoften exhibits close word choices and hate speakers from the same community, which GNNs canleverage to reveal and explain patterns, alongside impressive classification scores. A novel approach employing graph neural networks for the identification and explication of hatespeech directed at Islam (XG-HSI) is introduced. The dataset is pre-processed to focus on Islamiccontexts, utilize pretrained NLP models for word embeddings, establish connections between texts,and employ a series of graph encoders for hate speech target identification, which achieves state-of-the-art performance.",
  "Background": "Graph Neural Networks (GNNs) are powerful neural networks designed for processing non-Euclideandata organized in complex, interconnected graphs. Using their ability to utilize relations betweendifferent data points, GNNs have shown tremendous promise in text classification and detectiontasks. GNNs have the ability to enhance hate speech detection on social media by modeling complexrelationships between users and content, capturing contextual information from interactions. Theypropagate information across the network, identifying coordinated and evolving hate speech patterns.We also present a case study in to illustrate how incorporating related information enhancesthe process. A general bag of words-based approach to create graphs, without LLMs is adopted. By integratingwith pretrained NLP models, GNNs leverage contextual word embeddings to better understand thesubtleties of hate speech. This combined approach improves the accuracy, context-awareness, andadaptability of detection systems, making them more effective in identifying hate speech directed atIslam and potentially generalizing to other targeted groups.",
  "Notations": "Let a graph G = (V, E, X), where V represents nodes, E denotes edges. We also define N and M as thenumbers of nodes and edges, respectively. Each node v is associated with a feature xi 2208 RF , andthe node feature matrix for the entire graph is denoted as X 2208 RN 00d7F , where F represents thefeature vector length. In our approach, each content denotes a node, contextual similarity betweentwo nodes is denoted by an edge and word embeddings are node features of the graph. The taskinvolves a node classification task to detect hate speech and Islamophobic content.",
  "Data Pre-Processing": "Initially, the dataset was filtered to focus on hate speech targeting Islam. Next, pretrained NLP modelsis applied to the text to obtain word embeddings X as node features for all nodes V. Edges E aredetermined using cosine similarity between embeddings with a threshold of 0.725. Subsequently,GNN is applied for the classification task.",
  "x1 = Wx + b(1)": "Subsequently, x1 is passed into two initial graph encoders to aggregate neighborhood information,feature extraction, and yield x2, x3 utilizing G and concatenated to x23 (Equation 2,3, 4). Here inEquation 2, we aggregate features from a nodes local neighborhood, to learn different characteristics.In Equation 3 and 4, we use a semi-supervised learning on graph-structured data, employing anefficient variant of convolutional neural networks that operate directly on graphs.",
  "Graph Explanation": "GNNExplainer is used to derive explanations from the graph encoder network for interpreting theresults and find underlying relations and causation. It works by taking a trained GNN model andits predictions as input, and returns explanations in the form of compact subgraph structures andsubsets of influential node features. This model-agnostic approach can explain predictions of anyGNN-based model on various graph-based machine learning tasks, including node classification,link prediction, and graph classification. GNNExplainer formulates explanations as rich subgraphsof the input graph, maximizing mutual information with the GNNs predictions. It achieves thisby employing a mean field variational approximation to learn real-valued graph masks that selectimportant subgraphs and feature masks that highlight crucial node features. Through this process,GNNExplainer offers insights into the underlying reasoning of GNN predictions, enhancing modelinterpretability and facilitating error analysis.",
  "Baselines. The baseline models are: CNN-GRU, BiRNN, BiRNN-HateXplain, BERT, BERT-HateXplain. Mentioned HateXplain-based models are fine-tuned on HateXplain dataset": "Implementation Details. Hugging Face transformers library is used to get embeddings from pre-trained BERT (bert-base-uncased) and BiRNN. The model is trained for 200 epochs with a learningrate of 0.001, using Adam optimizer. The experimental results in show that our model achievesremarkable performance comparing to benchmarks with explaining occurring phenomenons.Weutilized a single layer for each type of GNN, with a maximum tokenization length of 512 in thetokenizer and length of BERT embeddings (F ) set to 128.",
  "Experimental Results": "shows the performance of various models in detecting hate speech, highlighting accuracy andMacro F1 metrics. Traditional models like CNN-GRU and BiRNN show lower performance, withBiRNN-HateXplain offering slight improvements. BERT-based models perform better, particularlyBERT-HateXplain. However, our proposed models, XG-HSI-BiRNN and XG-HSI-BERT, signifi-cantly outperform all others, with XG-HSI-BERT achieving the highest accuracy (0.741) and MacroF1 (0.747). These results demonstrate the superior effectiveness of our dual GNN approach in hatespeech detection.",
  "Graph Explanation Case Study": "For a given post, \"How is all that awesome Muslim diversity going for you native germans? Youhave allowed this yourselves. If you do not stand and fight against this. You get what you asked forwhat you deserve!\", the predicted classification was offensive towards Islam. As per the explainer,the neighbouring and self-tokens helped to classify this as offensive to Muslims are fight, Muslimdiversity, brooks, rish, donald, syrian, schultz, typed. The texts association of \"Muslim diversity\"with potential blame and its confrontational tone in phrases like \"stand and fight against this,\"combined with neighbouring tokens like syrians, brooks, syrians denoted negative sentiment.",
  "Discussion": "This study not only addresses the immediate challenge of identifying and explaining hate speechdirected at Islam but also recognizes the broader impact of hate speech propagation on onlineplatforms. The proliferation of Islamophobic language fosters intolerance, division, and hostilitywithin communities, perpetuating harmful stereotypes and prejudices. By leveraging GNNs in ourXG-HSI framework, we not only detect hate speech but also provide explanations for its occurrence,shedding light on the underlying factors driving such behaviour. GNNs excel in capturing complexrelationships and patterns within data, enabling them to effectively identify instances of hate speechand elucidate the contextual nuances surrounding them. By leveraging the inherent structure of socialnetworks and textual data, our approach offers a comprehensive understanding of how hate speechpropagates in online discourse. In future research, exploring the integration of multimodal data sources, such as images and videos,could enhance the robustness of hate speech detection models, particularly in detecting nuancedforms of Islamophobic content. Additionally, investigating the dynamic nature of online communitiesand incorporating temporal aspects into GNN architectures could provide deeper insights into theevolution of hate speech propagation and enable more proactive interventions to counter its spread.",
  "Conclusion": "Identifying and addressing Islamophobic hatred on social media is crucial for achieving harmonyand peace. This research presents a novel method using GNNs to detect hate speech towards Islam.Empirical findings demonstrate that our model achieves exceptional performance, significantlyoutperforming all others, with XG-HSI-BERT achieving the highest accuracy (0.741) and Macro F1(0.747). Explainability aspect of this approach is also very promising, as it provides insights intoboth correlations and causation. This further highlights the potential of GNNs in combating onlinehate speech and fostering a safer, more inclusive online environment.",
  "Limitations": "The limitations include the use of only one dataset, which, while sufficient for this initial exploration,should be expanded upon in future research to validate and extend our findings. Additionally, whileGraph Neural Networks (GNNs) are known to be computationally intensive, especially with large-scale datasets, the relatively limited number of hate speech keywords suggests that GNNs may stillbe highly effective. Furthermore, more efficient GNN training methods are now available, whichaddress some of the computational challenges in future applications.",
  "Ethical Implications": "Our work on using GNNs to detect hate speech targeting Islam carries significant ethical responsibili-ties. We focus on minimizing biases in the model to ensure fair treatment of all groups, emphasizingthe need for transparency in how the model arrives at its decisions. By using interpretable GNNmethods, we strive to provide clear explanations for the models classifications, allowing for greateraccountability. We also acknowledge the potential risks of misuse and take steps to prevent these,adhering to ethical guidelines that respect privacy and avoid unjust censorship.",
  "Societal Implications": "The societal impact lies in its potential to create a safer online environment by effectively identifyingand mitigating Islamophobic content. By enhancing the detection accuracy and providing clearexplanations for the identified hate speech, our model contributes to fostering more inclusive andrespectful online communities. Additionally, our work highlights the importance of combating digitalhate speech, which can lead to real-world harm. We aim to empower platforms and policymakerswith tools that uphold freedom of expression while curbing harmful rhetoric, thus promoting socialharmony and understanding.",
  "Potential Risks": "The application of our model presents several risks. One major concern is the potential for modelmisclassification, which could lead to false positives or negatives, impacting users unfairly. Addition-ally, there is a risk of over-reliance on automated systems, which might not capture nuanced contextsand could inadvertently suppress legitimate speech. Annotation errors can also induce bias, but aswe used a previously peer-reviewed benchmark dataset, we hope those type of concerns are alreadyaddressed."
}