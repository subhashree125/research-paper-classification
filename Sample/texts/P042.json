{
  "Abstract": "This paper introduces a novel semantic similarity metric designed for image regis-tration. Current metrics, such as Euclidean distance or normalized cross-correlation,primarily focus on aligning intensity values, which presents challenges when deal-ing with low contrast or noise. Our approach utilizes learned, dataset-specificfeatures to guide the optimization of learning-based registration models. In com-parisons with existing unsupervised and supervised methods across various imagemodalities and applications, our method demonstrates consistently superior regis-tration accuracy and faster convergence. Additionally, its learned noise invarianceresults in smoother transformations on lower-quality images.",
  "Introduction": "This paper delves into the significant area of deformable registration, an essential preprocessingstep in medical imaging. The primary objective is to ascertain anatomical correspondences betweenimages and determine geometric transformations, denoted as , for their alignment. The majorityof algorithmic and deep learning-based techniques achieve alignment by optimizing a similaritymeasure, D, and a -weighted regularizer, R, which are combined to form a loss function:",
  "L(I, J, ) = D(I , J) + R().(1)": "The alignment is critically evaluated by the similarity metric, D, which significantly impacts thefinal outcome. Common pixel-based metrics, such as Euclidean distance (MSE) and patch-wisenormalized cross-correlation (NCC), are used in both algorithmic and deep learning approaches toimage registration. Typically, a similarity measure for a particular task is selected from a small set ofmetrics, with no certainty that any of them is suitable for the data. The limitations of pixel-based similarity metrics have been extensively studied in the image generationfield, where the adoption of deep similarity metrics, designed to emulate human visual perception, hasenhanced the generation of highly realistic images. Because registration models are also generative,we anticipate that employing these similarity metrics could also improve registration results. However,current methods that use learned similarity metrics for image registration require ground truthtransformations, or they restrict the input to the registration model. We propose a data-driven similarity metric for image registration that relies on aligning semanticfeatures. Our metric uses learned semantic filters specific to the dataset, which are then used to traina registration model. We have validated our method using three biomedical datasets characterized byvarying image modalities and applications. Across all datasets, our approach achieves consistentlyhigh registration accuracy, even outperforming metrics that use supervised information. Our modelsalso demonstrate quicker convergence and learn to overlook noisy image patches, leading to moreconsistent transformations on lower-quality data.",
  "A Deep Similarity Metric for Image Registration": "To align areas with comparable semantic content, we propose a similarity metric based on theconsensus of semantic feature representations between two images. These semantic feature mapsare generated by a feature extractor, trained through a surrogate segmentation task. To capturethe alignment of both localized, specific features and more abstract, global ones, we compute thesimilarity across multiple layers of abstraction.",
  "Fl(I )pFl(J)p(2)": "where Fl(J)p denotes the l-th layer feature extractor applied to image J at spatial coordinate p. It isrepresented as a vector of Cl output channels, and the spatial size of the l-th feature map is denotedas |l|. The metric is influenced by the pixels neighborhood, since Fl uses convolutional filters withan expanding receptive area. Note that the formulation, using cosine similarity, mirrors the classicNCC metric, which can be interpreted as the squared cosine-similarity between two zero-mean patchdescription vectors. To improve registration, the functions Fl() should extract features that are semantically relevantto the registration task, while ignoring noise and artifacts. This is achieved by training the featureextractor on an additional segmentation task, since segmentation models excel at learning pertinentkernels while also achieving invariance to features like noise that are not predictive. The convolutionalfilters obtained act as feature extractors for DeepSim.",
  "Experiments": "We evaluated registration models trained with DeepSim against baseline metrics such as MSE,NCC, NCCsup (NCC using supervised information), and VGG (a VGG-based metric used in imagegeneration, similar to our approach). The model architecture is shown in . For bothregistration and segmentation, we used U-nets. The registration network predicts the transformation based on two input images, I and J. The spatial transformer module applies to obtain themorphed image I . The loss function is as in Eq. 1; we chose the diffusion regularizer for R andfine-tuned the hyperparameter on the validation sets. To demonstrate the broad applicability of our method across various registration tasks, we assessed itusing three datasets of both 2D and 3D images with different image modalities: T1-weighted Brain-MRI scans, human blood cells from the Platelet-EM dataset, and cell tracking from the PhC-U373dataset. Each dataset was divided into training, validation, and testing subsets.",
  "indicates p<0.001 statistical significance with effect size > 0.8": "Registration Accuracy Convergence: We evaluated the mean Srensen-Dice coefficient on theunseen test set () and tested the statistical significance of the results using the Wilcoxonsigned-rank test for paired samples. The null hypothesis for each similarity metric was that the model trained with DeepSim would perform better. Statistical significance levels were set at p = 0.05,p = 0.01, and p = 0.001. Additionally, we used Cohens d to measure the effect size. Modelstrained with our proposed DeepSim were ranked highest on both the Brain-MRI and Platelet-EMdatasets, exhibiting strong statistical significance. In the PhC-U373 dataset, all models achieved ahigh dice-overlap exceeding 0.97. DeepSim converged faster than the baseline models, particularlyduring the initial training epochs. Qualitative Examples Transformation Grids: We display the fixed and moving images, I andJ, along with the transformed image I , for each similarity metric model in (a), and amore detailed view of a noisy patch from the Platelet-EM dataset in (b). The transformationis shown using grid-lines, which were transformed from an evenly spaced grid. We observedconsiderably distorted transformation fields in noisy image areas in models trained with the baselines.Specifically, models trained with NCC and NCCsup demonstrated highly irregular transformations,despite the careful adjustment of the regularization hyperparameter. The model trained with DeepSimshowed greater invariance to noise.",
  "Discussion and Conclusion": "Registration models trained with DeepSim show substantial registration accuracy across multipledatasets, which improves downstream medical analysis and diagnostics. The reliability of ourproposed metric reduces the need for testing multiple traditional metrics. Instead of experimentallydetermining whether MSE or NCC best captures the properties of a dataset, DeepSim can be used tolearn the appropriate features from the data. The analysis of noisy patches in (b) highlights an inherent resistance to noise. Pixel-basedsimilarity metrics are influenced by artifacts, leading to excessively detailed transformation fields,which DeepSim does not exhibit. Although smoother transformation fields can be achieved forall metrics by increasing the regularizer, this would negatively affect the registration precision ofanatomically important areas. Accurate registration of noisy, low-quality images allows for shorteracquisition times and reduced radiation in medical applications. DeepSim is a general metric that can be applied to image registration across all modalities andanatomies. Beyond the presented datasets, good results on low-quality data suggest that DeepSimcould improve registration accuracy in lung CT and ultrasound imaging, where details are difficult toidentify, and image quality is often compromised. Furthermore, DeepSim is not restricted to deeplearning; algorithmic image registration follows a comparable optimization structure where similarity-based loss is minimized through gradient descent methods. Applying DeepSim in algorithmicmethods can improve their performance by aligning deep, semantic feature embeddings.",
  "Broader Impact": "The widespread applications of medical image registration significantly amplify the broader impactof our work. Some of the typical applications include neuroscience, CT imaging of the lungs andabdomen, as well as the fusion and combination of different modalities. The use of deep learning for image registration, while capable of achieving remarkable outcomesacross many different applications, often necessitates the training of models using specializedhardware over extended periods. This energy-intensive task may raise carbon emissions, which area major contributor to climate change. By introducing a method that learns a semantic similaritymetric directly from data, we hope to eliminate the need for excessive testing of other loss functions.This can reduce the number of model configurations tested during the development of deep learningmethods, thus contributing to a lower environmental impact within the image registration community."
}