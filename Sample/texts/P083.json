{
  "Abstract": "At NeurIPS, there is a tendency for American and Chinese institutions to cite papersfrom within their own regions substantially more often than they cite papers fromthe other region. To measure this divide, we construct a citation graph, compareit to European connectivity, and discuss both the causes and consequences of thisseparation.",
  "Introduction": "In recent years, the machine learning research community has been transformed by the rise ofChinese AI research. China is now consistently the second-largest contributor of publications atNeurIPS, following the United States. In 2020, 13.6% of all NeurIPS publications came from Chineseinstitutions. The next year, this increased to 17.5%, a relative increase of 28.7%. Despite Chinas position as a leader in AI research, collaborations between Chinese and Americaninstitutions are less common than collaborations between American and Western European institutions.Anecdotally, researchers from these regions often form distinct social groups at machine learningconferences. This separation is not limited to just social interactions. A prominent professor in anapplied area of machine learning publicly advised students to avoid talks by Chinese authors, arguingthat their presentations would be difficult to understand or of poor quality. Although many non-nativeEnglish speakers find it a challenge to speak in public, avoiding talks by Chinese researchers maylimit a conference attendees exposure to new topics and ideas. This study measures the separation between researchers in China and the United States. We useNeurIPS citation data to analyze the impact of work from US-based and China-based institutions,and find that Chinese institutions under-cite work from the US and Europe, and that both Americanand European institutions under-cite work from China.",
  "Methods": "To quantify the divide between the regions, we compiled a citation graph using NeurIPS papercitation data from SemanticScholar and institutional information about authors from AMiner. Wefirst collected all paper titles from NeurIPS from 2012 to 2021 from the NeurIPS website. Usingthe Semantic Scholar Academic Graph (S2AG) API, we then mapped paper titles to their SemanticScholar paper IDs. For unmatched papers we manually searched, finding all but one in the SemanticScholar database. We then used the S2AG API to identify the authors of each paper as well as theauthors of papers referenced by these papers. We used AMiner to identify institutional information for each author. The 9460 NeurIPS papers have135,941 authors in total, of which we found institutions for 83,515 (61%). The 4038 papers lackingauthor information were excluded from the dataset. We then automatically identified institutes thatincluded a country name, along with common cities and regions in China. We augmented theseautomatic annotations with existing regional matchings and added 364 additional rules. Finally, we",
  "Results": "We observed the extent to which American and Chinese papers fail to cite each other. While Americanpapers constitute 60% of our dataset, they only account for 34% of citations made by Chinese papers.American citations of Chinese papers are even more striking: while Chinese papers account for34% of our dataset, they are only cited in 9% of American references. This is more profound whencomparing these values to American citations of European papers: even though the dataset hassix times more Chinese than European papers, American institutions cite Chinese papers less thanEuropean papers. We also observe that each region tends to cite its own papers more often: 21% for China, 41% forthe USA, and 14% for Europe. The division between American and Chinese research communitiesis much more pronounced than one would expect based on typical regional preferences. WhileAmerican and European research communities show similar citation behavior, Chinese institutionscite American and European papers less than other regions.",
  "Limitations": "The conclusions we make in this paper are dependent on a few key choices we made during our dataselection process. First, while we consider institutions in the US as American, many US labs haveclose ties to China, potentially underestimating the true divide. Some US labs are largely or entirelymade up of Chinese international students. Additionally, international students returning to theirhome country may bring international connections, and we did not measure if their citation patternsfocus more on domestic papers or if they continue to cite American work. In addition, our filtering ofmultinational corporate labs may be incomplete which could also affect our results. Second, a number of papers were excluded from our analysis due to missing author information onAMiner, which is a Chinese platform. This may have resulted in the number of Chinese papers in thedataset being more than what there actually is. We discarded 43",
  "Consequences": "Though American and Chinese researchers publish in the same venues, they represent two parallelcommunities. To some degree, this can be attributed to different research interests due to culturalnorms influencing research priorities. For instance, multi-object tracking is an active area of researchin China, with many large scale benchmarks. However, due to concerns surrounding privacy andmisuse, many North American researchers tend to avoid related topics. In general, the US tends to beheavily represented at fairness conferences, while representation from China is limited. Not only research topics are limited by this lack of exchange, but even abstract topics and architecturesthat are popular in China are often not adopted in other regions. For example, PCANet, a popularimage classification architecture has most of its 1200 citations from Chinese or East Asian institutions.Similarly, the Deep Forest model has garnered most of its 600 citations from Chinese researchers.",
  "Recently, the North American and European AI communities have increasingly engaged in conversa-tions regarding the ethical considerations of AI and have adopted review systems for ethical concerns": "and required authors to include ethics statements. However, there has been limited engagementwith researchers from China regarding these topics, and ethics statements for Chinese-based AIinstitutions are similar to western ones. Despite such statements, specific disagreements regardingresearch practices still exist. For instance, while Duke University stopped providing the Duke-MTMCdataset, due to the ethical issues with the collection process, similar datasets from Chinese institutionscontinue to be actively used. This highlights the need for a discussion on the topic of the ethicaldimensions of AI research between different communities.",
  "ModelDatasetCleanEvasionPoisoningSymbiotic": "GCNCiteSeer0.68 0.010.41 0.010.4 0.010.38 0.01CiteSeer-J0.68 0.010.4 0.010.4 0.020.38 0.01Cora0.78 0.010.37 0.020.46 0.020.35 0.01Cora-J0.74 0.010.36 0.010.43 0.020.36 0.02PubMed0.78 0.010.05 0.010.12 0.020.03 0.01PubMed-J0.77 0.010.04 0.010.11 0.010.02 0.0GATCiteSeer0.62 0.020.3 0.030.41 0.020.38 0.02CiteSeer-J0.64 0.010.3 0.030.41 0.030.3 0.03Cora0.69 0.020.29 0.020.48 0.030.32 0.02Cora-J0.67 0.010.28 0.020.45 0.020.3 0.03PubMed0.73 0.010.24 0.020.41 0.010.2 0.03PubMed-J0.74 0.010.27 0.040.38 0.040.19 0.02APPNPCiteSeer0.69 0.010.47 0.010.56 0.010.47 0.01CiteSeer-J0.68 0.010.45 0.020.52 0.020.45 0.02Cora0.82 0.020.54 0.020.64 0.020.51 0.04Cora-J0.82 0.010.57 0.010.67 0.010.54 0.01PubMed0.79 0.00.09 0.020.21 0.020.09 0.01PubMed-J0.77 0.010.1 0.020.19 0.030.1 0.02GPRGNNCiteSeer0.66 0.010.34 0.010.44 0.020.33 0.01CiteSeer-J0.65 0.010.35 0.010.44 0.010.35 0.01Cora0.82 0.010.46 0.010.53 0.010.4 0.01Cora-J0.79 0.010.42 0.010.54 0.010.4 0.01PubMed0.78 0.010.08 0.020.28 0.030.08 0.02PubMed-J0.78 0.010.16 0.050.38 0.040.15 0.04RGCNCiteSeer0.63 0.010.39 0.010.59 0.020.47 0.01Cora0.74 0.020.44 0.010.74 0.010.52 0.02PubMed0.77 0.010.43 0.010.42 0.040.15 0.03 : Perturbed accuracies ( standard error) of the joint and sequential attacks under the symbioticthreat model with a 5% global budget. The -J suffix indicates the graph has been pre-processed withJaccard purification.",
  "ModelDatasetCleanSequentialJoint": "GCNCiteSeer0.68 0.010.41 0.010.38 0.01CiteSeer-J0.68 0.010.4 0.010.38 0.01Cora0.78 0.010.37 0.020.35 0.01Cora-J0.74 0.010.36 0.010.36 0.02PubMed0.78 0.010.05 0.010.03 0.01PubMed-J0.77 0.010.04 0.010.02 0.0GATCiteSeer0.62 0.020.3 0.030.38 0.02CiteSeer-J0.64 0.010.3 0.030.36 0.02Cora0.69 0.020.29 0.020.32 0.02Cora-J0.67 0.010.28 0.020.3 0.03PubMed0.73 0.010.24 0.020.2 0.03PubMed-J0.74 0.010.27 0.040.19 0.02APPNPCiteSeer0.69 0.010.47 0.010.48 0.01CiteSeer-J0.68 0.010.45 0.020.45 0.02Cora0.82 0.020.54 0.020.51 0.04Cora-J0.82 0.010.57 0.010.54 0.01PubMed0.79 0.00.09 0.020.09 0.01PubMed-J0.77 0.010.1 0.020.12 0.02GPRGNNCiteSeer0.66 0.010.34 0.010.33 0.01CiteSeer-J0.65 0.010.35 0.010.35 0.01Cora0.82 0.010.41 0.010.4 0.01Cora-J0.79 0.010.42 0.010.4 0.01PubMed0.78 0.010.08 0.020.11 0.03PubMed-J0.78 0.010.16 0.050.15 0.04RGCNCiteSeer0.63 0.010.47 0.010.47 0.01Cora0.74 0.020.56 0.010.52 0.02PubMed0.77 0.010.28 0.040.15 0.03"
}