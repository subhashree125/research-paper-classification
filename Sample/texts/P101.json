{
  "Abstract": "This paper presents a methodology for identifying disease characteristics frommedical imaging data using 3D volumes, which have weak annotations. Thisapproach converts 3D volumes into sequences of 2D images. We show the efficacyof our method when detecting emphysema using low-dose CT images taken fromlung cancer screenings. Our method uses convolutional long short-term memory(LSTM) to sequentially \"scan\" through an imaging volume to detect diseases withinspecific areas. This structure enables effective learning by using just volumetricimages and binary disease labels, facilitating training with a large dataset of 6,631unannotated image volumes from 4,486 patients. When evaluated on a testingset of 2,163 volumes from 2,163 patients, our model detected emphysema withan area under the receiver operating characteristic curve (AUC) of 0.83. Thismethod outperformed both 2D convolutional neural networks (CNN) using dif-ferent multiple-instance learning techniques (AUC=0.69-0.76) and a 3D CNN(AUC=.77).",
  "Introduction": "This paper addresses the critical challenge of developing deep learning-based computer-aided diag-nosis (CAD) systems in radiology, which is often limited by the need for large, annotated medicalimage datasets. It is particularly difficult to acquire manual annotations from radiologists, whichis required to train deep models, especially for 3D imaging techniques like computed tomography(CT). As a result, it is frequently unfeasible to use a model trained using a large, labeled dataset. Thedetection of emphysema, a disease associated with shortness of breath and an elevated risk of cancer,is one such area. Emphysema is frequently observed as ruptured air sacs within a small portion ofthe lung volume. The wide range of manifestations in CT scans makes training a model to detectemphysema using solely volumetric imaging data and binary diagnostic labels difficult. A common strategy to enable learning without precise labels is multiple instance learning (MIL). InMIL, sets of samples are organized into labeled bags, with a positive label indicating the existenceof positive samples within the bag. Prior research has effectively used a MIL framework to identifyemphysema and other lung disorders on CT scans. It has been demonstrated that MIL, when usedwith a handcrafted feature-based classifier to analyze a number of 2D patches from the lung, canidentify emphysema and other lung diseases. More recently, researchers reported positive results ingrading emphysema by summarizing the results of a convolutional neural network (CNN) across aset of 2D patches using a proportional method similar to MIL. A drawback of MIL-based techniques is their failure to maintain inter-sample relationships. For in-stance, MIL does not retain the spatial relationship between samples collected from an image, despitebeing successful in summarizing data from a number of samples. Furthermore, the effectivenessof MIL depends on the pooling strategy used to summarize predictions across the bag, a variablethat can greatly affect the instances in which a model succeeds or fails. For example, a maximumpooling-based approach considers only the single sample with the strongest correlation to disease,",
  "disregarding any data from the bags other samples. On the other hand, a mean pooling of predictionswithin a bag may fail to detect a disease present in only a small number of samples": "Recurrent neural networks, such as long short-term memory (LSTM), are highly adept at identifyingcorrelations between connected samples, such as in pattern recognition across time series data.Convolutional long short term memory (Conv-LSTM) expands this capability to spatial data byapplying convolutional operations to an LSTM. Conv-LSTM has been highly successful in identifyingchanges in image patterns over time, including applications like video classification and gesturerecognition. Instead of utilizing Conv-LSTM to identify spatiotemporal patterns from time seriesimage data, we suggest using it to \"scan\" through an imaging volume for the presence of diseasewithout the need for expert annotations of the diseased regions. Our framework allows for theidentification of emphysema-related image patterns on and between slices as it processes the imagevolume, unlike an MIL-based technique. The network stores emphysema-related image patternsthrough several bidirectional passes through a volume and produces a final set of characteristics thatdescribe the full volume without the requirement for a possibly reductive bag pooling operation.Our method can make effective use of readily available, but weak, image labels (such as a binarydiagnosis of emphysema as positive or negative) for abnormality identification inside image volumes.",
  "Dataset and Processing": "A total of 8,794 non-contrast CT volumes from 6,648 unique participants in the National LungScreening Trial (NLST) were used. We classified 3,807 CT volumes from 2,789 participants whowere diagnosed with emphysema during the three years of the study as positive samples, and 4,987 CTvolumes from 3,859 participants who were not diagnosed with emphysema in any of the three yearsas negative samples. 75% of these scans, with a balanced distribution of emphysema-positive andemphysema-negative patients, were utilized for model training. 4,197 volumes from 3,166 patientswere used to directly learn model parameters, while 2,434 volumes from 1,319 patients were usedto fine-tune hyper-parameters and assess performance in order to select the best-performing model.The remaining 2,163 volumes (578 emphysema positive, 1,585 emphysema negative), each from aunique patient, were held out for independent testing. Volumes were resized to 128x128x35, whichcorresponds to an average slice spacing of 9 mm.",
  "Convolutional Long Short Term Memory (LSTM)": "The architecture includes four units, each consisting of convolution operations applied to each sliceindividually and a conv-LSTM to process the volume slice by slice. Two 3x3 convolutional layerswith batch normalization are followed by max-pooling. The output of the convolutional layers foreach slice is then processed sequentially by the conv-LSTM layer in either forward or reverse order.This outputs a set of features collected through convolutional operations using both the current sliceand previous slices within the volume. All layers within a unit have the same number of filtersand process the volume in either ascending or descending order. The four convolutional units havethe following dimensionality and directionality: Ascending 1: 32 filters, Descending 1: 32 filters,Ascending 2: 64 filters, Descending 2: 64 filters. The final Conv-LSTM layer produces a single set offeatures that summarizes the networks results after processing the full imaging volume multiple times.Finally, a fully-connected layer with sigmoid activation calculates the probability of emphysema. Thenetwork, as illustrated in , contains a total of 901,000 parameters. All models were trainedfor 50 epochs or until validation set performance stopped improving.",
  "Comparison Experiments": "Multiple Instance Learning: We developed an MIL-based network in which each slice of the CTvolume was treated as a sample from a bag. We implemented a solely convolutional network designsimilar to the one shown in , but with more single-slice convolutional layers instead ofconv-LSTM layers, to achieve this. Various methods for summarizing predictions across the entirevolume into a single bag probability were investigated. The following methods can be used tocompute the overall probability, P, for a bag containing N samples with an individual probability ofemphysema, pi, i 1, ..., N:",
  ". Product Pooling: P = 1 Ni=1(1 pi)": "3D CNN: Conv-LSTM was also compared to a 3D CNN with a similar structure to the 2D CNN usedwith MIL, with the exception of a single dense layer and no pooling action on the final convolutionallayer. The number of kernels for each comparison model was raised to make its number of parametersroughly comparable to that of our Conv-LSTM framework and ensure a fair comparison ().",
  "Results": "Convolutional-LSTM demonstrated high accuracy in the detection of emphysema when trainedusing only weakly annotated imaging volumes, achieving an AUC of 0.82. It outperformed a CNNwith MIL, regardless of the pooling strategy (Max pooling: AUC=0.69, Mean Pooling: AUC=0.70,Product pooling: AUC=0.76). At the optimal operating point corresponding to the Youden Index, ourmodel achieved a sensitivity of 0.77 and a specificity of 0.74. The results for all evaluated models inthe testing set are shown in .",
  ": Emphysema detection results in the testing set (2,219 CT volumes) and model size": "Our method eliminates the need for manual processing or time-consuming annotation of imagingdata. Our framework makes it possible to train for disease detection using simple binary diagnosticlabels, even when the disease is confined to a small area of the image. As a result, our networkcan be trained easily using information that can be gathered automatically by mining radiologyreports. This significantly increases the amount of volumetric imaging data that can be used forthis kind of application and enables easy retraining and fine-tuning of an algorithm when used in adifferent hospital. This strategy can be used in other disease/abnormality detection problems outsideof emphysema when the amount of volumetric imaging data accessible is greater than the capacity ofradiologists to offer manually drawn ground truth, but when labels may be readily retrieved fromradiology reports."
}