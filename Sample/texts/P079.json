{
  "Abstract": "We introduce OmniPrint, a synthetic data generator for isolated printed charactersdesigned to support machine learning research. While being inspired by populardatasets, such as MNIST, SVHN, and Omniglot, OmniPrint provides the uniqueability to produce a wide range of printed characters from various languages, fonts,and styles, with custom distortions. OmniPrint includes 935 fonts from 27 scripts,and supports many types of distortions. As a demonstration of its functionality, wepresent several use cases, including an example of a meta-learning dataset designedfor a machine learning competition. OmniPrint is publicly available at a specifiedgithub link.",
  "Introduction and Motivation": "Benchmarks and shared datasets have helped propel progress in machine learning. One popularbenchmark is MNIST, used worldwide in tutorials, textbooks, and classes. Many variants of MNISTexist, including Omniglot, which includes characters from several different scripts. Since DeepLearning techniques rely heavily on data, as there is an increasing number of datasets, more, largerdatasets are required. Since collecting and labeling data can be time-consuming and expensive,artificial data generation can be used to drive ML research. This motivates the creation of OmniPrint,an extension of Omniglot, specifically designed for the generation of printed characters. Our focus is on classification and regression problems, where a vector y, which is composed of eitherdiscrete or continuous labels, is to be predicted using an input vector x of observations, which inthe case of OmniPrint, is an image of a printed character. Additionally, data are often affected bynuisance variables z, which are discrete or continuous labels that represent metadata or covariates.For our work, z may include character distortions such as shear, rotation, line width variations, orbackground changes. Thus, a data generation process with OmniPrint contains the following steps: Z P(Z),Y P(Y |Z),X P(X|Z, Y ).In many domains such as image, video, sound, and text applications, where objects or conceptsare target values to be predicted from percepts, Z and Y are independent and hence P(Y |Z) =P(Y ). This type of data generation is also encountered in medical diagnoses of genetic disease, forwhich x would be a phenotype and y a genotype, and also analytical chemistry where x might bechromatograms and y would be compounds to be identified. We expect that progress made usingOmniPrint to benchmark machine learning systems should foster progress in these domains. Character images represent excellent benchmarks for machine learning, given their simplicity, andvisual nature, and for enabling the development of real-world applications. However, our explorationof available resources revealed that there is no synthesizer that fulfills all of our needs. No availablesynthesizer allows for the generation of realistic small-sized images, supports a wide variety ofcharacter sets, and offers control over the variation of realistic conditions through parameters.The synthesizer must support pre-rasterization manipulation of anchor points, post-rasterizationdistortions, seamless background blending, foreground filling, anti-aliasing rendering, and be easilyextensible with new fonts and styles.",
  "Overview": "OmniPrint builds on the open-source software TextRecognitionDataGenerator, adapting it to ourspecifications. The software is designed to allow researchers to generate data in a form that makesit easier to train machine learning models. To obtain a large number of classes (Y labels), wemanually selected and filtered characters from the Unicode standard, forming alphabets for over 20languages. These alphabets are divided into partitions (e.g., Oriya consonants). Nuisance parameters(Z) are divided into Font, Style, Background, and Noise. The fonts are selected by an automaticfont collection module. We added a feature using the FreeType rasterization engine which enablesvector-based pre-rasterization transformations. Additionally, we enriched background generationwith seamless blending, and enabled custom post-rasterization transformations. We also implementedutility code including dataset formatters, and a data loader which generates episodes for meta-learningapplications. To our knowledge, OmniPrint is the first text image synthesizer geared toward MLresearch to support pre-rasterization transforms.",
  "FreeType vector representation: Text, font, and style parameters are used by the FreeTyperasterization engine": "Pre-rasterization transformed character: FreeType performs all the pre-rasterization(vector-based) transformations. Pre-rasterization manipulations include linear transforms,stroke width variation, random elastic transformation, and variation of character proportion.The RGB bitmaps output by FreeType are called the foreground layer. Pixel character on white background: Post-rasterization transformations are applied tothe foreground layer. The layer is kept at a high resolution, using ReLU activations, to avoidartifacts. The RGB image is then resized using a three step process; applying a Gaussianfilter to smooth the image, reducing the image by an integer factor, and resizing usingLanczos resampling."
}