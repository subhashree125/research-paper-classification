{
  "Abstract": "A number of psychological and physiological evidences suggest that early visualattention works in a coarse-to- fine way, which lays a basis for the reverse hierarchytheory (RHT). This theory states that attention propagates from the top level ofthe visual hierarchy that processes gist and abstract information of input, to thebottom level that processes local details. Inspired by the theory, we develop acomputational model for saliency detection in images. First, the original imageis downsampled to different scales to constitute a pyramid. Then, saliency oneach layer is obtained by image super-resolution reconstruction from the layerabove, which is defined as unpredictability from this coarse-to-fine reconstruction.Finally, saliency on each layer of the pyramid is fused into stochastic fixationsthrough a probabilistic model, where attention initiates from the top layer andpropagates downward through the pyramid. Extensive experiments on two standardeye-tracking datasets show that the proposed method can achieve competitiveresults with state-of-the-art models.",
  "Introduction": "Human vision system can selectively direct eyes to informative and salient parts of natural scenes.This ability allows adaptive and efficient allocation of limited computational resources to importantobjects. Though enjoying great potential in various applications of computer vision, predicting eyefixations, however, remains a challenging task. The underlying difficulty inherits from the ambiguousnotion of what attracts eye fixations, or what is salient. In fact, the theoretical investigation of visualsaliency has aroused enduring controversies. One possible explanation often adopted in the design ofsaliency detection approaches is the Feature Integration Theory (FIT). According to FIT, attentionserves as a mechanism to coherently combine features for the perception of objects. Therefore,starting from , eye fixations are commonly predicted by directly conjoining saliency activations frommultiple channels, which can be global and local channels, multiple features and so on. Anatomical and physiological studies have shown that human visual system is organized hierarchically,which is believed to be advantageous in efficient processing of visual input. Computational studieshave shown that hierarchical models (e.g. HMAX, CDBN) are effective for object recognition. Mostsaliency detection models, however, do not seriously take this into account. An obvious methodto fill this gap is to develop hierarchical bottom-up models for saliency detection in the mannerof HMAX, CDBN and the like. But there exists theoretical alternatives. The Reverse HierarchyTheory (RHT) argues that parallel feedforward feature activation acts implicitly at first to construct acoarse gist of the scene, while explicit perception incrementally incorporates fine details via feedbackcontrol. This theory potentially has tremendous applications in computer vision including imagesegmentation, object recognition and scene understanding, however, computational studies are scarce.In this paper, we present an effective model based on RHT for saliency detection, which proves thatRHT is helpful at least in this particular computer vision application. As for this application, a moredirect evidence for the proposed model refers to a psychophysical study which showed that fixationsfrom low-resolution images could predict fixations on higher-resolution images.",
  "Related Work": "The majority of computational attention modeling studies follow the Feature Integration Theory.In particular, the pioneering work by first explored the computational aspect of FIT by searchingfor center-surround patterns across multiple feature channels and image scales. This method wasfurther extended through integration of color contrast, symmetry, etc. Random Center SurroundSaliency adopted a similar center-surround heuristic but with center size and region randomly sampled.introduced a graph-based model that treated feature maps as fully connected nodes, while the nodescommunicated according to their dissimilarity and distance in a Markovian way. Saliency wasactivated as the equilibrium distribution. Several saliency models adopted a probabilistic approach and modeled the statistics of image features.and Baldi defined saliency as surprise that arised from the divergence of prior and posterior belief.SUN was a Bayesian framework using natural statistics, in which bottom-up saliency was defined asself-information. proposed an attention model based on information maximization of image patches.defined the saliency by computing the Hotellings T-squared statistics of each multi-scale featurechannel. considered saliency in a discriminative setting by defining the KL-divergence betweenfeatures and class labels. A special class of saliency detection schemes was frequency-domain methods. proposed a spectralresidual method, which defined saliency as irregularities in amplitude information. explored the phaseinformation in the frequency domain with a Quaternion Fourier Transform. Recently, introduced asimple image descriptor, based on which a competitive fast saliency detection algorithm was devised. Different from our proposal, the conventional practice in fusing saliency at different image scales andfeature channels was through linear combination. proposed a model that combined a global saliencymodel AIM and a local model through linear addition of normalized maps. Some models learned thelinear combination weights for feature channels. trained a linear SVM from human eye fixation datato optimally combine the activation of several low-, mid- and high-level features. With a similar idea,adopted a regression-based approach. Our model is characterized by a top-down flow of information. But it differs from most existingsaliency detection models that incorporate top-down components such as in two aspects. First, abiased prior (e.g., context clues, object features, task-related factors) is often needed in those models,serving as the goal of top-down modulation, which is not necessary in our model. Second, hierarchicalstructure of the visual cortex is not considered in those models, but plays a significant role in ourmodel. Nevertheless, there were a few preliminary studies trying to make use of the hierarchical structure forsaliency detection and attention modeling. The Selective Tuning Model was such a model. It wasa biologically plausible neural network that modeled visual attention as a forward winner-takes-allprocess among units in each visual layer. A recent study used hierarchical structure to combinemulti-scale saliency, with a hierarchical inference procedure that enforces the saliency of a region tobe consistent across different layers.",
  "Saliency from Image Super-Resolution": "In this section, a coarse-to-fine saliency model based on image super-resolution is presented. Weconsider an image at two consecutive scales in an image pyramid: a coarse one Il and a fine oneIh. Inspired by RHT, we define saliency as details in Ih that are unpredictable from Il. In the nextsection, we discuss how to fuse saliency on each layer of the pyramid into fixation estimate.",
  "Saliency as Unpredictability": "Predicting Ih using the information of Il is closely related to image super-resolution, which hasbeen extensively studied using techniques including Markov random field, example-based learning,compressive sensing, etc. In patch-based representation of images, the problem is to predict a high-resolution H H patch xh Ih from its low-resolution L L counterpart xl Il. For convenienceof notation, we also use xh and xl as H2 and L2 dimensional vectors, which are computed byreshaping the corresponding patches. Then xl is obtained by blurring and downsampling xh:xl = GBxh,(1) where B denotes a H2 H2 blurring matrix (throughout the paper a Gaussian matrix is used) and Grepresents a L2 H2 downsampling matrix. Let zh denote the reconstructed patch by some methodA, which summarizes the best knowledge one can recover from the coarse perception of xl, via A.The reconstruction error of zh from xh, naturally represents the fine-scale information that cannot berecovered. Therefore, we define saliency S(xh|xl) as the Normalized Mean Square Error (NMSE):",
  "Coarse-to-Fine Reconstruction": "The reconstruction from the coarse scale subject to the constraint (1) is actually not well-defined, sincegiven a low-resolution patch xl, there exists an infinite number of possible high-resolution patchesxh. To resolve this issue, the basic idea is to incorporate some prior knowledge, which inherits fromthe properties of natural images. In what follows we discuss several possible reconstruction schemeswith increasingly sophisticated prior knowledge. Linear Reconstruction (LR). Consider a trivial case: the coarse patch xl = Bxh, is just the blurredversion and we do nothing but output zh = xl. Therefore, no prior is used in this case. Saliency canbe computed according to (2). As shown in , this method assigns more saliency to patchescontaining many high-frequency components like edges and textures. Bicubic Interpolation (BI). If we reconstruct xh using bicubic interpolation, then we utilize asmoothness prior in image interpolation. Although this approach concentrates less on edges than thelinear reconstruction, its prediction is still far from the ground truth. See . With LR or BI, the saliency computed in (2) is the normalized l2-norm of the Laplacian pyramid. Inaddition, the two techniques can be used to implement the center-surround strategy adopted in somesaliency models, e.g. . Compressive Sensing (CS). We now consider a more sophisticated prior of image structure sparsity.According to this prior, any patch xh of a high-resolution image can be sparsely approximated by alinear combination of items in a dictionary Dh:xh Dh,(3) for some sparse coefficients that satisfies ||||0 K for some small K. Assuming is sparse,the theory of compressive sensing states that can be recovered from sufficient measurementsxl = GBxh by solving the following optimization problem:min ||||0subjectto||Dl xl|| < ,(4) where Dl = GBDh, denotes the blurred and downsampled dictionary Dh, and is the allowed errortolerance. This is hard to solve, and in practice the following relaxed problem is often solved:min ||||1subjectto||Dl xl|| < .(5)",
  "The coefficients are then used to reconstruct zh byzh = Dh.(6)": "Once we have obtained zh, saliency of the image patch can be computed using (2). Preliminaryresults in indicate that the saliency obtained by compressive sensing can largely differ fromthat obtained by LR and BIL. The dictionaries Dh and Dl are constructed as follows. For each scale of the image pyramid, wefirst uniformly sample raw patches {dj}nj=1 of size H H (n > H2), and stack them into a high-resolution dictionary Dh = [d1, d2, ..., dn]. Then we apply the blurring matrix B and downsamplingmatrix G to each dj, to obtain dj = GBdj. So Dl = [d1, d2, ..., dn] is the collection of correspondinglow-resolution patches. The use of overcomplete raw patches for Dh and Dl has been shown effectivefor image super-resolution.",
  "A saliency map M is obtained by collecting patch saliency defined in (2) over the entire image. First,calculateM[i, j] = S(xh[i, j]|xl[i, j]),(7)": "where xh[i, j] is the patch centered at pixel (i, j) in the image and xl[i, j] is its low-resolution version.Then M is blurred with a Gaussian filter and normalized to be between to yield the final saliencymap M. One should not confuse this Gaussian filter with B in Sections 3.1 and 3.2.",
  "Generating Fixations": "We model attention as random variables A0, A1, ..., An on saliency maps M0, M1, ..., Mn, which areordered in a coarse-to-fine scale hierarchy. Specifically, let Pr[Ak = (i, j)] denote the probability forpixel (i, j) attracting a fixation. To define this probability, we need to consider factors that influencethe random variable Ak. First of all, the saliency map Mk is an important factor. Pixels with highervalues should receive more fixations. Second, according to RHT, attention starts from M0, and thengradually propagates down along the hierarchy. Therefore, Ak should also depend on Ak1, ..., A0.For simplicity, we assume that only Ak1 has an influence on Ak while Ak2, ..., A0 do not.",
  "for k = 1, ..., n. A log-linear model is used for this conditional probabilityPr[Ak = (i, j)|Mk, Ak1] exp(Mk[i, j] + L(Ak, Ak1)),(9)": "where L(Ak, Ak1) is a spatial coherence term, and are two constants. The spatial coherenceterm restricts the fixated patches to be close in space. The motivation of introducing this termcomes from the fact that the visual system is more likely to amplify the response of neurons that iscoherent with initial perception. To compute the term, we first convert the coordinate Ak1 into thecorresponding coordinate (u, v) in the saliency map just below it, i.e. Mk. Then computeL(Ak, Ak1) = ((i u)2 + (j v)2).(10) In other words, the farther away a patch x is from Ak1, the less likely it would be attended by Ak.Therefore, for predicting the fixation probability of any patch in the current layer, the model makes atradeoff between the spatial coherence with previous attention and its current saliency value.",
  "If we do not consider any prior on the top layer, Pr[A0] depends on the saliency map onlyPr[A0 = (i, j)] exp(M0[i, j]).(11)": "We can then generate fixations via an ancestral sampling procedure from the probability model.Specifically, we first sample fixation A0 on map M0 according to (11), and then for k = 1, 2, ...sample Ak on map Mk given Ak1 on the coarser scale according to (9). Finally, we collect allsamples on the finest scale, and use them as prediction of the eye fixations.",
  "Experiment Settings": "Datasets. The performance of the proposed reverse hierarchy model (RHM) was evaluated on twohuman eye-tracking datasets. One was the TORONTO dataset. It contained 120 indoor and outdoorcolor images as well as fixation data from 20 subjects. The other was the MIT dataset, whichcontained 1003 images collected from Flicker and LabelMe. The fixation data was obtained from 15subjects. Parameters. The raw image I in RGB representation was downsampled by factors of 27, 9, 3 toconstruct a coarse-to-fine image pyramid. The patch size for super-resolution was set as 9 9 oneach layer. To construct corresponding coarse patches, we used Gaussian blurring filter B ( = 3)and downsampling operator G with a factor of 3. A total of 1000 image patches were randomlysampled from all images at the current scale to construct the dictionary Dh, which is then blurred anddownsampled to build Dl.",
  "In some experiments, we included a center bias in the model. This is achieved by switching from 0to 1 in (12)": "Note that the reverse propagation described in (8)-(11) is a stochastic sampling procedure and weneed to generate a large number of fixations to ensure unbiased sampling. We found that 20000 pointson each image were enough to achieve good performance, which was adopted in all experiments.The stochastic points were then blurred with a Gaussian filter to yield the final saliency map. Thestandard deviation of the Gaussian filter was fixed as 4 pixels on saliency maps, which was about 5 Evaluation metric. Several metrics have been used to evaluate the performance of saliency models.We adopted Area Under Curve (AUC), Normalized Scanpath Saliency (NSS) and Similarity (S).Specifically, We used the AUC code from the GBVS toolbox, NSS code from and Similarity codefrom . Following , we first matched the histogram of the saliency map to that of the fixation mapto equalize the amount of salient pixels in the map, and then used the matched saliency map forevaluation. Note that AUC was invariant to this histogram matching. Models for comparison. The proposed model was compared with several state-of-the-art models:Itti Koch, Spectral Residual Methods (SR), Saliency based on Information Maximization (AIM),Graph Based Visual Saliency (GBVS), Image Signature (ImgSig), SUN framework and AdaptiveWhitening Saliency (AWS). The implementation of these models were based on publicly availablecodes/software. Among these models, GBVS, ImgSig and AWS usually performed better than theothers. Inspired by the center bias, we included a Center model as a baseline, which was simply a Gaussianfunction with mean at the center of the image and standard deviation being 1/4 of the image width.This simple model was also combined with other saliency detection models to account for the centerbias, which could boost accuracy of fixation prediction. Following , this was achieved by multiplyingthe center model with the saliency maps obtained by these models in a point-wise manner.",
  "Results": "First, we compared different super-resolution techniques (LR, BI and CS) for eye fixation prediction. shows the results of RHM with the three techniques. The CS method significantly outperformedLR and BI. Therefore, sparsity as a prior offers great advantage in discovering salient fine details. Wethen focused on RHM with CS in subsequent experiments. shows some qualitative comparison of the proposed model against existing models. shows quantitative results under three metrics. As we can see, no single model could dominate othersunder all three metrics. However, in most cases (including both with and without center settings),the RHM outperformed the current state-of-the-art models. This demonstrated the reverse hierarchytheory as a promising way to predict human eye fixations.",
  "Contributions of Individual Components": "The RHM consists of two components: coarse-to-fine reconstruction (especially compressive sensing)and reverse propagation. Although the two components integrated together showed promising results,the contribution of each component to the performance is unclear. This is discussed as follows. Compressive sensing. To identify the role of compressive sensing, we substituted it with other saliencymodels. Specifically, we replaced the saliency maps obtained from coarse-to-fine reconstructionby the saliency maps obtained by existing models. The models designed to work on a single scale,including SR, AIM, SUN, were applied to images of different scales to obtain multiple saliency maps.For multi-scale models such as Itti Koch, we use their intermediate single-scale results. Notice that blurring with a Gaussian filter is a necessary step in our model to obtain a smooth saliencymap from stochastic fixations. Previous results have shown that blurring improved the performanceof saliency models. For the sake of fairness, we also tested the models with the same amount ofblurring (the sigma of Gaussian) used in RHM. shows the results on the TORONTO dataset.",
  "The reverse propagation procedure improved the AUC of these models. However, their performanceis still behind RHM. Therefore, compressive sensing is a critical component in the RHM": "Reverse propagation. To investigate the effect of reverse propagation, we substituted it with linearcombination of saliency maps, which is widely adopted in literature. shows the results. Thelinear combination produced an AUC between the best and worst that a single saliency map couldachieve. However, RHM outperformed the best single-map performance. Therefore, through reversepropagation, RHM could integrate complementary information in each map for better prediction.",
  "Conclusion and Future Work": "In this paper, we present a novel reverse hierarchy model for predicting eye fixations based on apsychological theory, reverse hierarch theory (RHT). Saliency is defined as unpredictability fromcoarse-to-fine image reconstruction, which is achieved by image super-resolution. Then a stochasticfixation model is presented, which propagates saliency from from the top layer to the bottom layer togenerate 01xation esti- mate. Experiments on two benchmark eye-tracking datasets demonstrate theeffectiveness of the model. This work could be extended in several ways. First, it is worth exploring whether there exist bettersuper- resolution techniques than compressive sensing for the pro- posed framework. Second, itis worth exploring if the ideas presented in the paper can be applied to a hierarchical struc- tureconsisting of different level of features, which play a signi01cant role in the top-down modulation assuggested by RHT. Finally, in view of the similar hierarchical structure used in this study for saliencydetection and other studies for object recognition, it would be interesting to devise a uni01ed modelfor both tasks."
}