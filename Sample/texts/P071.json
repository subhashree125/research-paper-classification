{
  "Abstract": "This paper investigates the role of fillers within text-based representations of speechtranscripts. While often ignored in Spoken Language Understanding tasks, wedemonstrate that these elements, such as \"um\" or \"uh,\" when incorporated usingdeep contextualized embeddings, enhance the modeling of spoken language. Thisis further shown through improvements in downstream tasks like predicting aspeakers stance and their expressed confidence.",
  "Introduction": "This paper addresses the critical role of disfluencies, specifically fillers, in spoken language processing.Disfluencies, which encompass phenomena like silent pauses, word repetitions, or self-corrections,are inherent to spoken language. Fillers, a type of disfluency, often manifest as sounds like \"um\" or\"uh,\" serving to bridge pauses during utterances or conversations. While prior research has demonstrated the efficacy of contextualized embeddings pre-trained onwritten text for adapting to smaller spoken language corpora, these models typically exclude fillers anddisfluencies in pre-processing. This practice is at odds with linguistic research, which considers fillersto be informative and integral to spoken language. Existing methods for analyzing fillers primarilyrely on handcrafted features. Furthermore, pre-trained word embeddings trained on written texthave shown poor performance in representing spontaneous speech words like \"uh,\" as their meaningvaries significantly in spoken contexts. In this work, we explore the use of deep contextualized wordrepresentations to model fillers. We assess their value in spoken language tasks without relying onmanual feature engineering. The core motivation of this study stems from the following observations: First, fillers are essentialto spoken language. For instance, speakers may employ fillers to signal the linguistic structure oftheir utterances, such as difficulties in choosing vocabulary or to indicate a pause in their speech.Second, research has connected fillers and prosodic cues to a speakers Feeling of Knowing (FOK)or expressed confidence, signifying a speakers commitment to a statement. Fillers and prosodiccues influence a listeners perception of a speakers expressed confidence, known as the Feelingof Anothers Knowing (FOAK). Finally, fillers have been successfully applied in stance prediction,which gauges a speakers subjective attitude. Therefore, we intend to validate these observations by exploring how to efficiently represent fillersautomatically. Our key contributions are: (1) Fillers convey useful information that can be harnessedthrough deep contextualized embeddings to improve spoken language modeling and should not bediscarded. We also investigate the best filler representation strategies for Spoken Language Modeling(SLM) and examine the learned positional distribution of fillers. (2) In a spontaneous speech corpusof monologues, we show that fillers serve as a distinctive feature in predicting both a speakersperceived confidence and their expressed sentiment.",
  "Spoken Language Modeling": "We utilize a masked language modeling (MLM) approach for Spoken Language Modeling. Thisinvolves masking some input words at random and then attempting to predict those masked tokens.This is a standard way of pre-training and fine-tuning BERT. In our case, this method will be used tofine-tune a pre-trained BERT model on a spoken language corpus. Each experiment involves a tokenrepresentation strategy i and a pre-processing strategy Si. The token representation strategies are essential for our goal of learning the distribution of fillersusing BERT. The three token representation strategies are outlined as follows: T1 involves no specialprocessing for the fillers and BERT is left to use its prior understanding of fillers to model language.In T2, \"uh\" and \"um\" are marked with specific filler tags to distinguish them from other tokens, witheach filler represented as separate tokens. This strategy encourages BERT to learn new embeddingsthat emphasize filler context and position. In T3, both fillers are represented as the same token,indicating that they carry the same meaning. gives a concrete example of this process.",
  "Pre-processing": "We investigate the impact of three pre-processing strategies denoted by S1, S2 and S3. In S1, allfillers are removed from the sentences during both training and inference. In S2, fillers are keptduring training, but removed during inference. In S3, fillers are preserved during both training andinference. For each combination of pre-processing and token representation strategies, we fine-tuneBERT using the Masked Language Model objective like the original BERT paper. If fine-tuning isnot performed the training data of S1 and S2 are equivalent. We evaluate the model performance inlanguage modeling using perplexity (ppl).",
  "Confidence and Sentiment Prediction": "In tasks of confidence prediction and sentiment analysis, our objective is to use BERTs text rep-resentations, which include fillers, to predict a confidence/sentiment label. We add a Multi-LayerPerceptron (MLP) to BERT, which may have been fine-tuned using MLM. The MLP is trained by min-imizing the mean squared error (MSE) loss. These experiments adopt the same token representationand pre-processing techniques discussed in .1.1.",
  "Data Description": "We use the Persuasive Opinion Mining (POM) dataset which contains 1000 English monologuevideos. The speakers recorded themselves giving a movie review. The movies were rated between1 (most negative) and 5 stars (most positive). The videos were annotated for high-level attributessuch as confidence, where annotators rated from 1 (not confident) to 7 (very confident). Similarly,sentiment was scored by annotators between 1 (strongly negative) to 7 (strongly positive). This dataset was chosen for several reasons: (1) The corpus contains manual transcriptions withfillers \"uh\" and \"um,\" where approximately 4% of speech consists of fillers. Additionally, sentencemarkers are transcribed, with fillers at sentence beginnings if they occur between sentences. (2)The dataset includes monologues, where speakers are aware of an unseen listener, thus we canconcentrate on fillers in speaker narratives. (3) The sentiment/stance polarity was clearly definedby choosing only reviews that were rated with 1-2 or 5 stars for annotation purposes. (4) FOAK,measured by confidence labels, has high inter-annotator agreement. More details can be found insupplementary materials. The confidence labels are the root mean square (RMS) values of labelsgiven by 3 annotators. The sentiment labels are the average of the 3 labels.",
  "Fillers Can Be Leveraged to Model Spoken Language": "Language Modeling with fillers. We examine language model (LM) perplexity using variouspre-processing strategies, using a fixed token representation strategy of T1. The results in (a)compares S1, S2 and S3. By keeping fillers during both training and inference, the model reaches alower perplexity, with a reduction of at least 10%. Therefore, fillers provide information that BERTcan effectively use. The fine-tuning procedure improves the language models perplexity. Additionally, even withoutfine-tuning, S3 outperforms S1 and S2 by reducing perplexity when fillers are used. This implies thatBERT has prior knowledge of spoken language and uses the fillers. Consequently, fillers can reduce uncertainty of BERT for SLM. This is not an intuitive outcome; onemight assume that removing fillers during training and inference would decrease perplexity. Thefact that S3 exceeds other preprocessing methods shows that the Masked Language Model (MLM)process effectively learns this filler information. Best token representation: The results presented in (b) reveal that T1 outperforms otherrepresentations when fine-tuning. Given the limited data and high BERT embedding dimensionality(768), retaining existing representations with T1 is better than learning representations from thescratch. Interestingly, T2 and T3 perform similarly. The hypothesis is that the difference between\"uh\" and \"um\" lies only in the duration of the pause, which cannot be captured in text. Consideringthese results, T1 is fixed as the token representation strategy in all subsequent experiments. Learned positional distribution of fillers: We further test our models learning of filler placement.We fine-tune BERT using a filler to determine where the model believes the fillers most likely reside.Given a sentence S with length L, we introduce a mask token after the word j and obtain S*. We thencompute the probability of a filler in position j+1. Specifically, we calculate P([MASK=filler] | S), as depicted in . Then, we plot the averageprobability of the masked word being a filler given its sentence position in . The fine-tunedBERT model with fillers predicts a high probability of fillers occurring at the beginning of sentences.This pattern is consistent with filler distribution in the dataset. The fine-tuned BERT without fillers,predicts constant low probabilities. Given that we only know sentence boundaries we still manageto observe that the model captures a similar positional distribution of fillers that are found in otherworks.",
  "Fillers are a discriminative feature for FOAK and stance prediction": "We look at the impact of fillers on two downstream tasks: FOAK prediction and sentiment analysis.Psycholinguistic studies have found a link between fillers and expressed confidence. Prior work haslinked fillers and a speakers expressed confidence in the narrow field of QA tasks. Fillers have alsobeen used to predict stance. In this work, we present data that suggests fillers play a role in predictinga speakers expressed confidence and their stance. (c) shows that S3, both with and without fine-tuning, reduces the MSE compared to S1 andS2. S1 and S2 have similar MSE since they remove fillers during inference. S2 has a higher MSE,possibly due to the mismatch between training and test datasets. This demonstrates that fillers can bea discriminative feature in FOAK and stance prediction. Does using fillers always improve results for spoken language tasks? In the subsection 3.1, weobserve that including fillers reduces MLM perplexity. An assumption is that that downstream taskswould also benefit from the inclusion of fillers. However, we notice that when predicting speakerpersuasiveness, the fillers are not a discriminative feature, following the same procedure as outlinedin subsubsection 2.1.2.",
  "Conclusion": "This paper demonstrates that retaining fillers in transcribed spoken language when using deepcontextualized representations can improve results in language modeling and downstream taskssuch as FOAK and stance prediction. We also propose and compare several token representationand pre-processing strategies for integrating fillers. We plan to extend these results to considercombining textual filler-oriented representations with acoustic representations, and to further analyzefiller representation learned during pre-training."
}