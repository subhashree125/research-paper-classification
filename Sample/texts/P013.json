{
  "Introduction": "In the last decade, deep neural classifiers achieved state-of-the-art results in many domains, amongothers in vision and language. Due to the complexity of a deep neural model, however, it is difficultto explain its decisions. Understanding its decision process potentially allows to improve the modeland may reveal new knowledge about the input. Recently, it was claimed that popular explanationapproaches for neural networks (...) do not provide the correct explanation, even for a simple linearmodel. They show that in a linear model, the weights serve to cancel noise in the input data and thusthe weights show how to extract the signal but not what the signal is. This is why explanation methodsneed to move beyond the weights, the authors explain, and they propose the methods PatternNetand PatternAttribution that learn explanations from data. We test their approach in the languagedomain and point to room for improvement in the new framework.",
  "Methodology": "Kindermans et al. assume that the data x passed to a linear model wT x = y is composed of signal(s) and noise (d, from distraction) x = s + d. Furthermore, they also assume that there is a linearrelation between signal and target y as = s where as is a so called signal base vector, which is in factthe pattern that PatternNet finds for us. As mentioned in the introduction, the authors show that inthe model above, w serves to cancel the noise such that",
  "wT d = 0, wT s = y.(1)": "They go on to explain that a good signal estimator S(x) = s should comply to the conditions in Eqs.1 but that these alone form an ill-posed quality criterion since S(x) = u(wT u)1y already satisfiesthem for any u for which wT u = 0. To address this issue they introduce another quality criterionover a batch of data x:(S) = 1 maxvcorr(y, vT (x S(x)))(2) and point out that Eq. 2 yields maximum values for signal estimators that remove most of theinformation about y in the noise. We argue that Eq. 2 still is not exhaustive. Consider the artificialestimatorSm(x) = mx + (1 m)s = s + md(3)",
  "(S) := maxv1 corr(wT x, vT1 S(x)) maxv2 corr(wT x, vT2 (x S(x))).(5)": "The minuend measures how much noise is left in the signal, the subtrahend measures how muchsignal is left in the noise. Good signal estimators split signal and noise well and thus yield large(S). We leave it to future research to evaluate existing signal estimators with our new criterion. Forour experiments, the authors equip us with expressions for the signal base vectors as for simple linearlayers and ReLU layers. For the simple linear model, for instance, it turns out that as = cov(x, y)/2y.To retrieve contributions for PatternAttribution, in the backward pass, the authors replace the weightsby w as.",
  "Experiments": "To test PatternAttribution in the NLP domain, we trained a CNN text classifier on a subset of theAmazon review polarity data set. We used 150 bigram filters, dropout regularization and a dense FCprojection with 128 neurons. Our classifier achieves an F1 score of 0.875 on a fixed test split. Wethen used PatternAttribution to retrieve neuron-wise signal contributions in the input vector space. Toalign these contributions with plain text, we summed up the contribution scores over the word vectordimensions for each word and used the accumulated scores to scale RGB values for word highlightsin the plain text space. Positive scores are highlighted in red, negative scores in blue. This approachis inspired by similar work. Example contributions are shown in Figs. 1 and 2.",
  "Related Work": "Many of the approaches used to explain and interpret models in NLP mirror methods originallydeveloped in the vision domain. In this paper we implemented a similar strategy. FollowingKindermans et al., however, our approach improves upon the latter methods for the reasons outlinedabove. Furthermore, PatternAttribution is related to work who make use of Taylor decompositions toexplain deep models. PatternAttribution reveals a good root point for the decomposition, the authorsexplain.",
  "Conclusion": "We successfully transferred a new explanation method to the NLP domain. We were able to demon-strate that PatternAttribution can be used to identify meaningful signal contributions in text inputs.Our method should be extended to other popular models in NLP. Furthermore, we introduced animproved quality criterion for signal estimators. In the future, estimators can be deduced from andtested against our new criterion."
}