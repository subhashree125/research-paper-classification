{
  "Abstract": "While large pre-trained language models are powerful, their predictions oftenlack logical consistency across test inputs. For example, a state-of-the-art Macawquestion-answering (QA) model answers Yes to Is a sparrow a bird? and Doesa bird have feet? but answers No to Does a sparrow have feet?. To address thisfailure mode, we propose a framework, Consistency Correction through RelationDetection, or ConCoRD, for boosting the consistency and accuracy of pre-trainedNLP models using pre-trained natural language inference (NLI) models withoutfine-tuning or re-training. Given a batch of test inputs, ConCoRD samples severalcandidate outputs for each input and instantiates a factor graph that accounts forboth the models belief about the likelihood of each answer choice in isolation andthe NLI models beliefs about pair-wise answer choice compatibility. We show thata weighted MaxSAT solver can efficiently compute high-quality answer choicesunder this factor graph, improving over the raw models predictions. Our experi-ments demonstrate that ConCoRD consistently boosts accuracy and consistency ofoff-the-shelf closed-book QA and VQA models using off-the-shelf NLI models,notably increasing accuracy of LXMERT on ConVQA by 5",
  "Introduction": "Reliable and trustworthy AI systems should demonstrate internal self-consistency, in the sense thattheir predictions across inputs should imply logically compatible beliefs about the world. However,even powerful large language models are known to lack self-consistency. For example, a question-answering (QA) model that answers the question Is a sparrow a bird? and Does a bird have feet?with Yes is implicitly expressing the belief that A sparrow is a bird and A bird has feet. If thesame model answers the question Does a sparrow have feet? with No, the model expresses thelogically incompatible belief A sparrow does not have feet. In such cases, ascertaining the models201ctrue201d belief is difficult, making interpreting and validating its behavior correspondinglychallenging. Prior work has improved model self-consistency by training with specialized loss functions or dataaugmentation, or alternatively re-ranking model predictions based on their mutual self-consistencyusing pre-written logical constraints, such as 201call mammals have fur201d. However, the first classof methods requires expensive fine-tuning which might be impractical for many practitioners forvery large pre-trained models, and re-ranking methods require an explicit collection of the logicalrelations of interest, making scaling a challenge. Still, re-ranking-based approaches have the benefitof not requiring fine-tuning, and we hypothesize that their scalability limitations may be addressed byestimating logical relationships between model predictions on the fly. Specifically, we hypothesizethat existing pre-trained natural language inference (NLI) models can estimate logical relationshipsbetween an arbitrary pair of model predictions well enough to provide an effective, scalable substitutefor explicit collection of such constraints. Leveraging these estimated constraints, we can construct",
  "a factor graph representing a probability distribution over model outputs that incorporates both theoriginal models confidence scores and the NLI models beliefs about logical relationships": "Our primary contribution is Consistency Correction through Relation Detection, or ConCoRD, aframework to improve the consistency and performance of a pre-trained base language model withoutfine-tuning by using more confident and better attested model predictions to override less confidentmodel beliefs. To enable propagation of model beliefs, we estimate pair-wise logical relationshipsbetween model predictions using a pre-trained NLI model. Using these pair-wise relationships, wedefine an undirected graphical model representing a distribution over responses accounting for boththe base models beliefs and the NLI models estimates of answer compatibility. We efficiently findthe approximate mode of this distribution among the base models top answer choices for each inputas the solution of a MaxSAT problem, which consistently produces more accurate and self-consistentpredictions than using the raw model predictions. We find that ConCoRD produces an 8.1",
  "Related Work": "Prior work for maintaining consistency in the question-answering space often involves additionaltraining to improve performance. Some work generates questions from unlabeled texts, then filtersthem to ensure roundtrip consistency; pre-training on this synthetic set improves performance onSQuAD 2.0 and Natural Questions. Other work augments QA-pairs with their logically symmetricand transitive counterparts through linguistic approaches to enhance cross-dataset QA performance.ConCoRD differs significantly from these question-answering-specific approaches because no fine-tuning of the base model is needed and the methodology is not specific to question-answering. Similarly to ConCoRD, other work re-rank model predictions by solving an optimization problemdefined by a combination of the base model confidence scores and pair-wise constraints representingthe logical compatibility of different model predictions stored in a persistent memory, which theycall BeliefBank. The key distinguishing property of ConCoRD is the fact that pair-wise constraintsbetween model predictions are dynamically estimated by a pre-trained NLI model, rather than drawnfrom a fixed, pre-collected set of constraints. Dynamically estimating the constraints has a variety ofbenefits, eliminating the need for manually collecting the logical constraints of interest, automatingthe process of determining whether a particular constraint applies to a particular pair of predictions,and likely inheriting improvements in Natural language inference (NLI) models over time. NLI has long been used to maintain logical consistency in generated dialogue utterances, radiologyreport domain entities, and summarization. Perhaps most similarly, other work uses NLI to estimateconstraints between factual statements produced by GPT-3. These prior approaches support ourintuition for using NLI models to improve logical consistency among batches of answers. While theauthors explore applications of this framework to multi-step reasoning for True/False questions orstatements, our work focuses on applying this methodology to more general settings, such as VQA,open-ended QA, and model editing.",
  "Consistency Correction through Relation Detection": "ConCoRD contains three key components, the base model, a relation model (typically a pre-trainedNLI model), and an inference procedure that combines the predictions of the two models into a moreaccurate and self-consistent set of beliefs. Importantly, both the base model and relation model arepre-trained, off-the-shelf models; ConCoRD does not update any weights or require training datafor either model, using only a small validation set for hyperparameter tuning. We next explain thefunction of each of these components when executing ConCoRD.",
  "Base Model": "The core function of the base model in ConCoRD is generating a set of candidate outputs for a giveninput, which are ultimately re-ranked by the inference process (Sec. 3.3). Given a batch of N modelqueries Q = {qi}, the first step of ConCoRD is to generate a set of J candidate outputs for each queryAi = {ai1, ..., aiJ}, along with their corresponding likelihoods p(aij|qi). Note that the candidateoutputs need not be an IID sample from the base model; for example, we might use beam searchwith a diversity bonus to produce a more diverse set of candidates. Each pair of query and candidate output forms a model belief bij = (qi, aij); the output of the base model is the complete set of modelbeliefs B = {bij} and their corresponding normalized probabilities pij. The base models in ourexperiments are pre-trained question-answering models based on T5-large and pre-trained visualquestion-answering models such as LXMERT and ViLT.",
  "Relation Model": "The relation model p(: |xi, x) estimates the most likely logical relationship between an ordered pairof natural language utterances from the choices {none, fwd entail, contradict, equivalence}.In addition to the model beliefs B, we define optional context statements cijk = C(bij), K relevantstatements that may be retrieved, generated, or manually written for each model belief. The abilityto incorporate context statements enables ConCoRD to modulate model behavior independently foreach input in the test batch, rather than reasoning transductively about pairs of test inputs. Inputsto the relation model are either pairs of two model beliefs (bij, bij) or pairs of one model beliefand one context statement (bij, cijk). We define the most likely inter-belief relation as rij,ij =argmaxrp(r|bij, bij), and similarly for belief-context relations rij,k = argmaxrp(r|bij, cijk).The output of the relation model is the set of most-likely relations R = {rij,ij} {rij,k} andtheir associated probabilities, which we denote as pij,ij",
  "and pij,k. Our experiments use variouspre-trained NLI models based on RoBERTa and ALBERT as the relation model": "Question-answer to statement conversion. While concatenating query qi and candidate output aijto produce inputs to the relation model is perhaps the simplest approach to estimating soft constraints,we use a statement conversion model to provide inputs to the relation model that are closer to itstraining distribution. Instead of defining the belief bij = (qi, aij) as concatenation of qi and aij, wedefine bij to be the statement f(qi, aij), where f is the conversion model. We fine-tune a smallT5 model on a combination of data from and BeliefBank to produce a model that maps a (question,answer) pair into a natural language statement.",
  "Inference": "ConCoRDs inference procedure maps the set of beliefs B and pair-wise relations R into a choiceof the most likely belief for each question. To define the inference problem, we first define a binarydecision variable zij representing the estimated truth value of model belief bij. A value of 1 for nodezij in the maximum likelihood configuration means that aij is returned for query qi; the problemincludes a constraint that exactly one candidate answer is true for each query. The factor graphincludes the set of variables Z = {zij}N,Ji,j=1,1 and various factors (functions mapping a subset ofZ to a non-negative scalar) derived from the base model and relation models beliefs and the hardconstraint of returning only one answer per question. Factors are defined such that more desirableconfigurations of zij yield a larger product of the individual factors. First, unary factors ij(zij)encode the base models beliefs about the likelihood of specific answers, and are defined as:",
  "ij(zij) = { p ij ifzij = 11 pijotherwise(1)": "where pij = p(aij|qi); in other words, the factor takes the odds ratio if the corresponding statementvariable zij is assigned a truth value of 1; otherwise, the factor takes value 1. In order to encode thehard constraint that exactly one output should be returned for each query, we include a J-ary factori(Zi) for each group of nodes Zi = {zij}Jj=1, which is equal to 1 for configurations where exactlyone of the nodes takes a value of 1, and 0 for all other configurations.",
  "An approximate solution to this inference problem can be efficiently found for most problems with aMaxSAT solver such as RC2. We omit arguments to the factors for conciseness": "Entailment correction. Consider a belief b, a set of its entailed statements S = {si}, unaryfactors (zb) and {(zsi)}, and binary factors = {(zb, zsi)}i. Recall that an entailment relationrij,ij(zij, zij) is satisfied (and the binary factor is maximized) if either zb = 0 or all zsi = 1.Consequently, as the cardinality of {zs|zsi = 0} increases, the more likely it is that zb = 0 willmaximize the product of all binary factors i (zb, zsi). This is true even if most entailed statementsare true, ie., |{zs|zsi = 1}| > |{zs|zsi = 0}|. If most of the statements entailed by a belief aretrue, assigning the belief to be false due to a small number of (potentially spuriously) false entailedstatements may be undesirable. To mitigate this outcome, we experiment with an additional type offactor in which configurations satisfying entailments with both zb = 1 and zsi = 1 are rewardedmore than other configurations satisfying the entailment:",
  "Hyperparameters of ConCoRD": "We introduce two key hyperparameters to ConCoRD. Because we do not know a priori the relativereliability of the base model and relation model, we introduce the hyperparameter , corre-sponding to a trade-off between the predictions of the base model and relation model. A value of = 1 corresponds to simply taking the raw predictions of the base model, while = 0 corresponds tooptimizing purely for answers that are self-consistent according to the relation model, without consid-ering the base models beliefs. The unary factors in the factor graph become i(zi) = (ij(zij)) andij,ij(zij, zij) = (ij,ij(zij, zij))1 (and similarly for ijk). In addition to , we introduce athreshold for relation model confidence to filter out low-confidence relation estimates. That is, wediscard a relation rij,ij or rij,k if pij,ij < or pij,k< , respectively. In practice, we find that theoptimal and vary across problems, perhaps due to the varying complexity of the model belief andcontext statements (and therefore the reliability of the relation models predictions). Therefore, weuse the hyperopt library for automated hyperparameter optimization, using the Tree Parzen Estimator(TPE) algorithm to tune and jointly. We use the optimal hyperparameters found on the validationdata for each problem to compute test performance.",
  "Experiments": "Our experiments are broadly designed to answer the high-level question: can ConCoRD leverage therelational knowledge in pre-trained NLI models to produce more accurate, self-consistent systembehavior, without additional data or fine-tuning? Further, we investigate ConCoRDs applicability toperforming test-time model editing, or injection of new information, and ConCoRDs sensitivity tothe choice of hyperparameters and types of relations detected.",
  "the template-generated gold question answer pair (qi, ai) is Q: Is it true that a lion is able to drinkliquids?; A: Yes": "We evaluate ConCoRD by sampling candidate answers from the top-2 output sizes of a multi-anglequestion answering model, given a multiple choice angle with choices Yes and No. The questionsand retrieved answers (qi, ai) form a set of beliefs Bsm for each entity. Since these are closed-bookquestions, no context statements are supplied; because they are yes/no questions, only one candidateanswer is obtained, i.e., J = 1. Question-answer to statement conversion is applied to all questionswith a default answer of Yes regardless of the answer ai, in order to provide the relation model withpositive natural language assertions from which to infer sets of relations Rsm; where the base modelanswers ai are No we replace node zi in the factor graph with its complement. Configurations Zsmare found for each sm S which maximize Equation 2 given Bsm, Rsm and together form a globalsolution Z. Datasets. We use a database with 12,636 facts (201csilver facts201d), each indicating whether one of601 predicates relates to one of 85 entities, as well as 4,060 confidence-weighted first-order constraintsmanually gathered from ConceptNet, forming a constraint graph G. Additionally, they provide 1,072distinct 201ccalibration facts201d, each relating one of 7 entities to one of 334 predicates.",
  "We tune and using a validation set of questions generated from the calibration facts, and evaluatetest time performance with questions generated from silver facts": "Metrics. We measure accuracy using binary F1 between elements zi of the configuration Z maxi-mizing (Z) (as in Equation 2), and the truth value of facts (Pn(sm))i. We use F1 for evaluationbecause gold answers are highly biased towards true No answers. We compute consistency within batches of questions using the complement of of conditional constraintviolation metric , defined here as the proportion of relevant gold constraints in G which are violated;a constraint (Pi(x) Pj(x)) is relevant iff, for some entity s, there is some belief bi B, smfrom fact (Pi(sm))i such that zi = 1, and there is some belief bj Bsm that corresponds to fact(Pj(sm))j; the constraint is violated when zj = 0. Comparisons. ConCoRD is evaluated against a naive baseline where only base model answers aiand probabilities are considered. A second baseline (G.C.) performs the inference described in Sec.3.3, replacing the inferred relations R with the gold constraints from constraint graph G, rather thanthose estimated by the relation model. Results. Results are shown in . ConCoRD provides an absolute improvement of over8% in F1 and consistency for Macaw-Large and 7% for Macaw-3B compared to the baseline.Notably, the margin of superiority of the Macaw-3B base model is mostly preserved after applyingConCoRD, suggesting that ConCoRD may provide a significant benefit even for very large models.A surprising result is that ConCoRD shows marked improvements in F1 over the gold constraintbaseline, suggesting that the detection and filtering of relations ConCoRD provides may, in thissetting, be an improvement over rigid adherence to the logical connections specified a priori. : F1 and consistency (1 - ) for two sizes of Macaw QA models, comparing ConCoRD toa naive QA baseline (Base) and ConCoRD with gold constraints (G.C.). ConCoRD significantlyimproves both F1 and consistency for both models.",
  "Internal Consistency in VQA": "Protocol. The Visual Question Answering (VQA) task involves a language model generating answersto questions that are directly associated with images. VQA tests for robustness and generalizabilityof ConCoRD as it introduces an additional layer of difficulty; the task moves away from purelytext-based tasks while expanding the answer space to the vocabulary of the LM being used. Thequestions from the ConVQA dataset and its associated images from the Visual Genome dataset",
  "provide an apt setting to assess ConCoRD, as the relatedness of questions for each image provideample opportunity for model self-inconsistency": "The ConVQA dataset consists of a set of images each associated with a group of related questionsabout the image, such as What color is the horse? and Is the horse brown? for a picture of a brownhorse in a stable. We evaluate ConCoRD with two VQA models, LXMERT and ViLT. For each groupof questions Qn = {qni}i, we sample the top-2 candidate outputs {ani1, ani2} for each question,and use a pre-trained NLI model to infer the most likely pair-wise relations R between outputs fromdifferent questions. We use the RC2 MaxSAT Solver to estimate the configuration that maximizesEquation 2. Metrics. We report accuracy as the proportion of questions answered correctly across all groups.We infer consistency using a metric previously used in the literature for the ConVQA dataset called201cperfect consistency201d. For all groups of related questions, a group is perfectly consistent ifall its questions are answered correctly. Perfect consistency then reports the proportion of questiongroups that were perfectly consistent. While this is not a perfect measure of consistency as it excludescases in which incorrect answers are consistent with each other, it still serves as a meaningful proxysince the dataset was designed such that any incorrect answer in a question group implies the presenceof inconsistency. Datasets. We divide the ConVQA dataset into a 201cclean201d (i.e. human verified and filtered)test set and a non-test set (train + val + test as defined by previous work). From the non-test set, wesample 10,000 random images equivalent to 123,746 questions to be used as our validation set fortuning our two hyperparameters. We use the clean test set 2013 725 images and 6,751 questions 2013to report our final results. Comparisons. ConCoRD is compared with a naive baseline and a top-2 oracle upper bound. Thenaive baseline is the answer with the highest VQA model probability. Top-2 oracle upper boundselects the correct answer if present within the top-2 predictions of the VQA model. Top-2 isappropriate given our use of the top-2 candidate outputs to generate inferences with NLI models. Results. The final results for ConCoRD, baseline, and oracle upper bound are shown in . ConCoRD increases the accuracy of LXMERT and ViLT by 5% and 2% respectively, and theconsistency of LXMERT and ViLT by 4.9% and 5.9% respectively. : ConVQA accuracy (Acc.) and perfect consistency (P.C.) of LXMERT and ViLT VQAmodels with and without ConCoRD. ConCoRD significantly improves accuracy and consistency ofboth models. Oracle performance is top-2 performance, as ConCoRD attempts to select the best ofthe top 2 answer choices of the base model.",
  "Test-Time Information Injection": "Protocol. We perform an additional experiment to evaluate ConCoRDs ability to integrate externalfactual information into its inference process, rather than only using other predictions in the testbatch. Such an ability enables editing a models behavior at test time, without re-training, as newinformation becomes available. We use the Natural Questions (NQ) dataset, rather than BeliefBank,to provide more challenging inputs to the relation model. Given a question from NQ, a sentencefrom the ground truth context document containing information about the answer is retrieved andprovided as an additional input to ConCoRD; we constrain the node representing this context variablein the factor graph to be true. Constraints are predicted between each answer choice and the contextstatement. As in the other experimental settings, hyperparameters are tuned on the validation set andapplied on the test set.",
  "Metrics. Model performance is evaluated using the SQuAD F1 score for overlapping tokens, follow-ing the same answer normalization protocols, including lower-casing and removing punctuation": "Datasets. The NQ development set consists of 7830 open-book question-answer pairs, with bothlong and short gold annotations in their context passages. Since the NQ test set is not available, wecreate a test and validation set from the NQ validation questions as follows: we take the first 5000questions to form our test set, and the rest to be our val set, which we use for hyperparameter tuning.Then each set is filtered such that only the answerable questions remain. 201cAnswerable201d isdefined as having a 201cshort answerspan defined in the annotations. This filtering process gives2713 test entries and 1576 val entries. Comparisons. ConCoRD is compared with a naive baseline and an oracle upper bound. All ofthese approaches operate on the fixed set of QA model answers for a specific QA model (one ofT5-Sm-NQ, T5-Lg-NQ, and T5-3B-NQ), specifically the set of top-4 answers for each question. Thenaive baseline selects the answer with the highest QA model probability, argmaxaijp(aij|qi). Theoracle upper bound approach selects the answer that has the best score with the gold short answerspan, argmaxaijF1(aij, aij). Results. The results on the test set using the naive baseline, ConCoRD, and oracle upper-boundare reported in . ConCoRD always outperforms the naive approach, demonstrating that theframework is useful even when each query input is processed independently (i.e., non-transductively).However, despite providing a relative gain of as high as 8.7% over the naive baseline, there is still agap between ConCoRD and the oracle. This gap may be attributable to the complexity of the NQquestions and context information compared with the statements in prior experimental settings. Otherwork demonstrates a significant gain in calibration performance from training on MultiNLI to trainingon a combination of MultiNLI and their NLI corpus adapted from NQ, perhaps hinting that crucialknowledge present in Natural Questions is not covered in MultiNLI, partially explaining the gapbetween ConCoRD and oracle F1 performance. Overall, these results suggest that ConCoRD canreason between context statements and model beliefs in addition to pairs of model beliefs, improvingperformance even with the increased complexity of the data. : Using ConCoRD to inject contextual information into a models decisions at test time.Injecting gold Natural Questions contexts consistently improves performance over the base modelwithout requiring fine-tuning.",
  "Ablating Relation Types": "Given that we consider two types of relations in our experiments, contradiction and entailment, it isnatural to wonder the relative contribution of these to ConCoRDs performance improvement; shows the results of this ablation. We re-run ConCoRD with either entailment or contradictionrelations removed, re-tuning the hyperparameters for both of the new settings (contradiction-onlyor entailment-only). We find that the relative contribution of contradiction and entailment relationsvaries significantly across models even within the same task, but using both relation types alwaysperforms approximately as well or better than using just one, suggesting that both types of detectedrelations from the NLI model carry useful information. However, we observe in several cases, suchas ViLT and the T5 models, that the entailment and contradiction relations may encode somewhatredundant information, as the performance when including either type of constraint alone nearlymatches that of using both types.",
  "Conclusion": "This paper presents a novel method, ConCoRD, for enhancing the self-consistency and performanceof pre-trained language models without requiring fine-tuning. ConCoRD leverages pre-trained NLImodels to estimate logical relationships between model predictions and uses a MaxSAT solver toenforce consistency. The experimental results demonstrate that ConCoRD improves over off-the-shelf : Ablating the relation types considered in ConCoRD2019s inference procedure. The Onlycont. and Only ent. are the results of applying ConCoRD with all entailment or con- tradictionrelations removed, respectively. The ConCoRD column is a reproduction of the results from Sections4.1-4.3, for convenience. Value shown is F1 score for BeliefBank (BB) and Natural Questions (NQ)and accuracy for ConVQA (CVQA). Note that hyperparameters 03b2 and 03bb are re-tuned on therespective validation set for each setting. : Comparing ConCoRD2019s performance for various NLI models on BB (BeliefBank),ConVQA, and NQ. Performance is measured as F1 score between predicted and gold text for BBand NQ, exact match accuracy for ConVQA. We use Macaw 3B for BB results, LXMERT for VQAresults and T5-3B for NQ results. The best NLI model(s) in each column are bolded; the best NLImodel varies across problems.",
  "BBConVQAAlb-XXLANLI0.8920.689RoB-LgANLI0.9310.706RoB-LgMNLI0.9180.706": "performance in a variety of settings and that it is relatively robust to the choice of hyperparameters.The paper also discusses potential future directions, such as integrating ConCoRD with other methodsand exploring its applications beyond natural language processing. : The QA statement conversion model outputs declarative statements from question-answerpairs. Out of the four validation examples presented, three are correct. The Red, bolded portion ofthe output of the second example indicates how it differs from the Teal, bolded corresponding portionof the gold statement.",
  "DatasetInputOutput": "SQuADWho established Yales residen- tial college system? Edward S. HarknessEdward S. HarknSQuADHow did Kuhn view the his- tory of science? competing paradigms or conceptual sys- temsKuhn viewed theBeliefBankIs it true that a poodle is a river? NoA poodle is not aBeliefBankIs a pigeon a living thing? YesA pigeon is a liv : Comparison of ConCoRD test performance vs. base- line with and without entailmentcorrection (E.C.) across base+relation models for closed-book question answering (Macaw) and VQA(LXMERT, ViLT) experiments (F1 for closed-book QA, exact-match accuracy for VQA), showingthat the entailment correction improves performance for most con01gurations.",
  "Mac-Lg+Rob/ANLI 0.8310.9140.909Mac-3B+Rob/ANLI 0.8550.9310.886LXMERT+Rob/MNLI 0.6560.7060.701LXMERT+Rob/ANLI 0.6560.7060.693ViLT+Rob/MNLI 0.7840.8040.810ViLT+Rob/ANLI 0.7840.8140.807": ": The numbers of good and bad flips in each of the experiments performed. We define flips aschoosing a different candidate from the naive baseline for the multiple choice experiments, and abinary truth value flip for BeliefBank. \"Good\" flips are flips that improve performance, and \"bad\"flips are those that are detrimental to performance.",
  "BeliefBankMacaw-3B723277VQALXMERT576238NQT5-3B-NQ16869": ": Editing a models behavior by adding new information to the context. The underlinedgeneration is the answer with the highest QA model confidence. The bolded generation is whatConCoRD selects after NLI inference. Teal, bolded generations indicate that ConCoRD selectsa generation with higher token overlap F1, while red, bolded generations indicate that ConCoRDselects a worse generation.",
  "Second Continental Congress;theUnited States; the British Crown; GreatBritain": "The United States Declara-tion of Independence is thestatement adopted by the Sec-ond Continental Congressmeeting at the Pennsylva-nia State House (Indepen-dence Hall) in Philadelphiaon July 4, 1776, which an-nounced that the thirteenAmerican colonies, then atwar with the Kingdom ofGreat Britain, regarded them-selves as thirteen indepen-dent sovereign states, nolonger under British rule."
}