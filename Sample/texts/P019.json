{
  "Abstract": "Digital Adherence Technologies (DATs) are becoming progressively favored as a means of confirming patientsadherence to various medications. This paper examines the information gathered from a city that utilizes 99DOTS,a telephone-based DAT implemented for tuberculosis (TB) treatment in India, where approximately 3 millionindividuals are diagnosed with the disease annually. The dataset encompasses approximately 17,000 patientsand 2.1 million dosage records. This research establishes the basis for deriving insights from this real-worlddata, encompassing a methodology to circumvent the influence of unrecorded interventions in the trainingdata employed for machine learning. Subsequently, a deep learning model is developed, its interpretability isillustrated, and it is demonstrated how it can be modified and trained under diverse clinical conditions to moreeffectively target and enhance patient treatment. In the context of real-time risk prediction, the model could beemployed to proactively intervene with 21% more patients and prevent 76% more missed doses compared tothe current heuristic benchmarks. Regarding outcome prediction, the model exhibits 40% improvement overbaseline approaches, enabling cities to allocate more resources to clinics with a higher proportion of patientssusceptible to treatment failure. Lastly, a case study is presented that illustrates how the model can be trained in anend-to-end, decision-focused learning framework to realize a 15% enhancement in solution quality in a sampledecision problem encountered by healthcare professionals.",
  "Introduction": "The World Health Organization (WHO) has identified tuberculosis (TB) as one of the leading ten causes of mortality globally, despiteit being a curable and preventable disease in the majority of instances. The widespread occurrence of TB is partially attributableto inadequate adherence to medication, which leads to an elevated probability of mortality, reinfection, and the development ofdrug-resistant strains of TB. To address the issue of non-adherence, the WHO advocates for directly observed treatment (DOT),wherein a healthcare professional directly observes and validates a patients daily intake of the necessary medication. Nevertheless,the necessity for patients to commute to the DOT facility imposes a financial strain and potentially introduces social stigma becauseof the public apprehension surrounding the disease. These obstacles make it challenging to eradicate TB, as they contribute topatients being lost to follow-up. Consequently, digital adherence technologies (DATs), which offer patients adaptable methods todemonstrate adherence, have experienced a surge in popularity on a global scale. DATs empower patients to be \"observed\" consuming their medication electronically through various means, such as two-waytext messaging, video recording, electronic pill containers, or toll-free phone calls. Healthcare professionals can subsequentlymonitor patient adherence in real-time using a dashboard. Besides enhancing patient adaptability and confidentiality, the dashboardempowers healthcare personnel to categorize patients and allocate their constrained resources towards those at the highest risk.Initial research indicates that DATs have the potential to enhance adherence in various disease contexts, thereby stimulating theirutilization and assessment for the management of TB adherence. The WHO has even issued a manual for the effective incorporationof this technology in TB patient care. In this paper, the focus is on investigating how the extensive longitudinal data generated by DATs can be utilized to assist healthworkers in better triaging TB patients and providing interventions to enhance the overall adherence of their patient group. The dataunder analysis originates from Mumbai, India, and is the result of a collaboration with the City TB Office of Mumbai. They haveput into practice a DAT that enables patients to verify their adherence by making daily toll-free calls. The DAT system was setup with technical assistance from the healthcare technology company Everwell and is recognized as 99DOTS. Everwell providessupport for the implementation of 99DOTS across India, where there were an estimated 2.7 million cases of TB in 2017. In Mumbai,patients registered in 99DOTS currently receive interventions based on the following broad guidelines. If they have not taken theirmedication by the afternoon, they (and their health worker) get a text message reminder. If the patient still does not take theirmedication after some time, the worker will call the patient directly. Lastly, if a patient does not respond to these interventions aftera certain number of days, they may be personally visited by a health worker. It is important to note that a significant number of thesepatients reside in communities with limited resources, where each health worker is responsible for managing dozens to hundreds of patients, far exceeding their capacity for daily visits. Therefore, models that can pinpoint patients at risk of missing doses andprioritize interventions by health workers are of the utmost importance. At first, the challenge of determining whom to target for an intervention seems to be a straightforward supervised machine learningtask. Provided with information regarding a patients medication adherence as indicated by their calls to the 99DOTS system, it ispossible to train a machine learning model to forecast whether they will miss medication doses in the future. Nevertheless, such amodel disregards the simultaneous interventions carried out by health workers during the data collection period and may result inerroneous prioritization choices, even when it exhibits high accuracy. As an illustration, it might be observed that missed doses aresucceeded by a phase of medication adherence. This observation does not imply that individuals who miss doses are more inclinedto take medication, but rather suggests that an intervention by a health worker likely occurred, after which the patient resumed theirmedication. Therefore, to prescribe interventions, its necessary to separate the impact of manual interventions from other underlying elementsthat contribute to missed doses. However, because this data was gathered through a wide-ranging implementation involving actualpatients, it incorporates the impacts of interventions executed by healthcare personnel. An added difficulty is that healthcare workersseldom document their interventions within the 99DOTS system, making it hard to gauge their consequences. Although there is asubstantial body of research on assessing heterogeneous treatment effects, conventional methods consistently necessitate awarenessof which patients underwent an intervention. It should be noted that such omissions will be prevalent as nations enthusiasticallyimplement DAT systems with the aim of aiding low-income areas. To facilitate the provision of enhanced care, it is imperative thatwe can glean insights from this complex yet abundant data. Hence, a general strategy is introduced for acquiring knowledge from adherence data with unrecorded interventions, grounded indomain expertise regarding the intervention heuristics used by healthcare workers. A proxy is created for interventions evident inthe historical 99DOTS data, and a model is devised to aid in prioritizing intervention targets for healthcare workers across variousclinical scenarios.",
  "Methodology": "The TB treatment system functions under severe resource constraints; for instance, a single health worker might be in charge ofover 100 patients. Therefore, it is essential that workers can precisely evaluate patient risk and prioritize interventions appropriately.Although machine learning can be employed to carry out such risk assessment with encouraging precision, it necessitates carefulconsideration of how intervention resources were distributed in the current data. A significant obstacle arises from the fact that users of the 99DOTS platform typically do not document interventions. Healthworkers might send texts, make calls, or conduct personal visits to patients in an effort to boost adherence, but these interventions arenot systematically recorded in the data. Although far from perfect, these gaps are unavoidable as countries with varying reportingstandards adopt DATs for TB treatment. Considering the wealth of data produced by DATs and their potential to affect humanlives, the importance of learning lessons in this demanding setting where unobserved interventions take place is emphasized. Thischallenge is subsequently addressed by developing a screening procedure that recognizes patients who were probable candidates forspecific interventions. The aim is to utilize the accessible data to create an approximation for when an intervention likely took place, enabling the trainingof models on data points unaffected by interventions. The initial step involves differentiating between various categories of healthworker interventions. Specifically, a house visit is regarded as a \"resource-limited\" intervention, given that workers are unable to visitall their patients promptly. Typically, this represents a last resort for health workers when patients are unresponsive to alternativemethods. On the other hand, calls and texts are viewed as \"non-resource-limited\" interventions, as they could feasibly be conductedon a large patient population at minimal expense. To develop the proxy, a search was conducted for health worker guidelines concerning house visits. The 2005 guide by IndiasRevised National Tuberculosis Control Program (RNTCP) mandated that workers perform a house visit after a single missed dose.However, more recent guidelines are considerably more ambiguous on this matter. Both the latest guide by the WHO and theRNTCP leave house visits to the health workers discretion. Nevertheless, through discussions in Mumbai, it was discerned thathealth workers give precedence to non-adherent patients for resource-limited interventions like house visits. Consequently, the proxywas formulated based on the adherence dashboard accessible to health workers. The 99DOTS dashboard provides a daily \"Attention Required\" status for each patient. Initially, if a patient has a record in the PatientLog, signifying that a provider made a note about the patient within the preceding 7 days, their status is automatically adjusted to\"MEDIUM\" attention. However, this guideline impacts fewer than 1% of the labels. The remaining 99% of labels are determined asfollows: if a patient misses 0 or 1 doses in the past 7 days, their attention level is changed to \"MEDIUM.\" If they miss 4 or more, itis changed to \"HIGH.\" Patients with 2-3 missed doses maintain their attention level from the day before. As a conservative proxy, itwas assumed that only \"HIGH\" attention patients were candidates for resource-limited interventions, considering that the attentionlevel serves as a health workers primary overview of recent patient adherence. This \"Attention Required\" system for screeningresource-limited interventions is applicable to any daily adherence context; one only needs to ascertain the threshold for a change toHIGH attention. Employing this screening system, sequences of days can be identified during which a patient was a candidate for a resource-limitedintervention, and subsequently, the use of signal from those days in the training task can be avoided.",
  "Experiments": "The objective was to create a model that mirrors the daily routine of a health worker, which involves analyzing their patients recentcall records to gauge adherence risk and subsequently planning various types of interventions. Enhanced prediction capabilitiesenable workers to engage with a greater number of patients proactively, prior to their missing crucial doses. The process began with the entire group of 16,975 patients and proceeded to create training samples from each patient in thefollowing manner. All consecutive sequences of 14 days of call data were considered, ensuring that the initial 7 days of eachsequence did not overlap. The first 7 days of each patients treatment, as well as the final day, were omitted to prevent any bias thatmight arise from interactions with health workers during the initiation or conclusion of treatment. Two filtering steps were thenimplemented. Initially, samples were excluded where the patient had in excess of 2 doses manually recorded by a provider during theinput sequence, as these patients likely had contact with their provider outside of the 99DOTS system. Secondly, samples in whichthe patient did not miss any doses in the input sequence were removed. Although these samples constituted the majority of the data,they included almost no positive (HIGH risk) labels, which distorted the training process. Moreover, positive predictions for patientswho missed 0 doses are improbable to be beneficial; no resource-limited intervention can be implemented so extensively that patientswith flawless recent adherence are targeted. The aforementioned steps yielded 16,015 samples, of which 2,437 were positive. Each sample comprised a time-series of call data along with static characteristics. The time series encompassed two sequences of 7in length for every sample. The initial sequence was a binary representation of call data, where 1 signified a call or manual doseand 0 indicated a miss. The subsequent sequence represented a cumulative count of all doses missed up to that specific day, takinginto account the patients entire history within the program. The static features incorporated four demographic attributes from thePatient Table: weight-band, age-band, gender, and treatment center ID. Supplementary features were derived from the patient CallLogs and captured a patients behavior beyond mere adherence. For instance, did the patient call at a consistent time each morningor at irregular intervals throughout the day? This was captured by calculating the mean and variance of the call minute and hour.Additional features encompassed the number of calls, number of manual doses, and the mean, maximum, and variance of calls perday, in addition to days per call. Analogous features were also incorporated, which exclusively utilized unique calls per day (i.e.,calls to distinct phone numbers) or disregarded manual doses. This procedure resulted in 29 descriptive features. Initially, standard models were tested that utilize solely the static features: linear regression, a random forest (with 100 trees and amaximum depth of 5), and a support vector machine. The random forest exhibited the best performance, so the others are omitted forthe sake of clarity. To make use of the time series data, a deep network was also constructed, designated as LEAP (Lstm rEal-timeAdherence Predictor), which accepts both the time series and static features as input. LEAP comprises two input layers: 1) an LSTMwith 64 hidden units for the time series input, and 2) a dense layer with 100 units for the static feature input. The outputs of thesetwo layers were concatenated and fed forward into another dense layer with 16 units, followed by a single sigmoid activation unit. Abatch size of 128 was employed, and training was conducted for 20 epochs. To assess the models, all data was randomized, and 25% was set aside as the test set. A 4-fold grid search was employed to ascertainthe optimal model parameters. To address class imbalance, SMOTE was utilized to oversample the training set, implemented usingthe Python library imblearn. Features were also normalized as percentiles using SKLearn, which was empirically found to beeffective. The benchmark for comparison was the method employed by the current 99DOTS platform to evaluate risk, namely, dosesmissed by the patient in the preceding week (lw-Misses).",
  "Results": "The models were compared against the baseline. The random forest slightly surpasses the baseline, and LEAP distinctly outperformsboth. Nevertheless, to gauge the efficacy of the methods relative to the baseline, a comparison is made regarding how each methodcould be applied to strategize house-visit interventions. Given that this constitutes a highly constrained resource, the most stringentbaseline threshold was established to contemplate patients for this intervention, specifically, 3 missed calls. Maintaining the FPR ofthis baseline method, it is demonstrated how many more patients in the test set would be reached weekly by the proposed method(owing to its enhanced TPR), alongside the enhancement in the quantity of missed doses detected. To ascertain the number of misseddoses caught, only missed doses that transpired before the patients transition to HIGH risk are counted. The model identifies 21.6%more patients and captures 76.5% more missed doses, signifying substantially more accurate targeting than the baseline. It is shown that the model also surpasses the baseline as both the true positive rate (TPR) and FPR escalate, underscoring the modelssuperior discriminatory capability. This proves advantageous for interventions not constrained by resources, like calls or texts. Itis important to remember that the screening procedure is not pertinent to this category of intervention; therefore, the predictionscan solely advocate for supplementary interventions. It is crucial that additional interventions are meticulously aimed, as repeatedengagement with a specific patient diminishes the effectiveness of each subsequent interaction over time. This emphasizes thesignificance of the enhanced precision provided by the model, as merely inundating the entire population with calls and texts isprobable to be ineffective. The model has the capability to prevent a greater number of missed doses compared to existing approaches. Nonetheless, theseadvancements cannot be realized unless health workers on the ground administer interventions in accordance with the predictions.Consequently, interpretability emerges as a crucial determinant of the models utility, as health workers must comprehend therationale behind the models predictions to trust it and incorporate its logic with their own professional expertise. The superior predictive performance was attained with LEAP, a black-box network, as opposed to an inherently interpretable modelsuch as linear regression. As a result, it is demonstrated how a visualization instrument can assist users in extracting insightsregarding the models reasoning. The SHapley Additive exPlanations (SHAP) python library was employed, which producesvisualizations to elucidate machine learning models. It is illustrated how static features affect the models prediction, where redfeatures drive predictions toward 1 (HIGH) and blue toward 0 (MEDIUM). It is important to recall that features are scaled aspercentiles. In the blue region, it is observed that this patient makes an above-average number of calls each week, pushing theprediction toward 0. Conversely, in the red region, it is noted that this patient has a very low average but a high variability in timebetween calls. These features capture that this patient missed two days of calls, then made three calls on one day in an attempt to\"back log\" their previous missed calls. The model learned that this is a high-risk behavior. Four distinct samples are presented as input to the LSTM layer of the model. On the left, the binary input sequence is depicted ascolored pixels, where black represents a call and yellow signifies a missed call. On the right, SHAP values corresponding to eachday of adherence data are displayed, and grey denotes the commencement of the call sequence. It is observed that the model hasdiscerned that calls made later in the week carry more weight than those made earlier. In Sample 1, the bottom two pixels (the mostrecent calls) have blue SHAP values, while the other pixels have SHAP values close to 0. In Sample 3, a single missed call at thebeginning of the week, combined with a call made at the end of the week, result in essentially canceling SHAP values. Sample 4also has one missed call, but on the last day of the week, resulting in a net positive SHAP value. This visualization method offers intuitive insights into the principles acquired by the model. In a real-world application, healthcareprofessionals could produce these visualizations for any given sample on-the-fly to support their decision-making procedure.",
  "Conclusion": "A framework is introduced for acquiring the ability to generate intervention recommendations from data produced by DAT systemsused in TB care. A comprehensive strategy is formulated for learning from medical adherence data that includes unrecordedinterventions, and this strategy is utilized to construct a model for forecasting risk in various contexts. In the real-time adherencescenario, it is demonstrated that the model would empower health workers to more precisely direct interventions to high-risk patientsat an earlier stage, identifying 21% more patients and preventing 76% more missed doses than the existing heuristic benchmark.Subsequently, the model is trained for outcome prediction, illustrating how adherence data can more accurately detect patientsat risk of unfavorable treatment outcomes. Insights are then derived that could assist health workers in accurately identifyingLCFO patients using a straightforward rule after a mere 7 days of treatment. Finally, it is demonstrated that adapting the LEAPmodel for a particular intervention through decision-focused learning can enhance performance by an additional 15%. The learningmethodologies presented here are versatile and could be applied to analyze data generated by DATs for any medication schedule.Given the increasing adoption of DAT systems for TB, HIV, diabetes, heart disease, and other medications, this work aims toestablish the groundwork for enhanced patient outcomes in healthcare settings worldwide.",
  "Outcome Prediction": "The subsequent phase involves an investigation into how adherence data can be employed to forecast the ultimate treatment outcome.Conventional studies on TB treatment typically model outcomes solely in relation to patient covariates, such as demographiccharacteristics. By utilizing daily real-time adherence data furnished by DATs, an exploration is conducted into how employingthe initial k days of a patients adherence facilitates more precise, individualized outcome predictions. It is important to notethat intervention effects are still discernible in this configuration. Nevertheless, the screening procedure will not be applicable,as predictions are made over a span of several months, during which practically all patients would have had recurring in-personinteractions with healthcare providers. The prediction task is formalized in the following manner: given the first k days of adherence data, predict the final binary treatmentoutcome. \"Cured\" and \"Treatment Complete\" were regarded as favorable outcomes, while \"Died,\" \"Lost to follow-up,\" and\"Treatment Failure\" were considered unfavorable. Solely patients who were assigned an outcome from these classifications areincorporated. Furthermore, given that patients with the outcome \"Died\" or \"Lost to follow-up\" exit the program prior to the full 6months of treatment, those who were present for less than k + 1 days were excluded. Lastly, patients who had in excess of half theirfirst k days marked as manual doses were omitted. This was inclined to enhance prediction performance, which is conjectured to beassociated with the observation that practices for reporting manual doses varied by health center, rendering the \"significance\" of amanual dose ambiguous across samples with respect to outcome. The final dataset comprised 4167 samples, with 433 unfavorablecases. Through discussions in Mumbai, it was learned that health workers often build a sense of a patients risk of an unfavorable outcomewithin their first month of treatment. To model this process, k=35 was set for the prediction task, capturing the first month of eachpatients adherence after enrollment in 99DOTS. (Note that this is not a general rule for health workers, but simply served as a motivation for the choice of k in this task.) Both the static features and the sequence inputs were the same as calculated for theweekly prediction task, but now taken over the initial 35 days. Two versions of the health worker baseline were included: misseddoses in the last week (lw-Misses) and total missed doses in 35 days (t-Misses). The same models, grid search design, training process, and evaluation procedure as before were used. For the Random Forest, 150trees were used with no maximum depth. For LEAP, 64 hidden units were used for the LSTM input layer, 48 units for the denselayer input, and 4 units in the penultimate dense layer. Even the rudimentary baseline of tallying the calls made in the preceding 7 days before the 35-day threshold is somewhat predictiveof the outcome, implying that the daily data provided by DATs is valuable in assessing which patients will fail TB treatment. TheML models exhibit even greater predictive capability, with LEAP leading in performance, closely followed by the random forest.It is emphasized how LEAPs predictive ability could aid officials in minimizing the expenses required to meet medical outcometargets for their city. For instance, suppose Mumbai initiates a new program to capture 80% of unfavorable outcomes (true positives)by recruiting additional health staff. Across the 17,000 patients in Mumbai, where 10% have unsuccessful outcomes as in the testset, an 80% capture rate necessitates rescuing 1360 patients. Employing either baseline, attaining the 80% TPR necessitates an FPRof 70%, which translates to hiring extra staff to support 10710 total patients in this hypothetical scenario. However, utilizing LEAPonly results in an FPR of 42%, corresponding to 6426 total patients. It is important to remember that in Mumbai, the typical healthworker attends to approximately 25 patients. With a yearly starting salary of |216,864, the model would result in |37M in saved costsannually.",
  "Detecting Low-Call Favorable Outcome Patients": "An additional significant hurdle within the 99DOTS system is that certain patients consistently take their doses as directed but opt notto call. Consequently, according to the dashboard, they appear to be missing doses and would be categorized as HIGH risk by both99DOTS and LEAP. However, in actuality, they should be classified as MEDIUM risk. In fact, almost 15% of patients who had anoutcome assigned as in section 3 called on fewer than 25% of the days during their treatment, yet experienced a favorable outcome. These patients are referred to as low-call favorable outcome (LCFO). The aim is to learn to recognize these LCFO patients to avoidincorrectly classifying them as HIGH risk, despite their lack of calls. Additionally, there is a desire to identify these patients early intheir treatment so they can be reassigned to an adherence monitoring method that is more appropriate for them. This is framed as a binary prediction task as follows: given the first k days of adherence data, predict whether the patient will bothcall on less than 25% of days from day k + 1 onward and have a favorable outcome. Only patients who were assigned an outcome asin and who had at least k + 7 days of adherence data were included. To detect LCFO status as early as possible, k was setto 7. Thus, the final dataset contained 7265 patients, of which 1124 were positive. Note that this population was larger than that ofthe outcome prediction task because 1) patients were required to be in the program for less time and 2) patients were not removedfor having too many manual doses since this was found to correlate with being LCFO. Both the static features and the sequence inputs were the same as calculated for the outcome prediction task, but this time taken overthe initial 7 days. The health worker baseline of missed doses in the last week (lw-Misses) was included, along with a random foresttrained only on demographic or \"0-day\" data (RF 0-day), a simple baseline that counts the number of manual doses in the last week(lw-Manual), a random forest trained on all non-sequence features over the initial 7 days (RF), and LEAP trained on all features andsequences. The same models, grid search design, training process, and evaluation procedure as the previous two formulations were used. For RF0-day, 300 trees were used with a maximum depth of 10. For RF, 200 trees were used with a maximum depth of 10. For LEAP, 200hidden units were used for the LSTM input layer, 1000 units for the dense layer input, and 16 units in the penultimate dense layer. Interestingly, for this task, the lw-Misses baseline has almost no predictive power. Conversely, the performance of the lw-Manualheuristic is notable, which simply counts the number of manual doses marked in the first 7 days for each patient. This simpleheuristic has almost equivalent predictive power to the machine learning models. This is a valuable insight for health workers,suggesting that if the worker is already manually marking doses for a patient early in their treatment, the patient is likely to continueto be disengaged with the system in the long term and should be considered for different adherence technology. The RF 0-day modelhas decent predictive power, though closer inspection reveals that most of this power is encoded in the treatment center ID that is,LCFO patients tend to be concentrated at certain treatment centers. This insight merits closer inspection by supervisors about whypatients in certain regions tend to be disengaged with 99DOTS but still consuming pills. The RF and LEAP models both performslightly better than the lw-Manual baseline but similarly to each other, suggesting that the adherence sequence structure does notencode additional information for this prediction task. These insights could improve processes by 1) helping to identify hotspotregions of LCFO patients, after which supervisors might investigate the underlying reason and adjust treatment accordingly at thosecenters and 2) the lw-Manual baseline, after only 7 days of dosage data, could give health workers a simple rule for identifyingLCFO patients that should switch to different adherence technology.",
  "Decision Focused Learning": "This section delves into a case study illustrating how the LEAP model can be specialized to furnish decision support for a specificintervention. The end-to-end differentiability of the model is utilized to supplant the earlier loss function (binary cross-entropy)with a performance metric customized to the objective and limitations of a particular decision problem. To realize this end-to-endtraining, recent developments in decision-focused learning are employed, which incorporates an optimization model within themachine learning training loop. The focus is on a particular optimization problem that simulates the allocation of health workers to intervene with patients who areat risk in the near future. This proactive intervention is facilitated by the real-time risk predictions and exemplifies how the systemcan empower preemptive, focused action by providers. Nonetheless, it is underscored that the system can be readily adapted toaccommodate other intervention problems. Such adaptability is one of the advantages of the technical approach, which permits theML model to automatically adjust to the problem delineated by a domain expert. The optimization problem models a health worker who orchestrates a sequence of interventions throughout a week. The healthworker is accountable for a patient population across various locations and may visit one location daily. Location identifiers areemployed at the TB Unit level, as this is the most detailed identifier shared by the majority of patients in the dataset. Visiting alocation enables the health worker to intervene with any of the patients at that location. The optimization problem involves choosinga set of locations to visit that maximizes the number of patients who receive an intervention on or before the first day they wouldhave missed a dose. This quantity is referred to as the number of successful interventions, which is selected as the objective for tworationales. Firstly, it gauges the degree to which the health worker can proactively engage with patients before adherence declines.Secondly, this objective exclusively counts patients who commence the week at MEDIUM attention and receive an interventionbefore they could have transitioned to HIGH, aligning with the earlier discussion on circumventing unobserved interventions in thedata. This extends the earlier intervention proxy to manage day-by-day rewards. The optimization problem can be formalized as a linear program. There is a set of locations i = 1, . . . , L and patients j = 1, . . . , N,where patient j has location j. Over the days of the week t = 1, . . . , 7, the objective coefficient cjt is 1 if an intervention on day twith patient j is successful and 0 otherwise. The decision variable is xit, which takes the value 1 if the health worker visits locationi on day t and 0 otherwise. With this notation, the final LP is as follows:",
  "t=1xit 1i,xit {0, 1}": "Here, the second constraint prevents the objective from double-counting multiple visits to a location. It is noted that the feasibleregion of the LP can be demonstrated to be equivalent to a bipartite matching polytope, implying that the optimal solution is alwaysintegral. The machine learning task involves predicting the values of cjt, which are unknown at the start of the week. Three models arecompared. Firstly, the lw-Misses baseline is extended to this setting by thresholding the number of doses patient j missed in the lastweek, setting cjt = 0 for all t if this value falls below the threshold and cjt = 1 otherwise. = 1 was used as it performed best.Secondly, the LEAP system was trained directly on the true cjt as a binary prediction task using cross-entropy loss. Thirdly, LEAPwas trained to predict cjt using performance on the above optimization problem as the loss function (training via the differentiablesurrogate). This model is referred to as LEAP-Decision. Instances of the decision problem were created by randomly dividing patients into groups of 100, simulating a health worker undersevere resource limitations (as they would benefit most from such a system). All patients were included, even those with no misseddoses in the last week, since the overall resource allocation problem over locations must still account for them. LEAP and LEAP-Decision both outperform lw-Misses, as anticipated. LEAP-Decision enhances the number of successfulinterventions by roughly 15% compared to LEAP, showcasing the merit of customizing the learned model to a given planningproblem. LEAP-Decision actually has a lower AUC than either LEAP or lw-Misses, suggesting that conventional measures ofmachine learning accuracy are not an ideal proxy for utility in decision-making. To investigate what specifically distinguishes thepredictions made by LEAP-Decision, scatter plots of the predicted utility at each location according to LEAP and LEAP-Decisionversus the true values are presented. Visually, LEAP-Decision appears better able to distinguish the high-utility outliers which aremost important to making good decisions. Quantitatively, LEAP-Decisions predictions have worse correlation with the ground truthoverall (0.463, versus 0.519 for LEAP), but better correlation on locations where the true utility is strictly more than 1 (0.504 versus0.409). Hence, decision-focused training incentivizes the model to focus on making accurate predictions specifically for locationsthat are likely to be good candidates for an intervention. This demonstrates the benefit of the flexible machine learning modelingapproach, which can use custom-defined loss functions to automatically adapt to particular decision problems."
}