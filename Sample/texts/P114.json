{
  "Abstract": "This paper presents an investigation into the computational modeling of the creativeprocess of a portrait artist, focusing on the incorporation of human traits like per-sonality and emotions into the artistic process. The system includes an empatheticconversational component to discern the dominant personality traits of the user,and this information is then utilized by a generative AI portraiture module to createa personalized stylization of the users portrait. The paper details the system andthe outcomes of real-time interactions from a demonstration session.",
  "Introduction": "The incorporation of human traits in the creation of artworks has consistently held significantimportance. Although there are differences between art and science regarding their goals andtoolsets, these distinctions blur when artists use scientific understanding to inform their work andscience examines art to comprehend the human experience. The idea of leveraging establishedpsychological insights into human traits such as personality and emotion to guide the creation,critique, and informing of artwork is not novel. Traditional portrait artists employ their understandingof human perception and vision to create portraits from life or photographs. This process includes thearrangement of the environment, placement of the subject, and an interview to grasp their mentaland physical characteristics. Artists also aim to convey their individual painting style while tryingto express personal and universal ideas. An artist has several options in themes, brush style, colorplan, edge and line plan, abstraction style, and emotional narrative to achieve the finished artwork.Computational creativity and generative art offer fresh avenues for modeling scientific knowledgeto replicate this process and deepen our grasp of human creativity. This study uses AI techniquesto begin emulating this artistic procedure. The Empathic AI Painter system seeks to discover novelapproaches to balance diverse aesthetic and conceptual aspects.",
  "System Description": "The Empathic Painter System is created to mimic the interaction between a live portrait artist anda person, referred to as the sitter. It aims to understand the sitters traits, such as personality andemotions, to create a unique portrait by selecting the appropriate abstraction techniques, color palette,and style that correspond to those traits. The system operates in a two-stage process; the first stageinvolves capturing the characteristics of the sitter, followed by the second stage, which uses thecaptured traits to generate a stylized artistic representation of their portrait. The initial stage ofcapturing the personality of the sitter occurs during the conversation with an embodied conversationalagent, using empathetic interaction methods. This system utilizes the M-Path conversational agent,which has been developed previously. The M-Path system was modified for this demonstration toconduct an interview based on the Big-5 personality questionnaire to categorize the sitter into oneof the established personality dimensions. This data is then used to map the personality traits to aparticular artistic style. The mapping is transferred to the Generative AI Portrait Stylization system in",
  "Big-5 Personality Mapping": "The five-factor model of personality is also known as the \"Big-5 Personality Model\" and is designedas a categorization to capture the variations in personality traits among individuals. This modelclassifies personality variations across five dimensions: extraversion, openness, conscientiousness,neuroticism, and agreeableness. Each of these dimensions encompasses a wide range of psychologicalfunctions, which are composed of more specific traits. Extraversion pertains to the extent to whichpeople are dominant, talkative, assertive, active, energetic and enthusiastic. Openness characterizespeople who are curious, creative, innovative, imaginative, reflective, cultured, curious, original,broad-minded, intelligent, and artistically sensitive, seeking new experiences and exploring novelideas. Conscientiousness indicates an individuals level of hard work, persistence, organization,and motivation in achieving their goals. Individuals high in conscientiousness tend to be organized,plan-oriented, and determined. Neuroticism, also referred to as Emotional Stability, representsdifferences in emotional stability and adjustment. Individuals scoring high on neuroticism tendto experience negative emotions, such as anxiety, depression, impulsiveness, self-consciousness,vulnerability, anger, hostility and worry. Agreeableness is linked to likability, conformity, friendliness,and social compliance. Individuals with high scores in agreeableness are characterized as trusting,caring, forgiving, altruistic, flexible, gullible, good-natured, soft-hearted, cooperative and tolerant.This model is based on factor analysis of descriptive words of human behavior. The questionnaireused is a shortened version of the Revised NEO Personality Inventory, which has 120 questionsand takes 45 minutes to complete. For the online demonstration, one statement for each dimensionwas used, where the whole conversational interaction could be completed in under 5 minutes. Eachquestion is further modified to align with the conversation setup in the demonstration environment.",
  "DimensionQuestion": "OpennessHow do you like the conference so far, is it interesting to you?ConscientiousnessDont you think the conferences are always a bit chaotic?ExtraversionDo you normally talk and interact with a lot of people?AgreeablenessHow about agents? Do you trust me in sharing how you feel?NeuroticismHow do you feel about your portrait being displayed on the screen?",
  ": The questions used for the personality dimensions": "The answers to these questions are evaluated for their polarity and then mapped onto two-factordimensions for personality adjectives. The mapping model is the Abridged Big Five CircumplexModel, in which facets of the Big Five dimensions are mapped as combinations of two factors. TheAB5C mapping contains descriptive personality terms for each of the resulting 90 combinations,where the most distinctive trait of an individual is used to select the column, and the second mostdistinctive trait selects the row. These traits may be either negative or positive. The mapping fromBig-5 traits to the Generative AI portrait styles was provided by art experts who independentlymapped the styles to the Big-5 categories and reached an agreement.",
  "Empathic Conversational Avatar": "The starting point of interaction is the empathetic conversational agent, M-Path, which was developedusing a framework based on a computational model of empathy. M-Path is a human-like avatarcapable of initiating and maintaining an emotional conversation, based on the predetermined goal ofthe dialogue. The interaction involves a face-to-face conversation with a human interaction partner, similar to a video-conference with audio and visual input and output. The agent processes thereal-time inputs in terms of their linguistic and affective properties to generate empathetic verbaland non-verbal behavior. The main objective of the interaction is to complete the modified Big-5questionnaire to categorize the partners personality and send it to the generative art system. Thesystem has three distinct modules: a perceptual module, a behavior controller and a behavior manager.The perceptual module gathers the video and audio signals when the conversation partner is speaking.This process was triggered with a push-to-talk system. M-Path enters a listening state when theuser speaks. During the listening state, speech and facial expressions are processed in real-time forspeech and emotion recognition. The video input is used in the facial emotion recognition module,which uses an OpenCV face-recognition algorithm to identify the face. Emotions are categorizedusing a CNN model, trained on the CK+ Dataset, into 6 basic emotion categories. The speechinput is sent to the speech-to-text module which uses a service to get streaming speech recognition.Sentiment analysis evaluates the text for its polarity using the SO-CAL Sentiment Analyzer, whichwas trained on the NRC-Canada lexicon. The text is sent to the decision-making module for creatingconversational responses. This process continues until the partner finishes speaking, which concludesthe listening state. The information is then sent to the decision-making module, and the agent enters athinking state. The behavior controller module creates goal-directed verbal and non-verbal responsesin all states of the conversation: listening, thinking, and speaking. This is done by analyzing the usersemotional response from the listening state. The conversation begins with the users greeting andfinishes when the agent receives suitable answers to the personality survey questions. The listening,thinking, and speaking states of the agent loop until the user is categorized. During the listeningstage, the agent shows a non-verbal affect matching response and backchanneling behavior. Affectmatching is a facial expression that mirrors the users facial expressions in real-time, chosen byempathy mechanisms. Backchanneling is created by a nodding behavior when pauses are detectedin the users speech. These behaviors are combined to create an empathic listening behavior. Afterthe conversation with the participant ends, the final text received and the users overall sentiment aresent to the Dialogue Manager (DM), and ultimately to the Empathy Mechanisms (EM). The DMcompletes the Big-5 personality questionnaire to assign a personality category. The EM ensures thatthe DM generates empathetic responses while reaching its goal. The DM gathers the appropriateemotional response from the EM to generate an emotionally appropriate verbal reaction to the user,followed by a survey-related coping response, and then the next survey question. The system uses thescikit-learn library in Python for the TF-IDF vectorizer model, and the NLTK Lemmatizer. A secondmodel is created by fine-tuning BERT for the classification of user responses according to sentimentand the Big-5 questionnaire answers. The Big-5 questionnaire answers are collected to select themost dominant personality dimensions of the user, based on their probability values and polarity. TheBig-5 mapping is used to select a category for the user, with adjectives. This categorization is thensent to the generative art cycle to produce a personalized portrait. After each response is generatedby the dialogue manager, it is sent to the behavior manager to be performed by the conversationalagent during the speaking state. To achieve a natural conversation, the system continuously producesnon-verbal and verbal behaviors. Lip movements, facial expressions, head gestures, body gestures,and posture are synchronized with the agents speech. The animation is sent as a BML message tothe Smartbody character animation platform, to display the generated behaviors.",
  "Generative AI Portraiture System": "The stylistic rendering of the portraits is generated by the generative art component of the system.The portrait goes through three processing phases. The first phase preprocesses the original portraitby using an AI tool to separate the foreground from the background, which will be used to stylizethe portrait. Then, the light and color balance of the face are adjusted to achieve a lighting effect,where one side of the face is dramatically shown. The next phase uses this image and the personalitycategory as inputs to a modified Deep Dream (mDD) system with multiple passes on the image tocreate the base style. While most DD systems use pre-trained networks with object recognition data,the modified system uses artistic paintings and drawings as training data. The system has a dataset of160,000 labeled and categorized paintings from 3000 artists. A method called hierarchical tight styleand tile was developed to overcome the problem that most artists create fewer than 200 paintingsin their lifetimes. In the last phase, the source image from the previous phase is further enhancedusing the personality category. The ePainterly system combines Deep Style techniques as a surfacetexture manipulator, and a series of Non-Photorealistic Rendering (NPR) techniques like particlesystems, color palette manipulation, and stroke engine techniques. This iterative process enhances the portrait, and the final result is shown in an online gallery. The ePainterly module is an expansionof the Painterly painting system, which models the cognitive processes of artists based on years ofresearch. The NPR subclass of stroke-based rendering is used as the final part of the process to realizethe internal mDD models with stroke-based output. This additional step reduces noise artifacts fromthe mDD output, creates cohesive stroke-based clustering, and a better distributed color space."
}