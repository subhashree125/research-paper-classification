{
  "Abstract": "This paper details our submission for stage 2 of the 2019 disentanglement challenge.It introduces a straightforward image preprocessing technique for discovering dis-entangled latent factors. Our approach involves training a variational autoencoderusing aggregated feature maps. These maps are obtained from networks that werepretrained on the ImageNet database, and we leverage the implicit inductive biaspresent in those features for disentanglement. This bias can be further strengthenedby fine-tuning the feature maps with auxiliary tasks such as angle, position estima-tion, or color classification. Our method achieved second place in stage 2 of thecompetition. Code is publicly available.",
  "Introduction": "Methods that are fully unsupervised are unable to learn disentangled representations unless furtherassumptions are made through inductive biases on both the model and the data. In our submission, weutilize the implicit inductive bias included in models pretrained on the ImageNet database, and thenimprove it by fine-tuning such models on tasks that are relevant to the challenge such as angle, positionestimation, or color classification. Our stage 2 submission builds upon our stage 1 submission, inwhich we used pretrained CNNs to extract convolutional feature maps as a preprocessing step beforetraining a VAE. Although this approach provided adequate disentanglement scores, two weaknesseswere identified with the feature vectors that were extracted. First, the feature extraction networkis trained on ImageNet, which is dissimilar to the MPI3d dataset that was used in the challenge.Secondly, the mechanism for feature aggregation was chosen in an ad-hoc way, and likely did notretain all information needed for disentanglement. We address these issues by fine-tuning the featureextraction network as well as by learning how to aggregate feature maps from data by using the labelsof the simulation datasets MPI3d-toy and MPI3d-realistic.",
  "Finetuning the Feature Extraction Network": "In this step, we fine-tune the feature extraction network offline, before submitting to the evaluationserver. The aim is to adapt the network so that it produces aggregated feature vectors that retain thenecessary information for disentangling the latent factors of the MPI3d-real dataset. The network isfine-tuned by learning to predict the value of each latent factor using the aggregated feature vector ofan image. To do so, we use the simulation datasets MPI3d-toy and MPI3d-realistic, specifically theimages as inputs and the labels as supervised classification targets.",
  "Feature Map Extraction and Aggregation": "In this step, we use the fine-tuned feature extraction network to produce a set of aggregated featurevectors. We simply run the network on each image of the dataset and store the aggregated 512-dimensional vectors in memory. Again, inputs to the feature extractor are standardized such that meanand variance across each channel correspond to the respective values from the ImageNet dataset.",
  "VAE Training": "Finally, we train a standard -VAE on the set of aggregated feature vectors. The encoder networkconsists of a single fully connected layer with 4096 neurons, followed by two fully-connected layersthat parameterize the means and log variances of a normal distribution N used as the approximateposterior q(z|x). The number of latent factors is determined experimentally. The decoder networkhas four fully-connected layers with 4096 neurons each, followed by a fully-connected layer parame-terizing the means of a normal distribution N used as the conditional likelihood p(x|z). The mean isconstrained to the range using the sigmoid activation. All fully connected layers except for thefinal ones use batch normalization and are followed by ReLU activation functions. We use orthogonalinitialization for all layers and assume a factorized standard normal distribution as the prior p(z) onthe latent variables. For optimization, we use the RAdam optimizer with a learning rate of 0.001, 0 = 0.999, 1 = 0.9and a batch size of 256. The VAE is trained for 120 epochs by maximizing the evidence lower bound,which is equivalent to minimizing",
  "B512i=1 ||i xi||2 + 0.5 Cj=1 1 + log(2j ) 2j 2j": "where is a hyperparameter to balance the MSE reconstruction and the KLD penalty term. Becausethe scale of the KLD term depends on the number of latent factors C, we normalize it by C such that can be varied independently of C. It can be harmful to start training with too much weight on the KLDterm. Therefore, we use the following cosine schedule to smoothly anneal from start = 0.005 toend = 0.4 over the course of training:",
  "tendtstart )) + startfortstart t tendendfort > tend": "where (t) is the value for in training episode t 0, ..., N 1, and annealing runs from epochtstart = 10 to epoch tend = 79. This schedule allows the model to initially learn to reconstructthe data well, and only then puts pressure on the latent variables to be factorized, which improvedperformance.",
  "Discussion": "Our method achieved second place in stage 2 of the competition. Compared to our stage 1 approach,our stage 2 approach resulted in large improvements on the FactorVAE and DCI metrics. On thepublic leaderboard, our best submission achieved first rank on these metrics. See appendix A forfurther discussion of the results. Introducing prior knowledge makes the disentanglement task considerably easier, and this is reflectedin the improved scores. However, our method uses task-specific supervision obtained from simulation,which restricts its applicability. Nevertheless, this demonstrates that such supervision can transfer tobetter disentanglement on real-world data, which was a goal of the challenge."
}