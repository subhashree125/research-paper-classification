{
  "Abstract": "We present a transition-based AMR parser that directly generates AMR parses fromplain text. We use Stack-LSTMs to represent our parser state and make decisionsgreedily. In our experiments, we show that our parser achieves very competitivescores on English using only AMR training data. Adding additional information,such as POS tags and dependency trees, improves the results further.",
  "Introduction": "Transition-based algorithms for natural language parsing are formulated as a series of decisions thatread words from a buffer and incrementally combine them to form syntactic structures in a stack.Apart from dependency parsing, these models, also known as shift-reduce algorithms, have beensuccessfully applied to tasks like phrase-structure parsing, named entity recognition, CCG parsing,joint syntactic and semantic parsing and even abstract- meaning representation parsing. AMR parsing requires solving several natural language processing tasks; mainly named entityrecognition, word sense disambiguation and joint syntactic and semantic role labeling. Given thedifficulty of building an end-to-end system, most prior work is based on pipelines or heavily dependenton precalculated features. Inspired by we present a shift- reduce algorithm that produces AMR graphs directly from plain text.presented transition-based tree-to-graph transducers that traverse a dependency tree and transformsit to an AMR graph. input is a sentence and it is therefore more similar (with a different parsingalgorithm) to our approach, but their parser relies on external tools, such as dependency parsing,semantic role labeling or named entity recognition. The input of our parser is plain text sentences and, through rich word representations, it predictsall actions (in a single algorithm) needed to generate an AMR graph representation for an inputsentence; it handles the detection and annotation of named entities, word sense disambiguation andit makes connections between the nodes detected towards building a predicate argument structure.Even though the system that runs with just words is very competitive, we further improve the resultsincorporating POS tags and dependency trees into our model. Stack-LSTMs have proven to be useful in tasks related to syntactic and semantic parsing and namedentity recognition. In this paper, we demonstrate that they can be effectively used for AMR parsingas well.",
  "Parsing Algorithm": "Our parsing algorithm makes use of a STACK (that stores AMR nodes and/or words) and a BUFFERthat contains the words that have yet to be processed. The parsing algorithm is inspired from thesemantic actions presented by , the transition-based NER algorithm by and the arc-standard algorithm.As in the buffer starts with the root symbol at the end of the sequence. shows a runningexample. The transition inventory is the following:",
  "SHIFT: pops the front of the BUFFER and push it to the STACK": "CONFIRM: calls a subroutine that predicts the AMR node corresponding to the top of theSTACK. It then pops the word from the STACK and pushes the AMR node to the STACK.An example is the prediction of a propbank sense: From occurred to occur-01. REDUCE: pops the top of the STACK. It occurs when the word/node at the top of the stackis complete (no more actions can be applied to it). Note that it can also be applied to wordsthat do not appear in the final output graph, and thus they are directly discarded. MERGE: pops the two nodes at the top of the STACK and then it merges them, it thenpushes the resulting node to the top of STACK. Note that this can be applied recursively.This action serves to get multiword named entities (e.g. New York City). ENTITY(label): labels the node at the top of the STACK with an entity label. This actionserves to label named entities, such as New York City or Madrid and it is normally run afterMERGE when it is a multi-word named entity, or after SHIFT if it is a single-word namedentity. DEPENDENT(label,node): creates a new node in the AMR graph that is dependent on thenode at the top of the STACK. An example is the introduction of a negative polarity to agiven node: From illegal to (legal, polarity -).",
  "LA(label) and RA(label): create a left/right arc with the top two nodes at the top of the": "STACK. They keep both the head and the dependent in the stack to allow reentrancies (multipleincoming edges). The head is now a composition of the head and the dependent. They are enrichedwith the AMR label. SWAP: pops the two top items at the top of the STACK, pushes the second node to the frontof the BUFFER, and pushes the first one back into the STACK. This action allows non-projective arcs as in but it also helps to introduce reentrancies. At oracle time, SWAP isproduced when the word at the top of the stack is blocking actions that may happen betweenthe second element at the top of the stack and any of the words in the buffer.",
  "shows the parser actions and the effect on the parser state (contents of the stack, buffer) andhow the graph is changed after applying the actions": "We implemented an oracle that produces the sequence of actions that leads to the gold (or close togold) AMR graph. In order to map words in the sentences to nodes in the AMR graph we need toalign them. We use the JAMR aligner provided by. It is important to mention that even though thealigner is quite accurate, it is not perfect, producing a F1 score of around 0.90. This means that mostsentences have at least one alignment error which implies that our oracle is not capable of perfectlyreproducing all AMR graphs. This has a direct impact on the accuracy of the parser described in thenext section since it is trained on sequences of actions that are not perfect. The oracle achieves 0.895F1 Smatch score when it is run on the development set of the LDC2014T12. The algorithm allows a set of different constraints that varies from the basic ones (not allowingimpossible actions such as SHIFT when the buffer is empty or not generating arcs when the wordshave not yet been CONFIRMed and thus transformed to nodes) to more complicated ones based onthe propbank candidates and number of arguments. We choose to constrain the parser to the basicones and let it learn the more complicated ones.",
  "Stack-LSTMs": "The stack LSTM is an augmented LSTM that allows adding new inputs in the same way as LSTMsbut it also provides a POP operation that moves a pointer to the previous element. The output vectorof the LSTM will consider the stack pointer instead of the rightmost position of the sequence.",
  "ACTIONSTACKBUFFER": "INITIt, should, be, vigorously, advocated, RSHIFTitshould, be, vigorously, advocated, RCONFIRMitshould, be, vigorously, advocated, RSHIFTshould, itbe, vigorously, advocated, RCONFIRMrecommend-01, itbe, vigorously, advocated, , RSWAPrecommend-01it, be, vigorously, advocated, RSHIFTit, recommend-01be, vigorously, advocated, RREDUCErecommend-01be, vigorously, advocated, RSHIFTbe, it, recommend-01vigorously, advocated, RREDUCEit, recommend-01vigorously, advocated, RSHIFTvigorously, it, recommend-01advocated, RCONFIRMvigorous, it, recommend-01advocated, RSWAPvigorous, recommend-01it, advocated, RSWAPvigorousrecommend-01, it, advocated, RSHIFTvigorousrecommend-01, advocated, RSHIFTvigorous, recommend-01advocated, RSHIFTit, vigorousrecommend-01, advocated, RCONFIRMadvocate-01, it, recommend-01, vigorousRLA(ARG1)advocate-01, it, recommend-01, vigorousRSWAPadvocate-01, recommend-01, vigorousit RSHIFTit, advocate-01, recommend-01, vigorousRREDUCEadvocate-01, recommend-01, vigorousRRA(ARG1)advocate-01, recommend-01, vigorousRSWAPadvocate-01, vigorousrecommend-01, RSHIFTrecommend01, advocate-01, vigorousRSHIFTR, recommend01, advocate-01, vigorousLA(root)R, recommend01, advocate-01, vigorousREDUCErecommend01, advocate-01, vigorousREDUCEadvocate-01, vigorousREDUCEvigorousREDUCE",
  "zA exp(gz.st+qz),": "where gz is a column vector representing the (output) embedding of the action z, and qz is a bias termfor action z. The set A represents the actions listed in . Note that due to parsing constraintsthe set of possible actions may vary. The total number of actions (in the LDC2014T12 dataset) is478; note that they include all possible labels (in the case of LA and RA ) and the different dependentnodes for the DEPENDENT action.",
  "eN exp(ge.st+qe),": "where N is the set of possible candidate nodes for the word at the top of the STACK. ge is a columnvector representing the (output) embedding of the node e, and qe is a bias term for the node e. It isimportant to mention that this implies finding a propbank sense or a lemma. For that, we rely entirelyon the AMR training set instead of using additional resources. Given that the system runs two softmax operations, one to predict the action to take and the secondone to predict the corresponding AMR node, and they both share LSTMs to make predictions, weinclude an additional layer with a tanh nonlinearity after st for each softmax.",
  "Word Representations": "We use character-based representations of words using bidirectional LSTMs . They learn represen-tations for words that are orthographically similar. Note that they are updated with the updates tothe model. demonstrated that it is possible to achieve high results in syntactic parsing and namedentity recognition by just using character-based word representations (not even POS tags, in fact, insome cases the results with just character-based representations outperform those that used explicitPOS tags since they provide similar vectors for words with similar/same morphosyntactic tag); in thispaper we show a similar result given that both syntactic parsing and named-entity recognition play acentral role in AMR parsing. These are concatenated with pretrained word embeddings. We use a variant of the skip n-gram modelwith the LDC English Gigaword corpus (version 5). These embeddings encode the syntactic behaviorof the words . More formally, to represent each input token, we concatenate two vectors: a learned character-basedrepresentation ( wC); and a fixed vector representation from a neural language model ( wLM). A linearmap (V) is applied to the resulting vector and passed through a component-wise ReLU,",
  "ModelF1(Newswire)F1(ALL)": "(POS, DEP)0.590.58(POS, DEP, NER)-0.66(POS, DEP, NER)0.62-(POS, DEP, NER, SRL)-0.61(POS, DEP, NER, SRL)-0.64(POS, CCG)0.66-(POS, DEP, NER)0.70-(POS, DEP, NER, SRL)0.710.66(LM, NER)-0.61(Wordnet, LM, NER)-0.66(POS, DEP, NER)0.630.59(POS, DEP, NER, SRL)0.700.66OUR PARSER (NO PRETRAINED-NO CHARS)0.640.59OUR PARSER (NO PRETRAINED-WITH CHARS)0.660.61OUR PARSER (WITH PRETRAINED-NO CHARS)0.660.62OUR PARSER0.680.63OUR PARSER (POS)0.680.63OUR PARSER (POS, DEP)0.690.64 : AMR results on the LDC2014T12 dataset; Newsire section (left) and full (right). Rowslabeled with OUR-PARSER show our results. POS indicates that the system uses preprocessed POStags, DEP indicates that it uses preprocessed dependency trees, SRL indicates that it uses preprocessedsemantic roles, NER indicates that it uses preprocessed named entitites. LM indicates that it usesa LM trained on AMR data and WordNet indicates that it uses WordNet to predict the concepts.Systems marked with * are pipeline systems that require a dependency parse as input. (WITHPRETRAINED-NO CHARS) shows the results of our parser without character-based representations.(NO PRETRAINED-WITH CHARS) shows results without pretrained word embeddings. (NOPRETRAINED-NO CHARS) shows results without character-based representations and withoutpretrained word embeddings. The rest of our results include both pretrained embeddings and character-based representations.",
  "POS tags: The POS tags are preprocessed and a learned representation tag is concatenated with theword representations. This is the same setting as": "Dependency Trees: We use them in the same way as POS tags by concatenating a learned representa-tion dep of the dependency label to the parent with the word representation. Additionally, we enrichthe state representation st, presented in .2. If the two words at the top of the STACK have adependency between them, st is enriched with a learned representation that indicates that and thedirection; otherwise st remains unchanged. st is calculated as follows:",
  "We use the LDC2014T12 dataset for our experiments. shows results, including comparisonwith prior work that are also evaluated on the same dataset": "Our model achieves 0.68 F1 in the newswire section of the test set just by using character-basedrepresentations of words and pretrained word embeddings. All prior work uses lemmatizers, POStaggers, dependency parsers, named entity recognizers and semantic role labelers that use additionaltraining data while we achieve competitive scores without that. reports 0.66 F1 in the full test byusing WordNet for concept identification, but their performance drops to 0.61 without WordNet. It isworth noting that we achieved 0.64 in the same test set without WordNet. without SRL (via Propbank)achieves only 0.63 in the newswire test set while we achieved 0.69 without SRL (and 0.68 withoutdependency trees). In order to see whether pretrained word embeddings and character-based embeddings are useful wecarried out an ablation study by showing the results of our parser with and without character-basedrepresentations (replaced by standard lookup table learned embeddings) and with and without pre-trained word embeddings. By looking at the results of the parser without character-based embeddingsbut with pretrained word embeddings we observe that the character- based representation of wordsare useful since they help to achieve 2 points better in the Newswire dataset and 1 point more in thefull test set. The parser with character-based embeddings but without pretrained word embeddings,the parser has more difficulty to learn and only achieves 0.61 in the full test set. Finally, the modelthat does not use neither character-based embeddings nor pretrained word embeddings is the worstachieving only 0.59 in the full test set, note that this model has no explicity way of getting anysyntactic information through the word embeddings nor a smart way to handle out of vocabularywords. All the systems marked with * require that the input is a dependency tree, which means that theysolve a transduction task between a dependency tree and an AMR graph. Even though our parserstarts from plain text sentences when we incorporate more information into our model, we achievefurther improvements. POS tags provide small improvements (0.6801 without POS tags vs 0.6822for the model that runs with POS tags). Dependency trees help a bit more achieving 0.6920.",
  "Conclusions and Future Work": "We present a new transition-based algorithm for AMR parsing and we implement it using Stack-LSTMS and a greedy decoder. We present competitive results, without any additional resourcesand external tools. Just by looking at the words, we achieve 0.68 F1 (and 0.69 by preprocessingdependency trees) in the standard dataset used for evaluation."
}