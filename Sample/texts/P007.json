{
  "Abstract": "Discourse parsing has long been treated as a stand-alone problem independent fromconstituency or dependency parsing. Most attempts at this problem are pipelinedrather than end-to-end, sophisticated, and not self-contained: they assume gold-standard text segmentations (Elementary Discourse Units), and use external parsersfor syntactic features. In this paper we propose the first end-to-end discourseparser that jointly parses in both syntax and discourse levels, as well as the firstsyntacto-discourse treebank by integrating the Penn Treebank with the RST Tree-bank. Built upon our recent span-based constituency parser, this joint syntacto-discourse parser requires no preprocessing whatsoever (such as segmentation orfea- ture extraction), achieves the state-of-the- art end-to-end discourse parsingaccuracy.",
  ". not self-contained: they rely on external syntactic parsers and pretrained word vectors;3. complicated: they design sophisticated features, including those from parse-trees": "We argue for the first time that discourse parsing should be viewed as an extension of, and beperformed in conjunction with, constituency parsing. We propose the first joint syntacto-discoursetree- bank, by unifying constituency and discourse tree representations. Based on this, we proposethe first end-to-end incremental parser that jointly parses at both constituency and discourse levels.Our algo- rithm builds up on the span-based parser; it employs the strong general- ization powerof bi-directional LSTMs, and parses efficiently and robustly with an extremely simple span-basedfeature set that does not use any tree structure information.",
  "We make the following contributions:": "1. We develop a combined representation of constituency and discourse trees to facilitateparsing at both levels without explicit conver- sion mechanism. Using this representation,we build and release a joint treebank based on the Penn Treebank and RST Treebank. 2. We propose a novel joint parser that parses at both constituency and discourse levels.3. Even though it simultaneously performs con- stituency parsing, our parser does not use anyexplicit syntactic feature, nor does it need any binarization of discourse trees, thanks to thepowerful span-based framework. 4. Empirically, our end-to-end parser outperforms the existing pipelined discourse pars- ingefforts. When the gold EDUs are pro- vided, our parser is also competitive to other existingapproaches with sophisticated fea- tures.",
  "Review: RST Discourse Structures": "In an RST discourse tree, there are two types of branchings. Most of the internal tree nodes are binarybranching, with one nucleus child containing the core semantic meaning of the current node, andone satellite child semantically decorating the nucleus. Like dependency labels, there is a relationannotated between each satellite-nucleus pair, such as Background or Purpose. There are alsonon- binary-branching internal nodes whose children are conjunctions, e.g., a List of semanticallysimilar EDUs (which are all nucleus nodes).",
  "Syntacto-Discourse Representation": "It is widely recognized that lower-level lexical and syntactic information can greatly help determin-ing both the boundaries of the EDUs (i.e., dis- course segmentation) as well as the semantic relationsbetween EDUs. While these previous approaches rely on pre-trained tools to provide both EDUsegmentation and intra-EDU syntactic parse trees, we in- stead propose to directly determine thelow-level segmentations, the syntactic parses, and the high- level discourse parses using a single jointparser. This parser is trained on the combined trees of constituency and discourse structures. We first convert an RST tree to a format similar to those constituency trees in the Penn Treebank. Foreach binary branching node with a nucleus child and a satellite child, we use the relation as the labelof the converted parent node. The nucleus/satellite relation, along with the direction (either or ,pointing from satellite to nucleus) is then used as the label. For a conjunctive branch (e.g. List), wesimply use the relation as the label of the converted node. After converting an RST tree into the constituency tree format, we then replace each leaf node (i.e.,EDU) with the corresponding syntactic (sub)tree from PTB. Given that the sentences in the RSTTreebank is a subset of that of PTB, we can always find the corresponding constituency subtrees foreach EDU leaf node. In most cases, each EDU corresponds to one sin- gle (sub)tree in PTB, since thediscourse bound- aries generally do not conflict with constituencies. In other cases, one EDU nodemay correspond to multiple subtrees in PTB, and for these EDUs we use the lowest common ancestorof those subtrees in the PTB as the label of that EDU in the con- verted tree. E.g., if CD is one EDUin the PTB tree A it might be converted to PurposeDCB A based on the Penn Treebank and RSTTreebank. This PTB-RST treebank is released as a set of tools to generate the joint trees given PennTree- bank and RST Treebank data. During the align- ment between the RST trees and the PTB trees,we only keep the common parts of the two trees. We follow the standard training/testing split of the RST Treebank. In the training set, there are 347joint trees with a total of 17,837 tokens, and the lengths of the discourses range from 30 to 2,199tokens. In the test set, there are 38 joint trees with a total of 4,819 tokens, and the lengths vary from45 to 2,607. shows the distribution of the discourse lengths over the whole dataset, which onaverage is about 2x of PTB sen- tence length, but longest ones are about 10x the longest lengths inthe Treebank.",
  "Using the conversion strategy described above we build the first joint syntacto-discourse treebank": "As in span-based parsing, at each step, we main- tain a a stack of spans. Notice that in conventionalincremental parsing, the stack stores the subtrees constructed so far, but in span-based constituencyparsing, the stack only stores the boundaries of subtrees, which are just a list of indices ...i k j. Inother words, quite shockingly, no tree structure is represented anywhere in the parser. Similar to span-based constituency parsing, we alternate between structural (either shift or combine)and label (labelX or nolabel) actions in an odd-even fashion. But different from previous work, after astructural action, we choose to keep the last branching point k, i.e., i k j (mostly for combine, but alsotrivially for shift). This is because in our parsing mechanism, the dis- course relation between twoEDUs is actually de- termined after the previous combine action. We need to keep the splitting pointto clearly find the spans of the two EDUs to determine their relations. This midpoint k disappearsafter a label ac- tion; therefore we can use the shape of the last span on the stack (whether it containsthe split point, i.e., i k j or i j) to determine the par- ity of the step and thus no longer need to carry thestep z in the state . The nolabel action makes the binarization of the discourse/constituency tree unnecessary, becausenolabel actually combines the top two spans on the stack into one span, but without annotating thenew span a label. This greatly simplifies the pre- processing and post-processing efforts needed.",
  "Recurrent Neural Models and Training": "The scoring functions in the deductive system are calculated by an underlying neu- ral model, whichis similar to the bi-directional LSTM model that evaluates based on span boundary features. Again, itis important to note that no discourse or syntactic tree structures are represented in the features. During the decoding time, a document is first passed into a two-layer bi-directional LSTM model,then the outputs at each text position of the two layers of the bi-directional LSTMs are con- catenatedas the positional features. The spans at each parsing step can be represented as the fea- ture vectorsat the boundaries. The span features are then passed into fully connected networks with softmax tocalculate the likelihood of performing the corresponding action or marking the cor- responding label.",
  "We use the treebank described in for empirical evaluation. We randomly choose 30documents from the training set as the development set": "We tune the hyperparameters of the neural model on the development set. For most of the hyperpa-rameters we settle with the same values sug- gested previously. To alleviate the overfitting problemfor training on the relative small RST Treebank, we use a dropout of 0.5. One particular hyperparameter is that we use a value to balance the chances between trainingfollowing the exploration (i.e., the best action cho- sen by the neural model) and following the correctpath provided by the dynamic oracle. We find that = 0.8, i.e., following the dynamic oracle with aprobability of 0.8, achieves the best performance. One explanation for this high chance to follow theoracle is that, since our combined trees are significantly larger than the constituency trees in PennTreebank, lower makes the parsing easily divert into wrong trails that are difficult to learn from. Since our parser essentially performs both constituency parsing task and discourse parsing task. Wealso evaluate the performances on sentence constituency level and discourse level separately. Theresult is shown in . Note that in constituency level, the accuracy is not directly comparablewith the accuracy reported previously, since: a) our parser is trained on a much smaller dataset (RSTTreebank is about 1/6 of Penn Treebank); b) the parser is trained to optimize the discourse-levelaccuracy. shows that, in the perspective of end- to-end discourse parsing, our parser first outper- formsthe state-of-the-art segmentator, and furthermore, in end-to-end pars- ing, the superiority of our parseris more pronounced comparing to the previously best parser. On the other hand, the majority of the conven- tional discourse parsers are not end-to-end: they relyon gold EDU segmentations and pre-trained tools like Stanford parsers to generate features. Weperform an experiment to compare the per- formance of our parser with them given the gold EDUsegments (). Note that most of these parsers do not handle multi-branching discourse nodesand are trained and evaluated on binarized discourse trees, so their performances are actually notdirectly comparable to the results we reported."
}