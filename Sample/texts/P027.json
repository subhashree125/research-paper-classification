{
  "Abstract": "Many current natural language processing applications for social media rely onrepresentation learning and utilize pre-trained word embeddings. There currentlyexist several publicly-available, pre-trained sets of word embeddings, but theycontain few or no emoji representations even as emoji usage in social media hasincreased. emoji2vec are pre-trained embeddings for all Unicode emojis which arelearned from their description in the Unicode emoji standard. The resulting emojiembeddings can be readily used in downstream social natural language processingapplications alongside word2vec. For the downstream task of sentiment analysis,emoji embeddings learned from short descriptions outperforms a skip-gram modeltrained on a large collection of tweets, while avoiding the need for contexts inwhich emojis need to appear frequently in order to estimate a representation.",
  "Introduction": "First introduced in 1997, emojis, a standardized set of small pictorial glyphs depicting everythingfrom smiling faces to international flags, have seen a drastic increase in usage in social media overthe last decade. The Oxford Dictionary named 2015 the year of the emoji, citing an increase in usageof over 800% during the course of the year, and elected the Face with Tears of Joy emoji () as theWord of the Year. As of this writing, over 10% of Twitter posts and over 50% of text on Instagramcontain one or more emojis. Due to their popularity and broad usage, they have been the subjectof much formal and informal research in language and social communication, as well as in naturallanguage processing (NLP). In the context of social sciences, research has focused on emoji usage as a means of expressingemotions on mobile platforms. Interestingly, although essentially thought of as means of expressingemotions, emojis have been adopted as tools to express relationally useful roles in conversation.Emojis are culturally and contextually bound, and are open to reinterpretation and misinterpretation.These findings have paved the way for many formal analyses of semantic characteristics of emojis. Concurrently we observe an increased interest in natural language processing on social mediadata. Many current NLP systems applied to social media rely on representation learning and wordembeddings. Such systems often rely on pre-trained word embeddings that can for instance beobtained from word2vec or GloVe. Yet, neither resource contain a complete set of Unicode emojirepresentations, which suggests that many social NLP applications could be improved by the additionof robust emoji representations. Embeddings for emoji Unicode symbols are learned from their description in the Unicode emojistandard. The usefulness of emoji representations trained in this way is demonstrated by evaluating ona Twitter sentiment analysis task. Furthermore, a qualitative analysis by investigating emoji analogyexamples and visualizing the emoji embedding space is provided.",
  "Related Work": "There has been little work in distributional embeddings of emojis. The first research done inthis direction was an informal blog post by the Instagram Data Team in 2015. They generatedvector embeddings for emojis similar to skip-gram-based vectors by training on the entire corpusof Instagram posts. Their research gave valuable insight into the usage of emojis on Instagram,and showed that distributed representations can help understanding emoji semantics in everydayusage. The second contribution, closest to ours, trained emoji embeddings from a large Twitterdataset of over 100 million English tweets using the skip-gram method. These pre-trained emojirepresentations led to increased accuracy on a similarity task, and a meaningful clustering of theemoji embedding space. While this method is able to learn robust representations for frequently-usedemojis, representations of less frequent emojis are estimated rather poorly or not available at all. Infact, only around 700 emojis can be found in this corpus, while there is support of over 1600 emojisin the Unicode standard. The approach differs in two important aspects. First, since the representation of emojis are estimateddirectly from their description, robust representations are obtained for all supported emoji symbols even the long tail of infrequently used ones. Secondly, the method works with much less data. Insteadof training on millions of tweets, the representations are trained on only a few thousand descriptions.Still, higher accuracy results are obtained on a Twitter sentiment analysis task. In addition, the work relates to building word representations for words and concepts based on theirdescription in a dictionary. Similarly to their approach, representations are build for emojis based ontheir descriptions and keyword phrases. Some of the limitations are evident in the work who showed that different cultural phenomena andlanguages may co-opt conventional emoji sentiment. Since training is only on English-languagedefinitions and ignore temporal definitions of emojis, the training method might not capture the fullsemantic characteristics of an emoji.",
  "Methodology": "The method maps emoji symbols into the same space as the 300-dimensional Google News word2vecembeddings. Thus, the resulting emoji2vec embeddings can be used in addition to 300-dimensionalword2vec embeddings in any application. To this end emojis, their name and their keyword phrasesare crawled from the Unicode emoji list, resulting in 6088 descriptions of 1661 emoji symbols.",
  "k=1wk,(1)": "where wk is the word2vec vector for word wk if that vector exists (otherwise we drop the summand)and vj is the vector representation of the description. A trainable vector xi for every emoji inour training set is defined, and the probability of a match between the emoji representation xiand its description representation vj is modeled using the sigmoid of the dot product of the tworepresentations (xTi vj). For training we use the logistic loss",
  "The model is implemented in TensorFlow and optimized using stochastic gradient descent with Adamas optimizer. As we do not observe any negative training examples (invalid descriptions of emojis do": "not appear in the original training set), to increase generalization performance we randomly sampledescriptions for emojis as negative instances (i.e. induce a mismatched description). One of theparameters of our model is the ratio of negative samples to positive samples; we found that havingone positive example per negative example produced the best results. We perform early-stopping ona held-out development set and found 80 epochs of training to give the best results. As we are onlytraining on emoji descriptions and our method is simple and cheap, training takes less than 3 minuteson a 2013 MacBook Pro.",
  "Emoji-Description Classification": "To analyze how well the method models the distribution of correct emoji descriptions, a manually-labeled test set containing pairs of emojis and phrases, as well as a correspondence label was created.For instance, the test set includes the example: , \"crying\", True, as well as the example , \"fish\", False.(xTi vi) is calculated for each example in the test set, measuring the similarity between the emojivector and the sum of word vectors in the phrase. When a classifier thresholds the above prediction at 0.5 to determine a positive or negative correlation,an accuracy of 85.5% is obtained for classifying whether an emoji-description pair is valid or not.By varying the threshold used for this classifier, a receiver operating characteristic curve with anarea-under-the-curve of 0.933 is obtained, which demonstrates that high quality of the learned emojirepresentations.",
  "Sentiment Analysis on Tweets": "As downstream task the accuracy of sentiment classification of tweets for various classifiers with threedifferent sets of pre-trained word embeddings are compared: (1) the original Google News word2vecembeddings, (2) word2vec augmented with emoji embeddings trained by skip-gram model, and (3)word2vec augmented with emoji2vec trained from Unicode descriptions. A dataset is used whichconsists of over 67k English tweets labelled manually for positive, neutral, or negative sentiment.In both the training set and the test set, 46% of tweets are labeled neutral, 29% are labeled positive,and 25% are labeled negative. To compute the feature vectors for training, we summed the vectorscorresponding to each word or emoji in the text of the Tweet. The goal of this simple sentimentanalysis model is not to produce state-of-the-art results in sentiment analysis; it is simply to show thatincluding emojis adds discriminating information to a model, which could potentially be exploited inmore advanced social NLP systems. Because the labels are rather evenly distributed, accuracy is an effective metric in determiningperformance on this classification task. Results are reported in . Augmenting word2vecwith emoji embeddings improves overall classification accuracy on the full corpus, and substantiallyimproves classification performance for tweets that contain emojis. It suggests that emoji embeddingscould improve performance for other social NLP tasks as well. Furthermore, emoji2vec generallyoutperforms the emoji embeddings trained by the skip-gram model, despite being trained on muchless data using a simple model.",
  "Analogy Task": "A well-known property of word2vec is that embeddings trained with this method to some extentcapture meaningful linear relationships between words directly in the vector space. For instance, itholds that the vector representation of king minus man plus woman is closest to queen. Wordembeddings have commonly been evaluated on such word analogy tasks. Unfortunately, it is difficultto build such an analogy task for emojis due to the small number and semantically distinct categoriesof emojis. Nevertheless, a few intuitive examples were collected. For every query the closest five",
  "Conclusion": "Since existing pre-trained word embeddings such as Google News word2vec embeddings or GloVefail to provide emoji embeddings, emoji2vec embeddings of 1661 emoji symbols were released.Instead of running word2vecs skip-gram model on a large collection of emojis and their contextsappearing in tweets, emoji2vec is directly trained on Unicode descriptions of emojis. The resultingemoji embeddings can be used to augment any downstream task that currently uses word2vecembeddings, and might prove especially useful in social NLP tasks where emojis are used frequently(e.g. Twitter, Instagram, etc.). Despite the fact that the model is simpler and trained on much lessdata, it outperforms the skip-gram model on the task of Twitter sentiment analysis. As the approach directly works on Unicode descriptions, it is not restricted to emoji symbols. Inthe future the usefulness of the method for other Unicode symbol embeddings will be investigated.Furthermore, plans are made to improve emoji2vec in the future by also reading full text emojidescriptions and using a recurrent neural network instead of a bag-of-word-vectors approach forenocoding descriptions. In addition, since the approach does not capture the context-dependentdefinitions of emojis (such as sarcasm, or appropriation via other cultural phenomena), mechanismswill be explored to efficiently capturing these nuanced meanings."
}